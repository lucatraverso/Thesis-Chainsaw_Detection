{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_io as tfio\n",
    "import dataLoader\n",
    "import modelo\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import evaluador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 183s 546ms/step - loss: 0.2657 - Accuracy: 0.9085 - Precision: 0.8305 - Recall: 0.7463 - TP: 2516.5100 - TN: 4737.6802 - FP: 909.3200 - FN: 855.4900 - val_loss: 0.1511 - val_Accuracy: 0.9613 - val_Precision: 0.9056 - val_Recall: 0.8499 - val_TP: 683.3200 - val_TN: 1005.0000 - val_FP: 101.0000 - val_FN: 120.6800\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1429 - Accuracy: 0.9625 - Precision: 0.9049 - Recall: 0.8595 - TP: 2898.1699 - TN: 5229.3701 - FP: 417.6300 - FN: 473.8300 - val_loss: 0.1134 - val_Accuracy: 0.9660 - val_Precision: 0.9259 - val_Recall: 0.8898 - val_TP: 715.4200 - val_TN: 1037.7800 - val_FP: 68.2200 - val_FN: 88.5800\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1177 - Accuracy: 0.9676 - Precision: 0.9165 - Recall: 0.8888 - TP: 2997.1201 - TN: 5314.2598 - FP: 332.7400 - FN: 374.8800 - val_loss: 0.0995 - val_Accuracy: 0.9696 - val_Precision: 0.9369 - val_Recall: 0.9033 - val_TP: 726.2400 - val_TN: 1052.1400 - val_FP: 53.8600 - val_FN: 77.7600\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1075 - Accuracy: 0.9696 - Precision: 0.9262 - Recall: 0.9003 - TP: 3035.9299 - TN: 5368.3701 - FP: 278.6300 - FN: 336.0700 - val_loss: 0.0938 - val_Accuracy: 0.9733 - val_Precision: 0.9367 - val_Recall: 0.9158 - val_TP: 736.2900 - val_TN: 1051.1500 - val_FP: 54.8500 - val_FN: 67.7100\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0994 - Accuracy: 0.9705 - Precision: 0.9288 - Recall: 0.9094 - TP: 3066.5701 - TN: 5386.0200 - FP: 260.9800 - FN: 305.4300 - val_loss: 0.0874 - val_Accuracy: 0.9733 - val_Precision: 0.9460 - val_Recall: 0.9173 - val_TP: 737.5000 - val_TN: 1063.4900 - val_FP: 42.5100 - val_FN: 66.5000\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0928 - Accuracy: 0.9721 - Precision: 0.9338 - Recall: 0.9140 - TP: 3082.1299 - TN: 5410.8301 - FP: 236.1700 - FN: 289.8700 - val_loss: 0.0868 - val_Accuracy: 0.9749 - val_Precision: 0.9438 - val_Recall: 0.9232 - val_TP: 742.2400 - val_TN: 1059.9301 - val_FP: 46.0700 - val_FN: 61.7600\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0898 - Accuracy: 0.9727 - Precision: 0.9354 - Recall: 0.9189 - TP: 3098.5400 - TN: 5420.7598 - FP: 226.2400 - FN: 273.4600 - val_loss: 0.0837 - val_Accuracy: 0.9749 - val_Precision: 0.9475 - val_Recall: 0.9251 - val_TP: 743.7800 - val_TN: 1064.5900 - val_FP: 41.4100 - val_FN: 60.2200\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0849 - Accuracy: 0.9737 - Precision: 0.9374 - Recall: 0.9220 - TP: 3108.9199 - TN: 5431.1802 - FP: 215.8200 - FN: 263.0800 - val_loss: 0.0799 - val_Accuracy: 0.9749 - val_Precision: 0.9506 - val_Recall: 0.9279 - val_TP: 746.0600 - val_TN: 1069.0500 - val_FP: 36.9500 - val_FN: 57.9400\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0845 - Accuracy: 0.9743 - Precision: 0.9388 - Recall: 0.9247 - TP: 3118.0801 - TN: 5438.5801 - FP: 208.4200 - FN: 253.9200 - val_loss: 0.0817 - val_Accuracy: 0.9754 - val_Precision: 0.9506 - val_Recall: 0.9281 - val_TP: 746.2300 - val_TN: 1067.8500 - val_FP: 38.1500 - val_FN: 57.7700\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0807 - Accuracy: 0.9747 - Precision: 0.9409 - Recall: 0.9264 - TP: 3123.9500 - TN: 5449.3901 - FP: 197.6100 - FN: 248.0500 - val_loss: 0.0780 - val_Accuracy: 0.9749 - val_Precision: 0.9526 - val_Recall: 0.9311 - val_TP: 748.5700 - val_TN: 1071.2700 - val_FP: 34.7300 - val_FN: 55.4300\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0785 - Accuracy: 0.9748 - Precision: 0.9419 - Recall: 0.9285 - TP: 3130.8999 - TN: 5453.3501 - FP: 193.6500 - FN: 241.1000 - val_loss: 0.0825 - val_Accuracy: 0.9743 - val_Precision: 0.9471 - val_Recall: 0.9317 - val_TP: 749.1100 - val_TN: 1063.8199 - val_FP: 42.1800 - val_FN: 54.8900\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0768 - Accuracy: 0.9761 - Precision: 0.9436 - Recall: 0.9294 - TP: 3133.9399 - TN: 5461.5801 - FP: 185.4200 - FN: 238.0600 - val_loss: 0.0781 - val_Accuracy: 0.9743 - val_Precision: 0.9504 - val_Recall: 0.9350 - val_TP: 751.7200 - val_TN: 1068.2600 - val_FP: 37.7400 - val_FN: 52.2800\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0744 - Accuracy: 0.9754 - Precision: 0.9432 - Recall: 0.9316 - TP: 3141.4399 - TN: 5459.0200 - FP: 187.9800 - FN: 230.5600 - val_loss: 0.0773 - val_Accuracy: 0.9754 - val_Precision: 0.9554 - val_Recall: 0.9327 - val_TP: 749.8600 - val_TN: 1073.8000 - val_FP: 32.2000 - val_FN: 54.1400\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0743 - Accuracy: 0.9769 - Precision: 0.9448 - Recall: 0.9321 - TP: 3143.1499 - TN: 5467.8501 - FP: 179.1500 - FN: 228.8500 - val_loss: 0.0759 - val_Accuracy: 0.9754 - val_Precision: 0.9544 - val_Recall: 0.9356 - val_TP: 752.2000 - val_TN: 1073.1500 - val_FP: 32.8500 - val_FN: 51.8000\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0719 - Accuracy: 0.9764 - Precision: 0.9450 - Recall: 0.9336 - TP: 3148.0601 - TN: 5468.9702 - FP: 178.0300 - FN: 223.9400 - val_loss: 0.0752 - val_Accuracy: 0.9759 - val_Precision: 0.9583 - val_Recall: 0.9339 - val_TP: 750.8700 - val_TN: 1077.3500 - val_FP: 28.6500 - val_FN: 53.1300\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0731 - Accuracy: 0.9772 - Precision: 0.9457 - Recall: 0.9351 - TP: 3153.0100 - TN: 5471.8101 - FP: 175.1900 - FN: 218.9900 - val_loss: 0.0788 - val_Accuracy: 0.9759 - val_Precision: 0.9556 - val_Recall: 0.9335 - val_TP: 750.5700 - val_TN: 1073.4500 - val_FP: 32.5500 - val_FN: 53.4300\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0726 - Accuracy: 0.9773 - Precision: 0.9472 - Recall: 0.9345 - TP: 3151.0400 - TN: 5479.1299 - FP: 167.8700 - FN: 220.9600 - val_loss: 0.0740 - val_Accuracy: 0.9754 - val_Precision: 0.9566 - val_Recall: 0.9376 - val_TP: 753.8200 - val_TN: 1075.7800 - val_FP: 30.2200 - val_FN: 50.1800\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0706 - Accuracy: 0.9777 - Precision: 0.9462 - Recall: 0.9371 - TP: 3159.8000 - TN: 5474.9800 - FP: 172.0200 - FN: 212.2000 - val_loss: 0.0760 - val_Accuracy: 0.9759 - val_Precision: 0.9590 - val_Recall: 0.9348 - val_TP: 751.5700 - val_TN: 1077.6100 - val_FP: 28.3900 - val_FN: 52.4300\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0681 - Accuracy: 0.9777 - Precision: 0.9484 - Recall: 0.9363 - TP: 3157.3101 - TN: 5485.0698 - FP: 161.9300 - FN: 214.6900 - val_loss: 0.0804 - val_Accuracy: 0.9759 - val_Precision: 0.9488 - val_Recall: 0.9376 - val_TP: 753.8500 - val_TN: 1066.3900 - val_FP: 39.6100 - val_FN: 50.1500\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0674 - Accuracy: 0.9783 - Precision: 0.9482 - Recall: 0.9381 - TP: 3163.3201 - TN: 5483.7100 - FP: 163.2900 - FN: 208.6800 - val_loss: 0.0747 - val_Accuracy: 0.9754 - val_Precision: 0.9572 - val_Recall: 0.9383 - val_TP: 754.4100 - val_TN: 1075.9100 - val_FP: 30.0900 - val_FN: 49.5900\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0660 - Accuracy: 0.9786 - Precision: 0.9489 - Recall: 0.9385 - TP: 3164.6599 - TN: 5486.0801 - FP: 160.9200 - FN: 207.3400 - val_loss: 0.0731 - val_Accuracy: 0.9759 - val_Precision: 0.9579 - val_Recall: 0.9392 - val_TP: 755.1500 - val_TN: 1077.2100 - val_FP: 28.7900 - val_FN: 48.8500\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0674 - Accuracy: 0.9785 - Precision: 0.9491 - Recall: 0.9387 - TP: 3165.1699 - TN: 5487.5498 - FP: 159.4500 - FN: 206.8300 - val_loss: 0.0744 - val_Accuracy: 0.9759 - val_Precision: 0.9578 - val_Recall: 0.9389 - val_TP: 754.8400 - val_TN: 1076.7000 - val_FP: 29.3000 - val_FN: 49.1600\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0657 - Accuracy: 0.9784 - Precision: 0.9494 - Recall: 0.9391 - TP: 3166.6399 - TN: 5488.5698 - FP: 158.4300 - FN: 205.3600 - val_loss: 0.0734 - val_Accuracy: 0.9759 - val_Precision: 0.9599 - val_Recall: 0.9385 - val_TP: 754.5800 - val_TN: 1079.0601 - val_FP: 26.9400 - val_FN: 49.4200\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0638 - Accuracy: 0.9796 - Precision: 0.9502 - Recall: 0.9397 - TP: 3168.8101 - TN: 5491.8999 - FP: 155.1000 - FN: 203.1900 - val_loss: 0.0750 - val_Accuracy: 0.9764 - val_Precision: 0.9562 - val_Recall: 0.9403 - val_TP: 755.9800 - val_TN: 1074.6700 - val_FP: 31.3300 - val_FN: 48.0200\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0637 - Accuracy: 0.9792 - Precision: 0.9500 - Recall: 0.9404 - TP: 3170.8999 - TN: 5491.6699 - FP: 155.3300 - FN: 201.1000 - val_loss: 0.0736 - val_Accuracy: 0.9759 - val_Precision: 0.9615 - val_Recall: 0.9380 - val_TP: 754.1700 - val_TN: 1080.6801 - val_FP: 25.3200 - val_FN: 49.8300\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0633 - Accuracy: 0.9796 - Precision: 0.9503 - Recall: 0.9408 - TP: 3172.3701 - TN: 5492.8799 - FP: 154.1200 - FN: 199.6300 - val_loss: 0.0741 - val_Accuracy: 0.9764 - val_Precision: 0.9607 - val_Recall: 0.9386 - val_TP: 754.6300 - val_TN: 1079.6801 - val_FP: 26.3200 - val_FN: 49.3700\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0642 - Accuracy: 0.9796 - Precision: 0.9500 - Recall: 0.9415 - TP: 3174.8799 - TN: 5492.3701 - FP: 154.6300 - FN: 197.1200 - val_loss: 0.0750 - val_Accuracy: 0.9770 - val_Precision: 0.9591 - val_Recall: 0.9392 - val_TP: 755.0900 - val_TN: 1077.7400 - val_FP: 28.2600 - val_FN: 48.9100\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0637 - Accuracy: 0.9796 - Precision: 0.9508 - Recall: 0.9415 - TP: 3174.7400 - TN: 5495.5698 - FP: 151.4300 - FN: 197.2600 - val_loss: 0.0741 - val_Accuracy: 0.9764 - val_Precision: 0.9620 - val_Recall: 0.9381 - val_TP: 754.2400 - val_TN: 1081.0800 - val_FP: 24.9200 - val_FN: 49.7600\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0626 - Accuracy: 0.9789 - Precision: 0.9518 - Recall: 0.9411 - TP: 3173.2700 - TN: 5499.7002 - FP: 147.3000 - FN: 198.7300 - val_loss: 0.0726 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9403 - val_TP: 755.9700 - val_TN: 1080.1200 - val_FP: 25.8800 - val_FN: 48.0300\n",
      "Epoch 30/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0608 - Accuracy: 0.9796 - Precision: 0.9516 - Recall: 0.9422 - TP: 3177.1001 - TN: 5498.6899 - FP: 148.3100 - FN: 194.9000 - val_loss: 0.0731 - val_Accuracy: 0.9770 - val_Precision: 0.9618 - val_Recall: 0.9397 - val_TP: 755.5000 - val_TN: 1081.0200 - val_FP: 24.9800 - val_FN: 48.5000\n",
      "Epoch 31/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0602 - Accuracy: 0.9803 - Precision: 0.9517 - Recall: 0.9427 - TP: 3178.9299 - TN: 5499.3799 - FP: 147.6200 - FN: 193.0700 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9592 - val_Recall: 0.9402 - val_TP: 755.9400 - val_TN: 1077.8900 - val_FP: 28.1100 - val_FN: 48.0600\n",
      "Epoch 32/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0604 - Accuracy: 0.9806 - Precision: 0.9518 - Recall: 0.9432 - TP: 3180.5000 - TN: 5500.1602 - FP: 146.8400 - FN: 191.5000 - val_loss: 0.0729 - val_Accuracy: 0.9770 - val_Precision: 0.9621 - val_Recall: 0.9401 - val_TP: 755.8500 - val_TN: 1081.3400 - val_FP: 24.6600 - val_FN: 48.1500\n",
      "Epoch 33/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0598 - Accuracy: 0.9797 - Precision: 0.9518 - Recall: 0.9433 - TP: 3180.8799 - TN: 5500.2700 - FP: 146.7300 - FN: 191.1200 - val_loss: 0.0765 - val_Accuracy: 0.9770 - val_Precision: 0.9559 - val_Recall: 0.9410 - val_TP: 756.6000 - val_TN: 1074.4100 - val_FP: 31.5900 - val_FN: 47.4000\n",
      "Epoch 34/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0594 - Accuracy: 0.9798 - Precision: 0.9531 - Recall: 0.9433 - TP: 3180.7600 - TN: 5504.9600 - FP: 142.0400 - FN: 191.2400 - val_loss: 0.0728 - val_Accuracy: 0.9775 - val_Precision: 0.9618 - val_Recall: 0.9409 - val_TP: 756.5200 - val_TN: 1081.1300 - val_FP: 24.8700 - val_FN: 47.4800\n",
      "Epoch 35/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0593 - Accuracy: 0.9810 - Precision: 0.9523 - Recall: 0.9445 - TP: 3184.7000 - TN: 5502.3599 - FP: 144.6400 - FN: 187.3000 - val_loss: 0.0727 - val_Accuracy: 0.9770 - val_Precision: 0.9621 - val_Recall: 0.9411 - val_TP: 756.6600 - val_TN: 1081.4700 - val_FP: 24.5300 - val_FN: 47.3400\n",
      "Epoch 36/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0580 - Accuracy: 0.9806 - Precision: 0.9532 - Recall: 0.9442 - TP: 3183.8101 - TN: 5505.4902 - FP: 141.5100 - FN: 188.1900 - val_loss: 0.0732 - val_Accuracy: 0.9770 - val_Precision: 0.9630 - val_Recall: 0.9403 - val_TP: 755.9700 - val_TN: 1082.2600 - val_FP: 23.7400 - val_FN: 48.0300\n",
      "Epoch 37/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0576 - Accuracy: 0.9807 - Precision: 0.9532 - Recall: 0.9448 - TP: 3185.7700 - TN: 5505.1499 - FP: 141.8500 - FN: 186.2300 - val_loss: 0.0733 - val_Accuracy: 0.9775 - val_Precision: 0.9641 - val_Recall: 0.9398 - val_TP: 755.5600 - val_TN: 1083.3800 - val_FP: 22.6200 - val_FN: 48.4400\n",
      "Epoch 38/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0563 - Accuracy: 0.9815 - Precision: 0.9539 - Recall: 0.9450 - TP: 3186.7000 - TN: 5507.7300 - FP: 139.2700 - FN: 185.3000 - val_loss: 0.0730 - val_Accuracy: 0.9770 - val_Precision: 0.9630 - val_Recall: 0.9411 - val_TP: 756.6100 - val_TN: 1082.3199 - val_FP: 23.6800 - val_FN: 47.3900\n",
      "Epoch 39/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0561 - Accuracy: 0.9817 - Precision: 0.9541 - Recall: 0.9450 - TP: 3186.4600 - TN: 5508.9102 - FP: 138.0900 - FN: 185.5400 - val_loss: 0.0737 - val_Accuracy: 0.9770 - val_Precision: 0.9616 - val_Recall: 0.9415 - val_TP: 756.9500 - val_TN: 1080.7800 - val_FP: 25.2200 - val_FN: 47.0500\n",
      "Epoch 40/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0559 - Accuracy: 0.9812 - Precision: 0.9538 - Recall: 0.9460 - TP: 3190.0400 - TN: 5507.7798 - FP: 139.2200 - FN: 181.9600 - val_loss: 0.0734 - val_Accuracy: 0.9770 - val_Precision: 0.9638 - val_Recall: 0.9406 - val_TP: 756.2300 - val_TN: 1083.0699 - val_FP: 22.9300 - val_FN: 47.7700\n",
      "Epoch 41/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0555 - Accuracy: 0.9816 - Precision: 0.9548 - Recall: 0.9456 - TP: 3188.6699 - TN: 5511.7900 - FP: 135.2100 - FN: 183.3300 - val_loss: 0.0731 - val_Accuracy: 0.9770 - val_Precision: 0.9641 - val_Recall: 0.9406 - val_TP: 756.2100 - val_TN: 1083.4600 - val_FP: 22.5400 - val_FN: 47.7900\n",
      "Epoch 42/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0569 - Accuracy: 0.9812 - Precision: 0.9542 - Recall: 0.9458 - TP: 3189.1899 - TN: 5510.2798 - FP: 136.7200 - FN: 182.8100 - val_loss: 0.0731 - val_Accuracy: 0.9780 - val_Precision: 0.9624 - val_Recall: 0.9420 - val_TP: 757.3500 - val_TN: 1081.7800 - val_FP: 24.2200 - val_FN: 46.6500\n",
      "Epoch 43/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0556 - Accuracy: 0.9819 - Precision: 0.9545 - Recall: 0.9463 - TP: 3190.7900 - TN: 5510.8799 - FP: 136.1200 - FN: 181.2100 - val_loss: 0.0814 - val_Accuracy: 0.9754 - val_Precision: 0.9515 - val_Recall: 0.9412 - val_TP: 756.6900 - val_TN: 1070.3900 - val_FP: 35.6100 - val_FN: 47.3100\n",
      "Epoch 44/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0570 - Accuracy: 0.9816 - Precision: 0.9542 - Recall: 0.9460 - TP: 3189.9900 - TN: 5510.3599 - FP: 136.6400 - FN: 182.0100 - val_loss: 0.0727 - val_Accuracy: 0.9770 - val_Precision: 0.9616 - val_Recall: 0.9431 - val_TP: 758.2600 - val_TN: 1081.0300 - val_FP: 24.9700 - val_FN: 45.7400\n",
      "Epoch 45/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0545 - Accuracy: 0.9817 - Precision: 0.9545 - Recall: 0.9469 - TP: 3192.8899 - TN: 5511.5898 - FP: 135.4100 - FN: 179.1100 - val_loss: 0.0732 - val_Accuracy: 0.9775 - val_Precision: 0.9635 - val_Recall: 0.9416 - val_TP: 757.0300 - val_TN: 1082.8800 - val_FP: 23.1200 - val_FN: 46.9700\n",
      "Epoch 46/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0553 - Accuracy: 0.9819 - Precision: 0.9549 - Recall: 0.9465 - TP: 3191.7300 - TN: 5512.6802 - FP: 134.3200 - FN: 180.2700 - val_loss: 0.0731 - val_Accuracy: 0.9775 - val_Precision: 0.9637 - val_Recall: 0.9419 - val_TP: 757.2700 - val_TN: 1083.0500 - val_FP: 22.9500 - val_FN: 46.7300\n",
      "Epoch 47/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0567 - Accuracy: 0.9813 - Precision: 0.9545 - Recall: 0.9468 - TP: 3192.4800 - TN: 5511.9902 - FP: 135.0100 - FN: 179.5200 - val_loss: 0.0732 - val_Accuracy: 0.9775 - val_Precision: 0.9630 - val_Recall: 0.9425 - val_TP: 757.7300 - val_TN: 1082.4000 - val_FP: 23.6000 - val_FN: 46.2700\n",
      "Epoch 48/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0564 - Accuracy: 0.9823 - Precision: 0.9557 - Recall: 0.9467 - TP: 3192.3999 - TN: 5517.1802 - FP: 129.8200 - FN: 179.6000 - val_loss: 0.0838 - val_Accuracy: 0.9749 - val_Precision: 0.9438 - val_Recall: 0.9449 - val_TP: 759.6700 - val_TN: 1062.8900 - val_FP: 43.1100 - val_FN: 44.3300\n",
      "Epoch 49/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0539 - Accuracy: 0.9820 - Precision: 0.9544 - Recall: 0.9480 - TP: 3196.5400 - TN: 5510.7598 - FP: 136.2400 - FN: 175.4600 - val_loss: 0.0742 - val_Accuracy: 0.9780 - val_Precision: 0.9631 - val_Recall: 0.9419 - val_TP: 757.2500 - val_TN: 1082.4500 - val_FP: 23.5500 - val_FN: 46.7500\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 6ms/step - loss: 0.0632 - Accuracy: 0.9804 - Precision: 0.9535 - Recall: 0.9421 - TP: 3176.7900 - TN: 5507.6201 - FP: 139.3800 - FN: 195.2100 - val_loss: 0.0727 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9403 - val_TP: 756.0300 - val_TN: 1079.9700 - val_FP: 26.0300 - val_FN: 47.9700\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0620 - Accuracy: 0.9804 - Precision: 0.9532 - Recall: 0.9423 - TP: 3177.5801 - TN: 5506.0498 - FP: 140.9500 - FN: 194.4200 - val_loss: 0.0728 - val_Accuracy: 0.9770 - val_Precision: 0.9605 - val_Recall: 0.9404 - val_TP: 756.0800 - val_TN: 1079.7100 - val_FP: 26.2900 - val_FN: 47.9200\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0609 - Accuracy: 0.9804 - Precision: 0.9528 - Recall: 0.9426 - TP: 3178.4199 - TN: 5504.2402 - FP: 142.7600 - FN: 193.5800 - val_loss: 0.0730 - val_Accuracy: 0.9770 - val_Precision: 0.9602 - val_Recall: 0.9404 - val_TP: 756.1100 - val_TN: 1079.3101 - val_FP: 26.6900 - val_FN: 47.8900\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0600 - Accuracy: 0.9804 - Precision: 0.9525 - Recall: 0.9428 - TP: 3179.0601 - TN: 5502.2798 - FP: 144.7200 - FN: 192.9400 - val_loss: 0.0732 - val_Accuracy: 0.9770 - val_Precision: 0.9599 - val_Recall: 0.9405 - val_TP: 756.1600 - val_TN: 1078.9800 - val_FP: 27.0200 - val_FN: 47.8400\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0594 - Accuracy: 0.9806 - Precision: 0.9521 - Recall: 0.9430 - TP: 3179.8101 - TN: 5500.3198 - FP: 146.6800 - FN: 192.1900 - val_loss: 0.0734 - val_Accuracy: 0.9770 - val_Precision: 0.9595 - val_Recall: 0.9405 - val_TP: 756.1600 - val_TN: 1078.5800 - val_FP: 27.4200 - val_FN: 47.8400\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0590 - Accuracy: 0.9807 - Precision: 0.9517 - Recall: 0.9432 - TP: 3180.3101 - TN: 5498.4102 - FP: 148.5900 - FN: 191.6900 - val_loss: 0.0737 - val_Accuracy: 0.9770 - val_Precision: 0.9592 - val_Recall: 0.9405 - val_TP: 756.1900 - val_TN: 1078.2800 - val_FP: 27.7200 - val_FN: 47.8100\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0588 - Accuracy: 0.9807 - Precision: 0.9513 - Recall: 0.9433 - TP: 3180.8201 - TN: 5496.5298 - FP: 150.4700 - FN: 191.1800 - val_loss: 0.0739 - val_Accuracy: 0.9770 - val_Precision: 0.9590 - val_Recall: 0.9405 - val_TP: 756.1900 - val_TN: 1078.0100 - val_FP: 27.9900 - val_FN: 47.8100\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0586 - Accuracy: 0.9808 - Precision: 0.9512 - Recall: 0.9433 - TP: 3180.8501 - TN: 5495.8301 - FP: 151.1700 - FN: 191.1500 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9589 - val_Recall: 0.9405 - val_TP: 756.1900 - val_TN: 1077.9000 - val_FP: 28.1000 - val_FN: 47.8100\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0586 - Accuracy: 0.9807 - Precision: 0.9510 - Recall: 0.9434 - TP: 3181.0400 - TN: 5495.1602 - FP: 151.8400 - FN: 190.9600 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9589 - val_Recall: 0.9405 - val_TP: 756.1600 - val_TN: 1077.9399 - val_FP: 28.0600 - val_FN: 47.8400\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0585 - Accuracy: 0.9806 - Precision: 0.9511 - Recall: 0.9433 - TP: 3180.8000 - TN: 5495.1499 - FP: 151.8500 - FN: 191.2000 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9587 - val_Recall: 0.9404 - val_TP: 756.0800 - val_TN: 1077.4700 - val_FP: 28.5300 - val_FN: 47.9200\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0585 - Accuracy: 0.9806 - Precision: 0.9510 - Recall: 0.9433 - TP: 3180.7800 - TN: 5494.2002 - FP: 152.8000 - FN: 191.2200 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9586 - val_Recall: 0.9404 - val_TP: 756.0500 - val_TN: 1077.4600 - val_FP: 28.5400 - val_FN: 47.9500\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0584 - Accuracy: 0.9806 - Precision: 0.9510 - Recall: 0.9433 - TP: 3180.7200 - TN: 5494.0000 - FP: 153.0000 - FN: 191.2800 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9587 - val_Recall: 0.9403 - val_TP: 756.0300 - val_TN: 1077.5601 - val_FP: 28.4400 - val_FN: 47.9700\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0584 - Accuracy: 0.9806 - Precision: 0.9511 - Recall: 0.9432 - TP: 3180.6299 - TN: 5494.3999 - FP: 152.6000 - FN: 191.3700 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9588 - val_Recall: 0.9403 - val_TP: 756.0100 - val_TN: 1077.6600 - val_FP: 28.3400 - val_FN: 47.9900\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0584 - Accuracy: 0.9806 - Precision: 0.9512 - Recall: 0.9432 - TP: 3180.4399 - TN: 5494.8599 - FP: 152.1400 - FN: 191.5600 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9590 - val_Recall: 0.9403 - val_TP: 756.0000 - val_TN: 1077.8199 - val_FP: 28.1800 - val_FN: 48.0000\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0583 - Accuracy: 0.9805 - Precision: 0.9514 - Recall: 0.9431 - TP: 3180.2400 - TN: 5495.6899 - FP: 151.3100 - FN: 191.7600 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9589 - val_Recall: 0.9403 - val_TP: 755.9800 - val_TN: 1077.7400 - val_FP: 28.2600 - val_FN: 48.0200\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0583 - Accuracy: 0.9805 - Precision: 0.9514 - Recall: 0.9431 - TP: 3180.2500 - TN: 5495.7300 - FP: 151.2700 - FN: 191.7500 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9591 - val_Recall: 0.9402 - val_TP: 755.9300 - val_TN: 1077.9500 - val_FP: 28.0500 - val_FN: 48.0700\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0583 - Accuracy: 0.9804 - Precision: 0.9515 - Recall: 0.9431 - TP: 3180.0400 - TN: 5496.2300 - FP: 150.7700 - FN: 191.9600 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9591 - val_Recall: 0.9402 - val_TP: 755.9300 - val_TN: 1077.9500 - val_FP: 28.0500 - val_FN: 48.0700\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0582 - Accuracy: 0.9805 - Precision: 0.9515 - Recall: 0.9431 - TP: 3179.9800 - TN: 5496.2900 - FP: 150.7100 - FN: 192.0200 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9592 - val_Recall: 0.9402 - val_TP: 755.9100 - val_TN: 1078.0100 - val_FP: 27.9900 - val_FN: 48.0900\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0582 - Accuracy: 0.9804 - Precision: 0.9518 - Recall: 0.9430 - TP: 3179.7700 - TN: 5497.4702 - FP: 149.5300 - FN: 192.2300 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9592 - val_Recall: 0.9402 - val_TP: 755.9000 - val_TN: 1077.9700 - val_FP: 28.0300 - val_FN: 48.1000\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0582 - Accuracy: 0.9804 - Precision: 0.9516 - Recall: 0.9431 - TP: 3180.0100 - TN: 5496.5000 - FP: 150.5000 - FN: 191.9900 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9592 - val_Recall: 0.9402 - val_TP: 755.8900 - val_TN: 1078.0601 - val_FP: 27.9400 - val_FN: 48.1100\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0581 - Accuracy: 0.9804 - Precision: 0.9517 - Recall: 0.9430 - TP: 3179.8701 - TN: 5497.1499 - FP: 149.8500 - FN: 192.1300 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9593 - val_Recall: 0.9401 - val_TP: 755.8800 - val_TN: 1078.1400 - val_FP: 27.8600 - val_FN: 48.1200\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 7s 8ms/step - loss: 0.0623 - Accuracy: 0.9804 - Precision: 0.9533 - Recall: 0.9423 - TP: 3177.4199 - TN: 5506.4600 - FP: 140.5400 - FN: 194.5800 - val_loss: 0.0728 - val_Accuracy: 0.9770 - val_Precision: 0.9605 - val_Recall: 0.9404 - val_TP: 756.0800 - val_TN: 1079.7600 - val_FP: 26.2400 - val_FN: 47.9200\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0611 - Accuracy: 0.9804 - Precision: 0.9529 - Recall: 0.9426 - TP: 3178.3401 - TN: 5504.5400 - FP: 142.4600 - FN: 193.6600 - val_loss: 0.0729 - val_Accuracy: 0.9770 - val_Precision: 0.9602 - val_Recall: 0.9404 - val_TP: 756.1100 - val_TN: 1079.3400 - val_FP: 26.6600 - val_FN: 47.8900\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0601 - Accuracy: 0.9804 - Precision: 0.9526 - Recall: 0.9427 - TP: 3178.9299 - TN: 5502.7598 - FP: 144.2400 - FN: 193.0700 - val_loss: 0.0732 - val_Accuracy: 0.9770 - val_Precision: 0.9599 - val_Recall: 0.9405 - val_TP: 756.1600 - val_TN: 1078.9600 - val_FP: 27.0400 - val_FN: 47.8400\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0594 - Accuracy: 0.9807 - Precision: 0.9520 - Recall: 0.9430 - TP: 3179.8799 - TN: 5500.1699 - FP: 146.8300 - FN: 192.1200 - val_loss: 0.0734 - val_Accuracy: 0.9770 - val_Precision: 0.9595 - val_Recall: 0.9405 - val_TP: 756.1900 - val_TN: 1078.5900 - val_FP: 27.4100 - val_FN: 47.8100\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0590 - Accuracy: 0.9807 - Precision: 0.9517 - Recall: 0.9432 - TP: 3180.4099 - TN: 5498.2598 - FP: 148.7400 - FN: 191.5900 - val_loss: 0.0737 - val_Accuracy: 0.9770 - val_Precision: 0.9593 - val_Recall: 0.9405 - val_TP: 756.1900 - val_TN: 1078.3199 - val_FP: 27.6800 - val_FN: 47.8100\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0588 - Accuracy: 0.9807 - Precision: 0.9514 - Recall: 0.9433 - TP: 3180.7400 - TN: 5496.9399 - FP: 150.0600 - FN: 191.2600 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9590 - val_Recall: 0.9405 - val_TP: 756.1900 - val_TN: 1077.9800 - val_FP: 28.0200 - val_FN: 47.8100\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0586 - Accuracy: 0.9807 - Precision: 0.9511 - Recall: 0.9434 - TP: 3181.0000 - TN: 5495.6299 - FP: 151.3700 - FN: 191.0000 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9589 - val_Recall: 0.9405 - val_TP: 756.1900 - val_TN: 1077.9200 - val_FP: 28.0800 - val_FN: 47.8100\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0586 - Accuracy: 0.9805 - Precision: 0.9510 - Recall: 0.9433 - TP: 3180.9099 - TN: 5494.9199 - FP: 152.0800 - FN: 191.0900 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9586 - val_Recall: 0.9405 - val_TP: 756.1500 - val_TN: 1077.3900 - val_FP: 28.6100 - val_FN: 47.8500\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0585 - Accuracy: 0.9806 - Precision: 0.9510 - Recall: 0.9433 - TP: 3180.8701 - TN: 5494.8799 - FP: 152.1200 - FN: 191.1300 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9586 - val_Recall: 0.9404 - val_TP: 756.1000 - val_TN: 1077.3800 - val_FP: 28.6200 - val_FN: 47.9000\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0585 - Accuracy: 0.9806 - Precision: 0.9509 - Recall: 0.9433 - TP: 3180.8501 - TN: 5493.8101 - FP: 153.1900 - FN: 191.1500 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9587 - val_Recall: 0.9404 - val_TP: 756.0600 - val_TN: 1077.5200 - val_FP: 28.4800 - val_FN: 47.9400\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0584 - Accuracy: 0.9806 - Precision: 0.9509 - Recall: 0.9433 - TP: 3180.7700 - TN: 5493.7998 - FP: 153.2000 - FN: 191.2300 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9587 - val_Recall: 0.9403 - val_TP: 756.0400 - val_TN: 1077.5699 - val_FP: 28.4300 - val_FN: 47.9600\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0584 - Accuracy: 0.9806 - Precision: 0.9511 - Recall: 0.9432 - TP: 3180.5200 - TN: 5494.6401 - FP: 152.3600 - FN: 191.4800 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9589 - val_Recall: 0.9403 - val_TP: 756.0000 - val_TN: 1077.7100 - val_FP: 28.2900 - val_FN: 48.0000\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0583 - Accuracy: 0.9806 - Precision: 0.9512 - Recall: 0.9432 - TP: 3180.4800 - TN: 5495.0298 - FP: 151.9700 - FN: 191.5200 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9589 - val_Recall: 0.9403 - val_TP: 755.9900 - val_TN: 1077.7500 - val_FP: 28.2500 - val_FN: 48.0100\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0583 - Accuracy: 0.9805 - Precision: 0.9514 - Recall: 0.9431 - TP: 3180.2400 - TN: 5495.7598 - FP: 151.2400 - FN: 191.7600 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9590 - val_Recall: 0.9402 - val_TP: 755.9400 - val_TN: 1077.8500 - val_FP: 28.1500 - val_FN: 48.0600\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0583 - Accuracy: 0.9805 - Precision: 0.9514 - Recall: 0.9431 - TP: 3180.2100 - TN: 5495.7002 - FP: 151.3000 - FN: 191.7900 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9592 - val_Recall: 0.9402 - val_TP: 755.9300 - val_TN: 1077.9900 - val_FP: 28.0100 - val_FN: 48.0700\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0582 - Accuracy: 0.9805 - Precision: 0.9515 - Recall: 0.9431 - TP: 3180.1201 - TN: 5496.1401 - FP: 150.8600 - FN: 191.8800 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9591 - val_Recall: 0.9402 - val_TP: 755.9200 - val_TN: 1077.9500 - val_FP: 28.0500 - val_FN: 48.0800\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0582 - Accuracy: 0.9805 - Precision: 0.9516 - Recall: 0.9431 - TP: 3180.0000 - TN: 5496.8501 - FP: 150.1500 - FN: 192.0000 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9593 - val_Recall: 0.9401 - val_TP: 755.8800 - val_TN: 1078.1000 - val_FP: 27.9000 - val_FN: 48.1200\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0582 - Accuracy: 0.9804 - Precision: 0.9518 - Recall: 0.9430 - TP: 3179.7600 - TN: 5497.4399 - FP: 149.5600 - FN: 192.2400 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9592 - val_Recall: 0.9401 - val_TP: 755.8800 - val_TN: 1078.0200 - val_FP: 27.9800 - val_FN: 48.1200\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0582 - Accuracy: 0.9804 - Precision: 0.9517 - Recall: 0.9430 - TP: 3179.8501 - TN: 5497.3198 - FP: 149.6800 - FN: 192.1500 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9593 - val_Recall: 0.9401 - val_TP: 755.8600 - val_TN: 1078.1400 - val_FP: 27.8600 - val_FN: 48.1400\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0581 - Accuracy: 0.9804 - Precision: 0.9517 - Recall: 0.9430 - TP: 3179.8301 - TN: 5497.3599 - FP: 149.6400 - FN: 192.1700 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9594 - val_Recall: 0.9401 - val_TP: 755.8400 - val_TN: 1078.2400 - val_FP: 27.7600 - val_FN: 48.1600\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0581 - Accuracy: 0.9804 - Precision: 0.9519 - Recall: 0.9430 - TP: 3179.6299 - TN: 5498.0801 - FP: 148.9200 - FN: 192.3700 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9594 - val_Recall: 0.9401 - val_TP: 755.8200 - val_TN: 1078.2500 - val_FP: 27.7500 - val_FN: 48.1800\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 7ms/step - loss: 0.0611 - Accuracy: 0.9804 - Precision: 0.9529 - Recall: 0.9425 - TP: 3178.2400 - TN: 5504.6499 - FP: 142.3500 - FN: 193.7600 - val_loss: 0.0729 - val_Accuracy: 0.9770 - val_Precision: 0.9602 - val_Recall: 0.9405 - val_TP: 756.1300 - val_TN: 1079.3400 - val_FP: 26.6600 - val_FN: 47.8700\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0601 - Accuracy: 0.9804 - Precision: 0.9525 - Recall: 0.9428 - TP: 3179.1201 - TN: 5502.2900 - FP: 144.7100 - FN: 192.8800 - val_loss: 0.0731 - val_Accuracy: 0.9770 - val_Precision: 0.9599 - val_Recall: 0.9405 - val_TP: 756.1600 - val_TN: 1079.0400 - val_FP: 26.9600 - val_FN: 47.8400\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0594 - Accuracy: 0.9807 - Precision: 0.9521 - Recall: 0.9430 - TP: 3179.8701 - TN: 5500.2002 - FP: 146.8000 - FN: 192.1300 - val_loss: 0.0734 - val_Accuracy: 0.9770 - val_Precision: 0.9595 - val_Recall: 0.9405 - val_TP: 756.1900 - val_TN: 1078.5800 - val_FP: 27.4200 - val_FN: 47.8100\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0590 - Accuracy: 0.9807 - Precision: 0.9517 - Recall: 0.9432 - TP: 3180.3899 - TN: 5498.2598 - FP: 148.7400 - FN: 191.6100 - val_loss: 0.0737 - val_Accuracy: 0.9770 - val_Precision: 0.9593 - val_Recall: 0.9405 - val_TP: 756.1900 - val_TN: 1078.3000 - val_FP: 27.7000 - val_FN: 47.8100\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0587 - Accuracy: 0.9807 - Precision: 0.9513 - Recall: 0.9433 - TP: 3180.9299 - TN: 5496.4600 - FP: 150.5400 - FN: 191.0700 - val_loss: 0.0739 - val_Accuracy: 0.9770 - val_Precision: 0.9590 - val_Recall: 0.9405 - val_TP: 756.1900 - val_TN: 1078.0400 - val_FP: 27.9600 - val_FN: 47.8100\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0586 - Accuracy: 0.9807 - Precision: 0.9511 - Recall: 0.9434 - TP: 3181.0200 - TN: 5495.5898 - FP: 151.4100 - FN: 190.9800 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9589 - val_Recall: 0.9405 - val_TP: 756.1900 - val_TN: 1077.9500 - val_FP: 28.0500 - val_FN: 47.8100\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0585 - Accuracy: 0.9808 - Precision: 0.9509 - Recall: 0.9434 - TP: 3181.0601 - TN: 5494.5098 - FP: 152.4900 - FN: 190.9400 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9589 - val_Recall: 0.9405 - val_TP: 756.1400 - val_TN: 1077.9399 - val_FP: 28.0600 - val_FN: 47.8600\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0585 - Accuracy: 0.9806 - Precision: 0.9510 - Recall: 0.9433 - TP: 3180.8101 - TN: 5494.7002 - FP: 152.3000 - FN: 191.1900 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9588 - val_Recall: 0.9404 - val_TP: 756.0800 - val_TN: 1077.5900 - val_FP: 28.4100 - val_FN: 47.9200\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0585 - Accuracy: 0.9805 - Precision: 0.9512 - Recall: 0.9432 - TP: 3180.6299 - TN: 5495.5098 - FP: 151.4900 - FN: 191.3700 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9587 - val_Recall: 0.9404 - val_TP: 756.0600 - val_TN: 1077.5601 - val_FP: 28.4400 - val_FN: 47.9400\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0584 - Accuracy: 0.9805 - Precision: 0.9512 - Recall: 0.9432 - TP: 3180.4500 - TN: 5495.2300 - FP: 151.7700 - FN: 191.5500 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9587 - val_Recall: 0.9403 - val_TP: 756.0400 - val_TN: 1077.5500 - val_FP: 28.4500 - val_FN: 47.9600\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0584 - Accuracy: 0.9806 - Precision: 0.9511 - Recall: 0.9432 - TP: 3180.5801 - TN: 5494.6499 - FP: 152.3500 - FN: 191.4200 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9590 - val_Recall: 0.9403 - val_TP: 755.9900 - val_TN: 1077.7800 - val_FP: 28.2200 - val_FN: 48.0100\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0583 - Accuracy: 0.9805 - Precision: 0.9512 - Recall: 0.9432 - TP: 3180.3899 - TN: 5495.1499 - FP: 151.8500 - FN: 191.6100 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9590 - val_Recall: 0.9403 - val_TP: 755.9800 - val_TN: 1077.7800 - val_FP: 28.2200 - val_FN: 48.0200\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0583 - Accuracy: 0.9805 - Precision: 0.9514 - Recall: 0.9431 - TP: 3180.2700 - TN: 5495.7500 - FP: 151.2500 - FN: 191.7300 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9590 - val_Recall: 0.9402 - val_TP: 755.9300 - val_TN: 1077.8400 - val_FP: 28.1600 - val_FN: 48.0700\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0583 - Accuracy: 0.9806 - Precision: 0.9514 - Recall: 0.9431 - TP: 3180.3000 - TN: 5495.6699 - FP: 151.3300 - FN: 191.7000 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9591 - val_Recall: 0.9402 - val_TP: 755.9300 - val_TN: 1077.9399 - val_FP: 28.0600 - val_FN: 48.0700\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0583 - Accuracy: 0.9805 - Precision: 0.9516 - Recall: 0.9430 - TP: 3179.9500 - TN: 5496.8398 - FP: 150.1600 - FN: 192.0500 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9592 - val_Recall: 0.9401 - val_TP: 755.8800 - val_TN: 1077.9900 - val_FP: 28.0100 - val_FN: 48.1200\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0582 - Accuracy: 0.9805 - Precision: 0.9516 - Recall: 0.9431 - TP: 3180.0100 - TN: 5496.7998 - FP: 150.2000 - FN: 191.9900 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9594 - val_Recall: 0.9401 - val_TP: 755.8600 - val_TN: 1078.1899 - val_FP: 27.8100 - val_FN: 48.1400\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0582 - Accuracy: 0.9804 - Precision: 0.9517 - Recall: 0.9430 - TP: 3179.7400 - TN: 5497.3501 - FP: 149.6500 - FN: 192.2600 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9594 - val_Recall: 0.9401 - val_TP: 755.8500 - val_TN: 1078.2700 - val_FP: 27.7300 - val_FN: 48.1500\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0582 - Accuracy: 0.9804 - Precision: 0.9517 - Recall: 0.9430 - TP: 3179.9399 - TN: 5497.0898 - FP: 149.9100 - FN: 192.0600 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9594 - val_Recall: 0.9401 - val_TP: 755.8500 - val_TN: 1078.2400 - val_FP: 27.7600 - val_FN: 48.1500\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0581 - Accuracy: 0.9804 - Precision: 0.9519 - Recall: 0.9430 - TP: 3179.7200 - TN: 5497.9502 - FP: 149.0500 - FN: 192.2800 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9595 - val_Recall: 0.9401 - val_TP: 755.8300 - val_TN: 1078.3101 - val_FP: 27.6900 - val_FN: 48.1700\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0581 - Accuracy: 0.9804 - Precision: 0.9520 - Recall: 0.9429 - TP: 3179.5701 - TN: 5498.5498 - FP: 148.4500 - FN: 192.4300 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9596 - val_Recall: 0.9400 - val_TP: 755.8000 - val_TN: 1078.3800 - val_FP: 27.6200 - val_FN: 48.2000\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0581 - Accuracy: 0.9804 - Precision: 0.9520 - Recall: 0.9429 - TP: 3179.5000 - TN: 5498.3799 - FP: 148.6200 - FN: 192.5000 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9596 - val_Recall: 0.9400 - val_TP: 755.7900 - val_TN: 1078.3600 - val_FP: 27.6400 - val_FN: 48.2100\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 7ms/step - loss: 0.0601 - Accuracy: 0.9804 - Precision: 0.9526 - Recall: 0.9428 - TP: 3179.0400 - TN: 5502.8799 - FP: 144.1200 - FN: 192.9600 - val_loss: 0.0732 - val_Accuracy: 0.9770 - val_Precision: 0.9599 - val_Recall: 0.9405 - val_TP: 756.1700 - val_TN: 1079.0000 - val_FP: 27.0000 - val_FN: 47.8300\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0594 - Accuracy: 0.9807 - Precision: 0.9520 - Recall: 0.9430 - TP: 3179.8899 - TN: 5500.1401 - FP: 146.8600 - FN: 192.1100 - val_loss: 0.0735 - val_Accuracy: 0.9770 - val_Precision: 0.9595 - val_Recall: 0.9405 - val_TP: 756.1900 - val_TN: 1078.5699 - val_FP: 27.4300 - val_FN: 47.8100\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0589 - Accuracy: 0.9807 - Precision: 0.9517 - Recall: 0.9432 - TP: 3180.3899 - TN: 5498.4600 - FP: 148.5400 - FN: 191.6100 - val_loss: 0.0737 - val_Accuracy: 0.9770 - val_Precision: 0.9592 - val_Recall: 0.9405 - val_TP: 756.1900 - val_TN: 1078.2400 - val_FP: 27.7600 - val_FN: 47.8100\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0587 - Accuracy: 0.9807 - Precision: 0.9511 - Recall: 0.9434 - TP: 3181.0500 - TN: 5495.7598 - FP: 151.2400 - FN: 190.9500 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9590 - val_Recall: 0.9405 - val_TP: 756.1900 - val_TN: 1077.9800 - val_FP: 28.0200 - val_FN: 47.8100\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0586 - Accuracy: 0.9808 - Precision: 0.9511 - Recall: 0.9434 - TP: 3181.0701 - TN: 5495.5801 - FP: 151.4200 - FN: 190.9300 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9589 - val_Recall: 0.9405 - val_TP: 756.1900 - val_TN: 1077.9301 - val_FP: 28.0700 - val_FN: 47.8100\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0585 - Accuracy: 0.9806 - Precision: 0.9511 - Recall: 0.9433 - TP: 3180.8601 - TN: 5495.1001 - FP: 151.9000 - FN: 191.1400 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9587 - val_Recall: 0.9405 - val_TP: 756.1400 - val_TN: 1077.4900 - val_FP: 28.5100 - val_FN: 47.8600\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0585 - Accuracy: 0.9807 - Precision: 0.9510 - Recall: 0.9433 - TP: 3180.8501 - TN: 5494.2900 - FP: 152.7100 - FN: 191.1500 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9587 - val_Recall: 0.9404 - val_TP: 756.0800 - val_TN: 1077.4800 - val_FP: 28.5200 - val_FN: 47.9200\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0584 - Accuracy: 0.9806 - Precision: 0.9511 - Recall: 0.9433 - TP: 3180.6799 - TN: 5494.6699 - FP: 152.3300 - FN: 191.3200 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9587 - val_Recall: 0.9404 - val_TP: 756.0800 - val_TN: 1077.5400 - val_FP: 28.4600 - val_FN: 47.9200\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0584 - Accuracy: 0.9806 - Precision: 0.9511 - Recall: 0.9433 - TP: 3180.6399 - TN: 5494.3901 - FP: 152.6100 - FN: 191.3600 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9588 - val_Recall: 0.9403 - val_TP: 756.0000 - val_TN: 1077.6400 - val_FP: 28.3600 - val_FN: 48.0000\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0583 - Accuracy: 0.9806 - Precision: 0.9514 - Recall: 0.9432 - TP: 3180.3701 - TN: 5495.7402 - FP: 151.2600 - FN: 191.6300 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9589 - val_Recall: 0.9403 - val_TP: 755.9900 - val_TN: 1077.6899 - val_FP: 28.3100 - val_FN: 48.0100\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0583 - Accuracy: 0.9806 - Precision: 0.9513 - Recall: 0.9432 - TP: 3180.3799 - TN: 5495.3901 - FP: 151.6100 - FN: 191.6200 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9590 - val_Recall: 0.9403 - val_TP: 755.9700 - val_TN: 1077.8300 - val_FP: 28.1700 - val_FN: 48.0300\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0583 - Accuracy: 0.9805 - Precision: 0.9513 - Recall: 0.9431 - TP: 3180.2900 - TN: 5495.5601 - FP: 151.4400 - FN: 191.7100 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9591 - val_Recall: 0.9402 - val_TP: 755.9300 - val_TN: 1077.9100 - val_FP: 28.0900 - val_FN: 48.0700\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0582 - Accuracy: 0.9805 - Precision: 0.9515 - Recall: 0.9431 - TP: 3180.1201 - TN: 5496.3398 - FP: 150.6600 - FN: 191.8800 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9591 - val_Recall: 0.9402 - val_TP: 755.9200 - val_TN: 1077.8900 - val_FP: 28.1100 - val_FN: 48.0800\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0582 - Accuracy: 0.9805 - Precision: 0.9515 - Recall: 0.9431 - TP: 3180.1201 - TN: 5496.2900 - FP: 150.7100 - FN: 191.8800 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9593 - val_Recall: 0.9401 - val_TP: 755.8800 - val_TN: 1078.1300 - val_FP: 27.8700 - val_FN: 48.1200\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0582 - Accuracy: 0.9804 - Precision: 0.9519 - Recall: 0.9430 - TP: 3179.6299 - TN: 5498.0400 - FP: 148.9600 - FN: 192.3700 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9594 - val_Recall: 0.9401 - val_TP: 755.8600 - val_TN: 1078.2400 - val_FP: 27.7600 - val_FN: 48.1400\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0581 - Accuracy: 0.9804 - Precision: 0.9517 - Recall: 0.9430 - TP: 3179.8601 - TN: 5497.2202 - FP: 149.7800 - FN: 192.1400 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9593 - val_Recall: 0.9401 - val_TP: 755.8500 - val_TN: 1078.1400 - val_FP: 27.8600 - val_FN: 48.1500\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0581 - Accuracy: 0.9804 - Precision: 0.9518 - Recall: 0.9430 - TP: 3179.7900 - TN: 5497.4502 - FP: 149.5500 - FN: 192.2100 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9595 - val_Recall: 0.9401 - val_TP: 755.8300 - val_TN: 1078.2800 - val_FP: 27.7200 - val_FN: 48.1700\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0581 - Accuracy: 0.9804 - Precision: 0.9520 - Recall: 0.9429 - TP: 3179.3899 - TN: 5498.7100 - FP: 148.2900 - FN: 192.6100 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9596 - val_Recall: 0.9401 - val_TP: 755.8300 - val_TN: 1078.3800 - val_FP: 27.6200 - val_FN: 48.1700\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0581 - Accuracy: 0.9804 - Precision: 0.9519 - Recall: 0.9430 - TP: 3179.7700 - TN: 5497.8999 - FP: 149.1000 - FN: 192.2300 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9597 - val_Recall: 0.9400 - val_TP: 755.8000 - val_TN: 1078.5200 - val_FP: 27.4800 - val_FN: 48.2000\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0580 - Accuracy: 0.9804 - Precision: 0.9521 - Recall: 0.9429 - TP: 3179.5901 - TN: 5498.7402 - FP: 148.2600 - FN: 192.4100 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9597 - val_Recall: 0.9401 - val_TP: 755.8200 - val_TN: 1078.5000 - val_FP: 27.5000 - val_FN: 48.1800\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0580 - Accuracy: 0.9804 - Precision: 0.9520 - Recall: 0.9430 - TP: 3179.6299 - TN: 5498.5898 - FP: 148.4100 - FN: 192.3700 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9596 - val_Recall: 0.9400 - val_TP: 755.8000 - val_TN: 1078.4000 - val_FP: 27.6000 - val_FN: 48.2000\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 7ms/step - loss: 0.0596 - Accuracy: 0.9806 - Precision: 0.9523 - Recall: 0.9429 - TP: 3179.5801 - TN: 5501.2798 - FP: 145.7200 - FN: 192.4200 - val_loss: 0.0733 - val_Accuracy: 0.9770 - val_Precision: 0.9597 - val_Recall: 0.9405 - val_TP: 756.1900 - val_TN: 1078.7500 - val_FP: 27.2500 - val_FN: 47.8100\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0590 - Accuracy: 0.9806 - Precision: 0.9518 - Recall: 0.9431 - TP: 3180.2500 - TN: 5499.0698 - FP: 147.9300 - FN: 191.7500 - val_loss: 0.0737 - val_Accuracy: 0.9770 - val_Precision: 0.9592 - val_Recall: 0.9406 - val_TP: 756.2400 - val_TN: 1078.2000 - val_FP: 27.8000 - val_FN: 47.7600\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0587 - Accuracy: 0.9807 - Precision: 0.9513 - Recall: 0.9433 - TP: 3180.8999 - TN: 5496.6401 - FP: 150.3600 - FN: 191.1000 - val_loss: 0.0739 - val_Accuracy: 0.9770 - val_Precision: 0.9590 - val_Recall: 0.9406 - val_TP: 756.2400 - val_TN: 1077.9800 - val_FP: 28.0200 - val_FN: 47.7600\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0586 - Accuracy: 0.9807 - Precision: 0.9511 - Recall: 0.9434 - TP: 3181.0801 - TN: 5495.5801 - FP: 151.4200 - FN: 190.9200 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9589 - val_Recall: 0.9405 - val_TP: 756.1900 - val_TN: 1077.9500 - val_FP: 28.0500 - val_FN: 47.8100\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0585 - Accuracy: 0.9806 - Precision: 0.9510 - Recall: 0.9434 - TP: 3180.9900 - TN: 5494.7500 - FP: 152.2500 - FN: 191.0100 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9586 - val_Recall: 0.9405 - val_TP: 756.1500 - val_TN: 1077.4500 - val_FP: 28.5500 - val_FN: 47.8500\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0585 - Accuracy: 0.9806 - Precision: 0.9509 - Recall: 0.9433 - TP: 3180.9500 - TN: 5494.0298 - FP: 152.9700 - FN: 191.0500 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9586 - val_Recall: 0.9405 - val_TP: 756.1300 - val_TN: 1077.4600 - val_FP: 28.5400 - val_FN: 47.8700\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0584 - Accuracy: 0.9806 - Precision: 0.9511 - Recall: 0.9433 - TP: 3180.7300 - TN: 5494.6201 - FP: 152.3800 - FN: 191.2700 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9587 - val_Recall: 0.9404 - val_TP: 756.0500 - val_TN: 1077.5601 - val_FP: 28.4400 - val_FN: 47.9500\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0584 - Accuracy: 0.9806 - Precision: 0.9511 - Recall: 0.9432 - TP: 3180.6101 - TN: 5494.5601 - FP: 152.4400 - FN: 191.3900 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9588 - val_Recall: 0.9403 - val_TP: 756.0100 - val_TN: 1077.6600 - val_FP: 28.3400 - val_FN: 47.9900\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0583 - Accuracy: 0.9806 - Precision: 0.9512 - Recall: 0.9432 - TP: 3180.5100 - TN: 5495.0698 - FP: 151.9300 - FN: 191.4900 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9589 - val_Recall: 0.9403 - val_TP: 755.9900 - val_TN: 1077.7300 - val_FP: 28.2700 - val_FN: 48.0100\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0583 - Accuracy: 0.9806 - Precision: 0.9513 - Recall: 0.9432 - TP: 3180.3701 - TN: 5495.4600 - FP: 151.5400 - FN: 191.6300 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9590 - val_Recall: 0.9403 - val_TP: 755.9700 - val_TN: 1077.8700 - val_FP: 28.1300 - val_FN: 48.0300\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0583 - Accuracy: 0.9805 - Precision: 0.9515 - Recall: 0.9431 - TP: 3180.0601 - TN: 5496.3599 - FP: 150.6400 - FN: 191.9400 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9593 - val_Recall: 0.9402 - val_TP: 755.9100 - val_TN: 1078.1000 - val_FP: 27.9000 - val_FN: 48.0900\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0582 - Accuracy: 0.9805 - Precision: 0.9515 - Recall: 0.9431 - TP: 3180.1699 - TN: 5496.1802 - FP: 150.8200 - FN: 191.8300 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9591 - val_Recall: 0.9402 - val_TP: 755.8900 - val_TN: 1077.9399 - val_FP: 28.0600 - val_FN: 48.1100\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0582 - Accuracy: 0.9805 - Precision: 0.9516 - Recall: 0.9431 - TP: 3180.0901 - TN: 5496.8101 - FP: 150.1900 - FN: 191.9100 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9593 - val_Recall: 0.9402 - val_TP: 755.8900 - val_TN: 1078.0800 - val_FP: 27.9200 - val_FN: 48.1100\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0582 - Accuracy: 0.9805 - Precision: 0.9516 - Recall: 0.9431 - TP: 3179.9900 - TN: 5496.9302 - FP: 150.0700 - FN: 192.0100 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9594 - val_Recall: 0.9401 - val_TP: 755.8600 - val_TN: 1078.2400 - val_FP: 27.7600 - val_FN: 48.1400\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0581 - Accuracy: 0.9804 - Precision: 0.9518 - Recall: 0.9430 - TP: 3179.7300 - TN: 5497.7798 - FP: 149.2200 - FN: 192.2700 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9595 - val_Recall: 0.9401 - val_TP: 755.8300 - val_TN: 1078.3101 - val_FP: 27.6900 - val_FN: 48.1700\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0581 - Accuracy: 0.9804 - Precision: 0.9519 - Recall: 0.9430 - TP: 3179.7600 - TN: 5498.0498 - FP: 148.9500 - FN: 192.2400 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9595 - val_Recall: 0.9401 - val_TP: 755.8300 - val_TN: 1078.3000 - val_FP: 27.7000 - val_FN: 48.1700\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0581 - Accuracy: 0.9804 - Precision: 0.9520 - Recall: 0.9429 - TP: 3179.5000 - TN: 5498.5601 - FP: 148.4400 - FN: 192.5000 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9594 - val_Recall: 0.9401 - val_TP: 755.8200 - val_TN: 1078.2200 - val_FP: 27.7800 - val_FN: 48.1800\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0581 - Accuracy: 0.9804 - Precision: 0.9519 - Recall: 0.9430 - TP: 3179.7200 - TN: 5497.9902 - FP: 149.0100 - FN: 192.2800 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9596 - val_Recall: 0.9401 - val_TP: 755.8100 - val_TN: 1078.3700 - val_FP: 27.6300 - val_FN: 48.1900\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0580 - Accuracy: 0.9804 - Precision: 0.9520 - Recall: 0.9430 - TP: 3179.6499 - TN: 5498.2900 - FP: 148.7100 - FN: 192.3500 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9597 - val_Recall: 0.9400 - val_TP: 755.8000 - val_TN: 1078.4900 - val_FP: 27.5100 - val_FN: 48.2000\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0580 - Accuracy: 0.9803 - Precision: 0.9521 - Recall: 0.9429 - TP: 3179.4500 - TN: 5499.0801 - FP: 147.9200 - FN: 192.5500 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9597 - val_Recall: 0.9400 - val_TP: 755.7900 - val_TN: 1078.5800 - val_FP: 27.4200 - val_FN: 48.2100\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0580 - Accuracy: 0.9803 - Precision: 0.9522 - Recall: 0.9429 - TP: 3179.3701 - TN: 5499.2002 - FP: 147.8000 - FN: 192.6300 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9598 - val_Recall: 0.9400 - val_TP: 755.7800 - val_TN: 1078.5900 - val_FP: 27.4100 - val_FN: 48.2200\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 7ms/step - loss: 0.0594 - Accuracy: 0.9807 - Precision: 0.9522 - Recall: 0.9430 - TP: 3179.7200 - TN: 5501.0200 - FP: 145.9800 - FN: 192.2800 - val_loss: 0.0735 - val_Accuracy: 0.9770 - val_Precision: 0.9595 - val_Recall: 0.9406 - val_TP: 756.2400 - val_TN: 1078.5500 - val_FP: 27.4500 - val_FN: 47.7600\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0589 - Accuracy: 0.9807 - Precision: 0.9516 - Recall: 0.9432 - TP: 3180.6101 - TN: 5497.7998 - FP: 149.2000 - FN: 191.3900 - val_loss: 0.0738 - val_Accuracy: 0.9770 - val_Precision: 0.9591 - val_Recall: 0.9406 - val_TP: 756.2300 - val_TN: 1078.1500 - val_FP: 27.8500 - val_FN: 47.7700\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0587 - Accuracy: 0.9807 - Precision: 0.9513 - Recall: 0.9433 - TP: 3180.8000 - TN: 5496.4800 - FP: 150.5200 - FN: 191.2000 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9590 - val_Recall: 0.9406 - val_TP: 756.2300 - val_TN: 1078.0000 - val_FP: 28.0000 - val_FN: 47.7700\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0586 - Accuracy: 0.9806 - Precision: 0.9511 - Recall: 0.9433 - TP: 3180.9399 - TN: 5495.4902 - FP: 151.5100 - FN: 191.0600 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9590 - val_Recall: 0.9405 - val_TP: 756.1700 - val_TN: 1078.0100 - val_FP: 27.9900 - val_FN: 47.8300\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0585 - Accuracy: 0.9806 - Precision: 0.9512 - Recall: 0.9433 - TP: 3180.9500 - TN: 5495.7998 - FP: 151.2000 - FN: 191.0500 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9586 - val_Recall: 0.9405 - val_TP: 756.1500 - val_TN: 1077.4700 - val_FP: 28.5300 - val_FN: 47.8500\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0585 - Accuracy: 0.9806 - Precision: 0.9510 - Recall: 0.9433 - TP: 3180.7200 - TN: 5494.2998 - FP: 152.7000 - FN: 191.2800 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9587 - val_Recall: 0.9404 - val_TP: 756.0900 - val_TN: 1077.5100 - val_FP: 28.4900 - val_FN: 47.9100\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0584 - Accuracy: 0.9806 - Precision: 0.9511 - Recall: 0.9433 - TP: 3180.8000 - TN: 5494.4800 - FP: 152.5200 - FN: 191.2000 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9588 - val_Recall: 0.9403 - val_TP: 756.0200 - val_TN: 1077.5800 - val_FP: 28.4200 - val_FN: 47.9800\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0583 - Accuracy: 0.9805 - Precision: 0.9513 - Recall: 0.9432 - TP: 3180.4199 - TN: 5495.1899 - FP: 151.8100 - FN: 191.5800 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9589 - val_Recall: 0.9403 - val_TP: 756.0100 - val_TN: 1077.6899 - val_FP: 28.3100 - val_FN: 47.9900\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0583 - Accuracy: 0.9805 - Precision: 0.9515 - Recall: 0.9431 - TP: 3180.2000 - TN: 5496.3398 - FP: 150.6600 - FN: 191.8000 - val_loss: 0.0744 - val_Accuracy: 0.9775 - val_Precision: 0.9590 - val_Recall: 0.9403 - val_TP: 755.9800 - val_TN: 1077.7700 - val_FP: 28.2300 - val_FN: 48.0200\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0583 - Accuracy: 0.9806 - Precision: 0.9513 - Recall: 0.9432 - TP: 3180.4399 - TN: 5495.5898 - FP: 151.4100 - FN: 191.5600 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9591 - val_Recall: 0.9402 - val_TP: 755.9100 - val_TN: 1077.9100 - val_FP: 28.0900 - val_FN: 48.0900\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0582 - Accuracy: 0.9805 - Precision: 0.9515 - Recall: 0.9431 - TP: 3180.1101 - TN: 5496.3398 - FP: 150.6600 - FN: 191.8900 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9593 - val_Recall: 0.9402 - val_TP: 755.9000 - val_TN: 1078.0800 - val_FP: 27.9200 - val_FN: 48.1000\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0582 - Accuracy: 0.9804 - Precision: 0.9517 - Recall: 0.9430 - TP: 3179.8899 - TN: 5497.1401 - FP: 149.8600 - FN: 192.1100 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9594 - val_Recall: 0.9401 - val_TP: 755.8700 - val_TN: 1078.1801 - val_FP: 27.8200 - val_FN: 48.1300\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0581 - Accuracy: 0.9804 - Precision: 0.9517 - Recall: 0.9430 - TP: 3179.9500 - TN: 5497.1401 - FP: 149.8600 - FN: 192.0500 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9594 - val_Recall: 0.9401 - val_TP: 755.8500 - val_TN: 1078.1801 - val_FP: 27.8200 - val_FN: 48.1500\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0581 - Accuracy: 0.9804 - Precision: 0.9518 - Recall: 0.9430 - TP: 3179.8601 - TN: 5497.5801 - FP: 149.4200 - FN: 192.1400 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9595 - val_Recall: 0.9401 - val_TP: 755.8300 - val_TN: 1078.3199 - val_FP: 27.6800 - val_FN: 48.1700\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0581 - Accuracy: 0.9804 - Precision: 0.9519 - Recall: 0.9430 - TP: 3179.7800 - TN: 5497.8901 - FP: 149.1100 - FN: 192.2200 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9595 - val_Recall: 0.9401 - val_TP: 755.8300 - val_TN: 1078.2900 - val_FP: 27.7100 - val_FN: 48.1700\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0581 - Accuracy: 0.9803 - Precision: 0.9519 - Recall: 0.9430 - TP: 3179.7500 - TN: 5497.9800 - FP: 149.0200 - FN: 192.2500 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9596 - val_Recall: 0.9401 - val_TP: 755.8200 - val_TN: 1078.4301 - val_FP: 27.5700 - val_FN: 48.1800\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0580 - Accuracy: 0.9804 - Precision: 0.9520 - Recall: 0.9429 - TP: 3179.6001 - TN: 5498.6401 - FP: 148.3600 - FN: 192.4000 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9598 - val_Recall: 0.9400 - val_TP: 755.8000 - val_TN: 1078.5800 - val_FP: 27.4200 - val_FN: 48.2000\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0580 - Accuracy: 0.9803 - Precision: 0.9522 - Recall: 0.9428 - TP: 3179.2800 - TN: 5499.5098 - FP: 147.4900 - FN: 192.7200 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9598 - val_Recall: 0.9401 - val_TP: 755.8100 - val_TN: 1078.6400 - val_FP: 27.3600 - val_FN: 48.1900\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0580 - Accuracy: 0.9803 - Precision: 0.9521 - Recall: 0.9429 - TP: 3179.4800 - TN: 5498.8301 - FP: 148.1700 - FN: 192.5200 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9597 - val_Recall: 0.9401 - val_TP: 755.8100 - val_TN: 1078.5000 - val_FP: 27.5000 - val_FN: 48.1900\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0580 - Accuracy: 0.9803 - Precision: 0.9521 - Recall: 0.9429 - TP: 3179.3999 - TN: 5499.1602 - FP: 147.8400 - FN: 192.6000 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9598 - val_Recall: 0.9400 - val_TP: 755.7900 - val_TN: 1078.6400 - val_FP: 27.3600 - val_FN: 48.2100\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0580 - Accuracy: 0.9803 - Precision: 0.9524 - Recall: 0.9428 - TP: 3179.0500 - TN: 5500.5098 - FP: 146.4900 - FN: 192.9500 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9600 - val_Recall: 0.9400 - val_TP: 755.7600 - val_TN: 1078.8300 - val_FP: 27.1700 - val_FN: 48.2400\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 7ms/step - loss: 0.0591 - Accuracy: 0.9807 - Precision: 0.9517 - Recall: 0.9432 - TP: 3180.4299 - TN: 5498.5400 - FP: 148.4600 - FN: 191.5700 - val_loss: 0.0736 - val_Accuracy: 0.9770 - val_Precision: 0.9593 - val_Recall: 0.9406 - val_TP: 756.2500 - val_TN: 1078.3800 - val_FP: 27.6200 - val_FN: 47.7500\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0587 - Accuracy: 0.9807 - Precision: 0.9515 - Recall: 0.9433 - TP: 3180.7000 - TN: 5497.3901 - FP: 149.6100 - FN: 191.3000 - val_loss: 0.0739 - val_Accuracy: 0.9770 - val_Precision: 0.9590 - val_Recall: 0.9406 - val_TP: 756.2400 - val_TN: 1078.0601 - val_FP: 27.9400 - val_FN: 47.7600\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0586 - Accuracy: 0.9809 - Precision: 0.9511 - Recall: 0.9434 - TP: 3181.1101 - TN: 5495.6699 - FP: 151.3300 - FN: 190.8900 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9589 - val_Recall: 0.9406 - val_TP: 756.2100 - val_TN: 1077.9200 - val_FP: 28.0800 - val_FN: 47.7900\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0585 - Accuracy: 0.9807 - Precision: 0.9512 - Recall: 0.9433 - TP: 3180.9299 - TN: 5495.6201 - FP: 151.3800 - FN: 191.0700 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9586 - val_Recall: 0.9405 - val_TP: 756.1900 - val_TN: 1077.3800 - val_FP: 28.6200 - val_FN: 47.8100\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0585 - Accuracy: 0.9805 - Precision: 0.9508 - Recall: 0.9434 - TP: 3181.2100 - TN: 5493.4102 - FP: 153.5900 - FN: 190.7900 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9587 - val_Recall: 0.9405 - val_TP: 756.1500 - val_TN: 1077.4900 - val_FP: 28.5100 - val_FN: 47.8500\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0584 - Accuracy: 0.9805 - Precision: 0.9512 - Recall: 0.9433 - TP: 3180.6399 - TN: 5494.8701 - FP: 152.1300 - FN: 191.3600 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9588 - val_Recall: 0.9403 - val_TP: 756.0400 - val_TN: 1077.6400 - val_FP: 28.3600 - val_FN: 47.9600\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0584 - Accuracy: 0.9805 - Precision: 0.9511 - Recall: 0.9432 - TP: 3180.5901 - TN: 5494.7700 - FP: 152.2300 - FN: 191.4100 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9589 - val_Recall: 0.9403 - val_TP: 756.0100 - val_TN: 1077.7200 - val_FP: 28.2800 - val_FN: 47.9900\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0583 - Accuracy: 0.9805 - Precision: 0.9514 - Recall: 0.9431 - TP: 3180.2900 - TN: 5496.1001 - FP: 150.9000 - FN: 191.7100 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9590 - val_Recall: 0.9403 - val_TP: 756.0000 - val_TN: 1077.8300 - val_FP: 28.1700 - val_FN: 48.0000\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0583 - Accuracy: 0.9804 - Precision: 0.9514 - Recall: 0.9432 - TP: 3180.3601 - TN: 5495.7402 - FP: 151.2600 - FN: 191.6400 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9592 - val_Recall: 0.9402 - val_TP: 755.9500 - val_TN: 1077.9800 - val_FP: 28.0200 - val_FN: 48.0500\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0582 - Accuracy: 0.9806 - Precision: 0.9516 - Recall: 0.9431 - TP: 3180.0100 - TN: 5496.9600 - FP: 150.0400 - FN: 191.9900 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9593 - val_Recall: 0.9402 - val_TP: 755.8900 - val_TN: 1078.1300 - val_FP: 27.8700 - val_FN: 48.1100\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0582 - Accuracy: 0.9804 - Precision: 0.9517 - Recall: 0.9430 - TP: 3179.8701 - TN: 5497.2798 - FP: 149.7200 - FN: 192.1300 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9592 - val_Recall: 0.9402 - val_TP: 755.9000 - val_TN: 1078.0100 - val_FP: 27.9900 - val_FN: 48.1000\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0582 - Accuracy: 0.9805 - Precision: 0.9516 - Recall: 0.9431 - TP: 3180.0300 - TN: 5496.7798 - FP: 150.2200 - FN: 191.9700 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9594 - val_Recall: 0.9401 - val_TP: 755.8500 - val_TN: 1078.1801 - val_FP: 27.8200 - val_FN: 48.1500\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0581 - Accuracy: 0.9804 - Precision: 0.9518 - Recall: 0.9430 - TP: 3179.8899 - TN: 5497.7002 - FP: 149.3000 - FN: 192.1100 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9594 - val_Recall: 0.9401 - val_TP: 755.8700 - val_TN: 1078.2700 - val_FP: 27.7300 - val_FN: 48.1300\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0581 - Accuracy: 0.9803 - Precision: 0.9518 - Recall: 0.9430 - TP: 3179.8201 - TN: 5497.6602 - FP: 149.3400 - FN: 192.1800 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9596 - val_Recall: 0.9401 - val_TP: 755.8200 - val_TN: 1078.3700 - val_FP: 27.6300 - val_FN: 48.1800\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0581 - Accuracy: 0.9803 - Precision: 0.9522 - Recall: 0.9429 - TP: 3179.3999 - TN: 5499.2002 - FP: 147.8000 - FN: 192.6000 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9595 - val_Recall: 0.9401 - val_TP: 755.8200 - val_TN: 1078.3199 - val_FP: 27.6800 - val_FN: 48.1800\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0581 - Accuracy: 0.9803 - Precision: 0.9520 - Recall: 0.9429 - TP: 3179.5500 - TN: 5498.6001 - FP: 148.4000 - FN: 192.4500 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9595 - val_Recall: 0.9401 - val_TP: 755.8200 - val_TN: 1078.3000 - val_FP: 27.7000 - val_FN: 48.1800\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0580 - Accuracy: 0.9803 - Precision: 0.9521 - Recall: 0.9429 - TP: 3179.5901 - TN: 5498.7300 - FP: 148.2700 - FN: 192.4100 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9596 - val_Recall: 0.9401 - val_TP: 755.8200 - val_TN: 1078.4600 - val_FP: 27.5400 - val_FN: 48.1800\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0580 - Accuracy: 0.9804 - Precision: 0.9521 - Recall: 0.9429 - TP: 3179.5701 - TN: 5498.8999 - FP: 148.1000 - FN: 192.4300 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9596 - val_Recall: 0.9401 - val_TP: 755.8200 - val_TN: 1078.4700 - val_FP: 27.5300 - val_FN: 48.1800\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0580 - Accuracy: 0.9803 - Precision: 0.9521 - Recall: 0.9429 - TP: 3179.5200 - TN: 5499.1099 - FP: 147.8900 - FN: 192.4800 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9598 - val_Recall: 0.9400 - val_TP: 755.7900 - val_TN: 1078.6000 - val_FP: 27.4000 - val_FN: 48.2100\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0579 - Accuracy: 0.9803 - Precision: 0.9523 - Recall: 0.9429 - TP: 3179.3101 - TN: 5499.6001 - FP: 147.4000 - FN: 192.6900 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9598 - val_Recall: 0.9400 - val_TP: 755.8000 - val_TN: 1078.6600 - val_FP: 27.3400 - val_FN: 48.2000\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0580 - Accuracy: 0.9803 - Precision: 0.9523 - Recall: 0.9428 - TP: 3179.2800 - TN: 5499.6499 - FP: 147.3500 - FN: 192.7200 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9599 - val_Recall: 0.9400 - val_TP: 755.7700 - val_TN: 1078.7500 - val_FP: 27.2500 - val_FN: 48.2300\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 8ms/step - loss: 0.0589 - Accuracy: 0.9807 - Precision: 0.9518 - Recall: 0.9432 - TP: 3180.4099 - TN: 5499.0200 - FP: 147.9800 - FN: 191.5900 - val_loss: 0.0737 - val_Accuracy: 0.9770 - val_Precision: 0.9592 - val_Recall: 0.9406 - val_TP: 756.2300 - val_TN: 1078.2800 - val_FP: 27.7200 - val_FN: 47.7700\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0587 - Accuracy: 0.9807 - Precision: 0.9513 - Recall: 0.9433 - TP: 3180.9299 - TN: 5496.5000 - FP: 150.5000 - FN: 191.0700 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9590 - val_Recall: 0.9406 - val_TP: 756.2100 - val_TN: 1078.0400 - val_FP: 27.9600 - val_FN: 47.7900\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0585 - Accuracy: 0.9806 - Precision: 0.9513 - Recall: 0.9433 - TP: 3180.8401 - TN: 5496.3198 - FP: 150.6800 - FN: 191.1600 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9586 - val_Recall: 0.9405 - val_TP: 756.1900 - val_TN: 1077.4600 - val_FP: 28.5400 - val_FN: 47.8100\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0585 - Accuracy: 0.9806 - Precision: 0.9509 - Recall: 0.9434 - TP: 3180.9800 - TN: 5493.7002 - FP: 153.3000 - FN: 191.0200 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9588 - val_Recall: 0.9404 - val_TP: 756.1200 - val_TN: 1077.5900 - val_FP: 28.4100 - val_FN: 47.8800\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0584 - Accuracy: 0.9805 - Precision: 0.9513 - Recall: 0.9432 - TP: 3180.5400 - TN: 5496.1499 - FP: 150.8500 - FN: 191.4600 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9588 - val_Recall: 0.9403 - val_TP: 756.0300 - val_TN: 1077.6500 - val_FP: 28.3500 - val_FN: 47.9700\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0584 - Accuracy: 0.9806 - Precision: 0.9511 - Recall: 0.9433 - TP: 3180.7100 - TN: 5494.6602 - FP: 152.3400 - FN: 191.2900 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9590 - val_Recall: 0.9403 - val_TP: 756.0100 - val_TN: 1077.8199 - val_FP: 28.1800 - val_FN: 47.9900\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0583 - Accuracy: 0.9806 - Precision: 0.9513 - Recall: 0.9432 - TP: 3180.4399 - TN: 5495.5698 - FP: 151.4300 - FN: 191.5600 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9590 - val_Recall: 0.9403 - val_TP: 755.9900 - val_TN: 1077.8400 - val_FP: 28.1600 - val_FN: 48.0100\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0583 - Accuracy: 0.9805 - Precision: 0.9515 - Recall: 0.9431 - TP: 3180.2300 - TN: 5496.0698 - FP: 150.9300 - FN: 191.7700 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9591 - val_Recall: 0.9403 - val_TP: 755.9900 - val_TN: 1077.8900 - val_FP: 28.1100 - val_FN: 48.0100\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0582 - Accuracy: 0.9805 - Precision: 0.9515 - Recall: 0.9431 - TP: 3180.1299 - TN: 5496.4302 - FP: 150.5700 - FN: 191.8700 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9592 - val_Recall: 0.9402 - val_TP: 755.9100 - val_TN: 1078.0300 - val_FP: 27.9700 - val_FN: 48.0900\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0582 - Accuracy: 0.9805 - Precision: 0.9516 - Recall: 0.9431 - TP: 3180.0000 - TN: 5496.8398 - FP: 150.1600 - FN: 192.0000 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9594 - val_Recall: 0.9401 - val_TP: 755.8800 - val_TN: 1078.1801 - val_FP: 27.8200 - val_FN: 48.1200\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0582 - Accuracy: 0.9804 - Precision: 0.9518 - Recall: 0.9430 - TP: 3179.8000 - TN: 5497.6001 - FP: 149.4000 - FN: 192.2000 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9593 - val_Recall: 0.9402 - val_TP: 755.8900 - val_TN: 1078.0800 - val_FP: 27.9200 - val_FN: 48.1100\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0581 - Accuracy: 0.9804 - Precision: 0.9517 - Recall: 0.9430 - TP: 3179.9399 - TN: 5497.3101 - FP: 149.6900 - FN: 192.0600 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9595 - val_Recall: 0.9401 - val_TP: 755.8400 - val_TN: 1078.3400 - val_FP: 27.6600 - val_FN: 48.1600\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0581 - Accuracy: 0.9804 - Precision: 0.9519 - Recall: 0.9430 - TP: 3179.8401 - TN: 5497.8999 - FP: 149.1000 - FN: 192.1600 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9596 - val_Recall: 0.9401 - val_TP: 755.8200 - val_TN: 1078.3800 - val_FP: 27.6200 - val_FN: 48.1800\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0581 - Accuracy: 0.9803 - Precision: 0.9520 - Recall: 0.9430 - TP: 3179.6299 - TN: 5498.6499 - FP: 148.3500 - FN: 192.3700 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9596 - val_Recall: 0.9401 - val_TP: 755.8200 - val_TN: 1078.4500 - val_FP: 27.5500 - val_FN: 48.1800\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0580 - Accuracy: 0.9803 - Precision: 0.9520 - Recall: 0.9430 - TP: 3179.7600 - TN: 5498.2300 - FP: 148.7700 - FN: 192.2400 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9597 - val_Recall: 0.9401 - val_TP: 755.8200 - val_TN: 1078.5300 - val_FP: 27.4700 - val_FN: 48.1800\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0580 - Accuracy: 0.9803 - Precision: 0.9522 - Recall: 0.9429 - TP: 3179.4099 - TN: 5499.3198 - FP: 147.6800 - FN: 192.5900 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9598 - val_Recall: 0.9401 - val_TP: 755.8100 - val_TN: 1078.6400 - val_FP: 27.3600 - val_FN: 48.1900\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0580 - Accuracy: 0.9803 - Precision: 0.9522 - Recall: 0.9429 - TP: 3179.4199 - TN: 5499.3901 - FP: 147.6100 - FN: 192.5800 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9597 - val_Recall: 0.9401 - val_TP: 755.8200 - val_TN: 1078.5000 - val_FP: 27.5000 - val_FN: 48.1800\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0580 - Accuracy: 0.9803 - Precision: 0.9523 - Recall: 0.9428 - TP: 3179.2000 - TN: 5499.7900 - FP: 147.2100 - FN: 192.8000 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9598 - val_Recall: 0.9401 - val_TP: 755.8100 - val_TN: 1078.6100 - val_FP: 27.3900 - val_FN: 48.1900\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0580 - Accuracy: 0.9803 - Precision: 0.9522 - Recall: 0.9429 - TP: 3179.3401 - TN: 5499.5000 - FP: 147.5000 - FN: 192.6600 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9598 - val_Recall: 0.9400 - val_TP: 755.7900 - val_TN: 1078.6000 - val_FP: 27.4000 - val_FN: 48.2100\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0579 - Accuracy: 0.9803 - Precision: 0.9523 - Recall: 0.9428 - TP: 3179.1799 - TN: 5499.8901 - FP: 147.1100 - FN: 192.8200 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9598 - val_Recall: 0.9400 - val_TP: 755.8000 - val_TN: 1078.6200 - val_FP: 27.3800 - val_FN: 48.2000\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0579 - Accuracy: 0.9803 - Precision: 0.9524 - Recall: 0.9428 - TP: 3179.1599 - TN: 5500.5098 - FP: 146.4900 - FN: 192.8400 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9598 - val_Recall: 0.9400 - val_TP: 755.7900 - val_TN: 1078.6400 - val_FP: 27.3600 - val_FN: 48.2100\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 7ms/step - loss: 0.0589 - Accuracy: 0.9805 - Precision: 0.9519 - Recall: 0.9431 - TP: 3180.1799 - TN: 5499.2202 - FP: 147.7800 - FN: 191.8200 - val_loss: 0.0737 - val_Accuracy: 0.9770 - val_Precision: 0.9593 - val_Recall: 0.9406 - val_TP: 756.2100 - val_TN: 1078.3300 - val_FP: 27.6700 - val_FN: 47.7900\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0586 - Accuracy: 0.9805 - Precision: 0.9514 - Recall: 0.9433 - TP: 3180.7000 - TN: 5496.8701 - FP: 150.1300 - FN: 191.3000 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9590 - val_Recall: 0.9405 - val_TP: 756.1900 - val_TN: 1078.0699 - val_FP: 27.9300 - val_FN: 47.8100\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0585 - Accuracy: 0.9806 - Precision: 0.9511 - Recall: 0.9433 - TP: 3180.8601 - TN: 5495.6802 - FP: 151.3200 - FN: 191.1400 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9587 - val_Recall: 0.9405 - val_TP: 756.1600 - val_TN: 1077.5100 - val_FP: 28.4900 - val_FN: 47.8400\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0584 - Accuracy: 0.9806 - Precision: 0.9512 - Recall: 0.9433 - TP: 3180.7500 - TN: 5495.5000 - FP: 151.5000 - FN: 191.2500 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9588 - val_Recall: 0.9404 - val_TP: 756.0600 - val_TN: 1077.5900 - val_FP: 28.4100 - val_FN: 47.9400\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0584 - Accuracy: 0.9806 - Precision: 0.9511 - Recall: 0.9433 - TP: 3180.6499 - TN: 5494.5298 - FP: 152.4700 - FN: 191.3500 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9589 - val_Recall: 0.9403 - val_TP: 756.0300 - val_TN: 1077.7100 - val_FP: 28.2900 - val_FN: 47.9700\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0583 - Accuracy: 0.9805 - Precision: 0.9512 - Recall: 0.9432 - TP: 3180.5400 - TN: 5495.1499 - FP: 151.8500 - FN: 191.4600 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9590 - val_Recall: 0.9403 - val_TP: 756.0000 - val_TN: 1077.8400 - val_FP: 28.1600 - val_FN: 48.0000\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0583 - Accuracy: 0.9805 - Precision: 0.9515 - Recall: 0.9431 - TP: 3180.1299 - TN: 5496.1099 - FP: 150.8900 - FN: 191.8700 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9592 - val_Recall: 0.9402 - val_TP: 755.9300 - val_TN: 1078.0200 - val_FP: 27.9800 - val_FN: 48.0700\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0583 - Accuracy: 0.9805 - Precision: 0.9516 - Recall: 0.9431 - TP: 3180.0701 - TN: 5496.7300 - FP: 150.2700 - FN: 191.9300 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9592 - val_Recall: 0.9402 - val_TP: 755.9100 - val_TN: 1078.0200 - val_FP: 27.9800 - val_FN: 48.0900\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0582 - Accuracy: 0.9805 - Precision: 0.9517 - Recall: 0.9430 - TP: 3179.9199 - TN: 5497.1001 - FP: 149.9000 - FN: 192.0800 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9592 - val_Recall: 0.9401 - val_TP: 755.8800 - val_TN: 1078.0699 - val_FP: 27.9300 - val_FN: 48.1200\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0581 - Accuracy: 0.9804 - Precision: 0.9518 - Recall: 0.9430 - TP: 3179.8799 - TN: 5497.4702 - FP: 149.5300 - FN: 192.1200 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9594 - val_Recall: 0.9401 - val_TP: 755.8400 - val_TN: 1078.2100 - val_FP: 27.7900 - val_FN: 48.1600\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0581 - Accuracy: 0.9804 - Precision: 0.9518 - Recall: 0.9430 - TP: 3179.8000 - TN: 5497.8301 - FP: 149.1700 - FN: 192.2000 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9594 - val_Recall: 0.9401 - val_TP: 755.8300 - val_TN: 1078.1801 - val_FP: 27.8200 - val_FN: 48.1700\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0581 - Accuracy: 0.9803 - Precision: 0.9519 - Recall: 0.9430 - TP: 3179.7600 - TN: 5498.0298 - FP: 148.9700 - FN: 192.2400 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9595 - val_Recall: 0.9401 - val_TP: 755.8300 - val_TN: 1078.3199 - val_FP: 27.6800 - val_FN: 48.1700\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0580 - Accuracy: 0.9803 - Precision: 0.9520 - Recall: 0.9430 - TP: 3179.6399 - TN: 5498.6401 - FP: 148.3600 - FN: 192.3600 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9597 - val_Recall: 0.9401 - val_TP: 755.8200 - val_TN: 1078.5200 - val_FP: 27.4800 - val_FN: 48.1800\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0580 - Accuracy: 0.9803 - Precision: 0.9521 - Recall: 0.9429 - TP: 3179.4299 - TN: 5498.9702 - FP: 148.0300 - FN: 192.5700 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9596 - val_Recall: 0.9401 - val_TP: 755.8100 - val_TN: 1078.4600 - val_FP: 27.5400 - val_FN: 48.1900\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0580 - Accuracy: 0.9803 - Precision: 0.9521 - Recall: 0.9429 - TP: 3179.5701 - TN: 5498.7300 - FP: 148.2700 - FN: 192.4300 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9597 - val_Recall: 0.9401 - val_TP: 755.8100 - val_TN: 1078.5000 - val_FP: 27.5000 - val_FN: 48.1900\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0580 - Accuracy: 0.9803 - Precision: 0.9521 - Recall: 0.9429 - TP: 3179.5300 - TN: 5498.8101 - FP: 148.1900 - FN: 192.4700 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9598 - val_Recall: 0.9401 - val_TP: 755.8100 - val_TN: 1078.6100 - val_FP: 27.3900 - val_FN: 48.1900\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0580 - Accuracy: 0.9803 - Precision: 0.9521 - Recall: 0.9429 - TP: 3179.3000 - TN: 5498.9502 - FP: 148.0500 - FN: 192.7000 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9599 - val_Recall: 0.9400 - val_TP: 755.7900 - val_TN: 1078.7000 - val_FP: 27.3000 - val_FN: 48.2100\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0580 - Accuracy: 0.9803 - Precision: 0.9523 - Recall: 0.9428 - TP: 3179.2100 - TN: 5499.9902 - FP: 147.0100 - FN: 192.7900 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9598 - val_Recall: 0.9400 - val_TP: 755.7800 - val_TN: 1078.6600 - val_FP: 27.3400 - val_FN: 48.2200\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0579 - Accuracy: 0.9803 - Precision: 0.9524 - Recall: 0.9428 - TP: 3179.1101 - TN: 5500.2300 - FP: 146.7700 - FN: 192.8900 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9599 - val_Recall: 0.9400 - val_TP: 755.7500 - val_TN: 1078.7700 - val_FP: 27.2300 - val_FN: 48.2500\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0579 - Accuracy: 0.9803 - Precision: 0.9524 - Recall: 0.9428 - TP: 3179.1799 - TN: 5500.3701 - FP: 146.6300 - FN: 192.8200 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9600 - val_Recall: 0.9400 - val_TP: 755.7600 - val_TN: 1078.9000 - val_FP: 27.1000 - val_FN: 48.2400\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0579 - Accuracy: 0.9803 - Precision: 0.9525 - Recall: 0.9428 - TP: 3179.1499 - TN: 5500.5498 - FP: 146.4500 - FN: 192.8500 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9599 - val_Recall: 0.9400 - val_TP: 755.7800 - val_TN: 1078.7700 - val_FP: 27.2300 - val_FN: 48.2200\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 8ms/step - loss: 0.0587 - Accuracy: 0.9805 - Precision: 0.9517 - Recall: 0.9432 - TP: 3180.3701 - TN: 5498.1699 - FP: 148.8300 - FN: 191.6300 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9591 - val_Recall: 0.9405 - val_TP: 756.1900 - val_TN: 1078.1100 - val_FP: 27.8900 - val_FN: 47.8100\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0585 - Accuracy: 0.9806 - Precision: 0.9512 - Recall: 0.9433 - TP: 3180.7700 - TN: 5496.0000 - FP: 151.0000 - FN: 191.2300 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9587 - val_Recall: 0.9405 - val_TP: 756.1600 - val_TN: 1077.5100 - val_FP: 28.4900 - val_FN: 47.8400\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0584 - Accuracy: 0.9806 - Precision: 0.9512 - Recall: 0.9433 - TP: 3180.7100 - TN: 5495.5601 - FP: 151.4400 - FN: 191.2900 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9588 - val_Recall: 0.9403 - val_TP: 756.0400 - val_TN: 1077.6500 - val_FP: 28.3500 - val_FN: 47.9600\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0584 - Accuracy: 0.9806 - Precision: 0.9512 - Recall: 0.9432 - TP: 3180.5400 - TN: 5495.2998 - FP: 151.7000 - FN: 191.4600 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9589 - val_Recall: 0.9403 - val_TP: 756.0200 - val_TN: 1077.6899 - val_FP: 28.3100 - val_FN: 47.9800\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0583 - Accuracy: 0.9805 - Precision: 0.9514 - Recall: 0.9432 - TP: 3180.3501 - TN: 5496.1401 - FP: 150.8600 - FN: 191.6500 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9590 - val_Recall: 0.9403 - val_TP: 755.9800 - val_TN: 1077.8000 - val_FP: 28.2000 - val_FN: 48.0200\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0583 - Accuracy: 0.9805 - Precision: 0.9514 - Recall: 0.9432 - TP: 3180.3301 - TN: 5495.9102 - FP: 151.0900 - FN: 191.6700 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9590 - val_Recall: 0.9402 - val_TP: 755.9500 - val_TN: 1077.8600 - val_FP: 28.1400 - val_FN: 48.0500\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0582 - Accuracy: 0.9804 - Precision: 0.9515 - Recall: 0.9431 - TP: 3180.1101 - TN: 5496.4600 - FP: 150.5400 - FN: 191.8900 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9593 - val_Recall: 0.9401 - val_TP: 755.8800 - val_TN: 1078.0900 - val_FP: 27.9100 - val_FN: 48.1200\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0582 - Accuracy: 0.9804 - Precision: 0.9517 - Recall: 0.9430 - TP: 3179.9099 - TN: 5497.2700 - FP: 149.7300 - FN: 192.0900 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9595 - val_Recall: 0.9401 - val_TP: 755.8400 - val_TN: 1078.2900 - val_FP: 27.7100 - val_FN: 48.1600\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0581 - Accuracy: 0.9805 - Precision: 0.9518 - Recall: 0.9430 - TP: 3179.8999 - TN: 5497.3999 - FP: 149.6000 - FN: 192.1000 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9595 - val_Recall: 0.9401 - val_TP: 755.8300 - val_TN: 1078.3199 - val_FP: 27.6800 - val_FN: 48.1700\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0581 - Accuracy: 0.9803 - Precision: 0.9519 - Recall: 0.9430 - TP: 3179.7600 - TN: 5498.0698 - FP: 148.9300 - FN: 192.2400 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9596 - val_Recall: 0.9401 - val_TP: 755.8300 - val_TN: 1078.4500 - val_FP: 27.5500 - val_FN: 48.1700\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0581 - Accuracy: 0.9803 - Precision: 0.9521 - Recall: 0.9429 - TP: 3179.4700 - TN: 5498.8999 - FP: 148.1000 - FN: 192.5300 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9596 - val_Recall: 0.9401 - val_TP: 755.8300 - val_TN: 1078.4200 - val_FP: 27.5800 - val_FN: 48.1700\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0581 - Accuracy: 0.9803 - Precision: 0.9520 - Recall: 0.9430 - TP: 3179.6299 - TN: 5498.3101 - FP: 148.6900 - FN: 192.3700 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9595 - val_Recall: 0.9401 - val_TP: 755.8300 - val_TN: 1078.3199 - val_FP: 27.6800 - val_FN: 48.1700\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0580 - Accuracy: 0.9804 - Precision: 0.9519 - Recall: 0.9430 - TP: 3179.8401 - TN: 5498.0898 - FP: 148.9100 - FN: 192.1600 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9598 - val_Recall: 0.9401 - val_TP: 755.8100 - val_TN: 1078.6000 - val_FP: 27.4000 - val_FN: 48.1900\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0580 - Accuracy: 0.9803 - Precision: 0.9523 - Recall: 0.9428 - TP: 3179.1699 - TN: 5499.7598 - FP: 147.2400 - FN: 192.8300 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9598 - val_Recall: 0.9400 - val_TP: 755.7800 - val_TN: 1078.6100 - val_FP: 27.3900 - val_FN: 48.2200\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0580 - Accuracy: 0.9803 - Precision: 0.9522 - Recall: 0.9429 - TP: 3179.3101 - TN: 5499.6001 - FP: 147.4000 - FN: 192.6900 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9598 - val_Recall: 0.9400 - val_TP: 755.8000 - val_TN: 1078.6801 - val_FP: 27.3200 - val_FN: 48.2000\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0579 - Accuracy: 0.9803 - Precision: 0.9524 - Recall: 0.9428 - TP: 3179.0400 - TN: 5500.4302 - FP: 146.5700 - FN: 192.9600 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9598 - val_Recall: 0.9400 - val_TP: 755.8000 - val_TN: 1078.6000 - val_FP: 27.4000 - val_FN: 48.2000\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0579 - Accuracy: 0.9803 - Precision: 0.9522 - Recall: 0.9429 - TP: 3179.4199 - TN: 5499.5498 - FP: 147.4500 - FN: 192.5800 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9598 - val_Recall: 0.9400 - val_TP: 755.7900 - val_TN: 1078.6300 - val_FP: 27.3700 - val_FN: 48.2100\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0579 - Accuracy: 0.9803 - Precision: 0.9524 - Recall: 0.9428 - TP: 3179.2000 - TN: 5500.2798 - FP: 146.7200 - FN: 192.8000 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9600 - val_Recall: 0.9400 - val_TP: 755.7600 - val_TN: 1078.8101 - val_FP: 27.1900 - val_FN: 48.2400\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0579 - Accuracy: 0.9803 - Precision: 0.9524 - Recall: 0.9429 - TP: 3179.3899 - TN: 5500.0698 - FP: 146.9300 - FN: 192.6100 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9600 - val_Recall: 0.9400 - val_TP: 755.7700 - val_TN: 1078.8400 - val_FP: 27.1600 - val_FN: 48.2300\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0579 - Accuracy: 0.9803 - Precision: 0.9526 - Recall: 0.9428 - TP: 3179.0801 - TN: 5501.1802 - FP: 145.8200 - FN: 192.9200 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9601 - val_Recall: 0.9400 - val_TP: 755.7600 - val_TN: 1078.9301 - val_FP: 27.0700 - val_FN: 48.2400\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0579 - Accuracy: 0.9803 - Precision: 0.9525 - Recall: 0.9428 - TP: 3179.2900 - TN: 5500.5400 - FP: 146.4600 - FN: 192.7100 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9600 - val_Recall: 0.9400 - val_TP: 755.7500 - val_TN: 1078.8300 - val_FP: 27.1700 - val_FN: 48.2500\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 8ms/step - loss: 0.0586 - Accuracy: 0.9805 - Precision: 0.9517 - Recall: 0.9432 - TP: 3180.3201 - TN: 5498.2500 - FP: 148.7500 - FN: 191.6800 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9591 - val_Recall: 0.9405 - val_TP: 756.1600 - val_TN: 1078.1200 - val_FP: 27.8800 - val_FN: 47.8400\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0584 - Accuracy: 0.9806 - Precision: 0.9512 - Recall: 0.9433 - TP: 3180.6599 - TN: 5495.3301 - FP: 151.6700 - FN: 191.3400 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9590 - val_Recall: 0.9403 - val_TP: 756.0400 - val_TN: 1077.8000 - val_FP: 28.2000 - val_FN: 47.9600\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0584 - Accuracy: 0.9806 - Precision: 0.9513 - Recall: 0.9432 - TP: 3180.5000 - TN: 5495.6602 - FP: 151.3400 - FN: 191.5000 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9590 - val_Recall: 0.9403 - val_TP: 756.0000 - val_TN: 1077.8101 - val_FP: 28.1900 - val_FN: 48.0000\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0583 - Accuracy: 0.9806 - Precision: 0.9514 - Recall: 0.9432 - TP: 3180.3301 - TN: 5495.8301 - FP: 151.1700 - FN: 191.6700 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9591 - val_Recall: 0.9403 - val_TP: 755.9700 - val_TN: 1077.9301 - val_FP: 28.0700 - val_FN: 48.0300\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0583 - Accuracy: 0.9804 - Precision: 0.9516 - Recall: 0.9431 - TP: 3180.0701 - TN: 5496.6899 - FP: 150.3100 - FN: 191.9300 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9592 - val_Recall: 0.9402 - val_TP: 755.9200 - val_TN: 1078.0200 - val_FP: 27.9800 - val_FN: 48.0800\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0582 - Accuracy: 0.9804 - Precision: 0.9517 - Recall: 0.9430 - TP: 3179.9600 - TN: 5497.3101 - FP: 149.6900 - FN: 192.0400 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9592 - val_Recall: 0.9401 - val_TP: 755.8800 - val_TN: 1078.0699 - val_FP: 27.9300 - val_FN: 48.1200\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0582 - Accuracy: 0.9805 - Precision: 0.9516 - Recall: 0.9431 - TP: 3180.0901 - TN: 5496.6899 - FP: 150.3100 - FN: 191.9100 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9594 - val_Recall: 0.9401 - val_TP: 755.8700 - val_TN: 1078.2100 - val_FP: 27.7900 - val_FN: 48.1300\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0581 - Accuracy: 0.9804 - Precision: 0.9519 - Recall: 0.9430 - TP: 3179.7500 - TN: 5498.2002 - FP: 148.8000 - FN: 192.2500 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9595 - val_Recall: 0.9401 - val_TP: 755.8400 - val_TN: 1078.3000 - val_FP: 27.7000 - val_FN: 48.1600\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0581 - Accuracy: 0.9804 - Precision: 0.9518 - Recall: 0.9431 - TP: 3179.9700 - TN: 5497.3901 - FP: 149.6100 - FN: 192.0300 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9596 - val_Recall: 0.9401 - val_TP: 755.8300 - val_TN: 1078.4600 - val_FP: 27.5400 - val_FN: 48.1700\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0581 - Accuracy: 0.9803 - Precision: 0.9522 - Recall: 0.9429 - TP: 3179.4800 - TN: 5499.2798 - FP: 147.7200 - FN: 192.5200 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9596 - val_Recall: 0.9401 - val_TP: 755.8300 - val_TN: 1078.3800 - val_FP: 27.6200 - val_FN: 48.1700\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0580 - Accuracy: 0.9803 - Precision: 0.9520 - Recall: 0.9430 - TP: 3179.6399 - TN: 5498.5200 - FP: 148.4800 - FN: 192.3600 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9595 - val_Recall: 0.9401 - val_TP: 755.8300 - val_TN: 1078.3300 - val_FP: 27.6700 - val_FN: 48.1700\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0580 - Accuracy: 0.9803 - Precision: 0.9520 - Recall: 0.9430 - TP: 3179.7100 - TN: 5498.3599 - FP: 148.6400 - FN: 192.2900 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9598 - val_Recall: 0.9401 - val_TP: 755.8300 - val_TN: 1078.6000 - val_FP: 27.4000 - val_FN: 48.1700\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0580 - Accuracy: 0.9803 - Precision: 0.9522 - Recall: 0.9429 - TP: 3179.3799 - TN: 5499.1699 - FP: 147.8300 - FN: 192.6200 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9598 - val_Recall: 0.9401 - val_TP: 755.8100 - val_TN: 1078.6700 - val_FP: 27.3300 - val_FN: 48.1900\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0580 - Accuracy: 0.9803 - Precision: 0.9523 - Recall: 0.9429 - TP: 3179.3501 - TN: 5499.7002 - FP: 147.3000 - FN: 192.6500 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9599 - val_Recall: 0.9400 - val_TP: 755.7900 - val_TN: 1078.7000 - val_FP: 27.3000 - val_FN: 48.2100\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0580 - Accuracy: 0.9803 - Precision: 0.9523 - Recall: 0.9428 - TP: 3179.2700 - TN: 5499.9399 - FP: 147.0600 - FN: 192.7300 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9599 - val_Recall: 0.9400 - val_TP: 755.7800 - val_TN: 1078.7000 - val_FP: 27.3000 - val_FN: 48.2200\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0579 - Accuracy: 0.9803 - Precision: 0.9523 - Recall: 0.9429 - TP: 3179.3401 - TN: 5499.8198 - FP: 147.1800 - FN: 192.6600 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9600 - val_Recall: 0.9400 - val_TP: 755.7600 - val_TN: 1078.9000 - val_FP: 27.1000 - val_FN: 48.2400\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0579 - Accuracy: 0.9803 - Precision: 0.9525 - Recall: 0.9428 - TP: 3179.0601 - TN: 5500.7100 - FP: 146.2900 - FN: 192.9400 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9599 - val_Recall: 0.9400 - val_TP: 755.7700 - val_TN: 1078.7000 - val_FP: 27.3000 - val_FN: 48.2300\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0579 - Accuracy: 0.9803 - Precision: 0.9525 - Recall: 0.9428 - TP: 3179.2500 - TN: 5500.5698 - FP: 146.4300 - FN: 192.7500 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9600 - val_Recall: 0.9400 - val_TP: 755.7400 - val_TN: 1078.8700 - val_FP: 27.1300 - val_FN: 48.2600\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0579 - Accuracy: 0.9803 - Precision: 0.9524 - Recall: 0.9429 - TP: 3179.3999 - TN: 5500.0801 - FP: 146.9200 - FN: 192.6000 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9600 - val_Recall: 0.9400 - val_TP: 755.7500 - val_TN: 1078.8800 - val_FP: 27.1200 - val_FN: 48.2500\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0578 - Accuracy: 0.9803 - Precision: 0.9526 - Recall: 0.9428 - TP: 3179.1799 - TN: 5501.3501 - FP: 145.6500 - FN: 192.8200 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9600 - val_Recall: 0.9400 - val_TP: 755.7500 - val_TN: 1078.8700 - val_FP: 27.1300 - val_FN: 48.2500\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0578 - Accuracy: 0.9802 - Precision: 0.9526 - Recall: 0.9428 - TP: 3179.1599 - TN: 5501.2500 - FP: 145.7500 - FN: 192.8400 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9600 - val_Recall: 0.9400 - val_TP: 755.7600 - val_TN: 1078.8600 - val_FP: 27.1400 - val_FN: 48.2400\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0578 - Accuracy: 0.9803 - Precision: 0.9526 - Recall: 0.9428 - TP: 3179.2300 - TN: 5501.3999 - FP: 145.6000 - FN: 192.7700 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9600 - val_Recall: 0.9400 - val_TP: 755.7900 - val_TN: 1078.8600 - val_FP: 27.1400 - val_FN: 48.2100\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0578 - Accuracy: 0.9803 - Precision: 0.9526 - Recall: 0.9429 - TP: 3179.4199 - TN: 5501.1499 - FP: 145.8500 - FN: 192.5800 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9601 - val_Recall: 0.9400 - val_TP: 755.7700 - val_TN: 1078.9500 - val_FP: 27.0500 - val_FN: 48.2300\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0578 - Accuracy: 0.9802 - Precision: 0.9527 - Recall: 0.9428 - TP: 3179.1899 - TN: 5501.6699 - FP: 145.3300 - FN: 192.8100 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9601 - val_Recall: 0.9400 - val_TP: 755.7700 - val_TN: 1079.0100 - val_FP: 26.9900 - val_FN: 48.2300\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0578 - Accuracy: 0.9802 - Precision: 0.9527 - Recall: 0.9428 - TP: 3179.2800 - TN: 5501.6401 - FP: 145.3600 - FN: 192.7200 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9601 - val_Recall: 0.9400 - val_TP: 755.7900 - val_TN: 1079.0200 - val_FP: 26.9800 - val_FN: 48.2100\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0578 - Accuracy: 0.9802 - Precision: 0.9528 - Recall: 0.9428 - TP: 3179.1799 - TN: 5501.9199 - FP: 145.0800 - FN: 192.8200 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9600 - val_Recall: 0.9400 - val_TP: 755.7900 - val_TN: 1078.8900 - val_FP: 27.1100 - val_FN: 48.2100\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0578 - Accuracy: 0.9803 - Precision: 0.9525 - Recall: 0.9429 - TP: 3179.5200 - TN: 5500.8101 - FP: 146.1900 - FN: 192.4800 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9601 - val_Recall: 0.9400 - val_TP: 755.8000 - val_TN: 1079.0100 - val_FP: 26.9900 - val_FN: 48.2000\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0577 - Accuracy: 0.9803 - Precision: 0.9528 - Recall: 0.9428 - TP: 3179.1899 - TN: 5501.9502 - FP: 145.0500 - FN: 192.8100 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9601 - val_Recall: 0.9400 - val_TP: 755.8000 - val_TN: 1078.9600 - val_FP: 27.0400 - val_FN: 48.2000\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0577 - Accuracy: 0.9804 - Precision: 0.9529 - Recall: 0.9428 - TP: 3179.1299 - TN: 5502.5400 - FP: 144.4600 - FN: 192.8700 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9601 - val_Recall: 0.9401 - val_TP: 755.8400 - val_TN: 1078.9700 - val_FP: 27.0300 - val_FN: 48.1600\n",
      "Epoch 30/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0577 - Accuracy: 0.9802 - Precision: 0.9528 - Recall: 0.9428 - TP: 3179.1699 - TN: 5502.2700 - FP: 144.7300 - FN: 192.8300 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9601 - val_Recall: 0.9401 - val_TP: 755.8600 - val_TN: 1078.9600 - val_FP: 27.0400 - val_FN: 48.1400\n",
      "Epoch 31/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0577 - Accuracy: 0.9803 - Precision: 0.9526 - Recall: 0.9429 - TP: 3179.5400 - TN: 5501.1499 - FP: 145.8500 - FN: 192.4600 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9602 - val_Recall: 0.9401 - val_TP: 755.8500 - val_TN: 1079.0300 - val_FP: 26.9700 - val_FN: 48.1500\n",
      "Epoch 32/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0577 - Accuracy: 0.9803 - Precision: 0.9529 - Recall: 0.9428 - TP: 3179.1599 - TN: 5502.7202 - FP: 144.2800 - FN: 192.8400 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9600 - val_Recall: 0.9401 - val_TP: 755.8800 - val_TN: 1078.9000 - val_FP: 27.1000 - val_FN: 48.1200\n",
      "Epoch 33/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0577 - Accuracy: 0.9804 - Precision: 0.9528 - Recall: 0.9429 - TP: 3179.4600 - TN: 5502.0000 - FP: 145.0000 - FN: 192.5400 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9601 - val_Recall: 0.9401 - val_TP: 755.8800 - val_TN: 1078.9900 - val_FP: 27.0100 - val_FN: 48.1200\n",
      "Epoch 34/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0577 - Accuracy: 0.9803 - Precision: 0.9527 - Recall: 0.9429 - TP: 3179.5400 - TN: 5501.7402 - FP: 145.2600 - FN: 192.4600 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9601 - val_Recall: 0.9401 - val_TP: 755.8800 - val_TN: 1079.0000 - val_FP: 27.0000 - val_FN: 48.1200\n",
      "Epoch 35/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0577 - Accuracy: 0.9803 - Precision: 0.9528 - Recall: 0.9429 - TP: 3179.5100 - TN: 5501.9102 - FP: 145.0900 - FN: 192.4900 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9602 - val_Recall: 0.9401 - val_TP: 755.8800 - val_TN: 1079.1000 - val_FP: 26.9000 - val_FN: 48.1200\n",
      "Epoch 36/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0576 - Accuracy: 0.9803 - Precision: 0.9530 - Recall: 0.9428 - TP: 3179.2200 - TN: 5502.9302 - FP: 144.0700 - FN: 192.7800 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9601 - val_Recall: 0.9401 - val_TP: 755.8800 - val_TN: 1079.0100 - val_FP: 26.9900 - val_FN: 48.1200\n",
      "Epoch 37/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0577 - Accuracy: 0.9803 - Precision: 0.9526 - Recall: 0.9430 - TP: 3179.6899 - TN: 5500.8501 - FP: 146.1500 - FN: 192.3100 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9602 - val_Recall: 0.9401 - val_TP: 755.8800 - val_TN: 1079.0500 - val_FP: 26.9500 - val_FN: 48.1200\n",
      "Epoch 38/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0576 - Accuracy: 0.9803 - Precision: 0.9530 - Recall: 0.9428 - TP: 3179.2400 - TN: 5502.9399 - FP: 144.0600 - FN: 192.7600 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9401 - val_TP: 755.8800 - val_TN: 1079.2300 - val_FP: 26.7700 - val_FN: 48.1200\n",
      "Epoch 39/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0576 - Accuracy: 0.9803 - Precision: 0.9528 - Recall: 0.9429 - TP: 3179.4700 - TN: 5502.0098 - FP: 144.9900 - FN: 192.5300 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9602 - val_Recall: 0.9401 - val_TP: 755.8800 - val_TN: 1079.1200 - val_FP: 26.8800 - val_FN: 48.1200\n",
      "Epoch 40/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0576 - Accuracy: 0.9804 - Precision: 0.9527 - Recall: 0.9430 - TP: 3179.6499 - TN: 5501.6499 - FP: 145.3500 - FN: 192.3500 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9402 - val_TP: 755.9100 - val_TN: 1079.2000 - val_FP: 26.8000 - val_FN: 48.0900\n",
      "Epoch 41/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0576 - Accuracy: 0.9803 - Precision: 0.9531 - Recall: 0.9429 - TP: 3179.3899 - TN: 5503.3398 - FP: 143.6600 - FN: 192.6100 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9402 - val_TP: 755.9200 - val_TN: 1079.2600 - val_FP: 26.7400 - val_FN: 48.0800\n",
      "Epoch 42/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0576 - Accuracy: 0.9803 - Precision: 0.9528 - Recall: 0.9429 - TP: 3179.5200 - TN: 5502.1899 - FP: 144.8100 - FN: 192.4800 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9402 - val_TP: 755.9200 - val_TN: 1079.2100 - val_FP: 26.7900 - val_FN: 48.0800\n",
      "Epoch 43/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0576 - Accuracy: 0.9804 - Precision: 0.9530 - Recall: 0.9429 - TP: 3179.4299 - TN: 5503.2202 - FP: 143.7800 - FN: 192.5700 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9402 - val_TP: 755.9300 - val_TN: 1079.2300 - val_FP: 26.7700 - val_FN: 48.0700\n",
      "Epoch 44/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0576 - Accuracy: 0.9803 - Precision: 0.9528 - Recall: 0.9430 - TP: 3179.7800 - TN: 5502.1699 - FP: 144.8300 - FN: 192.2200 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9402 - val_TP: 755.9300 - val_TN: 1079.2200 - val_FP: 26.7800 - val_FN: 48.0700\n",
      "Epoch 45/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0576 - Accuracy: 0.9803 - Precision: 0.9530 - Recall: 0.9429 - TP: 3179.5801 - TN: 5502.9399 - FP: 144.0600 - FN: 192.4200 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9402 - val_TP: 755.9400 - val_TN: 1079.2000 - val_FP: 26.8000 - val_FN: 48.0600\n",
      "Epoch 46/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0575 - Accuracy: 0.9803 - Precision: 0.9530 - Recall: 0.9429 - TP: 3179.4800 - TN: 5503.1899 - FP: 143.8100 - FN: 192.5200 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9598 - val_Recall: 0.9402 - val_TP: 755.9600 - val_TN: 1078.5500 - val_FP: 27.4500 - val_FN: 48.0400\n",
      "Epoch 47/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0576 - Accuracy: 0.9804 - Precision: 0.9528 - Recall: 0.9430 - TP: 3179.8601 - TN: 5502.1401 - FP: 144.8600 - FN: 192.1400 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9402 - val_TP: 755.9300 - val_TN: 1079.2900 - val_FP: 26.7100 - val_FN: 48.0700\n",
      "Epoch 48/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0575 - Accuracy: 0.9804 - Precision: 0.9529 - Recall: 0.9430 - TP: 3179.7600 - TN: 5502.3901 - FP: 144.6100 - FN: 192.2400 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9402 - val_TP: 755.9400 - val_TN: 1079.2600 - val_FP: 26.7400 - val_FN: 48.0600\n",
      "Epoch 49/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0575 - Accuracy: 0.9804 - Precision: 0.9530 - Recall: 0.9430 - TP: 3179.6499 - TN: 5502.9600 - FP: 144.0400 - FN: 192.3500 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9402 - val_TP: 755.9300 - val_TN: 1079.2900 - val_FP: 26.7100 - val_FN: 48.0700\n",
      "Epoch 50/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0575 - Accuracy: 0.9804 - Precision: 0.9530 - Recall: 0.9430 - TP: 3179.7100 - TN: 5503.1099 - FP: 143.8900 - FN: 192.2900 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9402 - val_TP: 755.9600 - val_TN: 1079.3000 - val_FP: 26.7000 - val_FN: 48.0400\n",
      "Epoch 51/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0575 - Accuracy: 0.9804 - Precision: 0.9531 - Recall: 0.9429 - TP: 3179.6001 - TN: 5503.4600 - FP: 143.5400 - FN: 192.4000 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9403 - val_TP: 755.9800 - val_TN: 1079.2700 - val_FP: 26.7300 - val_FN: 48.0200\n",
      "Epoch 52/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0575 - Accuracy: 0.9804 - Precision: 0.9530 - Recall: 0.9430 - TP: 3179.8201 - TN: 5502.7900 - FP: 144.2100 - FN: 192.1800 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9403 - val_TP: 755.9700 - val_TN: 1079.2100 - val_FP: 26.7900 - val_FN: 48.0300\n",
      "Epoch 53/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0575 - Accuracy: 0.9804 - Precision: 0.9530 - Recall: 0.9430 - TP: 3179.8201 - TN: 5502.8198 - FP: 144.1800 - FN: 192.1800 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9598 - val_Recall: 0.9403 - val_TP: 755.9900 - val_TN: 1078.6000 - val_FP: 27.4000 - val_FN: 48.0100\n",
      "Epoch 54/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0575 - Accuracy: 0.9804 - Precision: 0.9529 - Recall: 0.9430 - TP: 3179.8799 - TN: 5502.5601 - FP: 144.4400 - FN: 192.1200 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9403 - val_TP: 755.9900 - val_TN: 1079.2500 - val_FP: 26.7500 - val_FN: 48.0100\n",
      "Epoch 55/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0575 - Accuracy: 0.9804 - Precision: 0.9529 - Recall: 0.9430 - TP: 3179.9299 - TN: 5502.3599 - FP: 144.6400 - FN: 192.0700 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9403 - val_TP: 755.9700 - val_TN: 1079.2900 - val_FP: 26.7100 - val_FN: 48.0300\n",
      "Epoch 56/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0575 - Accuracy: 0.9805 - Precision: 0.9530 - Recall: 0.9430 - TP: 3179.8101 - TN: 5502.7900 - FP: 144.2100 - FN: 192.1900 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9602 - val_Recall: 0.9403 - val_TP: 756.0000 - val_TN: 1079.1100 - val_FP: 26.8900 - val_FN: 48.0000\n",
      "Epoch 57/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0575 - Accuracy: 0.9804 - Precision: 0.9530 - Recall: 0.9431 - TP: 3179.9800 - TN: 5502.8599 - FP: 144.1400 - FN: 192.0200 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9403 - val_TP: 756.0000 - val_TN: 1079.2300 - val_FP: 26.7700 - val_FN: 48.0000\n",
      "Epoch 58/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0574 - Accuracy: 0.9804 - Precision: 0.9530 - Recall: 0.9431 - TP: 3180.0300 - TN: 5502.7900 - FP: 144.2100 - FN: 191.9700 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9602 - val_Recall: 0.9403 - val_TP: 756.0200 - val_TN: 1079.1500 - val_FP: 26.8500 - val_FN: 47.9800\n",
      "Epoch 59/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0575 - Accuracy: 0.9805 - Precision: 0.9529 - Recall: 0.9431 - TP: 3180.0901 - TN: 5502.4502 - FP: 144.5500 - FN: 191.9100 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9403 - val_TP: 756.0200 - val_TN: 1079.2400 - val_FP: 26.7600 - val_FN: 47.9800\n",
      "Epoch 60/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0574 - Accuracy: 0.9804 - Precision: 0.9531 - Recall: 0.9431 - TP: 3179.9800 - TN: 5503.5400 - FP: 143.4600 - FN: 192.0200 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9403 - val_TP: 756.0200 - val_TN: 1079.2500 - val_FP: 26.7500 - val_FN: 47.9800\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 8ms/step - loss: 0.0574 - Accuracy: 0.9805 - Precision: 0.9532 - Recall: 0.9430 - TP: 3179.9099 - TN: 5503.9800 - FP: 143.0200 - FN: 192.0900 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9403 - val_TP: 756.0300 - val_TN: 1079.2700 - val_FP: 26.7300 - val_FN: 47.9700\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0574 - Accuracy: 0.9804 - Precision: 0.9531 - Recall: 0.9431 - TP: 3180.2000 - TN: 5503.4399 - FP: 143.5600 - FN: 191.8000 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9404 - val_TP: 756.0700 - val_TN: 1079.2100 - val_FP: 26.7900 - val_FN: 47.9300\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0574 - Accuracy: 0.9804 - Precision: 0.9530 - Recall: 0.9431 - TP: 3180.2300 - TN: 5503.0000 - FP: 144.0000 - FN: 191.7700 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9404 - val_TP: 756.0600 - val_TN: 1079.2000 - val_FP: 26.8000 - val_FN: 47.9400\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0574 - Accuracy: 0.9804 - Precision: 0.9530 - Recall: 0.9431 - TP: 3180.2600 - TN: 5503.2300 - FP: 143.7700 - FN: 191.7400 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9404 - val_TP: 756.0600 - val_TN: 1079.2200 - val_FP: 26.7800 - val_FN: 47.9400\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0574 - Accuracy: 0.9804 - Precision: 0.9531 - Recall: 0.9431 - TP: 3180.2100 - TN: 5503.4502 - FP: 143.5500 - FN: 191.7900 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9404 - val_TP: 756.0600 - val_TN: 1079.2500 - val_FP: 26.7500 - val_FN: 47.9400\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0574 - Accuracy: 0.9805 - Precision: 0.9530 - Recall: 0.9431 - TP: 3180.2800 - TN: 5502.9199 - FP: 144.0800 - FN: 191.7200 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9404 - val_TP: 756.0900 - val_TN: 1079.2200 - val_FP: 26.7800 - val_FN: 47.9100\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0574 - Accuracy: 0.9804 - Precision: 0.9529 - Recall: 0.9432 - TP: 3180.4900 - TN: 5502.7300 - FP: 144.2700 - FN: 191.5100 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9404 - val_TP: 756.1000 - val_TN: 1079.2300 - val_FP: 26.7700 - val_FN: 47.9000\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0573 - Accuracy: 0.9805 - Precision: 0.9531 - Recall: 0.9432 - TP: 3180.3799 - TN: 5503.3901 - FP: 143.6100 - FN: 191.6200 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9404 - val_TP: 756.0700 - val_TN: 1079.2600 - val_FP: 26.7400 - val_FN: 47.9300\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0573 - Accuracy: 0.9805 - Precision: 0.9531 - Recall: 0.9432 - TP: 3180.3501 - TN: 5503.3999 - FP: 143.6000 - FN: 191.6500 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9404 - val_TP: 756.1000 - val_TN: 1079.2500 - val_FP: 26.7500 - val_FN: 47.9000\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0573 - Accuracy: 0.9805 - Precision: 0.9532 - Recall: 0.9431 - TP: 3180.2600 - TN: 5503.8301 - FP: 143.1700 - FN: 191.7400 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9599 - val_Recall: 0.9405 - val_TP: 756.1300 - val_TN: 1078.6400 - val_FP: 27.3600 - val_FN: 47.8700\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0573 - Accuracy: 0.9805 - Precision: 0.9529 - Recall: 0.9432 - TP: 3180.4099 - TN: 5502.5000 - FP: 144.5000 - FN: 191.5900 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9404 - val_TP: 756.1100 - val_TN: 1079.2600 - val_FP: 26.7400 - val_FN: 47.8900\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0573 - Accuracy: 0.9805 - Precision: 0.9530 - Recall: 0.9432 - TP: 3180.5901 - TN: 5503.1299 - FP: 143.8700 - FN: 191.4100 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9404 - val_TP: 756.1100 - val_TN: 1079.2400 - val_FP: 26.7600 - val_FN: 47.8900\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0573 - Accuracy: 0.9805 - Precision: 0.9530 - Recall: 0.9432 - TP: 3180.6101 - TN: 5502.7998 - FP: 144.2000 - FN: 191.3900 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9404 - val_TP: 756.1000 - val_TN: 1079.3199 - val_FP: 26.6800 - val_FN: 47.9000\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0573 - Accuracy: 0.9805 - Precision: 0.9530 - Recall: 0.9433 - TP: 3180.6499 - TN: 5503.0400 - FP: 143.9600 - FN: 191.3500 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9404 - val_TP: 756.1000 - val_TN: 1079.2200 - val_FP: 26.7800 - val_FN: 47.9000\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0573 - Accuracy: 0.9806 - Precision: 0.9531 - Recall: 0.9432 - TP: 3180.5500 - TN: 5503.2998 - FP: 143.7000 - FN: 191.4500 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9404 - val_TP: 756.0700 - val_TN: 1079.3199 - val_FP: 26.6800 - val_FN: 47.9300\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0573 - Accuracy: 0.9805 - Precision: 0.9531 - Recall: 0.9432 - TP: 3180.5601 - TN: 5503.4102 - FP: 143.5900 - FN: 191.4400 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9404 - val_TP: 756.1100 - val_TN: 1079.2600 - val_FP: 26.7400 - val_FN: 47.8900\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0573 - Accuracy: 0.9806 - Precision: 0.9529 - Recall: 0.9433 - TP: 3180.8000 - TN: 5502.4399 - FP: 144.5600 - FN: 191.2000 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9404 - val_TP: 756.1000 - val_TN: 1079.3199 - val_FP: 26.6800 - val_FN: 47.9000\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0573 - Accuracy: 0.9805 - Precision: 0.9533 - Recall: 0.9432 - TP: 3180.3601 - TN: 5504.3701 - FP: 142.6300 - FN: 191.6400 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9404 - val_TP: 756.1000 - val_TN: 1079.3400 - val_FP: 26.6600 - val_FN: 47.9000\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0572 - Accuracy: 0.9805 - Precision: 0.9529 - Recall: 0.9433 - TP: 3180.9700 - TN: 5502.3301 - FP: 144.6700 - FN: 191.0300 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9405 - val_TP: 756.1400 - val_TN: 1079.2600 - val_FP: 26.7400 - val_FN: 47.8600\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0573 - Accuracy: 0.9805 - Precision: 0.9531 - Recall: 0.9432 - TP: 3180.5400 - TN: 5503.7100 - FP: 143.2900 - FN: 191.4600 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9405 - val_TP: 756.1400 - val_TN: 1079.3700 - val_FP: 26.6300 - val_FN: 47.8600\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0572 - Accuracy: 0.9806 - Precision: 0.9532 - Recall: 0.9432 - TP: 3180.5601 - TN: 5503.7500 - FP: 143.2500 - FN: 191.4400 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9405 - val_TP: 756.1400 - val_TN: 1079.2800 - val_FP: 26.7200 - val_FN: 47.8600\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0572 - Accuracy: 0.9807 - Precision: 0.9528 - Recall: 0.9434 - TP: 3181.0500 - TN: 5501.6699 - FP: 145.3300 - FN: 190.9500 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9405 - val_TP: 756.1800 - val_TN: 1079.3500 - val_FP: 26.6500 - val_FN: 47.8200\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0572 - Accuracy: 0.9806 - Precision: 0.9531 - Recall: 0.9433 - TP: 3180.8000 - TN: 5503.3198 - FP: 143.6800 - FN: 191.2000 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9405 - val_TP: 756.2000 - val_TN: 1079.2700 - val_FP: 26.7300 - val_FN: 47.8000\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0572 - Accuracy: 0.9805 - Precision: 0.9533 - Recall: 0.9432 - TP: 3180.5801 - TN: 5504.4199 - FP: 142.5800 - FN: 191.4200 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9599 - val_Recall: 0.9406 - val_TP: 756.2100 - val_TN: 1078.6400 - val_FP: 27.3600 - val_FN: 47.7900\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0572 - Accuracy: 0.9806 - Precision: 0.9527 - Recall: 0.9434 - TP: 3180.9900 - TN: 5501.4800 - FP: 145.5200 - FN: 191.0100 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9406 - val_TP: 756.2100 - val_TN: 1079.1899 - val_FP: 26.8100 - val_FN: 47.7900\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0572 - Accuracy: 0.9806 - Precision: 0.9531 - Recall: 0.9433 - TP: 3180.7400 - TN: 5503.6802 - FP: 143.3200 - FN: 191.2600 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9405 - val_TP: 756.2000 - val_TN: 1079.3199 - val_FP: 26.6800 - val_FN: 47.8000\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0572 - Accuracy: 0.9806 - Precision: 0.9533 - Recall: 0.9433 - TP: 3180.8201 - TN: 5504.3198 - FP: 142.6800 - FN: 191.1800 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9599 - val_Recall: 0.9406 - val_TP: 756.2100 - val_TN: 1078.7100 - val_FP: 27.2900 - val_FN: 47.7900\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0572 - Accuracy: 0.9806 - Precision: 0.9529 - Recall: 0.9434 - TP: 3181.0200 - TN: 5502.0801 - FP: 144.9200 - FN: 190.9800 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9405 - val_TP: 756.1900 - val_TN: 1079.2800 - val_FP: 26.7200 - val_FN: 47.8100\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0572 - Accuracy: 0.9806 - Precision: 0.9531 - Recall: 0.9433 - TP: 3180.8101 - TN: 5503.5200 - FP: 143.4800 - FN: 191.1900 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9599 - val_Recall: 0.9406 - val_TP: 756.2100 - val_TN: 1078.6400 - val_FP: 27.3600 - val_FN: 47.7900\n",
      "Epoch 30/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0572 - Accuracy: 0.9806 - Precision: 0.9529 - Recall: 0.9433 - TP: 3180.9500 - TN: 5502.4199 - FP: 144.5800 - FN: 191.0500 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9405 - val_TP: 756.1900 - val_TN: 1079.2700 - val_FP: 26.7300 - val_FN: 47.8100\n",
      "Epoch 31/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0571 - Accuracy: 0.9806 - Precision: 0.9530 - Recall: 0.9434 - TP: 3181.0000 - TN: 5503.1602 - FP: 143.8400 - FN: 191.0000 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9405 - val_TP: 756.1900 - val_TN: 1079.3300 - val_FP: 26.6700 - val_FN: 47.8100\n",
      "Epoch 32/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0571 - Accuracy: 0.9806 - Precision: 0.9533 - Recall: 0.9433 - TP: 3180.7400 - TN: 5504.3599 - FP: 142.6400 - FN: 191.2600 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9405 - val_TP: 756.1900 - val_TN: 1079.3300 - val_FP: 26.6700 - val_FN: 47.8100\n",
      "Epoch 33/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0571 - Accuracy: 0.9806 - Precision: 0.9529 - Recall: 0.9434 - TP: 3180.9800 - TN: 5502.5801 - FP: 144.4200 - FN: 191.0200 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9405 - val_TP: 756.1900 - val_TN: 1079.3600 - val_FP: 26.6400 - val_FN: 47.8100\n",
      "Epoch 34/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0571 - Accuracy: 0.9806 - Precision: 0.9532 - Recall: 0.9433 - TP: 3180.8701 - TN: 5503.7998 - FP: 143.2000 - FN: 191.1300 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9406 - val_TP: 756.2100 - val_TN: 1079.3300 - val_FP: 26.6700 - val_FN: 47.7900\n",
      "Epoch 35/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0571 - Accuracy: 0.9806 - Precision: 0.9531 - Recall: 0.9434 - TP: 3181.1101 - TN: 5503.7002 - FP: 143.3000 - FN: 190.8900 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9406 - val_TP: 756.2100 - val_TN: 1079.3500 - val_FP: 26.6500 - val_FN: 47.7900\n",
      "Epoch 36/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0571 - Accuracy: 0.9806 - Precision: 0.9533 - Recall: 0.9433 - TP: 3180.9299 - TN: 5504.3599 - FP: 142.6400 - FN: 191.0700 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9406 - val_TP: 756.2300 - val_TN: 1079.2600 - val_FP: 26.7400 - val_FN: 47.7700\n",
      "Epoch 37/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0571 - Accuracy: 0.9806 - Precision: 0.9531 - Recall: 0.9434 - TP: 3181.1299 - TN: 5503.3599 - FP: 143.6400 - FN: 190.8700 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9406 - val_TP: 756.2200 - val_TN: 1079.3400 - val_FP: 26.6600 - val_FN: 47.7800\n",
      "Epoch 38/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0571 - Accuracy: 0.9806 - Precision: 0.9531 - Recall: 0.9434 - TP: 3181.0801 - TN: 5503.5801 - FP: 143.4200 - FN: 190.9200 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9406 - val_TP: 756.2300 - val_TN: 1079.2300 - val_FP: 26.7700 - val_FN: 47.7700\n",
      "Epoch 39/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0571 - Accuracy: 0.9806 - Precision: 0.9531 - Recall: 0.9434 - TP: 3181.0300 - TN: 5503.4902 - FP: 143.5100 - FN: 190.9700 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9405 - val_TP: 756.2000 - val_TN: 1079.4100 - val_FP: 26.5900 - val_FN: 47.8000\n",
      "Epoch 40/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0570 - Accuracy: 0.9806 - Precision: 0.9530 - Recall: 0.9434 - TP: 3181.2500 - TN: 5503.1099 - FP: 143.8900 - FN: 190.7500 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9406 - val_TP: 756.2300 - val_TN: 1079.3300 - val_FP: 26.6700 - val_FN: 47.7700\n",
      "Epoch 41/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0571 - Accuracy: 0.9806 - Precision: 0.9534 - Recall: 0.9433 - TP: 3180.7900 - TN: 5504.8398 - FP: 142.1600 - FN: 191.2100 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9406 - val_TP: 756.2300 - val_TN: 1079.2900 - val_FP: 26.7100 - val_FN: 47.7700\n",
      "Epoch 42/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0570 - Accuracy: 0.9806 - Precision: 0.9532 - Recall: 0.9434 - TP: 3181.1001 - TN: 5504.0200 - FP: 142.9800 - FN: 190.9000 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9599 - val_Recall: 0.9406 - val_TP: 756.2300 - val_TN: 1078.6801 - val_FP: 27.3200 - val_FN: 47.7700\n",
      "Epoch 43/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0571 - Accuracy: 0.9806 - Precision: 0.9532 - Recall: 0.9434 - TP: 3181.1101 - TN: 5503.8301 - FP: 143.1700 - FN: 190.8900 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9602 - val_Recall: 0.9406 - val_TP: 756.2500 - val_TN: 1079.1801 - val_FP: 26.8200 - val_FN: 47.7500\n",
      "Epoch 44/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0571 - Accuracy: 0.9806 - Precision: 0.9530 - Recall: 0.9435 - TP: 3181.3301 - TN: 5503.0200 - FP: 143.9800 - FN: 190.6700 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9406 - val_TP: 756.2400 - val_TN: 1079.2500 - val_FP: 26.7500 - val_FN: 47.7600\n",
      "Epoch 45/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0570 - Accuracy: 0.9807 - Precision: 0.9531 - Recall: 0.9435 - TP: 3181.3501 - TN: 5503.5098 - FP: 143.4900 - FN: 190.6500 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9406 - val_TP: 756.2300 - val_TN: 1079.3300 - val_FP: 26.6700 - val_FN: 47.7700\n",
      "Epoch 46/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0570 - Accuracy: 0.9806 - Precision: 0.9532 - Recall: 0.9434 - TP: 3181.2600 - TN: 5504.0298 - FP: 142.9700 - FN: 190.7400 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9406 - val_TP: 756.2500 - val_TN: 1079.2100 - val_FP: 26.7900 - val_FN: 47.7500\n",
      "Epoch 47/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0570 - Accuracy: 0.9806 - Precision: 0.9532 - Recall: 0.9434 - TP: 3181.2400 - TN: 5504.0200 - FP: 142.9800 - FN: 190.7600 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9405 - val_TP: 756.1900 - val_TN: 1079.3000 - val_FP: 26.7000 - val_FN: 47.8100\n",
      "Epoch 48/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0570 - Accuracy: 0.9807 - Precision: 0.9531 - Recall: 0.9435 - TP: 3181.4299 - TN: 5503.5298 - FP: 143.4700 - FN: 190.5700 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9406 - val_TP: 756.2400 - val_TN: 1079.2900 - val_FP: 26.7100 - val_FN: 47.7600\n",
      "Epoch 49/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0570 - Accuracy: 0.9806 - Precision: 0.9532 - Recall: 0.9434 - TP: 3181.3000 - TN: 5504.0498 - FP: 142.9500 - FN: 190.7000 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9406 - val_TP: 756.2600 - val_TN: 1079.2900 - val_FP: 26.7100 - val_FN: 47.7400\n",
      "Epoch 50/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0570 - Accuracy: 0.9806 - Precision: 0.9533 - Recall: 0.9435 - TP: 3181.3899 - TN: 5504.2402 - FP: 142.7600 - FN: 190.6100 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9406 - val_TP: 756.2600 - val_TN: 1079.3500 - val_FP: 26.6500 - val_FN: 47.7400\n",
      "Epoch 51/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0570 - Accuracy: 0.9806 - Precision: 0.9533 - Recall: 0.9434 - TP: 3181.2500 - TN: 5504.3198 - FP: 142.6800 - FN: 190.7500 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9406 - val_TP: 756.2400 - val_TN: 1079.2800 - val_FP: 26.7200 - val_FN: 47.7600\n",
      "Epoch 52/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0570 - Accuracy: 0.9806 - Precision: 0.9531 - Recall: 0.9435 - TP: 3181.5000 - TN: 5503.4199 - FP: 143.5800 - FN: 190.5000 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9406 - val_TP: 756.2400 - val_TN: 1079.3500 - val_FP: 26.6500 - val_FN: 47.7600\n",
      "Epoch 53/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0570 - Accuracy: 0.9806 - Precision: 0.9533 - Recall: 0.9434 - TP: 3181.2700 - TN: 5504.2798 - FP: 142.7200 - FN: 190.7300 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9406 - val_TP: 756.2400 - val_TN: 1079.2800 - val_FP: 26.7200 - val_FN: 47.7600\n",
      "Epoch 54/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0569 - Accuracy: 0.9806 - Precision: 0.9532 - Recall: 0.9435 - TP: 3181.5000 - TN: 5503.7500 - FP: 143.2500 - FN: 190.5000 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9406 - val_TP: 756.2200 - val_TN: 1079.3500 - val_FP: 26.6500 - val_FN: 47.7800\n",
      "Epoch 55/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0569 - Accuracy: 0.9807 - Precision: 0.9532 - Recall: 0.9435 - TP: 3181.3301 - TN: 5503.8999 - FP: 143.1000 - FN: 190.6700 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9406 - val_TP: 756.2200 - val_TN: 1079.3500 - val_FP: 26.6500 - val_FN: 47.7800\n",
      "Epoch 56/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0570 - Accuracy: 0.9806 - Precision: 0.9531 - Recall: 0.9435 - TP: 3181.5200 - TN: 5503.3999 - FP: 143.6000 - FN: 190.4800 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9406 - val_TP: 756.2400 - val_TN: 1079.3700 - val_FP: 26.6300 - val_FN: 47.7600\n",
      "Epoch 57/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0569 - Accuracy: 0.9807 - Precision: 0.9533 - Recall: 0.9435 - TP: 3181.5000 - TN: 5504.2998 - FP: 142.7000 - FN: 190.5000 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9406 - val_TP: 756.2200 - val_TN: 1079.4200 - val_FP: 26.5800 - val_FN: 47.7800\n",
      "Epoch 58/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0569 - Accuracy: 0.9807 - Precision: 0.9532 - Recall: 0.9435 - TP: 3181.6499 - TN: 5504.1001 - FP: 142.9000 - FN: 190.3500 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9406 - val_TP: 756.2300 - val_TN: 1079.3900 - val_FP: 26.6100 - val_FN: 47.7700\n",
      "Epoch 59/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0569 - Accuracy: 0.9808 - Precision: 0.9533 - Recall: 0.9435 - TP: 3181.4500 - TN: 5504.4800 - FP: 142.5200 - FN: 190.5500 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9406 - val_TP: 756.2400 - val_TN: 1079.3800 - val_FP: 26.6200 - val_FN: 47.7600\n",
      "Epoch 60/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0569 - Accuracy: 0.9808 - Precision: 0.9532 - Recall: 0.9435 - TP: 3181.6299 - TN: 5504.0698 - FP: 142.9300 - FN: 190.3700 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9406 - val_TP: 756.2300 - val_TN: 1079.3800 - val_FP: 26.6200 - val_FN: 47.7700\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 8ms/step - loss: 0.0569 - Accuracy: 0.9806 - Precision: 0.9537 - Recall: 0.9433 - TP: 3180.9600 - TN: 5506.1499 - FP: 140.8500 - FN: 191.0400 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9406 - val_TP: 756.2400 - val_TN: 1079.4800 - val_FP: 26.5200 - val_FN: 47.7600\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0569 - Accuracy: 0.9807 - Precision: 0.9532 - Recall: 0.9435 - TP: 3181.6499 - TN: 5503.8799 - FP: 143.1200 - FN: 190.3500 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9406 - val_TP: 756.2300 - val_TN: 1079.4301 - val_FP: 26.5700 - val_FN: 47.7700\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0568 - Accuracy: 0.9809 - Precision: 0.9534 - Recall: 0.9435 - TP: 3181.6001 - TN: 5504.7402 - FP: 142.2600 - FN: 190.4000 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9406 - val_TP: 756.2500 - val_TN: 1079.3500 - val_FP: 26.6500 - val_FN: 47.7500\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0569 - Accuracy: 0.9807 - Precision: 0.9533 - Recall: 0.9436 - TP: 3181.6899 - TN: 5504.6001 - FP: 142.4000 - FN: 190.3100 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9406 - val_TP: 756.2500 - val_TN: 1079.3900 - val_FP: 26.6100 - val_FN: 47.7500\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0568 - Accuracy: 0.9806 - Precision: 0.9534 - Recall: 0.9435 - TP: 3181.5300 - TN: 5504.6802 - FP: 142.3200 - FN: 190.4700 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9406 - val_TP: 756.2600 - val_TN: 1079.3600 - val_FP: 26.6400 - val_FN: 47.7400\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0568 - Accuracy: 0.9809 - Precision: 0.9531 - Recall: 0.9436 - TP: 3181.8601 - TN: 5503.4702 - FP: 143.5300 - FN: 190.1400 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9406 - val_TP: 756.2500 - val_TN: 1079.4399 - val_FP: 26.5600 - val_FN: 47.7500\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0568 - Accuracy: 0.9808 - Precision: 0.9534 - Recall: 0.9436 - TP: 3181.7200 - TN: 5504.7798 - FP: 142.2200 - FN: 190.2800 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9406 - val_TP: 756.2700 - val_TN: 1079.3600 - val_FP: 26.6400 - val_FN: 47.7300\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0568 - Accuracy: 0.9807 - Precision: 0.9532 - Recall: 0.9437 - TP: 3182.0000 - TN: 5503.7002 - FP: 143.3000 - FN: 190.0000 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9406 - val_TP: 756.2600 - val_TN: 1079.4700 - val_FP: 26.5300 - val_FN: 47.7400\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0568 - Accuracy: 0.9808 - Precision: 0.9535 - Recall: 0.9435 - TP: 3181.6001 - TN: 5505.2998 - FP: 141.7000 - FN: 190.4000 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9599 - val_Recall: 0.9407 - val_TP: 756.3300 - val_TN: 1078.7400 - val_FP: 27.2600 - val_FN: 47.6700\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0568 - Accuracy: 0.9808 - Precision: 0.9533 - Recall: 0.9436 - TP: 3181.8401 - TN: 5504.1001 - FP: 142.9000 - FN: 190.1600 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9406 - val_TP: 756.2700 - val_TN: 1079.4301 - val_FP: 26.5700 - val_FN: 47.7300\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0568 - Accuracy: 0.9808 - Precision: 0.9534 - Recall: 0.9436 - TP: 3181.8401 - TN: 5504.7500 - FP: 142.2500 - FN: 190.1600 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9406 - val_TP: 756.2800 - val_TN: 1079.4200 - val_FP: 26.5800 - val_FN: 47.7200\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0568 - Accuracy: 0.9809 - Precision: 0.9531 - Recall: 0.9437 - TP: 3182.2700 - TN: 5503.1299 - FP: 143.8700 - FN: 189.7300 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9406 - val_TP: 756.2700 - val_TN: 1079.4399 - val_FP: 26.5600 - val_FN: 47.7300\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0568 - Accuracy: 0.9808 - Precision: 0.9535 - Recall: 0.9435 - TP: 3181.5400 - TN: 5505.4102 - FP: 141.5900 - FN: 190.4600 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9407 - val_TP: 756.2900 - val_TN: 1079.3700 - val_FP: 26.6300 - val_FN: 47.7100\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0568 - Accuracy: 0.9808 - Precision: 0.9533 - Recall: 0.9436 - TP: 3181.9199 - TN: 5504.4399 - FP: 142.5600 - FN: 190.0800 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9406 - val_TP: 756.2800 - val_TN: 1079.4399 - val_FP: 26.5600 - val_FN: 47.7200\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0568 - Accuracy: 0.9809 - Precision: 0.9533 - Recall: 0.9437 - TP: 3182.2000 - TN: 5504.1499 - FP: 142.8500 - FN: 189.8000 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9407 - val_TP: 756.3000 - val_TN: 1079.3400 - val_FP: 26.6600 - val_FN: 47.7000\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0567 - Accuracy: 0.9808 - Precision: 0.9533 - Recall: 0.9437 - TP: 3182.0801 - TN: 5504.3501 - FP: 142.6500 - FN: 189.9200 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9407 - val_TP: 756.3100 - val_TN: 1079.3500 - val_FP: 26.6500 - val_FN: 47.6900\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0567 - Accuracy: 0.9808 - Precision: 0.9535 - Recall: 0.9436 - TP: 3181.8601 - TN: 5505.0898 - FP: 141.9100 - FN: 190.1400 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9407 - val_TP: 756.3200 - val_TN: 1079.3900 - val_FP: 26.6100 - val_FN: 47.6800\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0567 - Accuracy: 0.9809 - Precision: 0.9533 - Recall: 0.9436 - TP: 3181.9800 - TN: 5504.5098 - FP: 142.4900 - FN: 190.0200 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9606 - val_Recall: 0.9406 - val_TP: 756.2700 - val_TN: 1079.5200 - val_FP: 26.4800 - val_FN: 47.7300\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0567 - Accuracy: 0.9809 - Precision: 0.9533 - Recall: 0.9437 - TP: 3182.2000 - TN: 5504.3701 - FP: 142.6300 - FN: 189.8000 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9407 - val_TP: 756.3400 - val_TN: 1079.3700 - val_FP: 26.6300 - val_FN: 47.6600\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0567 - Accuracy: 0.9807 - Precision: 0.9535 - Recall: 0.9436 - TP: 3181.8201 - TN: 5505.5498 - FP: 141.4500 - FN: 190.1800 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9600 - val_Recall: 0.9407 - val_TP: 756.3100 - val_TN: 1078.7900 - val_FP: 27.2100 - val_FN: 47.6900\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0567 - Accuracy: 0.9808 - Precision: 0.9533 - Recall: 0.9437 - TP: 3182.1299 - TN: 5504.0601 - FP: 142.9400 - FN: 189.8700 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9600 - val_Recall: 0.9407 - val_TP: 756.3100 - val_TN: 1078.7800 - val_FP: 27.2200 - val_FN: 47.6900\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 7ms/step - loss: 0.0569 - Accuracy: 0.9806 - Precision: 0.9536 - Recall: 0.9434 - TP: 3181.2000 - TN: 5505.7998 - FP: 141.2000 - FN: 190.8000 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9406 - val_TP: 756.2500 - val_TN: 1079.4100 - val_FP: 26.5900 - val_FN: 47.7500\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0569 - Accuracy: 0.9807 - Precision: 0.9535 - Recall: 0.9435 - TP: 3181.5801 - TN: 5505.1899 - FP: 141.8100 - FN: 190.4200 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9406 - val_TP: 756.2800 - val_TN: 1079.3600 - val_FP: 26.6400 - val_FN: 47.7200\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0569 - Accuracy: 0.9808 - Precision: 0.9532 - Recall: 0.9436 - TP: 3181.9399 - TN: 5503.6201 - FP: 143.3800 - FN: 190.0600 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9606 - val_Recall: 0.9406 - val_TP: 756.2600 - val_TN: 1079.5400 - val_FP: 26.4600 - val_FN: 47.7400\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0569 - Accuracy: 0.9806 - Precision: 0.9534 - Recall: 0.9435 - TP: 3181.5300 - TN: 5504.9399 - FP: 142.0600 - FN: 190.4700 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9600 - val_Recall: 0.9407 - val_TP: 756.3000 - val_TN: 1078.7800 - val_FP: 27.2200 - val_FN: 47.7000\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0568 - Accuracy: 0.9808 - Precision: 0.9533 - Recall: 0.9436 - TP: 3181.8799 - TN: 5504.1499 - FP: 142.8500 - FN: 190.1200 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9406 - val_TP: 756.2800 - val_TN: 1079.3900 - val_FP: 26.6100 - val_FN: 47.7200\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0568 - Accuracy: 0.9808 - Precision: 0.9533 - Recall: 0.9435 - TP: 3181.6499 - TN: 5504.2500 - FP: 142.7500 - FN: 190.3500 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9600 - val_Recall: 0.9407 - val_TP: 756.2900 - val_TN: 1078.7900 - val_FP: 27.2100 - val_FN: 47.7100\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0568 - Accuracy: 0.9808 - Precision: 0.9531 - Recall: 0.9437 - TP: 3182.0901 - TN: 5503.4902 - FP: 143.5100 - FN: 189.9100 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9407 - val_TP: 756.3000 - val_TN: 1079.3600 - val_FP: 26.6400 - val_FN: 47.7000\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0568 - Accuracy: 0.9808 - Precision: 0.9534 - Recall: 0.9436 - TP: 3181.8101 - TN: 5504.6699 - FP: 142.3300 - FN: 190.1900 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9407 - val_TP: 756.3100 - val_TN: 1079.3700 - val_FP: 26.6300 - val_FN: 47.6900\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0568 - Accuracy: 0.9808 - Precision: 0.9531 - Recall: 0.9437 - TP: 3182.1899 - TN: 5503.4399 - FP: 143.5600 - FN: 189.8100 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9407 - val_TP: 756.3100 - val_TN: 1079.4200 - val_FP: 26.5800 - val_FN: 47.6900\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0568 - Accuracy: 0.9808 - Precision: 0.9535 - Recall: 0.9436 - TP: 3181.7300 - TN: 5505.2500 - FP: 141.7500 - FN: 190.2700 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9407 - val_TP: 756.3200 - val_TN: 1079.3300 - val_FP: 26.6700 - val_FN: 47.6800\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0568 - Accuracy: 0.9809 - Precision: 0.9531 - Recall: 0.9437 - TP: 3182.1299 - TN: 5503.4902 - FP: 143.5100 - FN: 189.8700 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9407 - val_TP: 756.3200 - val_TN: 1079.3500 - val_FP: 26.6500 - val_FN: 47.6800\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0568 - Accuracy: 0.9808 - Precision: 0.9533 - Recall: 0.9437 - TP: 3182.0500 - TN: 5504.5098 - FP: 142.4900 - FN: 189.9500 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9407 - val_TP: 756.3300 - val_TN: 1079.4200 - val_FP: 26.5800 - val_FN: 47.6700\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0568 - Accuracy: 0.9808 - Precision: 0.9533 - Recall: 0.9436 - TP: 3181.8501 - TN: 5504.2998 - FP: 142.7000 - FN: 190.1500 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9406 - val_TP: 756.2800 - val_TN: 1079.5000 - val_FP: 26.5000 - val_FN: 47.7200\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0567 - Accuracy: 0.9809 - Precision: 0.9534 - Recall: 0.9437 - TP: 3182.0300 - TN: 5504.6802 - FP: 142.3200 - FN: 189.9700 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9406 - val_TP: 756.2800 - val_TN: 1079.4500 - val_FP: 26.5500 - val_FN: 47.7200\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0567 - Accuracy: 0.9808 - Precision: 0.9534 - Recall: 0.9437 - TP: 3182.0200 - TN: 5505.0098 - FP: 141.9900 - FN: 189.9800 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9407 - val_TP: 756.3200 - val_TN: 1079.3500 - val_FP: 26.6500 - val_FN: 47.6800\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0568 - Accuracy: 0.9808 - Precision: 0.9533 - Recall: 0.9436 - TP: 3181.9500 - TN: 5504.2500 - FP: 142.7500 - FN: 190.0500 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9407 - val_TP: 756.3100 - val_TN: 1079.4800 - val_FP: 26.5200 - val_FN: 47.6900\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0567 - Accuracy: 0.9808 - Precision: 0.9534 - Recall: 0.9437 - TP: 3182.1101 - TN: 5504.9902 - FP: 142.0100 - FN: 189.8900 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9407 - val_TP: 756.3100 - val_TN: 1079.3400 - val_FP: 26.6600 - val_FN: 47.6900\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0567 - Accuracy: 0.9809 - Precision: 0.9531 - Recall: 0.9438 - TP: 3182.4700 - TN: 5503.4600 - FP: 143.5400 - FN: 189.5300 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9407 - val_TP: 756.3100 - val_TN: 1079.4900 - val_FP: 26.5100 - val_FN: 47.6900\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0567 - Accuracy: 0.9808 - Precision: 0.9536 - Recall: 0.9436 - TP: 3181.8101 - TN: 5505.6201 - FP: 141.3800 - FN: 190.1900 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9407 - val_TP: 756.3100 - val_TN: 1079.3199 - val_FP: 26.6800 - val_FN: 47.6900\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0567 - Accuracy: 0.9808 - Precision: 0.9533 - Recall: 0.9437 - TP: 3182.2500 - TN: 5504.2202 - FP: 142.7800 - FN: 189.7500 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9407 - val_TP: 756.3200 - val_TN: 1079.4600 - val_FP: 26.5400 - val_FN: 47.6800\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0567 - Accuracy: 0.9808 - Precision: 0.9534 - Recall: 0.9437 - TP: 3182.1299 - TN: 5505.1001 - FP: 141.9000 - FN: 189.8700 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9407 - val_TP: 756.3200 - val_TN: 1079.3600 - val_FP: 26.6400 - val_FN: 47.6800\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0567 - Accuracy: 0.9808 - Precision: 0.9535 - Recall: 0.9437 - TP: 3182.1399 - TN: 5505.4302 - FP: 141.5700 - FN: 189.8600 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9599 - val_Recall: 0.9407 - val_TP: 756.3500 - val_TN: 1078.7600 - val_FP: 27.2400 - val_FN: 47.6500\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0567 - Accuracy: 0.9809 - Precision: 0.9530 - Recall: 0.9438 - TP: 3182.4900 - TN: 5502.9302 - FP: 144.0700 - FN: 189.5100 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9407 - val_TP: 756.3300 - val_TN: 1079.3500 - val_FP: 26.6500 - val_FN: 47.6700\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 7ms/step - loss: 0.0569 - Accuracy: 0.9807 - Precision: 0.9536 - Recall: 0.9434 - TP: 3181.2500 - TN: 5505.9702 - FP: 141.0300 - FN: 190.7500 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9606 - val_Recall: 0.9406 - val_TP: 756.2500 - val_TN: 1079.5900 - val_FP: 26.4100 - val_FN: 47.7500\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0568 - Accuracy: 0.9808 - Precision: 0.9533 - Recall: 0.9435 - TP: 3181.6399 - TN: 5504.5000 - FP: 142.5000 - FN: 190.3600 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9406 - val_TP: 756.2800 - val_TN: 1079.4301 - val_FP: 26.5700 - val_FN: 47.7200\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0568 - Accuracy: 0.9809 - Precision: 0.9533 - Recall: 0.9436 - TP: 3181.7100 - TN: 5504.5200 - FP: 142.4800 - FN: 190.2900 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9406 - val_TP: 756.2800 - val_TN: 1079.4399 - val_FP: 26.5600 - val_FN: 47.7200\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0568 - Accuracy: 0.9806 - Precision: 0.9536 - Recall: 0.9435 - TP: 3181.4600 - TN: 5505.7100 - FP: 141.2900 - FN: 190.5400 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9407 - val_TP: 756.2900 - val_TN: 1079.4000 - val_FP: 26.6000 - val_FN: 47.7100\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0568 - Accuracy: 0.9809 - Precision: 0.9531 - Recall: 0.9437 - TP: 3182.1201 - TN: 5503.5098 - FP: 143.4900 - FN: 189.8800 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9407 - val_TP: 756.2900 - val_TN: 1079.3300 - val_FP: 26.6700 - val_FN: 47.7100\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0568 - Accuracy: 0.9807 - Precision: 0.9535 - Recall: 0.9435 - TP: 3181.6499 - TN: 5505.1802 - FP: 141.8200 - FN: 190.3500 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9406 - val_TP: 756.2800 - val_TN: 1079.3500 - val_FP: 26.6500 - val_FN: 47.7200\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0568 - Accuracy: 0.9808 - Precision: 0.9533 - Recall: 0.9436 - TP: 3181.9099 - TN: 5504.1899 - FP: 142.8100 - FN: 190.0900 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9406 - val_TP: 756.2700 - val_TN: 1079.4000 - val_FP: 26.6000 - val_FN: 47.7300\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0568 - Accuracy: 0.9808 - Precision: 0.9533 - Recall: 0.9436 - TP: 3181.8701 - TN: 5504.1201 - FP: 142.8800 - FN: 190.1300 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9407 - val_TP: 756.3300 - val_TN: 1079.3000 - val_FP: 26.7000 - val_FN: 47.6700\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0568 - Accuracy: 0.9809 - Precision: 0.9533 - Recall: 0.9437 - TP: 3182.1299 - TN: 5504.1802 - FP: 142.8200 - FN: 189.8700 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9407 - val_TP: 756.3000 - val_TN: 1079.4500 - val_FP: 26.5500 - val_FN: 47.7000\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0567 - Accuracy: 0.9808 - Precision: 0.9533 - Recall: 0.9437 - TP: 3182.0100 - TN: 5504.1802 - FP: 142.8200 - FN: 189.9900 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9407 - val_TP: 756.2900 - val_TN: 1079.3800 - val_FP: 26.6200 - val_FN: 47.7100\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0567 - Accuracy: 0.9809 - Precision: 0.9533 - Recall: 0.9437 - TP: 3182.2000 - TN: 5504.3999 - FP: 142.6000 - FN: 189.8000 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9407 - val_TP: 756.3000 - val_TN: 1079.4100 - val_FP: 26.5900 - val_FN: 47.7000\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0568 - Accuracy: 0.9808 - Precision: 0.9534 - Recall: 0.9437 - TP: 3182.0400 - TN: 5504.9702 - FP: 142.0300 - FN: 189.9600 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9407 - val_TP: 756.3500 - val_TN: 1079.3800 - val_FP: 26.6200 - val_FN: 47.6500\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0568 - Accuracy: 0.9809 - Precision: 0.9533 - Recall: 0.9437 - TP: 3182.2800 - TN: 5504.1001 - FP: 142.9000 - FN: 189.7200 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9407 - val_TP: 756.3200 - val_TN: 1079.4399 - val_FP: 26.5600 - val_FN: 47.6800\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0567 - Accuracy: 0.9808 - Precision: 0.9535 - Recall: 0.9436 - TP: 3181.8999 - TN: 5505.3398 - FP: 141.6600 - FN: 190.1000 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9407 - val_TP: 756.3100 - val_TN: 1079.3800 - val_FP: 26.6200 - val_FN: 47.6900\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0567 - Accuracy: 0.9809 - Precision: 0.9534 - Recall: 0.9437 - TP: 3182.1499 - TN: 5504.7202 - FP: 142.2800 - FN: 189.8500 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9407 - val_TP: 756.3000 - val_TN: 1079.4500 - val_FP: 26.5500 - val_FN: 47.7000\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0567 - Accuracy: 0.9808 - Precision: 0.9536 - Recall: 0.9436 - TP: 3181.9500 - TN: 5505.6401 - FP: 141.3600 - FN: 190.0500 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9407 - val_TP: 756.3500 - val_TN: 1079.4700 - val_FP: 26.5300 - val_FN: 47.6500\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0567 - Accuracy: 0.9809 - Precision: 0.9531 - Recall: 0.9438 - TP: 3182.4299 - TN: 5503.4502 - FP: 143.5500 - FN: 189.5700 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9407 - val_TP: 756.3400 - val_TN: 1079.3500 - val_FP: 26.6500 - val_FN: 47.6600\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0567 - Accuracy: 0.9809 - Precision: 0.9534 - Recall: 0.9438 - TP: 3182.3701 - TN: 5504.6802 - FP: 142.3200 - FN: 189.6300 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9407 - val_TP: 756.3300 - val_TN: 1079.4700 - val_FP: 26.5300 - val_FN: 47.6700\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0567 - Accuracy: 0.9809 - Precision: 0.9533 - Recall: 0.9438 - TP: 3182.3899 - TN: 5504.4199 - FP: 142.5800 - FN: 189.6100 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9407 - val_TP: 756.3300 - val_TN: 1079.4500 - val_FP: 26.5500 - val_FN: 47.6700\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0567 - Accuracy: 0.9809 - Precision: 0.9534 - Recall: 0.9438 - TP: 3182.3301 - TN: 5504.8599 - FP: 142.1400 - FN: 189.6700 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9407 - val_TP: 756.3300 - val_TN: 1079.4600 - val_FP: 26.5400 - val_FN: 47.6700\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0567 - Accuracy: 0.9809 - Precision: 0.9535 - Recall: 0.9437 - TP: 3182.0000 - TN: 5505.5200 - FP: 141.4800 - FN: 190.0000 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9600 - val_Recall: 0.9407 - val_TP: 756.3400 - val_TN: 1078.8000 - val_FP: 27.2000 - val_FN: 47.6600\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 7ms/step - loss: 0.0570 - Accuracy: 0.9806 - Precision: 0.9539 - Recall: 0.9433 - TP: 3180.8301 - TN: 5507.7700 - FP: 139.2300 - FN: 191.1700 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9606 - val_Recall: 0.9406 - val_TP: 756.2800 - val_TN: 1079.5200 - val_FP: 26.4800 - val_FN: 47.7200\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0569 - Accuracy: 0.9808 - Precision: 0.9535 - Recall: 0.9435 - TP: 3181.5300 - TN: 5505.5698 - FP: 141.4300 - FN: 190.4700 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9406 - val_TP: 756.2800 - val_TN: 1079.4000 - val_FP: 26.6000 - val_FN: 47.7200\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0568 - Accuracy: 0.9808 - Precision: 0.9534 - Recall: 0.9436 - TP: 3181.8000 - TN: 5504.7202 - FP: 142.2800 - FN: 190.2000 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9407 - val_TP: 756.3000 - val_TN: 1079.4399 - val_FP: 26.5600 - val_FN: 47.7000\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0568 - Accuracy: 0.9809 - Precision: 0.9533 - Recall: 0.9436 - TP: 3181.9399 - TN: 5504.3501 - FP: 142.6500 - FN: 190.0600 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9407 - val_TP: 756.3000 - val_TN: 1079.3199 - val_FP: 26.6800 - val_FN: 47.7000\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0568 - Accuracy: 0.9807 - Precision: 0.9533 - Recall: 0.9436 - TP: 3181.8301 - TN: 5504.5000 - FP: 142.5000 - FN: 190.1700 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9406 - val_TP: 756.2600 - val_TN: 1079.4900 - val_FP: 26.5100 - val_FN: 47.7400\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0568 - Accuracy: 0.9809 - Precision: 0.9533 - Recall: 0.9437 - TP: 3182.0300 - TN: 5504.0498 - FP: 142.9500 - FN: 189.9700 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9406 - val_TP: 756.2700 - val_TN: 1079.4600 - val_FP: 26.5400 - val_FN: 47.7300\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0568 - Accuracy: 0.9807 - Precision: 0.9536 - Recall: 0.9435 - TP: 3181.5100 - TN: 5505.8398 - FP: 141.1600 - FN: 190.4900 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9598 - val_Recall: 0.9407 - val_TP: 756.3000 - val_TN: 1078.6500 - val_FP: 27.3500 - val_FN: 47.7000\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0568 - Accuracy: 0.9809 - Precision: 0.9531 - Recall: 0.9437 - TP: 3182.2400 - TN: 5503.4399 - FP: 143.5600 - FN: 189.7600 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9407 - val_TP: 756.2900 - val_TN: 1079.4000 - val_FP: 26.6000 - val_FN: 47.7100\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0568 - Accuracy: 0.9808 - Precision: 0.9533 - Recall: 0.9437 - TP: 3182.1699 - TN: 5504.0601 - FP: 142.9400 - FN: 189.8300 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9600 - val_Recall: 0.9407 - val_TP: 756.3400 - val_TN: 1078.7900 - val_FP: 27.2100 - val_FN: 47.6600\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0567 - Accuracy: 0.9809 - Precision: 0.9533 - Recall: 0.9437 - TP: 3182.1201 - TN: 5504.4702 - FP: 142.5300 - FN: 189.8800 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9407 - val_TP: 756.3100 - val_TN: 1079.3500 - val_FP: 26.6500 - val_FN: 47.6900\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0568 - Accuracy: 0.9808 - Precision: 0.9533 - Recall: 0.9436 - TP: 3181.9700 - TN: 5504.4102 - FP: 142.5900 - FN: 190.0300 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9407 - val_TP: 756.2900 - val_TN: 1079.4600 - val_FP: 26.5400 - val_FN: 47.7100\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0567 - Accuracy: 0.9808 - Precision: 0.9533 - Recall: 0.9437 - TP: 3182.1101 - TN: 5504.3701 - FP: 142.6300 - FN: 189.8900 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9407 - val_TP: 756.3000 - val_TN: 1079.3900 - val_FP: 26.6100 - val_FN: 47.7000\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0567 - Accuracy: 0.9808 - Precision: 0.9535 - Recall: 0.9436 - TP: 3181.9099 - TN: 5505.0498 - FP: 141.9500 - FN: 190.0900 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9407 - val_TP: 756.3100 - val_TN: 1079.3500 - val_FP: 26.6500 - val_FN: 47.6900\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0567 - Accuracy: 0.9809 - Precision: 0.9533 - Recall: 0.9438 - TP: 3182.4500 - TN: 5504.3599 - FP: 142.6400 - FN: 189.5500 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9407 - val_TP: 756.3400 - val_TN: 1079.3800 - val_FP: 26.6200 - val_FN: 47.6600\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0567 - Accuracy: 0.9808 - Precision: 0.9534 - Recall: 0.9437 - TP: 3182.2200 - TN: 5504.9702 - FP: 142.0300 - FN: 189.7800 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9600 - val_Recall: 0.9407 - val_TP: 756.3400 - val_TN: 1078.8101 - val_FP: 27.1900 - val_FN: 47.6600\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0567 - Accuracy: 0.9809 - Precision: 0.9532 - Recall: 0.9438 - TP: 3182.5801 - TN: 5503.8701 - FP: 143.1300 - FN: 189.4200 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9407 - val_TP: 756.3000 - val_TN: 1079.4399 - val_FP: 26.5600 - val_FN: 47.7000\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0567 - Accuracy: 0.9809 - Precision: 0.9533 - Recall: 0.9438 - TP: 3182.3899 - TN: 5504.4800 - FP: 142.5200 - FN: 189.6100 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9606 - val_Recall: 0.9407 - val_TP: 756.3100 - val_TN: 1079.5699 - val_FP: 26.4300 - val_FN: 47.6900\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0567 - Accuracy: 0.9809 - Precision: 0.9535 - Recall: 0.9437 - TP: 3182.1399 - TN: 5505.5098 - FP: 141.4900 - FN: 189.8600 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9407 - val_TP: 756.3300 - val_TN: 1079.5000 - val_FP: 26.5000 - val_FN: 47.6700\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0567 - Accuracy: 0.9808 - Precision: 0.9532 - Recall: 0.9438 - TP: 3182.6299 - TN: 5503.6699 - FP: 143.3300 - FN: 189.3700 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9407 - val_TP: 756.3200 - val_TN: 1079.4000 - val_FP: 26.6000 - val_FN: 47.6800\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0566 - Accuracy: 0.9808 - Precision: 0.9533 - Recall: 0.9438 - TP: 3182.5100 - TN: 5504.3901 - FP: 142.6100 - FN: 189.4900 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9407 - val_TP: 756.3300 - val_TN: 1079.4800 - val_FP: 26.5200 - val_FN: 47.6700\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0566 - Accuracy: 0.9809 - Precision: 0.9532 - Recall: 0.9438 - TP: 3182.5701 - TN: 5503.8101 - FP: 143.1900 - FN: 189.4300 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9407 - val_TP: 756.3400 - val_TN: 1079.5000 - val_FP: 26.5000 - val_FN: 47.6600\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0566 - Accuracy: 0.9808 - Precision: 0.9536 - Recall: 0.9437 - TP: 3182.1899 - TN: 5505.6899 - FP: 141.3100 - FN: 189.8100 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9407 - val_TP: 756.3400 - val_TN: 1079.4200 - val_FP: 26.5800 - val_FN: 47.6600\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0566 - Accuracy: 0.9807 - Precision: 0.9535 - Recall: 0.9437 - TP: 3182.2900 - TN: 5505.0400 - FP: 141.9600 - FN: 189.7100 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9600 - val_Recall: 0.9407 - val_TP: 756.3600 - val_TN: 1078.8199 - val_FP: 27.1800 - val_FN: 47.6400\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0566 - Accuracy: 0.9809 - Precision: 0.9532 - Recall: 0.9438 - TP: 3182.6201 - TN: 5503.5000 - FP: 143.5000 - FN: 189.3800 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9606 - val_Recall: 0.9407 - val_TP: 756.3400 - val_TN: 1079.5400 - val_FP: 26.4600 - val_FN: 47.6600\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0566 - Accuracy: 0.9809 - Precision: 0.9535 - Recall: 0.9438 - TP: 3182.4700 - TN: 5505.1401 - FP: 141.8600 - FN: 189.5300 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9407 - val_TP: 756.3600 - val_TN: 1079.4900 - val_FP: 26.5100 - val_FN: 47.6400\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0566 - Accuracy: 0.9808 - Precision: 0.9535 - Recall: 0.9438 - TP: 3182.4199 - TN: 5505.5098 - FP: 141.4900 - FN: 189.5800 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9408 - val_TP: 756.3700 - val_TN: 1079.3700 - val_FP: 26.6300 - val_FN: 47.6300\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0566 - Accuracy: 0.9809 - Precision: 0.9533 - Recall: 0.9438 - TP: 3182.6399 - TN: 5504.2700 - FP: 142.7300 - FN: 189.3600 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9408 - val_TP: 756.3700 - val_TN: 1079.4900 - val_FP: 26.5100 - val_FN: 47.6300\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0566 - Accuracy: 0.9809 - Precision: 0.9535 - Recall: 0.9438 - TP: 3182.4399 - TN: 5505.3501 - FP: 141.6500 - FN: 189.5600 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9407 - val_TP: 756.3600 - val_TN: 1079.4000 - val_FP: 26.6000 - val_FN: 47.6400\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0565 - Accuracy: 0.9808 - Precision: 0.9533 - Recall: 0.9438 - TP: 3182.6101 - TN: 5504.0698 - FP: 142.9300 - FN: 189.3900 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9600 - val_Recall: 0.9407 - val_TP: 756.3600 - val_TN: 1078.8199 - val_FP: 27.1800 - val_FN: 47.6400\n",
      "Epoch 30/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0566 - Accuracy: 0.9809 - Precision: 0.9533 - Recall: 0.9439 - TP: 3182.7500 - TN: 5503.9702 - FP: 143.0300 - FN: 189.2500 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9408 - val_TP: 756.3800 - val_TN: 1079.4100 - val_FP: 26.5900 - val_FN: 47.6200\n",
      "Epoch 31/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0565 - Accuracy: 0.9808 - Precision: 0.9535 - Recall: 0.9438 - TP: 3182.6001 - TN: 5505.2900 - FP: 141.7100 - FN: 189.4000 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9408 - val_TP: 756.3800 - val_TN: 1079.4399 - val_FP: 26.5600 - val_FN: 47.6200\n",
      "Epoch 32/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0565 - Accuracy: 0.9809 - Precision: 0.9534 - Recall: 0.9439 - TP: 3182.7700 - TN: 5504.8398 - FP: 142.1600 - FN: 189.2300 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9606 - val_Recall: 0.9408 - val_TP: 756.3800 - val_TN: 1079.5400 - val_FP: 26.4600 - val_FN: 47.6200\n",
      "Epoch 33/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0565 - Accuracy: 0.9808 - Precision: 0.9535 - Recall: 0.9438 - TP: 3182.5200 - TN: 5505.1899 - FP: 141.8100 - FN: 189.4800 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9408 - val_TP: 756.4300 - val_TN: 1079.3600 - val_FP: 26.6400 - val_FN: 47.5700\n",
      "Epoch 34/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0565 - Accuracy: 0.9808 - Precision: 0.9534 - Recall: 0.9439 - TP: 3182.6799 - TN: 5504.7402 - FP: 142.2600 - FN: 189.3200 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9606 - val_Recall: 0.9408 - val_TP: 756.4000 - val_TN: 1079.5300 - val_FP: 26.4700 - val_FN: 47.6000\n",
      "Epoch 35/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0565 - Accuracy: 0.9809 - Precision: 0.9535 - Recall: 0.9438 - TP: 3182.6299 - TN: 5505.3901 - FP: 141.6100 - FN: 189.3700 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9408 - val_TP: 756.4100 - val_TN: 1079.4600 - val_FP: 26.5400 - val_FN: 47.5900\n",
      "Epoch 36/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0565 - Accuracy: 0.9809 - Precision: 0.9535 - Recall: 0.9439 - TP: 3182.8101 - TN: 5505.2798 - FP: 141.7200 - FN: 189.1900 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9606 - val_Recall: 0.9408 - val_TP: 756.4100 - val_TN: 1079.5699 - val_FP: 26.4300 - val_FN: 47.5900\n",
      "Epoch 37/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0565 - Accuracy: 0.9808 - Precision: 0.9535 - Recall: 0.9439 - TP: 3182.9099 - TN: 5505.0200 - FP: 141.9800 - FN: 189.0900 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9409 - val_TP: 756.4600 - val_TN: 1079.3400 - val_FP: 26.6600 - val_FN: 47.5400\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 8ms/step - loss: 0.0568 - Accuracy: 0.9808 - Precision: 0.9539 - Recall: 0.9435 - TP: 3181.5400 - TN: 5507.3799 - FP: 139.6200 - FN: 190.4600 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9606 - val_Recall: 0.9407 - val_TP: 756.3600 - val_TN: 1079.5200 - val_FP: 26.4800 - val_FN: 47.6400\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0566 - Accuracy: 0.9809 - Precision: 0.9536 - Recall: 0.9437 - TP: 3182.2500 - TN: 5505.7002 - FP: 141.3000 - FN: 189.7500 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9408 - val_TP: 756.4100 - val_TN: 1079.3700 - val_FP: 26.6300 - val_FN: 47.5900\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0566 - Accuracy: 0.9808 - Precision: 0.9533 - Recall: 0.9438 - TP: 3182.5400 - TN: 5504.2700 - FP: 142.7300 - FN: 189.4600 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9407 - val_TP: 756.3400 - val_TN: 1079.4200 - val_FP: 26.5800 - val_FN: 47.6600\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0566 - Accuracy: 0.9809 - Precision: 0.9534 - Recall: 0.9438 - TP: 3182.5300 - TN: 5504.8599 - FP: 142.1400 - FN: 189.4700 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9407 - val_TP: 756.3600 - val_TN: 1079.4500 - val_FP: 26.5500 - val_FN: 47.6400\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0566 - Accuracy: 0.9809 - Precision: 0.9533 - Recall: 0.9438 - TP: 3182.5901 - TN: 5504.2700 - FP: 142.7300 - FN: 189.4100 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9407 - val_TP: 756.3600 - val_TN: 1079.4600 - val_FP: 26.5400 - val_FN: 47.6400\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0566 - Accuracy: 0.9807 - Precision: 0.9536 - Recall: 0.9437 - TP: 3182.2100 - TN: 5505.9102 - FP: 141.0900 - FN: 189.7900 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9408 - val_TP: 756.3800 - val_TN: 1079.4700 - val_FP: 26.5300 - val_FN: 47.6200\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0566 - Accuracy: 0.9808 - Precision: 0.9534 - Recall: 0.9438 - TP: 3182.5601 - TN: 5504.5898 - FP: 142.4100 - FN: 189.4400 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9599 - val_Recall: 0.9408 - val_TP: 756.3800 - val_TN: 1078.7700 - val_FP: 27.2300 - val_FN: 47.6200\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0566 - Accuracy: 0.9809 - Precision: 0.9531 - Recall: 0.9439 - TP: 3182.8799 - TN: 5503.1401 - FP: 143.8600 - FN: 189.1200 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9408 - val_TP: 756.3700 - val_TN: 1079.4500 - val_FP: 26.5500 - val_FN: 47.6300\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0566 - Accuracy: 0.9809 - Precision: 0.9534 - Recall: 0.9439 - TP: 3182.6899 - TN: 5504.6699 - FP: 142.3300 - FN: 189.3100 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9606 - val_Recall: 0.9408 - val_TP: 756.3700 - val_TN: 1079.5200 - val_FP: 26.4800 - val_FN: 47.6300\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0566 - Accuracy: 0.9809 - Precision: 0.9535 - Recall: 0.9438 - TP: 3182.4700 - TN: 5505.2402 - FP: 141.7600 - FN: 189.5300 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9407 - val_TP: 756.3600 - val_TN: 1079.3700 - val_FP: 26.6300 - val_FN: 47.6400\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0566 - Accuracy: 0.9808 - Precision: 0.9535 - Recall: 0.9438 - TP: 3182.6399 - TN: 5505.2300 - FP: 141.7700 - FN: 189.3600 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9408 - val_TP: 756.3800 - val_TN: 1079.4000 - val_FP: 26.6000 - val_FN: 47.6200\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0566 - Accuracy: 0.9808 - Precision: 0.9535 - Recall: 0.9438 - TP: 3182.4299 - TN: 5505.2998 - FP: 141.7000 - FN: 189.5700 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9408 - val_TP: 756.4400 - val_TN: 1079.3700 - val_FP: 26.6300 - val_FN: 47.5600\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0565 - Accuracy: 0.9808 - Precision: 0.9535 - Recall: 0.9438 - TP: 3182.6201 - TN: 5505.2100 - FP: 141.7900 - FN: 189.3800 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9409 - val_TP: 756.4600 - val_TN: 1079.3300 - val_FP: 26.6700 - val_FN: 47.5400\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0565 - Accuracy: 0.9809 - Precision: 0.9535 - Recall: 0.9439 - TP: 3182.8201 - TN: 5505.3101 - FP: 141.6900 - FN: 189.1800 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9600 - val_Recall: 0.9409 - val_TP: 756.4500 - val_TN: 1078.8700 - val_FP: 27.1300 - val_FN: 47.5500\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0565 - Accuracy: 0.9808 - Precision: 0.9534 - Recall: 0.9439 - TP: 3182.7200 - TN: 5504.8599 - FP: 142.1400 - FN: 189.2800 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9599 - val_Recall: 0.9409 - val_TP: 756.4800 - val_TN: 1078.7400 - val_FP: 27.2600 - val_FN: 47.5200\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0565 - Accuracy: 0.9808 - Precision: 0.9534 - Recall: 0.9439 - TP: 3182.7700 - TN: 5504.6401 - FP: 142.3600 - FN: 189.2300 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9601 - val_Recall: 0.9408 - val_TP: 756.4400 - val_TN: 1078.8800 - val_FP: 27.1200 - val_FN: 47.5600\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0565 - Accuracy: 0.9809 - Precision: 0.9534 - Recall: 0.9439 - TP: 3182.7600 - TN: 5504.6401 - FP: 142.3600 - FN: 189.2400 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9600 - val_Recall: 0.9409 - val_TP: 756.4500 - val_TN: 1078.8400 - val_FP: 27.1600 - val_FN: 47.5500\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0565 - Accuracy: 0.9809 - Precision: 0.9534 - Recall: 0.9440 - TP: 3183.0300 - TN: 5504.4902 - FP: 142.5100 - FN: 188.9700 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9409 - val_TP: 756.4700 - val_TN: 1079.4200 - val_FP: 26.5800 - val_FN: 47.5300\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0565 - Accuracy: 0.9808 - Precision: 0.9535 - Recall: 0.9439 - TP: 3182.7800 - TN: 5505.4502 - FP: 141.5500 - FN: 189.2200 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9606 - val_Recall: 0.9409 - val_TP: 756.4500 - val_TN: 1079.5601 - val_FP: 26.4400 - val_FN: 47.5500\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0565 - Accuracy: 0.9809 - Precision: 0.9534 - Recall: 0.9439 - TP: 3182.7600 - TN: 5504.6201 - FP: 142.3800 - FN: 189.2400 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9408 - val_TP: 756.4400 - val_TN: 1079.4000 - val_FP: 26.6000 - val_FN: 47.5600\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0565 - Accuracy: 0.9809 - Precision: 0.9534 - Recall: 0.9439 - TP: 3182.9500 - TN: 5504.8999 - FP: 142.1000 - FN: 189.0500 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9606 - val_Recall: 0.9408 - val_TP: 756.4400 - val_TN: 1079.5601 - val_FP: 26.4400 - val_FN: 47.5600\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 8ms/step - loss: 0.0568 - Accuracy: 0.9808 - Precision: 0.9538 - Recall: 0.9436 - TP: 3181.7700 - TN: 5507.4199 - FP: 139.5800 - FN: 190.2300 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9408 - val_TP: 756.3900 - val_TN: 1079.4800 - val_FP: 26.5200 - val_FN: 47.6100\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0566 - Accuracy: 0.9808 - Precision: 0.9535 - Recall: 0.9438 - TP: 3182.4099 - TN: 5505.2002 - FP: 141.8000 - FN: 189.5900 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9408 - val_TP: 756.4400 - val_TN: 1079.3600 - val_FP: 26.6400 - val_FN: 47.5600\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0566 - Accuracy: 0.9809 - Precision: 0.9532 - Recall: 0.9439 - TP: 3182.7600 - TN: 5503.9902 - FP: 143.0100 - FN: 189.2400 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9408 - val_TP: 756.3900 - val_TN: 1079.4700 - val_FP: 26.5300 - val_FN: 47.6100\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0566 - Accuracy: 0.9808 - Precision: 0.9537 - Recall: 0.9437 - TP: 3182.2200 - TN: 5506.0898 - FP: 140.9100 - FN: 189.7800 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9600 - val_Recall: 0.9407 - val_TP: 756.3600 - val_TN: 1078.8500 - val_FP: 27.1500 - val_FN: 47.6400\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0566 - Accuracy: 0.9808 - Precision: 0.9532 - Recall: 0.9439 - TP: 3182.7200 - TN: 5503.5200 - FP: 143.4800 - FN: 189.2800 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9408 - val_TP: 756.3800 - val_TN: 1079.3700 - val_FP: 26.6300 - val_FN: 47.6200\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0566 - Accuracy: 0.9809 - Precision: 0.9534 - Recall: 0.9438 - TP: 3182.6399 - TN: 5504.8198 - FP: 142.1800 - FN: 189.3600 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9408 - val_TP: 756.4300 - val_TN: 1079.4100 - val_FP: 26.5900 - val_FN: 47.5700\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0566 - Accuracy: 0.9808 - Precision: 0.9533 - Recall: 0.9439 - TP: 3182.8401 - TN: 5504.1699 - FP: 142.8300 - FN: 189.1600 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9408 - val_TP: 756.4000 - val_TN: 1079.4200 - val_FP: 26.5800 - val_FN: 47.6000\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0566 - Accuracy: 0.9808 - Precision: 0.9535 - Recall: 0.9438 - TP: 3182.5901 - TN: 5505.3301 - FP: 141.6700 - FN: 189.4100 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9606 - val_Recall: 0.9408 - val_TP: 756.3700 - val_TN: 1079.5200 - val_FP: 26.4800 - val_FN: 47.6300\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0566 - Accuracy: 0.9808 - Precision: 0.9533 - Recall: 0.9438 - TP: 3182.6599 - TN: 5503.9902 - FP: 143.0100 - FN: 189.3400 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9408 - val_TP: 756.3900 - val_TN: 1079.4700 - val_FP: 26.5300 - val_FN: 47.6100\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0566 - Accuracy: 0.9808 - Precision: 0.9535 - Recall: 0.9438 - TP: 3182.3999 - TN: 5505.3501 - FP: 141.6500 - FN: 189.6000 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9408 - val_TP: 756.4000 - val_TN: 1079.3900 - val_FP: 26.6100 - val_FN: 47.6000\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0566 - Accuracy: 0.9808 - Precision: 0.9534 - Recall: 0.9439 - TP: 3182.7100 - TN: 5504.9702 - FP: 142.0300 - FN: 189.2900 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9409 - val_TP: 756.4500 - val_TN: 1079.3700 - val_FP: 26.6300 - val_FN: 47.5500\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0565 - Accuracy: 0.9808 - Precision: 0.9534 - Recall: 0.9439 - TP: 3182.7200 - TN: 5504.6201 - FP: 142.3800 - FN: 189.2800 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9408 - val_TP: 756.4300 - val_TN: 1079.4100 - val_FP: 26.5900 - val_FN: 47.5700\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0565 - Accuracy: 0.9808 - Precision: 0.9536 - Recall: 0.9438 - TP: 3182.5601 - TN: 5505.7798 - FP: 141.2200 - FN: 189.4400 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9409 - val_TP: 756.4600 - val_TN: 1079.3300 - val_FP: 26.6700 - val_FN: 47.5400\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0565 - Accuracy: 0.9809 - Precision: 0.9535 - Recall: 0.9438 - TP: 3182.5801 - TN: 5505.0801 - FP: 141.9200 - FN: 189.4200 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9409 - val_TP: 756.4500 - val_TN: 1079.3400 - val_FP: 26.6600 - val_FN: 47.5500\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0565 - Accuracy: 0.9808 - Precision: 0.9535 - Recall: 0.9439 - TP: 3182.8000 - TN: 5505.2002 - FP: 141.8000 - FN: 189.2000 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9409 - val_TP: 756.4600 - val_TN: 1079.3500 - val_FP: 26.6500 - val_FN: 47.5400\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0565 - Accuracy: 0.9808 - Precision: 0.9534 - Recall: 0.9439 - TP: 3182.8501 - TN: 5504.8701 - FP: 142.1300 - FN: 189.1500 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9600 - val_Recall: 0.9409 - val_TP: 756.4500 - val_TN: 1078.8600 - val_FP: 27.1400 - val_FN: 47.5500\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0565 - Accuracy: 0.9809 - Precision: 0.9534 - Recall: 0.9440 - TP: 3183.0000 - TN: 5504.4702 - FP: 142.5300 - FN: 189.0000 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9606 - val_Recall: 0.9409 - val_TP: 756.4600 - val_TN: 1079.5500 - val_FP: 26.4500 - val_FN: 47.5400\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0565 - Accuracy: 0.9807 - Precision: 0.9537 - Recall: 0.9438 - TP: 3182.5000 - TN: 5506.2100 - FP: 140.7900 - FN: 189.5000 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9606 - val_Recall: 0.9409 - val_TP: 756.4500 - val_TN: 1079.5601 - val_FP: 26.4400 - val_FN: 47.5500\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0565 - Accuracy: 0.9809 - Precision: 0.9533 - Recall: 0.9440 - TP: 3183.0701 - TN: 5504.2900 - FP: 142.7100 - FN: 188.9300 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9409 - val_TP: 756.4600 - val_TN: 1079.4600 - val_FP: 26.5400 - val_FN: 47.5400\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0564 - Accuracy: 0.9808 - Precision: 0.9535 - Recall: 0.9439 - TP: 3182.8899 - TN: 5505.4199 - FP: 141.5800 - FN: 189.1100 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9409 - val_TP: 756.4700 - val_TN: 1079.3600 - val_FP: 26.6400 - val_FN: 47.5300\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0564 - Accuracy: 0.9809 - Precision: 0.9534 - Recall: 0.9440 - TP: 3183.0901 - TN: 5504.7700 - FP: 142.2300 - FN: 188.9100 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9409 - val_TP: 756.4700 - val_TN: 1079.4301 - val_FP: 26.5700 - val_FN: 47.5300\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0564 - Accuracy: 0.9809 - Precision: 0.9537 - Recall: 0.9439 - TP: 3182.7600 - TN: 5506.0801 - FP: 140.9200 - FN: 189.2400 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9601 - val_Recall: 0.9409 - val_TP: 756.4900 - val_TN: 1078.8800 - val_FP: 27.1200 - val_FN: 47.5100\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0564 - Accuracy: 0.9808 - Precision: 0.9536 - Recall: 0.9439 - TP: 3182.9900 - TN: 5505.6201 - FP: 141.3800 - FN: 189.0100 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9600 - val_Recall: 0.9409 - val_TP: 756.5000 - val_TN: 1078.8101 - val_FP: 27.1900 - val_FN: 47.5000\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0565 - Accuracy: 0.9809 - Precision: 0.9532 - Recall: 0.9440 - TP: 3183.1899 - TN: 5503.2798 - FP: 143.7200 - FN: 188.8100 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9606 - val_Recall: 0.9409 - val_TP: 756.4500 - val_TN: 1079.5000 - val_FP: 26.5000 - val_FN: 47.5500\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0564 - Accuracy: 0.9809 - Precision: 0.9534 - Recall: 0.9440 - TP: 3183.2500 - TN: 5504.8599 - FP: 142.1400 - FN: 188.7500 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9408 - val_TP: 756.4400 - val_TN: 1079.6400 - val_FP: 26.3600 - val_FN: 47.5600\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0564 - Accuracy: 0.9809 - Precision: 0.9535 - Recall: 0.9439 - TP: 3182.9299 - TN: 5505.1602 - FP: 141.8400 - FN: 189.0700 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9409 - val_TP: 756.4600 - val_TN: 1079.6500 - val_FP: 26.3500 - val_FN: 47.5400\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0564 - Accuracy: 0.9808 - Precision: 0.9537 - Recall: 0.9439 - TP: 3182.8899 - TN: 5505.9600 - FP: 141.0400 - FN: 189.1100 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9409 - val_TP: 756.5000 - val_TN: 1079.4800 - val_FP: 26.5200 - val_FN: 47.5000\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0564 - Accuracy: 0.9808 - Precision: 0.9535 - Recall: 0.9440 - TP: 3183.1799 - TN: 5505.3301 - FP: 141.6700 - FN: 188.8200 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9409 - val_TP: 756.4700 - val_TN: 1079.4800 - val_FP: 26.5200 - val_FN: 47.5300\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0564 - Accuracy: 0.9808 - Precision: 0.9535 - Recall: 0.9440 - TP: 3183.2700 - TN: 5505.2202 - FP: 141.7800 - FN: 188.7300 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9601 - val_Recall: 0.9409 - val_TP: 756.4800 - val_TN: 1078.9500 - val_FP: 27.0500 - val_FN: 47.5200\n",
      "Epoch 30/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0564 - Accuracy: 0.9809 - Precision: 0.9535 - Recall: 0.9440 - TP: 3183.2400 - TN: 5505.1602 - FP: 141.8400 - FN: 188.7600 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9409 - val_TP: 756.4600 - val_TN: 1079.6100 - val_FP: 26.3900 - val_FN: 47.5400\n",
      "Epoch 31/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0563 - Accuracy: 0.9810 - Precision: 0.9536 - Recall: 0.9440 - TP: 3183.2300 - TN: 5505.5601 - FP: 141.4400 - FN: 188.7700 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9409 - val_TP: 756.5100 - val_TN: 1079.4600 - val_FP: 26.5400 - val_FN: 47.4900\n",
      "Epoch 32/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0563 - Accuracy: 0.9808 - Precision: 0.9536 - Recall: 0.9440 - TP: 3183.2300 - TN: 5505.9399 - FP: 141.0600 - FN: 188.7700 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9606 - val_Recall: 0.9409 - val_TP: 756.4800 - val_TN: 1079.5200 - val_FP: 26.4800 - val_FN: 47.5200\n",
      "Epoch 33/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0563 - Accuracy: 0.9810 - Precision: 0.9533 - Recall: 0.9441 - TP: 3183.6201 - TN: 5503.9902 - FP: 143.0100 - FN: 188.3800 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9409 - val_TP: 756.4900 - val_TN: 1079.6400 - val_FP: 26.3600 - val_FN: 47.5100\n",
      "Epoch 34/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0563 - Accuracy: 0.9810 - Precision: 0.9536 - Recall: 0.9440 - TP: 3183.3000 - TN: 5505.6201 - FP: 141.3800 - FN: 188.7000 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9410 - val_TP: 756.5500 - val_TN: 1079.4500 - val_FP: 26.5500 - val_FN: 47.4500\n",
      "Epoch 35/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0563 - Accuracy: 0.9810 - Precision: 0.9535 - Recall: 0.9441 - TP: 3183.5100 - TN: 5505.0698 - FP: 141.9300 - FN: 188.4900 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9409 - val_TP: 756.4900 - val_TN: 1079.6899 - val_FP: 26.3100 - val_FN: 47.5100\n",
      "Epoch 36/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0563 - Accuracy: 0.9809 - Precision: 0.9537 - Recall: 0.9440 - TP: 3183.2000 - TN: 5506.3101 - FP: 140.6900 - FN: 188.8000 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9409 - val_TP: 756.5100 - val_TN: 1079.5000 - val_FP: 26.5000 - val_FN: 47.4900\n",
      "Epoch 37/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0563 - Accuracy: 0.9813 - Precision: 0.9534 - Recall: 0.9442 - TP: 3183.7500 - TN: 5504.7100 - FP: 142.2900 - FN: 188.2500 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9606 - val_Recall: 0.9409 - val_TP: 756.5000 - val_TN: 1079.5300 - val_FP: 26.4700 - val_FN: 47.5000\n",
      "Epoch 38/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0562 - Accuracy: 0.9812 - Precision: 0.9536 - Recall: 0.9441 - TP: 3183.6499 - TN: 5505.4502 - FP: 141.5500 - FN: 188.3500 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9606 - val_Recall: 0.9409 - val_TP: 756.5000 - val_TN: 1079.5699 - val_FP: 26.4300 - val_FN: 47.5000\n",
      "Epoch 39/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0562 - Accuracy: 0.9809 - Precision: 0.9536 - Recall: 0.9441 - TP: 3183.4399 - TN: 5505.4902 - FP: 141.5100 - FN: 188.5600 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9409 - val_TP: 756.5000 - val_TN: 1079.6899 - val_FP: 26.3100 - val_FN: 47.5000\n",
      "Epoch 40/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0562 - Accuracy: 0.9812 - Precision: 0.9536 - Recall: 0.9441 - TP: 3183.5801 - TN: 5505.5098 - FP: 141.4900 - FN: 188.4200 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9409 - val_TP: 756.4900 - val_TN: 1079.6500 - val_FP: 26.3500 - val_FN: 47.5100\n",
      "Epoch 41/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0562 - Accuracy: 0.9810 - Precision: 0.9536 - Recall: 0.9441 - TP: 3183.4500 - TN: 5505.8599 - FP: 141.1400 - FN: 188.5500 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9606 - val_Recall: 0.9409 - val_TP: 756.5000 - val_TN: 1079.5601 - val_FP: 26.4400 - val_FN: 47.5000\n",
      "Epoch 42/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0562 - Accuracy: 0.9809 - Precision: 0.9536 - Recall: 0.9441 - TP: 3183.5901 - TN: 5505.8901 - FP: 141.1100 - FN: 188.4100 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9409 - val_TP: 756.5000 - val_TN: 1079.6500 - val_FP: 26.3500 - val_FN: 47.5000\n",
      "Epoch 43/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0562 - Accuracy: 0.9810 - Precision: 0.9536 - Recall: 0.9441 - TP: 3183.5400 - TN: 5505.7700 - FP: 141.2300 - FN: 188.4600 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9409 - val_TP: 756.5000 - val_TN: 1079.6400 - val_FP: 26.3600 - val_FN: 47.5000\n",
      "Epoch 44/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0562 - Accuracy: 0.9812 - Precision: 0.9536 - Recall: 0.9441 - TP: 3183.5000 - TN: 5505.7300 - FP: 141.2700 - FN: 188.5000 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9606 - val_Recall: 0.9409 - val_TP: 756.5000 - val_TN: 1079.6000 - val_FP: 26.4000 - val_FN: 47.5000\n",
      "Epoch 45/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0562 - Accuracy: 0.9813 - Precision: 0.9536 - Recall: 0.9441 - TP: 3183.6101 - TN: 5505.6802 - FP: 141.3200 - FN: 188.3900 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9409 - val_TP: 756.5000 - val_TN: 1079.6899 - val_FP: 26.3100 - val_FN: 47.5000\n",
      "Epoch 46/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0562 - Accuracy: 0.9813 - Precision: 0.9536 - Recall: 0.9442 - TP: 3183.7400 - TN: 5505.8701 - FP: 141.1300 - FN: 188.2600 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9606 - val_Recall: 0.9409 - val_TP: 756.5000 - val_TN: 1079.5900 - val_FP: 26.4100 - val_FN: 47.5000\n",
      "Epoch 47/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0561 - Accuracy: 0.9813 - Precision: 0.9536 - Recall: 0.9442 - TP: 3183.8701 - TN: 5505.3701 - FP: 141.6300 - FN: 188.1300 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9409 - val_TP: 756.5000 - val_TN: 1079.7100 - val_FP: 26.2900 - val_FN: 47.5000\n",
      "Epoch 48/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0562 - Accuracy: 0.9810 - Precision: 0.9538 - Recall: 0.9441 - TP: 3183.4800 - TN: 5506.6802 - FP: 140.3200 - FN: 188.5200 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9409 - val_TP: 756.5000 - val_TN: 1079.6700 - val_FP: 26.3300 - val_FN: 47.5000\n",
      "Epoch 49/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0561 - Accuracy: 0.9813 - Precision: 0.9538 - Recall: 0.9441 - TP: 3183.6101 - TN: 5506.4702 - FP: 140.5300 - FN: 188.3900 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9410 - val_TP: 756.5300 - val_TN: 1079.5100 - val_FP: 26.4900 - val_FN: 47.4700\n",
      "Epoch 50/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0561 - Accuracy: 0.9813 - Precision: 0.9535 - Recall: 0.9443 - TP: 3184.1101 - TN: 5504.7900 - FP: 142.2100 - FN: 187.8900 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9606 - val_Recall: 0.9409 - val_TP: 756.5200 - val_TN: 1079.5300 - val_FP: 26.4700 - val_FN: 47.4800\n",
      "Epoch 51/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0561 - Accuracy: 0.9813 - Precision: 0.9537 - Recall: 0.9442 - TP: 3183.8401 - TN: 5505.8301 - FP: 141.1700 - FN: 188.1600 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9409 - val_TP: 756.5100 - val_TN: 1079.7700 - val_FP: 26.2300 - val_FN: 47.4900\n",
      "Epoch 52/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0561 - Accuracy: 0.9812 - Precision: 0.9537 - Recall: 0.9442 - TP: 3183.8899 - TN: 5505.9199 - FP: 141.0800 - FN: 188.1100 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9410 - val_TP: 756.5300 - val_TN: 1079.7100 - val_FP: 26.2900 - val_FN: 47.4700\n",
      "Epoch 53/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0561 - Accuracy: 0.9813 - Precision: 0.9537 - Recall: 0.9442 - TP: 3183.8999 - TN: 5505.9199 - FP: 141.0800 - FN: 188.1000 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9410 - val_TP: 756.5300 - val_TN: 1079.7000 - val_FP: 26.3000 - val_FN: 47.4700\n",
      "Epoch 54/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0561 - Accuracy: 0.9812 - Precision: 0.9536 - Recall: 0.9442 - TP: 3183.8701 - TN: 5505.8101 - FP: 141.1900 - FN: 188.1300 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9410 - val_TP: 756.5400 - val_TN: 1079.6899 - val_FP: 26.3100 - val_FN: 47.4600\n",
      "Epoch 55/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0561 - Accuracy: 0.9813 - Precision: 0.9539 - Recall: 0.9441 - TP: 3183.6499 - TN: 5506.9702 - FP: 140.0300 - FN: 188.3500 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9410 - val_TP: 756.5600 - val_TN: 1079.5200 - val_FP: 26.4800 - val_FN: 47.4400\n",
      "Epoch 56/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0560 - Accuracy: 0.9812 - Precision: 0.9535 - Recall: 0.9443 - TP: 3184.2600 - TN: 5505.3101 - FP: 141.6900 - FN: 187.7400 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9410 - val_TP: 756.5400 - val_TN: 1079.6700 - val_FP: 26.3300 - val_FN: 47.4600\n",
      "Epoch 57/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0560 - Accuracy: 0.9812 - Precision: 0.9538 - Recall: 0.9442 - TP: 3184.0000 - TN: 5506.6699 - FP: 140.3300 - FN: 188.0000 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9410 - val_TP: 756.5400 - val_TN: 1079.6400 - val_FP: 26.3600 - val_FN: 47.4600\n",
      "Epoch 58/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0560 - Accuracy: 0.9813 - Precision: 0.9537 - Recall: 0.9443 - TP: 3184.1599 - TN: 5506.0298 - FP: 140.9700 - FN: 187.8400 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9410 - val_TP: 756.5300 - val_TN: 1079.6300 - val_FP: 26.3700 - val_FN: 47.4700\n",
      "Epoch 59/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0561 - Accuracy: 0.9813 - Precision: 0.9536 - Recall: 0.9442 - TP: 3183.9900 - TN: 5505.5898 - FP: 141.4100 - FN: 188.0100 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9410 - val_TP: 756.5400 - val_TN: 1079.6700 - val_FP: 26.3300 - val_FN: 47.4600\n",
      "Epoch 60/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0560 - Accuracy: 0.9813 - Precision: 0.9537 - Recall: 0.9443 - TP: 3184.0901 - TN: 5505.8501 - FP: 141.1500 - FN: 187.9100 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9606 - val_Recall: 0.9410 - val_TP: 756.5400 - val_TN: 1079.5800 - val_FP: 26.4200 - val_FN: 47.4600\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 5s 9ms/step - loss: 0.0561 - Accuracy: 0.9809 - Precision: 0.9539 - Recall: 0.9442 - TP: 3183.8301 - TN: 5507.0298 - FP: 139.9700 - FN: 188.1700 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9606 - val_Recall: 0.9410 - val_TP: 756.5500 - val_TN: 1079.6200 - val_FP: 26.3800 - val_FN: 47.4500\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 0.0560 - Accuracy: 0.9813 - Precision: 0.9537 - Recall: 0.9443 - TP: 3184.3201 - TN: 5505.9902 - FP: 141.0100 - FN: 187.6800 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9606 - val_Recall: 0.9410 - val_TP: 756.5700 - val_TN: 1079.5601 - val_FP: 26.4400 - val_FN: 47.4300\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0560 - Accuracy: 0.9813 - Precision: 0.9538 - Recall: 0.9443 - TP: 3184.2700 - TN: 5506.3398 - FP: 140.6600 - FN: 187.7300 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9410 - val_TP: 756.5700 - val_TN: 1079.6801 - val_FP: 26.3200 - val_FN: 47.4300\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0560 - Accuracy: 0.9812 - Precision: 0.9539 - Recall: 0.9443 - TP: 3184.0500 - TN: 5506.7700 - FP: 140.2300 - FN: 187.9500 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9601 - val_Recall: 0.9410 - val_TP: 756.5800 - val_TN: 1078.9700 - val_FP: 27.0300 - val_FN: 47.4200\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0560 - Accuracy: 0.9813 - Precision: 0.9536 - Recall: 0.9444 - TP: 3184.4199 - TN: 5505.5601 - FP: 141.4400 - FN: 187.5800 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9410 - val_TP: 756.5800 - val_TN: 1079.5200 - val_FP: 26.4800 - val_FN: 47.4200\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0559 - Accuracy: 0.9813 - Precision: 0.9538 - Recall: 0.9443 - TP: 3184.3101 - TN: 5506.3701 - FP: 140.6300 - FN: 187.6900 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9606 - val_Recall: 0.9410 - val_TP: 756.5800 - val_TN: 1079.5800 - val_FP: 26.4200 - val_FN: 47.4200\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0559 - Accuracy: 0.9813 - Precision: 0.9537 - Recall: 0.9444 - TP: 3184.3701 - TN: 5505.9800 - FP: 141.0200 - FN: 187.6300 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9410 - val_TP: 756.5700 - val_TN: 1079.6700 - val_FP: 26.3300 - val_FN: 47.4300\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0559 - Accuracy: 0.9813 - Precision: 0.9539 - Recall: 0.9443 - TP: 3184.2100 - TN: 5507.2002 - FP: 139.8000 - FN: 187.7900 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9410 - val_TP: 756.5700 - val_TN: 1079.6300 - val_FP: 26.3700 - val_FN: 47.4300\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0559 - Accuracy: 0.9813 - Precision: 0.9538 - Recall: 0.9443 - TP: 3184.3201 - TN: 5506.2100 - FP: 140.7900 - FN: 187.6800 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9410 - val_TP: 756.6000 - val_TN: 1079.6801 - val_FP: 26.3200 - val_FN: 47.4000\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0559 - Accuracy: 0.9813 - Precision: 0.9537 - Recall: 0.9443 - TP: 3184.3401 - TN: 5506.0400 - FP: 140.9600 - FN: 187.6600 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9410 - val_TP: 756.5800 - val_TN: 1079.7300 - val_FP: 26.2700 - val_FN: 47.4200\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0559 - Accuracy: 0.9812 - Precision: 0.9539 - Recall: 0.9443 - TP: 3184.3101 - TN: 5507.0098 - FP: 139.9900 - FN: 187.6900 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9410 - val_TP: 756.6000 - val_TN: 1079.6200 - val_FP: 26.3800 - val_FN: 47.4000\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0559 - Accuracy: 0.9813 - Precision: 0.9537 - Recall: 0.9444 - TP: 3184.5400 - TN: 5505.9902 - FP: 141.0100 - FN: 187.4600 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9602 - val_Recall: 0.9411 - val_TP: 756.6200 - val_TN: 1079.0000 - val_FP: 27.0000 - val_FN: 47.3800\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0559 - Accuracy: 0.9812 - Precision: 0.9538 - Recall: 0.9444 - TP: 3184.3799 - TN: 5506.2402 - FP: 140.7600 - FN: 187.6200 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9411 - val_TP: 756.6100 - val_TN: 1079.7900 - val_FP: 26.2100 - val_FN: 47.3900\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0559 - Accuracy: 0.9812 - Precision: 0.9538 - Recall: 0.9444 - TP: 3184.4399 - TN: 5506.6201 - FP: 140.3800 - FN: 187.5600 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9411 - val_TP: 756.6100 - val_TN: 1079.6801 - val_FP: 26.3200 - val_FN: 47.3900\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0559 - Accuracy: 0.9813 - Precision: 0.9537 - Recall: 0.9444 - TP: 3184.6599 - TN: 5505.9702 - FP: 141.0300 - FN: 187.3400 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9411 - val_TP: 756.6200 - val_TN: 1079.8700 - val_FP: 26.1300 - val_FN: 47.3800\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0558 - Accuracy: 0.9813 - Precision: 0.9539 - Recall: 0.9444 - TP: 3184.4299 - TN: 5507.0298 - FP: 139.9700 - FN: 187.5700 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9411 - val_TP: 756.6200 - val_TN: 1079.8300 - val_FP: 26.1700 - val_FN: 47.3800\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0558 - Accuracy: 0.9813 - Precision: 0.9538 - Recall: 0.9444 - TP: 3184.5300 - TN: 5506.5601 - FP: 140.4400 - FN: 187.4700 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9411 - val_TP: 756.6200 - val_TN: 1079.7100 - val_FP: 26.2900 - val_FN: 47.3800\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0558 - Accuracy: 0.9813 - Precision: 0.9537 - Recall: 0.9444 - TP: 3184.6399 - TN: 5506.0298 - FP: 140.9700 - FN: 187.3600 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9411 - val_TP: 756.6400 - val_TN: 1079.6801 - val_FP: 26.3200 - val_FN: 47.3600\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0558 - Accuracy: 0.9813 - Precision: 0.9537 - Recall: 0.9444 - TP: 3184.6799 - TN: 5505.9302 - FP: 141.0700 - FN: 187.3200 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9411 - val_TP: 756.6300 - val_TN: 1079.8300 - val_FP: 26.1700 - val_FN: 47.3700\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0558 - Accuracy: 0.9812 - Precision: 0.9540 - Recall: 0.9444 - TP: 3184.4199 - TN: 5507.3301 - FP: 139.6700 - FN: 187.5800 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9411 - val_TP: 756.6200 - val_TN: 1079.7300 - val_FP: 26.2700 - val_FN: 47.3800\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0558 - Accuracy: 0.9809 - Precision: 0.9536 - Recall: 0.9445 - TP: 3184.9500 - TN: 5505.5698 - FP: 141.4300 - FN: 187.0500 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9411 - val_TP: 756.6400 - val_TN: 1079.8199 - val_FP: 26.1800 - val_FN: 47.3600\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0558 - Accuracy: 0.9813 - Precision: 0.9539 - Recall: 0.9444 - TP: 3184.4399 - TN: 5506.8999 - FP: 140.1000 - FN: 187.5600 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9411 - val_TP: 756.6500 - val_TN: 1079.6500 - val_FP: 26.3500 - val_FN: 47.3500\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0558 - Accuracy: 0.9813 - Precision: 0.9537 - Recall: 0.9445 - TP: 3184.7300 - TN: 5506.0200 - FP: 140.9800 - FN: 187.2700 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9411 - val_TP: 756.6200 - val_TN: 1079.8500 - val_FP: 26.1500 - val_FN: 47.3800\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0557 - Accuracy: 0.9812 - Precision: 0.9541 - Recall: 0.9444 - TP: 3184.3501 - TN: 5508.0098 - FP: 138.9900 - FN: 187.6500 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9411 - val_TP: 756.6200 - val_TN: 1079.7600 - val_FP: 26.2400 - val_FN: 47.3800\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0558 - Accuracy: 0.9813 - Precision: 0.9537 - Recall: 0.9445 - TP: 3184.6899 - TN: 5506.0200 - FP: 140.9800 - FN: 187.3100 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9602 - val_Recall: 0.9411 - val_TP: 756.6800 - val_TN: 1079.0800 - val_FP: 26.9200 - val_FN: 47.3200\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0557 - Accuracy: 0.9813 - Precision: 0.9539 - Recall: 0.9444 - TP: 3184.5801 - TN: 5507.0801 - FP: 139.9200 - FN: 187.4200 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9411 - val_TP: 756.6400 - val_TN: 1079.7100 - val_FP: 26.2900 - val_FN: 47.3600\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0557 - Accuracy: 0.9813 - Precision: 0.9540 - Recall: 0.9444 - TP: 3184.6499 - TN: 5507.2500 - FP: 139.7500 - FN: 187.3500 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9411 - val_TP: 756.6700 - val_TN: 1079.2000 - val_FP: 26.8000 - val_FN: 47.3300\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0557 - Accuracy: 0.9813 - Precision: 0.9536 - Recall: 0.9446 - TP: 3185.1699 - TN: 5505.1899 - FP: 141.8100 - FN: 186.8300 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9411 - val_TP: 756.6700 - val_TN: 1079.8800 - val_FP: 26.1200 - val_FN: 47.3300\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0557 - Accuracy: 0.9813 - Precision: 0.9539 - Recall: 0.9445 - TP: 3184.8201 - TN: 5506.8799 - FP: 140.1200 - FN: 187.1800 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9411 - val_TP: 756.6700 - val_TN: 1079.8300 - val_FP: 26.1700 - val_FN: 47.3300\n",
      "Epoch 30/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0557 - Accuracy: 0.9813 - Precision: 0.9541 - Recall: 0.9444 - TP: 3184.4900 - TN: 5507.9800 - FP: 139.0200 - FN: 187.5100 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9411 - val_TP: 756.6800 - val_TN: 1079.6801 - val_FP: 26.3200 - val_FN: 47.3200\n",
      "Epoch 31/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0557 - Accuracy: 0.9812 - Precision: 0.9537 - Recall: 0.9446 - TP: 3185.0701 - TN: 5505.8101 - FP: 141.1900 - FN: 186.9300 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9411 - val_TP: 756.6800 - val_TN: 1079.6801 - val_FP: 26.3200 - val_FN: 47.3200\n",
      "Epoch 32/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0557 - Accuracy: 0.9810 - Precision: 0.9538 - Recall: 0.9446 - TP: 3185.2100 - TN: 5506.4800 - FP: 140.5200 - FN: 186.7900 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9411 - val_TP: 756.6700 - val_TN: 1079.8000 - val_FP: 26.2000 - val_FN: 47.3300\n",
      "Epoch 33/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0557 - Accuracy: 0.9812 - Precision: 0.9539 - Recall: 0.9445 - TP: 3184.8999 - TN: 5506.9702 - FP: 140.0300 - FN: 187.1000 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9412 - val_TP: 756.6900 - val_TN: 1079.6600 - val_FP: 26.3400 - val_FN: 47.3100\n",
      "Epoch 34/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0556 - Accuracy: 0.9813 - Precision: 0.9540 - Recall: 0.9445 - TP: 3184.9500 - TN: 5507.3701 - FP: 139.6300 - FN: 187.0500 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9412 - val_TP: 756.7000 - val_TN: 1079.7200 - val_FP: 26.2800 - val_FN: 47.3000\n",
      "Epoch 35/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0556 - Accuracy: 0.9813 - Precision: 0.9538 - Recall: 0.9446 - TP: 3185.0500 - TN: 5506.5098 - FP: 140.4900 - FN: 186.9500 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9411 - val_TP: 756.6800 - val_TN: 1079.7700 - val_FP: 26.2300 - val_FN: 47.3200\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 8ms/step - loss: 0.0562 - Accuracy: 0.9809 - Precision: 0.9546 - Recall: 0.9440 - TP: 3183.2200 - TN: 5511.2202 - FP: 135.7800 - FN: 188.7800 - val_loss: 0.0734 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9411 - val_TP: 756.6300 - val_TN: 1080.0800 - val_FP: 25.9200 - val_FN: 47.3700\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0558 - Accuracy: 0.9812 - Precision: 0.9541 - Recall: 0.9444 - TP: 3184.3899 - TN: 5507.8101 - FP: 139.1900 - FN: 187.6100 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9601 - val_Recall: 0.9412 - val_TP: 756.7000 - val_TN: 1078.9100 - val_FP: 27.0900 - val_FN: 47.3000\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0558 - Accuracy: 0.9812 - Precision: 0.9535 - Recall: 0.9446 - TP: 3185.0500 - TN: 5505.1899 - FP: 141.8100 - FN: 186.9500 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9411 - val_TP: 756.6800 - val_TN: 1079.6801 - val_FP: 26.3200 - val_FN: 47.3200\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0558 - Accuracy: 0.9809 - Precision: 0.9538 - Recall: 0.9444 - TP: 3184.6201 - TN: 5506.3398 - FP: 140.6600 - FN: 187.3800 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9606 - val_Recall: 0.9412 - val_TP: 756.6900 - val_TN: 1079.5800 - val_FP: 26.4200 - val_FN: 47.3100\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0558 - Accuracy: 0.9812 - Precision: 0.9538 - Recall: 0.9445 - TP: 3184.7900 - TN: 5506.6201 - FP: 140.3800 - FN: 187.2100 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9606 - val_Recall: 0.9411 - val_TP: 756.6700 - val_TN: 1079.6200 - val_FP: 26.3800 - val_FN: 47.3300\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0558 - Accuracy: 0.9813 - Precision: 0.9537 - Recall: 0.9445 - TP: 3184.9099 - TN: 5506.0200 - FP: 140.9800 - FN: 187.0900 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9411 - val_TP: 756.6500 - val_TN: 1079.6600 - val_FP: 26.3400 - val_FN: 47.3500\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0558 - Accuracy: 0.9813 - Precision: 0.9538 - Recall: 0.9445 - TP: 3184.6899 - TN: 5506.3599 - FP: 140.6400 - FN: 187.3100 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9606 - val_Recall: 0.9411 - val_TP: 756.6700 - val_TN: 1079.6000 - val_FP: 26.4000 - val_FN: 47.3300\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0558 - Accuracy: 0.9813 - Precision: 0.9539 - Recall: 0.9445 - TP: 3184.8601 - TN: 5506.7798 - FP: 140.2200 - FN: 187.1400 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9411 - val_TP: 756.6500 - val_TN: 1079.6600 - val_FP: 26.3400 - val_FN: 47.3500\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0558 - Accuracy: 0.9810 - Precision: 0.9536 - Recall: 0.9446 - TP: 3185.1599 - TN: 5505.6802 - FP: 141.3200 - FN: 186.8400 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9411 - val_TP: 756.6600 - val_TN: 1079.7700 - val_FP: 26.2300 - val_FN: 47.3400\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0557 - Accuracy: 0.9812 - Precision: 0.9539 - Recall: 0.9445 - TP: 3184.8799 - TN: 5506.7900 - FP: 140.2100 - FN: 187.1200 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9412 - val_TP: 756.6900 - val_TN: 1079.7900 - val_FP: 26.2100 - val_FN: 47.3100\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0557 - Accuracy: 0.9813 - Precision: 0.9539 - Recall: 0.9444 - TP: 3184.6799 - TN: 5507.1099 - FP: 139.8900 - FN: 187.3200 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9411 - val_TP: 756.6600 - val_TN: 1079.7900 - val_FP: 26.2100 - val_FN: 47.3400\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0557 - Accuracy: 0.9813 - Precision: 0.9539 - Recall: 0.9445 - TP: 3184.7700 - TN: 5506.7300 - FP: 140.2700 - FN: 187.2300 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9412 - val_TP: 756.6900 - val_TN: 1079.7200 - val_FP: 26.2800 - val_FN: 47.3100\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0557 - Accuracy: 0.9813 - Precision: 0.9539 - Recall: 0.9445 - TP: 3184.7100 - TN: 5506.7402 - FP: 140.2600 - FN: 187.2900 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9412 - val_TP: 756.6900 - val_TN: 1079.7800 - val_FP: 26.2200 - val_FN: 47.3100\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0557 - Accuracy: 0.9813 - Precision: 0.9539 - Recall: 0.9445 - TP: 3184.8701 - TN: 5507.0298 - FP: 139.9700 - FN: 187.1300 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9412 - val_TP: 756.6900 - val_TN: 1079.6801 - val_FP: 26.3200 - val_FN: 47.3100\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0557 - Accuracy: 0.9813 - Precision: 0.9538 - Recall: 0.9445 - TP: 3184.8701 - TN: 5506.3599 - FP: 140.6400 - FN: 187.1300 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9411 - val_TP: 756.6600 - val_TN: 1079.7700 - val_FP: 26.2300 - val_FN: 47.3400\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0557 - Accuracy: 0.9813 - Precision: 0.9538 - Recall: 0.9446 - TP: 3185.2100 - TN: 5506.2998 - FP: 140.7000 - FN: 186.7900 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9412 - val_TP: 756.7000 - val_TN: 1079.7600 - val_FP: 26.2400 - val_FN: 47.3000\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0557 - Accuracy: 0.9812 - Precision: 0.9539 - Recall: 0.9445 - TP: 3184.8799 - TN: 5506.8701 - FP: 140.1300 - FN: 187.1200 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9412 - val_TP: 756.6900 - val_TN: 1079.8800 - val_FP: 26.1200 - val_FN: 47.3100\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0556 - Accuracy: 0.9812 - Precision: 0.9539 - Recall: 0.9446 - TP: 3185.0801 - TN: 5506.8799 - FP: 140.1200 - FN: 186.9200 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9412 - val_TP: 756.7100 - val_TN: 1079.7000 - val_FP: 26.3000 - val_FN: 47.2900\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0556 - Accuracy: 0.9812 - Precision: 0.9538 - Recall: 0.9446 - TP: 3185.2900 - TN: 5506.3398 - FP: 140.6600 - FN: 186.7100 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9411 - val_TP: 756.6700 - val_TN: 1079.8600 - val_FP: 26.1400 - val_FN: 47.3300\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0556 - Accuracy: 0.9810 - Precision: 0.9541 - Recall: 0.9445 - TP: 3184.8601 - TN: 5507.7100 - FP: 139.2900 - FN: 187.1400 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9412 - val_TP: 756.6900 - val_TN: 1079.7900 - val_FP: 26.2100 - val_FN: 47.3100\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0556 - Accuracy: 0.9812 - Precision: 0.9539 - Recall: 0.9446 - TP: 3185.2200 - TN: 5507.1401 - FP: 139.8600 - FN: 186.7800 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9412 - val_TP: 756.6900 - val_TN: 1079.7800 - val_FP: 26.2200 - val_FN: 47.3100\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 9ms/step - loss: 0.0561 - Accuracy: 0.9809 - Precision: 0.9546 - Recall: 0.9441 - TP: 3183.6201 - TN: 5511.3901 - FP: 135.6100 - FN: 188.3800 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9412 - val_TP: 756.7300 - val_TN: 1079.5400 - val_FP: 26.4600 - val_FN: 47.2700\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0558 - Accuracy: 0.9813 - Precision: 0.9538 - Recall: 0.9445 - TP: 3184.8999 - TN: 5506.7500 - FP: 140.2500 - FN: 187.1000 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9412 - val_TP: 756.7500 - val_TN: 1079.4100 - val_FP: 26.5900 - val_FN: 47.2500\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0558 - Accuracy: 0.9810 - Precision: 0.9535 - Recall: 0.9446 - TP: 3185.1499 - TN: 5505.2798 - FP: 141.7200 - FN: 186.8500 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9412 - val_TP: 756.7000 - val_TN: 1079.7200 - val_FP: 26.2800 - val_FN: 47.3000\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0558 - Accuracy: 0.9812 - Precision: 0.9537 - Recall: 0.9445 - TP: 3184.8201 - TN: 5505.8999 - FP: 141.1000 - FN: 187.1800 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9411 - val_TP: 756.6800 - val_TN: 1079.7800 - val_FP: 26.2200 - val_FN: 47.3200\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0558 - Accuracy: 0.9813 - Precision: 0.9538 - Recall: 0.9445 - TP: 3184.8301 - TN: 5506.5200 - FP: 140.4800 - FN: 187.1700 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9412 - val_TP: 756.7000 - val_TN: 1079.7500 - val_FP: 26.2500 - val_FN: 47.3000\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0558 - Accuracy: 0.9813 - Precision: 0.9538 - Recall: 0.9444 - TP: 3184.6799 - TN: 5506.6099 - FP: 140.3900 - FN: 187.3200 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9411 - val_TP: 756.6700 - val_TN: 1079.7500 - val_FP: 26.2500 - val_FN: 47.3300\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0558 - Accuracy: 0.9810 - Precision: 0.9536 - Recall: 0.9445 - TP: 3185.0100 - TN: 5505.7002 - FP: 141.3000 - FN: 186.9900 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9411 - val_TP: 756.6800 - val_TN: 1079.6600 - val_FP: 26.3400 - val_FN: 47.3200\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0558 - Accuracy: 0.9813 - Precision: 0.9539 - Recall: 0.9445 - TP: 3184.7200 - TN: 5506.6899 - FP: 140.3100 - FN: 187.2800 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9411 - val_TP: 756.6800 - val_TN: 1079.7200 - val_FP: 26.2800 - val_FN: 47.3200\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0557 - Accuracy: 0.9812 - Precision: 0.9540 - Recall: 0.9444 - TP: 3184.6499 - TN: 5507.6099 - FP: 139.3900 - FN: 187.3500 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9602 - val_Recall: 0.9412 - val_TP: 756.7500 - val_TN: 1079.0400 - val_FP: 26.9600 - val_FN: 47.2500\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0557 - Accuracy: 0.9813 - Precision: 0.9538 - Recall: 0.9445 - TP: 3184.9399 - TN: 5506.2002 - FP: 140.8000 - FN: 187.0600 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9412 - val_TP: 756.7000 - val_TN: 1079.6600 - val_FP: 26.3400 - val_FN: 47.3000\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0557 - Accuracy: 0.9812 - Precision: 0.9536 - Recall: 0.9445 - TP: 3185.0200 - TN: 5505.5498 - FP: 141.4500 - FN: 186.9800 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9412 - val_TP: 756.6900 - val_TN: 1079.8500 - val_FP: 26.1500 - val_FN: 47.3100\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0557 - Accuracy: 0.9813 - Precision: 0.9539 - Recall: 0.9445 - TP: 3184.9900 - TN: 5506.8198 - FP: 140.1800 - FN: 187.0100 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9412 - val_TP: 756.6900 - val_TN: 1079.7400 - val_FP: 26.2600 - val_FN: 47.3100\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0557 - Accuracy: 0.9812 - Precision: 0.9538 - Recall: 0.9445 - TP: 3184.9299 - TN: 5506.6001 - FP: 140.4000 - FN: 187.0700 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9412 - val_TP: 756.6900 - val_TN: 1079.8101 - val_FP: 26.1900 - val_FN: 47.3100\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0557 - Accuracy: 0.9810 - Precision: 0.9540 - Recall: 0.9445 - TP: 3184.8101 - TN: 5507.4502 - FP: 139.5500 - FN: 187.1900 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9412 - val_TP: 756.6900 - val_TN: 1079.7400 - val_FP: 26.2600 - val_FN: 47.3100\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0557 - Accuracy: 0.9812 - Precision: 0.9539 - Recall: 0.9446 - TP: 3185.0601 - TN: 5506.7598 - FP: 140.2400 - FN: 186.9400 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9412 - val_TP: 756.6900 - val_TN: 1079.7800 - val_FP: 26.2200 - val_FN: 47.3100\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0557 - Accuracy: 0.9812 - Precision: 0.9539 - Recall: 0.9446 - TP: 3185.1101 - TN: 5506.8398 - FP: 140.1600 - FN: 186.8900 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9412 - val_TP: 756.6900 - val_TN: 1079.8101 - val_FP: 26.1900 - val_FN: 47.3100\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0556 - Accuracy: 0.9810 - Precision: 0.9539 - Recall: 0.9446 - TP: 3185.0701 - TN: 5506.9199 - FP: 140.0800 - FN: 186.9300 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9412 - val_TP: 756.7200 - val_TN: 1079.7300 - val_FP: 26.2700 - val_FN: 47.2800\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0556 - Accuracy: 0.9812 - Precision: 0.9538 - Recall: 0.9446 - TP: 3185.2500 - TN: 5506.5400 - FP: 140.4600 - FN: 186.7500 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9412 - val_TP: 756.6900 - val_TN: 1079.8500 - val_FP: 26.1500 - val_FN: 47.3100\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0556 - Accuracy: 0.9812 - Precision: 0.9538 - Recall: 0.9446 - TP: 3185.1399 - TN: 5506.3999 - FP: 140.6000 - FN: 186.8600 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9412 - val_TP: 756.7000 - val_TN: 1079.8400 - val_FP: 26.1600 - val_FN: 47.3000\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0556 - Accuracy: 0.9813 - Precision: 0.9540 - Recall: 0.9446 - TP: 3185.0500 - TN: 5507.1602 - FP: 139.8400 - FN: 186.9500 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9411 - val_TP: 756.6800 - val_TN: 1079.9000 - val_FP: 26.1000 - val_FN: 47.3200\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0556 - Accuracy: 0.9810 - Precision: 0.9539 - Recall: 0.9446 - TP: 3185.2000 - TN: 5506.7202 - FP: 140.2800 - FN: 186.8000 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9411 - val_TP: 756.6800 - val_TN: 1079.8700 - val_FP: 26.1300 - val_FN: 47.3200\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0556 - Accuracy: 0.9812 - Precision: 0.9540 - Recall: 0.9446 - TP: 3185.1699 - TN: 5507.2500 - FP: 139.7500 - FN: 186.8300 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9412 - val_TP: 756.7100 - val_TN: 1079.6899 - val_FP: 26.3100 - val_FN: 47.2900\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0555 - Accuracy: 0.9813 - Precision: 0.9540 - Recall: 0.9446 - TP: 3185.2100 - TN: 5507.4102 - FP: 139.5900 - FN: 186.7900 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9412 - val_TP: 756.7000 - val_TN: 1079.6700 - val_FP: 26.3300 - val_FN: 47.3000\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0556 - Accuracy: 0.9813 - Precision: 0.9540 - Recall: 0.9446 - TP: 3185.1399 - TN: 5507.1802 - FP: 139.8200 - FN: 186.8600 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9412 - val_TP: 756.6900 - val_TN: 1079.7800 - val_FP: 26.2200 - val_FN: 47.3100\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0556 - Accuracy: 0.9810 - Precision: 0.9538 - Recall: 0.9447 - TP: 3185.4500 - TN: 5506.5098 - FP: 140.4900 - FN: 186.5500 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9412 - val_TP: 756.7100 - val_TN: 1079.8000 - val_FP: 26.2000 - val_FN: 47.2900\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0555 - Accuracy: 0.9812 - Precision: 0.9541 - Recall: 0.9446 - TP: 3185.1499 - TN: 5507.5698 - FP: 139.4300 - FN: 186.8500 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9412 - val_TP: 756.6900 - val_TN: 1079.9500 - val_FP: 26.0500 - val_FN: 47.3100\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0555 - Accuracy: 0.9813 - Precision: 0.9541 - Recall: 0.9446 - TP: 3185.1399 - TN: 5507.6699 - FP: 139.3300 - FN: 186.8600 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9412 - val_TP: 756.7300 - val_TN: 1079.7800 - val_FP: 26.2200 - val_FN: 47.2700\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0555 - Accuracy: 0.9812 - Precision: 0.9541 - Recall: 0.9446 - TP: 3185.2300 - TN: 5507.6802 - FP: 139.3200 - FN: 186.7700 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9412 - val_TP: 756.7100 - val_TN: 1079.6801 - val_FP: 26.3200 - val_FN: 47.2900\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0555 - Accuracy: 0.9812 - Precision: 0.9538 - Recall: 0.9446 - TP: 3185.3101 - TN: 5506.2500 - FP: 140.7500 - FN: 186.6900 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9412 - val_TP: 756.7100 - val_TN: 1079.9100 - val_FP: 26.0900 - val_FN: 47.2900\n",
      "Epoch 30/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0555 - Accuracy: 0.9812 - Precision: 0.9541 - Recall: 0.9446 - TP: 3185.1499 - TN: 5507.6099 - FP: 139.3900 - FN: 186.8500 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9412 - val_TP: 756.7100 - val_TN: 1079.8800 - val_FP: 26.1200 - val_FN: 47.2900\n",
      "Epoch 31/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0555 - Accuracy: 0.9812 - Precision: 0.9540 - Recall: 0.9446 - TP: 3185.3101 - TN: 5507.4102 - FP: 139.5900 - FN: 186.6900 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9412 - val_TP: 756.7100 - val_TN: 1079.9100 - val_FP: 26.0900 - val_FN: 47.2900\n",
      "Epoch 32/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0555 - Accuracy: 0.9812 - Precision: 0.9540 - Recall: 0.9447 - TP: 3185.3701 - TN: 5507.0601 - FP: 139.9400 - FN: 186.6300 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9412 - val_TP: 756.7500 - val_TN: 1079.7300 - val_FP: 26.2700 - val_FN: 47.2500\n",
      "Epoch 33/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0554 - Accuracy: 0.9812 - Precision: 0.9540 - Recall: 0.9447 - TP: 3185.4700 - TN: 5507.5000 - FP: 139.5000 - FN: 186.5300 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9412 - val_TP: 756.7500 - val_TN: 1079.7700 - val_FP: 26.2300 - val_FN: 47.2500\n",
      "Epoch 34/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0554 - Accuracy: 0.9812 - Precision: 0.9541 - Recall: 0.9446 - TP: 3185.3201 - TN: 5507.7798 - FP: 139.2200 - FN: 186.6800 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9413 - val_TP: 756.7700 - val_TN: 1079.7300 - val_FP: 26.2700 - val_FN: 47.2300\n",
      "Epoch 35/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0555 - Accuracy: 0.9812 - Precision: 0.9539 - Recall: 0.9447 - TP: 3185.4600 - TN: 5506.6899 - FP: 140.3100 - FN: 186.5400 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9413 - val_TP: 756.7800 - val_TN: 1079.7600 - val_FP: 26.2400 - val_FN: 47.2200\n",
      "Epoch 36/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0554 - Accuracy: 0.9813 - Precision: 0.9541 - Recall: 0.9447 - TP: 3185.4800 - TN: 5507.6099 - FP: 139.3900 - FN: 186.5200 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9413 - val_TP: 756.7800 - val_TN: 1079.7500 - val_FP: 26.2500 - val_FN: 47.2200\n",
      "Epoch 37/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0554 - Accuracy: 0.9814 - Precision: 0.9541 - Recall: 0.9447 - TP: 3185.5000 - TN: 5507.8901 - FP: 139.1100 - FN: 186.5000 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9412 - val_TP: 756.7500 - val_TN: 1079.7900 - val_FP: 26.2100 - val_FN: 47.2500\n",
      "Epoch 38/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0554 - Accuracy: 0.9812 - Precision: 0.9540 - Recall: 0.9447 - TP: 3185.5801 - TN: 5507.2300 - FP: 139.7700 - FN: 186.4200 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9413 - val_TP: 756.7900 - val_TN: 1079.8199 - val_FP: 26.1800 - val_FN: 47.2100\n",
      "Epoch 39/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0554 - Accuracy: 0.9812 - Precision: 0.9541 - Recall: 0.9447 - TP: 3185.3701 - TN: 5507.6401 - FP: 139.3600 - FN: 186.6300 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9413 - val_TP: 756.7900 - val_TN: 1079.6700 - val_FP: 26.3300 - val_FN: 47.2100\n",
      "Epoch 40/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0554 - Accuracy: 0.9812 - Precision: 0.9540 - Recall: 0.9447 - TP: 3185.5100 - TN: 5507.3101 - FP: 139.6900 - FN: 186.4900 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9413 - val_TP: 756.7800 - val_TN: 1079.7600 - val_FP: 26.2400 - val_FN: 47.2200\n",
      "Epoch 41/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0554 - Accuracy: 0.9812 - Precision: 0.9540 - Recall: 0.9448 - TP: 3185.8000 - TN: 5507.1602 - FP: 139.8400 - FN: 186.2000 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9413 - val_TP: 756.8000 - val_TN: 1079.7600 - val_FP: 26.2400 - val_FN: 47.2000\n",
      "Epoch 42/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0553 - Accuracy: 0.9813 - Precision: 0.9541 - Recall: 0.9447 - TP: 3185.5801 - TN: 5507.9502 - FP: 139.0500 - FN: 186.4200 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9413 - val_TP: 756.8100 - val_TN: 1079.1700 - val_FP: 26.8300 - val_FN: 47.1900\n",
      "Epoch 43/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0553 - Accuracy: 0.9813 - Precision: 0.9539 - Recall: 0.9448 - TP: 3185.8999 - TN: 5506.7598 - FP: 140.2400 - FN: 186.1000 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9413 - val_TP: 756.7800 - val_TN: 1079.8700 - val_FP: 26.1300 - val_FN: 47.2200\n",
      "Epoch 44/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0553 - Accuracy: 0.9812 - Precision: 0.9542 - Recall: 0.9447 - TP: 3185.5300 - TN: 5508.3501 - FP: 138.6500 - FN: 186.4700 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9413 - val_TP: 756.7800 - val_TN: 1079.8000 - val_FP: 26.2000 - val_FN: 47.2200\n",
      "Epoch 45/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0553 - Accuracy: 0.9813 - Precision: 0.9540 - Recall: 0.9448 - TP: 3185.7200 - TN: 5506.9800 - FP: 140.0200 - FN: 186.2800 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9412 - val_TP: 756.7600 - val_TN: 1079.9000 - val_FP: 26.1000 - val_FN: 47.2400\n",
      "Epoch 46/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0554 - Accuracy: 0.9813 - Precision: 0.9541 - Recall: 0.9448 - TP: 3185.7800 - TN: 5507.5000 - FP: 139.5000 - FN: 186.2200 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9413 - val_TP: 756.7900 - val_TN: 1079.9600 - val_FP: 26.0400 - val_FN: 47.2100\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 8ms/step - loss: 0.0556 - Accuracy: 0.9809 - Precision: 0.9547 - Recall: 0.9444 - TP: 3184.6799 - TN: 5511.4800 - FP: 135.5200 - FN: 187.3200 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9602 - val_Recall: 0.9412 - val_TP: 756.7500 - val_TN: 1079.1100 - val_FP: 26.8900 - val_FN: 47.2500\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0555 - Accuracy: 0.9810 - Precision: 0.9538 - Recall: 0.9447 - TP: 3185.6001 - TN: 5506.3901 - FP: 140.6100 - FN: 186.4000 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9412 - val_TP: 756.7200 - val_TN: 1079.8300 - val_FP: 26.1700 - val_FN: 47.2800\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0555 - Accuracy: 0.9812 - Precision: 0.9538 - Recall: 0.9447 - TP: 3185.5000 - TN: 5506.2598 - FP: 140.7400 - FN: 186.5000 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9412 - val_TP: 756.7000 - val_TN: 1079.9301 - val_FP: 26.0700 - val_FN: 47.3000\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0555 - Accuracy: 0.9812 - Precision: 0.9542 - Recall: 0.9446 - TP: 3185.1399 - TN: 5508.4102 - FP: 138.5900 - FN: 186.8600 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9412 - val_TP: 756.7100 - val_TN: 1079.8199 - val_FP: 26.1800 - val_FN: 47.2900\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0555 - Accuracy: 0.9812 - Precision: 0.9539 - Recall: 0.9447 - TP: 3185.4800 - TN: 5506.8999 - FP: 140.1000 - FN: 186.5200 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9412 - val_TP: 756.7200 - val_TN: 1079.9200 - val_FP: 26.0800 - val_FN: 47.2800\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0555 - Accuracy: 0.9812 - Precision: 0.9539 - Recall: 0.9447 - TP: 3185.4199 - TN: 5506.8198 - FP: 140.1800 - FN: 186.5800 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9412 - val_TP: 756.7200 - val_TN: 1079.9100 - val_FP: 26.0900 - val_FN: 47.2800\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0554 - Accuracy: 0.9812 - Precision: 0.9541 - Recall: 0.9447 - TP: 3185.4199 - TN: 5507.7798 - FP: 139.2200 - FN: 186.5800 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9413 - val_TP: 756.7800 - val_TN: 1079.7300 - val_FP: 26.2700 - val_FN: 47.2200\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0555 - Accuracy: 0.9812 - Precision: 0.9541 - Recall: 0.9447 - TP: 3185.3601 - TN: 5507.8599 - FP: 139.1400 - FN: 186.6400 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9413 - val_TP: 756.7800 - val_TN: 1079.7400 - val_FP: 26.2600 - val_FN: 47.2200\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0554 - Accuracy: 0.9812 - Precision: 0.9539 - Recall: 0.9447 - TP: 3185.6899 - TN: 5506.6001 - FP: 140.4000 - FN: 186.3100 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9412 - val_TP: 756.7500 - val_TN: 1079.8700 - val_FP: 26.1300 - val_FN: 47.2500\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0554 - Accuracy: 0.9812 - Precision: 0.9540 - Recall: 0.9447 - TP: 3185.5400 - TN: 5507.3301 - FP: 139.6700 - FN: 186.4600 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9413 - val_TP: 756.7700 - val_TN: 1079.8500 - val_FP: 26.1500 - val_FN: 47.2300\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0554 - Accuracy: 0.9814 - Precision: 0.9541 - Recall: 0.9447 - TP: 3185.5200 - TN: 5507.7002 - FP: 139.3000 - FN: 186.4800 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9413 - val_TP: 756.7900 - val_TN: 1079.6899 - val_FP: 26.3100 - val_FN: 47.2100\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0554 - Accuracy: 0.9810 - Precision: 0.9539 - Recall: 0.9448 - TP: 3185.8301 - TN: 5506.7798 - FP: 140.2200 - FN: 186.1700 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9413 - val_TP: 756.7700 - val_TN: 1079.9100 - val_FP: 26.0900 - val_FN: 47.2300\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0554 - Accuracy: 0.9813 - Precision: 0.9542 - Recall: 0.9447 - TP: 3185.3601 - TN: 5508.4199 - FP: 138.5800 - FN: 186.6400 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9413 - val_TP: 756.7900 - val_TN: 1079.7800 - val_FP: 26.2200 - val_FN: 47.2100\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0554 - Accuracy: 0.9813 - Precision: 0.9540 - Recall: 0.9447 - TP: 3185.6799 - TN: 5507.4502 - FP: 139.5500 - FN: 186.3200 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9413 - val_TP: 756.7800 - val_TN: 1079.7500 - val_FP: 26.2500 - val_FN: 47.2200\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0554 - Accuracy: 0.9813 - Precision: 0.9541 - Recall: 0.9447 - TP: 3185.4500 - TN: 5507.7300 - FP: 139.2700 - FN: 186.5500 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9413 - val_TP: 756.8000 - val_TN: 1079.7000 - val_FP: 26.3000 - val_FN: 47.2000\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0553 - Accuracy: 0.9812 - Precision: 0.9541 - Recall: 0.9447 - TP: 3185.6001 - TN: 5507.9502 - FP: 139.0500 - FN: 186.4000 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9413 - val_TP: 756.8100 - val_TN: 1079.1801 - val_FP: 26.8200 - val_FN: 47.1900\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0553 - Accuracy: 0.9812 - Precision: 0.9539 - Recall: 0.9448 - TP: 3185.7900 - TN: 5506.4600 - FP: 140.5400 - FN: 186.2100 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9413 - val_TP: 756.7700 - val_TN: 1079.9100 - val_FP: 26.0900 - val_FN: 47.2300\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0553 - Accuracy: 0.9813 - Precision: 0.9539 - Recall: 0.9449 - TP: 3186.1699 - TN: 5506.6699 - FP: 140.3300 - FN: 185.8300 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9413 - val_TP: 756.8000 - val_TN: 1079.8600 - val_FP: 26.1400 - val_FN: 47.2000\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0553 - Accuracy: 0.9813 - Precision: 0.9543 - Recall: 0.9447 - TP: 3185.4900 - TN: 5508.7598 - FP: 138.2400 - FN: 186.5100 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9413 - val_TP: 756.8100 - val_TN: 1079.7400 - val_FP: 26.2600 - val_FN: 47.1900\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0553 - Accuracy: 0.9813 - Precision: 0.9541 - Recall: 0.9448 - TP: 3185.7700 - TN: 5507.8101 - FP: 139.1900 - FN: 186.2300 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9413 - val_TP: 756.8100 - val_TN: 1079.1500 - val_FP: 26.8500 - val_FN: 47.1900\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0553 - Accuracy: 0.9813 - Precision: 0.9541 - Recall: 0.9448 - TP: 3185.8000 - TN: 5507.7798 - FP: 139.2200 - FN: 186.2000 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9413 - val_TP: 756.7900 - val_TN: 1079.9700 - val_FP: 26.0300 - val_FN: 47.2100\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0553 - Accuracy: 0.9813 - Precision: 0.9541 - Recall: 0.9448 - TP: 3185.9199 - TN: 5507.6602 - FP: 139.3400 - FN: 186.0800 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9413 - val_TP: 756.8000 - val_TN: 1079.8101 - val_FP: 26.1900 - val_FN: 47.2000\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0553 - Accuracy: 0.9812 - Precision: 0.9541 - Recall: 0.9448 - TP: 3185.7600 - TN: 5507.6802 - FP: 139.3200 - FN: 186.2400 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9413 - val_TP: 756.8000 - val_TN: 1079.8800 - val_FP: 26.1200 - val_FN: 47.2000\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0552 - Accuracy: 0.9813 - Precision: 0.9543 - Recall: 0.9448 - TP: 3185.7800 - TN: 5508.6802 - FP: 138.3200 - FN: 186.2200 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9413 - val_TP: 756.8000 - val_TN: 1079.2200 - val_FP: 26.7800 - val_FN: 47.2000\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0552 - Accuracy: 0.9812 - Precision: 0.9539 - Recall: 0.9449 - TP: 3186.3701 - TN: 5506.5400 - FP: 140.4600 - FN: 185.6300 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9413 - val_TP: 756.8000 - val_TN: 1080.0300 - val_FP: 25.9700 - val_FN: 47.2000\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0552 - Accuracy: 0.9813 - Precision: 0.9543 - Recall: 0.9448 - TP: 3185.8701 - TN: 5508.8301 - FP: 138.1700 - FN: 186.1300 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9413 - val_TP: 756.8100 - val_TN: 1079.8600 - val_FP: 26.1400 - val_FN: 47.1900\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0553 - Accuracy: 0.9812 - Precision: 0.9539 - Recall: 0.9449 - TP: 3186.3501 - TN: 5506.5400 - FP: 140.4600 - FN: 185.6500 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9413 - val_TP: 756.8200 - val_TN: 1079.7800 - val_FP: 26.2200 - val_FN: 47.1800\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0552 - Accuracy: 0.9812 - Precision: 0.9541 - Recall: 0.9449 - TP: 3186.0801 - TN: 5507.6499 - FP: 139.3500 - FN: 185.9200 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9413 - val_TP: 756.8100 - val_TN: 1080.0100 - val_FP: 25.9900 - val_FN: 47.1900\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0552 - Accuracy: 0.9813 - Precision: 0.9543 - Recall: 0.9448 - TP: 3185.9199 - TN: 5508.6499 - FP: 138.3500 - FN: 186.0800 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9414 - val_TP: 756.8700 - val_TN: 1079.7000 - val_FP: 26.3000 - val_FN: 47.1300\n",
      "Epoch 30/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0552 - Accuracy: 0.9812 - Precision: 0.9540 - Recall: 0.9450 - TP: 3186.3899 - TN: 5507.2798 - FP: 139.7200 - FN: 185.6100 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9413 - val_TP: 756.8200 - val_TN: 1079.8600 - val_FP: 26.1400 - val_FN: 47.1800\n",
      "Epoch 31/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0551 - Accuracy: 0.9812 - Precision: 0.9541 - Recall: 0.9449 - TP: 3186.2300 - TN: 5507.8501 - FP: 139.1500 - FN: 185.7700 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9413 - val_TP: 756.7900 - val_TN: 1079.9100 - val_FP: 26.0900 - val_FN: 47.2100\n",
      "Epoch 32/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0552 - Accuracy: 0.9812 - Precision: 0.9542 - Recall: 0.9449 - TP: 3186.2000 - TN: 5507.9902 - FP: 139.0100 - FN: 185.8000 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9413 - val_TP: 756.8400 - val_TN: 1079.8800 - val_FP: 26.1200 - val_FN: 47.1600\n",
      "Epoch 33/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0551 - Accuracy: 0.9812 - Precision: 0.9542 - Recall: 0.9449 - TP: 3186.1001 - TN: 5508.2300 - FP: 138.7700 - FN: 185.9000 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9413 - val_TP: 756.8200 - val_TN: 1080.0601 - val_FP: 25.9400 - val_FN: 47.1800\n",
      "Epoch 34/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0551 - Accuracy: 0.9812 - Precision: 0.9544 - Recall: 0.9448 - TP: 3185.8501 - TN: 5509.2798 - FP: 137.7200 - FN: 186.1500 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9414 - val_TP: 756.8700 - val_TN: 1079.2500 - val_FP: 26.7500 - val_FN: 47.1300\n",
      "Epoch 35/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0551 - Accuracy: 0.9813 - Precision: 0.9540 - Recall: 0.9450 - TP: 3186.4099 - TN: 5506.8901 - FP: 140.1100 - FN: 185.5900 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9414 - val_TP: 756.8700 - val_TN: 1079.7800 - val_FP: 26.2200 - val_FN: 47.1300\n",
      "Epoch 36/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0551 - Accuracy: 0.9813 - Precision: 0.9540 - Recall: 0.9450 - TP: 3186.4700 - TN: 5507.2300 - FP: 139.7700 - FN: 185.5300 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9414 - val_TP: 756.8600 - val_TN: 1079.8900 - val_FP: 26.1100 - val_FN: 47.1400\n",
      "Epoch 37/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0551 - Accuracy: 0.9812 - Precision: 0.9542 - Recall: 0.9449 - TP: 3186.3101 - TN: 5508.0400 - FP: 138.9600 - FN: 185.6900 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9414 - val_TP: 756.8600 - val_TN: 1080.0500 - val_FP: 25.9500 - val_FN: 47.1400\n",
      "Epoch 38/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0551 - Accuracy: 0.9810 - Precision: 0.9542 - Recall: 0.9449 - TP: 3186.1599 - TN: 5508.2002 - FP: 138.8000 - FN: 185.8400 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9414 - val_TP: 756.8600 - val_TN: 1079.8199 - val_FP: 26.1800 - val_FN: 47.1400\n",
      "Epoch 39/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0550 - Accuracy: 0.9812 - Precision: 0.9543 - Recall: 0.9449 - TP: 3186.3501 - TN: 5508.7900 - FP: 138.2100 - FN: 185.6500 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9414 - val_TP: 756.8500 - val_TN: 1079.7700 - val_FP: 26.2300 - val_FN: 47.1500\n",
      "Epoch 40/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0551 - Accuracy: 0.9813 - Precision: 0.9539 - Recall: 0.9450 - TP: 3186.5500 - TN: 5506.7700 - FP: 140.2300 - FN: 185.4500 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9414 - val_TP: 756.8700 - val_TN: 1080.0200 - val_FP: 25.9800 - val_FN: 47.1300\n",
      "Epoch 41/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0550 - Accuracy: 0.9813 - Precision: 0.9544 - Recall: 0.9449 - TP: 3186.1799 - TN: 5509.3701 - FP: 137.6300 - FN: 185.8200 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9414 - val_TP: 756.8500 - val_TN: 1079.7900 - val_FP: 26.2100 - val_FN: 47.1500\n",
      "Epoch 42/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0551 - Accuracy: 0.9813 - Precision: 0.9541 - Recall: 0.9450 - TP: 3186.4399 - TN: 5507.7700 - FP: 139.2300 - FN: 185.5600 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9414 - val_TP: 756.8600 - val_TN: 1079.9399 - val_FP: 26.0600 - val_FN: 47.1400\n",
      "Epoch 43/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0550 - Accuracy: 0.9813 - Precision: 0.9543 - Recall: 0.9449 - TP: 3186.3701 - TN: 5508.6499 - FP: 138.3500 - FN: 185.6300 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9414 - val_TP: 756.8700 - val_TN: 1079.7400 - val_FP: 26.2600 - val_FN: 47.1300\n",
      "Epoch 44/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0550 - Accuracy: 0.9812 - Precision: 0.9542 - Recall: 0.9450 - TP: 3186.3899 - TN: 5508.3501 - FP: 138.6500 - FN: 185.6100 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9414 - val_TP: 756.8900 - val_TN: 1079.7200 - val_FP: 26.2800 - val_FN: 47.1100\n",
      "Epoch 45/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0550 - Accuracy: 0.9812 - Precision: 0.9542 - Recall: 0.9451 - TP: 3186.7500 - TN: 5507.9399 - FP: 139.0600 - FN: 185.2500 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9414 - val_TP: 756.8800 - val_TN: 1079.2300 - val_FP: 26.7700 - val_FN: 47.1200\n",
      "Epoch 46/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0550 - Accuracy: 0.9812 - Precision: 0.9541 - Recall: 0.9450 - TP: 3186.5601 - TN: 5507.4502 - FP: 139.5500 - FN: 185.4400 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9414 - val_TP: 756.8800 - val_TN: 1079.8800 - val_FP: 26.1200 - val_FN: 47.1200\n",
      "Epoch 47/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0550 - Accuracy: 0.9812 - Precision: 0.9541 - Recall: 0.9451 - TP: 3186.7100 - TN: 5507.6499 - FP: 139.3500 - FN: 185.2900 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9414 - val_TP: 756.8700 - val_TN: 1080.0699 - val_FP: 25.9300 - val_FN: 47.1300\n",
      "Epoch 48/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0550 - Accuracy: 0.9812 - Precision: 0.9543 - Recall: 0.9450 - TP: 3186.5200 - TN: 5508.2998 - FP: 138.7000 - FN: 185.4800 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9414 - val_TP: 756.8800 - val_TN: 1080.1000 - val_FP: 25.9000 - val_FN: 47.1200\n",
      "Epoch 49/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0549 - Accuracy: 0.9813 - Precision: 0.9544 - Recall: 0.9450 - TP: 3186.5400 - TN: 5509.2900 - FP: 137.7100 - FN: 185.4600 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9414 - val_TP: 756.8900 - val_TN: 1079.9800 - val_FP: 26.0200 - val_FN: 47.1100\n",
      "Epoch 50/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0549 - Accuracy: 0.9812 - Precision: 0.9544 - Recall: 0.9450 - TP: 3186.5200 - TN: 5508.9502 - FP: 138.0500 - FN: 185.4800 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9414 - val_TP: 756.8900 - val_TN: 1079.9800 - val_FP: 26.0200 - val_FN: 47.1100\n",
      "Epoch 51/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0549 - Accuracy: 0.9812 - Precision: 0.9543 - Recall: 0.9450 - TP: 3186.6001 - TN: 5508.4902 - FP: 138.5100 - FN: 185.4000 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9414 - val_TP: 756.8900 - val_TN: 1079.9800 - val_FP: 26.0200 - val_FN: 47.1100\n",
      "Epoch 52/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0549 - Accuracy: 0.9812 - Precision: 0.9543 - Recall: 0.9451 - TP: 3186.7300 - TN: 5508.5801 - FP: 138.4200 - FN: 185.2700 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9414 - val_TP: 756.8900 - val_TN: 1079.9800 - val_FP: 26.0200 - val_FN: 47.1100\n",
      "Epoch 53/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0549 - Accuracy: 0.9812 - Precision: 0.9543 - Recall: 0.9450 - TP: 3186.5701 - TN: 5508.7500 - FP: 138.2500 - FN: 185.4300 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9414 - val_TP: 756.8900 - val_TN: 1079.9399 - val_FP: 26.0600 - val_FN: 47.1100\n",
      "Epoch 54/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0549 - Accuracy: 0.9812 - Precision: 0.9541 - Recall: 0.9451 - TP: 3186.9399 - TN: 5507.3901 - FP: 139.6100 - FN: 185.0600 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9414 - val_TP: 756.8900 - val_TN: 1080.0100 - val_FP: 25.9900 - val_FN: 47.1100\n",
      "Epoch 55/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0549 - Accuracy: 0.9812 - Precision: 0.9545 - Recall: 0.9450 - TP: 3186.5100 - TN: 5509.7002 - FP: 137.3000 - FN: 185.4900 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9414 - val_TP: 756.8900 - val_TN: 1079.9700 - val_FP: 26.0300 - val_FN: 47.1100\n",
      "Epoch 56/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0550 - Accuracy: 0.9812 - Precision: 0.9542 - Recall: 0.9451 - TP: 3186.9099 - TN: 5507.8999 - FP: 139.1000 - FN: 185.0900 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9414 - val_TP: 756.8900 - val_TN: 1079.9500 - val_FP: 26.0500 - val_FN: 47.1100\n",
      "Epoch 57/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0549 - Accuracy: 0.9812 - Precision: 0.9543 - Recall: 0.9451 - TP: 3186.8101 - TN: 5508.5000 - FP: 138.5000 - FN: 185.1900 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9414 - val_TP: 756.9000 - val_TN: 1079.9600 - val_FP: 26.0400 - val_FN: 47.1000\n",
      "Epoch 58/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0548 - Accuracy: 0.9812 - Precision: 0.9542 - Recall: 0.9452 - TP: 3187.1101 - TN: 5507.8101 - FP: 139.1900 - FN: 184.8900 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9414 - val_TP: 756.9000 - val_TN: 1080.0300 - val_FP: 25.9700 - val_FN: 47.1000\n",
      "Epoch 59/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0548 - Accuracy: 0.9813 - Precision: 0.9545 - Recall: 0.9450 - TP: 3186.5200 - TN: 5509.6699 - FP: 137.3300 - FN: 185.4800 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9414 - val_TP: 756.9000 - val_TN: 1079.9301 - val_FP: 26.0700 - val_FN: 47.1000\n",
      "Epoch 60/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0548 - Accuracy: 0.9812 - Precision: 0.9543 - Recall: 0.9451 - TP: 3186.8601 - TN: 5508.4702 - FP: 138.5300 - FN: 185.1400 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9414 - val_TP: 756.9000 - val_TN: 1079.9100 - val_FP: 26.0900 - val_FN: 47.1000\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 10ms/step - loss: 0.0550 - Accuracy: 0.9810 - Precision: 0.9550 - Recall: 0.9449 - TP: 3186.1399 - TN: 5512.6299 - FP: 134.3700 - FN: 185.8600 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9415 - val_TP: 756.9800 - val_TN: 1079.7800 - val_FP: 26.2200 - val_FN: 47.0200\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0548 - Accuracy: 0.9812 - Precision: 0.9542 - Recall: 0.9452 - TP: 3187.3701 - TN: 5508.3599 - FP: 138.6400 - FN: 184.6300 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9415 - val_TP: 756.9800 - val_TN: 1079.7600 - val_FP: 26.2400 - val_FN: 47.0200\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0548 - Accuracy: 0.9813 - Precision: 0.9541 - Recall: 0.9453 - TP: 3187.6699 - TN: 5507.7402 - FP: 139.2600 - FN: 184.3300 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9415 - val_TP: 756.9800 - val_TN: 1079.8900 - val_FP: 26.1100 - val_FN: 47.0200\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0548 - Accuracy: 0.9812 - Precision: 0.9542 - Recall: 0.9452 - TP: 3187.3401 - TN: 5508.3101 - FP: 138.6900 - FN: 184.6600 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9415 - val_TP: 756.9500 - val_TN: 1079.9100 - val_FP: 26.0900 - val_FN: 47.0500\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0548 - Accuracy: 0.9812 - Precision: 0.9544 - Recall: 0.9452 - TP: 3187.0701 - TN: 5509.1099 - FP: 137.8900 - FN: 184.9300 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9607 - val_Recall: 0.9415 - val_TP: 756.9700 - val_TN: 1079.7400 - val_FP: 26.2600 - val_FN: 47.0300\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0548 - Accuracy: 0.9812 - Precision: 0.9541 - Recall: 0.9453 - TP: 3187.5300 - TN: 5507.7100 - FP: 139.2900 - FN: 184.4700 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9414 - val_TP: 756.9100 - val_TN: 1079.9800 - val_FP: 26.0200 - val_FN: 47.0900\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0548 - Accuracy: 0.9812 - Precision: 0.9545 - Recall: 0.9451 - TP: 3187.0100 - TN: 5509.3398 - FP: 137.6600 - FN: 184.9900 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9415 - val_TP: 756.9700 - val_TN: 1079.7600 - val_FP: 26.2400 - val_FN: 47.0300\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0547 - Accuracy: 0.9813 - Precision: 0.9543 - Recall: 0.9453 - TP: 3187.4099 - TN: 5508.5498 - FP: 138.4500 - FN: 184.5900 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9415 - val_TP: 756.9400 - val_TN: 1080.1100 - val_FP: 25.8900 - val_FN: 47.0600\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0547 - Accuracy: 0.9812 - Precision: 0.9545 - Recall: 0.9451 - TP: 3186.9900 - TN: 5509.6899 - FP: 137.3100 - FN: 185.0100 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9415 - val_TP: 756.9700 - val_TN: 1079.8800 - val_FP: 26.1200 - val_FN: 47.0300\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0547 - Accuracy: 0.9812 - Precision: 0.9543 - Recall: 0.9453 - TP: 3187.3899 - TN: 5508.4502 - FP: 138.5500 - FN: 184.6100 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9415 - val_TP: 756.9700 - val_TN: 1079.8300 - val_FP: 26.1700 - val_FN: 47.0300\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0547 - Accuracy: 0.9812 - Precision: 0.9545 - Recall: 0.9452 - TP: 3187.1299 - TN: 5509.3301 - FP: 137.6700 - FN: 184.8700 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9415 - val_TP: 756.9400 - val_TN: 1079.8300 - val_FP: 26.1700 - val_FN: 47.0600\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0547 - Accuracy: 0.9813 - Precision: 0.9543 - Recall: 0.9453 - TP: 3187.5801 - TN: 5508.7402 - FP: 138.2600 - FN: 184.4200 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9415 - val_TP: 756.9700 - val_TN: 1079.2800 - val_FP: 26.7200 - val_FN: 47.0300\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0547 - Accuracy: 0.9812 - Precision: 0.9543 - Recall: 0.9453 - TP: 3187.4099 - TN: 5508.4902 - FP: 138.5100 - FN: 184.5900 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9415 - val_TP: 756.9700 - val_TN: 1079.9900 - val_FP: 26.0100 - val_FN: 47.0300\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0547 - Accuracy: 0.9812 - Precision: 0.9543 - Recall: 0.9453 - TP: 3187.4399 - TN: 5508.6499 - FP: 138.3500 - FN: 184.5600 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9415 - val_TP: 756.9500 - val_TN: 1080.1700 - val_FP: 25.8300 - val_FN: 47.0500\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0546 - Accuracy: 0.9810 - Precision: 0.9546 - Recall: 0.9452 - TP: 3187.2500 - TN: 5510.1201 - FP: 136.8800 - FN: 184.7500 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9415 - val_TP: 756.9600 - val_TN: 1079.3000 - val_FP: 26.7000 - val_FN: 47.0400\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0546 - Accuracy: 0.9812 - Precision: 0.9541 - Recall: 0.9454 - TP: 3187.8401 - TN: 5507.4199 - FP: 139.5800 - FN: 184.1600 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9415 - val_TP: 756.9400 - val_TN: 1080.1899 - val_FP: 25.8100 - val_FN: 47.0600\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0546 - Accuracy: 0.9812 - Precision: 0.9546 - Recall: 0.9452 - TP: 3187.2200 - TN: 5509.8101 - FP: 137.1900 - FN: 184.7800 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9415 - val_TP: 756.9700 - val_TN: 1080.0000 - val_FP: 26.0000 - val_FN: 47.0300\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0546 - Accuracy: 0.9812 - Precision: 0.9543 - Recall: 0.9453 - TP: 3187.5601 - TN: 5508.5298 - FP: 138.4700 - FN: 184.4400 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9415 - val_TP: 756.9400 - val_TN: 1080.2000 - val_FP: 25.8000 - val_FN: 47.0600\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0546 - Accuracy: 0.9812 - Precision: 0.9544 - Recall: 0.9454 - TP: 3187.7700 - TN: 5508.8101 - FP: 138.1900 - FN: 184.2300 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9415 - val_TP: 756.9800 - val_TN: 1080.1200 - val_FP: 25.8800 - val_FN: 47.0200\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0546 - Accuracy: 0.9812 - Precision: 0.9546 - Recall: 0.9452 - TP: 3187.2400 - TN: 5509.9502 - FP: 137.0500 - FN: 184.7600 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9415 - val_TP: 756.9800 - val_TN: 1080.1000 - val_FP: 25.9000 - val_FN: 47.0200\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0546 - Accuracy: 0.9812 - Precision: 0.9545 - Recall: 0.9453 - TP: 3187.4800 - TN: 5509.5698 - FP: 137.4300 - FN: 184.5200 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9415 - val_TP: 756.9900 - val_TN: 1079.9700 - val_FP: 26.0300 - val_FN: 47.0100\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0546 - Accuracy: 0.9812 - Precision: 0.9544 - Recall: 0.9453 - TP: 3187.7100 - TN: 5509.1802 - FP: 137.8200 - FN: 184.2900 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9415 - val_TP: 756.9900 - val_TN: 1079.9100 - val_FP: 26.0900 - val_FN: 47.0100\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0546 - Accuracy: 0.9813 - Precision: 0.9543 - Recall: 0.9454 - TP: 3187.8701 - TN: 5508.6299 - FP: 138.3700 - FN: 184.1300 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9415 - val_TP: 756.9800 - val_TN: 1080.1600 - val_FP: 25.8400 - val_FN: 47.0200\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0545 - Accuracy: 0.9810 - Precision: 0.9547 - Recall: 0.9452 - TP: 3187.3799 - TN: 5510.3701 - FP: 136.6300 - FN: 184.6200 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9415 - val_TP: 756.9800 - val_TN: 1080.0900 - val_FP: 25.9100 - val_FN: 47.0200\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0545 - Accuracy: 0.9812 - Precision: 0.9543 - Recall: 0.9454 - TP: 3187.9299 - TN: 5508.7998 - FP: 138.2000 - FN: 184.0700 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9416 - val_TP: 757.0100 - val_TN: 1079.9600 - val_FP: 26.0400 - val_FN: 46.9900\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0545 - Accuracy: 0.9812 - Precision: 0.9545 - Recall: 0.9453 - TP: 3187.6899 - TN: 5509.5498 - FP: 137.4500 - FN: 184.3100 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9416 - val_TP: 757.0100 - val_TN: 1079.8500 - val_FP: 26.1500 - val_FN: 46.9900\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0545 - Accuracy: 0.9810 - Precision: 0.9544 - Recall: 0.9454 - TP: 3188.0000 - TN: 5508.7598 - FP: 138.2400 - FN: 184.0000 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9416 - val_TP: 757.0100 - val_TN: 1080.0200 - val_FP: 25.9800 - val_FN: 46.9900\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0545 - Accuracy: 0.9810 - Precision: 0.9546 - Recall: 0.9453 - TP: 3187.7000 - TN: 5510.1802 - FP: 136.8200 - FN: 184.3000 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9416 - val_TP: 757.0100 - val_TN: 1079.9600 - val_FP: 26.0400 - val_FN: 46.9900\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0545 - Accuracy: 0.9813 - Precision: 0.9544 - Recall: 0.9454 - TP: 3187.8799 - TN: 5509.0898 - FP: 137.9100 - FN: 184.1200 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9416 - val_TP: 757.0100 - val_TN: 1080.0400 - val_FP: 25.9600 - val_FN: 46.9900\n",
      "Epoch 30/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0544 - Accuracy: 0.9812 - Precision: 0.9545 - Recall: 0.9454 - TP: 3187.8799 - TN: 5509.7402 - FP: 137.2600 - FN: 184.1200 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9416 - val_TP: 757.0300 - val_TN: 1080.0400 - val_FP: 25.9600 - val_FN: 46.9700\n",
      "Epoch 31/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0545 - Accuracy: 0.9810 - Precision: 0.9543 - Recall: 0.9455 - TP: 3188.0901 - TN: 5508.6499 - FP: 138.3500 - FN: 183.9100 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9416 - val_TP: 757.0100 - val_TN: 1080.0601 - val_FP: 25.9400 - val_FN: 46.9900\n",
      "Epoch 32/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0544 - Accuracy: 0.9812 - Precision: 0.9545 - Recall: 0.9454 - TP: 3187.8601 - TN: 5509.6001 - FP: 137.4000 - FN: 184.1400 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9416 - val_TP: 757.0100 - val_TN: 1080.0400 - val_FP: 25.9600 - val_FN: 46.9900\n",
      "Epoch 33/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0544 - Accuracy: 0.9812 - Precision: 0.9546 - Recall: 0.9454 - TP: 3187.8201 - TN: 5510.0698 - FP: 136.9300 - FN: 184.1800 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9416 - val_TP: 757.0100 - val_TN: 1080.0500 - val_FP: 25.9500 - val_FN: 46.9900\n",
      "Epoch 34/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0544 - Accuracy: 0.9810 - Precision: 0.9546 - Recall: 0.9454 - TP: 3187.9800 - TN: 5509.8198 - FP: 137.1800 - FN: 184.0200 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9416 - val_TP: 757.0100 - val_TN: 1080.0500 - val_FP: 25.9500 - val_FN: 46.9900\n",
      "Epoch 35/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0544 - Accuracy: 0.9812 - Precision: 0.9544 - Recall: 0.9454 - TP: 3187.9199 - TN: 5509.1802 - FP: 137.8200 - FN: 184.0800 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9416 - val_TP: 757.0200 - val_TN: 1080.1200 - val_FP: 25.8800 - val_FN: 46.9800\n",
      "Epoch 36/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0544 - Accuracy: 0.9810 - Precision: 0.9545 - Recall: 0.9454 - TP: 3187.9399 - TN: 5509.6899 - FP: 137.3100 - FN: 184.0600 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9416 - val_TP: 757.0100 - val_TN: 1080.0100 - val_FP: 25.9900 - val_FN: 46.9900\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 9ms/step - loss: 0.0547 - Accuracy: 0.9812 - Precision: 0.9548 - Recall: 0.9452 - TP: 3187.2400 - TN: 5511.2002 - FP: 135.8000 - FN: 184.7600 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9415 - val_TP: 756.9700 - val_TN: 1080.2000 - val_FP: 25.8000 - val_FN: 47.0300\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0546 - Accuracy: 0.9812 - Precision: 0.9545 - Recall: 0.9453 - TP: 3187.6399 - TN: 5509.7998 - FP: 137.2000 - FN: 184.3600 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9415 - val_TP: 756.9800 - val_TN: 1080.0400 - val_FP: 25.9600 - val_FN: 47.0200\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0546 - Accuracy: 0.9812 - Precision: 0.9545 - Recall: 0.9453 - TP: 3187.5300 - TN: 5509.3999 - FP: 137.6000 - FN: 184.4700 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9415 - val_TP: 756.9800 - val_TN: 1079.8800 - val_FP: 26.1200 - val_FN: 47.0200\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0546 - Accuracy: 0.9812 - Precision: 0.9544 - Recall: 0.9454 - TP: 3187.8401 - TN: 5509.0098 - FP: 137.9900 - FN: 184.1600 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9415 - val_TP: 756.9900 - val_TN: 1079.9600 - val_FP: 26.0400 - val_FN: 47.0100\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0546 - Accuracy: 0.9812 - Precision: 0.9545 - Recall: 0.9453 - TP: 3187.5901 - TN: 5509.4702 - FP: 137.5300 - FN: 184.4100 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9415 - val_TP: 756.9800 - val_TN: 1079.8600 - val_FP: 26.1400 - val_FN: 47.0200\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0546 - Accuracy: 0.9812 - Precision: 0.9543 - Recall: 0.9453 - TP: 3187.5801 - TN: 5508.6602 - FP: 138.3400 - FN: 184.4200 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9415 - val_TP: 756.9900 - val_TN: 1080.0200 - val_FP: 25.9800 - val_FN: 47.0100\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0546 - Accuracy: 0.9812 - Precision: 0.9546 - Recall: 0.9453 - TP: 3187.3999 - TN: 5510.1699 - FP: 136.8300 - FN: 184.6000 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9415 - val_TP: 756.9600 - val_TN: 1080.1801 - val_FP: 25.8200 - val_FN: 47.0400\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0545 - Accuracy: 0.9812 - Precision: 0.9542 - Recall: 0.9455 - TP: 3188.0801 - TN: 5507.9902 - FP: 139.0100 - FN: 183.9200 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9415 - val_TP: 756.9600 - val_TN: 1080.1700 - val_FP: 25.8300 - val_FN: 47.0400\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0545 - Accuracy: 0.9812 - Precision: 0.9545 - Recall: 0.9454 - TP: 3187.7600 - TN: 5509.7402 - FP: 137.2600 - FN: 184.2400 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9416 - val_TP: 757.0100 - val_TN: 1080.0000 - val_FP: 26.0000 - val_FN: 46.9900\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0545 - Accuracy: 0.9810 - Precision: 0.9546 - Recall: 0.9453 - TP: 3187.5100 - TN: 5509.8599 - FP: 137.1400 - FN: 184.4900 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9415 - val_TP: 756.9800 - val_TN: 1080.0699 - val_FP: 25.9300 - val_FN: 47.0200\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0545 - Accuracy: 0.9813 - Precision: 0.9546 - Recall: 0.9454 - TP: 3187.8301 - TN: 5509.9800 - FP: 137.0200 - FN: 184.1700 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9416 - val_TP: 757.0200 - val_TN: 1079.9200 - val_FP: 26.0800 - val_FN: 46.9800\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0545 - Accuracy: 0.9812 - Precision: 0.9544 - Recall: 0.9454 - TP: 3187.7700 - TN: 5509.0400 - FP: 137.9600 - FN: 184.2300 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9415 - val_TP: 756.9900 - val_TN: 1080.1200 - val_FP: 25.8800 - val_FN: 47.0100\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0545 - Accuracy: 0.9813 - Precision: 0.9546 - Recall: 0.9453 - TP: 3187.6599 - TN: 5510.1099 - FP: 136.8900 - FN: 184.3400 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9415 - val_TP: 757.0000 - val_TN: 1079.9800 - val_FP: 26.0200 - val_FN: 47.0000\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0545 - Accuracy: 0.9810 - Precision: 0.9543 - Recall: 0.9455 - TP: 3188.2700 - TN: 5508.6201 - FP: 138.3800 - FN: 183.7300 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9416 - val_TP: 757.0400 - val_TN: 1080.0200 - val_FP: 25.9800 - val_FN: 46.9600\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0545 - Accuracy: 0.9812 - Precision: 0.9544 - Recall: 0.9454 - TP: 3188.0500 - TN: 5508.8599 - FP: 138.1400 - FN: 183.9500 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9416 - val_TP: 757.0100 - val_TN: 1080.2700 - val_FP: 25.7300 - val_FN: 46.9900\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0545 - Accuracy: 0.9812 - Precision: 0.9546 - Recall: 0.9454 - TP: 3187.9800 - TN: 5510.0498 - FP: 136.9500 - FN: 184.0200 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9415 - val_TP: 757.0000 - val_TN: 1080.0699 - val_FP: 25.9300 - val_FN: 47.0000\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0544 - Accuracy: 0.9810 - Precision: 0.9545 - Recall: 0.9454 - TP: 3188.0100 - TN: 5509.6099 - FP: 137.3900 - FN: 183.9900 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9416 - val_TP: 757.0300 - val_TN: 1080.0500 - val_FP: 25.9500 - val_FN: 46.9700\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0544 - Accuracy: 0.9812 - Precision: 0.9547 - Recall: 0.9454 - TP: 3187.8101 - TN: 5510.2500 - FP: 136.7500 - FN: 184.1900 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9416 - val_TP: 757.0100 - val_TN: 1079.8800 - val_FP: 26.1200 - val_FN: 46.9900\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0544 - Accuracy: 0.9812 - Precision: 0.9546 - Recall: 0.9454 - TP: 3187.9600 - TN: 5509.6699 - FP: 137.3300 - FN: 184.0400 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9416 - val_TP: 757.0100 - val_TN: 1079.9600 - val_FP: 26.0400 - val_FN: 46.9900\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0544 - Accuracy: 0.9812 - Precision: 0.9545 - Recall: 0.9455 - TP: 3188.0601 - TN: 5509.6299 - FP: 137.3700 - FN: 183.9400 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9416 - val_TP: 757.0200 - val_TN: 1080.0500 - val_FP: 25.9500 - val_FN: 46.9800\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0544 - Accuracy: 0.9810 - Precision: 0.9545 - Recall: 0.9454 - TP: 3187.8601 - TN: 5509.7402 - FP: 137.2600 - FN: 184.1400 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9416 - val_TP: 757.0300 - val_TN: 1079.3900 - val_FP: 26.6100 - val_FN: 46.9700\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0544 - Accuracy: 0.9812 - Precision: 0.9544 - Recall: 0.9455 - TP: 3188.2300 - TN: 5509.1299 - FP: 137.8700 - FN: 183.7700 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9416 - val_TP: 757.0500 - val_TN: 1080.0000 - val_FP: 26.0000 - val_FN: 46.9500\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0544 - Accuracy: 0.9810 - Precision: 0.9545 - Recall: 0.9455 - TP: 3188.2100 - TN: 5509.2998 - FP: 137.7000 - FN: 183.7900 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9416 - val_TP: 757.0200 - val_TN: 1080.0300 - val_FP: 25.9700 - val_FN: 46.9800\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0543 - Accuracy: 0.9810 - Precision: 0.9545 - Recall: 0.9455 - TP: 3188.2800 - TN: 5509.5898 - FP: 137.4100 - FN: 183.7200 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9416 - val_TP: 757.0700 - val_TN: 1080.0100 - val_FP: 25.9900 - val_FN: 46.9300\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0543 - Accuracy: 0.9812 - Precision: 0.9545 - Recall: 0.9455 - TP: 3188.2900 - TN: 5509.6802 - FP: 137.3200 - FN: 183.7100 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9416 - val_TP: 757.0400 - val_TN: 1080.1200 - val_FP: 25.8800 - val_FN: 46.9600\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0544 - Accuracy: 0.9810 - Precision: 0.9545 - Recall: 0.9455 - TP: 3188.1699 - TN: 5509.3799 - FP: 137.6200 - FN: 183.8300 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9416 - val_TP: 757.0200 - val_TN: 1080.2100 - val_FP: 25.7900 - val_FN: 46.9800\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0543 - Accuracy: 0.9812 - Precision: 0.9547 - Recall: 0.9454 - TP: 3188.0000 - TN: 5510.6099 - FP: 136.3900 - FN: 184.0000 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9416 - val_TP: 757.0400 - val_TN: 1080.0800 - val_FP: 25.9200 - val_FN: 46.9600\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0543 - Accuracy: 0.9812 - Precision: 0.9546 - Recall: 0.9455 - TP: 3188.0801 - TN: 5509.9600 - FP: 137.0400 - FN: 183.9200 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9417 - val_TP: 757.0900 - val_TN: 1079.4100 - val_FP: 26.5900 - val_FN: 46.9100\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0543 - Accuracy: 0.9810 - Precision: 0.9547 - Recall: 0.9455 - TP: 3188.2200 - TN: 5510.2798 - FP: 136.7200 - FN: 183.7800 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9417 - val_TP: 757.1300 - val_TN: 1079.2800 - val_FP: 26.7200 - val_FN: 46.8700\n",
      "Epoch 30/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0543 - Accuracy: 0.9810 - Precision: 0.9544 - Recall: 0.9456 - TP: 3188.5801 - TN: 5508.9800 - FP: 138.0200 - FN: 183.4200 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9417 - val_TP: 757.1400 - val_TN: 1079.9301 - val_FP: 26.0700 - val_FN: 46.8600\n",
      "Epoch 31/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0543 - Accuracy: 0.9814 - Precision: 0.9545 - Recall: 0.9456 - TP: 3188.6101 - TN: 5509.2998 - FP: 137.7000 - FN: 183.3900 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9417 - val_TP: 757.1200 - val_TN: 1080.0400 - val_FP: 25.9600 - val_FN: 46.8800\n",
      "Epoch 32/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0543 - Accuracy: 0.9812 - Precision: 0.9546 - Recall: 0.9455 - TP: 3188.3501 - TN: 5510.1001 - FP: 136.9000 - FN: 183.6500 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9417 - val_TP: 757.1200 - val_TN: 1080.1100 - val_FP: 25.8900 - val_FN: 46.8800\n",
      "Epoch 33/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0542 - Accuracy: 0.9812 - Precision: 0.9545 - Recall: 0.9456 - TP: 3188.5601 - TN: 5509.5098 - FP: 137.4900 - FN: 183.4400 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9417 - val_TP: 757.1200 - val_TN: 1079.9900 - val_FP: 26.0100 - val_FN: 46.8800\n",
      "Epoch 34/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0542 - Accuracy: 0.9812 - Precision: 0.9547 - Recall: 0.9455 - TP: 3188.3101 - TN: 5510.6201 - FP: 136.3800 - FN: 183.6900 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9417 - val_TP: 757.1200 - val_TN: 1079.3500 - val_FP: 26.6500 - val_FN: 46.8800\n",
      "Epoch 35/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0542 - Accuracy: 0.9812 - Precision: 0.9547 - Recall: 0.9455 - TP: 3188.2900 - TN: 5510.3101 - FP: 136.6900 - FN: 183.7100 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9602 - val_Recall: 0.9417 - val_TP: 757.1500 - val_TN: 1079.1400 - val_FP: 26.8600 - val_FN: 46.8500\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 9ms/step - loss: 0.0546 - Accuracy: 0.9810 - Precision: 0.9551 - Recall: 0.9452 - TP: 3187.1899 - TN: 5512.9502 - FP: 134.0500 - FN: 184.8100 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9416 - val_TP: 757.0400 - val_TN: 1080.1500 - val_FP: 25.8500 - val_FN: 46.9600\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0544 - Accuracy: 0.9812 - Precision: 0.9545 - Recall: 0.9455 - TP: 3188.1101 - TN: 5509.6802 - FP: 137.3200 - FN: 183.8900 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9417 - val_TP: 757.1300 - val_TN: 1079.2500 - val_FP: 26.7500 - val_FN: 46.8700\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0544 - Accuracy: 0.9813 - Precision: 0.9543 - Recall: 0.9456 - TP: 3188.4900 - TN: 5508.6401 - FP: 138.3600 - FN: 183.5100 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9417 - val_TP: 757.1000 - val_TN: 1080.0300 - val_FP: 25.9700 - val_FN: 46.9000\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0544 - Accuracy: 0.9812 - Precision: 0.9545 - Recall: 0.9455 - TP: 3188.3000 - TN: 5509.7500 - FP: 137.2500 - FN: 183.7000 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9416 - val_TP: 757.0500 - val_TN: 1080.0500 - val_FP: 25.9500 - val_FN: 46.9500\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0544 - Accuracy: 0.9810 - Precision: 0.9546 - Recall: 0.9454 - TP: 3188.0300 - TN: 5509.8901 - FP: 137.1100 - FN: 183.9700 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9417 - val_TP: 757.1600 - val_TN: 1079.8000 - val_FP: 26.2000 - val_FN: 46.8400\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0544 - Accuracy: 0.9812 - Precision: 0.9544 - Recall: 0.9456 - TP: 3188.5100 - TN: 5508.9902 - FP: 138.0100 - FN: 183.4900 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9416 - val_TP: 757.0200 - val_TN: 1080.1500 - val_FP: 25.8500 - val_FN: 46.9800\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0543 - Accuracy: 0.9812 - Precision: 0.9547 - Recall: 0.9454 - TP: 3187.9800 - TN: 5510.7100 - FP: 136.2900 - FN: 184.0200 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9417 - val_TP: 757.0900 - val_TN: 1079.8500 - val_FP: 26.1500 - val_FN: 46.9100\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0544 - Accuracy: 0.9812 - Precision: 0.9546 - Recall: 0.9454 - TP: 3187.8701 - TN: 5509.9902 - FP: 137.0100 - FN: 184.1300 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9417 - val_TP: 757.1200 - val_TN: 1080.0200 - val_FP: 25.9800 - val_FN: 46.8800\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0544 - Accuracy: 0.9810 - Precision: 0.9543 - Recall: 0.9456 - TP: 3188.5601 - TN: 5508.4302 - FP: 138.5700 - FN: 183.4400 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9417 - val_TP: 757.1000 - val_TN: 1079.9399 - val_FP: 26.0600 - val_FN: 46.9000\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0543 - Accuracy: 0.9813 - Precision: 0.9545 - Recall: 0.9455 - TP: 3188.2900 - TN: 5509.5000 - FP: 137.5000 - FN: 183.7100 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9416 - val_TP: 757.0300 - val_TN: 1080.1899 - val_FP: 25.8100 - val_FN: 46.9700\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0543 - Accuracy: 0.9810 - Precision: 0.9546 - Recall: 0.9454 - TP: 3188.0000 - TN: 5510.0898 - FP: 136.9100 - FN: 184.0000 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9417 - val_TP: 757.0900 - val_TN: 1079.9301 - val_FP: 26.0700 - val_FN: 46.9100\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0543 - Accuracy: 0.9810 - Precision: 0.9545 - Recall: 0.9456 - TP: 3188.4800 - TN: 5509.3301 - FP: 137.6700 - FN: 183.5200 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9416 - val_TP: 757.0600 - val_TN: 1080.0900 - val_FP: 25.9100 - val_FN: 46.9400\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0543 - Accuracy: 0.9812 - Precision: 0.9544 - Recall: 0.9456 - TP: 3188.5400 - TN: 5509.1299 - FP: 137.8700 - FN: 183.4600 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9416 - val_TP: 757.0700 - val_TN: 1080.2200 - val_FP: 25.7800 - val_FN: 46.9300\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0543 - Accuracy: 0.9812 - Precision: 0.9548 - Recall: 0.9454 - TP: 3188.0500 - TN: 5510.7900 - FP: 136.2100 - FN: 183.9500 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9416 - val_TP: 757.0600 - val_TN: 1080.1000 - val_FP: 25.9000 - val_FN: 46.9400\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0542 - Accuracy: 0.9810 - Precision: 0.9548 - Recall: 0.9455 - TP: 3188.0801 - TN: 5510.8799 - FP: 136.1200 - FN: 183.9200 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9417 - val_TP: 757.1400 - val_TN: 1079.2400 - val_FP: 26.7600 - val_FN: 46.8600\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0543 - Accuracy: 0.9812 - Precision: 0.9543 - Recall: 0.9456 - TP: 3188.7000 - TN: 5508.5698 - FP: 138.4300 - FN: 183.3000 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9417 - val_TP: 757.1000 - val_TN: 1080.0300 - val_FP: 25.9700 - val_FN: 46.9000\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0543 - Accuracy: 0.9812 - Precision: 0.9546 - Recall: 0.9455 - TP: 3188.3301 - TN: 5510.1802 - FP: 136.8200 - FN: 183.6700 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9417 - val_TP: 757.1100 - val_TN: 1080.0800 - val_FP: 25.9200 - val_FN: 46.8900\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0542 - Accuracy: 0.9812 - Precision: 0.9546 - Recall: 0.9456 - TP: 3188.4700 - TN: 5510.1699 - FP: 136.8300 - FN: 183.5300 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9417 - val_TP: 757.1200 - val_TN: 1079.9200 - val_FP: 26.0800 - val_FN: 46.8800\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0542 - Accuracy: 0.9812 - Precision: 0.9545 - Recall: 0.9457 - TP: 3188.8101 - TN: 5509.2500 - FP: 137.7500 - FN: 183.1900 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9417 - val_TP: 757.1100 - val_TN: 1080.1899 - val_FP: 25.8100 - val_FN: 46.8900\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0542 - Accuracy: 0.9812 - Precision: 0.9548 - Recall: 0.9455 - TP: 3188.3501 - TN: 5510.7598 - FP: 136.2400 - FN: 183.6500 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9416 - val_TP: 757.0500 - val_TN: 1080.1400 - val_FP: 25.8600 - val_FN: 46.9500\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0542 - Accuracy: 0.9812 - Precision: 0.9545 - Recall: 0.9456 - TP: 3188.7200 - TN: 5509.4102 - FP: 137.5900 - FN: 183.2800 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9417 - val_TP: 757.1200 - val_TN: 1080.0100 - val_FP: 25.9900 - val_FN: 46.8800\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0542 - Accuracy: 0.9812 - Precision: 0.9547 - Recall: 0.9456 - TP: 3188.4800 - TN: 5510.1499 - FP: 136.8500 - FN: 183.5200 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9417 - val_TP: 757.1000 - val_TN: 1080.1100 - val_FP: 25.8900 - val_FN: 46.9000\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0542 - Accuracy: 0.9810 - Precision: 0.9546 - Recall: 0.9456 - TP: 3188.7100 - TN: 5510.0498 - FP: 136.9500 - FN: 183.2900 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9417 - val_TP: 757.1100 - val_TN: 1080.1400 - val_FP: 25.8600 - val_FN: 46.8900\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0542 - Accuracy: 0.9812 - Precision: 0.9546 - Recall: 0.9457 - TP: 3188.8201 - TN: 5510.1802 - FP: 136.8200 - FN: 183.1800 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9613 - val_Recall: 0.9417 - val_TP: 757.1000 - val_TN: 1080.3101 - val_FP: 25.6900 - val_FN: 46.9000\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0541 - Accuracy: 0.9812 - Precision: 0.9549 - Recall: 0.9455 - TP: 3188.2800 - TN: 5511.2900 - FP: 135.7100 - FN: 183.7200 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9417 - val_TP: 757.1100 - val_TN: 1079.4200 - val_FP: 26.5800 - val_FN: 46.8900\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0541 - Accuracy: 0.9813 - Precision: 0.9544 - Recall: 0.9458 - TP: 3189.0901 - TN: 5508.5801 - FP: 138.4200 - FN: 182.9100 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9417 - val_TP: 757.1000 - val_TN: 1080.2300 - val_FP: 25.7700 - val_FN: 46.9000\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0541 - Accuracy: 0.9812 - Precision: 0.9547 - Recall: 0.9457 - TP: 3188.8601 - TN: 5510.2202 - FP: 136.7800 - FN: 183.1400 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9417 - val_TP: 757.1200 - val_TN: 1080.2300 - val_FP: 25.7700 - val_FN: 46.8800\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0541 - Accuracy: 0.9812 - Precision: 0.9547 - Recall: 0.9456 - TP: 3188.7300 - TN: 5510.3599 - FP: 136.6400 - FN: 183.2700 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9417 - val_TP: 757.1100 - val_TN: 1080.2400 - val_FP: 25.7600 - val_FN: 46.8900\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0541 - Accuracy: 0.9812 - Precision: 0.9547 - Recall: 0.9456 - TP: 3188.6499 - TN: 5510.2300 - FP: 136.7700 - FN: 183.3500 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9417 - val_TP: 757.1400 - val_TN: 1080.1200 - val_FP: 25.8800 - val_FN: 46.8600\n",
      "Epoch 30/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0541 - Accuracy: 0.9812 - Precision: 0.9546 - Recall: 0.9457 - TP: 3188.8501 - TN: 5510.0400 - FP: 136.9600 - FN: 183.1500 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9417 - val_TP: 757.1400 - val_TN: 1080.1500 - val_FP: 25.8500 - val_FN: 46.8600\n",
      "Epoch 31/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0541 - Accuracy: 0.9812 - Precision: 0.9549 - Recall: 0.9456 - TP: 3188.4800 - TN: 5511.4399 - FP: 135.5600 - FN: 183.5200 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9417 - val_TP: 757.1500 - val_TN: 1079.4100 - val_FP: 26.5900 - val_FN: 46.8500\n",
      "Epoch 32/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0541 - Accuracy: 0.9812 - Precision: 0.9545 - Recall: 0.9457 - TP: 3188.9900 - TN: 5509.4502 - FP: 137.5500 - FN: 183.0100 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9417 - val_TP: 757.1300 - val_TN: 1080.1400 - val_FP: 25.8600 - val_FN: 46.8700\n",
      "Epoch 33/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0540 - Accuracy: 0.9812 - Precision: 0.9548 - Recall: 0.9457 - TP: 3188.7900 - TN: 5510.9399 - FP: 136.0600 - FN: 183.2100 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9417 - val_TP: 757.1200 - val_TN: 1080.1400 - val_FP: 25.8600 - val_FN: 46.8800\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 9ms/step - loss: 0.0544 - Accuracy: 0.9810 - Precision: 0.9552 - Recall: 0.9452 - TP: 3187.3799 - TN: 5513.5000 - FP: 133.5000 - FN: 184.6200 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9417 - val_TP: 757.1300 - val_TN: 1080.1300 - val_FP: 25.8700 - val_FN: 46.8700\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0543 - Accuracy: 0.9813 - Precision: 0.9545 - Recall: 0.9456 - TP: 3188.6499 - TN: 5509.6001 - FP: 137.4000 - FN: 183.3500 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9613 - val_Recall: 0.9417 - val_TP: 757.0900 - val_TN: 1080.3199 - val_FP: 25.6800 - val_FN: 46.9100\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0542 - Accuracy: 0.9812 - Precision: 0.9547 - Recall: 0.9456 - TP: 3188.5901 - TN: 5510.2900 - FP: 136.7100 - FN: 183.4100 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9417 - val_TP: 757.1200 - val_TN: 1080.0900 - val_FP: 25.9100 - val_FN: 46.8800\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0542 - Accuracy: 0.9812 - Precision: 0.9546 - Recall: 0.9456 - TP: 3188.4299 - TN: 5509.7700 - FP: 137.2300 - FN: 183.5700 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9417 - val_TP: 757.0900 - val_TN: 1080.1100 - val_FP: 25.8900 - val_FN: 46.9100\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0542 - Accuracy: 0.9812 - Precision: 0.9547 - Recall: 0.9456 - TP: 3188.4199 - TN: 5510.2798 - FP: 136.7200 - FN: 183.5800 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9417 - val_TP: 757.1000 - val_TN: 1080.1500 - val_FP: 25.8500 - val_FN: 46.9000\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0542 - Accuracy: 0.9812 - Precision: 0.9547 - Recall: 0.9456 - TP: 3188.4600 - TN: 5510.3701 - FP: 136.6300 - FN: 183.5400 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9417 - val_TP: 757.1400 - val_TN: 1080.0601 - val_FP: 25.9400 - val_FN: 46.8600\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0542 - Accuracy: 0.9810 - Precision: 0.9547 - Recall: 0.9456 - TP: 3188.4700 - TN: 5510.4702 - FP: 136.5300 - FN: 183.5300 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9417 - val_TP: 757.1300 - val_TN: 1079.9399 - val_FP: 26.0600 - val_FN: 46.8700\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0542 - Accuracy: 0.9810 - Precision: 0.9546 - Recall: 0.9456 - TP: 3188.6001 - TN: 5510.1201 - FP: 136.8800 - FN: 183.4000 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9417 - val_TP: 757.1300 - val_TN: 1080.0900 - val_FP: 25.9100 - val_FN: 46.8700\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0542 - Accuracy: 0.9812 - Precision: 0.9547 - Recall: 0.9456 - TP: 3188.6201 - TN: 5510.2100 - FP: 136.7900 - FN: 183.3800 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9418 - val_TP: 757.1700 - val_TN: 1079.3500 - val_FP: 26.6500 - val_FN: 46.8300\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0543 - Accuracy: 0.9812 - Precision: 0.9543 - Recall: 0.9457 - TP: 3188.9800 - TN: 5508.4502 - FP: 138.5500 - FN: 183.0200 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9417 - val_TP: 757.0900 - val_TN: 1080.1600 - val_FP: 25.8400 - val_FN: 46.9100\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0542 - Accuracy: 0.9812 - Precision: 0.9546 - Recall: 0.9456 - TP: 3188.6201 - TN: 5509.9502 - FP: 137.0500 - FN: 183.3800 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9417 - val_TP: 757.1600 - val_TN: 1080.0800 - val_FP: 25.9200 - val_FN: 46.8400\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0541 - Accuracy: 0.9812 - Precision: 0.9548 - Recall: 0.9456 - TP: 3188.5500 - TN: 5510.5601 - FP: 136.4400 - FN: 183.4500 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9416 - val_TP: 757.0800 - val_TN: 1080.1500 - val_FP: 25.8500 - val_FN: 46.9200\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0541 - Accuracy: 0.9812 - Precision: 0.9547 - Recall: 0.9456 - TP: 3188.5400 - TN: 5510.3999 - FP: 136.6000 - FN: 183.4600 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9417 - val_TP: 757.0900 - val_TN: 1080.1700 - val_FP: 25.8300 - val_FN: 46.9100\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0542 - Accuracy: 0.9812 - Precision: 0.9547 - Recall: 0.9456 - TP: 3188.5200 - TN: 5510.1499 - FP: 136.8500 - FN: 183.4800 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9417 - val_TP: 757.1100 - val_TN: 1080.1600 - val_FP: 25.8400 - val_FN: 46.8900\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0542 - Accuracy: 0.9812 - Precision: 0.9546 - Recall: 0.9457 - TP: 3188.7900 - TN: 5510.1201 - FP: 136.8800 - FN: 183.2100 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9417 - val_TP: 757.1000 - val_TN: 1079.9800 - val_FP: 26.0200 - val_FN: 46.9000\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0541 - Accuracy: 0.9812 - Precision: 0.9546 - Recall: 0.9457 - TP: 3188.8301 - TN: 5509.6802 - FP: 137.3200 - FN: 183.1700 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9613 - val_Recall: 0.9417 - val_TP: 757.1000 - val_TN: 1080.3600 - val_FP: 25.6400 - val_FN: 46.9000\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0540 - Accuracy: 0.9812 - Precision: 0.9549 - Recall: 0.9456 - TP: 3188.5601 - TN: 5511.3999 - FP: 135.6000 - FN: 183.4400 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9418 - val_TP: 757.1800 - val_TN: 1079.1899 - val_FP: 26.8100 - val_FN: 46.8200\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0541 - Accuracy: 0.9812 - Precision: 0.9548 - Recall: 0.9456 - TP: 3188.6101 - TN: 5510.9502 - FP: 136.0500 - FN: 183.3900 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9417 - val_TP: 757.1600 - val_TN: 1079.2400 - val_FP: 26.7600 - val_FN: 46.8400\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0541 - Accuracy: 0.9812 - Precision: 0.9547 - Recall: 0.9457 - TP: 3188.9399 - TN: 5510.2002 - FP: 136.8000 - FN: 183.0600 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9418 - val_TP: 757.1900 - val_TN: 1079.3600 - val_FP: 26.6400 - val_FN: 46.8100\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0540 - Accuracy: 0.9812 - Precision: 0.9545 - Recall: 0.9458 - TP: 3189.3101 - TN: 5509.3501 - FP: 137.6500 - FN: 182.6900 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9417 - val_TP: 757.1600 - val_TN: 1080.0699 - val_FP: 25.9300 - val_FN: 46.8400\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0540 - Accuracy: 0.9812 - Precision: 0.9547 - Recall: 0.9458 - TP: 3189.1399 - TN: 5510.5898 - FP: 136.4100 - FN: 182.8600 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9418 - val_TP: 757.1900 - val_TN: 1079.9399 - val_FP: 26.0600 - val_FN: 46.8100\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0540 - Accuracy: 0.9812 - Precision: 0.9548 - Recall: 0.9457 - TP: 3188.9700 - TN: 5510.8198 - FP: 136.1800 - FN: 183.0300 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9418 - val_TP: 757.2000 - val_TN: 1079.9800 - val_FP: 26.0200 - val_FN: 46.8000\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0540 - Accuracy: 0.9812 - Precision: 0.9545 - Recall: 0.9459 - TP: 3189.4299 - TN: 5509.6602 - FP: 137.3400 - FN: 182.5700 - val_loss: 0.0734 - val_Accuracy: 0.9775 - val_Precision: 0.9613 - val_Recall: 0.9417 - val_TP: 757.1500 - val_TN: 1080.3800 - val_FP: 25.6200 - val_FN: 46.8500\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0540 - Accuracy: 0.9812 - Precision: 0.9546 - Recall: 0.9458 - TP: 3189.1001 - TN: 5510.0000 - FP: 137.0000 - FN: 182.9000 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9417 - val_TP: 757.1600 - val_TN: 1080.2600 - val_FP: 25.7400 - val_FN: 46.8400\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0540 - Accuracy: 0.9813 - Precision: 0.9546 - Recall: 0.9458 - TP: 3189.3601 - TN: 5509.8501 - FP: 137.1500 - FN: 182.6400 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9613 - val_Recall: 0.9417 - val_TP: 757.1400 - val_TN: 1080.3101 - val_FP: 25.6900 - val_FN: 46.8600\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0541 - Accuracy: 0.9810 - Precision: 0.9550 - Recall: 0.9456 - TP: 3188.5300 - TN: 5511.9302 - FP: 135.0700 - FN: 183.4700 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9418 - val_TP: 757.1700 - val_TN: 1080.1500 - val_FP: 25.8500 - val_FN: 46.8300\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0539 - Accuracy: 0.9813 - Precision: 0.9547 - Recall: 0.9459 - TP: 3189.4700 - TN: 5510.0298 - FP: 136.9700 - FN: 182.5300 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9613 - val_Recall: 0.9417 - val_TP: 757.1300 - val_TN: 1080.4000 - val_FP: 25.6000 - val_FN: 46.8700\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0539 - Accuracy: 0.9812 - Precision: 0.9547 - Recall: 0.9458 - TP: 3189.3501 - TN: 5510.2202 - FP: 136.7800 - FN: 182.6500 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9418 - val_TP: 757.1700 - val_TN: 1080.2600 - val_FP: 25.7400 - val_FN: 46.8300\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0540 - Accuracy: 0.9812 - Precision: 0.9548 - Recall: 0.9458 - TP: 3189.1499 - TN: 5511.0898 - FP: 135.9100 - FN: 182.8500 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9418 - val_TP: 757.2100 - val_TN: 1080.1801 - val_FP: 25.8200 - val_FN: 46.7900\n",
      "Epoch 30/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0540 - Accuracy: 0.9812 - Precision: 0.9548 - Recall: 0.9459 - TP: 3189.4099 - TN: 5510.8301 - FP: 136.1700 - FN: 182.5900 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9418 - val_TP: 757.2300 - val_TN: 1080.0699 - val_FP: 25.9300 - val_FN: 46.7700\n",
      "Epoch 31/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0539 - Accuracy: 0.9812 - Precision: 0.9547 - Recall: 0.9459 - TP: 3189.4700 - TN: 5510.4199 - FP: 136.5800 - FN: 182.5300 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9418 - val_TP: 757.1900 - val_TN: 1080.2000 - val_FP: 25.8000 - val_FN: 46.8100\n",
      "Epoch 32/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0539 - Accuracy: 0.9813 - Precision: 0.9548 - Recall: 0.9459 - TP: 3189.5901 - TN: 5510.8901 - FP: 136.1100 - FN: 182.4100 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9418 - val_TP: 757.2100 - val_TN: 1080.1899 - val_FP: 25.8100 - val_FN: 46.7900\n",
      "Epoch 33/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0539 - Accuracy: 0.9813 - Precision: 0.9548 - Recall: 0.9459 - TP: 3189.5500 - TN: 5510.5498 - FP: 136.4500 - FN: 182.4500 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9613 - val_Recall: 0.9417 - val_TP: 757.1500 - val_TN: 1080.4000 - val_FP: 25.6000 - val_FN: 46.8500\n",
      "Epoch 34/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0538 - Accuracy: 0.9812 - Precision: 0.9547 - Recall: 0.9459 - TP: 3189.6101 - TN: 5510.4600 - FP: 136.5400 - FN: 182.3900 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9418 - val_TP: 757.1900 - val_TN: 1080.2600 - val_FP: 25.7400 - val_FN: 46.8100\n",
      "Epoch 35/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0539 - Accuracy: 0.9812 - Precision: 0.9551 - Recall: 0.9457 - TP: 3188.9700 - TN: 5512.1401 - FP: 134.8600 - FN: 183.0300 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9606 - val_Recall: 0.9418 - val_TP: 757.2100 - val_TN: 1079.5200 - val_FP: 26.4800 - val_FN: 46.7900\n",
      "Epoch 36/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0538 - Accuracy: 0.9813 - Precision: 0.9547 - Recall: 0.9460 - TP: 3189.7900 - TN: 5510.1401 - FP: 136.8600 - FN: 182.2100 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9418 - val_TP: 757.2100 - val_TN: 1080.2400 - val_FP: 25.7600 - val_FN: 46.7900\n",
      "Epoch 37/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0538 - Accuracy: 0.9813 - Precision: 0.9548 - Recall: 0.9459 - TP: 3189.4800 - TN: 5510.9302 - FP: 136.0700 - FN: 182.5200 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9419 - val_TP: 757.2500 - val_TN: 1080.0800 - val_FP: 25.9200 - val_FN: 46.7500\n",
      "Epoch 38/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0538 - Accuracy: 0.9812 - Precision: 0.9548 - Recall: 0.9459 - TP: 3189.6201 - TN: 5510.9302 - FP: 136.0700 - FN: 182.3800 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9418 - val_TP: 757.2400 - val_TN: 1080.1801 - val_FP: 25.8200 - val_FN: 46.7600\n",
      "Epoch 39/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0538 - Accuracy: 0.9812 - Precision: 0.9548 - Recall: 0.9459 - TP: 3189.7400 - TN: 5510.5298 - FP: 136.4700 - FN: 182.2600 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9613 - val_Recall: 0.9418 - val_TP: 757.2100 - val_TN: 1080.3101 - val_FP: 25.6900 - val_FN: 46.7900\n",
      "Epoch 40/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0538 - Accuracy: 0.9812 - Precision: 0.9549 - Recall: 0.9459 - TP: 3189.5901 - TN: 5511.3501 - FP: 135.6500 - FN: 182.4100 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9419 - val_TP: 757.2700 - val_TN: 1080.1200 - val_FP: 25.8800 - val_FN: 46.7300\n",
      "Epoch 41/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0537 - Accuracy: 0.9813 - Precision: 0.9548 - Recall: 0.9460 - TP: 3189.8501 - TN: 5510.6201 - FP: 136.3800 - FN: 182.1500 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9418 - val_TP: 757.2200 - val_TN: 1080.2000 - val_FP: 25.8000 - val_FN: 46.7800\n",
      "Epoch 42/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0537 - Accuracy: 0.9813 - Precision: 0.9547 - Recall: 0.9460 - TP: 3189.8799 - TN: 5510.3599 - FP: 136.6400 - FN: 182.1200 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9613 - val_Recall: 0.9418 - val_TP: 757.2200 - val_TN: 1080.3500 - val_FP: 25.6500 - val_FN: 46.7800\n",
      "Epoch 43/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0538 - Accuracy: 0.9813 - Precision: 0.9549 - Recall: 0.9460 - TP: 3189.7800 - TN: 5511.3398 - FP: 135.6600 - FN: 182.2200 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9614 - val_Recall: 0.9418 - val_TP: 757.1900 - val_TN: 1080.5100 - val_FP: 25.4900 - val_FN: 46.8100\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 5s 8ms/step - loss: 0.0541 - Accuracy: 0.9812 - Precision: 0.9551 - Recall: 0.9458 - TP: 3189.1001 - TN: 5513.2100 - FP: 133.7900 - FN: 182.9000 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9419 - val_TP: 757.3000 - val_TN: 1080.1100 - val_FP: 25.8900 - val_FN: 46.7000\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0540 - Accuracy: 0.9812 - Precision: 0.9546 - Recall: 0.9459 - TP: 3189.5601 - TN: 5510.1099 - FP: 136.8900 - FN: 182.4400 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9418 - val_TP: 757.2300 - val_TN: 1080.1700 - val_FP: 25.8300 - val_FN: 46.7700\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0540 - Accuracy: 0.9812 - Precision: 0.9546 - Recall: 0.9459 - TP: 3189.5500 - TN: 5510.0298 - FP: 136.9700 - FN: 182.4500 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9419 - val_TP: 757.2500 - val_TN: 1080.0601 - val_FP: 25.9400 - val_FN: 46.7500\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0539 - Accuracy: 0.9813 - Precision: 0.9546 - Recall: 0.9460 - TP: 3189.8301 - TN: 5509.7500 - FP: 137.2500 - FN: 182.1700 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9419 - val_TP: 757.2600 - val_TN: 1080.2200 - val_FP: 25.7800 - val_FN: 46.7400\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0540 - Accuracy: 0.9812 - Precision: 0.9548 - Recall: 0.9458 - TP: 3189.3501 - TN: 5510.7402 - FP: 136.2600 - FN: 182.6500 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9418 - val_TP: 757.2100 - val_TN: 1080.2900 - val_FP: 25.7100 - val_FN: 46.7900\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0539 - Accuracy: 0.9812 - Precision: 0.9548 - Recall: 0.9458 - TP: 3189.3799 - TN: 5510.8398 - FP: 136.1600 - FN: 182.6200 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9418 - val_TP: 757.1900 - val_TN: 1080.3000 - val_FP: 25.7000 - val_FN: 46.8100\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0539 - Accuracy: 0.9813 - Precision: 0.9546 - Recall: 0.9459 - TP: 3189.6499 - TN: 5510.0200 - FP: 136.9800 - FN: 182.3500 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9418 - val_TP: 757.2100 - val_TN: 1080.1500 - val_FP: 25.8500 - val_FN: 46.7900\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0539 - Accuracy: 0.9812 - Precision: 0.9546 - Recall: 0.9459 - TP: 3189.7100 - TN: 5510.0698 - FP: 136.9300 - FN: 182.2900 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9418 - val_TP: 757.2100 - val_TN: 1080.1801 - val_FP: 25.8200 - val_FN: 46.7900\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0539 - Accuracy: 0.9812 - Precision: 0.9547 - Recall: 0.9459 - TP: 3189.5300 - TN: 5510.3101 - FP: 136.6900 - FN: 182.4700 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9419 - val_TP: 757.2500 - val_TN: 1080.2700 - val_FP: 25.7300 - val_FN: 46.7500\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0538 - Accuracy: 0.9812 - Precision: 0.9548 - Recall: 0.9459 - TP: 3189.4700 - TN: 5510.6499 - FP: 136.3500 - FN: 182.5300 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9418 - val_TP: 757.2300 - val_TN: 1080.1200 - val_FP: 25.8800 - val_FN: 46.7700\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0539 - Accuracy: 0.9812 - Precision: 0.9547 - Recall: 0.9459 - TP: 3189.5500 - TN: 5510.4800 - FP: 136.5200 - FN: 182.4500 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9418 - val_TP: 757.2100 - val_TN: 1080.2800 - val_FP: 25.7200 - val_FN: 46.7900\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0538 - Accuracy: 0.9813 - Precision: 0.9549 - Recall: 0.9459 - TP: 3189.6001 - TN: 5511.2100 - FP: 135.7900 - FN: 182.4000 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9419 - val_TP: 757.2600 - val_TN: 1080.0800 - val_FP: 25.9200 - val_FN: 46.7400\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0538 - Accuracy: 0.9813 - Precision: 0.9549 - Recall: 0.9459 - TP: 3189.4099 - TN: 5511.2798 - FP: 135.7200 - FN: 182.5900 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9419 - val_TP: 757.2500 - val_TN: 1080.2000 - val_FP: 25.8000 - val_FN: 46.7500\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0538 - Accuracy: 0.9812 - Precision: 0.9549 - Recall: 0.9459 - TP: 3189.7000 - TN: 5511.0400 - FP: 135.9600 - FN: 182.3000 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9418 - val_TP: 757.2400 - val_TN: 1080.2800 - val_FP: 25.7200 - val_FN: 46.7600\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0538 - Accuracy: 0.9812 - Precision: 0.9548 - Recall: 0.9460 - TP: 3189.8201 - TN: 5510.8901 - FP: 136.1100 - FN: 182.1800 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9419 - val_TP: 757.2600 - val_TN: 1080.1801 - val_FP: 25.8200 - val_FN: 46.7400\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0538 - Accuracy: 0.9814 - Precision: 0.9548 - Recall: 0.9460 - TP: 3189.9299 - TN: 5510.6499 - FP: 136.3500 - FN: 182.0700 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9419 - val_TP: 757.2700 - val_TN: 1080.1000 - val_FP: 25.9000 - val_FN: 46.7300\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0538 - Accuracy: 0.9812 - Precision: 0.9548 - Recall: 0.9461 - TP: 3190.1201 - TN: 5510.6299 - FP: 136.3700 - FN: 181.8800 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9418 - val_TP: 757.2200 - val_TN: 1080.3000 - val_FP: 25.7000 - val_FN: 46.7800\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 0.0537 - Accuracy: 0.9812 - Precision: 0.9547 - Recall: 0.9460 - TP: 3189.9900 - TN: 5510.3999 - FP: 136.6000 - FN: 182.0100 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9613 - val_Recall: 0.9419 - val_TP: 757.2600 - val_TN: 1080.3900 - val_FP: 25.6100 - val_FN: 46.7400\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0538 - Accuracy: 0.9815 - Precision: 0.9550 - Recall: 0.9459 - TP: 3189.5801 - TN: 5511.9199 - FP: 135.0800 - FN: 182.4200 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9418 - val_TP: 757.2300 - val_TN: 1080.1899 - val_FP: 25.8100 - val_FN: 46.7700\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0538 - Accuracy: 0.9814 - Precision: 0.9549 - Recall: 0.9459 - TP: 3189.7000 - TN: 5511.0298 - FP: 135.9700 - FN: 182.3000 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9614 - val_Recall: 0.9419 - val_TP: 757.2500 - val_TN: 1080.4900 - val_FP: 25.5100 - val_FN: 46.7500\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0537 - Accuracy: 0.9812 - Precision: 0.9549 - Recall: 0.9460 - TP: 3190.0200 - TN: 5511.0400 - FP: 135.9600 - FN: 181.9800 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9613 - val_Recall: 0.9419 - val_TP: 757.2500 - val_TN: 1080.4000 - val_FP: 25.6000 - val_FN: 46.7500\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0537 - Accuracy: 0.9813 - Precision: 0.9549 - Recall: 0.9459 - TP: 3189.7300 - TN: 5511.3799 - FP: 135.6200 - FN: 182.2700 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9419 - val_TP: 757.2600 - val_TN: 1080.2600 - val_FP: 25.7400 - val_FN: 46.7400\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0537 - Accuracy: 0.9814 - Precision: 0.9550 - Recall: 0.9460 - TP: 3189.8799 - TN: 5511.3501 - FP: 135.6500 - FN: 182.1200 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9419 - val_TP: 757.2700 - val_TN: 1080.0699 - val_FP: 25.9300 - val_FN: 46.7300\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0537 - Accuracy: 0.9815 - Precision: 0.9548 - Recall: 0.9461 - TP: 3190.2900 - TN: 5510.6899 - FP: 136.3100 - FN: 181.7100 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9419 - val_TP: 757.2600 - val_TN: 1080.2800 - val_FP: 25.7200 - val_FN: 46.7400\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0537 - Accuracy: 0.9814 - Precision: 0.9551 - Recall: 0.9459 - TP: 3189.6499 - TN: 5512.5601 - FP: 134.4400 - FN: 182.3500 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9606 - val_Recall: 0.9419 - val_TP: 757.3000 - val_TN: 1079.5100 - val_FP: 26.4900 - val_FN: 46.7000\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0537 - Accuracy: 0.9814 - Precision: 0.9547 - Recall: 0.9461 - TP: 3190.2900 - TN: 5510.3301 - FP: 136.6700 - FN: 181.7100 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9419 - val_TP: 757.2800 - val_TN: 1080.1700 - val_FP: 25.8300 - val_FN: 46.7200\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0536 - Accuracy: 0.9815 - Precision: 0.9549 - Recall: 0.9460 - TP: 3190.0500 - TN: 5511.2798 - FP: 135.7200 - FN: 181.9500 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9419 - val_TP: 757.2800 - val_TN: 1080.2600 - val_FP: 25.7400 - val_FN: 46.7200\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0536 - Accuracy: 0.9815 - Precision: 0.9548 - Recall: 0.9461 - TP: 3190.3000 - TN: 5510.7598 - FP: 136.2400 - FN: 181.7000 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9613 - val_Recall: 0.9419 - val_TP: 757.2800 - val_TN: 1080.3300 - val_FP: 25.6700 - val_FN: 46.7200\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0536 - Accuracy: 0.9815 - Precision: 0.9550 - Recall: 0.9461 - TP: 3190.3799 - TN: 5511.4702 - FP: 135.5300 - FN: 181.6200 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9613 - val_Recall: 0.9419 - val_TP: 757.2700 - val_TN: 1080.3700 - val_FP: 25.6300 - val_FN: 46.7300\n",
      "Epoch 30/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0536 - Accuracy: 0.9815 - Precision: 0.9551 - Recall: 0.9460 - TP: 3190.0400 - TN: 5511.9800 - FP: 135.0200 - FN: 181.9600 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9419 - val_TP: 757.3000 - val_TN: 1080.3101 - val_FP: 25.6900 - val_FN: 46.7000\n",
      "Epoch 31/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0536 - Accuracy: 0.9816 - Precision: 0.9549 - Recall: 0.9461 - TP: 3190.3799 - TN: 5511.2402 - FP: 135.7600 - FN: 181.6200 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9613 - val_Recall: 0.9419 - val_TP: 757.2700 - val_TN: 1080.3500 - val_FP: 25.6500 - val_FN: 46.7300\n",
      "Epoch 32/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0536 - Accuracy: 0.9815 - Precision: 0.9549 - Recall: 0.9461 - TP: 3190.1101 - TN: 5511.1201 - FP: 135.8800 - FN: 181.8900 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9613 - val_Recall: 0.9419 - val_TP: 757.2600 - val_TN: 1080.4100 - val_FP: 25.5900 - val_FN: 46.7400\n",
      "Epoch 33/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0536 - Accuracy: 0.9814 - Precision: 0.9551 - Recall: 0.9460 - TP: 3190.0100 - TN: 5512.2500 - FP: 134.7500 - FN: 181.9900 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9420 - val_TP: 757.3500 - val_TN: 1080.1000 - val_FP: 25.9000 - val_FN: 46.6500\n",
      "Epoch 34/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0536 - Accuracy: 0.9816 - Precision: 0.9550 - Recall: 0.9461 - TP: 3190.3799 - TN: 5511.6001 - FP: 135.4000 - FN: 181.6200 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9421 - val_TP: 757.4300 - val_TN: 1079.4600 - val_FP: 26.5400 - val_FN: 46.5700\n",
      "Epoch 35/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0535 - Accuracy: 0.9814 - Precision: 0.9550 - Recall: 0.9461 - TP: 3190.2800 - TN: 5511.6899 - FP: 135.3100 - FN: 181.7200 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9421 - val_TP: 757.4200 - val_TN: 1079.3800 - val_FP: 26.6200 - val_FN: 46.5800\n",
      "Epoch 36/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0536 - Accuracy: 0.9816 - Precision: 0.9548 - Recall: 0.9462 - TP: 3190.7200 - TN: 5510.6099 - FP: 136.3900 - FN: 181.2800 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9614 - val_Recall: 0.9419 - val_TP: 757.3000 - val_TN: 1080.5200 - val_FP: 25.4800 - val_FN: 46.7000\n",
      "Epoch 37/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0535 - Accuracy: 0.9815 - Precision: 0.9551 - Recall: 0.9461 - TP: 3190.2500 - TN: 5512.2202 - FP: 134.7800 - FN: 181.7500 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9420 - val_TP: 757.3700 - val_TN: 1080.1600 - val_FP: 25.8400 - val_FN: 46.6300\n",
      "Epoch 38/60\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 0.0535 - Accuracy: 0.9815 - Precision: 0.9552 - Recall: 0.9461 - TP: 3190.0901 - TN: 5512.5898 - FP: 134.4100 - FN: 181.9100 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9420 - val_TP: 757.3800 - val_TN: 1080.2100 - val_FP: 25.7900 - val_FN: 46.6200\n",
      "Epoch 39/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0535 - Accuracy: 0.9817 - Precision: 0.9547 - Recall: 0.9463 - TP: 3191.0601 - TN: 5510.0498 - FP: 136.9500 - FN: 180.9400 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9420 - val_TP: 757.3800 - val_TN: 1080.2800 - val_FP: 25.7200 - val_FN: 46.6200\n",
      "Epoch 40/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0535 - Accuracy: 0.9815 - Precision: 0.9551 - Recall: 0.9462 - TP: 3190.4399 - TN: 5512.0498 - FP: 134.9500 - FN: 181.5600 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9613 - val_Recall: 0.9420 - val_TP: 757.3800 - val_TN: 1080.3400 - val_FP: 25.6600 - val_FN: 46.6200\n",
      "Epoch 41/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0535 - Accuracy: 0.9816 - Precision: 0.9552 - Recall: 0.9461 - TP: 3190.3201 - TN: 5512.3701 - FP: 134.6300 - FN: 181.6800 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9420 - val_TP: 757.3900 - val_TN: 1080.1801 - val_FP: 25.8200 - val_FN: 46.6100\n",
      "Epoch 42/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0535 - Accuracy: 0.9818 - Precision: 0.9549 - Recall: 0.9462 - TP: 3190.6001 - TN: 5511.0200 - FP: 135.9800 - FN: 181.4000 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9420 - val_TP: 757.3900 - val_TN: 1080.1899 - val_FP: 25.8100 - val_FN: 46.6100\n",
      "Epoch 43/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0534 - Accuracy: 0.9817 - Precision: 0.9549 - Recall: 0.9463 - TP: 3190.9199 - TN: 5511.0098 - FP: 135.9900 - FN: 181.0800 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9420 - val_TP: 757.3900 - val_TN: 1080.2800 - val_FP: 25.7200 - val_FN: 46.6100\n",
      "Epoch 44/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0534 - Accuracy: 0.9817 - Precision: 0.9552 - Recall: 0.9462 - TP: 3190.5901 - TN: 5512.4902 - FP: 134.5100 - FN: 181.4100 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9613 - val_Recall: 0.9420 - val_TP: 757.3700 - val_TN: 1080.3700 - val_FP: 25.6300 - val_FN: 46.6300\n",
      "Epoch 45/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0534 - Accuracy: 0.9818 - Precision: 0.9551 - Recall: 0.9462 - TP: 3190.6699 - TN: 5512.1401 - FP: 134.8600 - FN: 181.3300 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9420 - val_TP: 757.3900 - val_TN: 1080.1500 - val_FP: 25.8500 - val_FN: 46.6100\n",
      "Epoch 46/60\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 0.0534 - Accuracy: 0.9817 - Precision: 0.9551 - Recall: 0.9463 - TP: 3190.7900 - TN: 5511.8999 - FP: 135.1000 - FN: 181.2100 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9420 - val_TP: 757.4000 - val_TN: 1080.1700 - val_FP: 25.8300 - val_FN: 46.6000\n",
      "Epoch 47/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0534 - Accuracy: 0.9818 - Precision: 0.9550 - Recall: 0.9464 - TP: 3191.1101 - TN: 5511.4600 - FP: 135.5400 - FN: 180.8900 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9420 - val_TP: 757.4000 - val_TN: 1080.2400 - val_FP: 25.7600 - val_FN: 46.6000\n",
      "Epoch 48/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0534 - Accuracy: 0.9818 - Precision: 0.9551 - Recall: 0.9463 - TP: 3190.8601 - TN: 5512.1699 - FP: 134.8300 - FN: 181.1400 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9420 - val_TP: 757.4000 - val_TN: 1080.2500 - val_FP: 25.7500 - val_FN: 46.6000\n",
      "Epoch 49/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0534 - Accuracy: 0.9816 - Precision: 0.9551 - Recall: 0.9463 - TP: 3190.8601 - TN: 5512.2402 - FP: 134.7600 - FN: 181.1400 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9420 - val_TP: 757.4000 - val_TN: 1080.2100 - val_FP: 25.7900 - val_FN: 46.6000\n",
      "Epoch 50/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0533 - Accuracy: 0.9816 - Precision: 0.9549 - Recall: 0.9464 - TP: 3191.1799 - TN: 5510.9902 - FP: 136.0100 - FN: 180.8200 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9614 - val_Recall: 0.9420 - val_TP: 757.3400 - val_TN: 1080.4700 - val_FP: 25.5300 - val_FN: 46.6600\n",
      "Epoch 51/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0533 - Accuracy: 0.9817 - Precision: 0.9554 - Recall: 0.9462 - TP: 3190.5300 - TN: 5513.4800 - FP: 133.5200 - FN: 181.4700 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9420 - val_TP: 757.3600 - val_TN: 1080.2400 - val_FP: 25.7600 - val_FN: 46.6400\n",
      "Epoch 52/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0533 - Accuracy: 0.9816 - Precision: 0.9550 - Recall: 0.9464 - TP: 3191.1001 - TN: 5511.3701 - FP: 135.6300 - FN: 180.9000 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9614 - val_Recall: 0.9420 - val_TP: 757.3700 - val_TN: 1080.4399 - val_FP: 25.5600 - val_FN: 46.6300\n",
      "Epoch 53/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0533 - Accuracy: 0.9818 - Precision: 0.9553 - Recall: 0.9462 - TP: 3190.7300 - TN: 5512.8501 - FP: 134.1500 - FN: 181.2700 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9421 - val_TP: 757.4300 - val_TN: 1080.2600 - val_FP: 25.7400 - val_FN: 46.5700\n",
      "Epoch 54/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0533 - Accuracy: 0.9818 - Precision: 0.9550 - Recall: 0.9464 - TP: 3191.1799 - TN: 5511.3999 - FP: 135.6000 - FN: 180.8200 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9615 - val_Recall: 0.9420 - val_TP: 757.3500 - val_TN: 1080.5800 - val_FP: 25.4200 - val_FN: 46.6500\n",
      "Epoch 55/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0532 - Accuracy: 0.9817 - Precision: 0.9553 - Recall: 0.9463 - TP: 3191.0000 - TN: 5512.8701 - FP: 134.1300 - FN: 181.0000 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9420 - val_TP: 757.3900 - val_TN: 1080.2400 - val_FP: 25.7600 - val_FN: 46.6100\n",
      "Epoch 56/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0533 - Accuracy: 0.9817 - Precision: 0.9550 - Recall: 0.9464 - TP: 3191.2100 - TN: 5511.6099 - FP: 135.3900 - FN: 180.7900 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9613 - val_Recall: 0.9420 - val_TP: 757.4000 - val_TN: 1080.3500 - val_FP: 25.6500 - val_FN: 46.6000\n",
      "Epoch 57/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0532 - Accuracy: 0.9817 - Precision: 0.9553 - Recall: 0.9463 - TP: 3190.8799 - TN: 5513.1401 - FP: 133.8600 - FN: 181.1200 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9421 - val_TP: 757.4400 - val_TN: 1080.1801 - val_FP: 25.8200 - val_FN: 46.5600\n",
      "Epoch 58/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0533 - Accuracy: 0.9818 - Precision: 0.9551 - Recall: 0.9464 - TP: 3191.3301 - TN: 5511.7798 - FP: 135.2200 - FN: 180.6700 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9421 - val_TP: 757.4200 - val_TN: 1080.2800 - val_FP: 25.7200 - val_FN: 46.5800\n",
      "Epoch 59/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0532 - Accuracy: 0.9816 - Precision: 0.9551 - Recall: 0.9465 - TP: 3191.4800 - TN: 5512.0801 - FP: 134.9200 - FN: 180.5200 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9614 - val_Recall: 0.9420 - val_TP: 757.3900 - val_TN: 1080.4500 - val_FP: 25.5500 - val_FN: 46.6100\n",
      "Epoch 60/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0532 - Accuracy: 0.9817 - Precision: 0.9554 - Recall: 0.9464 - TP: 3191.2600 - TN: 5513.3599 - FP: 133.6400 - FN: 180.7400 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9421 - val_TP: 757.4300 - val_TN: 1080.1801 - val_FP: 25.8200 - val_FN: 46.5700\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 6s 13ms/step - loss: 0.0532 - Accuracy: 0.9817 - Precision: 0.9553 - Recall: 0.9464 - TP: 3191.2200 - TN: 5513.1499 - FP: 133.8500 - FN: 180.7800 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9613 - val_Recall: 0.9421 - val_TP: 757.4800 - val_TN: 1080.4100 - val_FP: 25.5900 - val_FN: 46.5200\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 0.0532 - Accuracy: 0.9818 - Precision: 0.9552 - Recall: 0.9465 - TP: 3191.5500 - TN: 5512.4502 - FP: 134.5500 - FN: 180.4500 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9613 - val_Recall: 0.9421 - val_TP: 757.4700 - val_TN: 1080.4200 - val_FP: 25.5800 - val_FN: 46.5300\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0532 - Accuracy: 0.9818 - Precision: 0.9551 - Recall: 0.9465 - TP: 3191.4600 - TN: 5511.9702 - FP: 135.0300 - FN: 180.5400 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9421 - val_TP: 757.4400 - val_TN: 1080.2800 - val_FP: 25.7200 - val_FN: 46.5600\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0532 - Accuracy: 0.9818 - Precision: 0.9552 - Recall: 0.9465 - TP: 3191.7000 - TN: 5512.6699 - FP: 134.3300 - FN: 180.3000 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9421 - val_TP: 757.4800 - val_TN: 1080.2300 - val_FP: 25.7700 - val_FN: 46.5200\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0532 - Accuracy: 0.9818 - Precision: 0.9552 - Recall: 0.9465 - TP: 3191.5100 - TN: 5512.4800 - FP: 134.5200 - FN: 180.4900 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9615 - val_Recall: 0.9421 - val_TP: 757.4100 - val_TN: 1080.5800 - val_FP: 25.4200 - val_FN: 46.5900\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0531 - Accuracy: 0.9818 - Precision: 0.9553 - Recall: 0.9465 - TP: 3191.4700 - TN: 5512.8599 - FP: 134.1400 - FN: 180.5300 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9421 - val_TP: 757.4500 - val_TN: 1080.3000 - val_FP: 25.7000 - val_FN: 46.5500\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0531 - Accuracy: 0.9819 - Precision: 0.9552 - Recall: 0.9466 - TP: 3191.7700 - TN: 5512.3501 - FP: 134.6500 - FN: 180.2300 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9613 - val_Recall: 0.9421 - val_TP: 757.4500 - val_TN: 1080.3700 - val_FP: 25.6300 - val_FN: 46.5500\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0531 - Accuracy: 0.9818 - Precision: 0.9554 - Recall: 0.9464 - TP: 3191.2300 - TN: 5513.7100 - FP: 133.2900 - FN: 180.7700 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9421 - val_TP: 757.4400 - val_TN: 1080.2500 - val_FP: 25.7500 - val_FN: 46.5600\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0531 - Accuracy: 0.9819 - Precision: 0.9550 - Recall: 0.9466 - TP: 3191.8999 - TN: 5511.7300 - FP: 135.2700 - FN: 180.1000 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9614 - val_Recall: 0.9421 - val_TP: 757.4200 - val_TN: 1080.5200 - val_FP: 25.4800 - val_FN: 46.5800\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0531 - Accuracy: 0.9819 - Precision: 0.9553 - Recall: 0.9465 - TP: 3191.6499 - TN: 5513.1401 - FP: 133.8600 - FN: 180.3500 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9613 - val_Recall: 0.9421 - val_TP: 757.4300 - val_TN: 1080.4100 - val_FP: 25.5900 - val_FN: 46.5700\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0531 - Accuracy: 0.9818 - Precision: 0.9552 - Recall: 0.9465 - TP: 3191.7400 - TN: 5512.3701 - FP: 134.6300 - FN: 180.2600 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9614 - val_Recall: 0.9421 - val_TP: 757.4400 - val_TN: 1080.4600 - val_FP: 25.5400 - val_FN: 46.5600\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0530 - Accuracy: 0.9815 - Precision: 0.9555 - Recall: 0.9464 - TP: 3191.2300 - TN: 5513.7100 - FP: 133.2900 - FN: 180.7700 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9613 - val_Recall: 0.9421 - val_TP: 757.4200 - val_TN: 1080.4301 - val_FP: 25.5700 - val_FN: 46.5800\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0531 - Accuracy: 0.9817 - Precision: 0.9554 - Recall: 0.9465 - TP: 3191.6001 - TN: 5513.2100 - FP: 133.7900 - FN: 180.4000 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9613 - val_Recall: 0.9421 - val_TP: 757.4100 - val_TN: 1080.4200 - val_FP: 25.5800 - val_FN: 46.5900\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0530 - Accuracy: 0.9819 - Precision: 0.9551 - Recall: 0.9466 - TP: 3191.9700 - TN: 5511.8301 - FP: 135.1700 - FN: 180.0300 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9614 - val_Recall: 0.9421 - val_TP: 757.4100 - val_TN: 1080.4800 - val_FP: 25.5200 - val_FN: 46.5900\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0530 - Accuracy: 0.9818 - Precision: 0.9554 - Recall: 0.9464 - TP: 3191.2500 - TN: 5513.6602 - FP: 133.3400 - FN: 180.7500 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9421 - val_TP: 757.4400 - val_TN: 1080.3199 - val_FP: 25.6800 - val_FN: 46.5600\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0530 - Accuracy: 0.9818 - Precision: 0.9553 - Recall: 0.9466 - TP: 3191.8301 - TN: 5512.6401 - FP: 134.3600 - FN: 180.1700 - val_loss: 0.0740 - val_Accuracy: 0.9780 - val_Precision: 0.9606 - val_Recall: 0.9421 - val_TP: 757.4700 - val_TN: 1079.5699 - val_FP: 26.4300 - val_FN: 46.5300\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0530 - Accuracy: 0.9818 - Precision: 0.9553 - Recall: 0.9465 - TP: 3191.7200 - TN: 5512.8198 - FP: 134.1800 - FN: 180.2800 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9421 - val_TP: 757.4300 - val_TN: 1080.3500 - val_FP: 25.6500 - val_FN: 46.5700\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0530 - Accuracy: 0.9818 - Precision: 0.9553 - Recall: 0.9465 - TP: 3191.7000 - TN: 5512.9800 - FP: 134.0200 - FN: 180.3000 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9421 - val_TP: 757.4400 - val_TN: 1080.2700 - val_FP: 25.7300 - val_FN: 46.5600\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0529 - Accuracy: 0.9817 - Precision: 0.9553 - Recall: 0.9466 - TP: 3191.8301 - TN: 5513.0898 - FP: 133.9100 - FN: 180.1700 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9613 - val_Recall: 0.9421 - val_TP: 757.4500 - val_TN: 1080.3600 - val_FP: 25.6400 - val_FN: 46.5500\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0530 - Accuracy: 0.9818 - Precision: 0.9553 - Recall: 0.9466 - TP: 3191.7900 - TN: 5512.8799 - FP: 134.1200 - FN: 180.2100 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9615 - val_Recall: 0.9421 - val_TP: 757.4300 - val_TN: 1080.5900 - val_FP: 25.4100 - val_FN: 46.5700\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0529 - Accuracy: 0.9817 - Precision: 0.9552 - Recall: 0.9466 - TP: 3191.9199 - TN: 5512.5200 - FP: 134.4800 - FN: 180.0800 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9615 - val_Recall: 0.9421 - val_TP: 757.4300 - val_TN: 1080.6000 - val_FP: 25.4000 - val_FN: 46.5700\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0529 - Accuracy: 0.9817 - Precision: 0.9557 - Recall: 0.9465 - TP: 3191.4700 - TN: 5514.8101 - FP: 132.1900 - FN: 180.5300 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9614 - val_Recall: 0.9421 - val_TP: 757.4300 - val_TN: 1080.4600 - val_FP: 25.5400 - val_FN: 46.5700\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 5s 9ms/step - loss: 0.0533 - Accuracy: 0.9819 - Precision: 0.9555 - Recall: 0.9462 - TP: 3190.6899 - TN: 5514.7300 - FP: 132.2700 - FN: 181.3100 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9422 - val_TP: 757.4900 - val_TN: 1079.4900 - val_FP: 26.5100 - val_FN: 46.5100\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0532 - Accuracy: 0.9818 - Precision: 0.9549 - Recall: 0.9466 - TP: 3191.8701 - TN: 5511.1802 - FP: 135.8200 - FN: 180.1300 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9613 - val_Recall: 0.9421 - val_TP: 757.4500 - val_TN: 1080.4000 - val_FP: 25.6000 - val_FN: 46.5500\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0531 - Accuracy: 0.9819 - Precision: 0.9553 - Recall: 0.9465 - TP: 3191.4800 - TN: 5513.2002 - FP: 133.8000 - FN: 180.5200 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9421 - val_TP: 757.4600 - val_TN: 1080.3101 - val_FP: 25.6900 - val_FN: 46.5400\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0531 - Accuracy: 0.9817 - Precision: 0.9554 - Recall: 0.9464 - TP: 3191.1299 - TN: 5513.2900 - FP: 133.7100 - FN: 180.8700 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9421 - val_TP: 757.4500 - val_TN: 1080.2500 - val_FP: 25.7500 - val_FN: 46.5500\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0532 - Accuracy: 0.9818 - Precision: 0.9549 - Recall: 0.9466 - TP: 3191.9900 - TN: 5510.8398 - FP: 136.1600 - FN: 180.0100 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9421 - val_TP: 757.4500 - val_TN: 1080.2800 - val_FP: 25.7200 - val_FN: 46.5500\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0531 - Accuracy: 0.9817 - Precision: 0.9553 - Recall: 0.9465 - TP: 3191.4500 - TN: 5513.0498 - FP: 133.9500 - FN: 180.5500 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9613 - val_Recall: 0.9421 - val_TP: 757.4200 - val_TN: 1080.4000 - val_FP: 25.6000 - val_FN: 46.5800\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0531 - Accuracy: 0.9817 - Precision: 0.9553 - Recall: 0.9464 - TP: 3191.4199 - TN: 5512.8599 - FP: 134.1400 - FN: 180.5800 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9421 - val_TP: 757.4600 - val_TN: 1080.1801 - val_FP: 25.8200 - val_FN: 46.5400\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0531 - Accuracy: 0.9819 - Precision: 0.9550 - Recall: 0.9466 - TP: 3192.0300 - TN: 5511.2100 - FP: 135.7900 - FN: 179.9700 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9615 - val_Recall: 0.9421 - val_TP: 757.4200 - val_TN: 1080.6400 - val_FP: 25.3600 - val_FN: 46.5800\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0530 - Accuracy: 0.9818 - Precision: 0.9551 - Recall: 0.9466 - TP: 3191.8799 - TN: 5512.0000 - FP: 135.0000 - FN: 180.1200 - val_loss: 0.0734 - val_Accuracy: 0.9775 - val_Precision: 0.9617 - val_Recall: 0.9421 - val_TP: 757.4100 - val_TN: 1080.7700 - val_FP: 25.2300 - val_FN: 46.5900\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0531 - Accuracy: 0.9819 - Precision: 0.9555 - Recall: 0.9465 - TP: 3191.4600 - TN: 5514.1602 - FP: 132.8400 - FN: 180.5400 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9613 - val_Recall: 0.9421 - val_TP: 757.4400 - val_TN: 1080.4200 - val_FP: 25.5800 - val_FN: 46.5600\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0530 - Accuracy: 0.9818 - Precision: 0.9555 - Recall: 0.9464 - TP: 3191.2600 - TN: 5514.1099 - FP: 132.8900 - FN: 180.7400 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9605 - val_Recall: 0.9421 - val_TP: 757.4500 - val_TN: 1079.4301 - val_FP: 26.5700 - val_FN: 46.5500\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0531 - Accuracy: 0.9818 - Precision: 0.9550 - Recall: 0.9466 - TP: 3191.8701 - TN: 5511.3901 - FP: 135.6100 - FN: 180.1300 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9421 - val_TP: 757.4200 - val_TN: 1080.3300 - val_FP: 25.6700 - val_FN: 46.5800\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0530 - Accuracy: 0.9816 - Precision: 0.9555 - Recall: 0.9464 - TP: 3191.3601 - TN: 5513.7402 - FP: 133.2600 - FN: 180.6400 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9613 - val_Recall: 0.9421 - val_TP: 757.4100 - val_TN: 1080.3600 - val_FP: 25.6400 - val_FN: 46.5900\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0530 - Accuracy: 0.9818 - Precision: 0.9551 - Recall: 0.9466 - TP: 3191.9700 - TN: 5512.0698 - FP: 134.9300 - FN: 180.0300 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9616 - val_Recall: 0.9421 - val_TP: 757.4100 - val_TN: 1080.6801 - val_FP: 25.3200 - val_FN: 46.5900\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0530 - Accuracy: 0.9817 - Precision: 0.9553 - Recall: 0.9465 - TP: 3191.7400 - TN: 5512.8198 - FP: 134.1800 - FN: 180.2600 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9615 - val_Recall: 0.9421 - val_TP: 757.4100 - val_TN: 1080.6500 - val_FP: 25.3500 - val_FN: 46.5900\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0530 - Accuracy: 0.9819 - Precision: 0.9552 - Recall: 0.9466 - TP: 3191.9299 - TN: 5512.1699 - FP: 134.8300 - FN: 180.0700 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9615 - val_Recall: 0.9420 - val_TP: 757.4000 - val_TN: 1080.6500 - val_FP: 25.3500 - val_FN: 46.6000\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0530 - Accuracy: 0.9817 - Precision: 0.9555 - Recall: 0.9464 - TP: 3191.1599 - TN: 5514.0000 - FP: 133.0000 - FN: 180.8400 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9614 - val_Recall: 0.9421 - val_TP: 757.4200 - val_TN: 1080.4600 - val_FP: 25.5400 - val_FN: 46.5800\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0530 - Accuracy: 0.9819 - Precision: 0.9552 - Recall: 0.9466 - TP: 3192.1001 - TN: 5512.6001 - FP: 134.4000 - FN: 179.9000 - val_loss: 0.0733 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9421 - val_TP: 757.4400 - val_TN: 1080.7700 - val_FP: 25.2300 - val_FN: 46.5600\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0529 - Accuracy: 0.9818 - Precision: 0.9555 - Recall: 0.9465 - TP: 3191.7200 - TN: 5513.6602 - FP: 133.3400 - FN: 180.2800 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9612 - val_Recall: 0.9421 - val_TP: 757.4800 - val_TN: 1080.3500 - val_FP: 25.6500 - val_FN: 46.5200\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0529 - Accuracy: 0.9817 - Precision: 0.9554 - Recall: 0.9466 - TP: 3191.7900 - TN: 5513.4702 - FP: 133.5300 - FN: 180.2100 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9612 - val_Recall: 0.9422 - val_TP: 757.4900 - val_TN: 1080.3300 - val_FP: 25.6700 - val_FN: 46.5100\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0529 - Accuracy: 0.9818 - Precision: 0.9552 - Recall: 0.9467 - TP: 3192.2000 - TN: 5512.5898 - FP: 134.4100 - FN: 179.8000 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9421 - val_TP: 757.4700 - val_TN: 1080.4500 - val_FP: 25.5500 - val_FN: 46.5300\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0529 - Accuracy: 0.9818 - Precision: 0.9555 - Recall: 0.9466 - TP: 3191.8799 - TN: 5513.6802 - FP: 133.3200 - FN: 180.1200 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9613 - val_Recall: 0.9421 - val_TP: 757.4800 - val_TN: 1080.4200 - val_FP: 25.5800 - val_FN: 46.5200\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0529 - Accuracy: 0.9818 - Precision: 0.9553 - Recall: 0.9466 - TP: 3192.0100 - TN: 5513.0801 - FP: 133.9200 - FN: 179.9900 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9422 - val_TP: 757.5000 - val_TN: 1080.4600 - val_FP: 25.5400 - val_FN: 46.5000\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0529 - Accuracy: 0.9817 - Precision: 0.9555 - Recall: 0.9465 - TP: 3191.7100 - TN: 5513.7798 - FP: 133.2200 - FN: 180.2900 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9421 - val_TP: 757.4800 - val_TN: 1080.4500 - val_FP: 25.5500 - val_FN: 46.5200\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0529 - Accuracy: 0.9818 - Precision: 0.9555 - Recall: 0.9466 - TP: 3191.7900 - TN: 5513.8799 - FP: 133.1200 - FN: 180.2100 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9607 - val_Recall: 0.9422 - val_TP: 757.5300 - val_TN: 1079.6600 - val_FP: 26.3400 - val_FN: 46.4700\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0529 - Accuracy: 0.9818 - Precision: 0.9552 - Recall: 0.9467 - TP: 3192.3501 - TN: 5512.2700 - FP: 134.7300 - FN: 179.6500 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9613 - val_Recall: 0.9422 - val_TP: 757.4900 - val_TN: 1080.4500 - val_FP: 25.5500 - val_FN: 46.5100\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0528 - Accuracy: 0.9816 - Precision: 0.9555 - Recall: 0.9466 - TP: 3191.8301 - TN: 5514.0098 - FP: 132.9900 - FN: 180.1700 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9613 - val_Recall: 0.9421 - val_TP: 757.4800 - val_TN: 1080.3700 - val_FP: 25.6300 - val_FN: 46.5200\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0528 - Accuracy: 0.9817 - Precision: 0.9552 - Recall: 0.9467 - TP: 3192.4099 - TN: 5512.5000 - FP: 134.5000 - FN: 179.5900 - val_loss: 0.0734 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9421 - val_TP: 757.4500 - val_TN: 1080.8600 - val_FP: 25.1400 - val_FN: 46.5500\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0528 - Accuracy: 0.9817 - Precision: 0.9555 - Recall: 0.9466 - TP: 3191.7900 - TN: 5514.0601 - FP: 132.9400 - FN: 180.2100 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9613 - val_Recall: 0.9422 - val_TP: 757.5000 - val_TN: 1080.3700 - val_FP: 25.6300 - val_FN: 46.5000\n",
      "Epoch 30/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0528 - Accuracy: 0.9817 - Precision: 0.9555 - Recall: 0.9466 - TP: 3192.1001 - TN: 5513.6899 - FP: 133.3100 - FN: 179.9000 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9612 - val_Recall: 0.9422 - val_TP: 757.5000 - val_TN: 1080.3500 - val_FP: 25.6500 - val_FN: 46.5000\n",
      "Epoch 31/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0528 - Accuracy: 0.9817 - Precision: 0.9555 - Recall: 0.9466 - TP: 3191.9800 - TN: 5513.7598 - FP: 133.2400 - FN: 180.0200 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9613 - val_Recall: 0.9422 - val_TP: 757.5100 - val_TN: 1080.3700 - val_FP: 25.6300 - val_FN: 46.4900\n",
      "Epoch 32/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0528 - Accuracy: 0.9817 - Precision: 0.9553 - Recall: 0.9467 - TP: 3192.3701 - TN: 5512.8398 - FP: 134.1600 - FN: 179.6300 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9613 - val_Recall: 0.9422 - val_TP: 757.5100 - val_TN: 1080.4399 - val_FP: 25.5600 - val_FN: 46.4900\n",
      "Epoch 33/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0527 - Accuracy: 0.9817 - Precision: 0.9556 - Recall: 0.9466 - TP: 3192.0400 - TN: 5514.4399 - FP: 132.5600 - FN: 179.9600 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9613 - val_Recall: 0.9422 - val_TP: 757.5100 - val_TN: 1080.3500 - val_FP: 25.6500 - val_FN: 46.4900\n",
      "Epoch 34/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0527 - Accuracy: 0.9818 - Precision: 0.9552 - Recall: 0.9468 - TP: 3192.6201 - TN: 5512.2598 - FP: 134.7400 - FN: 179.3800 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9422 - val_TP: 757.5100 - val_TN: 1080.5800 - val_FP: 25.4200 - val_FN: 46.4900\n",
      "Epoch 35/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0527 - Accuracy: 0.9817 - Precision: 0.9554 - Recall: 0.9467 - TP: 3192.3799 - TN: 5513.6001 - FP: 133.4000 - FN: 179.6200 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9421 - val_TP: 757.4800 - val_TN: 1080.6500 - val_FP: 25.3500 - val_FN: 46.5200\n",
      "Epoch 36/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0527 - Accuracy: 0.9817 - Precision: 0.9556 - Recall: 0.9467 - TP: 3192.1499 - TN: 5514.2300 - FP: 132.7700 - FN: 179.8500 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9613 - val_Recall: 0.9422 - val_TP: 757.4900 - val_TN: 1080.4500 - val_FP: 25.5500 - val_FN: 46.5100\n",
      "Epoch 37/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0527 - Accuracy: 0.9818 - Precision: 0.9556 - Recall: 0.9467 - TP: 3192.2600 - TN: 5514.0898 - FP: 132.9100 - FN: 179.7400 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9612 - val_Recall: 0.9422 - val_TP: 757.5500 - val_TN: 1080.3500 - val_FP: 25.6500 - val_FN: 46.4500\n",
      "Epoch 38/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0527 - Accuracy: 0.9817 - Precision: 0.9556 - Recall: 0.9466 - TP: 3192.0701 - TN: 5514.0698 - FP: 132.9300 - FN: 179.9300 - val_loss: 0.0740 - val_Accuracy: 0.9780 - val_Precision: 0.9609 - val_Recall: 0.9422 - val_TP: 757.5000 - val_TN: 1079.8500 - val_FP: 26.1500 - val_FN: 46.5000\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 9ms/step - loss: 0.0531 - Accuracy: 0.9816 - Precision: 0.9561 - Recall: 0.9463 - TP: 3190.8201 - TN: 5517.2598 - FP: 129.7400 - FN: 181.1800 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9421 - val_TP: 757.4800 - val_TN: 1080.4900 - val_FP: 25.5100 - val_FN: 46.5200\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0529 - Accuracy: 0.9818 - Precision: 0.9554 - Recall: 0.9465 - TP: 3191.7500 - TN: 5513.6299 - FP: 133.3700 - FN: 180.2500 - val_loss: 0.0740 - val_Accuracy: 0.9780 - val_Precision: 0.9606 - val_Recall: 0.9422 - val_TP: 757.5300 - val_TN: 1079.5601 - val_FP: 26.4400 - val_FN: 46.4700\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0529 - Accuracy: 0.9818 - Precision: 0.9552 - Recall: 0.9466 - TP: 3192.0300 - TN: 5512.6699 - FP: 134.3300 - FN: 179.9700 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9421 - val_TP: 757.4800 - val_TN: 1080.5000 - val_FP: 25.5000 - val_FN: 46.5200\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0530 - Accuracy: 0.9818 - Precision: 0.9553 - Recall: 0.9466 - TP: 3191.8101 - TN: 5512.8901 - FP: 134.1100 - FN: 180.1900 - val_loss: 0.0734 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9421 - val_TP: 757.4600 - val_TN: 1080.7300 - val_FP: 25.2700 - val_FN: 46.5400\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0529 - Accuracy: 0.9817 - Precision: 0.9554 - Recall: 0.9466 - TP: 3191.8799 - TN: 5513.6001 - FP: 133.4000 - FN: 180.1200 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9611 - val_Recall: 0.9422 - val_TP: 757.5000 - val_TN: 1080.2200 - val_FP: 25.7800 - val_FN: 46.5000\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0529 - Accuracy: 0.9817 - Precision: 0.9552 - Recall: 0.9467 - TP: 3192.3301 - TN: 5512.5601 - FP: 134.4400 - FN: 179.6700 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9421 - val_TP: 757.4700 - val_TN: 1080.5400 - val_FP: 25.4600 - val_FN: 46.5300\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0528 - Accuracy: 0.9818 - Precision: 0.9554 - Recall: 0.9466 - TP: 3191.8101 - TN: 5513.6299 - FP: 133.3700 - FN: 180.1900 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9421 - val_TP: 757.4700 - val_TN: 1080.4600 - val_FP: 25.5400 - val_FN: 46.5300\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0528 - Accuracy: 0.9818 - Precision: 0.9554 - Recall: 0.9467 - TP: 3192.2900 - TN: 5513.5498 - FP: 133.4500 - FN: 179.7100 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9421 - val_TP: 757.4800 - val_TN: 1080.4800 - val_FP: 25.5200 - val_FN: 46.5200\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0528 - Accuracy: 0.9818 - Precision: 0.9553 - Recall: 0.9467 - TP: 3192.2600 - TN: 5513.1602 - FP: 133.8400 - FN: 179.7400 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9612 - val_Recall: 0.9422 - val_TP: 757.5000 - val_TN: 1080.3500 - val_FP: 25.6500 - val_FN: 46.5000\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0528 - Accuracy: 0.9817 - Precision: 0.9554 - Recall: 0.9467 - TP: 3192.2000 - TN: 5513.4902 - FP: 133.5100 - FN: 179.8000 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9612 - val_Recall: 0.9422 - val_TP: 757.4900 - val_TN: 1080.3101 - val_FP: 25.6900 - val_FN: 46.5100\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0528 - Accuracy: 0.9817 - Precision: 0.9555 - Recall: 0.9466 - TP: 3191.8701 - TN: 5513.7998 - FP: 133.2000 - FN: 180.1300 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9421 - val_TP: 757.4700 - val_TN: 1080.5699 - val_FP: 25.4300 - val_FN: 46.5300\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0528 - Accuracy: 0.9818 - Precision: 0.9553 - Recall: 0.9467 - TP: 3192.2400 - TN: 5513.1802 - FP: 133.8200 - FN: 179.7600 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9421 - val_TP: 757.4600 - val_TN: 1080.4900 - val_FP: 25.5100 - val_FN: 46.5400\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0528 - Accuracy: 0.9818 - Precision: 0.9557 - Recall: 0.9466 - TP: 3191.8101 - TN: 5514.5801 - FP: 132.4200 - FN: 180.1900 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9612 - val_Recall: 0.9422 - val_TP: 757.4900 - val_TN: 1080.2900 - val_FP: 25.7100 - val_FN: 46.5100\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0527 - Accuracy: 0.9818 - Precision: 0.9553 - Recall: 0.9467 - TP: 3192.3799 - TN: 5512.6899 - FP: 134.3100 - FN: 179.6200 - val_loss: 0.0734 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9422 - val_TP: 757.5100 - val_TN: 1080.7800 - val_FP: 25.2200 - val_FN: 46.4900\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0527 - Accuracy: 0.9819 - Precision: 0.9555 - Recall: 0.9467 - TP: 3192.3101 - TN: 5513.8701 - FP: 133.1300 - FN: 179.6900 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9613 - val_Recall: 0.9422 - val_TP: 757.5100 - val_TN: 1080.3700 - val_FP: 25.6300 - val_FN: 46.4900\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0527 - Accuracy: 0.9818 - Precision: 0.9554 - Recall: 0.9468 - TP: 3192.4500 - TN: 5513.1602 - FP: 133.8400 - FN: 179.5500 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9422 - val_TP: 757.5000 - val_TN: 1080.4900 - val_FP: 25.5100 - val_FN: 46.5000\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0527 - Accuracy: 0.9817 - Precision: 0.9554 - Recall: 0.9468 - TP: 3192.5300 - TN: 5513.5498 - FP: 133.4500 - FN: 179.4700 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9613 - val_Recall: 0.9422 - val_TP: 757.5000 - val_TN: 1080.3800 - val_FP: 25.6200 - val_FN: 46.5000\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0527 - Accuracy: 0.9818 - Precision: 0.9554 - Recall: 0.9468 - TP: 3192.5000 - TN: 5513.6201 - FP: 133.3800 - FN: 179.5000 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9422 - val_TP: 757.5100 - val_TN: 1080.5800 - val_FP: 25.4200 - val_FN: 46.4900\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0527 - Accuracy: 0.9818 - Precision: 0.9555 - Recall: 0.9467 - TP: 3192.3799 - TN: 5513.9702 - FP: 133.0300 - FN: 179.6200 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9422 - val_TP: 757.5400 - val_TN: 1080.5300 - val_FP: 25.4700 - val_FN: 46.4600\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0527 - Accuracy: 0.9817 - Precision: 0.9557 - Recall: 0.9466 - TP: 3192.0601 - TN: 5514.9302 - FP: 132.0700 - FN: 179.9400 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9612 - val_Recall: 0.9422 - val_TP: 757.5500 - val_TN: 1080.2900 - val_FP: 25.7100 - val_FN: 46.4500\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0528 - Accuracy: 0.9819 - Precision: 0.9551 - Recall: 0.9469 - TP: 3192.8899 - TN: 5511.5098 - FP: 135.4900 - FN: 179.1100 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9422 - val_TP: 757.5100 - val_TN: 1080.5000 - val_FP: 25.5000 - val_FN: 46.4900\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0526 - Accuracy: 0.9819 - Precision: 0.9556 - Recall: 0.9467 - TP: 3192.2400 - TN: 5514.1802 - FP: 132.8200 - FN: 179.7600 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9422 - val_TP: 757.5000 - val_TN: 1080.8400 - val_FP: 25.1600 - val_FN: 46.5000\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0526 - Accuracy: 0.9818 - Precision: 0.9555 - Recall: 0.9468 - TP: 3192.6101 - TN: 5513.6899 - FP: 133.3100 - FN: 179.3900 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9422 - val_TP: 757.5300 - val_TN: 1080.7100 - val_FP: 25.2900 - val_FN: 46.4700\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0526 - Accuracy: 0.9817 - Precision: 0.9556 - Recall: 0.9467 - TP: 3192.4299 - TN: 5514.4502 - FP: 132.5500 - FN: 179.5700 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9422 - val_TP: 757.5300 - val_TN: 1080.4900 - val_FP: 25.5100 - val_FN: 46.4700\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0527 - Accuracy: 0.9818 - Precision: 0.9553 - Recall: 0.9469 - TP: 3192.9099 - TN: 5512.5801 - FP: 134.4200 - FN: 179.0900 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9422 - val_TP: 757.5200 - val_TN: 1080.8101 - val_FP: 25.1900 - val_FN: 46.4800\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0526 - Accuracy: 0.9818 - Precision: 0.9555 - Recall: 0.9468 - TP: 3192.7500 - TN: 5513.9102 - FP: 133.0900 - FN: 179.2500 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9422 - val_TP: 757.5000 - val_TN: 1080.8600 - val_FP: 25.1400 - val_FN: 46.5000\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0526 - Accuracy: 0.9818 - Precision: 0.9556 - Recall: 0.9468 - TP: 3192.4500 - TN: 5514.4399 - FP: 132.5600 - FN: 179.5500 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9422 - val_TP: 757.5200 - val_TN: 1080.6200 - val_FP: 25.3800 - val_FN: 46.4800\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0525 - Accuracy: 0.9818 - Precision: 0.9557 - Recall: 0.9468 - TP: 3192.5300 - TN: 5514.5200 - FP: 132.4800 - FN: 179.4700 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9422 - val_TP: 757.5300 - val_TN: 1080.5400 - val_FP: 25.4600 - val_FN: 46.4700\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0525 - Accuracy: 0.9818 - Precision: 0.9556 - Recall: 0.9469 - TP: 3192.8401 - TN: 5514.1099 - FP: 132.8900 - FN: 179.1600 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9423 - val_TP: 757.5700 - val_TN: 1080.7000 - val_FP: 25.3000 - val_FN: 46.4300\n",
      "Epoch 30/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0526 - Accuracy: 0.9818 - Precision: 0.9556 - Recall: 0.9468 - TP: 3192.7000 - TN: 5514.2798 - FP: 132.7200 - FN: 179.3000 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9422 - val_TP: 757.5200 - val_TN: 1080.5699 - val_FP: 25.4300 - val_FN: 46.4800\n",
      "Epoch 31/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0525 - Accuracy: 0.9818 - Precision: 0.9555 - Recall: 0.9469 - TP: 3192.9500 - TN: 5513.7402 - FP: 133.2600 - FN: 179.0500 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9423 - val_TP: 757.6100 - val_TN: 1080.7500 - val_FP: 25.2500 - val_FN: 46.3900\n",
      "Epoch 32/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0525 - Accuracy: 0.9817 - Precision: 0.9556 - Recall: 0.9469 - TP: 3192.8401 - TN: 5514.2700 - FP: 132.7300 - FN: 179.1600 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9423 - val_TP: 757.5900 - val_TN: 1080.5300 - val_FP: 25.4700 - val_FN: 46.4100\n",
      "Epoch 33/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0525 - Accuracy: 0.9817 - Precision: 0.9554 - Recall: 0.9470 - TP: 3193.3501 - TN: 5513.2900 - FP: 133.7100 - FN: 178.6500 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9423 - val_TP: 757.5900 - val_TN: 1080.7200 - val_FP: 25.2800 - val_FN: 46.4100\n",
      "Epoch 34/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0524 - Accuracy: 0.9818 - Precision: 0.9557 - Recall: 0.9469 - TP: 3192.8501 - TN: 5514.7500 - FP: 132.2500 - FN: 179.1500 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9423 - val_TP: 757.6000 - val_TN: 1080.6899 - val_FP: 25.3100 - val_FN: 46.4000\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 5s 10ms/step - loss: 0.0529 - Accuracy: 0.9817 - Precision: 0.9559 - Recall: 0.9465 - TP: 3191.6699 - TN: 5516.6699 - FP: 130.3300 - FN: 180.3300 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9422 - val_TP: 757.5200 - val_TN: 1080.4700 - val_FP: 25.5300 - val_FN: 46.4800\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0528 - Accuracy: 0.9817 - Precision: 0.9556 - Recall: 0.9466 - TP: 3192.0801 - TN: 5514.5000 - FP: 132.5000 - FN: 179.9200 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9422 - val_TP: 757.5000 - val_TN: 1080.6000 - val_FP: 25.4000 - val_FN: 46.5000\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0527 - Accuracy: 0.9818 - Precision: 0.9554 - Recall: 0.9468 - TP: 3192.5400 - TN: 5513.2500 - FP: 133.7500 - FN: 179.4600 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9422 - val_TP: 757.5000 - val_TN: 1080.6300 - val_FP: 25.3700 - val_FN: 46.5000\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0527 - Accuracy: 0.9818 - Precision: 0.9556 - Recall: 0.9467 - TP: 3192.4199 - TN: 5514.5801 - FP: 132.4200 - FN: 179.5800 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9613 - val_Recall: 0.9422 - val_TP: 757.5500 - val_TN: 1080.4600 - val_FP: 25.5400 - val_FN: 46.4500\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0527 - Accuracy: 0.9818 - Precision: 0.9554 - Recall: 0.9468 - TP: 3192.4700 - TN: 5513.2700 - FP: 133.7300 - FN: 179.5300 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9613 - val_Recall: 0.9422 - val_TP: 757.5300 - val_TN: 1080.4399 - val_FP: 25.5600 - val_FN: 46.4700\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0527 - Accuracy: 0.9817 - Precision: 0.9554 - Recall: 0.9468 - TP: 3192.6899 - TN: 5513.4199 - FP: 133.5800 - FN: 179.3100 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9422 - val_TP: 757.5500 - val_TN: 1080.4900 - val_FP: 25.5100 - val_FN: 46.4500\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0527 - Accuracy: 0.9818 - Precision: 0.9554 - Recall: 0.9468 - TP: 3192.4900 - TN: 5513.1499 - FP: 133.8500 - FN: 179.5100 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9422 - val_TP: 757.5100 - val_TN: 1080.6300 - val_FP: 25.3700 - val_FN: 46.4900\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0526 - Accuracy: 0.9817 - Precision: 0.9555 - Recall: 0.9468 - TP: 3192.5400 - TN: 5513.9800 - FP: 133.0200 - FN: 179.4600 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9422 - val_TP: 757.5000 - val_TN: 1080.6500 - val_FP: 25.3500 - val_FN: 46.5000\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0526 - Accuracy: 0.9817 - Precision: 0.9557 - Recall: 0.9466 - TP: 3192.0400 - TN: 5514.9399 - FP: 132.0600 - FN: 179.9600 - val_loss: 0.0742 - val_Accuracy: 0.9780 - val_Precision: 0.9606 - val_Recall: 0.9423 - val_TP: 757.6000 - val_TN: 1079.5601 - val_FP: 26.4400 - val_FN: 46.4000\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0526 - Accuracy: 0.9818 - Precision: 0.9553 - Recall: 0.9469 - TP: 3192.9500 - TN: 5512.9800 - FP: 134.0200 - FN: 179.0500 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9422 - val_TP: 757.5600 - val_TN: 1080.5400 - val_FP: 25.4600 - val_FN: 46.4400\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0525 - Accuracy: 0.9818 - Precision: 0.9557 - Recall: 0.9467 - TP: 3192.3000 - TN: 5514.9902 - FP: 132.0100 - FN: 179.7000 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9612 - val_Recall: 0.9422 - val_TP: 757.5500 - val_TN: 1080.3500 - val_FP: 25.6500 - val_FN: 46.4500\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0526 - Accuracy: 0.9818 - Precision: 0.9554 - Recall: 0.9468 - TP: 3192.7400 - TN: 5513.3301 - FP: 133.6700 - FN: 179.2600 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9613 - val_Recall: 0.9423 - val_TP: 757.6100 - val_TN: 1080.4600 - val_FP: 25.5400 - val_FN: 46.3900\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0526 - Accuracy: 0.9817 - Precision: 0.9554 - Recall: 0.9468 - TP: 3192.7300 - TN: 5513.6201 - FP: 133.3800 - FN: 179.2700 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9608 - val_Recall: 0.9423 - val_TP: 757.6200 - val_TN: 1079.8199 - val_FP: 26.1800 - val_FN: 46.3800\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0526 - Accuracy: 0.9818 - Precision: 0.9554 - Recall: 0.9469 - TP: 3192.9600 - TN: 5513.3301 - FP: 133.6700 - FN: 179.0400 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9613 - val_Recall: 0.9423 - val_TP: 757.6200 - val_TN: 1080.4000 - val_FP: 25.6000 - val_FN: 46.3800\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0526 - Accuracy: 0.9818 - Precision: 0.9554 - Recall: 0.9469 - TP: 3193.1101 - TN: 5513.3198 - FP: 133.6800 - FN: 178.8900 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9423 - val_TP: 757.5900 - val_TN: 1080.7400 - val_FP: 25.2600 - val_FN: 46.4100\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0526 - Accuracy: 0.9818 - Precision: 0.9556 - Recall: 0.9468 - TP: 3192.5300 - TN: 5514.5000 - FP: 132.5000 - FN: 179.4700 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9423 - val_TP: 757.6100 - val_TN: 1080.5500 - val_FP: 25.4500 - val_FN: 46.3900\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0525 - Accuracy: 0.9819 - Precision: 0.9553 - Recall: 0.9470 - TP: 3193.4399 - TN: 5513.1401 - FP: 133.8600 - FN: 178.5600 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9423 - val_TP: 757.5900 - val_TN: 1080.8300 - val_FP: 25.1700 - val_FN: 46.4100\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0525 - Accuracy: 0.9817 - Precision: 0.9558 - Recall: 0.9467 - TP: 3192.4399 - TN: 5515.2300 - FP: 131.7700 - FN: 179.5600 - val_loss: 0.0740 - val_Accuracy: 0.9780 - val_Precision: 0.9608 - val_Recall: 0.9423 - val_TP: 757.6200 - val_TN: 1079.8101 - val_FP: 26.1900 - val_FN: 46.3800\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0525 - Accuracy: 0.9818 - Precision: 0.9555 - Recall: 0.9469 - TP: 3193.0000 - TN: 5513.5801 - FP: 133.4200 - FN: 179.0000 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9423 - val_TP: 757.6200 - val_TN: 1080.5400 - val_FP: 25.4600 - val_FN: 46.3800\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0525 - Accuracy: 0.9818 - Precision: 0.9555 - Recall: 0.9469 - TP: 3192.9600 - TN: 5513.8301 - FP: 133.1700 - FN: 179.0400 - val_loss: 0.0734 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9423 - val_TP: 757.6100 - val_TN: 1080.8500 - val_FP: 25.1500 - val_FN: 46.3900\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0524 - Accuracy: 0.9818 - Precision: 0.9558 - Recall: 0.9468 - TP: 3192.5801 - TN: 5515.4702 - FP: 131.5300 - FN: 179.4200 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9424 - val_TP: 757.6500 - val_TN: 1080.5000 - val_FP: 25.5000 - val_FN: 46.3500\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0525 - Accuracy: 0.9818 - Precision: 0.9557 - Recall: 0.9470 - TP: 3193.1499 - TN: 5514.7598 - FP: 132.2400 - FN: 178.8500 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9613 - val_Recall: 0.9424 - val_TP: 757.6600 - val_TN: 1080.3800 - val_FP: 25.6200 - val_FN: 46.3400\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0524 - Accuracy: 0.9817 - Precision: 0.9555 - Recall: 0.9470 - TP: 3193.1499 - TN: 5513.8901 - FP: 133.1100 - FN: 178.8500 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9423 - val_TP: 757.6200 - val_TN: 1080.5300 - val_FP: 25.4700 - val_FN: 46.3800\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0524 - Accuracy: 0.9818 - Precision: 0.9557 - Recall: 0.9469 - TP: 3192.9900 - TN: 5514.5801 - FP: 132.4200 - FN: 179.0100 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9613 - val_Recall: 0.9423 - val_TP: 757.6300 - val_TN: 1080.4100 - val_FP: 25.5900 - val_FN: 46.3700\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0524 - Accuracy: 0.9816 - Precision: 0.9556 - Recall: 0.9469 - TP: 3192.9800 - TN: 5514.5098 - FP: 132.4900 - FN: 179.0200 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9423 - val_TP: 757.6100 - val_TN: 1080.7600 - val_FP: 25.2400 - val_FN: 46.3900\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0524 - Accuracy: 0.9818 - Precision: 0.9555 - Recall: 0.9470 - TP: 3193.2800 - TN: 5514.0098 - FP: 132.9900 - FN: 178.7200 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9423 - val_TP: 757.6200 - val_TN: 1080.6100 - val_FP: 25.3900 - val_FN: 46.3800\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0523 - Accuracy: 0.9817 - Precision: 0.9558 - Recall: 0.9469 - TP: 3192.9900 - TN: 5515.4600 - FP: 131.5400 - FN: 179.0100 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9613 - val_Recall: 0.9424 - val_TP: 757.6600 - val_TN: 1080.4500 - val_FP: 25.5500 - val_FN: 46.3400\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0524 - Accuracy: 0.9818 - Precision: 0.9554 - Recall: 0.9471 - TP: 3193.6101 - TN: 5513.1802 - FP: 133.8200 - FN: 178.3900 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9423 - val_TP: 757.6400 - val_TN: 1080.6100 - val_FP: 25.3900 - val_FN: 46.3600\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0523 - Accuracy: 0.9816 - Precision: 0.9559 - Recall: 0.9469 - TP: 3192.9299 - TN: 5515.4800 - FP: 131.5200 - FN: 179.0700 - val_loss: 0.0740 - val_Accuracy: 0.9780 - val_Precision: 0.9607 - val_Recall: 0.9424 - val_TP: 757.6800 - val_TN: 1079.7500 - val_FP: 26.2500 - val_FN: 46.3200\n",
      "Epoch 30/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0524 - Accuracy: 0.9816 - Precision: 0.9554 - Recall: 0.9471 - TP: 3193.5601 - TN: 5513.3301 - FP: 133.6700 - FN: 178.4400 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9423 - val_TP: 757.6400 - val_TN: 1080.6801 - val_FP: 25.3200 - val_FN: 46.3600\n",
      "Epoch 31/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0523 - Accuracy: 0.9819 - Precision: 0.9556 - Recall: 0.9470 - TP: 3193.3999 - TN: 5514.2598 - FP: 132.7400 - FN: 178.6000 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9424 - val_TP: 757.6800 - val_TN: 1080.6899 - val_FP: 25.3100 - val_FN: 46.3200\n",
      "Epoch 32/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0523 - Accuracy: 0.9817 - Precision: 0.9559 - Recall: 0.9469 - TP: 3192.7900 - TN: 5515.8301 - FP: 131.1700 - FN: 179.2100 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9612 - val_Recall: 0.9424 - val_TP: 757.7000 - val_TN: 1080.3600 - val_FP: 25.6400 - val_FN: 46.3000\n",
      "Epoch 33/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0523 - Accuracy: 0.9818 - Precision: 0.9554 - Recall: 0.9472 - TP: 3193.8999 - TN: 5513.2598 - FP: 133.7400 - FN: 178.1000 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9424 - val_TP: 757.6900 - val_TN: 1080.8199 - val_FP: 25.1800 - val_FN: 46.3100\n",
      "Epoch 34/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0523 - Accuracy: 0.9817 - Precision: 0.9558 - Recall: 0.9469 - TP: 3193.0901 - TN: 5515.2900 - FP: 131.7100 - FN: 178.9100 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9424 - val_TP: 757.7000 - val_TN: 1080.5100 - val_FP: 25.4900 - val_FN: 46.3000\n",
      "Epoch 35/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0522 - Accuracy: 0.9818 - Precision: 0.9557 - Recall: 0.9471 - TP: 3193.5901 - TN: 5514.5601 - FP: 132.4400 - FN: 178.4100 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9424 - val_TP: 757.6500 - val_TN: 1080.5800 - val_FP: 25.4200 - val_FN: 46.3500\n",
      "Epoch 36/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0522 - Accuracy: 0.9818 - Precision: 0.9556 - Recall: 0.9472 - TP: 3193.8999 - TN: 5514.2900 - FP: 132.7100 - FN: 178.1000 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9424 - val_TP: 757.7000 - val_TN: 1080.5200 - val_FP: 25.4800 - val_FN: 46.3000\n",
      "Epoch 37/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0523 - Accuracy: 0.9818 - Precision: 0.9559 - Recall: 0.9469 - TP: 3193.0200 - TN: 5516.1499 - FP: 130.8500 - FN: 178.9800 - val_loss: 0.0741 - val_Accuracy: 0.9780 - val_Precision: 0.9608 - val_Recall: 0.9424 - val_TP: 757.6900 - val_TN: 1079.7700 - val_FP: 26.2300 - val_FN: 46.3100\n",
      "Epoch 38/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0523 - Accuracy: 0.9818 - Precision: 0.9555 - Recall: 0.9471 - TP: 3193.7700 - TN: 5513.8799 - FP: 133.1200 - FN: 178.2300 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9424 - val_TP: 757.6900 - val_TN: 1080.5200 - val_FP: 25.4800 - val_FN: 46.3100\n",
      "Epoch 39/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0522 - Accuracy: 0.9817 - Precision: 0.9557 - Recall: 0.9470 - TP: 3193.4399 - TN: 5514.5298 - FP: 132.4700 - FN: 178.5600 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9424 - val_TP: 757.6600 - val_TN: 1080.8900 - val_FP: 25.1100 - val_FN: 46.3400\n",
      "Epoch 40/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0522 - Accuracy: 0.9817 - Precision: 0.9559 - Recall: 0.9470 - TP: 3193.3601 - TN: 5515.7500 - FP: 131.2500 - FN: 178.6400 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9424 - val_TP: 757.6600 - val_TN: 1080.7700 - val_FP: 25.2300 - val_FN: 46.3400\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 8ms/step - loss: 0.0526 - Accuracy: 0.9820 - Precision: 0.9559 - Recall: 0.9468 - TP: 3192.7700 - TN: 5516.3101 - FP: 130.6900 - FN: 179.2300 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9424 - val_TP: 757.7100 - val_TN: 1080.5601 - val_FP: 25.4400 - val_FN: 46.2900\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0525 - Accuracy: 0.9819 - Precision: 0.9556 - Recall: 0.9470 - TP: 3193.2600 - TN: 5514.2598 - FP: 132.7400 - FN: 178.7400 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9424 - val_TP: 757.6700 - val_TN: 1080.7500 - val_FP: 25.2500 - val_FN: 46.3300\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0523 - Accuracy: 0.9818 - Precision: 0.9561 - Recall: 0.9468 - TP: 3192.4500 - TN: 5516.9102 - FP: 130.0900 - FN: 179.5500 - val_loss: 0.0744 - val_Accuracy: 0.9780 - val_Precision: 0.9604 - val_Recall: 0.9425 - val_TP: 757.7300 - val_TN: 1079.3500 - val_FP: 26.6500 - val_FN: 46.2700\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0524 - Accuracy: 0.9816 - Precision: 0.9550 - Recall: 0.9472 - TP: 3193.9399 - TN: 5511.4302 - FP: 135.5700 - FN: 178.0600 - val_loss: 0.0734 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9424 - val_TP: 757.6800 - val_TN: 1080.7900 - val_FP: 25.2100 - val_FN: 46.3200\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0524 - Accuracy: 0.9818 - Precision: 0.9557 - Recall: 0.9470 - TP: 3193.1799 - TN: 5515.0898 - FP: 131.9100 - FN: 178.8200 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9424 - val_TP: 757.6800 - val_TN: 1080.5100 - val_FP: 25.4900 - val_FN: 46.3200\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0524 - Accuracy: 0.9817 - Precision: 0.9553 - Recall: 0.9471 - TP: 3193.7400 - TN: 5512.5801 - FP: 134.4200 - FN: 178.2600 - val_loss: 0.0734 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9424 - val_TP: 757.6600 - val_TN: 1080.8800 - val_FP: 25.1200 - val_FN: 46.3400\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0524 - Accuracy: 0.9818 - Precision: 0.9556 - Recall: 0.9470 - TP: 3193.2300 - TN: 5514.3701 - FP: 132.6300 - FN: 178.7700 - val_loss: 0.0734 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9423 - val_TP: 757.6400 - val_TN: 1080.8900 - val_FP: 25.1100 - val_FN: 46.3600\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0524 - Accuracy: 0.9817 - Precision: 0.9559 - Recall: 0.9468 - TP: 3192.7300 - TN: 5515.6099 - FP: 131.3900 - FN: 179.2700 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9423 - val_TP: 757.6300 - val_TN: 1080.6600 - val_FP: 25.3400 - val_FN: 46.3700\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0523 - Accuracy: 0.9817 - Precision: 0.9557 - Recall: 0.9469 - TP: 3193.0300 - TN: 5514.7700 - FP: 132.2300 - FN: 178.9700 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9613 - val_Recall: 0.9424 - val_TP: 757.6800 - val_TN: 1080.3800 - val_FP: 25.6200 - val_FN: 46.3200\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0523 - Accuracy: 0.9816 - Precision: 0.9556 - Recall: 0.9470 - TP: 3193.3701 - TN: 5514.0400 - FP: 132.9600 - FN: 178.6300 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9424 - val_TP: 757.6900 - val_TN: 1080.5699 - val_FP: 25.4300 - val_FN: 46.3100\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0523 - Accuracy: 0.9818 - Precision: 0.9558 - Recall: 0.9470 - TP: 3193.3999 - TN: 5515.0698 - FP: 131.9300 - FN: 178.6000 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9613 - val_Recall: 0.9424 - val_TP: 757.7200 - val_TN: 1080.4000 - val_FP: 25.6000 - val_FN: 46.2800\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0523 - Accuracy: 0.9819 - Precision: 0.9554 - Recall: 0.9472 - TP: 3193.9800 - TN: 5513.1499 - FP: 133.8500 - FN: 178.0200 - val_loss: 0.0734 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9424 - val_TP: 757.6900 - val_TN: 1080.8800 - val_FP: 25.1200 - val_FN: 46.3100\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0522 - Accuracy: 0.9818 - Precision: 0.9557 - Recall: 0.9471 - TP: 3193.6799 - TN: 5514.8799 - FP: 132.1200 - FN: 178.3200 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9424 - val_TP: 757.6900 - val_TN: 1080.6600 - val_FP: 25.3400 - val_FN: 46.3100\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0523 - Accuracy: 0.9816 - Precision: 0.9558 - Recall: 0.9469 - TP: 3193.0801 - TN: 5515.3101 - FP: 131.6900 - FN: 178.9200 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9424 - val_TP: 757.6700 - val_TN: 1080.5900 - val_FP: 25.4100 - val_FN: 46.3300\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0522 - Accuracy: 0.9817 - Precision: 0.9556 - Recall: 0.9471 - TP: 3193.7000 - TN: 5514.1802 - FP: 132.8200 - FN: 178.3000 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9424 - val_TP: 757.7000 - val_TN: 1080.6899 - val_FP: 25.3100 - val_FN: 46.3000\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0522 - Accuracy: 0.9817 - Precision: 0.9557 - Recall: 0.9471 - TP: 3193.6499 - TN: 5514.5298 - FP: 132.4700 - FN: 178.3500 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9424 - val_TP: 757.6900 - val_TN: 1080.8700 - val_FP: 25.1300 - val_FN: 46.3100\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0522 - Accuracy: 0.9817 - Precision: 0.9558 - Recall: 0.9470 - TP: 3193.3201 - TN: 5515.0801 - FP: 131.9200 - FN: 178.6800 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9424 - val_TP: 757.6900 - val_TN: 1080.8300 - val_FP: 25.1700 - val_FN: 46.3100\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0522 - Accuracy: 0.9818 - Precision: 0.9558 - Recall: 0.9470 - TP: 3193.4500 - TN: 5515.3101 - FP: 131.6900 - FN: 178.5500 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9424 - val_TP: 757.7000 - val_TN: 1080.6100 - val_FP: 25.3900 - val_FN: 46.3000\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0522 - Accuracy: 0.9817 - Precision: 0.9555 - Recall: 0.9471 - TP: 3193.7300 - TN: 5513.9302 - FP: 133.0700 - FN: 178.2700 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9424 - val_TP: 757.7100 - val_TN: 1080.6600 - val_FP: 25.3400 - val_FN: 46.2900\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0522 - Accuracy: 0.9817 - Precision: 0.9558 - Recall: 0.9471 - TP: 3193.6599 - TN: 5515.0898 - FP: 131.9100 - FN: 178.3400 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9424 - val_TP: 757.6900 - val_TN: 1080.7800 - val_FP: 25.2200 - val_FN: 46.3100\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0522 - Accuracy: 0.9818 - Precision: 0.9557 - Recall: 0.9472 - TP: 3193.8999 - TN: 5514.6899 - FP: 132.3100 - FN: 178.1000 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9425 - val_TP: 757.7400 - val_TN: 1080.7400 - val_FP: 25.2600 - val_FN: 46.2600\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0522 - Accuracy: 0.9818 - Precision: 0.9557 - Recall: 0.9472 - TP: 3194.0300 - TN: 5515.1001 - FP: 131.9000 - FN: 177.9700 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9424 - val_TP: 757.7200 - val_TN: 1080.7700 - val_FP: 25.2300 - val_FN: 46.2800\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0522 - Accuracy: 0.9816 - Precision: 0.9557 - Recall: 0.9471 - TP: 3193.6201 - TN: 5514.5898 - FP: 132.4100 - FN: 178.3800 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9612 - val_Recall: 0.9425 - val_TP: 757.7700 - val_TN: 1080.3800 - val_FP: 25.6200 - val_FN: 46.2300\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0521 - Accuracy: 0.9819 - Precision: 0.9558 - Recall: 0.9472 - TP: 3193.8799 - TN: 5514.9302 - FP: 132.0700 - FN: 178.1200 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9424 - val_TP: 757.7000 - val_TN: 1080.8300 - val_FP: 25.1700 - val_FN: 46.3000\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0521 - Accuracy: 0.9818 - Precision: 0.9558 - Recall: 0.9472 - TP: 3193.9199 - TN: 5515.2100 - FP: 131.7900 - FN: 178.0800 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9425 - val_TP: 757.7400 - val_TN: 1080.7800 - val_FP: 25.2200 - val_FN: 46.2600\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0521 - Accuracy: 0.9816 - Precision: 0.9558 - Recall: 0.9472 - TP: 3193.7900 - TN: 5515.0000 - FP: 132.0000 - FN: 178.2100 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9424 - val_TP: 757.7200 - val_TN: 1080.9301 - val_FP: 25.0700 - val_FN: 46.2800\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 10ms/step - loss: 0.0527 - Accuracy: 0.9815 - Precision: 0.9563 - Recall: 0.9468 - TP: 3192.6101 - TN: 5518.2598 - FP: 128.7400 - FN: 179.3900 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9609 - val_Recall: 0.9425 - val_TP: 757.8100 - val_TN: 1080.0699 - val_FP: 25.9300 - val_FN: 46.1900\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0524 - Accuracy: 0.9817 - Precision: 0.9554 - Recall: 0.9471 - TP: 3193.5601 - TN: 5513.6201 - FP: 133.3800 - FN: 178.4400 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9425 - val_TP: 757.7300 - val_TN: 1080.4900 - val_FP: 25.5100 - val_FN: 46.2700\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0523 - Accuracy: 0.9818 - Precision: 0.9554 - Recall: 0.9472 - TP: 3194.0500 - TN: 5513.5098 - FP: 133.4900 - FN: 177.9500 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9424 - val_TP: 757.7200 - val_TN: 1080.6600 - val_FP: 25.3400 - val_FN: 46.2800\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0523 - Accuracy: 0.9817 - Precision: 0.9558 - Recall: 0.9471 - TP: 3193.6699 - TN: 5515.3501 - FP: 131.6500 - FN: 178.3300 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9610 - val_Recall: 0.9426 - val_TP: 757.8200 - val_TN: 1080.1300 - val_FP: 25.8700 - val_FN: 46.1800\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0523 - Accuracy: 0.9818 - Precision: 0.9556 - Recall: 0.9471 - TP: 3193.4900 - TN: 5514.1401 - FP: 132.8600 - FN: 178.5100 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9424 - val_TP: 757.7100 - val_TN: 1080.5699 - val_FP: 25.4300 - val_FN: 46.2900\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0523 - Accuracy: 0.9818 - Precision: 0.9556 - Recall: 0.9472 - TP: 3193.8799 - TN: 5514.2900 - FP: 132.7100 - FN: 178.1200 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9424 - val_TP: 757.6800 - val_TN: 1080.5900 - val_FP: 25.4100 - val_FN: 46.3200\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0523 - Accuracy: 0.9818 - Precision: 0.9557 - Recall: 0.9471 - TP: 3193.5801 - TN: 5514.4502 - FP: 132.5500 - FN: 178.4200 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9424 - val_TP: 757.6900 - val_TN: 1080.6200 - val_FP: 25.3800 - val_FN: 46.3100\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0523 - Accuracy: 0.9816 - Precision: 0.9555 - Recall: 0.9471 - TP: 3193.7300 - TN: 5513.8398 - FP: 133.1600 - FN: 178.2700 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9424 - val_TP: 757.7200 - val_TN: 1080.5800 - val_FP: 25.4200 - val_FN: 46.2800\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0523 - Accuracy: 0.9817 - Precision: 0.9556 - Recall: 0.9471 - TP: 3193.6499 - TN: 5514.4702 - FP: 132.5300 - FN: 178.3500 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9424 - val_TP: 757.7100 - val_TN: 1080.5400 - val_FP: 25.4600 - val_FN: 46.2900\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0522 - Accuracy: 0.9819 - Precision: 0.9555 - Recall: 0.9472 - TP: 3194.1101 - TN: 5513.7998 - FP: 133.2000 - FN: 177.8900 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9424 - val_TP: 757.6800 - val_TN: 1080.9000 - val_FP: 25.1000 - val_FN: 46.3200\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0522 - Accuracy: 0.9818 - Precision: 0.9561 - Recall: 0.9470 - TP: 3193.3401 - TN: 5517.0000 - FP: 130.0000 - FN: 178.6600 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9424 - val_TP: 757.6700 - val_TN: 1080.5500 - val_FP: 25.4500 - val_FN: 46.3300\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0522 - Accuracy: 0.9817 - Precision: 0.9556 - Recall: 0.9472 - TP: 3193.8701 - TN: 5514.4800 - FP: 132.5200 - FN: 178.1300 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9608 - val_Recall: 0.9425 - val_TP: 757.7800 - val_TN: 1079.8300 - val_FP: 26.1700 - val_FN: 46.2200\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0522 - Accuracy: 0.9818 - Precision: 0.9558 - Recall: 0.9470 - TP: 3193.3501 - TN: 5515.3901 - FP: 131.6100 - FN: 178.6500 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9424 - val_TP: 757.6800 - val_TN: 1080.8400 - val_FP: 25.1600 - val_FN: 46.3200\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0522 - Accuracy: 0.9817 - Precision: 0.9556 - Recall: 0.9471 - TP: 3193.7700 - TN: 5514.0200 - FP: 132.9800 - FN: 178.2300 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9424 - val_TP: 757.6700 - val_TN: 1080.6600 - val_FP: 25.3400 - val_FN: 46.3300\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0522 - Accuracy: 0.9818 - Precision: 0.9558 - Recall: 0.9472 - TP: 3193.8401 - TN: 5515.1201 - FP: 131.8800 - FN: 178.1600 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9424 - val_TP: 757.7100 - val_TN: 1080.6899 - val_FP: 25.3100 - val_FN: 46.2900\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0521 - Accuracy: 0.9818 - Precision: 0.9557 - Recall: 0.9472 - TP: 3193.8799 - TN: 5514.6802 - FP: 132.3200 - FN: 178.1200 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9424 - val_TP: 757.7200 - val_TN: 1080.6300 - val_FP: 25.3700 - val_FN: 46.2800\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0521 - Accuracy: 0.9817 - Precision: 0.9559 - Recall: 0.9471 - TP: 3193.6799 - TN: 5515.8301 - FP: 131.1700 - FN: 178.3200 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9424 - val_TP: 757.7200 - val_TN: 1080.8700 - val_FP: 25.1300 - val_FN: 46.2800\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0521 - Accuracy: 0.9818 - Precision: 0.9556 - Recall: 0.9473 - TP: 3194.2900 - TN: 5514.3398 - FP: 132.6600 - FN: 177.7100 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9613 - val_Recall: 0.9425 - val_TP: 757.7600 - val_TN: 1080.4399 - val_FP: 25.5600 - val_FN: 46.2400\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0521 - Accuracy: 0.9817 - Precision: 0.9558 - Recall: 0.9472 - TP: 3193.9600 - TN: 5514.9902 - FP: 132.0100 - FN: 178.0400 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9424 - val_TP: 757.7200 - val_TN: 1080.8199 - val_FP: 25.1800 - val_FN: 46.2800\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0521 - Accuracy: 0.9818 - Precision: 0.9558 - Recall: 0.9472 - TP: 3193.9199 - TN: 5515.4800 - FP: 131.5200 - FN: 178.0800 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9425 - val_TP: 757.7500 - val_TN: 1080.6600 - val_FP: 25.3400 - val_FN: 46.2500\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0522 - Accuracy: 0.9817 - Precision: 0.9557 - Recall: 0.9472 - TP: 3193.8999 - TN: 5514.5298 - FP: 132.4700 - FN: 178.1000 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9425 - val_TP: 757.7500 - val_TN: 1080.6000 - val_FP: 25.4000 - val_FN: 46.2500\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0520 - Accuracy: 0.9818 - Precision: 0.9557 - Recall: 0.9473 - TP: 3194.3101 - TN: 5514.4600 - FP: 132.5400 - FN: 177.6900 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9619 - val_Recall: 0.9424 - val_TP: 757.7100 - val_TN: 1081.0200 - val_FP: 24.9800 - val_FN: 46.2900\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0520 - Accuracy: 0.9816 - Precision: 0.9561 - Recall: 0.9470 - TP: 3193.4399 - TN: 5516.8101 - FP: 130.1900 - FN: 178.5600 - val_loss: 0.0740 - val_Accuracy: 0.9780 - val_Precision: 0.9608 - val_Recall: 0.9425 - val_TP: 757.7800 - val_TN: 1079.8400 - val_FP: 26.1600 - val_FN: 46.2200\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0520 - Accuracy: 0.9818 - Precision: 0.9558 - Recall: 0.9473 - TP: 3194.1299 - TN: 5515.0898 - FP: 131.9100 - FN: 177.8700 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9425 - val_TP: 757.7600 - val_TN: 1080.7000 - val_FP: 25.3000 - val_FN: 46.2400\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0520 - Accuracy: 0.9819 - Precision: 0.9558 - Recall: 0.9473 - TP: 3194.1499 - TN: 5515.0098 - FP: 131.9900 - FN: 177.8500 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9425 - val_TP: 757.7600 - val_TN: 1080.9200 - val_FP: 25.0800 - val_FN: 46.2400\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0521 - Accuracy: 0.9817 - Precision: 0.9559 - Recall: 0.9472 - TP: 3193.8301 - TN: 5515.8198 - FP: 131.1800 - FN: 178.1700 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9425 - val_TP: 757.7700 - val_TN: 1080.6300 - val_FP: 25.3700 - val_FN: 46.2300\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0520 - Accuracy: 0.9817 - Precision: 0.9560 - Recall: 0.9472 - TP: 3193.9800 - TN: 5516.0400 - FP: 130.9600 - FN: 178.0200 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9425 - val_TP: 757.7600 - val_TN: 1080.6100 - val_FP: 25.3900 - val_FN: 46.2400\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0519 - Accuracy: 0.9818 - Precision: 0.9558 - Recall: 0.9473 - TP: 3194.3799 - TN: 5515.5200 - FP: 131.4800 - FN: 177.6200 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9425 - val_TP: 757.7700 - val_TN: 1080.7000 - val_FP: 25.3000 - val_FN: 46.2300\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0519 - Accuracy: 0.9818 - Precision: 0.9557 - Recall: 0.9474 - TP: 3194.5901 - TN: 5514.6602 - FP: 132.3400 - FN: 177.4100 - val_loss: 0.0734 - val_Accuracy: 0.9780 - val_Precision: 0.9619 - val_Recall: 0.9425 - val_TP: 757.7600 - val_TN: 1081.1000 - val_FP: 24.9000 - val_FN: 46.2400\n",
      "Epoch 30/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0519 - Accuracy: 0.9818 - Precision: 0.9558 - Recall: 0.9474 - TP: 3194.5400 - TN: 5515.4800 - FP: 131.5200 - FN: 177.4600 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9426 - val_TP: 757.8400 - val_TN: 1080.6400 - val_FP: 25.3600 - val_FN: 46.1600\n",
      "Epoch 31/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0519 - Accuracy: 0.9818 - Precision: 0.9558 - Recall: 0.9473 - TP: 3194.4299 - TN: 5515.3198 - FP: 131.6800 - FN: 177.5700 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9425 - val_TP: 757.7800 - val_TN: 1080.8700 - val_FP: 25.1300 - val_FN: 46.2200\n",
      "Epoch 32/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0519 - Accuracy: 0.9817 - Precision: 0.9558 - Recall: 0.9473 - TP: 3194.3101 - TN: 5515.2002 - FP: 131.8000 - FN: 177.6900 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9425 - val_TP: 757.8000 - val_TN: 1080.9301 - val_FP: 25.0700 - val_FN: 46.2000\n",
      "Epoch 33/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0519 - Accuracy: 0.9817 - Precision: 0.9561 - Recall: 0.9473 - TP: 3194.2200 - TN: 5516.6499 - FP: 130.3500 - FN: 177.7800 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9426 - val_TP: 757.8300 - val_TN: 1080.6500 - val_FP: 25.3500 - val_FN: 46.1700\n",
      "Epoch 34/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0519 - Accuracy: 0.9819 - Precision: 0.9557 - Recall: 0.9474 - TP: 3194.7800 - TN: 5514.6299 - FP: 132.3700 - FN: 177.2200 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9426 - val_TP: 757.8200 - val_TN: 1080.8800 - val_FP: 25.1200 - val_FN: 46.1800\n",
      "Epoch 35/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0518 - Accuracy: 0.9817 - Precision: 0.9559 - Recall: 0.9474 - TP: 3194.6499 - TN: 5515.4702 - FP: 131.5300 - FN: 177.3500 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9425 - val_TP: 757.7700 - val_TN: 1080.9100 - val_FP: 25.0900 - val_FN: 46.2300\n",
      "Epoch 36/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0519 - Accuracy: 0.9817 - Precision: 0.9560 - Recall: 0.9473 - TP: 3194.4299 - TN: 5516.0498 - FP: 130.9500 - FN: 177.5700 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9619 - val_Recall: 0.9425 - val_TP: 757.7800 - val_TN: 1081.0000 - val_FP: 25.0000 - val_FN: 46.2200\n",
      "Epoch 37/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0519 - Accuracy: 0.9817 - Precision: 0.9559 - Recall: 0.9474 - TP: 3194.6101 - TN: 5515.6099 - FP: 131.3900 - FN: 177.3900 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9426 - val_TP: 757.8400 - val_TN: 1080.6000 - val_FP: 25.4000 - val_FN: 46.1600\n",
      "Epoch 38/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0519 - Accuracy: 0.9818 - Precision: 0.9557 - Recall: 0.9475 - TP: 3194.9500 - TN: 5514.3501 - FP: 132.6500 - FN: 177.0500 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9619 - val_Recall: 0.9425 - val_TP: 757.7500 - val_TN: 1081.0100 - val_FP: 24.9900 - val_FN: 46.2500\n",
      "Epoch 39/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0518 - Accuracy: 0.9817 - Precision: 0.9560 - Recall: 0.9474 - TP: 3194.4900 - TN: 5516.2100 - FP: 130.7900 - FN: 177.5100 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9425 - val_TP: 757.7800 - val_TN: 1080.7300 - val_FP: 25.2700 - val_FN: 46.2200\n",
      "Epoch 40/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0518 - Accuracy: 0.9818 - Precision: 0.9559 - Recall: 0.9475 - TP: 3194.8101 - TN: 5515.4199 - FP: 131.5800 - FN: 177.1900 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9426 - val_TP: 757.8300 - val_TN: 1080.8900 - val_FP: 25.1100 - val_FN: 46.1700\n",
      "Epoch 41/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0518 - Accuracy: 0.9816 - Precision: 0.9560 - Recall: 0.9474 - TP: 3194.5300 - TN: 5515.9302 - FP: 131.0700 - FN: 177.4700 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9425 - val_TP: 757.8100 - val_TN: 1080.7800 - val_FP: 25.2200 - val_FN: 46.1900\n",
      "Epoch 42/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0518 - Accuracy: 0.9816 - Precision: 0.9561 - Recall: 0.9474 - TP: 3194.5400 - TN: 5516.5898 - FP: 130.4100 - FN: 177.4600 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9426 - val_TP: 757.8300 - val_TN: 1080.8000 - val_FP: 25.2000 - val_FN: 46.1700\n",
      "Epoch 43/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0517 - Accuracy: 0.9817 - Precision: 0.9561 - Recall: 0.9474 - TP: 3194.4800 - TN: 5516.5801 - FP: 130.4200 - FN: 177.5200 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9426 - val_TP: 757.8900 - val_TN: 1080.5800 - val_FP: 25.4200 - val_FN: 46.1100\n",
      "Epoch 44/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0517 - Accuracy: 0.9819 - Precision: 0.9558 - Recall: 0.9476 - TP: 3195.3401 - TN: 5514.8799 - FP: 132.1200 - FN: 176.6600 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9427 - val_TP: 757.9000 - val_TN: 1080.5500 - val_FP: 25.4500 - val_FN: 46.1000\n",
      "Epoch 45/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0517 - Accuracy: 0.9818 - Precision: 0.9559 - Recall: 0.9476 - TP: 3195.2700 - TN: 5515.4302 - FP: 131.5700 - FN: 176.7300 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9427 - val_TP: 757.9000 - val_TN: 1080.6600 - val_FP: 25.3400 - val_FN: 46.1000\n",
      "Epoch 46/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0517 - Accuracy: 0.9819 - Precision: 0.9558 - Recall: 0.9476 - TP: 3195.1399 - TN: 5515.1602 - FP: 131.8400 - FN: 176.8600 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9426 - val_TP: 757.8700 - val_TN: 1080.7500 - val_FP: 25.2500 - val_FN: 46.1300\n",
      "Epoch 47/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0517 - Accuracy: 0.9817 - Precision: 0.9562 - Recall: 0.9474 - TP: 3194.7200 - TN: 5517.2202 - FP: 129.7800 - FN: 177.2800 - val_loss: 0.0741 - val_Accuracy: 0.9780 - val_Precision: 0.9607 - val_Recall: 0.9427 - val_TP: 757.9600 - val_TN: 1079.7200 - val_FP: 26.2800 - val_FN: 46.0400\n",
      "Epoch 48/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0517 - Accuracy: 0.9816 - Precision: 0.9560 - Recall: 0.9475 - TP: 3195.0601 - TN: 5515.7500 - FP: 131.2500 - FN: 176.9400 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9426 - val_TP: 757.8800 - val_TN: 1080.7400 - val_FP: 25.2600 - val_FN: 46.1200\n",
      "Epoch 49/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0516 - Accuracy: 0.9817 - Precision: 0.9559 - Recall: 0.9476 - TP: 3195.3601 - TN: 5515.4199 - FP: 131.5800 - FN: 176.6400 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9427 - val_TP: 757.9700 - val_TN: 1080.6899 - val_FP: 25.3100 - val_FN: 46.0300\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 9ms/step - loss: 0.0520 - Accuracy: 0.9816 - Precision: 0.9563 - Recall: 0.9471 - TP: 3193.7500 - TN: 5517.8301 - FP: 129.1700 - FN: 178.2500 - val_loss: 0.0741 - val_Accuracy: 0.9780 - val_Precision: 0.9608 - val_Recall: 0.9426 - val_TP: 757.8200 - val_TN: 1079.8400 - val_FP: 26.1600 - val_FN: 46.1800\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0520 - Accuracy: 0.9818 - Precision: 0.9557 - Recall: 0.9474 - TP: 3194.6899 - TN: 5514.5000 - FP: 132.5000 - FN: 177.3100 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9425 - val_TP: 757.7700 - val_TN: 1080.9399 - val_FP: 25.0600 - val_FN: 46.2300\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0519 - Accuracy: 0.9818 - Precision: 0.9561 - Recall: 0.9472 - TP: 3194.0601 - TN: 5516.3999 - FP: 130.6000 - FN: 177.9400 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9426 - val_TP: 757.8400 - val_TN: 1080.7300 - val_FP: 25.2700 - val_FN: 46.1600\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0519 - Accuracy: 0.9819 - Precision: 0.9558 - Recall: 0.9474 - TP: 3194.4900 - TN: 5515.3398 - FP: 131.6600 - FN: 177.5100 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9426 - val_TP: 757.8300 - val_TN: 1080.7100 - val_FP: 25.2900 - val_FN: 46.1700\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0519 - Accuracy: 0.9818 - Precision: 0.9559 - Recall: 0.9473 - TP: 3194.4199 - TN: 5515.5801 - FP: 131.4200 - FN: 177.5800 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9426 - val_TP: 757.8900 - val_TN: 1080.5500 - val_FP: 25.4500 - val_FN: 46.1100\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0519 - Accuracy: 0.9817 - Precision: 0.9557 - Recall: 0.9474 - TP: 3194.8000 - TN: 5514.8198 - FP: 132.1800 - FN: 177.2000 - val_loss: 0.0734 - val_Accuracy: 0.9780 - val_Precision: 0.9619 - val_Recall: 0.9426 - val_TP: 757.8300 - val_TN: 1081.0100 - val_FP: 24.9900 - val_FN: 46.1700\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0519 - Accuracy: 0.9817 - Precision: 0.9562 - Recall: 0.9473 - TP: 3194.1699 - TN: 5517.0400 - FP: 129.9600 - FN: 177.8300 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9426 - val_TP: 757.8500 - val_TN: 1080.6801 - val_FP: 25.3200 - val_FN: 46.1500\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0519 - Accuracy: 0.9817 - Precision: 0.9558 - Recall: 0.9474 - TP: 3194.7700 - TN: 5515.2002 - FP: 131.8000 - FN: 177.2300 - val_loss: 0.0734 - val_Accuracy: 0.9780 - val_Precision: 0.9619 - val_Recall: 0.9425 - val_TP: 757.8100 - val_TN: 1081.0400 - val_FP: 24.9600 - val_FN: 46.1900\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0518 - Accuracy: 0.9816 - Precision: 0.9559 - Recall: 0.9474 - TP: 3194.5000 - TN: 5515.5200 - FP: 131.4800 - FN: 177.5000 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9426 - val_TP: 757.8300 - val_TN: 1080.7100 - val_FP: 25.2900 - val_FN: 46.1700\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0518 - Accuracy: 0.9818 - Precision: 0.9559 - Recall: 0.9474 - TP: 3194.7000 - TN: 5515.5298 - FP: 131.4700 - FN: 177.3000 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9426 - val_TP: 757.8900 - val_TN: 1080.5200 - val_FP: 25.4800 - val_FN: 46.1100\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0518 - Accuracy: 0.9817 - Precision: 0.9560 - Recall: 0.9474 - TP: 3194.7200 - TN: 5516.0098 - FP: 130.9900 - FN: 177.2800 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9426 - val_TP: 757.8900 - val_TN: 1080.7600 - val_FP: 25.2400 - val_FN: 46.1100\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0518 - Accuracy: 0.9819 - Precision: 0.9558 - Recall: 0.9475 - TP: 3195.0200 - TN: 5515.2300 - FP: 131.7700 - FN: 176.9800 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9426 - val_TP: 757.8400 - val_TN: 1080.9301 - val_FP: 25.0700 - val_FN: 46.1600\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0517 - Accuracy: 0.9818 - Precision: 0.9561 - Recall: 0.9475 - TP: 3194.8999 - TN: 5516.6099 - FP: 130.3900 - FN: 177.1000 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9613 - val_Recall: 0.9427 - val_TP: 757.9500 - val_TN: 1080.5000 - val_FP: 25.5000 - val_FN: 46.0500\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0518 - Accuracy: 0.9818 - Precision: 0.9558 - Recall: 0.9475 - TP: 3195.0901 - TN: 5515.0098 - FP: 131.9900 - FN: 176.9100 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9426 - val_TP: 757.8900 - val_TN: 1080.7900 - val_FP: 25.2100 - val_FN: 46.1100\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0517 - Accuracy: 0.9817 - Precision: 0.9559 - Recall: 0.9475 - TP: 3195.1299 - TN: 5515.5898 - FP: 131.4100 - FN: 176.8700 - val_loss: 0.0740 - val_Accuracy: 0.9780 - val_Precision: 0.9613 - val_Recall: 0.9426 - val_TP: 757.8800 - val_TN: 1080.4600 - val_FP: 25.5400 - val_FN: 46.1200\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0517 - Accuracy: 0.9817 - Precision: 0.9562 - Recall: 0.9474 - TP: 3194.7700 - TN: 5516.8901 - FP: 130.1100 - FN: 177.2300 - val_loss: 0.0742 - val_Accuracy: 0.9780 - val_Precision: 0.9607 - val_Recall: 0.9427 - val_TP: 757.9200 - val_TN: 1079.7100 - val_FP: 26.2900 - val_FN: 46.0800\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0517 - Accuracy: 0.9818 - Precision: 0.9559 - Recall: 0.9475 - TP: 3195.0200 - TN: 5515.5400 - FP: 131.4600 - FN: 176.9800 - val_loss: 0.0740 - val_Accuracy: 0.9780 - val_Precision: 0.9609 - val_Recall: 0.9427 - val_TP: 757.9100 - val_TN: 1079.9399 - val_FP: 26.0600 - val_FN: 46.0900\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0517 - Accuracy: 0.9818 - Precision: 0.9559 - Recall: 0.9476 - TP: 3195.1799 - TN: 5515.6802 - FP: 131.3200 - FN: 176.8200 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9426 - val_TP: 757.8200 - val_TN: 1080.9399 - val_FP: 25.0600 - val_FN: 46.1800\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0516 - Accuracy: 0.9819 - Precision: 0.9563 - Recall: 0.9475 - TP: 3194.9399 - TN: 5517.3901 - FP: 129.6100 - FN: 177.0600 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9613 - val_Recall: 0.9427 - val_TP: 757.9600 - val_TN: 1080.4600 - val_FP: 25.5400 - val_FN: 46.0400\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0517 - Accuracy: 0.9817 - Precision: 0.9558 - Recall: 0.9476 - TP: 3195.2600 - TN: 5515.0801 - FP: 131.9200 - FN: 176.7400 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9428 - val_TP: 757.9800 - val_TN: 1080.6000 - val_FP: 25.4000 - val_FN: 46.0200\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0516 - Accuracy: 0.9819 - Precision: 0.9559 - Recall: 0.9476 - TP: 3195.3601 - TN: 5515.7500 - FP: 131.2500 - FN: 176.6400 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9427 - val_TP: 757.9300 - val_TN: 1080.8000 - val_FP: 25.2000 - val_FN: 46.0700\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0516 - Accuracy: 0.9818 - Precision: 0.9561 - Recall: 0.9475 - TP: 3195.0601 - TN: 5516.3901 - FP: 130.6100 - FN: 176.9400 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9427 - val_TP: 757.9100 - val_TN: 1080.9600 - val_FP: 25.0400 - val_FN: 46.0900\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0516 - Accuracy: 0.9818 - Precision: 0.9560 - Recall: 0.9476 - TP: 3195.3201 - TN: 5516.0098 - FP: 130.9900 - FN: 176.6800 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9426 - val_TP: 757.8900 - val_TN: 1080.8400 - val_FP: 25.1600 - val_FN: 46.1100\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0516 - Accuracy: 0.9819 - Precision: 0.9559 - Recall: 0.9477 - TP: 3195.7500 - TN: 5515.3301 - FP: 131.6700 - FN: 176.2500 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9427 - val_TP: 757.9300 - val_TN: 1080.9200 - val_FP: 25.0800 - val_FN: 46.0700\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0516 - Accuracy: 0.9819 - Precision: 0.9561 - Recall: 0.9477 - TP: 3195.5200 - TN: 5516.4502 - FP: 130.5500 - FN: 176.4800 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9427 - val_TP: 757.9300 - val_TN: 1080.7000 - val_FP: 25.3000 - val_FN: 46.0700\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0516 - Accuracy: 0.9820 - Precision: 0.9559 - Recall: 0.9477 - TP: 3195.7300 - TN: 5515.7598 - FP: 131.2400 - FN: 176.2700 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9619 - val_Recall: 0.9427 - val_TP: 757.9400 - val_TN: 1081.0400 - val_FP: 24.9600 - val_FN: 46.0600\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 5s 10ms/step - loss: 0.0519 - Accuracy: 0.9817 - Precision: 0.9561 - Recall: 0.9473 - TP: 3194.2700 - TN: 5516.6099 - FP: 130.3900 - FN: 177.7300 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9425 - val_TP: 757.7800 - val_TN: 1080.9800 - val_FP: 25.0200 - val_FN: 46.2200\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0518 - Accuracy: 0.9818 - Precision: 0.9562 - Recall: 0.9473 - TP: 3194.1899 - TN: 5517.1001 - FP: 129.9000 - FN: 177.8100 - val_loss: 0.0742 - val_Accuracy: 0.9780 - val_Precision: 0.9608 - val_Recall: 0.9426 - val_TP: 757.8800 - val_TN: 1079.8300 - val_FP: 26.1700 - val_FN: 46.1200\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0519 - Accuracy: 0.9819 - Precision: 0.9557 - Recall: 0.9476 - TP: 3195.1699 - TN: 5514.2798 - FP: 132.7200 - FN: 176.8300 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9425 - val_TP: 757.7900 - val_TN: 1080.9700 - val_FP: 25.0300 - val_FN: 46.2100\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0519 - Accuracy: 0.9816 - Precision: 0.9562 - Recall: 0.9472 - TP: 3193.9299 - TN: 5517.0400 - FP: 129.9600 - FN: 178.0700 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9426 - val_TP: 757.8600 - val_TN: 1080.8101 - val_FP: 25.1900 - val_FN: 46.1400\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0518 - Accuracy: 0.9817 - Precision: 0.9559 - Recall: 0.9474 - TP: 3194.7700 - TN: 5515.4902 - FP: 131.5100 - FN: 177.2300 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9425 - val_TP: 757.8000 - val_TN: 1080.9800 - val_FP: 25.0200 - val_FN: 46.2000\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0517 - Accuracy: 0.9817 - Precision: 0.9562 - Recall: 0.9474 - TP: 3194.5601 - TN: 5516.9902 - FP: 130.0100 - FN: 177.4400 - val_loss: 0.0741 - val_Accuracy: 0.9780 - val_Precision: 0.9609 - val_Recall: 0.9426 - val_TP: 757.8600 - val_TN: 1079.9399 - val_FP: 26.0600 - val_FN: 46.1400\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0518 - Accuracy: 0.9818 - Precision: 0.9559 - Recall: 0.9475 - TP: 3194.8301 - TN: 5515.4902 - FP: 131.5100 - FN: 177.1700 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9426 - val_TP: 757.8400 - val_TN: 1080.8700 - val_FP: 25.1300 - val_FN: 46.1600\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0517 - Accuracy: 0.9819 - Precision: 0.9560 - Recall: 0.9476 - TP: 3195.1799 - TN: 5516.0298 - FP: 130.9700 - FN: 176.8200 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9427 - val_TP: 757.9100 - val_TN: 1080.7300 - val_FP: 25.2700 - val_FN: 46.0900\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0517 - Accuracy: 0.9818 - Precision: 0.9561 - Recall: 0.9475 - TP: 3194.8501 - TN: 5516.5400 - FP: 130.4600 - FN: 177.1500 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9427 - val_TP: 757.9200 - val_TN: 1080.8000 - val_FP: 25.2000 - val_FN: 46.0800\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0518 - Accuracy: 0.9817 - Precision: 0.9558 - Recall: 0.9475 - TP: 3195.0300 - TN: 5515.2202 - FP: 131.7800 - FN: 176.9700 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9426 - val_TP: 757.8800 - val_TN: 1080.9301 - val_FP: 25.0700 - val_FN: 46.1200\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0516 - Accuracy: 0.9817 - Precision: 0.9562 - Recall: 0.9475 - TP: 3194.8101 - TN: 5517.1602 - FP: 129.8400 - FN: 177.1900 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9427 - val_TP: 757.9500 - val_TN: 1080.5900 - val_FP: 25.4100 - val_FN: 46.0500\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0517 - Accuracy: 0.9818 - Precision: 0.9559 - Recall: 0.9476 - TP: 3195.2400 - TN: 5515.3398 - FP: 131.6600 - FN: 176.7600 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9619 - val_Recall: 0.9426 - val_TP: 757.8600 - val_TN: 1081.0601 - val_FP: 24.9400 - val_FN: 46.1400\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0517 - Accuracy: 0.9817 - Precision: 0.9560 - Recall: 0.9475 - TP: 3195.0701 - TN: 5516.0601 - FP: 130.9400 - FN: 176.9300 - val_loss: 0.0734 - val_Accuracy: 0.9780 - val_Precision: 0.9619 - val_Recall: 0.9427 - val_TP: 757.9100 - val_TN: 1081.0601 - val_FP: 24.9400 - val_FN: 46.0900\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0517 - Accuracy: 0.9819 - Precision: 0.9559 - Recall: 0.9476 - TP: 3195.2600 - TN: 5515.7100 - FP: 131.2900 - FN: 176.7400 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9428 - val_TP: 757.9800 - val_TN: 1080.8500 - val_FP: 25.1500 - val_FN: 46.0200\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0516 - Accuracy: 0.9818 - Precision: 0.9561 - Recall: 0.9476 - TP: 3195.2500 - TN: 5516.4502 - FP: 130.5500 - FN: 176.7500 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9619 - val_Recall: 0.9426 - val_TP: 757.8800 - val_TN: 1081.0800 - val_FP: 24.9200 - val_FN: 46.1200\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0516 - Accuracy: 0.9818 - Precision: 0.9560 - Recall: 0.9476 - TP: 3195.2700 - TN: 5516.0601 - FP: 130.9400 - FN: 176.7300 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9427 - val_TP: 757.9500 - val_TN: 1080.7300 - val_FP: 25.2700 - val_FN: 46.0500\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0516 - Accuracy: 0.9816 - Precision: 0.9560 - Recall: 0.9476 - TP: 3195.2800 - TN: 5516.0898 - FP: 130.9100 - FN: 176.7200 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9427 - val_TP: 757.9400 - val_TN: 1080.7300 - val_FP: 25.2700 - val_FN: 46.0600\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0515 - Accuracy: 0.9818 - Precision: 0.9560 - Recall: 0.9476 - TP: 3195.4600 - TN: 5516.1602 - FP: 130.8400 - FN: 176.5400 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9427 - val_TP: 757.9600 - val_TN: 1080.9000 - val_FP: 25.1000 - val_FN: 46.0400\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0516 - Accuracy: 0.9817 - Precision: 0.9561 - Recall: 0.9476 - TP: 3195.3401 - TN: 5516.5298 - FP: 130.4700 - FN: 176.6600 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9427 - val_TP: 757.9700 - val_TN: 1080.6500 - val_FP: 25.3500 - val_FN: 46.0300\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0516 - Accuracy: 0.9820 - Precision: 0.9561 - Recall: 0.9476 - TP: 3195.4700 - TN: 5516.6802 - FP: 130.3200 - FN: 176.5300 - val_loss: 0.0741 - val_Accuracy: 0.9780 - val_Precision: 0.9610 - val_Recall: 0.9427 - val_TP: 757.9100 - val_TN: 1080.0500 - val_FP: 25.9500 - val_FN: 46.0900\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0515 - Accuracy: 0.9817 - Precision: 0.9559 - Recall: 0.9477 - TP: 3195.6299 - TN: 5515.7300 - FP: 131.2700 - FN: 176.3700 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9427 - val_TP: 757.9300 - val_TN: 1080.9500 - val_FP: 25.0500 - val_FN: 46.0700\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0515 - Accuracy: 0.9819 - Precision: 0.9560 - Recall: 0.9478 - TP: 3195.8201 - TN: 5516.1201 - FP: 130.8800 - FN: 176.1800 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9427 - val_TP: 757.9500 - val_TN: 1080.9301 - val_FP: 25.0700 - val_FN: 46.0500\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0515 - Accuracy: 0.9819 - Precision: 0.9561 - Recall: 0.9476 - TP: 3195.4299 - TN: 5516.7402 - FP: 130.2600 - FN: 176.5700 - val_loss: 0.0734 - val_Accuracy: 0.9780 - val_Precision: 0.9619 - val_Recall: 0.9427 - val_TP: 757.9500 - val_TN: 1081.1300 - val_FP: 24.8700 - val_FN: 46.0500\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0515 - Accuracy: 0.9819 - Precision: 0.9560 - Recall: 0.9478 - TP: 3195.9399 - TN: 5516.1802 - FP: 130.8200 - FN: 176.0600 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9619 - val_Recall: 0.9427 - val_TP: 757.9500 - val_TN: 1081.1300 - val_FP: 24.8700 - val_FN: 46.0500\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0515 - Accuracy: 0.9819 - Precision: 0.9562 - Recall: 0.9476 - TP: 3195.2400 - TN: 5517.2002 - FP: 129.8000 - FN: 176.7600 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9428 - val_TP: 757.9900 - val_TN: 1080.6200 - val_FP: 25.3800 - val_FN: 46.0100\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0515 - Accuracy: 0.9819 - Precision: 0.9562 - Recall: 0.9477 - TP: 3195.6399 - TN: 5516.8101 - FP: 130.1900 - FN: 176.3600 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9428 - val_TP: 758.0000 - val_TN: 1080.7000 - val_FP: 25.3000 - val_FN: 46.0000\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0514 - Accuracy: 0.9818 - Precision: 0.9561 - Recall: 0.9477 - TP: 3195.7600 - TN: 5516.4902 - FP: 130.5100 - FN: 176.2400 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9428 - val_TP: 758.0400 - val_TN: 1080.8101 - val_FP: 25.1900 - val_FN: 45.9600\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0514 - Accuracy: 0.9819 - Precision: 0.9563 - Recall: 0.9477 - TP: 3195.7300 - TN: 5517.2100 - FP: 129.7900 - FN: 176.2700 - val_loss: 0.0741 - val_Accuracy: 0.9780 - val_Precision: 0.9610 - val_Recall: 0.9428 - val_TP: 758.0100 - val_TN: 1080.0400 - val_FP: 25.9600 - val_FN: 45.9900\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0514 - Accuracy: 0.9819 - Precision: 0.9558 - Recall: 0.9479 - TP: 3196.2400 - TN: 5515.0898 - FP: 131.9100 - FN: 175.7600 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9619 - val_Recall: 0.9428 - val_TP: 758.0000 - val_TN: 1081.0500 - val_FP: 24.9500 - val_FN: 46.0000\n",
      "Epoch 30/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0514 - Accuracy: 0.9819 - Precision: 0.9564 - Recall: 0.9476 - TP: 3195.3401 - TN: 5517.9399 - FP: 129.0600 - FN: 176.6600 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9428 - val_TP: 758.0400 - val_TN: 1080.6500 - val_FP: 25.3500 - val_FN: 45.9600\n",
      "Epoch 31/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0514 - Accuracy: 0.9819 - Precision: 0.9561 - Recall: 0.9478 - TP: 3195.8501 - TN: 5516.3701 - FP: 130.6300 - FN: 176.1500 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9428 - val_TP: 758.0400 - val_TN: 1080.7300 - val_FP: 25.2700 - val_FN: 45.9600\n",
      "Epoch 32/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0513 - Accuracy: 0.9820 - Precision: 0.9562 - Recall: 0.9477 - TP: 3195.6599 - TN: 5517.1699 - FP: 129.8300 - FN: 176.3400 - val_loss: 0.0740 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9428 - val_TP: 758.0500 - val_TN: 1080.5900 - val_FP: 25.4100 - val_FN: 45.9500\n",
      "Epoch 33/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0514 - Accuracy: 0.9820 - Precision: 0.9560 - Recall: 0.9479 - TP: 3196.3701 - TN: 5515.8999 - FP: 131.1000 - FN: 175.6300 - val_loss: 0.0733 - val_Accuracy: 0.9780 - val_Precision: 0.9625 - val_Recall: 0.9428 - val_TP: 757.9800 - val_TN: 1081.8700 - val_FP: 24.1300 - val_FN: 46.0200\n",
      "Epoch 34/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0513 - Accuracy: 0.9819 - Precision: 0.9561 - Recall: 0.9479 - TP: 3196.1799 - TN: 5516.6001 - FP: 130.4000 - FN: 175.8200 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9619 - val_Recall: 0.9429 - val_TP: 758.0600 - val_TN: 1081.0900 - val_FP: 24.9100 - val_FN: 45.9400\n",
      "Epoch 35/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0513 - Accuracy: 0.9819 - Precision: 0.9562 - Recall: 0.9478 - TP: 3195.9299 - TN: 5517.1699 - FP: 129.8300 - FN: 176.0700 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9429 - val_TP: 758.0600 - val_TN: 1080.7800 - val_FP: 25.2200 - val_FN: 45.9400\n",
      "Epoch 36/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0513 - Accuracy: 0.9820 - Precision: 0.9564 - Recall: 0.9477 - TP: 3195.6699 - TN: 5517.8901 - FP: 129.1100 - FN: 176.3300 - val_loss: 0.0742 - val_Accuracy: 0.9780 - val_Precision: 0.9608 - val_Recall: 0.9429 - val_TP: 758.0600 - val_TN: 1079.8900 - val_FP: 26.1100 - val_FN: 45.9400\n",
      "Epoch 37/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0513 - Accuracy: 0.9820 - Precision: 0.9562 - Recall: 0.9478 - TP: 3196.0601 - TN: 5516.9102 - FP: 130.0900 - FN: 175.9400 - val_loss: 0.0741 - val_Accuracy: 0.9780 - val_Precision: 0.9610 - val_Recall: 0.9428 - val_TP: 758.0500 - val_TN: 1080.0699 - val_FP: 25.9300 - val_FN: 45.9500\n",
      "Epoch 38/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0513 - Accuracy: 0.9820 - Precision: 0.9561 - Recall: 0.9480 - TP: 3196.5000 - TN: 5516.3901 - FP: 130.6100 - FN: 175.5000 - val_loss: 0.0740 - val_Accuracy: 0.9780 - val_Precision: 0.9610 - val_Recall: 0.9429 - val_TP: 758.0700 - val_TN: 1080.0800 - val_FP: 25.9200 - val_FN: 45.9300\n",
      "Epoch 39/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0513 - Accuracy: 0.9820 - Precision: 0.9563 - Recall: 0.9478 - TP: 3195.8799 - TN: 5517.5000 - FP: 129.5000 - FN: 176.1200 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9428 - val_TP: 758.0200 - val_TN: 1080.8000 - val_FP: 25.2000 - val_FN: 45.9800\n",
      "Epoch 40/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0513 - Accuracy: 0.9819 - Precision: 0.9561 - Recall: 0.9479 - TP: 3196.3000 - TN: 5516.7300 - FP: 130.2700 - FN: 175.7000 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9429 - val_TP: 758.0700 - val_TN: 1080.8500 - val_FP: 25.1500 - val_FN: 45.9300\n",
      "Epoch 41/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0512 - Accuracy: 0.9821 - Precision: 0.9561 - Recall: 0.9481 - TP: 3196.8701 - TN: 5516.2900 - FP: 130.7100 - FN: 175.1300 - val_loss: 0.0733 - val_Accuracy: 0.9780 - val_Precision: 0.9625 - val_Recall: 0.9427 - val_TP: 757.9700 - val_TN: 1081.8900 - val_FP: 24.1100 - val_FN: 46.0300\n",
      "Epoch 42/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0512 - Accuracy: 0.9820 - Precision: 0.9565 - Recall: 0.9478 - TP: 3195.9500 - TN: 5518.4399 - FP: 128.5600 - FN: 176.0500 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9620 - val_Recall: 0.9428 - val_TP: 757.9900 - val_TN: 1081.1500 - val_FP: 24.8500 - val_FN: 46.0100\n",
      "Epoch 43/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0512 - Accuracy: 0.9821 - Precision: 0.9563 - Recall: 0.9478 - TP: 3195.9299 - TN: 5517.2300 - FP: 129.7700 - FN: 176.0700 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9429 - val_TP: 758.0800 - val_TN: 1080.7600 - val_FP: 25.2400 - val_FN: 45.9200\n",
      "Epoch 44/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0512 - Accuracy: 0.9820 - Precision: 0.9563 - Recall: 0.9479 - TP: 3196.4299 - TN: 5517.3301 - FP: 129.6700 - FN: 175.5700 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9615 - val_Recall: 0.9429 - val_TP: 758.1100 - val_TN: 1080.6400 - val_FP: 25.3600 - val_FN: 45.8900\n",
      "Epoch 45/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0511 - Accuracy: 0.9821 - Precision: 0.9564 - Recall: 0.9479 - TP: 3196.3501 - TN: 5518.1099 - FP: 128.8900 - FN: 175.6500 - val_loss: 0.0740 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9429 - val_TP: 758.0800 - val_TN: 1080.6400 - val_FP: 25.3600 - val_FN: 45.9200\n",
      "Epoch 46/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0511 - Accuracy: 0.9820 - Precision: 0.9563 - Recall: 0.9480 - TP: 3196.5601 - TN: 5517.4902 - FP: 129.5100 - FN: 175.4400 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9430 - val_TP: 758.1400 - val_TN: 1080.0000 - val_FP: 26.0000 - val_FN: 45.8600\n",
      "Epoch 47/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0511 - Accuracy: 0.9821 - Precision: 0.9563 - Recall: 0.9479 - TP: 3196.3601 - TN: 5517.0601 - FP: 129.9400 - FN: 175.6400 - val_loss: 0.0740 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9429 - val_TP: 758.0700 - val_TN: 1080.7300 - val_FP: 25.2700 - val_FN: 45.9300\n",
      "Epoch 48/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0511 - Accuracy: 0.9820 - Precision: 0.9563 - Recall: 0.9479 - TP: 3196.3201 - TN: 5517.5898 - FP: 129.4100 - FN: 175.6800 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9430 - val_TP: 758.1400 - val_TN: 1079.9100 - val_FP: 26.0900 - val_FN: 45.8600\n",
      "Epoch 49/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0511 - Accuracy: 0.9821 - Precision: 0.9563 - Recall: 0.9479 - TP: 3196.2600 - TN: 5517.1899 - FP: 129.8100 - FN: 175.7400 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9616 - val_Recall: 0.9429 - val_TP: 758.1200 - val_TN: 1080.7700 - val_FP: 25.2300 - val_FN: 45.8800\n",
      "Epoch 50/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0511 - Accuracy: 0.9823 - Precision: 0.9563 - Recall: 0.9479 - TP: 3196.4199 - TN: 5517.5400 - FP: 129.4600 - FN: 175.5800 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9618 - val_Recall: 0.9429 - val_TP: 758.1200 - val_TN: 1080.9399 - val_FP: 25.0600 - val_FN: 45.8800\n",
      "Epoch 51/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0510 - Accuracy: 0.9823 - Precision: 0.9563 - Recall: 0.9480 - TP: 3196.7800 - TN: 5517.1099 - FP: 129.8900 - FN: 175.2200 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9620 - val_Recall: 0.9429 - val_TP: 758.1300 - val_TN: 1081.2000 - val_FP: 24.8000 - val_FN: 45.8700\n",
      "Epoch 52/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0511 - Accuracy: 0.9821 - Precision: 0.9564 - Recall: 0.9480 - TP: 3196.6201 - TN: 5517.6099 - FP: 129.3900 - FN: 175.3800 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9617 - val_Recall: 0.9430 - val_TP: 758.1500 - val_TN: 1080.9399 - val_FP: 25.0600 - val_FN: 45.8500\n",
      "Epoch 53/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0510 - Accuracy: 0.9823 - Precision: 0.9563 - Recall: 0.9481 - TP: 3196.8301 - TN: 5517.2100 - FP: 129.7900 - FN: 175.1700 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9619 - val_Recall: 0.9429 - val_TP: 758.1200 - val_TN: 1081.1000 - val_FP: 24.9000 - val_FN: 45.8800\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 5s 10ms/step - loss: 0.0515 - Accuracy: 0.9819 - Precision: 0.9567 - Recall: 0.9476 - TP: 3195.1699 - TN: 5519.6802 - FP: 127.3200 - FN: 176.8300 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9429 - val_TP: 758.0600 - val_TN: 1080.8800 - val_FP: 25.1200 - val_FN: 45.9400\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0514 - Accuracy: 0.9821 - Precision: 0.9560 - Recall: 0.9479 - TP: 3196.3799 - TN: 5516.2700 - FP: 130.7300 - FN: 175.6200 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9621 - val_Recall: 0.9428 - val_TP: 757.9900 - val_TN: 1081.2800 - val_FP: 24.7200 - val_FN: 46.0100\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0513 - Accuracy: 0.9821 - Precision: 0.9564 - Recall: 0.9478 - TP: 3196.1499 - TN: 5518.0698 - FP: 128.9300 - FN: 175.8500 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9429 - val_TP: 758.0600 - val_TN: 1081.0300 - val_FP: 24.9700 - val_FN: 45.9400\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0512 - Accuracy: 0.9820 - Precision: 0.9564 - Recall: 0.9478 - TP: 3195.8799 - TN: 5518.2300 - FP: 128.7700 - FN: 176.1200 - val_loss: 0.0741 - val_Accuracy: 0.9780 - val_Precision: 0.9609 - val_Recall: 0.9429 - val_TP: 758.1100 - val_TN: 1079.9600 - val_FP: 26.0400 - val_FN: 45.8900\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0513 - Accuracy: 0.9819 - Precision: 0.9560 - Recall: 0.9479 - TP: 3196.3601 - TN: 5516.0898 - FP: 130.9100 - FN: 175.6400 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9428 - val_TP: 758.0200 - val_TN: 1080.8600 - val_FP: 25.1400 - val_FN: 45.9800\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0513 - Accuracy: 0.9820 - Precision: 0.9560 - Recall: 0.9480 - TP: 3196.6101 - TN: 5515.9199 - FP: 131.0800 - FN: 175.3900 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9620 - val_Recall: 0.9428 - val_TP: 758.0000 - val_TN: 1081.1600 - val_FP: 24.8400 - val_FN: 46.0000\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0513 - Accuracy: 0.9821 - Precision: 0.9564 - Recall: 0.9478 - TP: 3195.8401 - TN: 5517.8999 - FP: 129.1000 - FN: 176.1600 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9429 - val_TP: 758.0600 - val_TN: 1081.0200 - val_FP: 24.9800 - val_FN: 45.9400\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0512 - Accuracy: 0.9819 - Precision: 0.9561 - Recall: 0.9479 - TP: 3196.3401 - TN: 5516.4902 - FP: 130.5100 - FN: 175.6600 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9619 - val_Recall: 0.9428 - val_TP: 758.0000 - val_TN: 1081.1300 - val_FP: 24.8700 - val_FN: 46.0000\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0512 - Accuracy: 0.9820 - Precision: 0.9566 - Recall: 0.9477 - TP: 3195.7200 - TN: 5519.1001 - FP: 127.9000 - FN: 176.2800 - val_loss: 0.0745 - val_Accuracy: 0.9775 - val_Precision: 0.9606 - val_Recall: 0.9429 - val_TP: 758.1000 - val_TN: 1079.6600 - val_FP: 26.3400 - val_FN: 45.9000\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0512 - Accuracy: 0.9819 - Precision: 0.9561 - Recall: 0.9480 - TP: 3196.4900 - TN: 5516.4600 - FP: 130.5400 - FN: 175.5100 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9429 - val_TP: 758.0700 - val_TN: 1080.8400 - val_FP: 25.1600 - val_FN: 45.9300\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0512 - Accuracy: 0.9819 - Precision: 0.9562 - Recall: 0.9480 - TP: 3196.7600 - TN: 5516.7300 - FP: 130.2700 - FN: 175.2400 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9620 - val_Recall: 0.9429 - val_TP: 758.0800 - val_TN: 1081.1500 - val_FP: 24.8500 - val_FN: 45.9200\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0512 - Accuracy: 0.9820 - Precision: 0.9563 - Recall: 0.9479 - TP: 3196.4099 - TN: 5517.4702 - FP: 129.5300 - FN: 175.5900 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9620 - val_Recall: 0.9429 - val_TP: 758.0600 - val_TN: 1081.2500 - val_FP: 24.7500 - val_FN: 45.9400\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0511 - Accuracy: 0.9821 - Precision: 0.9562 - Recall: 0.9480 - TP: 3196.7200 - TN: 5517.0400 - FP: 129.9600 - FN: 175.2800 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9618 - val_Recall: 0.9429 - val_TP: 758.1100 - val_TN: 1080.9900 - val_FP: 25.0100 - val_FN: 45.8900\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0511 - Accuracy: 0.9821 - Precision: 0.9563 - Recall: 0.9480 - TP: 3196.5100 - TN: 5517.5200 - FP: 129.4800 - FN: 175.4900 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9620 - val_Recall: 0.9429 - val_TP: 758.0600 - val_TN: 1081.2300 - val_FP: 24.7700 - val_FN: 45.9400\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0511 - Accuracy: 0.9823 - Precision: 0.9565 - Recall: 0.9478 - TP: 3196.1001 - TN: 5518.2998 - FP: 128.7000 - FN: 175.9000 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9616 - val_Recall: 0.9429 - val_TP: 758.1000 - val_TN: 1080.7900 - val_FP: 25.2100 - val_FN: 45.9000\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0511 - Accuracy: 0.9821 - Precision: 0.9565 - Recall: 0.9478 - TP: 3196.0300 - TN: 5518.4199 - FP: 128.5800 - FN: 175.9700 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9617 - val_Recall: 0.9429 - val_TP: 758.1300 - val_TN: 1080.9000 - val_FP: 25.1000 - val_FN: 45.8700\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0511 - Accuracy: 0.9821 - Precision: 0.9562 - Recall: 0.9481 - TP: 3196.8999 - TN: 5516.6899 - FP: 130.3100 - FN: 175.1000 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9620 - val_Recall: 0.9429 - val_TP: 758.0900 - val_TN: 1081.1400 - val_FP: 24.8600 - val_FN: 45.9100\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0511 - Accuracy: 0.9821 - Precision: 0.9564 - Recall: 0.9479 - TP: 3196.4299 - TN: 5518.1899 - FP: 128.8100 - FN: 175.5700 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9430 - val_TP: 758.2100 - val_TN: 1079.9000 - val_FP: 26.1000 - val_FN: 45.7900\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0511 - Accuracy: 0.9821 - Precision: 0.9562 - Recall: 0.9480 - TP: 3196.7500 - TN: 5516.9399 - FP: 130.0600 - FN: 175.2500 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9616 - val_Recall: 0.9430 - val_TP: 758.1800 - val_TN: 1080.7600 - val_FP: 25.2400 - val_FN: 45.8200\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0510 - Accuracy: 0.9821 - Precision: 0.9562 - Recall: 0.9481 - TP: 3196.9800 - TN: 5516.8101 - FP: 130.1900 - FN: 175.0200 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9617 - val_Recall: 0.9430 - val_TP: 758.1600 - val_TN: 1080.9100 - val_FP: 25.0900 - val_FN: 45.8400\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0510 - Accuracy: 0.9823 - Precision: 0.9563 - Recall: 0.9481 - TP: 3196.8401 - TN: 5517.4502 - FP: 129.5500 - FN: 175.1600 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9429 - val_TP: 758.0900 - val_TN: 1081.2700 - val_FP: 24.7300 - val_FN: 45.9100\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0510 - Accuracy: 0.9821 - Precision: 0.9567 - Recall: 0.9479 - TP: 3196.3000 - TN: 5519.2002 - FP: 127.8000 - FN: 175.7000 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9617 - val_Recall: 0.9430 - val_TP: 758.1800 - val_TN: 1080.9100 - val_FP: 25.0900 - val_FN: 45.8200\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 5s 8ms/step - loss: 0.0514 - Accuracy: 0.9820 - Precision: 0.9569 - Recall: 0.9475 - TP: 3195.1101 - TN: 5520.9600 - FP: 126.0400 - FN: 176.8900 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9428 - val_TP: 758.0500 - val_TN: 1080.7700 - val_FP: 25.2300 - val_FN: 45.9500\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0513 - Accuracy: 0.9819 - Precision: 0.9562 - Recall: 0.9479 - TP: 3196.2800 - TN: 5517.0298 - FP: 129.9700 - FN: 175.7200 - val_loss: 0.0740 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9429 - val_TP: 758.1000 - val_TN: 1080.5800 - val_FP: 25.4200 - val_FN: 45.9000\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0513 - Accuracy: 0.9820 - Precision: 0.9563 - Recall: 0.9478 - TP: 3195.8501 - TN: 5517.0898 - FP: 129.9100 - FN: 176.1500 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9429 - val_TP: 758.0900 - val_TN: 1080.8700 - val_FP: 25.1300 - val_FN: 45.9100\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0512 - Accuracy: 0.9819 - Precision: 0.9562 - Recall: 0.9479 - TP: 3196.1599 - TN: 5517.2900 - FP: 129.7100 - FN: 175.8400 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9429 - val_TP: 758.0900 - val_TN: 1081.0000 - val_FP: 25.0000 - val_FN: 45.9100\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0513 - Accuracy: 0.9821 - Precision: 0.9561 - Recall: 0.9478 - TP: 3196.1399 - TN: 5516.4102 - FP: 130.5900 - FN: 175.8600 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9620 - val_Recall: 0.9429 - val_TP: 758.0800 - val_TN: 1081.2200 - val_FP: 24.7800 - val_FN: 45.9200\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0512 - Accuracy: 0.9820 - Precision: 0.9564 - Recall: 0.9479 - TP: 3196.1599 - TN: 5518.2202 - FP: 128.7800 - FN: 175.8400 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9614 - val_Recall: 0.9429 - val_TP: 758.1100 - val_TN: 1080.6200 - val_FP: 25.3800 - val_FN: 45.8900\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0512 - Accuracy: 0.9823 - Precision: 0.9560 - Recall: 0.9480 - TP: 3196.5601 - TN: 5516.1201 - FP: 130.8800 - FN: 175.4400 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9619 - val_Recall: 0.9429 - val_TP: 758.1100 - val_TN: 1081.1000 - val_FP: 24.9000 - val_FN: 45.8900\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0512 - Accuracy: 0.9821 - Precision: 0.9563 - Recall: 0.9480 - TP: 3196.6201 - TN: 5517.3999 - FP: 129.6000 - FN: 175.3800 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9619 - val_Recall: 0.9429 - val_TP: 758.1100 - val_TN: 1081.0900 - val_FP: 24.9100 - val_FN: 45.8900\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0512 - Accuracy: 0.9820 - Precision: 0.9564 - Recall: 0.9479 - TP: 3196.2500 - TN: 5518.1001 - FP: 128.9000 - FN: 175.7500 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9618 - val_Recall: 0.9429 - val_TP: 758.1100 - val_TN: 1080.9700 - val_FP: 25.0300 - val_FN: 45.8900\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0513 - Accuracy: 0.9818 - Precision: 0.9561 - Recall: 0.9479 - TP: 3196.4500 - TN: 5516.6602 - FP: 130.3400 - FN: 175.5500 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9618 - val_Recall: 0.9429 - val_TP: 758.0800 - val_TN: 1081.0100 - val_FP: 24.9900 - val_FN: 45.9200\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0512 - Accuracy: 0.9820 - Precision: 0.9565 - Recall: 0.9478 - TP: 3196.0000 - TN: 5518.1899 - FP: 128.8100 - FN: 176.0000 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9616 - val_Recall: 0.9429 - val_TP: 758.1100 - val_TN: 1080.8101 - val_FP: 25.1900 - val_FN: 45.8900\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 0.0512 - Accuracy: 0.9821 - Precision: 0.9562 - Recall: 0.9480 - TP: 3196.5701 - TN: 5516.7900 - FP: 130.2100 - FN: 175.4300 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9615 - val_Recall: 0.9430 - val_TP: 758.1800 - val_TN: 1080.7200 - val_FP: 25.2800 - val_FN: 45.8200\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0512 - Accuracy: 0.9820 - Precision: 0.9564 - Recall: 0.9479 - TP: 3196.3201 - TN: 5517.8398 - FP: 129.1600 - FN: 175.6800 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9621 - val_Recall: 0.9429 - val_TP: 758.0700 - val_TN: 1081.3101 - val_FP: 24.6900 - val_FN: 45.9300\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0512 - Accuracy: 0.9820 - Precision: 0.9564 - Recall: 0.9479 - TP: 3196.3899 - TN: 5517.7002 - FP: 129.3000 - FN: 175.6100 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9618 - val_Recall: 0.9429 - val_TP: 758.0800 - val_TN: 1080.9700 - val_FP: 25.0300 - val_FN: 45.9200\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0511 - Accuracy: 0.9824 - Precision: 0.9562 - Recall: 0.9480 - TP: 3196.7300 - TN: 5517.0298 - FP: 129.9700 - FN: 175.2700 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9617 - val_Recall: 0.9430 - val_TP: 758.1700 - val_TN: 1080.8600 - val_FP: 25.1400 - val_FN: 45.8300\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0512 - Accuracy: 0.9821 - Precision: 0.9561 - Recall: 0.9481 - TP: 3196.9299 - TN: 5516.7402 - FP: 130.2600 - FN: 175.0700 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9620 - val_Recall: 0.9429 - val_TP: 758.1200 - val_TN: 1081.2200 - val_FP: 24.7800 - val_FN: 45.8800\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0511 - Accuracy: 0.9821 - Precision: 0.9563 - Recall: 0.9480 - TP: 3196.8101 - TN: 5517.2402 - FP: 129.7600 - FN: 175.1900 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9618 - val_Recall: 0.9429 - val_TP: 758.1300 - val_TN: 1081.0000 - val_FP: 25.0000 - val_FN: 45.8700\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0511 - Accuracy: 0.9823 - Precision: 0.9565 - Recall: 0.9480 - TP: 3196.6001 - TN: 5518.3398 - FP: 128.6600 - FN: 175.4000 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9617 - val_Recall: 0.9430 - val_TP: 758.1500 - val_TN: 1080.9100 - val_FP: 25.0900 - val_FN: 45.8500\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0510 - Accuracy: 0.9823 - Precision: 0.9564 - Recall: 0.9481 - TP: 3196.9600 - TN: 5517.6602 - FP: 129.3400 - FN: 175.0400 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9616 - val_Recall: 0.9430 - val_TP: 758.1800 - val_TN: 1080.8400 - val_FP: 25.1600 - val_FN: 45.8200\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0510 - Accuracy: 0.9823 - Precision: 0.9565 - Recall: 0.9481 - TP: 3196.8601 - TN: 5518.4199 - FP: 128.5800 - FN: 175.1400 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9615 - val_Recall: 0.9431 - val_TP: 758.2200 - val_TN: 1080.7500 - val_FP: 25.2500 - val_FN: 45.7800\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0509 - Accuracy: 0.9824 - Precision: 0.9566 - Recall: 0.9480 - TP: 3196.7400 - TN: 5518.5200 - FP: 128.4800 - FN: 175.2600 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9431 - val_TP: 758.2200 - val_TN: 1080.0300 - val_FP: 25.9700 - val_FN: 45.7800\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0510 - Accuracy: 0.9823 - Precision: 0.9563 - Recall: 0.9480 - TP: 3196.7600 - TN: 5517.2402 - FP: 129.7600 - FN: 175.2400 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9617 - val_Recall: 0.9430 - val_TP: 758.2000 - val_TN: 1080.8600 - val_FP: 25.1400 - val_FN: 45.8000\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0510 - Accuracy: 0.9823 - Precision: 0.9563 - Recall: 0.9481 - TP: 3197.1201 - TN: 5517.3901 - FP: 129.6100 - FN: 174.8800 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9619 - val_Recall: 0.9429 - val_TP: 758.1300 - val_TN: 1081.0800 - val_FP: 24.9200 - val_FN: 45.8700\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0509 - Accuracy: 0.9823 - Precision: 0.9564 - Recall: 0.9481 - TP: 3196.9199 - TN: 5517.7798 - FP: 129.2200 - FN: 175.0800 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9614 - val_Recall: 0.9431 - val_TP: 758.2400 - val_TN: 1080.6200 - val_FP: 25.3800 - val_FN: 45.7600\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0509 - Accuracy: 0.9824 - Precision: 0.9564 - Recall: 0.9482 - TP: 3197.1699 - TN: 5518.0801 - FP: 128.9200 - FN: 174.8300 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9615 - val_Recall: 0.9431 - val_TP: 758.2500 - val_TN: 1080.6801 - val_FP: 25.3200 - val_FN: 45.7500\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0509 - Accuracy: 0.9821 - Precision: 0.9564 - Recall: 0.9481 - TP: 3197.0901 - TN: 5517.7100 - FP: 129.2900 - FN: 174.9100 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9617 - val_Recall: 0.9430 - val_TP: 758.2100 - val_TN: 1080.8600 - val_FP: 25.1400 - val_FN: 45.7900\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0509 - Accuracy: 0.9823 - Precision: 0.9564 - Recall: 0.9482 - TP: 3197.1899 - TN: 5517.6001 - FP: 129.4000 - FN: 174.8100 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9619 - val_Recall: 0.9430 - val_TP: 758.2100 - val_TN: 1081.0800 - val_FP: 24.9200 - val_FN: 45.7900\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0509 - Accuracy: 0.9824 - Precision: 0.9566 - Recall: 0.9481 - TP: 3196.9700 - TN: 5518.5698 - FP: 128.4300 - FN: 175.0300 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9617 - val_Recall: 0.9430 - val_TP: 758.2100 - val_TN: 1080.9100 - val_FP: 25.0900 - val_FN: 45.7900\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0508 - Accuracy: 0.9826 - Precision: 0.9566 - Recall: 0.9482 - TP: 3197.3401 - TN: 5518.8501 - FP: 128.1500 - FN: 174.6600 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9617 - val_Recall: 0.9431 - val_TP: 758.2200 - val_TN: 1080.8600 - val_FP: 25.1400 - val_FN: 45.7800\n",
      "Epoch 30/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0508 - Accuracy: 0.9825 - Precision: 0.9564 - Recall: 0.9483 - TP: 3197.7600 - TN: 5518.2002 - FP: 128.8000 - FN: 174.2400 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9617 - val_Recall: 0.9430 - val_TP: 758.1900 - val_TN: 1080.9399 - val_FP: 25.0600 - val_FN: 45.8100\n",
      "Epoch 31/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0509 - Accuracy: 0.9824 - Precision: 0.9565 - Recall: 0.9482 - TP: 3197.1699 - TN: 5518.2202 - FP: 128.7800 - FN: 174.8300 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9618 - val_Recall: 0.9430 - val_TP: 758.1600 - val_TN: 1081.0100 - val_FP: 24.9900 - val_FN: 45.8400\n",
      "Epoch 32/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0508 - Accuracy: 0.9824 - Precision: 0.9564 - Recall: 0.9484 - TP: 3197.8999 - TN: 5517.6401 - FP: 129.3600 - FN: 174.1000 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9430 - val_TP: 758.1400 - val_TN: 1081.2800 - val_FP: 24.7200 - val_FN: 45.8600\n",
      "Epoch 33/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0508 - Accuracy: 0.9825 - Precision: 0.9566 - Recall: 0.9482 - TP: 3197.4399 - TN: 5519.1802 - FP: 127.8200 - FN: 174.5600 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9430 - val_TP: 758.2000 - val_TN: 1080.2200 - val_FP: 25.7800 - val_FN: 45.8000\n",
      "Epoch 34/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0508 - Accuracy: 0.9826 - Precision: 0.9562 - Recall: 0.9483 - TP: 3197.7200 - TN: 5516.9302 - FP: 130.0700 - FN: 174.2800 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9430 - val_TP: 758.1700 - val_TN: 1081.4200 - val_FP: 24.5800 - val_FN: 45.8300\n",
      "Epoch 35/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0507 - Accuracy: 0.9823 - Precision: 0.9567 - Recall: 0.9482 - TP: 3197.4700 - TN: 5519.4102 - FP: 127.5900 - FN: 174.5300 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9618 - val_Recall: 0.9430 - val_TP: 758.1900 - val_TN: 1081.0400 - val_FP: 24.9600 - val_FN: 45.8100\n",
      "Epoch 36/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0507 - Accuracy: 0.9823 - Precision: 0.9564 - Recall: 0.9484 - TP: 3198.1299 - TN: 5517.6802 - FP: 129.3200 - FN: 173.8700 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9619 - val_Recall: 0.9430 - val_TP: 758.1800 - val_TN: 1081.0900 - val_FP: 24.9100 - val_FN: 45.8200\n",
      "Epoch 37/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0507 - Accuracy: 0.9825 - Precision: 0.9567 - Recall: 0.9483 - TP: 3197.6299 - TN: 5519.2500 - FP: 127.7500 - FN: 174.3700 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9431 - val_TP: 758.2500 - val_TN: 1080.9200 - val_FP: 25.0800 - val_FN: 45.7500\n",
      "Epoch 38/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0507 - Accuracy: 0.9824 - Precision: 0.9567 - Recall: 0.9482 - TP: 3197.3601 - TN: 5519.3501 - FP: 127.6500 - FN: 174.6400 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9618 - val_Recall: 0.9430 - val_TP: 758.1600 - val_TN: 1081.0100 - val_FP: 24.9900 - val_FN: 45.8400\n",
      "Epoch 39/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0506 - Accuracy: 0.9823 - Precision: 0.9567 - Recall: 0.9482 - TP: 3197.3000 - TN: 5518.9800 - FP: 128.0200 - FN: 174.7000 - val_loss: 0.0742 - val_Accuracy: 0.9780 - val_Precision: 0.9608 - val_Recall: 0.9431 - val_TP: 758.2900 - val_TN: 1079.9600 - val_FP: 26.0400 - val_FN: 45.7100\n",
      "Epoch 40/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0507 - Accuracy: 0.9824 - Precision: 0.9566 - Recall: 0.9483 - TP: 3197.6399 - TN: 5518.9102 - FP: 128.0900 - FN: 174.3600 - val_loss: 0.0743 - val_Accuracy: 0.9780 - val_Precision: 0.9609 - val_Recall: 0.9431 - val_TP: 758.2600 - val_TN: 1080.0100 - val_FP: 25.9900 - val_FN: 45.7400\n",
      "Epoch 41/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0507 - Accuracy: 0.9824 - Precision: 0.9564 - Recall: 0.9484 - TP: 3197.9299 - TN: 5517.3501 - FP: 129.6500 - FN: 174.0700 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9619 - val_Recall: 0.9431 - val_TP: 758.2200 - val_TN: 1081.1000 - val_FP: 24.9000 - val_FN: 45.7800\n",
      "Epoch 42/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0506 - Accuracy: 0.9823 - Precision: 0.9567 - Recall: 0.9483 - TP: 3197.7600 - TN: 5519.3901 - FP: 127.6100 - FN: 174.2400 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9431 - val_TP: 758.2400 - val_TN: 1080.7400 - val_FP: 25.2600 - val_FN: 45.7600\n",
      "Epoch 43/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0506 - Accuracy: 0.9823 - Precision: 0.9565 - Recall: 0.9484 - TP: 3197.9299 - TN: 5518.0698 - FP: 128.9300 - FN: 174.0700 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9431 - val_TP: 758.2600 - val_TN: 1080.8000 - val_FP: 25.2000 - val_FN: 45.7400\n",
      "Epoch 44/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0506 - Accuracy: 0.9823 - Precision: 0.9564 - Recall: 0.9483 - TP: 3197.5500 - TN: 5517.7700 - FP: 129.2300 - FN: 174.4500 - val_loss: 0.0736 - val_Accuracy: 0.9770 - val_Precision: 0.9623 - val_Recall: 0.9429 - val_TP: 758.1300 - val_TN: 1081.5400 - val_FP: 24.4600 - val_FN: 45.8700\n",
      "Epoch 45/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0506 - Accuracy: 0.9825 - Precision: 0.9567 - Recall: 0.9484 - TP: 3197.8899 - TN: 5519.0000 - FP: 128.0000 - FN: 174.1100 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9431 - val_TP: 758.2200 - val_TN: 1081.0400 - val_FP: 24.9600 - val_FN: 45.7800\n",
      "Epoch 46/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0505 - Accuracy: 0.9823 - Precision: 0.9568 - Recall: 0.9483 - TP: 3197.6799 - TN: 5519.4702 - FP: 127.5300 - FN: 174.3200 - val_loss: 0.0743 - val_Accuracy: 0.9780 - val_Precision: 0.9607 - val_Recall: 0.9432 - val_TP: 758.3300 - val_TN: 1079.8199 - val_FP: 26.1800 - val_FN: 45.6700\n",
      "Epoch 47/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0505 - Accuracy: 0.9825 - Precision: 0.9563 - Recall: 0.9485 - TP: 3198.1799 - TN: 5517.3101 - FP: 129.6900 - FN: 173.8200 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9430 - val_TP: 758.1700 - val_TN: 1081.3900 - val_FP: 24.6100 - val_FN: 45.8300\n",
      "Epoch 48/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0506 - Accuracy: 0.9824 - Precision: 0.9567 - Recall: 0.9483 - TP: 3197.8201 - TN: 5518.8501 - FP: 128.1500 - FN: 174.1800 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9430 - val_TP: 758.1600 - val_TN: 1081.4500 - val_FP: 24.5500 - val_FN: 45.8400\n",
      "Epoch 49/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0505 - Accuracy: 0.9825 - Precision: 0.9567 - Recall: 0.9485 - TP: 3198.2700 - TN: 5519.4800 - FP: 127.5200 - FN: 173.7300 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9619 - val_Recall: 0.9431 - val_TP: 758.2600 - val_TN: 1081.0900 - val_FP: 24.9100 - val_FN: 45.7400\n",
      "Epoch 50/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0506 - Accuracy: 0.9824 - Precision: 0.9568 - Recall: 0.9484 - TP: 3197.9199 - TN: 5519.6099 - FP: 127.3900 - FN: 174.0800 - val_loss: 0.0742 - val_Accuracy: 0.9780 - val_Precision: 0.9609 - val_Recall: 0.9432 - val_TP: 758.3300 - val_TN: 1080.0200 - val_FP: 25.9800 - val_FN: 45.6700\n",
      "Epoch 51/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0506 - Accuracy: 0.9825 - Precision: 0.9566 - Recall: 0.9485 - TP: 3198.3201 - TN: 5518.6001 - FP: 128.4000 - FN: 173.6800 - val_loss: 0.0741 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9432 - val_TP: 758.3300 - val_TN: 1080.6500 - val_FP: 25.3500 - val_FN: 45.6700\n",
      "Epoch 52/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0504 - Accuracy: 0.9824 - Precision: 0.9566 - Recall: 0.9485 - TP: 3198.2500 - TN: 5518.6299 - FP: 128.3700 - FN: 173.7500 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9431 - val_TP: 758.2500 - val_TN: 1081.0100 - val_FP: 24.9900 - val_FN: 45.7500\n",
      "Epoch 53/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0504 - Accuracy: 0.9825 - Precision: 0.9567 - Recall: 0.9485 - TP: 3198.3899 - TN: 5519.5400 - FP: 127.4600 - FN: 173.6100 - val_loss: 0.0743 - val_Accuracy: 0.9780 - val_Precision: 0.9610 - val_Recall: 0.9431 - val_TP: 758.2400 - val_TN: 1080.1100 - val_FP: 25.8900 - val_FN: 45.7600\n",
      "Epoch 54/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0505 - Accuracy: 0.9824 - Precision: 0.9565 - Recall: 0.9485 - TP: 3198.4399 - TN: 5517.9600 - FP: 129.0400 - FN: 173.5600 - val_loss: 0.0741 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9432 - val_TP: 758.3300 - val_TN: 1080.6300 - val_FP: 25.3700 - val_FN: 45.6700\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 7ms/step - loss: 0.0508 - Accuracy: 0.9824 - Precision: 0.9566 - Recall: 0.9483 - TP: 3197.7800 - TN: 5519.1401 - FP: 127.8600 - FN: 174.2200 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9431 - val_TP: 758.2900 - val_TN: 1081.0100 - val_FP: 24.9900 - val_FN: 45.7100\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0507 - Accuracy: 0.9824 - Precision: 0.9567 - Recall: 0.9482 - TP: 3197.3999 - TN: 5519.3101 - FP: 127.6900 - FN: 174.6000 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9615 - val_Recall: 0.9431 - val_TP: 758.2200 - val_TN: 1080.7400 - val_FP: 25.2600 - val_FN: 45.7800\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 0.0508 - Accuracy: 0.9824 - Precision: 0.9564 - Recall: 0.9482 - TP: 3197.4900 - TN: 5517.8999 - FP: 129.1000 - FN: 174.5100 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9431 - val_TP: 758.2600 - val_TN: 1080.8600 - val_FP: 25.1400 - val_FN: 45.7400\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 0.0507 - Accuracy: 0.9823 - Precision: 0.9567 - Recall: 0.9482 - TP: 3197.4399 - TN: 5519.0698 - FP: 127.9300 - FN: 174.5600 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9617 - val_Recall: 0.9430 - val_TP: 758.1800 - val_TN: 1080.9500 - val_FP: 25.0500 - val_FN: 45.8200\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0507 - Accuracy: 0.9824 - Precision: 0.9563 - Recall: 0.9484 - TP: 3197.8501 - TN: 5517.4302 - FP: 129.5700 - FN: 174.1500 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9431 - val_TP: 758.2500 - val_TN: 1081.0400 - val_FP: 24.9600 - val_FN: 45.7500\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 0.0507 - Accuracy: 0.9824 - Precision: 0.9566 - Recall: 0.9482 - TP: 3197.3401 - TN: 5518.9600 - FP: 128.0400 - FN: 174.6600 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9619 - val_Recall: 0.9430 - val_TP: 758.1900 - val_TN: 1081.1200 - val_FP: 24.8800 - val_FN: 45.8100\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 3s 11ms/step - loss: 0.0507 - Accuracy: 0.9824 - Precision: 0.9565 - Recall: 0.9485 - TP: 3198.1799 - TN: 5518.1899 - FP: 128.8100 - FN: 173.8200 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9430 - val_TP: 758.1900 - val_TN: 1080.9301 - val_FP: 25.0700 - val_FN: 45.8100\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0507 - Accuracy: 0.9825 - Precision: 0.9566 - Recall: 0.9484 - TP: 3197.9299 - TN: 5518.5200 - FP: 128.4800 - FN: 174.0700 - val_loss: 0.0740 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9431 - val_TP: 758.2600 - val_TN: 1080.7800 - val_FP: 25.2200 - val_FN: 45.7400\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0507 - Accuracy: 0.9823 - Precision: 0.9565 - Recall: 0.9484 - TP: 3198.0000 - TN: 5518.2402 - FP: 128.7600 - FN: 174.0000 - val_loss: 0.0734 - val_Accuracy: 0.9780 - val_Precision: 0.9627 - val_Recall: 0.9430 - val_TP: 758.1800 - val_TN: 1082.0900 - val_FP: 23.9100 - val_FN: 45.8200\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0506 - Accuracy: 0.9825 - Precision: 0.9565 - Recall: 0.9486 - TP: 3198.5400 - TN: 5518.2900 - FP: 128.7100 - FN: 173.4600 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9622 - val_Recall: 0.9430 - val_TP: 758.1800 - val_TN: 1081.4700 - val_FP: 24.5300 - val_FN: 45.8200\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0506 - Accuracy: 0.9825 - Precision: 0.9566 - Recall: 0.9483 - TP: 3197.7600 - TN: 5519.2998 - FP: 127.7000 - FN: 174.2400 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9431 - val_TP: 758.2600 - val_TN: 1081.0000 - val_FP: 25.0000 - val_FN: 45.7400\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0506 - Accuracy: 0.9825 - Precision: 0.9566 - Recall: 0.9484 - TP: 3198.1001 - TN: 5518.5898 - FP: 128.4100 - FN: 173.9000 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9622 - val_Recall: 0.9430 - val_TP: 758.1800 - val_TN: 1081.4100 - val_FP: 24.5900 - val_FN: 45.8200\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 0.0506 - Accuracy: 0.9824 - Precision: 0.9566 - Recall: 0.9485 - TP: 3198.3201 - TN: 5518.8398 - FP: 128.1600 - FN: 173.6800 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9430 - val_TP: 758.1600 - val_TN: 1081.3900 - val_FP: 24.6100 - val_FN: 45.8400\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0506 - Accuracy: 0.9824 - Precision: 0.9566 - Recall: 0.9484 - TP: 3197.8401 - TN: 5518.7998 - FP: 128.2000 - FN: 174.1600 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9620 - val_Recall: 0.9431 - val_TP: 758.2300 - val_TN: 1081.1801 - val_FP: 24.8200 - val_FN: 45.7700\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 0.0504 - Accuracy: 0.9824 - Precision: 0.9570 - Recall: 0.9483 - TP: 3197.8101 - TN: 5520.7500 - FP: 126.2500 - FN: 174.1900 - val_loss: 0.0742 - val_Accuracy: 0.9780 - val_Precision: 0.9611 - val_Recall: 0.9431 - val_TP: 758.2600 - val_TN: 1080.1899 - val_FP: 25.8100 - val_FN: 45.7400\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0505 - Accuracy: 0.9826 - Precision: 0.9561 - Recall: 0.9487 - TP: 3198.9099 - TN: 5516.3501 - FP: 130.6500 - FN: 173.0900 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9430 - val_TP: 758.1800 - val_TN: 1081.4900 - val_FP: 24.5100 - val_FN: 45.8200\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0505 - Accuracy: 0.9824 - Precision: 0.9569 - Recall: 0.9484 - TP: 3197.9099 - TN: 5520.2100 - FP: 126.7900 - FN: 174.0900 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9621 - val_Recall: 0.9431 - val_TP: 758.2200 - val_TN: 1081.3500 - val_FP: 24.6500 - val_FN: 45.7800\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0506 - Accuracy: 0.9825 - Precision: 0.9568 - Recall: 0.9485 - TP: 3198.2000 - TN: 5519.4702 - FP: 127.5300 - FN: 173.8000 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9619 - val_Recall: 0.9430 - val_TP: 758.2100 - val_TN: 1081.0800 - val_FP: 24.9200 - val_FN: 45.7900\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0504 - Accuracy: 0.9825 - Precision: 0.9566 - Recall: 0.9486 - TP: 3198.5400 - TN: 5518.8398 - FP: 128.1600 - FN: 173.4600 - val_loss: 0.0734 - val_Accuracy: 0.9775 - val_Precision: 0.9628 - val_Recall: 0.9430 - val_TP: 758.1700 - val_TN: 1082.1801 - val_FP: 23.8200 - val_FN: 45.8300\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0505 - Accuracy: 0.9825 - Precision: 0.9567 - Recall: 0.9485 - TP: 3198.2500 - TN: 5519.3101 - FP: 127.6900 - FN: 173.7500 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9622 - val_Recall: 0.9431 - val_TP: 758.2300 - val_TN: 1081.3900 - val_FP: 24.6100 - val_FN: 45.7700\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0504 - Accuracy: 0.9824 - Precision: 0.9569 - Recall: 0.9485 - TP: 3198.2500 - TN: 5519.9800 - FP: 127.0200 - FN: 173.7500 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9618 - val_Recall: 0.9431 - val_TP: 758.2300 - val_TN: 1081.0000 - val_FP: 25.0000 - val_FN: 45.7700\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0504 - Accuracy: 0.9825 - Precision: 0.9565 - Recall: 0.9486 - TP: 3198.7100 - TN: 5518.1802 - FP: 128.8200 - FN: 173.2900 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9430 - val_TP: 758.2000 - val_TN: 1081.3300 - val_FP: 24.6700 - val_FN: 45.8000\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0504 - Accuracy: 0.9825 - Precision: 0.9569 - Recall: 0.9485 - TP: 3198.2300 - TN: 5520.5698 - FP: 126.4300 - FN: 173.7700 - val_loss: 0.0740 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9432 - val_TP: 758.3200 - val_TN: 1080.8000 - val_FP: 25.2000 - val_FN: 45.6800\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0503 - Accuracy: 0.9826 - Precision: 0.9565 - Recall: 0.9487 - TP: 3199.1699 - TN: 5518.1602 - FP: 128.8400 - FN: 172.8300 - val_loss: 0.0734 - val_Accuracy: 0.9780 - val_Precision: 0.9627 - val_Recall: 0.9431 - val_TP: 758.2600 - val_TN: 1082.1400 - val_FP: 23.8600 - val_FN: 45.7400\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0503 - Accuracy: 0.9823 - Precision: 0.9569 - Recall: 0.9483 - TP: 3197.7700 - TN: 5520.5698 - FP: 126.4300 - FN: 174.2300 - val_loss: 0.0744 - val_Accuracy: 0.9780 - val_Precision: 0.9610 - val_Recall: 0.9432 - val_TP: 758.3400 - val_TN: 1080.1400 - val_FP: 25.8600 - val_FN: 45.6600\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0503 - Accuracy: 0.9826 - Precision: 0.9566 - Recall: 0.9487 - TP: 3198.9199 - TN: 5518.7100 - FP: 128.2900 - FN: 173.0800 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9622 - val_Recall: 0.9431 - val_TP: 758.2800 - val_TN: 1081.4100 - val_FP: 24.5900 - val_FN: 45.7200\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0504 - Accuracy: 0.9826 - Precision: 0.9568 - Recall: 0.9485 - TP: 3198.3899 - TN: 5519.3599 - FP: 127.6400 - FN: 173.6100 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9620 - val_Recall: 0.9432 - val_TP: 758.3200 - val_TN: 1081.2000 - val_FP: 24.8000 - val_FN: 45.6800\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0504 - Accuracy: 0.9824 - Precision: 0.9568 - Recall: 0.9486 - TP: 3198.5200 - TN: 5519.5000 - FP: 127.5000 - FN: 173.4800 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9619 - val_Recall: 0.9432 - val_TP: 758.3200 - val_TN: 1081.0900 - val_FP: 24.9100 - val_FN: 45.6800\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0503 - Accuracy: 0.9824 - Precision: 0.9569 - Recall: 0.9486 - TP: 3198.6001 - TN: 5519.8198 - FP: 127.1800 - FN: 173.4000 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9431 - val_TP: 758.2600 - val_TN: 1081.3400 - val_FP: 24.6600 - val_FN: 45.7400\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 9ms/step - loss: 0.0512 - Accuracy: 0.9823 - Precision: 0.9575 - Recall: 0.9479 - TP: 3196.3000 - TN: 5523.6899 - FP: 123.3100 - FN: 175.7000 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9619 - val_Recall: 0.9431 - val_TP: 758.2900 - val_TN: 1081.1300 - val_FP: 24.8700 - val_FN: 45.7100\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0506 - Accuracy: 0.9825 - Precision: 0.9564 - Recall: 0.9485 - TP: 3198.3601 - TN: 5517.5400 - FP: 129.4600 - FN: 173.6400 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9620 - val_Recall: 0.9431 - val_TP: 758.2400 - val_TN: 1081.2300 - val_FP: 24.7700 - val_FN: 45.7600\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0506 - Accuracy: 0.9825 - Precision: 0.9566 - Recall: 0.9485 - TP: 3198.2200 - TN: 5518.8599 - FP: 128.1400 - FN: 173.7800 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9431 - val_TP: 758.2800 - val_TN: 1080.9200 - val_FP: 25.0800 - val_FN: 45.7200\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0507 - Accuracy: 0.9825 - Precision: 0.9567 - Recall: 0.9483 - TP: 3197.6101 - TN: 5519.3901 - FP: 127.6100 - FN: 174.3900 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9431 - val_TP: 758.2500 - val_TN: 1080.8500 - val_FP: 25.1500 - val_FN: 45.7500\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0505 - Accuracy: 0.9825 - Precision: 0.9566 - Recall: 0.9484 - TP: 3198.0100 - TN: 5518.7900 - FP: 128.2100 - FN: 173.9900 - val_loss: 0.0734 - val_Accuracy: 0.9780 - val_Precision: 0.9626 - val_Recall: 0.9430 - val_TP: 758.2000 - val_TN: 1082.0000 - val_FP: 24.0000 - val_FN: 45.8000\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0506 - Accuracy: 0.9825 - Precision: 0.9567 - Recall: 0.9484 - TP: 3198.0000 - TN: 5519.0000 - FP: 128.0000 - FN: 174.0000 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9620 - val_Recall: 0.9430 - val_TP: 758.1900 - val_TN: 1081.2500 - val_FP: 24.7500 - val_FN: 45.8100\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 0.0505 - Accuracy: 0.9824 - Precision: 0.9568 - Recall: 0.9484 - TP: 3197.9299 - TN: 5519.7402 - FP: 127.2600 - FN: 174.0700 - val_loss: 0.0740 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9431 - val_TP: 758.2800 - val_TN: 1080.8101 - val_FP: 25.1900 - val_FN: 45.7200\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0506 - Accuracy: 0.9823 - Precision: 0.9566 - Recall: 0.9485 - TP: 3198.3101 - TN: 5518.9399 - FP: 128.0600 - FN: 173.6900 - val_loss: 0.0743 - val_Accuracy: 0.9780 - val_Precision: 0.9608 - val_Recall: 0.9433 - val_TP: 758.3800 - val_TN: 1079.8900 - val_FP: 26.1100 - val_FN: 45.6200\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0505 - Accuracy: 0.9824 - Precision: 0.9565 - Recall: 0.9485 - TP: 3198.3101 - TN: 5517.8901 - FP: 129.1100 - FN: 173.6900 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9619 - val_Recall: 0.9432 - val_TP: 758.3000 - val_TN: 1081.1100 - val_FP: 24.8900 - val_FN: 45.7000\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0505 - Accuracy: 0.9827 - Precision: 0.9567 - Recall: 0.9486 - TP: 3198.7200 - TN: 5519.1602 - FP: 127.8400 - FN: 173.2800 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9621 - val_Recall: 0.9431 - val_TP: 758.2800 - val_TN: 1081.3500 - val_FP: 24.6500 - val_FN: 45.7200\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0506 - Accuracy: 0.9824 - Precision: 0.9567 - Recall: 0.9484 - TP: 3198.0000 - TN: 5519.5498 - FP: 127.4500 - FN: 174.0000 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9432 - val_TP: 758.3500 - val_TN: 1081.0200 - val_FP: 24.9800 - val_FN: 45.6500\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0504 - Accuracy: 0.9824 - Precision: 0.9567 - Recall: 0.9485 - TP: 3198.4700 - TN: 5519.1401 - FP: 127.8600 - FN: 173.5300 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9431 - val_TP: 758.2300 - val_TN: 1081.4500 - val_FP: 24.5500 - val_FN: 45.7700\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0504 - Accuracy: 0.9825 - Precision: 0.9567 - Recall: 0.9486 - TP: 3198.7200 - TN: 5518.9199 - FP: 128.0800 - FN: 173.2800 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9620 - val_Recall: 0.9432 - val_TP: 758.3200 - val_TN: 1081.2400 - val_FP: 24.7600 - val_FN: 45.6800\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 0.0504 - Accuracy: 0.9824 - Precision: 0.9568 - Recall: 0.9486 - TP: 3198.5701 - TN: 5519.6602 - FP: 127.3400 - FN: 173.4300 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9619 - val_Recall: 0.9432 - val_TP: 758.3000 - val_TN: 1081.1400 - val_FP: 24.8600 - val_FN: 45.7000\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0504 - Accuracy: 0.9825 - Precision: 0.9569 - Recall: 0.9485 - TP: 3198.4600 - TN: 5520.2798 - FP: 126.7200 - FN: 173.5400 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9620 - val_Recall: 0.9431 - val_TP: 758.2600 - val_TN: 1081.2700 - val_FP: 24.7300 - val_FN: 45.7400\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0503 - Accuracy: 0.9826 - Precision: 0.9568 - Recall: 0.9486 - TP: 3198.5701 - TN: 5519.3599 - FP: 127.6400 - FN: 173.4300 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9620 - val_Recall: 0.9432 - val_TP: 758.3200 - val_TN: 1081.2100 - val_FP: 24.7900 - val_FN: 45.6800\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0504 - Accuracy: 0.9824 - Precision: 0.9569 - Recall: 0.9485 - TP: 3198.5100 - TN: 5520.1699 - FP: 126.8300 - FN: 173.4900 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9430 - val_TP: 758.2000 - val_TN: 1081.3400 - val_FP: 24.6600 - val_FN: 45.8000\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0503 - Accuracy: 0.9825 - Precision: 0.9566 - Recall: 0.9488 - TP: 3199.2600 - TN: 5518.6899 - FP: 128.3100 - FN: 172.7400 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9620 - val_Recall: 0.9432 - val_TP: 758.3300 - val_TN: 1081.2900 - val_FP: 24.7100 - val_FN: 45.6700\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0503 - Accuracy: 0.9824 - Precision: 0.9568 - Recall: 0.9486 - TP: 3198.8201 - TN: 5519.6401 - FP: 127.3600 - FN: 173.1800 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9620 - val_Recall: 0.9432 - val_TP: 758.3600 - val_TN: 1081.2500 - val_FP: 24.7500 - val_FN: 45.6400\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0502 - Accuracy: 0.9825 - Precision: 0.9571 - Recall: 0.9485 - TP: 3198.4099 - TN: 5521.2300 - FP: 125.7700 - FN: 173.5900 - val_loss: 0.0742 - val_Accuracy: 0.9780 - val_Precision: 0.9612 - val_Recall: 0.9432 - val_TP: 758.3400 - val_TN: 1080.3400 - val_FP: 25.6600 - val_FN: 45.6600\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0503 - Accuracy: 0.9826 - Precision: 0.9569 - Recall: 0.9486 - TP: 3198.7400 - TN: 5519.7300 - FP: 127.2700 - FN: 173.2600 - val_loss: 0.0743 - val_Accuracy: 0.9780 - val_Precision: 0.9611 - val_Recall: 0.9432 - val_TP: 758.3600 - val_TN: 1080.2800 - val_FP: 25.7200 - val_FN: 45.6400\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0503 - Accuracy: 0.9824 - Precision: 0.9568 - Recall: 0.9486 - TP: 3198.7700 - TN: 5519.5601 - FP: 127.4400 - FN: 173.2300 - val_loss: 0.0740 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9433 - val_TP: 758.4000 - val_TN: 1080.8400 - val_FP: 25.1600 - val_FN: 45.6000\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0502 - Accuracy: 0.9827 - Precision: 0.9566 - Recall: 0.9488 - TP: 3199.3201 - TN: 5518.8701 - FP: 128.1300 - FN: 172.6800 - val_loss: 0.0741 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9433 - val_TP: 758.3900 - val_TN: 1080.7600 - val_FP: 25.2400 - val_FN: 45.6100\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0503 - Accuracy: 0.9825 - Precision: 0.9569 - Recall: 0.9486 - TP: 3198.6499 - TN: 5520.0098 - FP: 126.9900 - FN: 173.3500 - val_loss: 0.0740 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9433 - val_TP: 758.4000 - val_TN: 1080.8600 - val_FP: 25.1400 - val_FN: 45.6000\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0503 - Accuracy: 0.9829 - Precision: 0.9567 - Recall: 0.9488 - TP: 3199.2400 - TN: 5519.1499 - FP: 127.8500 - FN: 172.7600 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9619 - val_Recall: 0.9433 - val_TP: 758.3900 - val_TN: 1081.1801 - val_FP: 24.8200 - val_FN: 45.6100\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 5s 10ms/step - loss: 0.0507 - Accuracy: 0.9824 - Precision: 0.9570 - Recall: 0.9483 - TP: 3197.5000 - TN: 5520.9902 - FP: 126.0100 - FN: 174.5000 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9621 - val_Recall: 0.9431 - val_TP: 758.2500 - val_TN: 1081.3101 - val_FP: 24.6900 - val_FN: 45.7500\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0505 - Accuracy: 0.9825 - Precision: 0.9568 - Recall: 0.9484 - TP: 3198.1201 - TN: 5519.6401 - FP: 127.3600 - FN: 173.8800 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9620 - val_Recall: 0.9431 - val_TP: 758.2700 - val_TN: 1081.2700 - val_FP: 24.7300 - val_FN: 45.7300\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0507 - Accuracy: 0.9824 - Precision: 0.9567 - Recall: 0.9484 - TP: 3198.1001 - TN: 5519.3501 - FP: 127.6500 - FN: 173.9000 - val_loss: 0.0740 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9432 - val_TP: 758.3400 - val_TN: 1080.6801 - val_FP: 25.3200 - val_FN: 45.6600\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0506 - Accuracy: 0.9825 - Precision: 0.9565 - Recall: 0.9486 - TP: 3198.5300 - TN: 5518.2900 - FP: 128.7100 - FN: 173.4700 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9432 - val_TP: 758.3100 - val_TN: 1080.9301 - val_FP: 25.0700 - val_FN: 45.6900\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0505 - Accuracy: 0.9825 - Precision: 0.9568 - Recall: 0.9484 - TP: 3198.1001 - TN: 5519.7300 - FP: 127.2700 - FN: 173.9000 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9432 - val_TP: 758.3200 - val_TN: 1080.9600 - val_FP: 25.0400 - val_FN: 45.6800\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0505 - Accuracy: 0.9827 - Precision: 0.9565 - Recall: 0.9486 - TP: 3198.6799 - TN: 5518.0898 - FP: 128.9100 - FN: 173.3200 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9620 - val_Recall: 0.9430 - val_TP: 758.2100 - val_TN: 1081.2700 - val_FP: 24.7300 - val_FN: 45.7900\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0504 - Accuracy: 0.9825 - Precision: 0.9568 - Recall: 0.9484 - TP: 3198.1101 - TN: 5519.3901 - FP: 127.6100 - FN: 173.8900 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9619 - val_Recall: 0.9431 - val_TP: 758.2700 - val_TN: 1081.1100 - val_FP: 24.8900 - val_FN: 45.7300\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0504 - Accuracy: 0.9824 - Precision: 0.9567 - Recall: 0.9485 - TP: 3198.4399 - TN: 5519.3799 - FP: 127.6200 - FN: 173.5600 - val_loss: 0.0741 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9432 - val_TP: 758.3200 - val_TN: 1080.7900 - val_FP: 25.2100 - val_FN: 45.6800\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0505 - Accuracy: 0.9827 - Precision: 0.9567 - Recall: 0.9486 - TP: 3198.6399 - TN: 5518.8799 - FP: 128.1200 - FN: 173.3600 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9620 - val_Recall: 0.9432 - val_TP: 758.3100 - val_TN: 1081.2100 - val_FP: 24.7900 - val_FN: 45.6900\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0504 - Accuracy: 0.9827 - Precision: 0.9567 - Recall: 0.9485 - TP: 3198.4199 - TN: 5519.2798 - FP: 127.7200 - FN: 173.5800 - val_loss: 0.0741 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9432 - val_TP: 758.3200 - val_TN: 1080.8800 - val_FP: 25.1200 - val_FN: 45.6800\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0503 - Accuracy: 0.9824 - Precision: 0.9566 - Recall: 0.9486 - TP: 3198.7600 - TN: 5518.8701 - FP: 128.1300 - FN: 173.2400 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9431 - val_TP: 758.2800 - val_TN: 1081.5300 - val_FP: 24.4700 - val_FN: 45.7200\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0504 - Accuracy: 0.9826 - Precision: 0.9572 - Recall: 0.9484 - TP: 3197.9500 - TN: 5521.3701 - FP: 125.6300 - FN: 174.0500 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9619 - val_Recall: 0.9431 - val_TP: 758.2800 - val_TN: 1081.0900 - val_FP: 24.9100 - val_FN: 45.7200\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0505 - Accuracy: 0.9826 - Precision: 0.9563 - Recall: 0.9488 - TP: 3199.4800 - TN: 5517.0601 - FP: 129.9400 - FN: 172.5200 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9431 - val_TP: 758.2900 - val_TN: 1081.4200 - val_FP: 24.5800 - val_FN: 45.7100\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0503 - Accuracy: 0.9826 - Precision: 0.9567 - Recall: 0.9487 - TP: 3199.0400 - TN: 5519.6299 - FP: 127.3700 - FN: 172.9600 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9620 - val_Recall: 0.9431 - val_TP: 758.2400 - val_TN: 1081.2400 - val_FP: 24.7600 - val_FN: 45.7600\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0503 - Accuracy: 0.9826 - Precision: 0.9568 - Recall: 0.9486 - TP: 3198.8301 - TN: 5519.8198 - FP: 127.1800 - FN: 173.1700 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9431 - val_TP: 758.2800 - val_TN: 1081.4500 - val_FP: 24.5500 - val_FN: 45.7200\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0503 - Accuracy: 0.9826 - Precision: 0.9571 - Recall: 0.9483 - TP: 3197.7700 - TN: 5520.7798 - FP: 126.2200 - FN: 174.2300 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9619 - val_Recall: 0.9432 - val_TP: 758.3000 - val_TN: 1081.1700 - val_FP: 24.8300 - val_FN: 45.7000\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0503 - Accuracy: 0.9826 - Precision: 0.9567 - Recall: 0.9489 - TP: 3199.6101 - TN: 5518.8398 - FP: 128.1600 - FN: 172.3900 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9432 - val_TP: 758.3100 - val_TN: 1081.4700 - val_FP: 24.5300 - val_FN: 45.6900\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 0.0503 - Accuracy: 0.9825 - Precision: 0.9569 - Recall: 0.9486 - TP: 3198.5701 - TN: 5520.1401 - FP: 126.8600 - FN: 173.4300 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9620 - val_Recall: 0.9433 - val_TP: 758.3900 - val_TN: 1081.2100 - val_FP: 24.7900 - val_FN: 45.6100\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0502 - Accuracy: 0.9828 - Precision: 0.9569 - Recall: 0.9487 - TP: 3199.0500 - TN: 5520.2998 - FP: 126.7000 - FN: 172.9500 - val_loss: 0.0744 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9432 - val_TP: 758.3100 - val_TN: 1080.2600 - val_FP: 25.7400 - val_FN: 45.6900\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0502 - Accuracy: 0.9824 - Precision: 0.9569 - Recall: 0.9486 - TP: 3198.8000 - TN: 5520.3501 - FP: 126.6500 - FN: 173.2000 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9618 - val_Recall: 0.9432 - val_TP: 758.3400 - val_TN: 1081.0300 - val_FP: 24.9700 - val_FN: 45.6600\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0502 - Accuracy: 0.9827 - Precision: 0.9566 - Recall: 0.9488 - TP: 3199.4299 - TN: 5518.4800 - FP: 128.5200 - FN: 172.5700 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9431 - val_TP: 758.2500 - val_TN: 1081.4800 - val_FP: 24.5200 - val_FN: 45.7500\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0502 - Accuracy: 0.9827 - Precision: 0.9569 - Recall: 0.9488 - TP: 3199.2000 - TN: 5519.9800 - FP: 127.0200 - FN: 172.8000 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9433 - val_TP: 758.3800 - val_TN: 1081.3700 - val_FP: 24.6300 - val_FN: 45.6200\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0501 - Accuracy: 0.9827 - Precision: 0.9568 - Recall: 0.9488 - TP: 3199.3101 - TN: 5519.5498 - FP: 127.4500 - FN: 172.6900 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9620 - val_Recall: 0.9432 - val_TP: 758.3000 - val_TN: 1081.2900 - val_FP: 24.7100 - val_FN: 45.7000\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0502 - Accuracy: 0.9827 - Precision: 0.9569 - Recall: 0.9487 - TP: 3199.0901 - TN: 5520.2100 - FP: 126.7900 - FN: 172.9100 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9620 - val_Recall: 0.9431 - val_TP: 758.2900 - val_TN: 1081.3000 - val_FP: 24.7000 - val_FN: 45.7100\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0501 - Accuracy: 0.9828 - Precision: 0.9568 - Recall: 0.9488 - TP: 3199.3501 - TN: 5519.6699 - FP: 127.3300 - FN: 172.6500 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9432 - val_TP: 758.3000 - val_TN: 1081.5400 - val_FP: 24.4600 - val_FN: 45.7000\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0501 - Accuracy: 0.9826 - Precision: 0.9570 - Recall: 0.9488 - TP: 3199.2000 - TN: 5520.5498 - FP: 126.4500 - FN: 172.8000 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9431 - val_TP: 758.2900 - val_TN: 1081.3600 - val_FP: 24.6400 - val_FN: 45.7100\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0501 - Accuracy: 0.9825 - Precision: 0.9569 - Recall: 0.9487 - TP: 3199.1799 - TN: 5519.8101 - FP: 127.1900 - FN: 172.8200 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9431 - val_TP: 758.2900 - val_TN: 1081.4301 - val_FP: 24.5700 - val_FN: 45.7100\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0500 - Accuracy: 0.9826 - Precision: 0.9568 - Recall: 0.9489 - TP: 3199.6201 - TN: 5519.6001 - FP: 127.4000 - FN: 172.3800 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9622 - val_Recall: 0.9433 - val_TP: 758.4200 - val_TN: 1081.4700 - val_FP: 24.5300 - val_FN: 45.5800\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0500 - Accuracy: 0.9826 - Precision: 0.9571 - Recall: 0.9488 - TP: 3199.3301 - TN: 5520.8398 - FP: 126.1600 - FN: 172.6700 - val_loss: 0.0741 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9434 - val_TP: 758.4600 - val_TN: 1080.8199 - val_FP: 25.1800 - val_FN: 45.5400\n",
      "Epoch 30/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0502 - Accuracy: 0.9828 - Precision: 0.9567 - Recall: 0.9489 - TP: 3199.6399 - TN: 5519.2598 - FP: 127.7400 - FN: 172.3600 - val_loss: 0.0742 - val_Accuracy: 0.9780 - val_Precision: 0.9611 - val_Recall: 0.9434 - val_TP: 758.5100 - val_TN: 1080.2600 - val_FP: 25.7400 - val_FN: 45.4900\n",
      "Epoch 31/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0500 - Accuracy: 0.9828 - Precision: 0.9568 - Recall: 0.9489 - TP: 3199.6001 - TN: 5519.4302 - FP: 127.5700 - FN: 172.4000 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9620 - val_Recall: 0.9433 - val_TP: 758.4200 - val_TN: 1081.2200 - val_FP: 24.7800 - val_FN: 45.5800\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 6ms/step - loss: 0.0509 - Accuracy: 0.9825 - Precision: 0.9574 - Recall: 0.9483 - TP: 3197.5901 - TN: 5523.1802 - FP: 123.8200 - FN: 174.4100 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9432 - val_TP: 758.3200 - val_TN: 1081.3700 - val_FP: 24.6300 - val_FN: 45.6800\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0504 - Accuracy: 0.9827 - Precision: 0.9571 - Recall: 0.9485 - TP: 3198.3899 - TN: 5521.3398 - FP: 125.6600 - FN: 173.6100 - val_loss: 0.0744 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9432 - val_TP: 758.3500 - val_TN: 1080.1000 - val_FP: 25.9000 - val_FN: 45.6500\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0503 - Accuracy: 0.9826 - Precision: 0.9566 - Recall: 0.9487 - TP: 3199.1101 - TN: 5518.7300 - FP: 128.2700 - FN: 172.8900 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9433 - val_TP: 758.4000 - val_TN: 1080.9800 - val_FP: 25.0200 - val_FN: 45.6000\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0503 - Accuracy: 0.9827 - Precision: 0.9566 - Recall: 0.9488 - TP: 3199.4500 - TN: 5518.8398 - FP: 128.1600 - FN: 172.5500 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9432 - val_TP: 758.3200 - val_TN: 1081.3199 - val_FP: 24.6800 - val_FN: 45.6800\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0503 - Accuracy: 0.9825 - Precision: 0.9569 - Recall: 0.9486 - TP: 3198.6899 - TN: 5519.8501 - FP: 127.1500 - FN: 173.3100 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9431 - val_TP: 758.2800 - val_TN: 1081.4500 - val_FP: 24.5500 - val_FN: 45.7200\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0503 - Accuracy: 0.9825 - Precision: 0.9569 - Recall: 0.9487 - TP: 3199.0100 - TN: 5520.4702 - FP: 126.5300 - FN: 172.9900 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9616 - val_Recall: 0.9432 - val_TP: 758.3500 - val_TN: 1080.8900 - val_FP: 25.1100 - val_FN: 45.6500\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0503 - Accuracy: 0.9827 - Precision: 0.9567 - Recall: 0.9486 - TP: 3198.8401 - TN: 5519.0898 - FP: 127.9100 - FN: 173.1600 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9432 - val_TP: 758.3100 - val_TN: 1081.4100 - val_FP: 24.5900 - val_FN: 45.6900\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0503 - Accuracy: 0.9825 - Precision: 0.9569 - Recall: 0.9487 - TP: 3198.9199 - TN: 5519.9800 - FP: 127.0200 - FN: 173.0800 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9618 - val_Recall: 0.9431 - val_TP: 758.2700 - val_TN: 1081.0900 - val_FP: 24.9100 - val_FN: 45.7300\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0501 - Accuracy: 0.9827 - Precision: 0.9568 - Recall: 0.9488 - TP: 3199.4700 - TN: 5519.6099 - FP: 127.3900 - FN: 172.5300 - val_loss: 0.0734 - val_Accuracy: 0.9775 - val_Precision: 0.9630 - val_Recall: 0.9430 - val_TP: 758.2000 - val_TN: 1082.3900 - val_FP: 23.6100 - val_FN: 45.8000\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0502 - Accuracy: 0.9827 - Precision: 0.9572 - Recall: 0.9487 - TP: 3199.0100 - TN: 5521.6602 - FP: 125.3400 - FN: 172.9900 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9433 - val_TP: 758.4400 - val_TN: 1081.1000 - val_FP: 24.9000 - val_FN: 45.5600\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0501 - Accuracy: 0.9826 - Precision: 0.9570 - Recall: 0.9487 - TP: 3199.1699 - TN: 5520.4600 - FP: 126.5400 - FN: 172.8300 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9618 - val_Recall: 0.9433 - val_TP: 758.3900 - val_TN: 1081.0601 - val_FP: 24.9400 - val_FN: 45.6100\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0502 - Accuracy: 0.9826 - Precision: 0.9567 - Recall: 0.9489 - TP: 3199.5701 - TN: 5519.1499 - FP: 127.8500 - FN: 172.4300 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9434 - val_TP: 758.5000 - val_TN: 1080.9700 - val_FP: 25.0300 - val_FN: 45.5000\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0501 - Accuracy: 0.9827 - Precision: 0.9569 - Recall: 0.9489 - TP: 3199.5601 - TN: 5519.9199 - FP: 127.0800 - FN: 172.4400 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9434 - val_TP: 758.4600 - val_TN: 1081.0800 - val_FP: 24.9200 - val_FN: 45.5400\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0501 - Accuracy: 0.9826 - Precision: 0.9568 - Recall: 0.9488 - TP: 3199.2700 - TN: 5519.7798 - FP: 127.2200 - FN: 172.7300 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9434 - val_TP: 758.4800 - val_TN: 1081.0500 - val_FP: 24.9500 - val_FN: 45.5200\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0501 - Accuracy: 0.9825 - Precision: 0.9569 - Recall: 0.9488 - TP: 3199.4199 - TN: 5520.1201 - FP: 126.8800 - FN: 172.5800 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9618 - val_Recall: 0.9433 - val_TP: 758.3900 - val_TN: 1081.0400 - val_FP: 24.9600 - val_FN: 45.6100\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0501 - Accuracy: 0.9827 - Precision: 0.9570 - Recall: 0.9488 - TP: 3199.1899 - TN: 5520.5898 - FP: 126.4100 - FN: 172.8100 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9431 - val_TP: 758.2800 - val_TN: 1081.4000 - val_FP: 24.6000 - val_FN: 45.7200\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0500 - Accuracy: 0.9830 - Precision: 0.9567 - Recall: 0.9491 - TP: 3200.2800 - TN: 5518.9702 - FP: 128.0300 - FN: 171.7200 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9622 - val_Recall: 0.9433 - val_TP: 758.4100 - val_TN: 1081.5100 - val_FP: 24.4900 - val_FN: 45.5900\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0501 - Accuracy: 0.9828 - Precision: 0.9570 - Recall: 0.9488 - TP: 3199.4199 - TN: 5520.7002 - FP: 126.3000 - FN: 172.5800 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9619 - val_Recall: 0.9433 - val_TP: 758.4500 - val_TN: 1081.2200 - val_FP: 24.7800 - val_FN: 45.5500\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0500 - Accuracy: 0.9828 - Precision: 0.9570 - Recall: 0.9489 - TP: 3199.6599 - TN: 5520.4302 - FP: 126.5700 - FN: 172.3400 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9619 - val_Recall: 0.9432 - val_TP: 758.3200 - val_TN: 1081.1700 - val_FP: 24.8300 - val_FN: 45.6800\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0501 - Accuracy: 0.9826 - Precision: 0.9569 - Recall: 0.9489 - TP: 3199.6101 - TN: 5520.3101 - FP: 126.6900 - FN: 172.3900 - val_loss: 0.0740 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9434 - val_TP: 758.4900 - val_TN: 1080.9900 - val_FP: 25.0100 - val_FN: 45.5100\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0500 - Accuracy: 0.9826 - Precision: 0.9571 - Recall: 0.9488 - TP: 3199.4900 - TN: 5521.0698 - FP: 125.9300 - FN: 172.5100 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9434 - val_TP: 758.4600 - val_TN: 1080.3199 - val_FP: 25.6800 - val_FN: 45.5400\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0500 - Accuracy: 0.9827 - Precision: 0.9567 - Recall: 0.9490 - TP: 3200.1899 - TN: 5518.9902 - FP: 128.0100 - FN: 171.8100 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9620 - val_Recall: 0.9433 - val_TP: 758.3800 - val_TN: 1081.2900 - val_FP: 24.7100 - val_FN: 45.6200\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0500 - Accuracy: 0.9830 - Precision: 0.9569 - Recall: 0.9489 - TP: 3199.7000 - TN: 5520.0498 - FP: 126.9500 - FN: 172.3000 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9624 - val_Recall: 0.9432 - val_TP: 758.3500 - val_TN: 1081.6801 - val_FP: 24.3200 - val_FN: 45.6500\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0500 - Accuracy: 0.9828 - Precision: 0.9572 - Recall: 0.9488 - TP: 3199.4500 - TN: 5521.8101 - FP: 125.1900 - FN: 172.5500 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9434 - val_TP: 758.5200 - val_TN: 1081.1100 - val_FP: 24.8900 - val_FN: 45.4800\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0499 - Accuracy: 0.9827 - Precision: 0.9570 - Recall: 0.9491 - TP: 3200.2300 - TN: 5520.4102 - FP: 126.5900 - FN: 171.7700 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9620 - val_Recall: 0.9435 - val_TP: 758.5400 - val_TN: 1081.3000 - val_FP: 24.7000 - val_FN: 45.4600\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0499 - Accuracy: 0.9830 - Precision: 0.9570 - Recall: 0.9490 - TP: 3200.0601 - TN: 5520.7402 - FP: 126.2600 - FN: 171.9400 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9620 - val_Recall: 0.9434 - val_TP: 758.4900 - val_TN: 1081.3101 - val_FP: 24.6900 - val_FN: 45.5100\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0499 - Accuracy: 0.9829 - Precision: 0.9570 - Recall: 0.9491 - TP: 3200.3701 - TN: 5520.7998 - FP: 126.2000 - FN: 171.6300 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9432 - val_TP: 758.3400 - val_TN: 1081.6200 - val_FP: 24.3800 - val_FN: 45.6600\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0499 - Accuracy: 0.9829 - Precision: 0.9572 - Recall: 0.9489 - TP: 3199.6201 - TN: 5521.1699 - FP: 125.8300 - FN: 172.3800 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9433 - val_TP: 758.4200 - val_TN: 1081.5100 - val_FP: 24.4900 - val_FN: 45.5800\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0498 - Accuracy: 0.9830 - Precision: 0.9571 - Recall: 0.9490 - TP: 3200.1699 - TN: 5520.8901 - FP: 126.1100 - FN: 171.8300 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9628 - val_Recall: 0.9432 - val_TP: 758.3500 - val_TN: 1082.2900 - val_FP: 23.7100 - val_FN: 45.6500\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0503 - Accuracy: 0.9825 - Precision: 0.9569 - Recall: 0.9488 - TP: 3199.4700 - TN: 5520.6001 - FP: 126.4000 - FN: 172.5300 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9625 - val_Recall: 0.9433 - val_TP: 758.4000 - val_TN: 1081.9600 - val_FP: 24.0400 - val_FN: 45.6000\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0502 - Accuracy: 0.9826 - Precision: 0.9568 - Recall: 0.9489 - TP: 3199.6499 - TN: 5520.0801 - FP: 126.9200 - FN: 172.3500 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9621 - val_Recall: 0.9433 - val_TP: 758.4000 - val_TN: 1081.4100 - val_FP: 24.5900 - val_FN: 45.6000\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0502 - Accuracy: 0.9826 - Precision: 0.9571 - Recall: 0.9486 - TP: 3198.8000 - TN: 5521.3999 - FP: 125.6000 - FN: 173.2000 - val_loss: 0.0745 - val_Accuracy: 0.9780 - val_Precision: 0.9608 - val_Recall: 0.9434 - val_TP: 758.5300 - val_TN: 1079.9399 - val_FP: 26.0600 - val_FN: 45.4700\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0502 - Accuracy: 0.9828 - Precision: 0.9567 - Recall: 0.9489 - TP: 3199.8101 - TN: 5519.0498 - FP: 127.9500 - FN: 172.1900 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9618 - val_Recall: 0.9433 - val_TP: 758.3800 - val_TN: 1081.0601 - val_FP: 24.9400 - val_FN: 45.6200\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0501 - Accuracy: 0.9826 - Precision: 0.9569 - Recall: 0.9489 - TP: 3199.6499 - TN: 5519.9102 - FP: 127.0900 - FN: 172.3500 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9619 - val_Recall: 0.9432 - val_TP: 758.3400 - val_TN: 1081.2100 - val_FP: 24.7900 - val_FN: 45.6600\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0501 - Accuracy: 0.9826 - Precision: 0.9569 - Recall: 0.9489 - TP: 3199.5400 - TN: 5519.9600 - FP: 127.0400 - FN: 172.4600 - val_loss: 0.0742 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9434 - val_TP: 758.4900 - val_TN: 1080.8101 - val_FP: 25.1900 - val_FN: 45.5100\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0501 - Accuracy: 0.9825 - Precision: 0.9572 - Recall: 0.9487 - TP: 3198.8999 - TN: 5521.4800 - FP: 125.5200 - FN: 173.1000 - val_loss: 0.0746 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9433 - val_TP: 758.4100 - val_TN: 1080.0300 - val_FP: 25.9700 - val_FN: 45.5900\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0501 - Accuracy: 0.9827 - Precision: 0.9566 - Recall: 0.9490 - TP: 3199.8701 - TN: 5519.1099 - FP: 127.8900 - FN: 172.1300 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9618 - val_Recall: 0.9433 - val_TP: 758.4300 - val_TN: 1081.0601 - val_FP: 24.9400 - val_FN: 45.5700\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0501 - Accuracy: 0.9826 - Precision: 0.9569 - Recall: 0.9489 - TP: 3199.6001 - TN: 5520.0698 - FP: 126.9300 - FN: 172.4000 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9434 - val_TP: 758.4700 - val_TN: 1081.0800 - val_FP: 24.9200 - val_FN: 45.5300\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0500 - Accuracy: 0.9827 - Precision: 0.9571 - Recall: 0.9488 - TP: 3199.4800 - TN: 5520.8501 - FP: 126.1500 - FN: 172.5200 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9432 - val_TP: 758.3600 - val_TN: 1081.5900 - val_FP: 24.4100 - val_FN: 45.6400\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0501 - Accuracy: 0.9827 - Precision: 0.9570 - Recall: 0.9489 - TP: 3199.7000 - TN: 5520.6699 - FP: 126.3300 - FN: 172.3000 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9620 - val_Recall: 0.9433 - val_TP: 758.4400 - val_TN: 1081.3101 - val_FP: 24.6900 - val_FN: 45.5600\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0500 - Accuracy: 0.9827 - Precision: 0.9570 - Recall: 0.9488 - TP: 3199.3501 - TN: 5520.7402 - FP: 126.2600 - FN: 172.6500 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9616 - val_Recall: 0.9433 - val_TP: 758.4400 - val_TN: 1080.9000 - val_FP: 25.1000 - val_FN: 45.5600\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0500 - Accuracy: 0.9827 - Precision: 0.9570 - Recall: 0.9489 - TP: 3199.6699 - TN: 5520.4399 - FP: 126.5600 - FN: 172.3300 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9620 - val_Recall: 0.9433 - val_TP: 758.3800 - val_TN: 1081.2300 - val_FP: 24.7700 - val_FN: 45.6200\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0500 - Accuracy: 0.9828 - Precision: 0.9569 - Recall: 0.9490 - TP: 3199.9800 - TN: 5519.9800 - FP: 127.0200 - FN: 172.0200 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9434 - val_TP: 758.4600 - val_TN: 1081.4500 - val_FP: 24.5500 - val_FN: 45.5400\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0499 - Accuracy: 0.9827 - Precision: 0.9571 - Recall: 0.9490 - TP: 3199.8601 - TN: 5521.0200 - FP: 125.9800 - FN: 172.1400 - val_loss: 0.0745 - val_Accuracy: 0.9780 - val_Precision: 0.9610 - val_Recall: 0.9434 - val_TP: 758.5300 - val_TN: 1080.1400 - val_FP: 25.8600 - val_FN: 45.4700\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0499 - Accuracy: 0.9831 - Precision: 0.9568 - Recall: 0.9492 - TP: 3200.5400 - TN: 5519.7202 - FP: 127.2800 - FN: 171.4600 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9628 - val_Recall: 0.9432 - val_TP: 758.3600 - val_TN: 1082.2300 - val_FP: 23.7700 - val_FN: 45.6400\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0498 - Accuracy: 0.9828 - Precision: 0.9572 - Recall: 0.9491 - TP: 3200.2600 - TN: 5521.7998 - FP: 125.2000 - FN: 171.7400 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9434 - val_TP: 758.4700 - val_TN: 1081.5601 - val_FP: 24.4400 - val_FN: 45.5300\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0499 - Accuracy: 0.9830 - Precision: 0.9572 - Recall: 0.9489 - TP: 3199.7100 - TN: 5521.7700 - FP: 125.2300 - FN: 172.2900 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9620 - val_Recall: 0.9435 - val_TP: 758.5400 - val_TN: 1081.2300 - val_FP: 24.7700 - val_FN: 45.4600\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0498 - Accuracy: 0.9829 - Precision: 0.9569 - Recall: 0.9491 - TP: 3200.4099 - TN: 5519.9902 - FP: 127.0100 - FN: 171.5900 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9625 - val_Recall: 0.9432 - val_TP: 758.3600 - val_TN: 1081.7500 - val_FP: 24.2500 - val_FN: 45.6400\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0499 - Accuracy: 0.9827 - Precision: 0.9574 - Recall: 0.9489 - TP: 3199.7300 - TN: 5522.4902 - FP: 124.5100 - FN: 172.2700 - val_loss: 0.0747 - val_Accuracy: 0.9780 - val_Precision: 0.9606 - val_Recall: 0.9435 - val_TP: 758.6000 - val_TN: 1079.7900 - val_FP: 26.2100 - val_FN: 45.4000\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0499 - Accuracy: 0.9827 - Precision: 0.9568 - Recall: 0.9492 - TP: 3200.5601 - TN: 5519.7100 - FP: 127.2900 - FN: 171.4400 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9433 - val_TP: 758.4200 - val_TN: 1081.4600 - val_FP: 24.5400 - val_FN: 45.5800\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 4ms/step - loss: 0.0504 - Accuracy: 0.9824 - Precision: 0.9571 - Recall: 0.9487 - TP: 3198.9800 - TN: 5521.5698 - FP: 125.4300 - FN: 173.0200 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9432 - val_TP: 758.3300 - val_TN: 1081.3000 - val_FP: 24.7000 - val_FN: 45.6700\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0501 - Accuracy: 0.9824 - Precision: 0.9571 - Recall: 0.9487 - TP: 3199.0701 - TN: 5521.0801 - FP: 125.9200 - FN: 172.9300 - val_loss: 0.0744 - val_Accuracy: 0.9780 - val_Precision: 0.9610 - val_Recall: 0.9434 - val_TP: 758.4600 - val_TN: 1080.1100 - val_FP: 25.8900 - val_FN: 45.5400\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0503 - Accuracy: 0.9827 - Precision: 0.9565 - Recall: 0.9489 - TP: 3199.6899 - TN: 5518.2402 - FP: 128.7600 - FN: 172.3100 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9432 - val_TP: 758.3600 - val_TN: 1081.3300 - val_FP: 24.6700 - val_FN: 45.6400\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0501 - Accuracy: 0.9826 - Precision: 0.9569 - Recall: 0.9489 - TP: 3199.6101 - TN: 5520.2402 - FP: 126.7600 - FN: 172.3900 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9618 - val_Recall: 0.9432 - val_TP: 758.3200 - val_TN: 1081.0400 - val_FP: 24.9600 - val_FN: 45.6800\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0501 - Accuracy: 0.9827 - Precision: 0.9570 - Recall: 0.9488 - TP: 3199.2100 - TN: 5520.5498 - FP: 126.4500 - FN: 172.7900 - val_loss: 0.0744 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9433 - val_TP: 758.4200 - val_TN: 1080.2000 - val_FP: 25.8000 - val_FN: 45.5800\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0501 - Accuracy: 0.9828 - Precision: 0.9569 - Recall: 0.9489 - TP: 3199.7100 - TN: 5519.8501 - FP: 127.1500 - FN: 172.2900 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9620 - val_Recall: 0.9434 - val_TP: 758.4700 - val_TN: 1081.3300 - val_FP: 24.6700 - val_FN: 45.5300\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0500 - Accuracy: 0.9828 - Precision: 0.9569 - Recall: 0.9491 - TP: 3200.2000 - TN: 5520.0698 - FP: 126.9300 - FN: 171.8000 - val_loss: 0.0734 - val_Accuracy: 0.9780 - val_Precision: 0.9627 - val_Recall: 0.9433 - val_TP: 758.4400 - val_TN: 1082.1700 - val_FP: 23.8300 - val_FN: 45.5600\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0501 - Accuracy: 0.9825 - Precision: 0.9573 - Recall: 0.9488 - TP: 3199.4600 - TN: 5522.4702 - FP: 124.5300 - FN: 172.5400 - val_loss: 0.0744 - val_Accuracy: 0.9780 - val_Precision: 0.9609 - val_Recall: 0.9434 - val_TP: 758.5000 - val_TN: 1080.1000 - val_FP: 25.9000 - val_FN: 45.5000\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0501 - Accuracy: 0.9829 - Precision: 0.9568 - Recall: 0.9489 - TP: 3199.6499 - TN: 5519.5801 - FP: 127.4200 - FN: 172.3500 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9434 - val_TP: 758.4600 - val_TN: 1081.4100 - val_FP: 24.5900 - val_FN: 45.5400\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0501 - Accuracy: 0.9827 - Precision: 0.9569 - Recall: 0.9489 - TP: 3199.5300 - TN: 5520.1899 - FP: 126.8100 - FN: 172.4700 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9620 - val_Recall: 0.9434 - val_TP: 758.4900 - val_TN: 1081.2900 - val_FP: 24.7100 - val_FN: 45.5100\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0501 - Accuracy: 0.9828 - Precision: 0.9570 - Recall: 0.9489 - TP: 3199.7200 - TN: 5520.8799 - FP: 126.1200 - FN: 172.2800 - val_loss: 0.0740 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9434 - val_TP: 758.5300 - val_TN: 1081.0200 - val_FP: 24.9800 - val_FN: 45.4700\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0499 - Accuracy: 0.9827 - Precision: 0.9570 - Recall: 0.9490 - TP: 3200.0200 - TN: 5520.3599 - FP: 126.6400 - FN: 171.9800 - val_loss: 0.0740 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9434 - val_TP: 758.5300 - val_TN: 1081.0900 - val_FP: 24.9100 - val_FN: 45.4700\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0500 - Accuracy: 0.9828 - Precision: 0.9571 - Recall: 0.9489 - TP: 3199.7900 - TN: 5520.8101 - FP: 126.1900 - FN: 172.2100 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9619 - val_Recall: 0.9434 - val_TP: 758.5100 - val_TN: 1081.2200 - val_FP: 24.7800 - val_FN: 45.4900\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0499 - Accuracy: 0.9828 - Precision: 0.9570 - Recall: 0.9490 - TP: 3199.9900 - TN: 5520.5698 - FP: 126.4300 - FN: 172.0100 - val_loss: 0.0740 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9435 - val_TP: 758.5400 - val_TN: 1081.0800 - val_FP: 24.9200 - val_FN: 45.4600\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0500 - Accuracy: 0.9830 - Precision: 0.9572 - Recall: 0.9489 - TP: 3199.7900 - TN: 5521.3599 - FP: 125.6400 - FN: 172.2100 - val_loss: 0.0742 - val_Accuracy: 0.9780 - val_Precision: 0.9612 - val_Recall: 0.9434 - val_TP: 758.5300 - val_TN: 1080.3300 - val_FP: 25.6700 - val_FN: 45.4700\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0499 - Accuracy: 0.9827 - Precision: 0.9572 - Recall: 0.9489 - TP: 3199.7800 - TN: 5521.7402 - FP: 125.2600 - FN: 172.2200 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9618 - val_Recall: 0.9433 - val_TP: 758.4100 - val_TN: 1081.0200 - val_FP: 24.9800 - val_FN: 45.5900\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0499 - Accuracy: 0.9830 - Precision: 0.9568 - Recall: 0.9492 - TP: 3200.8101 - TN: 5519.6602 - FP: 127.3400 - FN: 171.1900 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9434 - val_TP: 758.5200 - val_TN: 1081.4200 - val_FP: 24.5800 - val_FN: 45.4800\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0499 - Accuracy: 0.9829 - Precision: 0.9572 - Recall: 0.9490 - TP: 3199.9399 - TN: 5522.0200 - FP: 124.9800 - FN: 172.0600 - val_loss: 0.0744 - val_Accuracy: 0.9780 - val_Precision: 0.9610 - val_Recall: 0.9435 - val_TP: 758.5800 - val_TN: 1080.2100 - val_FP: 25.7900 - val_FN: 45.4200\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0500 - Accuracy: 0.9828 - Precision: 0.9568 - Recall: 0.9491 - TP: 3200.4099 - TN: 5519.2798 - FP: 127.7200 - FN: 171.5900 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9624 - val_Recall: 0.9432 - val_TP: 758.3700 - val_TN: 1081.6500 - val_FP: 24.3500 - val_FN: 45.6300\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0498 - Accuracy: 0.9829 - Precision: 0.9570 - Recall: 0.9491 - TP: 3200.2200 - TN: 5520.5601 - FP: 126.4400 - FN: 171.7800 - val_loss: 0.0742 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9435 - val_TP: 758.5900 - val_TN: 1080.8300 - val_FP: 25.1700 - val_FN: 45.4100\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0498 - Accuracy: 0.9829 - Precision: 0.9571 - Recall: 0.9492 - TP: 3200.6399 - TN: 5520.9199 - FP: 126.0800 - FN: 171.3600 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9619 - val_Recall: 0.9434 - val_TP: 758.5100 - val_TN: 1081.1200 - val_FP: 24.8800 - val_FN: 45.4900\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0497 - Accuracy: 0.9830 - Precision: 0.9571 - Recall: 0.9491 - TP: 3200.3601 - TN: 5521.1899 - FP: 125.8100 - FN: 171.6400 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9434 - val_TP: 758.4800 - val_TN: 1081.3300 - val_FP: 24.6700 - val_FN: 45.5200\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0498 - Accuracy: 0.9830 - Precision: 0.9574 - Recall: 0.9491 - TP: 3200.2000 - TN: 5522.3398 - FP: 124.6600 - FN: 171.8000 - val_loss: 0.0745 - val_Accuracy: 0.9780 - val_Precision: 0.9608 - val_Recall: 0.9436 - val_TP: 758.6300 - val_TN: 1079.9800 - val_FP: 26.0200 - val_FN: 45.3700\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0498 - Accuracy: 0.9830 - Precision: 0.9569 - Recall: 0.9492 - TP: 3200.8501 - TN: 5519.9702 - FP: 127.0300 - FN: 171.1500 - val_loss: 0.0744 - val_Accuracy: 0.9780 - val_Precision: 0.9611 - val_Recall: 0.9435 - val_TP: 758.5900 - val_TN: 1080.2500 - val_FP: 25.7500 - val_FN: 45.4100\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0498 - Accuracy: 0.9831 - Precision: 0.9571 - Recall: 0.9492 - TP: 3200.6599 - TN: 5520.9800 - FP: 126.0200 - FN: 171.3400 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9621 - val_Recall: 0.9435 - val_TP: 758.5700 - val_TN: 1081.3400 - val_FP: 24.6600 - val_FN: 45.4300\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0497 - Accuracy: 0.9830 - Precision: 0.9572 - Recall: 0.9492 - TP: 3200.8401 - TN: 5521.7300 - FP: 125.2700 - FN: 171.1600 - val_loss: 0.0741 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9435 - val_TP: 758.5600 - val_TN: 1081.0800 - val_FP: 24.9200 - val_FN: 45.4400\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0498 - Accuracy: 0.9830 - Precision: 0.9571 - Recall: 0.9491 - TP: 3200.3401 - TN: 5520.9702 - FP: 126.0300 - FN: 171.6600 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9434 - val_TP: 758.5100 - val_TN: 1081.4399 - val_FP: 24.5600 - val_FN: 45.4900\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0504 - Accuracy: 0.9825 - Precision: 0.9574 - Recall: 0.9487 - TP: 3199.1499 - TN: 5522.9102 - FP: 124.0900 - FN: 172.8500 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9621 - val_Recall: 0.9433 - val_TP: 758.4300 - val_TN: 1081.3600 - val_FP: 24.6400 - val_FN: 45.5700\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0500 - Accuracy: 0.9828 - Precision: 0.9573 - Recall: 0.9489 - TP: 3199.8101 - TN: 5522.2500 - FP: 124.7500 - FN: 172.1900 - val_loss: 0.0742 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9434 - val_TP: 758.5100 - val_TN: 1080.8101 - val_FP: 25.1900 - val_FN: 45.4900\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0500 - Accuracy: 0.9828 - Precision: 0.9566 - Recall: 0.9491 - TP: 3200.4700 - TN: 5518.6899 - FP: 128.3100 - FN: 171.5300 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9435 - val_TP: 758.5700 - val_TN: 1081.0400 - val_FP: 24.9600 - val_FN: 45.4300\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0501 - Accuracy: 0.9828 - Precision: 0.9570 - Recall: 0.9489 - TP: 3199.7600 - TN: 5520.6299 - FP: 126.3700 - FN: 172.2400 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9619 - val_Recall: 0.9434 - val_TP: 758.5100 - val_TN: 1081.1700 - val_FP: 24.8300 - val_FN: 45.4900\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0500 - Accuracy: 0.9826 - Precision: 0.9572 - Recall: 0.9489 - TP: 3199.6299 - TN: 5521.7402 - FP: 125.2600 - FN: 172.3700 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9619 - val_Recall: 0.9433 - val_TP: 758.4200 - val_TN: 1081.1899 - val_FP: 24.8100 - val_FN: 45.5800\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0500 - Accuracy: 0.9828 - Precision: 0.9567 - Recall: 0.9491 - TP: 3200.3301 - TN: 5518.9902 - FP: 128.0100 - FN: 171.6700 - val_loss: 0.0735 - val_Accuracy: 0.9780 - val_Precision: 0.9626 - val_Recall: 0.9434 - val_TP: 758.5000 - val_TN: 1082.0699 - val_FP: 23.9300 - val_FN: 45.5000\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0499 - Accuracy: 0.9829 - Precision: 0.9570 - Recall: 0.9492 - TP: 3200.7100 - TN: 5521.0200 - FP: 125.9800 - FN: 171.2900 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9432 - val_TP: 758.3500 - val_TN: 1081.5200 - val_FP: 24.4800 - val_FN: 45.6500\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0500 - Accuracy: 0.9827 - Precision: 0.9572 - Recall: 0.9490 - TP: 3200.0901 - TN: 5521.5298 - FP: 125.4700 - FN: 171.9100 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9618 - val_Recall: 0.9433 - val_TP: 758.4300 - val_TN: 1081.1100 - val_FP: 24.8900 - val_FN: 45.5700\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0498 - Accuracy: 0.9829 - Precision: 0.9572 - Recall: 0.9491 - TP: 3200.2400 - TN: 5521.2998 - FP: 125.7000 - FN: 171.7600 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9434 - val_TP: 758.4800 - val_TN: 1080.3300 - val_FP: 25.6700 - val_FN: 45.5200\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0498 - Accuracy: 0.9828 - Precision: 0.9570 - Recall: 0.9490 - TP: 3200.1899 - TN: 5520.5098 - FP: 126.4900 - FN: 171.8100 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9620 - val_Recall: 0.9434 - val_TP: 758.4700 - val_TN: 1081.2400 - val_FP: 24.7600 - val_FN: 45.5300\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0499 - Accuracy: 0.9828 - Precision: 0.9568 - Recall: 0.9492 - TP: 3200.6299 - TN: 5519.3701 - FP: 127.6300 - FN: 171.3700 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9627 - val_Recall: 0.9434 - val_TP: 758.4800 - val_TN: 1082.1500 - val_FP: 23.8500 - val_FN: 45.5200\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0500 - Accuracy: 0.9831 - Precision: 0.9572 - Recall: 0.9490 - TP: 3199.9299 - TN: 5521.7598 - FP: 125.2400 - FN: 172.0700 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9624 - val_Recall: 0.9433 - val_TP: 758.4200 - val_TN: 1081.6400 - val_FP: 24.3600 - val_FN: 45.5800\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0498 - Accuracy: 0.9829 - Precision: 0.9573 - Recall: 0.9491 - TP: 3200.3601 - TN: 5521.8198 - FP: 125.1800 - FN: 171.6400 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9435 - val_TP: 758.5400 - val_TN: 1081.3800 - val_FP: 24.6200 - val_FN: 45.4600\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0498 - Accuracy: 0.9830 - Precision: 0.9575 - Recall: 0.9489 - TP: 3199.7800 - TN: 5523.1401 - FP: 123.8600 - FN: 172.2200 - val_loss: 0.0747 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9435 - val_TP: 758.5600 - val_TN: 1080.0000 - val_FP: 26.0000 - val_FN: 45.4400\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0498 - Accuracy: 0.9829 - Precision: 0.9571 - Recall: 0.9490 - TP: 3200.1899 - TN: 5521.0601 - FP: 125.9400 - FN: 171.8100 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9435 - val_TP: 758.5400 - val_TN: 1081.3700 - val_FP: 24.6300 - val_FN: 45.4600\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0497 - Accuracy: 0.9828 - Precision: 0.9570 - Recall: 0.9493 - TP: 3200.9700 - TN: 5520.4502 - FP: 126.5500 - FN: 171.0300 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9624 - val_Recall: 0.9434 - val_TP: 758.4600 - val_TN: 1081.6899 - val_FP: 24.3100 - val_FN: 45.5400\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0497 - Accuracy: 0.9827 - Precision: 0.9576 - Recall: 0.9489 - TP: 3199.7500 - TN: 5523.6201 - FP: 123.3800 - FN: 172.2500 - val_loss: 0.0742 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9435 - val_TP: 758.6100 - val_TN: 1080.8500 - val_FP: 25.1500 - val_FN: 45.3900\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0498 - Accuracy: 0.9830 - Precision: 0.9568 - Recall: 0.9492 - TP: 3200.8601 - TN: 5519.6602 - FP: 127.3400 - FN: 171.1400 - val_loss: 0.0740 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9436 - val_TP: 758.6300 - val_TN: 1081.0200 - val_FP: 24.9800 - val_FN: 45.3700\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0498 - Accuracy: 0.9830 - Precision: 0.9569 - Recall: 0.9494 - TP: 3201.3401 - TN: 5520.2700 - FP: 126.7300 - FN: 170.6600 - val_loss: 0.0740 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9435 - val_TP: 758.6100 - val_TN: 1081.0900 - val_FP: 24.9100 - val_FN: 45.3900\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0497 - Accuracy: 0.9830 - Precision: 0.9573 - Recall: 0.9492 - TP: 3200.7300 - TN: 5522.3701 - FP: 124.6300 - FN: 171.2700 - val_loss: 0.0745 - val_Accuracy: 0.9780 - val_Precision: 0.9609 - val_Recall: 0.9436 - val_TP: 758.6600 - val_TN: 1080.0900 - val_FP: 25.9100 - val_FN: 45.3400\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0497 - Accuracy: 0.9831 - Precision: 0.9571 - Recall: 0.9492 - TP: 3200.7600 - TN: 5520.7798 - FP: 126.2200 - FN: 171.2400 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9435 - val_TP: 758.5800 - val_TN: 1081.5500 - val_FP: 24.4500 - val_FN: 45.4200\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0497 - Accuracy: 0.9829 - Precision: 0.9573 - Recall: 0.9492 - TP: 3200.8101 - TN: 5521.6699 - FP: 125.3300 - FN: 171.1900 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9619 - val_Recall: 0.9435 - val_TP: 758.5900 - val_TN: 1081.2300 - val_FP: 24.7700 - val_FN: 45.4100\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0495 - Accuracy: 0.9831 - Precision: 0.9574 - Recall: 0.9492 - TP: 3200.7100 - TN: 5522.4199 - FP: 124.5800 - FN: 171.2900 - val_loss: 0.0750 - val_Accuracy: 0.9775 - val_Precision: 0.9602 - val_Recall: 0.9436 - val_TP: 758.6200 - val_TN: 1079.3199 - val_FP: 26.6800 - val_FN: 45.3800\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0496 - Accuracy: 0.9830 - Precision: 0.9570 - Recall: 0.9493 - TP: 3201.1201 - TN: 5520.5898 - FP: 126.4100 - FN: 170.8800 - val_loss: 0.0740 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9436 - val_TP: 758.6400 - val_TN: 1081.1000 - val_FP: 24.9000 - val_FN: 45.3600\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0496 - Accuracy: 0.9829 - Precision: 0.9570 - Recall: 0.9494 - TP: 3201.2900 - TN: 5520.2900 - FP: 126.7100 - FN: 170.7100 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9622 - val_Recall: 0.9436 - val_TP: 758.6400 - val_TN: 1081.5400 - val_FP: 24.4600 - val_FN: 45.3600\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0496 - Accuracy: 0.9829 - Precision: 0.9573 - Recall: 0.9492 - TP: 3200.6499 - TN: 5522.2798 - FP: 124.7200 - FN: 171.3500 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9436 - val_TP: 758.6200 - val_TN: 1081.4200 - val_FP: 24.5800 - val_FN: 45.3800\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 4ms/step - loss: 0.0502 - Accuracy: 0.9828 - Precision: 0.9576 - Recall: 0.9488 - TP: 3199.5200 - TN: 5523.8398 - FP: 123.1600 - FN: 172.4800 - val_loss: 0.0740 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9437 - val_TP: 758.7100 - val_TN: 1080.6600 - val_FP: 25.3400 - val_FN: 45.2900\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0499 - Accuracy: 0.9826 - Precision: 0.9568 - Recall: 0.9492 - TP: 3200.6899 - TN: 5519.7500 - FP: 127.2500 - FN: 171.3100 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9621 - val_Recall: 0.9435 - val_TP: 758.5800 - val_TN: 1081.4200 - val_FP: 24.5800 - val_FN: 45.4200\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0500 - Accuracy: 0.9828 - Precision: 0.9568 - Recall: 0.9492 - TP: 3200.6201 - TN: 5519.8599 - FP: 127.1400 - FN: 171.3800 - val_loss: 0.0741 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9434 - val_TP: 758.5300 - val_TN: 1080.9500 - val_FP: 25.0500 - val_FN: 45.4700\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0500 - Accuracy: 0.9827 - Precision: 0.9568 - Recall: 0.9491 - TP: 3200.5200 - TN: 5519.5601 - FP: 127.4400 - FN: 171.4800 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9622 - val_Recall: 0.9434 - val_TP: 758.4600 - val_TN: 1081.5000 - val_FP: 24.5000 - val_FN: 45.5400\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0499 - Accuracy: 0.9828 - Precision: 0.9569 - Recall: 0.9492 - TP: 3200.6799 - TN: 5520.2798 - FP: 126.7200 - FN: 171.3200 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9627 - val_Recall: 0.9433 - val_TP: 758.4400 - val_TN: 1082.1700 - val_FP: 23.8300 - val_FN: 45.5600\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0499 - Accuracy: 0.9828 - Precision: 0.9575 - Recall: 0.9488 - TP: 3199.3201 - TN: 5523.1201 - FP: 123.8800 - FN: 172.6800 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9617 - val_Recall: 0.9434 - val_TP: 758.4800 - val_TN: 1081.0000 - val_FP: 25.0000 - val_FN: 45.5200\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0499 - Accuracy: 0.9829 - Precision: 0.9570 - Recall: 0.9490 - TP: 3200.1299 - TN: 5520.3999 - FP: 126.6000 - FN: 171.8700 - val_loss: 0.0736 - val_Accuracy: 0.9780 - val_Precision: 0.9622 - val_Recall: 0.9434 - val_TP: 758.5200 - val_TN: 1081.5000 - val_FP: 24.5000 - val_FN: 45.4800\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0498 - Accuracy: 0.9827 - Precision: 0.9570 - Recall: 0.9493 - TP: 3201.1799 - TN: 5520.9399 - FP: 126.0600 - FN: 170.8200 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9434 - val_TP: 758.5300 - val_TN: 1081.5500 - val_FP: 24.4500 - val_FN: 45.4700\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0498 - Accuracy: 0.9830 - Precision: 0.9569 - Recall: 0.9493 - TP: 3200.9800 - TN: 5520.3101 - FP: 126.6900 - FN: 171.0200 - val_loss: 0.0741 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9435 - val_TP: 758.5400 - val_TN: 1081.0601 - val_FP: 24.9400 - val_FN: 45.4600\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0497 - Accuracy: 0.9830 - Precision: 0.9572 - Recall: 0.9491 - TP: 3200.3899 - TN: 5521.6499 - FP: 125.3500 - FN: 171.6100 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9619 - val_Recall: 0.9434 - val_TP: 758.4900 - val_TN: 1081.1400 - val_FP: 24.8600 - val_FN: 45.5100\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0498 - Accuracy: 0.9830 - Precision: 0.9571 - Recall: 0.9492 - TP: 3200.6399 - TN: 5520.7900 - FP: 126.2100 - FN: 171.3600 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9434 - val_TP: 758.5200 - val_TN: 1081.4900 - val_FP: 24.5100 - val_FN: 45.4800\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0497 - Accuracy: 0.9829 - Precision: 0.9573 - Recall: 0.9492 - TP: 3200.6201 - TN: 5521.8501 - FP: 125.1500 - FN: 171.3800 - val_loss: 0.0739 - val_Accuracy: 0.9780 - val_Precision: 0.9619 - val_Recall: 0.9435 - val_TP: 758.6100 - val_TN: 1081.1899 - val_FP: 24.8100 - val_FN: 45.3900\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0496 - Accuracy: 0.9830 - Precision: 0.9571 - Recall: 0.9492 - TP: 3200.7900 - TN: 5520.5400 - FP: 126.4600 - FN: 171.2100 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9435 - val_TP: 758.5500 - val_TN: 1081.5500 - val_FP: 24.4500 - val_FN: 45.4500\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0496 - Accuracy: 0.9830 - Precision: 0.9573 - Recall: 0.9491 - TP: 3200.5000 - TN: 5521.9302 - FP: 125.0700 - FN: 171.5000 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9625 - val_Recall: 0.9433 - val_TP: 758.4200 - val_TN: 1081.7600 - val_FP: 24.2400 - val_FN: 45.5800\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0497 - Accuracy: 0.9829 - Precision: 0.9573 - Recall: 0.9492 - TP: 3200.6001 - TN: 5522.0698 - FP: 124.9300 - FN: 171.4000 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9435 - val_TP: 758.5600 - val_TN: 1081.5200 - val_FP: 24.4800 - val_FN: 45.4400\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0497 - Accuracy: 0.9831 - Precision: 0.9569 - Recall: 0.9494 - TP: 3201.3999 - TN: 5520.0400 - FP: 126.9600 - FN: 170.6000 - val_loss: 0.0737 - val_Accuracy: 0.9780 - val_Precision: 0.9622 - val_Recall: 0.9436 - val_TP: 758.6300 - val_TN: 1081.4500 - val_FP: 24.5500 - val_FN: 45.3700\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0496 - Accuracy: 0.9829 - Precision: 0.9575 - Recall: 0.9492 - TP: 3200.7300 - TN: 5522.9302 - FP: 124.0700 - FN: 171.2700 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9435 - val_TP: 758.5600 - val_TN: 1081.5601 - val_FP: 24.4400 - val_FN: 45.4400\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0497 - Accuracy: 0.9831 - Precision: 0.9569 - Recall: 0.9494 - TP: 3201.3999 - TN: 5519.9502 - FP: 127.0500 - FN: 170.6000 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9435 - val_TP: 758.5800 - val_TN: 1081.4800 - val_FP: 24.5200 - val_FN: 45.4200\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0495 - Accuracy: 0.9829 - Precision: 0.9574 - Recall: 0.9491 - TP: 3200.5000 - TN: 5522.6001 - FP: 124.4000 - FN: 171.5000 - val_loss: 0.0745 - val_Accuracy: 0.9780 - val_Precision: 0.9609 - val_Recall: 0.9436 - val_TP: 758.6500 - val_TN: 1080.1200 - val_FP: 25.8800 - val_FN: 45.3500\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0496 - Accuracy: 0.9829 - Precision: 0.9571 - Recall: 0.9493 - TP: 3201.1499 - TN: 5520.7598 - FP: 126.2400 - FN: 170.8500 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9435 - val_TP: 758.6000 - val_TN: 1081.5400 - val_FP: 24.4600 - val_FN: 45.4000\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0496 - Accuracy: 0.9831 - Precision: 0.9574 - Recall: 0.9493 - TP: 3200.9700 - TN: 5522.4702 - FP: 124.5300 - FN: 171.0300 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9619 - val_Recall: 0.9435 - val_TP: 758.5900 - val_TN: 1081.2300 - val_FP: 24.7700 - val_FN: 45.4100\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0495 - Accuracy: 0.9830 - Precision: 0.9572 - Recall: 0.9494 - TP: 3201.4500 - TN: 5521.4902 - FP: 125.5100 - FN: 170.5500 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9620 - val_Recall: 0.9435 - val_TP: 758.5900 - val_TN: 1081.3300 - val_FP: 24.6700 - val_FN: 45.4100\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0495 - Accuracy: 0.9831 - Precision: 0.9571 - Recall: 0.9495 - TP: 3201.7600 - TN: 5520.8301 - FP: 126.1700 - FN: 170.2400 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9627 - val_Recall: 0.9435 - val_TP: 758.5800 - val_TN: 1082.1700 - val_FP: 23.8300 - val_FN: 45.4200\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0497 - Accuracy: 0.9830 - Precision: 0.9573 - Recall: 0.9492 - TP: 3200.8000 - TN: 5522.2998 - FP: 124.7000 - FN: 171.2000 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9436 - val_TP: 758.6200 - val_TN: 1081.4301 - val_FP: 24.5700 - val_FN: 45.3800\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0494 - Accuracy: 0.9828 - Precision: 0.9577 - Recall: 0.9492 - TP: 3200.5801 - TN: 5523.8398 - FP: 123.1600 - FN: 171.4200 - val_loss: 0.0747 - val_Accuracy: 0.9775 - val_Precision: 0.9608 - val_Recall: 0.9436 - val_TP: 758.6800 - val_TN: 1079.9700 - val_FP: 26.0300 - val_FN: 45.3200\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0499 - Accuracy: 0.9829 - Precision: 0.9569 - Recall: 0.9493 - TP: 3201.2000 - TN: 5520.4800 - FP: 126.5200 - FN: 170.8000 - val_loss: 0.0734 - val_Accuracy: 0.9780 - val_Precision: 0.9628 - val_Recall: 0.9434 - val_TP: 758.5100 - val_TN: 1082.2800 - val_FP: 23.7200 - val_FN: 45.4900\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0498 - Accuracy: 0.9830 - Precision: 0.9574 - Recall: 0.9491 - TP: 3200.2900 - TN: 5522.6499 - FP: 124.3500 - FN: 171.7100 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9624 - val_Recall: 0.9433 - val_TP: 758.4200 - val_TN: 1081.6500 - val_FP: 24.3500 - val_FN: 45.5800\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0498 - Accuracy: 0.9828 - Precision: 0.9571 - Recall: 0.9494 - TP: 3201.2500 - TN: 5521.6001 - FP: 125.4000 - FN: 170.7500 - val_loss: 0.0745 - val_Accuracy: 0.9780 - val_Precision: 0.9610 - val_Recall: 0.9435 - val_TP: 758.5600 - val_TN: 1080.1700 - val_FP: 25.8300 - val_FN: 45.4400\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0498 - Accuracy: 0.9830 - Precision: 0.9572 - Recall: 0.9491 - TP: 3200.2600 - TN: 5521.6001 - FP: 125.4000 - FN: 171.7400 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9434 - val_TP: 758.5000 - val_TN: 1081.6300 - val_FP: 24.3700 - val_FN: 45.5000\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0498 - Accuracy: 0.9830 - Precision: 0.9572 - Recall: 0.9490 - TP: 3200.0300 - TN: 5521.4102 - FP: 125.5900 - FN: 171.9700 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9620 - val_Recall: 0.9434 - val_TP: 758.4900 - val_TN: 1081.2900 - val_FP: 24.7100 - val_FN: 45.5100\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0497 - Accuracy: 0.9829 - Precision: 0.9571 - Recall: 0.9491 - TP: 3200.4900 - TN: 5521.1899 - FP: 125.8100 - FN: 171.5100 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9621 - val_Recall: 0.9435 - val_TP: 758.5700 - val_TN: 1081.3800 - val_FP: 24.6200 - val_FN: 45.4300\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0497 - Accuracy: 0.9830 - Precision: 0.9573 - Recall: 0.9493 - TP: 3200.9199 - TN: 5521.7402 - FP: 125.2600 - FN: 171.0800 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9621 - val_Recall: 0.9435 - val_TP: 758.5600 - val_TN: 1081.4000 - val_FP: 24.6000 - val_FN: 45.4400\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0498 - Accuracy: 0.9830 - Precision: 0.9571 - Recall: 0.9493 - TP: 3201.1599 - TN: 5521.0098 - FP: 125.9900 - FN: 170.8400 - val_loss: 0.0740 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9436 - val_TP: 758.6200 - val_TN: 1081.1000 - val_FP: 24.9000 - val_FN: 45.3800\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0497 - Accuracy: 0.9831 - Precision: 0.9571 - Recall: 0.9493 - TP: 3200.9500 - TN: 5521.1099 - FP: 125.8900 - FN: 171.0500 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9434 - val_TP: 758.4900 - val_TN: 1081.4900 - val_FP: 24.5100 - val_FN: 45.5100\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0496 - Accuracy: 0.9829 - Precision: 0.9573 - Recall: 0.9493 - TP: 3200.8899 - TN: 5521.9902 - FP: 125.0100 - FN: 171.1100 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9618 - val_Recall: 0.9435 - val_TP: 758.5700 - val_TN: 1081.1100 - val_FP: 24.8900 - val_FN: 45.4300\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0496 - Accuracy: 0.9831 - Precision: 0.9571 - Recall: 0.9494 - TP: 3201.5100 - TN: 5521.0698 - FP: 125.9300 - FN: 170.4900 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9619 - val_Recall: 0.9434 - val_TP: 758.5300 - val_TN: 1081.1600 - val_FP: 24.8400 - val_FN: 45.4700\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0497 - Accuracy: 0.9830 - Precision: 0.9570 - Recall: 0.9493 - TP: 3201.0400 - TN: 5520.6899 - FP: 126.3100 - FN: 170.9600 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9435 - val_TP: 758.5700 - val_TN: 1081.6200 - val_FP: 24.3800 - val_FN: 45.4300\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0496 - Accuracy: 0.9830 - Precision: 0.9573 - Recall: 0.9494 - TP: 3201.3000 - TN: 5522.1099 - FP: 124.8900 - FN: 170.7000 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9436 - val_TP: 758.6300 - val_TN: 1081.3500 - val_FP: 24.6500 - val_FN: 45.3700\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0497 - Accuracy: 0.9829 - Precision: 0.9573 - Recall: 0.9492 - TP: 3200.7800 - TN: 5521.7002 - FP: 125.3000 - FN: 171.2200 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9625 - val_Recall: 0.9434 - val_TP: 758.4700 - val_TN: 1081.7300 - val_FP: 24.2700 - val_FN: 45.5300\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0495 - Accuracy: 0.9833 - Precision: 0.9574 - Recall: 0.9494 - TP: 3201.2900 - TN: 5522.3198 - FP: 124.6800 - FN: 170.7100 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9435 - val_TP: 758.5700 - val_TN: 1081.3700 - val_FP: 24.6300 - val_FN: 45.4300\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0496 - Accuracy: 0.9831 - Precision: 0.9574 - Recall: 0.9493 - TP: 3201.1399 - TN: 5522.5098 - FP: 124.4900 - FN: 170.8600 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9625 - val_Recall: 0.9434 - val_TP: 758.5100 - val_TN: 1081.7600 - val_FP: 24.2400 - val_FN: 45.4900\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0496 - Accuracy: 0.9830 - Precision: 0.9571 - Recall: 0.9496 - TP: 3201.9199 - TN: 5521.0098 - FP: 125.9900 - FN: 170.0800 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9436 - val_TP: 758.6200 - val_TN: 1081.6300 - val_FP: 24.3700 - val_FN: 45.3800\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0494 - Accuracy: 0.9831 - Precision: 0.9571 - Recall: 0.9496 - TP: 3201.8999 - TN: 5521.1001 - FP: 125.9000 - FN: 170.1000 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9631 - val_Recall: 0.9433 - val_TP: 758.4500 - val_TN: 1082.5100 - val_FP: 23.4900 - val_FN: 45.5500\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0495 - Accuracy: 0.9829 - Precision: 0.9575 - Recall: 0.9492 - TP: 3200.7000 - TN: 5522.9502 - FP: 124.0500 - FN: 171.3000 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9435 - val_TP: 758.5800 - val_TN: 1081.4600 - val_FP: 24.5400 - val_FN: 45.4200\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0495 - Accuracy: 0.9831 - Precision: 0.9573 - Recall: 0.9495 - TP: 3201.5500 - TN: 5521.8301 - FP: 125.1700 - FN: 170.4500 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9435 - val_TP: 758.5500 - val_TN: 1081.6100 - val_FP: 24.3900 - val_FN: 45.4500\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0495 - Accuracy: 0.9830 - Precision: 0.9575 - Recall: 0.9493 - TP: 3201.0200 - TN: 5522.5898 - FP: 124.4100 - FN: 170.9800 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9624 - val_Recall: 0.9435 - val_TP: 758.5700 - val_TN: 1081.6500 - val_FP: 24.3500 - val_FN: 45.4300\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0501 - Accuracy: 0.9828 - Precision: 0.9577 - Recall: 0.9490 - TP: 3199.8701 - TN: 5524.0698 - FP: 122.9300 - FN: 172.1300 - val_loss: 0.0743 - val_Accuracy: 0.9780 - val_Precision: 0.9612 - val_Recall: 0.9435 - val_TP: 758.5600 - val_TN: 1080.3300 - val_FP: 25.6700 - val_FN: 45.4400\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0498 - Accuracy: 0.9828 - Precision: 0.9571 - Recall: 0.9491 - TP: 3200.5200 - TN: 5521.0400 - FP: 125.9600 - FN: 171.4800 - val_loss: 0.0741 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9435 - val_TP: 758.6100 - val_TN: 1081.0000 - val_FP: 25.0000 - val_FN: 45.3900\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0498 - Accuracy: 0.9828 - Precision: 0.9569 - Recall: 0.9493 - TP: 3201.0100 - TN: 5520.3701 - FP: 126.6300 - FN: 170.9900 - val_loss: 0.0742 - val_Accuracy: 0.9780 - val_Precision: 0.9617 - val_Recall: 0.9435 - val_TP: 758.5400 - val_TN: 1080.9600 - val_FP: 25.0400 - val_FN: 45.4600\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0498 - Accuracy: 0.9828 - Precision: 0.9572 - Recall: 0.9491 - TP: 3200.4900 - TN: 5521.5498 - FP: 125.4500 - FN: 171.5100 - val_loss: 0.0746 - val_Accuracy: 0.9780 - val_Precision: 0.9609 - val_Recall: 0.9436 - val_TP: 758.6500 - val_TN: 1080.0601 - val_FP: 25.9400 - val_FN: 45.3500\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0498 - Accuracy: 0.9829 - Precision: 0.9573 - Recall: 0.9491 - TP: 3200.3799 - TN: 5521.8198 - FP: 125.1800 - FN: 171.6200 - val_loss: 0.0744 - val_Accuracy: 0.9780 - val_Precision: 0.9612 - val_Recall: 0.9435 - val_TP: 758.5700 - val_TN: 1080.3500 - val_FP: 25.6500 - val_FN: 45.4300\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0497 - Accuracy: 0.9830 - Precision: 0.9571 - Recall: 0.9493 - TP: 3200.8799 - TN: 5520.6401 - FP: 126.3600 - FN: 171.1200 - val_loss: 0.0740 - val_Accuracy: 0.9780 - val_Precision: 0.9619 - val_Recall: 0.9435 - val_TP: 758.5600 - val_TN: 1081.1600 - val_FP: 24.8400 - val_FN: 45.4400\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0499 - Accuracy: 0.9829 - Precision: 0.9571 - Recall: 0.9492 - TP: 3200.6101 - TN: 5521.0898 - FP: 125.9100 - FN: 171.3900 - val_loss: 0.0744 - val_Accuracy: 0.9780 - val_Precision: 0.9612 - val_Recall: 0.9435 - val_TP: 758.5900 - val_TN: 1080.3500 - val_FP: 25.6500 - val_FN: 45.4100\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0497 - Accuracy: 0.9829 - Precision: 0.9573 - Recall: 0.9492 - TP: 3200.8501 - TN: 5522.1001 - FP: 124.9000 - FN: 171.1500 - val_loss: 0.0744 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9435 - val_TP: 758.5700 - val_TN: 1080.2900 - val_FP: 25.7100 - val_FN: 45.4300\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0497 - Accuracy: 0.9829 - Precision: 0.9570 - Recall: 0.9493 - TP: 3201.1799 - TN: 5521.0898 - FP: 125.9100 - FN: 170.8200 - val_loss: 0.0742 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9436 - val_TP: 758.6800 - val_TN: 1080.8800 - val_FP: 25.1200 - val_FN: 45.3200\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0497 - Accuracy: 0.9829 - Precision: 0.9571 - Recall: 0.9493 - TP: 3200.9299 - TN: 5520.8901 - FP: 126.1100 - FN: 171.0700 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9617 - val_Recall: 0.9435 - val_TP: 758.5800 - val_TN: 1080.9900 - val_FP: 25.0100 - val_FN: 45.4200\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0497 - Accuracy: 0.9831 - Precision: 0.9571 - Recall: 0.9494 - TP: 3201.2100 - TN: 5521.0000 - FP: 126.0000 - FN: 170.7900 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9624 - val_Recall: 0.9434 - val_TP: 758.5200 - val_TN: 1081.6400 - val_FP: 24.3600 - val_FN: 45.4800\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0496 - Accuracy: 0.9830 - Precision: 0.9572 - Recall: 0.9494 - TP: 3201.5200 - TN: 5522.0098 - FP: 124.9900 - FN: 170.4800 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9620 - val_Recall: 0.9435 - val_TP: 758.5900 - val_TN: 1081.3300 - val_FP: 24.6700 - val_FN: 45.4100\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0496 - Accuracy: 0.9830 - Precision: 0.9571 - Recall: 0.9494 - TP: 3201.3501 - TN: 5521.1699 - FP: 125.8300 - FN: 170.6500 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9617 - val_Recall: 0.9436 - val_TP: 758.6200 - val_TN: 1080.9900 - val_FP: 25.0100 - val_FN: 45.3800\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0495 - Accuracy: 0.9831 - Precision: 0.9572 - Recall: 0.9495 - TP: 3201.5901 - TN: 5521.5200 - FP: 125.4800 - FN: 170.4100 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9434 - val_TP: 758.5100 - val_TN: 1081.4900 - val_FP: 24.5100 - val_FN: 45.4900\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0494 - Accuracy: 0.9829 - Precision: 0.9577 - Recall: 0.9492 - TP: 3200.8201 - TN: 5524.1899 - FP: 122.8100 - FN: 171.1800 - val_loss: 0.0754 - val_Accuracy: 0.9780 - val_Precision: 0.9598 - val_Recall: 0.9436 - val_TP: 758.6800 - val_TN: 1078.9700 - val_FP: 27.0300 - val_FN: 45.3200\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0497 - Accuracy: 0.9831 - Precision: 0.9567 - Recall: 0.9497 - TP: 3202.2400 - TN: 5519.3799 - FP: 127.6200 - FN: 169.7600 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9617 - val_Recall: 0.9436 - val_TP: 758.6300 - val_TN: 1081.0000 - val_FP: 25.0000 - val_FN: 45.3700\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0495 - Accuracy: 0.9831 - Precision: 0.9574 - Recall: 0.9493 - TP: 3201.0200 - TN: 5522.1699 - FP: 124.8300 - FN: 170.9800 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9434 - val_TP: 758.5100 - val_TN: 1081.5300 - val_FP: 24.4700 - val_FN: 45.4900\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0494 - Accuracy: 0.9829 - Precision: 0.9575 - Recall: 0.9494 - TP: 3201.2600 - TN: 5522.5898 - FP: 124.4100 - FN: 170.7400 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9435 - val_TP: 758.5700 - val_TN: 1081.5601 - val_FP: 24.4400 - val_FN: 45.4300\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0494 - Accuracy: 0.9829 - Precision: 0.9577 - Recall: 0.9493 - TP: 3201.2000 - TN: 5523.7700 - FP: 123.2300 - FN: 170.8000 - val_loss: 0.0747 - val_Accuracy: 0.9780 - val_Precision: 0.9608 - val_Recall: 0.9437 - val_TP: 758.7300 - val_TN: 1080.0100 - val_FP: 25.9900 - val_FN: 45.2700\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0493 - Accuracy: 0.9833 - Precision: 0.9573 - Recall: 0.9496 - TP: 3201.9700 - TN: 5522.0000 - FP: 125.0000 - FN: 170.0300 - val_loss: 0.0751 - val_Accuracy: 0.9780 - val_Precision: 0.9600 - val_Recall: 0.9437 - val_TP: 758.7200 - val_TN: 1079.1899 - val_FP: 26.8100 - val_FN: 45.2800\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0494 - Accuracy: 0.9831 - Precision: 0.9572 - Recall: 0.9495 - TP: 3201.7300 - TN: 5521.2700 - FP: 125.7300 - FN: 170.2700 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9435 - val_TP: 758.6100 - val_TN: 1081.5601 - val_FP: 24.4400 - val_FN: 45.3900\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0495 - Accuracy: 0.9831 - Precision: 0.9575 - Recall: 0.9494 - TP: 3201.4299 - TN: 5522.6802 - FP: 124.3200 - FN: 170.5700 - val_loss: 0.0747 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9436 - val_TP: 758.6700 - val_TN: 1080.0699 - val_FP: 25.9300 - val_FN: 45.3300\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0494 - Accuracy: 0.9830 - Precision: 0.9574 - Recall: 0.9495 - TP: 3201.5901 - TN: 5522.3198 - FP: 124.6800 - FN: 170.4100 - val_loss: 0.0744 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9436 - val_TP: 758.6800 - val_TN: 1080.3300 - val_FP: 25.6700 - val_FN: 45.3200\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0493 - Accuracy: 0.9833 - Precision: 0.9574 - Recall: 0.9494 - TP: 3201.4900 - TN: 5522.2798 - FP: 124.7200 - FN: 170.5100 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9619 - val_Recall: 0.9436 - val_TP: 758.6500 - val_TN: 1081.2100 - val_FP: 24.7900 - val_FN: 45.3500\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0493 - Accuracy: 0.9831 - Precision: 0.9572 - Recall: 0.9497 - TP: 3202.2500 - TN: 5521.2900 - FP: 125.7100 - FN: 169.7500 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9435 - val_TP: 758.6100 - val_TN: 1081.6400 - val_FP: 24.3600 - val_FN: 45.3900\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0493 - Accuracy: 0.9833 - Precision: 0.9577 - Recall: 0.9495 - TP: 3201.7600 - TN: 5523.9102 - FP: 123.0900 - FN: 170.2400 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9618 - val_Recall: 0.9437 - val_TP: 758.7000 - val_TN: 1081.0900 - val_FP: 24.9100 - val_FN: 45.3000\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0493 - Accuracy: 0.9830 - Precision: 0.9572 - Recall: 0.9497 - TP: 3202.2500 - TN: 5521.3501 - FP: 125.6500 - FN: 169.7500 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9435 - val_TP: 758.6000 - val_TN: 1081.4600 - val_FP: 24.5400 - val_FN: 45.4000\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0493 - Accuracy: 0.9831 - Precision: 0.9574 - Recall: 0.9496 - TP: 3202.0400 - TN: 5522.4502 - FP: 124.5500 - FN: 169.9600 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9437 - val_TP: 758.7000 - val_TN: 1081.5900 - val_FP: 24.4100 - val_FN: 45.3000\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0492 - Accuracy: 0.9830 - Precision: 0.9574 - Recall: 0.9497 - TP: 3202.2300 - TN: 5522.4199 - FP: 124.5800 - FN: 169.7700 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9435 - val_TP: 758.6000 - val_TN: 1081.6100 - val_FP: 24.3900 - val_FN: 45.4000\n",
      "Epoch 30/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0492 - Accuracy: 0.9831 - Precision: 0.9575 - Recall: 0.9496 - TP: 3202.1101 - TN: 5522.6299 - FP: 124.3700 - FN: 169.8900 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9436 - val_TP: 758.6300 - val_TN: 1081.4900 - val_FP: 24.5100 - val_FN: 45.3700\n",
      "Epoch 31/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0492 - Accuracy: 0.9830 - Precision: 0.9575 - Recall: 0.9495 - TP: 3201.7100 - TN: 5522.7100 - FP: 124.2900 - FN: 170.2900 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9435 - val_TP: 758.5900 - val_TN: 1081.4600 - val_FP: 24.5400 - val_FN: 45.4100\n",
      "Epoch 32/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0492 - Accuracy: 0.9830 - Precision: 0.9577 - Recall: 0.9495 - TP: 3201.8501 - TN: 5523.8701 - FP: 123.1300 - FN: 170.1500 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9619 - val_Recall: 0.9437 - val_TP: 758.7000 - val_TN: 1081.1700 - val_FP: 24.8300 - val_FN: 45.3000\n",
      "Epoch 33/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0491 - Accuracy: 0.9831 - Precision: 0.9572 - Recall: 0.9498 - TP: 3202.7800 - TN: 5521.2598 - FP: 125.7400 - FN: 169.2200 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9436 - val_TP: 758.6900 - val_TN: 1081.5500 - val_FP: 24.4500 - val_FN: 45.3100\n",
      "Epoch 34/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0492 - Accuracy: 0.9831 - Precision: 0.9578 - Recall: 0.9494 - TP: 3201.3201 - TN: 5524.3301 - FP: 122.6700 - FN: 170.6800 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9435 - val_TP: 758.6000 - val_TN: 1081.5100 - val_FP: 24.4900 - val_FN: 45.4000\n",
      "Epoch 35/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0490 - Accuracy: 0.9830 - Precision: 0.9575 - Recall: 0.9497 - TP: 3202.3101 - TN: 5522.7300 - FP: 124.2700 - FN: 169.6900 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9437 - val_TP: 758.7500 - val_TN: 1081.3900 - val_FP: 24.6100 - val_FN: 45.2500\n",
      "Epoch 36/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0491 - Accuracy: 0.9830 - Precision: 0.9574 - Recall: 0.9497 - TP: 3202.5400 - TN: 5522.0698 - FP: 124.9300 - FN: 169.4600 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9437 - val_TP: 758.7300 - val_TN: 1081.5900 - val_FP: 24.4100 - val_FN: 45.2700\n",
      "Epoch 37/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0490 - Accuracy: 0.9833 - Precision: 0.9574 - Recall: 0.9499 - TP: 3202.9600 - TN: 5522.5000 - FP: 124.5000 - FN: 169.0400 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9629 - val_Recall: 0.9436 - val_TP: 758.6600 - val_TN: 1082.3800 - val_FP: 23.6200 - val_FN: 45.3400\n",
      "Epoch 38/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0491 - Accuracy: 0.9831 - Precision: 0.9577 - Recall: 0.9496 - TP: 3202.0801 - TN: 5524.0601 - FP: 122.9400 - FN: 169.9200 - val_loss: 0.0745 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9438 - val_TP: 758.8400 - val_TN: 1080.2700 - val_FP: 25.7300 - val_FN: 45.1600\n",
      "Epoch 39/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0490 - Accuracy: 0.9830 - Precision: 0.9574 - Recall: 0.9498 - TP: 3202.8601 - TN: 5522.2300 - FP: 124.7700 - FN: 169.1400 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9438 - val_TP: 758.7900 - val_TN: 1081.4700 - val_FP: 24.5300 - val_FN: 45.2100\n",
      "Epoch 40/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0490 - Accuracy: 0.9830 - Precision: 0.9575 - Recall: 0.9498 - TP: 3202.6101 - TN: 5523.0000 - FP: 124.0000 - FN: 169.3900 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9620 - val_Recall: 0.9437 - val_TP: 758.7400 - val_TN: 1081.3000 - val_FP: 24.7000 - val_FN: 45.2600\n",
      "Epoch 41/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0490 - Accuracy: 0.9830 - Precision: 0.9576 - Recall: 0.9497 - TP: 3202.4800 - TN: 5523.0298 - FP: 123.9700 - FN: 169.5200 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9629 - val_Recall: 0.9436 - val_TP: 758.6500 - val_TN: 1082.4000 - val_FP: 23.6000 - val_FN: 45.3500\n",
      "Epoch 42/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0489 - Accuracy: 0.9830 - Precision: 0.9577 - Recall: 0.9497 - TP: 3202.3799 - TN: 5523.7300 - FP: 123.2700 - FN: 169.6200 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9438 - val_TP: 758.8000 - val_TN: 1081.5900 - val_FP: 24.4100 - val_FN: 45.2000\n",
      "Epoch 43/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0489 - Accuracy: 0.9829 - Precision: 0.9577 - Recall: 0.9498 - TP: 3202.6001 - TN: 5523.7998 - FP: 123.2000 - FN: 169.4000 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9624 - val_Recall: 0.9438 - val_TP: 758.7800 - val_TN: 1081.7300 - val_FP: 24.2700 - val_FN: 45.2200\n",
      "Epoch 44/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0489 - Accuracy: 0.9830 - Precision: 0.9573 - Recall: 0.9498 - TP: 3202.8799 - TN: 5521.6099 - FP: 125.3900 - FN: 169.1200 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9628 - val_Recall: 0.9438 - val_TP: 758.7800 - val_TN: 1082.3000 - val_FP: 23.7000 - val_FN: 45.2200\n",
      "Epoch 45/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0489 - Accuracy: 0.9830 - Precision: 0.9578 - Recall: 0.9497 - TP: 3202.4500 - TN: 5524.4702 - FP: 122.5300 - FN: 169.5500 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9624 - val_Recall: 0.9437 - val_TP: 758.7300 - val_TN: 1081.7300 - val_FP: 24.2700 - val_FN: 45.2700\n",
      "Epoch 46/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0488 - Accuracy: 0.9830 - Precision: 0.9577 - Recall: 0.9498 - TP: 3202.8401 - TN: 5523.7100 - FP: 123.2900 - FN: 169.1600 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9618 - val_Recall: 0.9439 - val_TP: 758.8600 - val_TN: 1081.1400 - val_FP: 24.8600 - val_FN: 45.1400\n",
      "Epoch 47/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0488 - Accuracy: 0.9831 - Precision: 0.9573 - Recall: 0.9500 - TP: 3203.5000 - TN: 5521.9800 - FP: 125.0200 - FN: 168.5000 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9437 - val_TP: 758.7700 - val_TN: 1081.5300 - val_FP: 24.4700 - val_FN: 45.2300\n",
      "Epoch 48/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0488 - Accuracy: 0.9830 - Precision: 0.9575 - Recall: 0.9499 - TP: 3203.1399 - TN: 5522.5400 - FP: 124.4600 - FN: 168.8600 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9437 - val_TP: 758.7300 - val_TN: 1081.6801 - val_FP: 24.3200 - val_FN: 45.2700\n",
      "Epoch 49/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0488 - Accuracy: 0.9831 - Precision: 0.9577 - Recall: 0.9499 - TP: 3203.1299 - TN: 5523.3999 - FP: 123.6000 - FN: 168.8700 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9437 - val_TP: 758.7700 - val_TN: 1081.4900 - val_FP: 24.5100 - val_FN: 45.2300\n",
      "Epoch 50/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0488 - Accuracy: 0.9831 - Precision: 0.9578 - Recall: 0.9498 - TP: 3202.8501 - TN: 5523.7798 - FP: 123.2200 - FN: 169.1500 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9620 - val_Recall: 0.9437 - val_TP: 758.7600 - val_TN: 1081.3700 - val_FP: 24.6300 - val_FN: 45.2400\n",
      "Epoch 51/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0488 - Accuracy: 0.9831 - Precision: 0.9579 - Recall: 0.9498 - TP: 3202.6101 - TN: 5524.5000 - FP: 122.5000 - FN: 169.3900 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9437 - val_TP: 758.7600 - val_TN: 1081.6899 - val_FP: 24.3100 - val_FN: 45.2400\n",
      "Epoch 52/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0487 - Accuracy: 0.9830 - Precision: 0.9578 - Recall: 0.9500 - TP: 3203.2800 - TN: 5524.0000 - FP: 123.0000 - FN: 168.7200 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9437 - val_TP: 758.7500 - val_TN: 1081.4700 - val_FP: 24.5300 - val_FN: 45.2500\n",
      "Epoch 53/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0487 - Accuracy: 0.9829 - Precision: 0.9577 - Recall: 0.9500 - TP: 3203.4199 - TN: 5523.6499 - FP: 123.3500 - FN: 168.5800 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9618 - val_Recall: 0.9438 - val_TP: 758.8500 - val_TN: 1081.1600 - val_FP: 24.8400 - val_FN: 45.1500\n",
      "Epoch 54/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0487 - Accuracy: 0.9833 - Precision: 0.9576 - Recall: 0.9500 - TP: 3203.5200 - TN: 5523.4302 - FP: 123.5700 - FN: 168.4800 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9620 - val_Recall: 0.9438 - val_TP: 758.8400 - val_TN: 1081.3700 - val_FP: 24.6300 - val_FN: 45.1600\n",
      "Epoch 55/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0486 - Accuracy: 0.9834 - Precision: 0.9580 - Recall: 0.9498 - TP: 3202.7500 - TN: 5525.0098 - FP: 121.9900 - FN: 169.2500 - val_loss: 0.0748 - val_Accuracy: 0.9770 - val_Precision: 0.9609 - val_Recall: 0.9438 - val_TP: 758.8400 - val_TN: 1080.1899 - val_FP: 25.8100 - val_FN: 45.1600\n",
      "Epoch 56/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0486 - Accuracy: 0.9830 - Precision: 0.9577 - Recall: 0.9500 - TP: 3203.3201 - TN: 5523.6401 - FP: 123.3600 - FN: 168.6800 - val_loss: 0.0745 - val_Accuracy: 0.9770 - val_Precision: 0.9617 - val_Recall: 0.9438 - val_TP: 758.8200 - val_TN: 1081.0500 - val_FP: 24.9500 - val_FN: 45.1800\n",
      "Epoch 57/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0486 - Accuracy: 0.9834 - Precision: 0.9574 - Recall: 0.9503 - TP: 3204.5400 - TN: 5522.3901 - FP: 124.6100 - FN: 167.4600 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9625 - val_Recall: 0.9437 - val_TP: 758.7600 - val_TN: 1081.8800 - val_FP: 24.1200 - val_FN: 45.2400\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 4ms/step - loss: 0.0500 - Accuracy: 0.9828 - Precision: 0.9582 - Recall: 0.9491 - TP: 3200.4700 - TN: 5526.5298 - FP: 120.4700 - FN: 171.5300 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9620 - val_Recall: 0.9439 - val_TP: 758.9000 - val_TN: 1081.3600 - val_FP: 24.6400 - val_FN: 45.1000\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0491 - Accuracy: 0.9830 - Precision: 0.9573 - Recall: 0.9499 - TP: 3203.0801 - TN: 5521.9102 - FP: 125.0900 - FN: 168.9200 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9620 - val_Recall: 0.9439 - val_TP: 758.8800 - val_TN: 1081.3300 - val_FP: 24.6700 - val_FN: 45.1200\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0489 - Accuracy: 0.9831 - Precision: 0.9577 - Recall: 0.9498 - TP: 3202.8301 - TN: 5523.7002 - FP: 123.3000 - FN: 169.1700 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9437 - val_TP: 758.7200 - val_TN: 1081.5400 - val_FP: 24.4600 - val_FN: 45.2800\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0490 - Accuracy: 0.9830 - Precision: 0.9574 - Recall: 0.9497 - TP: 3202.4900 - TN: 5522.2500 - FP: 124.7500 - FN: 169.5100 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9624 - val_Recall: 0.9437 - val_TP: 758.7000 - val_TN: 1081.7700 - val_FP: 24.2300 - val_FN: 45.3000\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0489 - Accuracy: 0.9833 - Precision: 0.9577 - Recall: 0.9498 - TP: 3202.6899 - TN: 5523.5801 - FP: 123.4200 - FN: 169.3100 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9438 - val_TP: 758.8000 - val_TN: 1081.6200 - val_FP: 24.3800 - val_FN: 45.2000\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0489 - Accuracy: 0.9831 - Precision: 0.9577 - Recall: 0.9498 - TP: 3202.6599 - TN: 5523.3198 - FP: 123.6800 - FN: 169.3400 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9625 - val_Recall: 0.9437 - val_TP: 758.7100 - val_TN: 1081.8101 - val_FP: 24.1900 - val_FN: 45.2900\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0490 - Accuracy: 0.9831 - Precision: 0.9576 - Recall: 0.9498 - TP: 3202.5901 - TN: 5523.2500 - FP: 123.7500 - FN: 169.4100 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9628 - val_Recall: 0.9437 - val_TP: 758.7500 - val_TN: 1082.2900 - val_FP: 23.7100 - val_FN: 45.2500\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0489 - Accuracy: 0.9831 - Precision: 0.9577 - Recall: 0.9498 - TP: 3202.7600 - TN: 5523.4502 - FP: 123.5500 - FN: 169.2400 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9624 - val_Recall: 0.9437 - val_TP: 758.7300 - val_TN: 1081.7200 - val_FP: 24.2800 - val_FN: 45.2700\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0488 - Accuracy: 0.9830 - Precision: 0.9576 - Recall: 0.9499 - TP: 3203.2000 - TN: 5523.2700 - FP: 123.7300 - FN: 168.8000 - val_loss: 0.0745 - val_Accuracy: 0.9775 - val_Precision: 0.9613 - val_Recall: 0.9437 - val_TP: 758.7500 - val_TN: 1080.5200 - val_FP: 25.4800 - val_FN: 45.2500\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0488 - Accuracy: 0.9830 - Precision: 0.9577 - Recall: 0.9498 - TP: 3202.8701 - TN: 5523.3398 - FP: 123.6600 - FN: 169.1300 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9619 - val_Recall: 0.9438 - val_TP: 758.8300 - val_TN: 1081.2700 - val_FP: 24.7300 - val_FN: 45.1700\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0489 - Accuracy: 0.9831 - Precision: 0.9576 - Recall: 0.9498 - TP: 3202.7700 - TN: 5522.9502 - FP: 124.0500 - FN: 169.2300 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9437 - val_TP: 758.7500 - val_TN: 1081.6200 - val_FP: 24.3800 - val_FN: 45.2500\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0488 - Accuracy: 0.9830 - Precision: 0.9577 - Recall: 0.9498 - TP: 3202.8501 - TN: 5523.7100 - FP: 123.2900 - FN: 169.1500 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9618 - val_Recall: 0.9438 - val_TP: 758.8500 - val_TN: 1081.1400 - val_FP: 24.8600 - val_FN: 45.1500\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0488 - Accuracy: 0.9830 - Precision: 0.9578 - Recall: 0.9499 - TP: 3202.8999 - TN: 5524.0200 - FP: 122.9800 - FN: 169.1000 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9437 - val_TP: 758.7300 - val_TN: 1081.5100 - val_FP: 24.4900 - val_FN: 45.2700\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0488 - Accuracy: 0.9831 - Precision: 0.9577 - Recall: 0.9499 - TP: 3203.2300 - TN: 5523.6099 - FP: 123.3900 - FN: 168.7700 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9437 - val_TP: 758.7700 - val_TN: 1081.5500 - val_FP: 24.4500 - val_FN: 45.2300\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0487 - Accuracy: 0.9831 - Precision: 0.9578 - Recall: 0.9500 - TP: 3203.3701 - TN: 5524.3999 - FP: 122.6000 - FN: 168.6300 - val_loss: 0.0739 - val_Accuracy: 0.9770 - val_Precision: 0.9622 - val_Recall: 0.9439 - val_TP: 758.9000 - val_TN: 1081.5300 - val_FP: 24.4700 - val_FN: 45.1000\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0488 - Accuracy: 0.9830 - Precision: 0.9574 - Recall: 0.9499 - TP: 3203.2300 - TN: 5522.5098 - FP: 124.4900 - FN: 168.7700 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9438 - val_TP: 758.8400 - val_TN: 1081.6200 - val_FP: 24.3800 - val_FN: 45.1600\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0486 - Accuracy: 0.9836 - Precision: 0.9576 - Recall: 0.9502 - TP: 3204.0801 - TN: 5523.3398 - FP: 123.6600 - FN: 167.9200 - val_loss: 0.0734 - val_Accuracy: 0.9775 - val_Precision: 0.9631 - val_Recall: 0.9438 - val_TP: 758.8100 - val_TN: 1082.6500 - val_FP: 23.3500 - val_FN: 45.1900\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0487 - Accuracy: 0.9831 - Precision: 0.9580 - Recall: 0.9497 - TP: 3202.4099 - TN: 5525.2598 - FP: 121.7400 - FN: 169.5900 - val_loss: 0.0745 - val_Accuracy: 0.9770 - val_Precision: 0.9614 - val_Recall: 0.9438 - val_TP: 758.8300 - val_TN: 1080.6300 - val_FP: 25.3700 - val_FN: 45.1700\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0487 - Accuracy: 0.9831 - Precision: 0.9578 - Recall: 0.9499 - TP: 3203.0300 - TN: 5524.0000 - FP: 123.0000 - FN: 168.9700 - val_loss: 0.0739 - val_Accuracy: 0.9770 - val_Precision: 0.9624 - val_Recall: 0.9438 - val_TP: 758.8300 - val_TN: 1081.7500 - val_FP: 24.2500 - val_FN: 45.1700\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0487 - Accuracy: 0.9831 - Precision: 0.9575 - Recall: 0.9500 - TP: 3203.4099 - TN: 5522.4800 - FP: 124.5200 - FN: 168.5900 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9621 - val_Recall: 0.9439 - val_TP: 758.8800 - val_TN: 1081.5100 - val_FP: 24.4900 - val_FN: 45.1200\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0487 - Accuracy: 0.9830 - Precision: 0.9580 - Recall: 0.9499 - TP: 3202.9500 - TN: 5524.8501 - FP: 122.1500 - FN: 169.0500 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9621 - val_Recall: 0.9439 - val_TP: 758.8700 - val_TN: 1081.4700 - val_FP: 24.5300 - val_FN: 45.1300\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0486 - Accuracy: 0.9833 - Precision: 0.9575 - Recall: 0.9502 - TP: 3203.9199 - TN: 5522.7598 - FP: 124.2400 - FN: 168.0800 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9622 - val_Recall: 0.9439 - val_TP: 758.8600 - val_TN: 1081.5699 - val_FP: 24.4300 - val_FN: 45.1400\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0486 - Accuracy: 0.9830 - Precision: 0.9576 - Recall: 0.9501 - TP: 3203.6299 - TN: 5523.2900 - FP: 123.7100 - FN: 168.3700 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9439 - val_TP: 758.9200 - val_TN: 1081.5200 - val_FP: 24.4800 - val_FN: 45.0800\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0485 - Accuracy: 0.9831 - Precision: 0.9578 - Recall: 0.9503 - TP: 3204.3401 - TN: 5523.9102 - FP: 123.0900 - FN: 167.6600 - val_loss: 0.0738 - val_Accuracy: 0.9770 - val_Precision: 0.9628 - val_Recall: 0.9438 - val_TP: 758.8400 - val_TN: 1082.3300 - val_FP: 23.6700 - val_FN: 45.1600\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0485 - Accuracy: 0.9834 - Precision: 0.9578 - Recall: 0.9500 - TP: 3203.5500 - TN: 5524.0801 - FP: 122.9200 - FN: 168.4500 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9439 - val_TP: 758.8900 - val_TN: 1081.6801 - val_FP: 24.3200 - val_FN: 45.1100\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0485 - Accuracy: 0.9831 - Precision: 0.9580 - Recall: 0.9501 - TP: 3203.7500 - TN: 5524.8701 - FP: 122.1300 - FN: 168.2500 - val_loss: 0.0737 - val_Accuracy: 0.9770 - val_Precision: 0.9630 - val_Recall: 0.9438 - val_TP: 758.8200 - val_TN: 1082.5300 - val_FP: 23.4700 - val_FN: 45.1800\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0486 - Accuracy: 0.9831 - Precision: 0.9579 - Recall: 0.9500 - TP: 3203.3000 - TN: 5524.7202 - FP: 122.2800 - FN: 168.7000 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9439 - val_TP: 758.8900 - val_TN: 1081.6400 - val_FP: 24.3600 - val_FN: 45.1100\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0486 - Accuracy: 0.9833 - Precision: 0.9577 - Recall: 0.9501 - TP: 3203.6201 - TN: 5523.6001 - FP: 123.4000 - FN: 168.3800 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9623 - val_Recall: 0.9439 - val_TP: 758.8600 - val_TN: 1081.7000 - val_FP: 24.3000 - val_FN: 45.1400\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0485 - Accuracy: 0.9830 - Precision: 0.9577 - Recall: 0.9502 - TP: 3204.1299 - TN: 5523.8101 - FP: 123.1900 - FN: 167.8700 - val_loss: 0.0737 - val_Accuracy: 0.9770 - val_Precision: 0.9630 - val_Recall: 0.9438 - val_TP: 758.8100 - val_TN: 1082.5200 - val_FP: 23.4800 - val_FN: 45.1900\n",
      "Epoch 30/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0484 - Accuracy: 0.9830 - Precision: 0.9583 - Recall: 0.9501 - TP: 3203.7700 - TN: 5526.4502 - FP: 120.5500 - FN: 168.2300 - val_loss: 0.0748 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9440 - val_TP: 758.9900 - val_TN: 1080.2600 - val_FP: 25.7400 - val_FN: 45.0100\n",
      "Epoch 31/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0483 - Accuracy: 0.9833 - Precision: 0.9577 - Recall: 0.9503 - TP: 3204.4600 - TN: 5523.5898 - FP: 123.4100 - FN: 167.5400 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9630 - val_Recall: 0.9439 - val_TP: 758.9000 - val_TN: 1082.5300 - val_FP: 23.4700 - val_FN: 45.1000\n",
      "Epoch 32/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0483 - Accuracy: 0.9834 - Precision: 0.9580 - Recall: 0.9505 - TP: 3204.9299 - TN: 5525.1299 - FP: 121.8700 - FN: 167.0700 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9629 - val_Recall: 0.9439 - val_TP: 758.9000 - val_TN: 1082.4100 - val_FP: 23.5900 - val_FN: 45.1000\n",
      "Epoch 33/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0484 - Accuracy: 0.9830 - Precision: 0.9580 - Recall: 0.9501 - TP: 3203.6599 - TN: 5525.1401 - FP: 121.8600 - FN: 168.3400 - val_loss: 0.0744 - val_Accuracy: 0.9775 - val_Precision: 0.9619 - val_Recall: 0.9440 - val_TP: 758.9500 - val_TN: 1081.2300 - val_FP: 24.7700 - val_FN: 45.0500\n",
      "Epoch 34/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0483 - Accuracy: 0.9830 - Precision: 0.9579 - Recall: 0.9502 - TP: 3204.1299 - TN: 5524.5601 - FP: 122.4400 - FN: 167.8700 - val_loss: 0.0744 - val_Accuracy: 0.9775 - val_Precision: 0.9617 - val_Recall: 0.9440 - val_TP: 759.0100 - val_TN: 1081.1200 - val_FP: 24.8800 - val_FN: 44.9900\n",
      "Epoch 35/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0483 - Accuracy: 0.9830 - Precision: 0.9582 - Recall: 0.9501 - TP: 3203.8601 - TN: 5525.6299 - FP: 121.3700 - FN: 168.1400 - val_loss: 0.0747 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9439 - val_TP: 758.9100 - val_TN: 1080.5100 - val_FP: 25.4900 - val_FN: 45.0900\n",
      "Epoch 36/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0485 - Accuracy: 0.9831 - Precision: 0.9577 - Recall: 0.9502 - TP: 3204.2300 - TN: 5523.6001 - FP: 123.4000 - FN: 167.7700 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9628 - val_Recall: 0.9440 - val_TP: 759.0100 - val_TN: 1082.3400 - val_FP: 23.6600 - val_FN: 44.9900\n",
      "Epoch 37/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0483 - Accuracy: 0.9835 - Precision: 0.9579 - Recall: 0.9502 - TP: 3203.9399 - TN: 5524.4502 - FP: 122.5500 - FN: 168.0600 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9440 - val_TP: 758.9500 - val_TN: 1081.4900 - val_FP: 24.5100 - val_FN: 45.0500\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0490 - Accuracy: 0.9829 - Precision: 0.9582 - Recall: 0.9496 - TP: 3202.2000 - TN: 5526.2500 - FP: 120.7500 - FN: 169.8000 - val_loss: 0.0746 - val_Accuracy: 0.9775 - val_Precision: 0.9610 - val_Recall: 0.9440 - val_TP: 758.9600 - val_TN: 1080.2900 - val_FP: 25.7100 - val_FN: 45.0400\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0487 - Accuracy: 0.9831 - Precision: 0.9578 - Recall: 0.9500 - TP: 3203.4199 - TN: 5523.9399 - FP: 123.0600 - FN: 168.5800 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9621 - val_Recall: 0.9438 - val_TP: 758.8400 - val_TN: 1081.4900 - val_FP: 24.5100 - val_FN: 45.1600\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0487 - Accuracy: 0.9833 - Precision: 0.9576 - Recall: 0.9501 - TP: 3203.6599 - TN: 5523.1699 - FP: 123.8300 - FN: 168.3400 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9440 - val_TP: 758.9500 - val_TN: 1081.5200 - val_FP: 24.4800 - val_FN: 45.0500\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0487 - Accuracy: 0.9830 - Precision: 0.9576 - Recall: 0.9501 - TP: 3203.8799 - TN: 5523.3398 - FP: 123.6600 - FN: 168.1200 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9440 - val_TP: 758.9400 - val_TN: 1081.4900 - val_FP: 24.5100 - val_FN: 45.0600\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0485 - Accuracy: 0.9831 - Precision: 0.9576 - Recall: 0.9502 - TP: 3203.9600 - TN: 5523.3398 - FP: 123.6600 - FN: 168.0400 - val_loss: 0.0739 - val_Accuracy: 0.9770 - val_Precision: 0.9624 - val_Recall: 0.9438 - val_TP: 758.8300 - val_TN: 1081.7400 - val_FP: 24.2600 - val_FN: 45.1700\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0486 - Accuracy: 0.9830 - Precision: 0.9579 - Recall: 0.9500 - TP: 3203.5300 - TN: 5524.7598 - FP: 122.2400 - FN: 168.4700 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9624 - val_Recall: 0.9438 - val_TP: 758.7900 - val_TN: 1081.7800 - val_FP: 24.2200 - val_FN: 45.2100\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0485 - Accuracy: 0.9834 - Precision: 0.9578 - Recall: 0.9501 - TP: 3203.5901 - TN: 5524.0801 - FP: 122.9200 - FN: 168.4100 - val_loss: 0.0738 - val_Accuracy: 0.9770 - val_Precision: 0.9630 - val_Recall: 0.9437 - val_TP: 758.7300 - val_TN: 1082.4900 - val_FP: 23.5100 - val_FN: 45.2700\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0485 - Accuracy: 0.9834 - Precision: 0.9578 - Recall: 0.9503 - TP: 3204.5601 - TN: 5524.1699 - FP: 122.8300 - FN: 167.4400 - val_loss: 0.0735 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9438 - val_TP: 758.8200 - val_TN: 1082.7500 - val_FP: 23.2500 - val_FN: 45.1800\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0485 - Accuracy: 0.9831 - Precision: 0.9579 - Recall: 0.9500 - TP: 3203.4600 - TN: 5524.7002 - FP: 122.3000 - FN: 168.5400 - val_loss: 0.0745 - val_Accuracy: 0.9770 - val_Precision: 0.9619 - val_Recall: 0.9439 - val_TP: 758.8900 - val_TN: 1081.2300 - val_FP: 24.7700 - val_FN: 45.1100\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0487 - Accuracy: 0.9830 - Precision: 0.9577 - Recall: 0.9500 - TP: 3203.4500 - TN: 5524.1499 - FP: 122.8500 - FN: 168.5500 - val_loss: 0.0739 - val_Accuracy: 0.9770 - val_Precision: 0.9629 - val_Recall: 0.9438 - val_TP: 758.7800 - val_TN: 1082.4100 - val_FP: 23.5900 - val_FN: 45.2200\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0485 - Accuracy: 0.9830 - Precision: 0.9576 - Recall: 0.9502 - TP: 3203.9500 - TN: 5523.0801 - FP: 123.9200 - FN: 168.0500 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9625 - val_Recall: 0.9437 - val_TP: 758.7700 - val_TN: 1081.8800 - val_FP: 24.1200 - val_FN: 45.2300\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0484 - Accuracy: 0.9834 - Precision: 0.9578 - Recall: 0.9502 - TP: 3204.0500 - TN: 5524.1699 - FP: 122.8300 - FN: 167.9500 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9629 - val_Recall: 0.9438 - val_TP: 758.8500 - val_TN: 1082.4200 - val_FP: 23.5800 - val_FN: 45.1500\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0484 - Accuracy: 0.9830 - Precision: 0.9580 - Recall: 0.9502 - TP: 3203.9299 - TN: 5525.1499 - FP: 121.8500 - FN: 168.0700 - val_loss: 0.0739 - val_Accuracy: 0.9770 - val_Precision: 0.9627 - val_Recall: 0.9438 - val_TP: 758.7800 - val_TN: 1082.0200 - val_FP: 23.9800 - val_FN: 45.2200\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0484 - Accuracy: 0.9830 - Precision: 0.9581 - Recall: 0.9500 - TP: 3203.3899 - TN: 5525.5698 - FP: 121.4300 - FN: 168.6100 - val_loss: 0.0738 - val_Accuracy: 0.9770 - val_Precision: 0.9631 - val_Recall: 0.9438 - val_TP: 758.8000 - val_TN: 1082.5800 - val_FP: 23.4200 - val_FN: 45.2000\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0484 - Accuracy: 0.9830 - Precision: 0.9582 - Recall: 0.9501 - TP: 3203.8401 - TN: 5526.3101 - FP: 120.6900 - FN: 168.1600 - val_loss: 0.0745 - val_Accuracy: 0.9775 - val_Precision: 0.9616 - val_Recall: 0.9441 - val_TP: 759.0600 - val_TN: 1081.0300 - val_FP: 24.9700 - val_FN: 44.9400\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0484 - Accuracy: 0.9834 - Precision: 0.9576 - Recall: 0.9505 - TP: 3205.2000 - TN: 5522.7700 - FP: 124.2300 - FN: 166.8000 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9625 - val_Recall: 0.9439 - val_TP: 758.8800 - val_TN: 1081.9100 - val_FP: 24.0900 - val_FN: 45.1200\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0483 - Accuracy: 0.9831 - Precision: 0.9579 - Recall: 0.9502 - TP: 3204.2000 - TN: 5524.7002 - FP: 122.3000 - FN: 167.8000 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9440 - val_TP: 758.9900 - val_TN: 1081.6801 - val_FP: 24.3200 - val_FN: 45.0100\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0482 - Accuracy: 0.9830 - Precision: 0.9580 - Recall: 0.9501 - TP: 3203.7300 - TN: 5525.2900 - FP: 121.7100 - FN: 168.2700 - val_loss: 0.0756 - val_Accuracy: 0.9770 - val_Precision: 0.9598 - val_Recall: 0.9442 - val_TP: 759.1000 - val_TN: 1079.0601 - val_FP: 26.9400 - val_FN: 44.9000\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0483 - Accuracy: 0.9835 - Precision: 0.9576 - Recall: 0.9505 - TP: 3205.1201 - TN: 5523.3999 - FP: 123.6000 - FN: 166.8800 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9625 - val_Recall: 0.9439 - val_TP: 758.8800 - val_TN: 1081.9100 - val_FP: 24.0900 - val_FN: 45.1200\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0482 - Accuracy: 0.9836 - Precision: 0.9581 - Recall: 0.9502 - TP: 3204.2000 - TN: 5525.1699 - FP: 121.8300 - FN: 167.8000 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9439 - val_TP: 758.9100 - val_TN: 1081.4800 - val_FP: 24.5200 - val_FN: 45.0900\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0482 - Accuracy: 0.9836 - Precision: 0.9579 - Recall: 0.9505 - TP: 3205.2500 - TN: 5524.5200 - FP: 122.4800 - FN: 166.7500 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9624 - val_Recall: 0.9439 - val_TP: 758.9200 - val_TN: 1081.7700 - val_FP: 24.2300 - val_FN: 45.0800\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0483 - Accuracy: 0.9834 - Precision: 0.9579 - Recall: 0.9503 - TP: 3204.2700 - TN: 5524.7002 - FP: 122.3000 - FN: 167.7300 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9439 - val_TP: 758.9200 - val_TN: 1081.6200 - val_FP: 24.3800 - val_FN: 45.0800\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0482 - Accuracy: 0.9834 - Precision: 0.9582 - Recall: 0.9503 - TP: 3204.2600 - TN: 5526.0000 - FP: 121.0000 - FN: 167.7400 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9439 - val_TP: 758.9000 - val_TN: 1081.6000 - val_FP: 24.4000 - val_FN: 45.1000\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0481 - Accuracy: 0.9833 - Precision: 0.9578 - Recall: 0.9506 - TP: 3205.4700 - TN: 5524.1802 - FP: 122.8200 - FN: 166.5300 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9626 - val_Recall: 0.9439 - val_TP: 758.9000 - val_TN: 1081.9700 - val_FP: 24.0300 - val_FN: 45.1000\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0482 - Accuracy: 0.9833 - Precision: 0.9582 - Recall: 0.9504 - TP: 3204.8899 - TN: 5526.0801 - FP: 120.9200 - FN: 167.1100 - val_loss: 0.0744 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9439 - val_TP: 758.9100 - val_TN: 1081.5000 - val_FP: 24.5000 - val_FN: 45.0900\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0482 - Accuracy: 0.9834 - Precision: 0.9579 - Recall: 0.9505 - TP: 3204.9700 - TN: 5524.3198 - FP: 122.6800 - FN: 167.0300 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9631 - val_Recall: 0.9440 - val_TP: 758.9400 - val_TN: 1082.6801 - val_FP: 23.3200 - val_FN: 45.0600\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0479 - Accuracy: 0.9834 - Precision: 0.9582 - Recall: 0.9503 - TP: 3204.5601 - TN: 5526.3701 - FP: 120.6300 - FN: 167.4400 - val_loss: 0.0754 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9440 - val_TP: 758.9400 - val_TN: 1079.5400 - val_FP: 26.4600 - val_FN: 45.0600\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0481 - Accuracy: 0.9837 - Precision: 0.9581 - Recall: 0.9506 - TP: 3205.3101 - TN: 5525.3101 - FP: 121.6900 - FN: 166.6900 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9632 - val_Recall: 0.9439 - val_TP: 758.8900 - val_TN: 1082.7100 - val_FP: 23.2900 - val_FN: 45.1100\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 6ms/step - loss: 0.0488 - Accuracy: 0.9830 - Precision: 0.9587 - Recall: 0.9496 - TP: 3202.0400 - TN: 5528.3101 - FP: 118.6900 - FN: 169.9600 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9624 - val_Recall: 0.9438 - val_TP: 758.8100 - val_TN: 1081.7500 - val_FP: 24.2500 - val_FN: 45.1900\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0484 - Accuracy: 0.9830 - Precision: 0.9581 - Recall: 0.9501 - TP: 3203.5701 - TN: 5525.2998 - FP: 121.7000 - FN: 168.4300 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9439 - val_TP: 758.9200 - val_TN: 1081.7100 - val_FP: 24.2900 - val_FN: 45.0800\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0486 - Accuracy: 0.9833 - Precision: 0.9578 - Recall: 0.9503 - TP: 3204.2900 - TN: 5524.2798 - FP: 122.7200 - FN: 167.7100 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9440 - val_TP: 758.9600 - val_TN: 1081.5900 - val_FP: 24.4100 - val_FN: 45.0400\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0484 - Accuracy: 0.9834 - Precision: 0.9581 - Recall: 0.9503 - TP: 3204.2500 - TN: 5525.3301 - FP: 121.6700 - FN: 167.7500 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9440 - val_TP: 758.9600 - val_TN: 1081.4600 - val_FP: 24.5400 - val_FN: 45.0400\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0484 - Accuracy: 0.9833 - Precision: 0.9579 - Recall: 0.9503 - TP: 3204.4700 - TN: 5524.7798 - FP: 122.2200 - FN: 167.5300 - val_loss: 0.0744 - val_Accuracy: 0.9775 - val_Precision: 0.9618 - val_Recall: 0.9440 - val_TP: 758.9800 - val_TN: 1081.1400 - val_FP: 24.8600 - val_FN: 45.0200\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0485 - Accuracy: 0.9829 - Precision: 0.9580 - Recall: 0.9500 - TP: 3203.2900 - TN: 5524.6602 - FP: 122.3400 - FN: 168.7100 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9440 - val_TP: 758.9500 - val_TN: 1081.6899 - val_FP: 24.3100 - val_FN: 45.0500\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0483 - Accuracy: 0.9831 - Precision: 0.9581 - Recall: 0.9503 - TP: 3204.2700 - TN: 5525.4302 - FP: 121.5700 - FN: 167.7300 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9620 - val_Recall: 0.9441 - val_TP: 759.0300 - val_TN: 1081.3700 - val_FP: 24.6300 - val_FN: 44.9700\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0484 - Accuracy: 0.9831 - Precision: 0.9577 - Recall: 0.9504 - TP: 3204.8701 - TN: 5523.6699 - FP: 123.3300 - FN: 167.1300 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9441 - val_TP: 759.0700 - val_TN: 1081.6600 - val_FP: 24.3400 - val_FN: 44.9300\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0484 - Accuracy: 0.9833 - Precision: 0.9577 - Recall: 0.9503 - TP: 3204.3899 - TN: 5523.6401 - FP: 123.3600 - FN: 167.6100 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9630 - val_Recall: 0.9441 - val_TP: 759.0200 - val_TN: 1082.5800 - val_FP: 23.4200 - val_FN: 44.9800\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0482 - Accuracy: 0.9831 - Precision: 0.9580 - Recall: 0.9503 - TP: 3204.4099 - TN: 5525.2798 - FP: 121.7200 - FN: 167.5900 - val_loss: 0.0755 - val_Accuracy: 0.9770 - val_Precision: 0.9601 - val_Recall: 0.9441 - val_TP: 759.0200 - val_TN: 1079.3700 - val_FP: 26.6300 - val_FN: 44.9800\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0484 - Accuracy: 0.9829 - Precision: 0.9581 - Recall: 0.9501 - TP: 3203.7400 - TN: 5525.5000 - FP: 121.5000 - FN: 168.2600 - val_loss: 0.0746 - val_Accuracy: 0.9775 - val_Precision: 0.9613 - val_Recall: 0.9440 - val_TP: 759.0100 - val_TN: 1080.5900 - val_FP: 25.4100 - val_FN: 44.9900\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0483 - Accuracy: 0.9835 - Precision: 0.9578 - Recall: 0.9506 - TP: 3205.2800 - TN: 5524.0298 - FP: 122.9700 - FN: 166.7200 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9441 - val_TP: 759.0200 - val_TN: 1081.7100 - val_FP: 24.2900 - val_FN: 44.9800\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0482 - Accuracy: 0.9831 - Precision: 0.9580 - Recall: 0.9504 - TP: 3204.6899 - TN: 5524.8901 - FP: 122.1100 - FN: 167.3100 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9440 - val_TP: 759.0100 - val_TN: 1081.7000 - val_FP: 24.3000 - val_FN: 44.9900\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0482 - Accuracy: 0.9833 - Precision: 0.9577 - Recall: 0.9505 - TP: 3205.2500 - TN: 5523.7998 - FP: 123.2000 - FN: 166.7500 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9628 - val_Recall: 0.9440 - val_TP: 758.9400 - val_TN: 1082.3300 - val_FP: 23.6700 - val_FN: 45.0600\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0481 - Accuracy: 0.9835 - Precision: 0.9582 - Recall: 0.9505 - TP: 3205.1001 - TN: 5525.8701 - FP: 121.1300 - FN: 166.9000 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9633 - val_Recall: 0.9439 - val_TP: 758.9000 - val_TN: 1082.8800 - val_FP: 23.1200 - val_FN: 45.1000\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0482 - Accuracy: 0.9834 - Precision: 0.9584 - Recall: 0.9503 - TP: 3204.3101 - TN: 5526.8701 - FP: 120.1300 - FN: 167.6900 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9440 - val_TP: 759.0100 - val_TN: 1081.5300 - val_FP: 24.4700 - val_FN: 44.9900\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0482 - Accuracy: 0.9834 - Precision: 0.9579 - Recall: 0.9505 - TP: 3204.9600 - TN: 5524.4302 - FP: 122.5700 - FN: 167.0400 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9624 - val_Recall: 0.9440 - val_TP: 758.9500 - val_TN: 1081.8000 - val_FP: 24.2000 - val_FN: 45.0500\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0482 - Accuracy: 0.9834 - Precision: 0.9581 - Recall: 0.9504 - TP: 3204.7500 - TN: 5525.7202 - FP: 121.2800 - FN: 167.2500 - val_loss: 0.0744 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9439 - val_TP: 758.9200 - val_TN: 1081.5200 - val_FP: 24.4800 - val_FN: 45.0800\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0481 - Accuracy: 0.9835 - Precision: 0.9582 - Recall: 0.9503 - TP: 3204.5100 - TN: 5525.9800 - FP: 121.0200 - FN: 167.4900 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9440 - val_TP: 758.9900 - val_TN: 1081.5300 - val_FP: 24.4700 - val_FN: 45.0100\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0480 - Accuracy: 0.9835 - Precision: 0.9580 - Recall: 0.9505 - TP: 3205.1599 - TN: 5525.1899 - FP: 121.8100 - FN: 166.8400 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9625 - val_Recall: 0.9440 - val_TP: 758.9600 - val_TN: 1081.8800 - val_FP: 24.1200 - val_FN: 45.0400\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0481 - Accuracy: 0.9835 - Precision: 0.9581 - Recall: 0.9503 - TP: 3204.4800 - TN: 5525.5098 - FP: 121.4900 - FN: 167.5200 - val_loss: 0.0744 - val_Accuracy: 0.9775 - val_Precision: 0.9619 - val_Recall: 0.9442 - val_TP: 759.1200 - val_TN: 1081.3199 - val_FP: 24.6800 - val_FN: 44.8800\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0480 - Accuracy: 0.9834 - Precision: 0.9578 - Recall: 0.9506 - TP: 3205.3000 - TN: 5523.9502 - FP: 123.0500 - FN: 166.7000 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9630 - val_Recall: 0.9440 - val_TP: 758.9800 - val_TN: 1082.5300 - val_FP: 23.4700 - val_FN: 45.0200\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0480 - Accuracy: 0.9834 - Precision: 0.9581 - Recall: 0.9506 - TP: 3205.3601 - TN: 5525.6201 - FP: 121.3800 - FN: 166.6400 - val_loss: 0.0744 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9440 - val_TP: 758.9600 - val_TN: 1081.5601 - val_FP: 24.4400 - val_FN: 45.0400\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0480 - Accuracy: 0.9836 - Precision: 0.9579 - Recall: 0.9505 - TP: 3205.1201 - TN: 5524.5200 - FP: 122.4800 - FN: 166.8800 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9442 - val_TP: 759.1300 - val_TN: 1081.6300 - val_FP: 24.3700 - val_FN: 44.8700\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0479 - Accuracy: 0.9837 - Precision: 0.9581 - Recall: 0.9507 - TP: 3205.8301 - TN: 5525.4800 - FP: 121.5200 - FN: 166.1700 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9631 - val_Recall: 0.9439 - val_TP: 758.9300 - val_TN: 1082.6200 - val_FP: 23.3800 - val_FN: 45.0700\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0480 - Accuracy: 0.9835 - Precision: 0.9582 - Recall: 0.9506 - TP: 3205.4399 - TN: 5526.1299 - FP: 120.8700 - FN: 166.5600 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9631 - val_Recall: 0.9440 - val_TP: 758.9500 - val_TN: 1082.6300 - val_FP: 23.3700 - val_FN: 45.0500\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0480 - Accuracy: 0.9834 - Precision: 0.9583 - Recall: 0.9504 - TP: 3204.6001 - TN: 5526.3599 - FP: 120.6400 - FN: 167.4000 - val_loss: 0.0745 - val_Accuracy: 0.9775 - val_Precision: 0.9619 - val_Recall: 0.9442 - val_TP: 759.1400 - val_TN: 1081.2700 - val_FP: 24.7300 - val_FN: 44.8600\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0479 - Accuracy: 0.9836 - Precision: 0.9584 - Recall: 0.9505 - TP: 3205.0100 - TN: 5526.8101 - FP: 120.1900 - FN: 166.9900 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9625 - val_Recall: 0.9441 - val_TP: 759.0400 - val_TN: 1081.9500 - val_FP: 24.0500 - val_FN: 44.9600\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0479 - Accuracy: 0.9834 - Precision: 0.9579 - Recall: 0.9507 - TP: 3205.8999 - TN: 5524.5000 - FP: 122.5000 - FN: 166.1000 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9617 - val_Recall: 0.9442 - val_TP: 759.1700 - val_TN: 1081.1400 - val_FP: 24.8600 - val_FN: 44.8300\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0484 - Accuracy: 0.9834 - Precision: 0.9581 - Recall: 0.9502 - TP: 3204.2000 - TN: 5525.4199 - FP: 121.5800 - FN: 167.8000 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9619 - val_Recall: 0.9441 - val_TP: 759.0800 - val_TN: 1081.3101 - val_FP: 24.6900 - val_FN: 44.9200\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0483 - Accuracy: 0.9834 - Precision: 0.9579 - Recall: 0.9505 - TP: 3205.2500 - TN: 5524.5400 - FP: 122.4600 - FN: 166.7500 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9630 - val_Recall: 0.9440 - val_TP: 758.9900 - val_TN: 1082.5100 - val_FP: 23.4900 - val_FN: 45.0100\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0483 - Accuracy: 0.9834 - Precision: 0.9577 - Recall: 0.9503 - TP: 3204.3101 - TN: 5523.6899 - FP: 123.3100 - FN: 167.6900 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9631 - val_Recall: 0.9439 - val_TP: 758.9000 - val_TN: 1082.5800 - val_FP: 23.4200 - val_FN: 45.1000\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0482 - Accuracy: 0.9833 - Precision: 0.9585 - Recall: 0.9502 - TP: 3204.1201 - TN: 5527.4302 - FP: 119.5700 - FN: 167.8800 - val_loss: 0.0751 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9442 - val_TP: 759.1500 - val_TN: 1079.5200 - val_FP: 26.4800 - val_FN: 44.8500\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0482 - Accuracy: 0.9837 - Precision: 0.9576 - Recall: 0.9507 - TP: 3205.6399 - TN: 5522.8198 - FP: 124.1800 - FN: 166.3600 - val_loss: 0.0734 - val_Accuracy: 0.9775 - val_Precision: 0.9634 - val_Recall: 0.9440 - val_TP: 759.0000 - val_TN: 1082.9100 - val_FP: 23.0900 - val_FN: 45.0000\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0483 - Accuracy: 0.9833 - Precision: 0.9581 - Recall: 0.9503 - TP: 3204.3999 - TN: 5525.4302 - FP: 121.5700 - FN: 167.6000 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9625 - val_Recall: 0.9440 - val_TP: 758.9800 - val_TN: 1081.8900 - val_FP: 24.1100 - val_FN: 45.0200\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0481 - Accuracy: 0.9836 - Precision: 0.9582 - Recall: 0.9505 - TP: 3204.9600 - TN: 5526.1201 - FP: 120.8800 - FN: 167.0400 - val_loss: 0.0753 - val_Accuracy: 0.9775 - val_Precision: 0.9603 - val_Recall: 0.9441 - val_TP: 759.0200 - val_TN: 1079.5400 - val_FP: 26.4600 - val_FN: 44.9800\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0482 - Accuracy: 0.9834 - Precision: 0.9579 - Recall: 0.9505 - TP: 3205.1101 - TN: 5524.3799 - FP: 122.6200 - FN: 166.8900 - val_loss: 0.0744 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9439 - val_TP: 758.9100 - val_TN: 1081.5699 - val_FP: 24.4300 - val_FN: 45.0900\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0481 - Accuracy: 0.9831 - Precision: 0.9580 - Recall: 0.9503 - TP: 3204.5000 - TN: 5524.9302 - FP: 122.0700 - FN: 167.5000 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9631 - val_Recall: 0.9440 - val_TP: 758.9600 - val_TN: 1082.6000 - val_FP: 23.4000 - val_FN: 45.0400\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0481 - Accuracy: 0.9834 - Precision: 0.9579 - Recall: 0.9503 - TP: 3204.5100 - TN: 5524.4302 - FP: 122.5700 - FN: 167.4900 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9630 - val_Recall: 0.9440 - val_TP: 758.9500 - val_TN: 1082.5200 - val_FP: 23.4800 - val_FN: 45.0500\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0481 - Accuracy: 0.9833 - Precision: 0.9582 - Recall: 0.9504 - TP: 3204.7800 - TN: 5526.0801 - FP: 120.9200 - FN: 167.2200 - val_loss: 0.0746 - val_Accuracy: 0.9775 - val_Precision: 0.9614 - val_Recall: 0.9440 - val_TP: 759.0000 - val_TN: 1080.7300 - val_FP: 25.2700 - val_FN: 45.0000\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0481 - Accuracy: 0.9834 - Precision: 0.9579 - Recall: 0.9504 - TP: 3204.8401 - TN: 5524.5698 - FP: 122.4300 - FN: 167.1600 - val_loss: 0.0745 - val_Accuracy: 0.9775 - val_Precision: 0.9618 - val_Recall: 0.9443 - val_TP: 759.2100 - val_TN: 1081.1600 - val_FP: 24.8400 - val_FN: 44.7900\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0480 - Accuracy: 0.9835 - Precision: 0.9580 - Recall: 0.9505 - TP: 3204.9900 - TN: 5524.6602 - FP: 122.3400 - FN: 167.0100 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9442 - val_TP: 759.1400 - val_TN: 1081.6300 - val_FP: 24.3700 - val_FN: 44.8600\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0480 - Accuracy: 0.9833 - Precision: 0.9582 - Recall: 0.9504 - TP: 3204.7600 - TN: 5526.1802 - FP: 120.8200 - FN: 167.2400 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9626 - val_Recall: 0.9439 - val_TP: 758.9200 - val_TN: 1081.9800 - val_FP: 24.0200 - val_FN: 45.0800\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0480 - Accuracy: 0.9833 - Precision: 0.9582 - Recall: 0.9504 - TP: 3204.8899 - TN: 5526.0898 - FP: 120.9100 - FN: 167.1100 - val_loss: 0.0749 - val_Accuracy: 0.9775 - val_Precision: 0.9611 - val_Recall: 0.9442 - val_TP: 759.1300 - val_TN: 1080.4399 - val_FP: 25.5600 - val_FN: 44.8700\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0480 - Accuracy: 0.9834 - Precision: 0.9580 - Recall: 0.9506 - TP: 3205.3899 - TN: 5524.8901 - FP: 122.1100 - FN: 166.6100 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9624 - val_Recall: 0.9440 - val_TP: 758.9700 - val_TN: 1081.7900 - val_FP: 24.2100 - val_FN: 45.0300\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0480 - Accuracy: 0.9833 - Precision: 0.9581 - Recall: 0.9506 - TP: 3205.2900 - TN: 5525.5400 - FP: 121.4600 - FN: 166.7100 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9632 - val_Recall: 0.9439 - val_TP: 758.9300 - val_TN: 1082.7400 - val_FP: 23.2600 - val_FN: 45.0700\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0479 - Accuracy: 0.9837 - Precision: 0.9583 - Recall: 0.9506 - TP: 3205.4500 - TN: 5526.4800 - FP: 120.5200 - FN: 166.5500 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9629 - val_Recall: 0.9442 - val_TP: 759.1100 - val_TN: 1082.4600 - val_FP: 23.5400 - val_FN: 44.8900\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0479 - Accuracy: 0.9834 - Precision: 0.9581 - Recall: 0.9506 - TP: 3205.4399 - TN: 5525.5000 - FP: 121.5000 - FN: 166.5600 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9617 - val_Recall: 0.9443 - val_TP: 759.2100 - val_TN: 1081.1100 - val_FP: 24.8900 - val_FN: 44.7900\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0479 - Accuracy: 0.9835 - Precision: 0.9580 - Recall: 0.9507 - TP: 3205.7800 - TN: 5525.0200 - FP: 121.9800 - FN: 166.2200 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9441 - val_TP: 759.0800 - val_TN: 1081.7100 - val_FP: 24.2900 - val_FN: 44.9200\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0480 - Accuracy: 0.9833 - Precision: 0.9585 - Recall: 0.9502 - TP: 3204.2100 - TN: 5526.8901 - FP: 120.1100 - FN: 167.7900 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9624 - val_Recall: 0.9440 - val_TP: 758.9800 - val_TN: 1081.8000 - val_FP: 24.2000 - val_FN: 45.0200\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0476 - Accuracy: 0.9836 - Precision: 0.9582 - Recall: 0.9508 - TP: 3206.2100 - TN: 5526.2002 - FP: 120.8000 - FN: 165.7900 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9628 - val_Recall: 0.9442 - val_TP: 759.1400 - val_TN: 1082.3300 - val_FP: 23.6700 - val_FN: 44.8600\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0478 - Accuracy: 0.9833 - Precision: 0.9581 - Recall: 0.9508 - TP: 3205.9700 - TN: 5525.6299 - FP: 121.3700 - FN: 166.0300 - val_loss: 0.0739 - val_Accuracy: 0.9770 - val_Precision: 0.9627 - val_Recall: 0.9443 - val_TP: 759.2300 - val_TN: 1082.2900 - val_FP: 23.7100 - val_FN: 44.7700\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0477 - Accuracy: 0.9836 - Precision: 0.9582 - Recall: 0.9508 - TP: 3205.9600 - TN: 5525.6499 - FP: 121.3500 - FN: 166.0400 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9631 - val_Recall: 0.9440 - val_TP: 758.9900 - val_TN: 1082.6400 - val_FP: 23.3600 - val_FN: 45.0100\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0477 - Accuracy: 0.9835 - Precision: 0.9585 - Recall: 0.9507 - TP: 3205.6299 - TN: 5527.5801 - FP: 119.4200 - FN: 166.3700 - val_loss: 0.0747 - val_Accuracy: 0.9770 - val_Precision: 0.9614 - val_Recall: 0.9443 - val_TP: 759.1800 - val_TN: 1080.7200 - val_FP: 25.2800 - val_FN: 44.8200\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0485 - Accuracy: 0.9833 - Precision: 0.9582 - Recall: 0.9505 - TP: 3205.2100 - TN: 5526.8799 - FP: 120.1200 - FN: 166.7900 - val_loss: 0.0743 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9445 - val_TP: 759.3400 - val_TN: 1081.0200 - val_FP: 24.9800 - val_FN: 44.6600\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0481 - Accuracy: 0.9835 - Precision: 0.9576 - Recall: 0.9506 - TP: 3205.5901 - TN: 5523.3301 - FP: 123.6700 - FN: 166.4100 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9629 - val_Recall: 0.9441 - val_TP: 759.0300 - val_TN: 1082.3900 - val_FP: 23.6100 - val_FN: 44.9700\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0483 - Accuracy: 0.9834 - Precision: 0.9580 - Recall: 0.9505 - TP: 3205.1799 - TN: 5525.0400 - FP: 121.9600 - FN: 166.8200 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9624 - val_Recall: 0.9442 - val_TP: 759.1200 - val_TN: 1081.7600 - val_FP: 24.2400 - val_FN: 44.8800\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0481 - Accuracy: 0.9833 - Precision: 0.9582 - Recall: 0.9504 - TP: 3204.6799 - TN: 5525.9702 - FP: 121.0300 - FN: 167.3200 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9442 - val_TP: 759.1600 - val_TN: 1081.6300 - val_FP: 24.3700 - val_FN: 44.8400\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0483 - Accuracy: 0.9833 - Precision: 0.9578 - Recall: 0.9504 - TP: 3204.6499 - TN: 5524.3599 - FP: 122.6400 - FN: 167.3500 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9619 - val_Recall: 0.9442 - val_TP: 759.1500 - val_TN: 1081.3199 - val_FP: 24.6800 - val_FN: 44.8500\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0481 - Accuracy: 0.9834 - Precision: 0.9580 - Recall: 0.9506 - TP: 3205.3899 - TN: 5525.1401 - FP: 121.8600 - FN: 166.6100 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9620 - val_Recall: 0.9442 - val_TP: 759.1100 - val_TN: 1081.4200 - val_FP: 24.5800 - val_FN: 44.8900\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0481 - Accuracy: 0.9835 - Precision: 0.9579 - Recall: 0.9505 - TP: 3205.2200 - TN: 5524.2998 - FP: 122.7000 - FN: 166.7800 - val_loss: 0.0736 - val_Accuracy: 0.9775 - val_Precision: 0.9632 - val_Recall: 0.9441 - val_TP: 759.0600 - val_TN: 1082.7100 - val_FP: 23.2900 - val_FN: 44.9400\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0480 - Accuracy: 0.9834 - Precision: 0.9583 - Recall: 0.9504 - TP: 3204.8999 - TN: 5526.6602 - FP: 120.3400 - FN: 167.1000 - val_loss: 0.0744 - val_Accuracy: 0.9775 - val_Precision: 0.9619 - val_Recall: 0.9443 - val_TP: 759.1900 - val_TN: 1081.2600 - val_FP: 24.7400 - val_FN: 44.8100\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0481 - Accuracy: 0.9834 - Precision: 0.9579 - Recall: 0.9507 - TP: 3205.7300 - TN: 5524.6899 - FP: 122.3100 - FN: 166.2700 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9442 - val_TP: 759.1300 - val_TN: 1081.5800 - val_FP: 24.4200 - val_FN: 44.8700\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0480 - Accuracy: 0.9835 - Precision: 0.9582 - Recall: 0.9506 - TP: 3205.4399 - TN: 5525.7900 - FP: 121.2100 - FN: 166.5600 - val_loss: 0.0743 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9441 - val_TP: 759.0300 - val_TN: 1081.6700 - val_FP: 24.3300 - val_FN: 44.9700\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0479 - Accuracy: 0.9831 - Precision: 0.9584 - Recall: 0.9503 - TP: 3204.5400 - TN: 5526.9102 - FP: 120.0900 - FN: 167.4600 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9442 - val_TP: 759.1000 - val_TN: 1081.6600 - val_FP: 24.3400 - val_FN: 44.9000\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0480 - Accuracy: 0.9834 - Precision: 0.9579 - Recall: 0.9507 - TP: 3205.7300 - TN: 5524.8799 - FP: 122.1200 - FN: 166.2700 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9443 - val_TP: 759.2400 - val_TN: 1081.4700 - val_FP: 24.5300 - val_FN: 44.7600\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0480 - Accuracy: 0.9835 - Precision: 0.9580 - Recall: 0.9507 - TP: 3205.8701 - TN: 5525.1299 - FP: 121.8700 - FN: 166.1300 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9625 - val_Recall: 0.9441 - val_TP: 759.0200 - val_TN: 1081.9100 - val_FP: 24.0900 - val_FN: 44.9800\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0479 - Accuracy: 0.9835 - Precision: 0.9581 - Recall: 0.9507 - TP: 3205.6201 - TN: 5525.6499 - FP: 121.3500 - FN: 166.3800 - val_loss: 0.0745 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9440 - val_TP: 759.0100 - val_TN: 1081.5300 - val_FP: 24.4700 - val_FN: 44.9900\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0479 - Accuracy: 0.9835 - Precision: 0.9585 - Recall: 0.9505 - TP: 3204.9900 - TN: 5526.9502 - FP: 120.0500 - FN: 167.0100 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9619 - val_Recall: 0.9442 - val_TP: 759.1700 - val_TN: 1081.3199 - val_FP: 24.6800 - val_FN: 44.8300\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0479 - Accuracy: 0.9835 - Precision: 0.9581 - Recall: 0.9506 - TP: 3205.5901 - TN: 5525.2598 - FP: 121.7400 - FN: 166.4100 - val_loss: 0.0745 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9442 - val_TP: 759.1100 - val_TN: 1081.4800 - val_FP: 24.5200 - val_FN: 44.8900\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0479 - Accuracy: 0.9834 - Precision: 0.9583 - Recall: 0.9506 - TP: 3205.5801 - TN: 5526.2100 - FP: 120.7900 - FN: 166.4200 - val_loss: 0.0744 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9441 - val_TP: 759.0800 - val_TN: 1081.6400 - val_FP: 24.3600 - val_FN: 44.9200\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0479 - Accuracy: 0.9835 - Precision: 0.9578 - Recall: 0.9510 - TP: 3206.6499 - TN: 5524.3999 - FP: 122.6000 - FN: 165.3500 - val_loss: 0.0737 - val_Accuracy: 0.9775 - val_Precision: 0.9632 - val_Recall: 0.9441 - val_TP: 759.0900 - val_TN: 1082.7800 - val_FP: 23.2200 - val_FN: 44.9100\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0478 - Accuracy: 0.9835 - Precision: 0.9583 - Recall: 0.9507 - TP: 3205.8601 - TN: 5526.5000 - FP: 120.5000 - FN: 166.1400 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9624 - val_Recall: 0.9441 - val_TP: 759.0500 - val_TN: 1081.8101 - val_FP: 24.1900 - val_FN: 44.9500\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0478 - Accuracy: 0.9836 - Precision: 0.9582 - Recall: 0.9508 - TP: 3206.2100 - TN: 5525.9902 - FP: 121.0100 - FN: 165.7900 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9631 - val_Recall: 0.9440 - val_TP: 759.0000 - val_TN: 1082.6300 - val_FP: 23.3700 - val_FN: 45.0000\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0477 - Accuracy: 0.9837 - Precision: 0.9583 - Recall: 0.9508 - TP: 3206.1699 - TN: 5526.2998 - FP: 120.7000 - FN: 165.8300 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9631 - val_Recall: 0.9440 - val_TP: 758.9900 - val_TN: 1082.7000 - val_FP: 23.3000 - val_FN: 45.0100\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0477 - Accuracy: 0.9834 - Precision: 0.9587 - Recall: 0.9505 - TP: 3205.1001 - TN: 5528.2998 - FP: 118.7000 - FN: 166.9000 - val_loss: 0.0749 - val_Accuracy: 0.9770 - val_Precision: 0.9612 - val_Recall: 0.9443 - val_TP: 759.2300 - val_TN: 1080.5400 - val_FP: 25.4600 - val_FN: 44.7700\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0477 - Accuracy: 0.9837 - Precision: 0.9580 - Recall: 0.9509 - TP: 3206.4600 - TN: 5524.7998 - FP: 122.2000 - FN: 165.5400 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9623 - val_Recall: 0.9442 - val_TP: 759.1700 - val_TN: 1081.6899 - val_FP: 24.3100 - val_FN: 44.8300\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0476 - Accuracy: 0.9834 - Precision: 0.9584 - Recall: 0.9509 - TP: 3206.3501 - TN: 5526.7202 - FP: 120.2800 - FN: 165.6500 - val_loss: 0.0745 - val_Accuracy: 0.9770 - val_Precision: 0.9620 - val_Recall: 0.9443 - val_TP: 759.2100 - val_TN: 1081.4700 - val_FP: 24.5300 - val_FN: 44.7900\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0476 - Accuracy: 0.9836 - Precision: 0.9585 - Recall: 0.9507 - TP: 3205.7300 - TN: 5526.9702 - FP: 120.0300 - FN: 166.2700 - val_loss: 0.0747 - val_Accuracy: 0.9770 - val_Precision: 0.9614 - val_Recall: 0.9443 - val_TP: 759.2200 - val_TN: 1080.7500 - val_FP: 25.2500 - val_FN: 44.7800\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0476 - Accuracy: 0.9836 - Precision: 0.9581 - Recall: 0.9510 - TP: 3206.8601 - TN: 5525.0498 - FP: 121.9500 - FN: 165.1400 - val_loss: 0.0739 - val_Accuracy: 0.9770 - val_Precision: 0.9631 - val_Recall: 0.9442 - val_TP: 759.1300 - val_TN: 1082.7000 - val_FP: 23.3000 - val_FN: 44.8700\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0476 - Accuracy: 0.9835 - Precision: 0.9583 - Recall: 0.9508 - TP: 3206.1299 - TN: 5526.4702 - FP: 120.5300 - FN: 165.8700 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9624 - val_Recall: 0.9442 - val_TP: 759.1500 - val_TN: 1081.7700 - val_FP: 24.2300 - val_FN: 44.8500\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0486 - Accuracy: 0.9831 - Precision: 0.9582 - Recall: 0.9506 - TP: 3205.5300 - TN: 5526.2202 - FP: 120.7800 - FN: 166.4700 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9626 - val_Recall: 0.9443 - val_TP: 759.2400 - val_TN: 1082.1200 - val_FP: 23.8800 - val_FN: 44.7600\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0481 - Accuracy: 0.9833 - Precision: 0.9581 - Recall: 0.9506 - TP: 3205.4900 - TN: 5525.6802 - FP: 121.3200 - FN: 166.5100 - val_loss: 0.0750 - val_Accuracy: 0.9775 - val_Precision: 0.9609 - val_Recall: 0.9444 - val_TP: 759.2600 - val_TN: 1080.1700 - val_FP: 25.8300 - val_FN: 44.7400\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0480 - Accuracy: 0.9835 - Precision: 0.9582 - Recall: 0.9505 - TP: 3205.1499 - TN: 5525.8198 - FP: 121.1800 - FN: 166.8500 - val_loss: 0.0749 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9442 - val_TP: 759.1300 - val_TN: 1080.4800 - val_FP: 25.5200 - val_FN: 44.8700\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0480 - Accuracy: 0.9834 - Precision: 0.9581 - Recall: 0.9506 - TP: 3205.3501 - TN: 5525.1001 - FP: 121.9000 - FN: 166.6500 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9631 - val_Recall: 0.9441 - val_TP: 759.0400 - val_TN: 1082.6600 - val_FP: 23.3400 - val_FN: 44.9600\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0479 - Accuracy: 0.9834 - Precision: 0.9578 - Recall: 0.9506 - TP: 3205.5701 - TN: 5524.1201 - FP: 122.8800 - FN: 166.4300 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9629 - val_Recall: 0.9441 - val_TP: 759.0600 - val_TN: 1082.4200 - val_FP: 23.5800 - val_FN: 44.9400\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0479 - Accuracy: 0.9835 - Precision: 0.9584 - Recall: 0.9506 - TP: 3205.3301 - TN: 5526.9702 - FP: 120.0300 - FN: 166.6700 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9625 - val_Recall: 0.9442 - val_TP: 759.1500 - val_TN: 1081.8600 - val_FP: 24.1400 - val_FN: 44.8500\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0480 - Accuracy: 0.9833 - Precision: 0.9580 - Recall: 0.9506 - TP: 3205.3899 - TN: 5525.2998 - FP: 121.7000 - FN: 166.6100 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9619 - val_Recall: 0.9443 - val_TP: 759.2300 - val_TN: 1081.3101 - val_FP: 24.6900 - val_FN: 44.7700\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0479 - Accuracy: 0.9835 - Precision: 0.9581 - Recall: 0.9507 - TP: 3205.8999 - TN: 5525.4502 - FP: 121.5500 - FN: 166.1000 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9630 - val_Recall: 0.9442 - val_TP: 759.1000 - val_TN: 1082.6000 - val_FP: 23.4000 - val_FN: 44.9000\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0479 - Accuracy: 0.9833 - Precision: 0.9582 - Recall: 0.9506 - TP: 3205.2800 - TN: 5525.8301 - FP: 121.1700 - FN: 166.7200 - val_loss: 0.0744 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9441 - val_TP: 759.0700 - val_TN: 1081.5400 - val_FP: 24.4600 - val_FN: 44.9300\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0478 - Accuracy: 0.9833 - Precision: 0.9581 - Recall: 0.9508 - TP: 3206.1699 - TN: 5525.4902 - FP: 121.5100 - FN: 165.8300 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9624 - val_Recall: 0.9441 - val_TP: 759.0800 - val_TN: 1081.7600 - val_FP: 24.2400 - val_FN: 44.9200\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0479 - Accuracy: 0.9836 - Precision: 0.9581 - Recall: 0.9507 - TP: 3205.6299 - TN: 5525.1899 - FP: 121.8100 - FN: 166.3700 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9630 - val_Recall: 0.9441 - val_TP: 759.0600 - val_TN: 1082.5800 - val_FP: 23.4200 - val_FN: 44.9400\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0478 - Accuracy: 0.9834 - Precision: 0.9583 - Recall: 0.9506 - TP: 3205.3899 - TN: 5525.9702 - FP: 121.0300 - FN: 166.6100 - val_loss: 0.0744 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9441 - val_TP: 759.0800 - val_TN: 1081.5601 - val_FP: 24.4400 - val_FN: 44.9200\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0478 - Accuracy: 0.9834 - Precision: 0.9584 - Recall: 0.9506 - TP: 3205.3701 - TN: 5526.6899 - FP: 120.3100 - FN: 166.6300 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9623 - val_Recall: 0.9441 - val_TP: 759.0600 - val_TN: 1081.7100 - val_FP: 24.2900 - val_FN: 44.9400\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0477 - Accuracy: 0.9837 - Precision: 0.9585 - Recall: 0.9508 - TP: 3206.0100 - TN: 5527.2900 - FP: 119.7100 - FN: 165.9900 - val_loss: 0.0745 - val_Accuracy: 0.9770 - val_Precision: 0.9619 - val_Recall: 0.9444 - val_TP: 759.3100 - val_TN: 1081.2800 - val_FP: 24.7200 - val_FN: 44.6900\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0477 - Accuracy: 0.9838 - Precision: 0.9581 - Recall: 0.9509 - TP: 3206.5100 - TN: 5525.2900 - FP: 121.7100 - FN: 165.4900 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9624 - val_Recall: 0.9443 - val_TP: 759.2300 - val_TN: 1081.7800 - val_FP: 24.2200 - val_FN: 44.7700\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0477 - Accuracy: 0.9834 - Precision: 0.9583 - Recall: 0.9506 - TP: 3205.5200 - TN: 5526.6001 - FP: 120.4000 - FN: 166.4800 - val_loss: 0.0739 - val_Accuracy: 0.9770 - val_Precision: 0.9628 - val_Recall: 0.9443 - val_TP: 759.2300 - val_TN: 1082.4100 - val_FP: 23.5900 - val_FN: 44.7700\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0477 - Accuracy: 0.9835 - Precision: 0.9584 - Recall: 0.9508 - TP: 3205.9700 - TN: 5526.7402 - FP: 120.2600 - FN: 166.0300 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9622 - val_Recall: 0.9444 - val_TP: 759.2900 - val_TN: 1081.6100 - val_FP: 24.3900 - val_FN: 44.7100\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0476 - Accuracy: 0.9836 - Precision: 0.9582 - Recall: 0.9510 - TP: 3206.9199 - TN: 5525.9800 - FP: 121.0200 - FN: 165.0800 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9624 - val_Recall: 0.9442 - val_TP: 759.1500 - val_TN: 1081.8300 - val_FP: 24.1700 - val_FN: 44.8500\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0476 - Accuracy: 0.9833 - Precision: 0.9583 - Recall: 0.9509 - TP: 3206.5000 - TN: 5526.3301 - FP: 120.6700 - FN: 165.5000 - val_loss: 0.0738 - val_Accuracy: 0.9770 - val_Precision: 0.9630 - val_Recall: 0.9444 - val_TP: 759.2700 - val_TN: 1082.5800 - val_FP: 23.4200 - val_FN: 44.7300\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0476 - Accuracy: 0.9836 - Precision: 0.9585 - Recall: 0.9508 - TP: 3206.2500 - TN: 5527.3301 - FP: 119.6700 - FN: 165.7500 - val_loss: 0.0747 - val_Accuracy: 0.9770 - val_Precision: 0.9616 - val_Recall: 0.9442 - val_TP: 759.1500 - val_TN: 1080.9200 - val_FP: 25.0800 - val_FN: 44.8500\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0476 - Accuracy: 0.9837 - Precision: 0.9583 - Recall: 0.9509 - TP: 3206.5701 - TN: 5526.3101 - FP: 120.6900 - FN: 165.4300 - val_loss: 0.0748 - val_Accuracy: 0.9770 - val_Precision: 0.9613 - val_Recall: 0.9444 - val_TP: 759.3300 - val_TN: 1080.6200 - val_FP: 25.3800 - val_FN: 44.6700\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0475 - Accuracy: 0.9837 - Precision: 0.9584 - Recall: 0.9509 - TP: 3206.5901 - TN: 5526.5801 - FP: 120.4200 - FN: 165.4100 - val_loss: 0.0754 - val_Accuracy: 0.9770 - val_Precision: 0.9611 - val_Recall: 0.9441 - val_TP: 759.0900 - val_TN: 1080.4800 - val_FP: 25.5200 - val_FN: 44.9100\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0476 - Accuracy: 0.9838 - Precision: 0.9582 - Recall: 0.9510 - TP: 3206.8401 - TN: 5525.8701 - FP: 121.1300 - FN: 165.1600 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9625 - val_Recall: 0.9444 - val_TP: 759.2600 - val_TN: 1081.9100 - val_FP: 24.0900 - val_FN: 44.7400\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0475 - Accuracy: 0.9836 - Precision: 0.9585 - Recall: 0.9509 - TP: 3206.4199 - TN: 5527.2100 - FP: 119.7900 - FN: 165.5800 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9624 - val_Recall: 0.9442 - val_TP: 759.1600 - val_TN: 1081.7900 - val_FP: 24.2100 - val_FN: 44.8400\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0483 - Accuracy: 0.9833 - Precision: 0.9584 - Recall: 0.9506 - TP: 3205.2900 - TN: 5527.2998 - FP: 119.7000 - FN: 166.7100 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9621 - val_Recall: 0.9442 - val_TP: 759.1600 - val_TN: 1081.5000 - val_FP: 24.5000 - val_FN: 44.8400\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0479 - Accuracy: 0.9837 - Precision: 0.9582 - Recall: 0.9508 - TP: 3206.0500 - TN: 5525.8599 - FP: 121.1400 - FN: 165.9500 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9630 - val_Recall: 0.9441 - val_TP: 759.0700 - val_TN: 1082.5800 - val_FP: 23.4200 - val_FN: 44.9300\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0479 - Accuracy: 0.9834 - Precision: 0.9582 - Recall: 0.9506 - TP: 3205.5500 - TN: 5525.8599 - FP: 121.1400 - FN: 166.4500 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9624 - val_Recall: 0.9442 - val_TP: 759.1700 - val_TN: 1081.7900 - val_FP: 24.2100 - val_FN: 44.8300\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0478 - Accuracy: 0.9837 - Precision: 0.9584 - Recall: 0.9507 - TP: 3205.8201 - TN: 5526.8398 - FP: 120.1600 - FN: 166.1800 - val_loss: 0.0739 - val_Accuracy: 0.9775 - val_Precision: 0.9630 - val_Recall: 0.9441 - val_TP: 759.0800 - val_TN: 1082.5800 - val_FP: 23.4200 - val_FN: 44.9200\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0478 - Accuracy: 0.9833 - Precision: 0.9584 - Recall: 0.9506 - TP: 3205.4600 - TN: 5526.7700 - FP: 120.2300 - FN: 166.5400 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9621 - val_Recall: 0.9442 - val_TP: 759.1500 - val_TN: 1081.5300 - val_FP: 24.4700 - val_FN: 44.8500\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0479 - Accuracy: 0.9835 - Precision: 0.9583 - Recall: 0.9507 - TP: 3205.6201 - TN: 5526.1401 - FP: 120.8600 - FN: 166.3800 - val_loss: 0.0742 - val_Accuracy: 0.9775 - val_Precision: 0.9625 - val_Recall: 0.9441 - val_TP: 759.0700 - val_TN: 1081.8600 - val_FP: 24.1400 - val_FN: 44.9300\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0478 - Accuracy: 0.9834 - Precision: 0.9580 - Recall: 0.9509 - TP: 3206.5801 - TN: 5524.9702 - FP: 122.0300 - FN: 165.4200 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9632 - val_Recall: 0.9441 - val_TP: 759.0500 - val_TN: 1082.8000 - val_FP: 23.2000 - val_FN: 44.9500\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0478 - Accuracy: 0.9835 - Precision: 0.9585 - Recall: 0.9505 - TP: 3205.0801 - TN: 5527.6001 - FP: 119.4000 - FN: 166.9200 - val_loss: 0.0745 - val_Accuracy: 0.9770 - val_Precision: 0.9619 - val_Recall: 0.9443 - val_TP: 759.1900 - val_TN: 1081.3600 - val_FP: 24.6400 - val_FN: 44.8100\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0479 - Accuracy: 0.9833 - Precision: 0.9580 - Recall: 0.9507 - TP: 3205.9099 - TN: 5524.6699 - FP: 122.3300 - FN: 166.0900 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9627 - val_Recall: 0.9441 - val_TP: 759.0500 - val_TN: 1082.1200 - val_FP: 23.8800 - val_FN: 44.9500\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0478 - Accuracy: 0.9831 - Precision: 0.9582 - Recall: 0.9508 - TP: 3205.9399 - TN: 5526.4902 - FP: 120.5100 - FN: 166.0600 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9619 - val_Recall: 0.9443 - val_TP: 759.2400 - val_TN: 1081.2900 - val_FP: 24.7100 - val_FN: 44.7600\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0477 - Accuracy: 0.9838 - Precision: 0.9580 - Recall: 0.9509 - TP: 3206.5701 - TN: 5524.8901 - FP: 122.1100 - FN: 165.4300 - val_loss: 0.0737 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9442 - val_TP: 759.1100 - val_TN: 1082.8000 - val_FP: 23.2000 - val_FN: 44.8900\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0480 - Accuracy: 0.9834 - Precision: 0.9583 - Recall: 0.9506 - TP: 3205.3501 - TN: 5526.5098 - FP: 120.4900 - FN: 166.6500 - val_loss: 0.0739 - val_Accuracy: 0.9770 - val_Precision: 0.9628 - val_Recall: 0.9444 - val_TP: 759.2700 - val_TN: 1082.4200 - val_FP: 23.5800 - val_FN: 44.7300\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0476 - Accuracy: 0.9834 - Precision: 0.9584 - Recall: 0.9507 - TP: 3205.9099 - TN: 5526.6899 - FP: 120.3100 - FN: 166.0900 - val_loss: 0.0751 - val_Accuracy: 0.9770 - val_Precision: 0.9610 - val_Recall: 0.9444 - val_TP: 759.2600 - val_TN: 1080.3700 - val_FP: 25.6300 - val_FN: 44.7400\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0477 - Accuracy: 0.9837 - Precision: 0.9583 - Recall: 0.9508 - TP: 3206.2300 - TN: 5526.2500 - FP: 120.7500 - FN: 165.7700 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9626 - val_Recall: 0.9442 - val_TP: 759.1700 - val_TN: 1082.0400 - val_FP: 23.9600 - val_FN: 44.8300\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0476 - Accuracy: 0.9837 - Precision: 0.9583 - Recall: 0.9509 - TP: 3206.4800 - TN: 5526.4600 - FP: 120.5400 - FN: 165.5200 - val_loss: 0.0739 - val_Accuracy: 0.9770 - val_Precision: 0.9628 - val_Recall: 0.9444 - val_TP: 759.3100 - val_TN: 1082.4000 - val_FP: 23.6000 - val_FN: 44.6900\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0475 - Accuracy: 0.9836 - Precision: 0.9582 - Recall: 0.9512 - TP: 3207.4199 - TN: 5525.9902 - FP: 121.0100 - FN: 164.5800 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9621 - val_Recall: 0.9445 - val_TP: 759.3900 - val_TN: 1081.5400 - val_FP: 24.4600 - val_FN: 44.6100\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0476 - Accuracy: 0.9834 - Precision: 0.9586 - Recall: 0.9509 - TP: 3206.2700 - TN: 5527.4502 - FP: 119.5500 - FN: 165.7300 - val_loss: 0.0745 - val_Accuracy: 0.9770 - val_Precision: 0.9624 - val_Recall: 0.9442 - val_TP: 759.1400 - val_TN: 1081.7900 - val_FP: 24.2100 - val_FN: 44.8600\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0476 - Accuracy: 0.9835 - Precision: 0.9585 - Recall: 0.9507 - TP: 3205.8301 - TN: 5527.1001 - FP: 119.9000 - FN: 166.1700 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9626 - val_Recall: 0.9444 - val_TP: 759.2900 - val_TN: 1081.9900 - val_FP: 24.0100 - val_FN: 44.7100\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0475 - Accuracy: 0.9837 - Precision: 0.9582 - Recall: 0.9511 - TP: 3207.1699 - TN: 5525.6401 - FP: 121.3600 - FN: 164.8300 - val_loss: 0.0739 - val_Accuracy: 0.9770 - val_Precision: 0.9630 - val_Recall: 0.9444 - val_TP: 759.3300 - val_TN: 1082.5800 - val_FP: 23.4200 - val_FN: 44.6700\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0475 - Accuracy: 0.9834 - Precision: 0.9583 - Recall: 0.9510 - TP: 3206.8899 - TN: 5526.7202 - FP: 120.2800 - FN: 165.1100 - val_loss: 0.0745 - val_Accuracy: 0.9770 - val_Precision: 0.9623 - val_Recall: 0.9442 - val_TP: 759.1100 - val_TN: 1081.7100 - val_FP: 24.2900 - val_FN: 44.8900\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0475 - Accuracy: 0.9835 - Precision: 0.9585 - Recall: 0.9509 - TP: 3206.5500 - TN: 5527.0400 - FP: 119.9600 - FN: 165.4500 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9621 - val_Recall: 0.9444 - val_TP: 759.2600 - val_TN: 1081.5500 - val_FP: 24.4500 - val_FN: 44.7400\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0475 - Accuracy: 0.9835 - Precision: 0.9583 - Recall: 0.9510 - TP: 3206.9399 - TN: 5526.3198 - FP: 120.6800 - FN: 165.0600 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9631 - val_Recall: 0.9442 - val_TP: 759.1400 - val_TN: 1082.7200 - val_FP: 23.2800 - val_FN: 44.8600\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0474 - Accuracy: 0.9836 - Precision: 0.9587 - Recall: 0.9509 - TP: 3206.5400 - TN: 5528.1699 - FP: 118.8300 - FN: 165.4600 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9622 - val_Recall: 0.9445 - val_TP: 759.3700 - val_TN: 1081.6200 - val_FP: 24.3800 - val_FN: 44.6300\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0473 - Accuracy: 0.9836 - Precision: 0.9587 - Recall: 0.9510 - TP: 3206.6799 - TN: 5528.0000 - FP: 119.0000 - FN: 165.3200 - val_loss: 0.0748 - val_Accuracy: 0.9770 - val_Precision: 0.9614 - val_Recall: 0.9445 - val_TP: 759.3400 - val_TN: 1080.7900 - val_FP: 25.2100 - val_FN: 44.6600\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0473 - Accuracy: 0.9835 - Precision: 0.9585 - Recall: 0.9511 - TP: 3207.2100 - TN: 5526.8799 - FP: 120.1200 - FN: 164.7900 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9631 - val_Recall: 0.9443 - val_TP: 759.2400 - val_TN: 1082.6700 - val_FP: 23.3300 - val_FN: 44.7600\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0473 - Accuracy: 0.9836 - Precision: 0.9585 - Recall: 0.9512 - TP: 3207.2900 - TN: 5527.3501 - FP: 119.6500 - FN: 164.7100 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9623 - val_Recall: 0.9445 - val_TP: 759.3700 - val_TN: 1081.7400 - val_FP: 24.2600 - val_FN: 44.6300\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0473 - Accuracy: 0.9837 - Precision: 0.9583 - Recall: 0.9513 - TP: 3207.7700 - TN: 5526.3799 - FP: 120.6200 - FN: 164.2300 - val_loss: 0.0739 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9444 - val_TP: 759.2900 - val_TN: 1082.7600 - val_FP: 23.2400 - val_FN: 44.7100\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0472 - Accuracy: 0.9838 - Precision: 0.9587 - Recall: 0.9512 - TP: 3207.3501 - TN: 5527.7798 - FP: 119.2200 - FN: 164.6500 - val_loss: 0.0739 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9444 - val_TP: 759.2700 - val_TN: 1082.8900 - val_FP: 23.1100 - val_FN: 44.7300\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0473 - Accuracy: 0.9837 - Precision: 0.9587 - Recall: 0.9510 - TP: 3206.8201 - TN: 5527.9902 - FP: 119.0100 - FN: 165.1800 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9622 - val_Recall: 0.9445 - val_TP: 759.3800 - val_TN: 1081.6600 - val_FP: 24.3400 - val_FN: 44.6200\n",
      "Epoch 30/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0473 - Accuracy: 0.9836 - Precision: 0.9585 - Recall: 0.9512 - TP: 3207.6101 - TN: 5527.1802 - FP: 119.8200 - FN: 164.3900 - val_loss: 0.0748 - val_Accuracy: 0.9764 - val_Precision: 0.9613 - val_Recall: 0.9446 - val_TP: 759.4400 - val_TN: 1080.6500 - val_FP: 25.3500 - val_FN: 44.5600\n",
      "Epoch 31/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0472 - Accuracy: 0.9835 - Precision: 0.9587 - Recall: 0.9510 - TP: 3206.9099 - TN: 5528.2500 - FP: 118.7500 - FN: 165.0900 - val_loss: 0.0762 - val_Accuracy: 0.9759 - val_Precision: 0.9591 - val_Recall: 0.9447 - val_TP: 759.5200 - val_TN: 1078.4100 - val_FP: 27.5900 - val_FN: 44.4800\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 4ms/step - loss: 0.0478 - Accuracy: 0.9836 - Precision: 0.9585 - Recall: 0.9508 - TP: 3206.1599 - TN: 5527.3701 - FP: 119.6300 - FN: 165.8400 - val_loss: 0.0738 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9442 - val_TP: 759.1400 - val_TN: 1082.7600 - val_FP: 23.2400 - val_FN: 44.8600\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0478 - Accuracy: 0.9834 - Precision: 0.9585 - Recall: 0.9506 - TP: 3205.4500 - TN: 5527.3198 - FP: 119.6800 - FN: 166.5500 - val_loss: 0.0739 - val_Accuracy: 0.9770 - val_Precision: 0.9631 - val_Recall: 0.9443 - val_TP: 759.2100 - val_TN: 1082.6500 - val_FP: 23.3500 - val_FN: 44.7900\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0476 - Accuracy: 0.9835 - Precision: 0.9585 - Recall: 0.9509 - TP: 3206.3301 - TN: 5527.2202 - FP: 119.7800 - FN: 165.6700 - val_loss: 0.0753 - val_Accuracy: 0.9770 - val_Precision: 0.9609 - val_Recall: 0.9444 - val_TP: 759.3100 - val_TN: 1080.2100 - val_FP: 25.7900 - val_FN: 44.6900\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0477 - Accuracy: 0.9837 - Precision: 0.9581 - Recall: 0.9509 - TP: 3206.3899 - TN: 5525.5000 - FP: 121.5000 - FN: 165.6100 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9624 - val_Recall: 0.9442 - val_TP: 759.1300 - val_TN: 1081.8500 - val_FP: 24.1500 - val_FN: 44.8700\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0476 - Accuracy: 0.9835 - Precision: 0.9588 - Recall: 0.9508 - TP: 3206.0601 - TN: 5528.4702 - FP: 118.5300 - FN: 165.9400 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9623 - val_Recall: 0.9442 - val_TP: 759.1700 - val_TN: 1081.7700 - val_FP: 24.2300 - val_FN: 44.8300\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0475 - Accuracy: 0.9834 - Precision: 0.9582 - Recall: 0.9509 - TP: 3206.3301 - TN: 5525.5601 - FP: 121.4400 - FN: 165.6700 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9631 - val_Recall: 0.9443 - val_TP: 759.2500 - val_TN: 1082.6200 - val_FP: 23.3800 - val_FN: 44.7500\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0476 - Accuracy: 0.9837 - Precision: 0.9582 - Recall: 0.9512 - TP: 3207.5601 - TN: 5525.8701 - FP: 121.1300 - FN: 164.4400 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9621 - val_Recall: 0.9444 - val_TP: 759.2600 - val_TN: 1081.5200 - val_FP: 24.4800 - val_FN: 44.7400\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0475 - Accuracy: 0.9835 - Precision: 0.9586 - Recall: 0.9509 - TP: 3206.3101 - TN: 5527.2402 - FP: 119.7600 - FN: 165.6900 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9626 - val_Recall: 0.9443 - val_TP: 759.2300 - val_TN: 1082.0400 - val_FP: 23.9600 - val_FN: 44.7700\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0477 - Accuracy: 0.9835 - Precision: 0.9584 - Recall: 0.9509 - TP: 3206.5400 - TN: 5527.3101 - FP: 119.6900 - FN: 165.4600 - val_loss: 0.0752 - val_Accuracy: 0.9770 - val_Precision: 0.9611 - val_Recall: 0.9444 - val_TP: 759.2900 - val_TN: 1080.4399 - val_FP: 25.5600 - val_FN: 44.7100\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0477 - Accuracy: 0.9835 - Precision: 0.9583 - Recall: 0.9508 - TP: 3206.1299 - TN: 5526.3101 - FP: 120.6900 - FN: 165.8700 - val_loss: 0.0747 - val_Accuracy: 0.9770 - val_Precision: 0.9620 - val_Recall: 0.9444 - val_TP: 759.2600 - val_TN: 1081.4800 - val_FP: 24.5200 - val_FN: 44.7400\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0475 - Accuracy: 0.9835 - Precision: 0.9584 - Recall: 0.9510 - TP: 3206.6299 - TN: 5526.8398 - FP: 120.1600 - FN: 165.3700 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9626 - val_Recall: 0.9442 - val_TP: 759.1500 - val_TN: 1082.0300 - val_FP: 23.9700 - val_FN: 44.8500\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0475 - Accuracy: 0.9838 - Precision: 0.9584 - Recall: 0.9511 - TP: 3207.1599 - TN: 5526.9702 - FP: 120.0300 - FN: 164.8400 - val_loss: 0.0745 - val_Accuracy: 0.9770 - val_Precision: 0.9621 - val_Recall: 0.9444 - val_TP: 759.2700 - val_TN: 1081.5601 - val_FP: 24.4400 - val_FN: 44.7300\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0475 - Accuracy: 0.9836 - Precision: 0.9586 - Recall: 0.9510 - TP: 3206.6499 - TN: 5527.5000 - FP: 119.5000 - FN: 165.3500 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9621 - val_Recall: 0.9446 - val_TP: 759.4400 - val_TN: 1081.5100 - val_FP: 24.4900 - val_FN: 44.5600\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0474 - Accuracy: 0.9835 - Precision: 0.9585 - Recall: 0.9512 - TP: 3207.2900 - TN: 5527.1401 - FP: 119.8600 - FN: 164.7100 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9622 - val_Recall: 0.9444 - val_TP: 759.2800 - val_TN: 1081.6300 - val_FP: 24.3700 - val_FN: 44.7200\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0473 - Accuracy: 0.9838 - Precision: 0.9583 - Recall: 0.9511 - TP: 3207.1699 - TN: 5526.4199 - FP: 120.5800 - FN: 164.8300 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9622 - val_Recall: 0.9445 - val_TP: 759.4100 - val_TN: 1081.6100 - val_FP: 24.3900 - val_FN: 44.5900\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0474 - Accuracy: 0.9835 - Precision: 0.9587 - Recall: 0.9510 - TP: 3206.7800 - TN: 5528.2100 - FP: 118.7900 - FN: 165.2200 - val_loss: 0.0762 - val_Accuracy: 0.9764 - val_Precision: 0.9594 - val_Recall: 0.9445 - val_TP: 759.3900 - val_TN: 1078.7100 - val_FP: 27.2900 - val_FN: 44.6100\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0474 - Accuracy: 0.9836 - Precision: 0.9587 - Recall: 0.9509 - TP: 3206.5801 - TN: 5527.8701 - FP: 119.1300 - FN: 165.4200 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9620 - val_Recall: 0.9445 - val_TP: 759.3600 - val_TN: 1081.4900 - val_FP: 24.5100 - val_FN: 44.6400\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0473 - Accuracy: 0.9836 - Precision: 0.9583 - Recall: 0.9512 - TP: 3207.6101 - TN: 5526.4800 - FP: 120.5200 - FN: 164.3900 - val_loss: 0.0752 - val_Accuracy: 0.9764 - val_Precision: 0.9608 - val_Recall: 0.9446 - val_TP: 759.4800 - val_TN: 1080.1500 - val_FP: 25.8500 - val_FN: 44.5200\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0473 - Accuracy: 0.9837 - Precision: 0.9583 - Recall: 0.9512 - TP: 3207.5100 - TN: 5526.4399 - FP: 120.5600 - FN: 164.4900 - val_loss: 0.0756 - val_Accuracy: 0.9759 - val_Precision: 0.9602 - val_Recall: 0.9446 - val_TP: 759.4300 - val_TN: 1079.5300 - val_FP: 26.4700 - val_FN: 44.5700\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0472 - Accuracy: 0.9838 - Precision: 0.9586 - Recall: 0.9511 - TP: 3207.1899 - TN: 5527.7700 - FP: 119.2300 - FN: 164.8100 - val_loss: 0.0750 - val_Accuracy: 0.9764 - val_Precision: 0.9611 - val_Recall: 0.9446 - val_TP: 759.4600 - val_TN: 1080.4800 - val_FP: 25.5200 - val_FN: 44.5400\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0472 - Accuracy: 0.9836 - Precision: 0.9586 - Recall: 0.9512 - TP: 3207.5300 - TN: 5527.2300 - FP: 119.7700 - FN: 164.4700 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9622 - val_Recall: 0.9445 - val_TP: 759.3600 - val_TN: 1081.6300 - val_FP: 24.3700 - val_FN: 44.6400\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0484 - Accuracy: 0.9834 - Precision: 0.9587 - Recall: 0.9507 - TP: 3205.8401 - TN: 5528.4800 - FP: 118.5200 - FN: 166.1600 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9628 - val_Recall: 0.9443 - val_TP: 759.2300 - val_TN: 1082.3800 - val_FP: 23.6200 - val_FN: 44.7700\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0477 - Accuracy: 0.9834 - Precision: 0.9583 - Recall: 0.9509 - TP: 3206.3401 - TN: 5526.5801 - FP: 120.4200 - FN: 165.6600 - val_loss: 0.0745 - val_Accuracy: 0.9770 - val_Precision: 0.9619 - val_Recall: 0.9444 - val_TP: 759.2800 - val_TN: 1081.3101 - val_FP: 24.6900 - val_FN: 44.7200\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0477 - Accuracy: 0.9834 - Precision: 0.9586 - Recall: 0.9508 - TP: 3206.0100 - TN: 5527.5400 - FP: 119.4600 - FN: 165.9900 - val_loss: 0.0748 - val_Accuracy: 0.9770 - val_Precision: 0.9610 - val_Recall: 0.9446 - val_TP: 759.4500 - val_TN: 1080.3800 - val_FP: 25.6200 - val_FN: 44.5500\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0476 - Accuracy: 0.9837 - Precision: 0.9583 - Recall: 0.9512 - TP: 3207.3101 - TN: 5526.3398 - FP: 120.6600 - FN: 164.6900 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9629 - val_Recall: 0.9444 - val_TP: 759.2800 - val_TN: 1082.4399 - val_FP: 23.5600 - val_FN: 44.7200\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0475 - Accuracy: 0.9837 - Precision: 0.9583 - Recall: 0.9512 - TP: 3207.4099 - TN: 5526.5200 - FP: 120.4800 - FN: 164.5900 - val_loss: 0.0739 - val_Accuracy: 0.9770 - val_Precision: 0.9631 - val_Recall: 0.9443 - val_TP: 759.2400 - val_TN: 1082.7200 - val_FP: 23.2800 - val_FN: 44.7600\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0475 - Accuracy: 0.9835 - Precision: 0.9585 - Recall: 0.9509 - TP: 3206.5601 - TN: 5527.0601 - FP: 119.9400 - FN: 165.4400 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9619 - val_Recall: 0.9444 - val_TP: 759.3300 - val_TN: 1081.3700 - val_FP: 24.6300 - val_FN: 44.6700\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0475 - Accuracy: 0.9835 - Precision: 0.9585 - Recall: 0.9510 - TP: 3206.8701 - TN: 5527.3901 - FP: 119.6100 - FN: 165.1300 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9623 - val_Recall: 0.9444 - val_TP: 759.2700 - val_TN: 1081.7300 - val_FP: 24.2700 - val_FN: 44.7300\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0474 - Accuracy: 0.9838 - Precision: 0.9584 - Recall: 0.9512 - TP: 3207.3701 - TN: 5526.5898 - FP: 120.4100 - FN: 164.6300 - val_loss: 0.0736 - val_Accuracy: 0.9770 - val_Precision: 0.9635 - val_Recall: 0.9444 - val_TP: 759.2700 - val_TN: 1083.0800 - val_FP: 22.9200 - val_FN: 44.7300\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0476 - Accuracy: 0.9834 - Precision: 0.9584 - Recall: 0.9508 - TP: 3205.9600 - TN: 5527.0801 - FP: 119.9200 - FN: 166.0400 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9442 - val_TP: 759.1700 - val_TN: 1082.8300 - val_FP: 23.1700 - val_FN: 44.8300\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0475 - Accuracy: 0.9835 - Precision: 0.9586 - Recall: 0.9509 - TP: 3206.4800 - TN: 5527.9399 - FP: 119.0600 - FN: 165.5200 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9621 - val_Recall: 0.9445 - val_TP: 759.3600 - val_TN: 1081.5800 - val_FP: 24.4200 - val_FN: 44.6400\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0474 - Accuracy: 0.9835 - Precision: 0.9582 - Recall: 0.9510 - TP: 3206.6499 - TN: 5525.7202 - FP: 121.2800 - FN: 165.3500 - val_loss: 0.0738 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9444 - val_TP: 759.3300 - val_TN: 1082.7600 - val_FP: 23.2400 - val_FN: 44.6700\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0474 - Accuracy: 0.9835 - Precision: 0.9584 - Recall: 0.9512 - TP: 3207.3799 - TN: 5527.0200 - FP: 119.9800 - FN: 164.6200 - val_loss: 0.0751 - val_Accuracy: 0.9770 - val_Precision: 0.9609 - val_Recall: 0.9446 - val_TP: 759.4400 - val_TN: 1080.3101 - val_FP: 25.6900 - val_FN: 44.5600\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0474 - Accuracy: 0.9837 - Precision: 0.9585 - Recall: 0.9512 - TP: 3207.3000 - TN: 5527.0200 - FP: 119.9800 - FN: 164.7000 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9624 - val_Recall: 0.9445 - val_TP: 759.4100 - val_TN: 1081.8300 - val_FP: 24.1700 - val_FN: 44.5900\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0474 - Accuracy: 0.9838 - Precision: 0.9586 - Recall: 0.9511 - TP: 3207.1201 - TN: 5527.8101 - FP: 119.1900 - FN: 164.8800 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9626 - val_Recall: 0.9445 - val_TP: 759.3500 - val_TN: 1082.0000 - val_FP: 24.0000 - val_FN: 44.6500\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0472 - Accuracy: 0.9838 - Precision: 0.9584 - Recall: 0.9514 - TP: 3208.2600 - TN: 5526.6099 - FP: 120.3900 - FN: 163.7400 - val_loss: 0.0738 - val_Accuracy: 0.9770 - val_Precision: 0.9635 - val_Recall: 0.9443 - val_TP: 759.2200 - val_TN: 1083.0800 - val_FP: 22.9200 - val_FN: 44.7800\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0472 - Accuracy: 0.9837 - Precision: 0.9586 - Recall: 0.9513 - TP: 3207.6299 - TN: 5527.8398 - FP: 119.1600 - FN: 164.3700 - val_loss: 0.0738 - val_Accuracy: 0.9770 - val_Precision: 0.9635 - val_Recall: 0.9443 - val_TP: 759.1900 - val_TN: 1083.1200 - val_FP: 22.8800 - val_FN: 44.8100\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0473 - Accuracy: 0.9837 - Precision: 0.9589 - Recall: 0.9511 - TP: 3207.1001 - TN: 5528.7402 - FP: 118.2600 - FN: 164.9000 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9622 - val_Recall: 0.9444 - val_TP: 759.3300 - val_TN: 1081.7000 - val_FP: 24.3000 - val_FN: 44.6700\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0471 - Accuracy: 0.9836 - Precision: 0.9586 - Recall: 0.9513 - TP: 3207.7800 - TN: 5527.4399 - FP: 119.5600 - FN: 164.2200 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9629 - val_Recall: 0.9446 - val_TP: 759.4600 - val_TN: 1082.5300 - val_FP: 23.4700 - val_FN: 44.5400\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0471 - Accuracy: 0.9836 - Precision: 0.9587 - Recall: 0.9512 - TP: 3207.5100 - TN: 5528.2900 - FP: 118.7100 - FN: 164.4900 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9621 - val_Recall: 0.9445 - val_TP: 759.3700 - val_TN: 1081.5900 - val_FP: 24.4100 - val_FN: 44.6300\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0473 - Accuracy: 0.9836 - Precision: 0.9587 - Recall: 0.9511 - TP: 3207.2500 - TN: 5527.9199 - FP: 119.0800 - FN: 164.7500 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9630 - val_Recall: 0.9445 - val_TP: 759.3800 - val_TN: 1082.6300 - val_FP: 23.3700 - val_FN: 44.6200\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0472 - Accuracy: 0.9836 - Precision: 0.9584 - Recall: 0.9512 - TP: 3207.4500 - TN: 5526.7798 - FP: 120.2200 - FN: 164.5500 - val_loss: 0.0739 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9445 - val_TP: 759.3500 - val_TN: 1082.9500 - val_FP: 23.0500 - val_FN: 44.6500\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0471 - Accuracy: 0.9837 - Precision: 0.9588 - Recall: 0.9512 - TP: 3207.5000 - TN: 5528.6699 - FP: 118.3300 - FN: 164.5000 - val_loss: 0.0743 - val_Accuracy: 0.9764 - val_Precision: 0.9624 - val_Recall: 0.9445 - val_TP: 759.3800 - val_TN: 1081.8900 - val_FP: 24.1100 - val_FN: 44.6200\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0471 - Accuracy: 0.9837 - Precision: 0.9588 - Recall: 0.9513 - TP: 3207.7300 - TN: 5528.6602 - FP: 118.3400 - FN: 164.2700 - val_loss: 0.0752 - val_Accuracy: 0.9764 - val_Precision: 0.9612 - val_Recall: 0.9445 - val_TP: 759.3900 - val_TN: 1080.6400 - val_FP: 25.3600 - val_FN: 44.6100\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0471 - Accuracy: 0.9835 - Precision: 0.9584 - Recall: 0.9514 - TP: 3208.0701 - TN: 5526.5400 - FP: 120.4600 - FN: 163.9300 - val_loss: 0.0747 - val_Accuracy: 0.9764 - val_Precision: 0.9617 - val_Recall: 0.9447 - val_TP: 759.5100 - val_TN: 1081.2500 - val_FP: 24.7500 - val_FN: 44.4900\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0470 - Accuracy: 0.9835 - Precision: 0.9589 - Recall: 0.9512 - TP: 3207.5100 - TN: 5528.9102 - FP: 118.0900 - FN: 164.4900 - val_loss: 0.0748 - val_Accuracy: 0.9764 - val_Precision: 0.9618 - val_Recall: 0.9447 - val_TP: 759.5300 - val_TN: 1081.2700 - val_FP: 24.7300 - val_FN: 44.4700\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0469 - Accuracy: 0.9838 - Precision: 0.9588 - Recall: 0.9515 - TP: 3208.3401 - TN: 5528.6499 - FP: 118.3500 - FN: 163.6600 - val_loss: 0.0753 - val_Accuracy: 0.9764 - val_Precision: 0.9610 - val_Recall: 0.9446 - val_TP: 759.4500 - val_TN: 1080.4600 - val_FP: 25.5400 - val_FN: 44.5500\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0471 - Accuracy: 0.9838 - Precision: 0.9586 - Recall: 0.9513 - TP: 3207.9099 - TN: 5527.3999 - FP: 119.6000 - FN: 164.0900 - val_loss: 0.0745 - val_Accuracy: 0.9770 - val_Precision: 0.9623 - val_Recall: 0.9446 - val_TP: 759.4300 - val_TN: 1081.7700 - val_FP: 24.2300 - val_FN: 44.5700\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0470 - Accuracy: 0.9836 - Precision: 0.9587 - Recall: 0.9514 - TP: 3208.2600 - TN: 5527.8901 - FP: 119.1100 - FN: 163.7400 - val_loss: 0.0745 - val_Accuracy: 0.9764 - val_Precision: 0.9621 - val_Recall: 0.9446 - val_TP: 759.4800 - val_TN: 1081.5601 - val_FP: 24.4400 - val_FN: 44.5200\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 5ms/step - loss: 0.0481 - Accuracy: 0.9835 - Precision: 0.9590 - Recall: 0.9510 - TP: 3206.7200 - TN: 5529.9302 - FP: 117.0700 - FN: 165.2800 - val_loss: 0.0752 - val_Accuracy: 0.9770 - val_Precision: 0.9609 - val_Recall: 0.9445 - val_TP: 759.4100 - val_TN: 1080.2500 - val_FP: 25.7500 - val_FN: 44.5900\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0474 - Accuracy: 0.9835 - Precision: 0.9582 - Recall: 0.9511 - TP: 3207.0801 - TN: 5525.8901 - FP: 121.1100 - FN: 164.9200 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9630 - val_Recall: 0.9443 - val_TP: 759.2500 - val_TN: 1082.5800 - val_FP: 23.4200 - val_FN: 44.7500\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0474 - Accuracy: 0.9837 - Precision: 0.9585 - Recall: 0.9512 - TP: 3207.2900 - TN: 5527.2100 - FP: 119.7900 - FN: 164.7100 - val_loss: 0.0737 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9445 - val_TP: 759.3400 - val_TN: 1082.8900 - val_FP: 23.1100 - val_FN: 44.6600\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0473 - Accuracy: 0.9836 - Precision: 0.9586 - Recall: 0.9511 - TP: 3207.0000 - TN: 5527.5400 - FP: 119.4600 - FN: 165.0000 - val_loss: 0.0748 - val_Accuracy: 0.9770 - val_Precision: 0.9612 - val_Recall: 0.9446 - val_TP: 759.4700 - val_TN: 1080.6100 - val_FP: 25.3900 - val_FN: 44.5300\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0476 - Accuracy: 0.9836 - Precision: 0.9585 - Recall: 0.9509 - TP: 3206.4500 - TN: 5527.3701 - FP: 119.6300 - FN: 165.5500 - val_loss: 0.0739 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9443 - val_TP: 759.2300 - val_TN: 1082.9200 - val_FP: 23.0800 - val_FN: 44.7700\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0473 - Accuracy: 0.9838 - Precision: 0.9586 - Recall: 0.9512 - TP: 3207.3799 - TN: 5527.7798 - FP: 119.2200 - FN: 164.6200 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9619 - val_Recall: 0.9445 - val_TP: 759.4100 - val_TN: 1081.4200 - val_FP: 24.5800 - val_FN: 44.5900\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0472 - Accuracy: 0.9836 - Precision: 0.9585 - Recall: 0.9513 - TP: 3207.6299 - TN: 5527.0298 - FP: 119.9700 - FN: 164.3700 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9625 - val_Recall: 0.9444 - val_TP: 759.2700 - val_TN: 1082.0000 - val_FP: 24.0000 - val_FN: 44.7300\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0474 - Accuracy: 0.9833 - Precision: 0.9583 - Recall: 0.9511 - TP: 3207.0500 - TN: 5526.3999 - FP: 120.6000 - FN: 164.9500 - val_loss: 0.0750 - val_Accuracy: 0.9770 - val_Precision: 0.9614 - val_Recall: 0.9444 - val_TP: 759.2600 - val_TN: 1080.8000 - val_FP: 25.2000 - val_FN: 44.7400\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0473 - Accuracy: 0.9838 - Precision: 0.9584 - Recall: 0.9515 - TP: 3208.4099 - TN: 5526.7300 - FP: 120.2700 - FN: 163.5900 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9634 - val_Recall: 0.9442 - val_TP: 759.1200 - val_TN: 1083.0000 - val_FP: 23.0000 - val_FN: 44.8800\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0472 - Accuracy: 0.9835 - Precision: 0.9584 - Recall: 0.9514 - TP: 3208.1299 - TN: 5526.7598 - FP: 120.2400 - FN: 163.8700 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9443 - val_TP: 759.2400 - val_TN: 1082.7800 - val_FP: 23.2200 - val_FN: 44.7600\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0472 - Accuracy: 0.9834 - Precision: 0.9590 - Recall: 0.9511 - TP: 3207.0100 - TN: 5529.3101 - FP: 117.6900 - FN: 164.9900 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9622 - val_Recall: 0.9445 - val_TP: 759.3600 - val_TN: 1081.6500 - val_FP: 24.3500 - val_FN: 44.6400\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0471 - Accuracy: 0.9839 - Precision: 0.9584 - Recall: 0.9515 - TP: 3208.3101 - TN: 5526.8101 - FP: 120.1900 - FN: 163.6900 - val_loss: 0.0739 - val_Accuracy: 0.9770 - val_Precision: 0.9635 - val_Recall: 0.9443 - val_TP: 759.2300 - val_TN: 1083.0699 - val_FP: 22.9300 - val_FN: 44.7700\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0472 - Accuracy: 0.9833 - Precision: 0.9586 - Recall: 0.9512 - TP: 3207.5601 - TN: 5527.7798 - FP: 119.2200 - FN: 164.4400 - val_loss: 0.0738 - val_Accuracy: 0.9770 - val_Precision: 0.9634 - val_Recall: 0.9445 - val_TP: 759.3400 - val_TN: 1083.0200 - val_FP: 22.9800 - val_FN: 44.6600\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0472 - Accuracy: 0.9837 - Precision: 0.9587 - Recall: 0.9512 - TP: 3207.5400 - TN: 5528.1602 - FP: 118.8400 - FN: 164.4600 - val_loss: 0.0745 - val_Accuracy: 0.9770 - val_Precision: 0.9625 - val_Recall: 0.9443 - val_TP: 759.2300 - val_TN: 1082.0000 - val_FP: 24.0000 - val_FN: 44.7700\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0472 - Accuracy: 0.9835 - Precision: 0.9587 - Recall: 0.9514 - TP: 3208.0300 - TN: 5528.1802 - FP: 118.8200 - FN: 163.9700 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9634 - val_Recall: 0.9444 - val_TP: 759.2900 - val_TN: 1082.9800 - val_FP: 23.0200 - val_FN: 44.7100\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0469 - Accuracy: 0.9837 - Precision: 0.9588 - Recall: 0.9516 - TP: 3208.6299 - TN: 5528.3799 - FP: 118.6200 - FN: 163.3700 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9444 - val_TP: 759.3300 - val_TN: 1082.9000 - val_FP: 23.1000 - val_FN: 44.6700\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0470 - Accuracy: 0.9839 - Precision: 0.9587 - Recall: 0.9515 - TP: 3208.5000 - TN: 5528.1802 - FP: 118.8200 - FN: 163.5000 - val_loss: 0.0738 - val_Accuracy: 0.9775 - val_Precision: 0.9637 - val_Recall: 0.9443 - val_TP: 759.2400 - val_TN: 1083.2500 - val_FP: 22.7500 - val_FN: 44.7600\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0469 - Accuracy: 0.9836 - Precision: 0.9592 - Recall: 0.9512 - TP: 3207.4299 - TN: 5530.2900 - FP: 116.7100 - FN: 164.5700 - val_loss: 0.0747 - val_Accuracy: 0.9764 - val_Precision: 0.9621 - val_Recall: 0.9445 - val_TP: 759.4000 - val_TN: 1081.5699 - val_FP: 24.4300 - val_FN: 44.6000\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0470 - Accuracy: 0.9835 - Precision: 0.9588 - Recall: 0.9513 - TP: 3207.7900 - TN: 5528.5400 - FP: 118.4600 - FN: 164.2100 - val_loss: 0.0742 - val_Accuracy: 0.9764 - val_Precision: 0.9625 - val_Recall: 0.9446 - val_TP: 759.4400 - val_TN: 1081.9600 - val_FP: 24.0400 - val_FN: 44.5600\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0470 - Accuracy: 0.9838 - Precision: 0.9585 - Recall: 0.9516 - TP: 3208.7700 - TN: 5526.7900 - FP: 120.2100 - FN: 163.2300 - val_loss: 0.0738 - val_Accuracy: 0.9764 - val_Precision: 0.9633 - val_Recall: 0.9446 - val_TP: 759.4500 - val_TN: 1082.9500 - val_FP: 23.0500 - val_FN: 44.5500\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0470 - Accuracy: 0.9838 - Precision: 0.9588 - Recall: 0.9514 - TP: 3208.2300 - TN: 5528.5098 - FP: 118.4900 - FN: 163.7700 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9631 - val_Recall: 0.9445 - val_TP: 759.3700 - val_TN: 1082.7100 - val_FP: 23.2900 - val_FN: 44.6300\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0469 - Accuracy: 0.9835 - Precision: 0.9588 - Recall: 0.9514 - TP: 3208.1699 - TN: 5528.3599 - FP: 118.6400 - FN: 163.8300 - val_loss: 0.0745 - val_Accuracy: 0.9770 - val_Precision: 0.9624 - val_Recall: 0.9445 - val_TP: 759.3600 - val_TN: 1081.9000 - val_FP: 24.1000 - val_FN: 44.6400\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0468 - Accuracy: 0.9836 - Precision: 0.9589 - Recall: 0.9515 - TP: 3208.5701 - TN: 5528.7598 - FP: 118.2400 - FN: 163.4300 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9622 - val_Recall: 0.9445 - val_TP: 759.4100 - val_TN: 1081.6899 - val_FP: 24.3100 - val_FN: 44.5900\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0476 - Accuracy: 0.9836 - Precision: 0.9584 - Recall: 0.9513 - TP: 3207.8101 - TN: 5527.0498 - FP: 119.9500 - FN: 164.1900 - val_loss: 0.0738 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9444 - val_TP: 759.2900 - val_TN: 1082.9100 - val_FP: 23.0900 - val_FN: 44.7100\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0475 - Accuracy: 0.9835 - Precision: 0.9587 - Recall: 0.9510 - TP: 3206.8999 - TN: 5528.2598 - FP: 118.7400 - FN: 165.1000 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9444 - val_TP: 759.2700 - val_TN: 1082.7600 - val_FP: 23.2400 - val_FN: 44.7300\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0473 - Accuracy: 0.9838 - Precision: 0.9583 - Recall: 0.9515 - TP: 3208.3101 - TN: 5526.2998 - FP: 120.7000 - FN: 163.6900 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9635 - val_Recall: 0.9442 - val_TP: 759.1400 - val_TN: 1083.0900 - val_FP: 22.9100 - val_FN: 44.8600\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0473 - Accuracy: 0.9837 - Precision: 0.9586 - Recall: 0.9513 - TP: 3207.9399 - TN: 5527.7798 - FP: 119.2200 - FN: 164.0600 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9444 - val_TP: 759.3200 - val_TN: 1082.8400 - val_FP: 23.1600 - val_FN: 44.6800\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0472 - Accuracy: 0.9833 - Precision: 0.9586 - Recall: 0.9511 - TP: 3207.1001 - TN: 5527.4702 - FP: 119.5300 - FN: 164.9000 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9626 - val_Recall: 0.9443 - val_TP: 759.2500 - val_TN: 1082.0601 - val_FP: 23.9400 - val_FN: 44.7500\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0473 - Accuracy: 0.9836 - Precision: 0.9590 - Recall: 0.9512 - TP: 3207.3000 - TN: 5529.2100 - FP: 117.7900 - FN: 164.7000 - val_loss: 0.0755 - val_Accuracy: 0.9764 - val_Precision: 0.9609 - val_Recall: 0.9445 - val_TP: 759.3700 - val_TN: 1080.3199 - val_FP: 25.6800 - val_FN: 44.6300\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0473 - Accuracy: 0.9836 - Precision: 0.9584 - Recall: 0.9514 - TP: 3208.2600 - TN: 5526.5200 - FP: 120.4800 - FN: 163.7400 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9625 - val_Recall: 0.9443 - val_TP: 759.2500 - val_TN: 1081.9900 - val_FP: 24.0100 - val_FN: 44.7500\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0473 - Accuracy: 0.9835 - Precision: 0.9586 - Recall: 0.9512 - TP: 3207.5200 - TN: 5527.6401 - FP: 119.3600 - FN: 164.4800 - val_loss: 0.0748 - val_Accuracy: 0.9764 - val_Precision: 0.9619 - val_Recall: 0.9446 - val_TP: 759.4600 - val_TN: 1081.3700 - val_FP: 24.6300 - val_FN: 44.5400\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0473 - Accuracy: 0.9836 - Precision: 0.9588 - Recall: 0.9509 - TP: 3206.5200 - TN: 5528.4199 - FP: 118.5800 - FN: 165.4800 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9626 - val_Recall: 0.9445 - val_TP: 759.3400 - val_TN: 1082.0601 - val_FP: 23.9400 - val_FN: 44.6600\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0472 - Accuracy: 0.9836 - Precision: 0.9584 - Recall: 0.9513 - TP: 3207.7300 - TN: 5527.1201 - FP: 119.8800 - FN: 164.2700 - val_loss: 0.0744 - val_Accuracy: 0.9764 - val_Precision: 0.9622 - val_Recall: 0.9446 - val_TP: 759.4300 - val_TN: 1081.7200 - val_FP: 24.2800 - val_FN: 44.5700\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0472 - Accuracy: 0.9836 - Precision: 0.9590 - Recall: 0.9512 - TP: 3207.3301 - TN: 5529.1802 - FP: 117.8200 - FN: 164.6700 - val_loss: 0.0746 - val_Accuracy: 0.9764 - val_Precision: 0.9622 - val_Recall: 0.9445 - val_TP: 759.3900 - val_TN: 1081.7000 - val_FP: 24.3000 - val_FN: 44.6100\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0470 - Accuracy: 0.9837 - Precision: 0.9585 - Recall: 0.9516 - TP: 3208.6499 - TN: 5527.1299 - FP: 119.8700 - FN: 163.3500 - val_loss: 0.0748 - val_Accuracy: 0.9764 - val_Precision: 0.9618 - val_Recall: 0.9447 - val_TP: 759.5100 - val_TN: 1081.3101 - val_FP: 24.6900 - val_FN: 44.4900\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0469 - Accuracy: 0.9837 - Precision: 0.9586 - Recall: 0.9514 - TP: 3208.1599 - TN: 5527.9902 - FP: 119.0100 - FN: 163.8400 - val_loss: 0.0764 - val_Accuracy: 0.9759 - val_Precision: 0.9593 - val_Recall: 0.9446 - val_TP: 759.4200 - val_TN: 1078.6300 - val_FP: 27.3700 - val_FN: 44.5800\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0472 - Accuracy: 0.9838 - Precision: 0.9585 - Recall: 0.9514 - TP: 3207.9700 - TN: 5526.9502 - FP: 120.0500 - FN: 164.0300 - val_loss: 0.0739 - val_Accuracy: 0.9764 - val_Precision: 0.9633 - val_Recall: 0.9445 - val_TP: 759.3700 - val_TN: 1082.9200 - val_FP: 23.0800 - val_FN: 44.6300\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0470 - Accuracy: 0.9835 - Precision: 0.9589 - Recall: 0.9511 - TP: 3207.1699 - TN: 5528.8901 - FP: 118.1100 - FN: 164.8300 - val_loss: 0.0742 - val_Accuracy: 0.9764 - val_Precision: 0.9630 - val_Recall: 0.9445 - val_TP: 759.3900 - val_TN: 1082.5900 - val_FP: 23.4100 - val_FN: 44.6100\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0469 - Accuracy: 0.9837 - Precision: 0.9588 - Recall: 0.9515 - TP: 3208.3401 - TN: 5528.4600 - FP: 118.5400 - FN: 163.6600 - val_loss: 0.0749 - val_Accuracy: 0.9764 - val_Precision: 0.9615 - val_Recall: 0.9445 - val_TP: 759.3900 - val_TN: 1080.9500 - val_FP: 25.0500 - val_FN: 44.6100\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0471 - Accuracy: 0.9837 - Precision: 0.9583 - Recall: 0.9516 - TP: 3208.7200 - TN: 5526.3599 - FP: 120.6400 - FN: 163.2800 - val_loss: 0.0741 - val_Accuracy: 0.9764 - val_Precision: 0.9629 - val_Recall: 0.9447 - val_TP: 759.5000 - val_TN: 1082.5300 - val_FP: 23.4700 - val_FN: 44.5000\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0469 - Accuracy: 0.9838 - Precision: 0.9590 - Recall: 0.9514 - TP: 3208.1101 - TN: 5529.4399 - FP: 117.5600 - FN: 163.8900 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9635 - val_Recall: 0.9444 - val_TP: 759.3000 - val_TN: 1083.1000 - val_FP: 22.9000 - val_FN: 44.7000\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0469 - Accuracy: 0.9837 - Precision: 0.9590 - Recall: 0.9515 - TP: 3208.6101 - TN: 5529.7402 - FP: 117.2600 - FN: 163.3900 - val_loss: 0.0754 - val_Accuracy: 0.9764 - val_Precision: 0.9610 - val_Recall: 0.9446 - val_TP: 759.4300 - val_TN: 1080.4301 - val_FP: 25.5700 - val_FN: 44.5700\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0471 - Accuracy: 0.9837 - Precision: 0.9585 - Recall: 0.9515 - TP: 3208.3401 - TN: 5527.4502 - FP: 119.5500 - FN: 163.6600 - val_loss: 0.0739 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9446 - val_TP: 759.4900 - val_TN: 1082.8199 - val_FP: 23.1800 - val_FN: 44.5100\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0467 - Accuracy: 0.9837 - Precision: 0.9587 - Recall: 0.9516 - TP: 3208.8701 - TN: 5528.3999 - FP: 118.6000 - FN: 163.1300 - val_loss: 0.0750 - val_Accuracy: 0.9764 - val_Precision: 0.9613 - val_Recall: 0.9446 - val_TP: 759.4400 - val_TN: 1080.7000 - val_FP: 25.3000 - val_FN: 44.5600\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 4ms/step - loss: 0.0475 - Accuracy: 0.9835 - Precision: 0.9582 - Recall: 0.9515 - TP: 3208.4900 - TN: 5526.3101 - FP: 120.6900 - FN: 163.5100 - val_loss: 0.0739 - val_Accuracy: 0.9770 - val_Precision: 0.9631 - val_Recall: 0.9446 - val_TP: 759.4300 - val_TN: 1082.6500 - val_FP: 23.3500 - val_FN: 44.5700\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0474 - Accuracy: 0.9837 - Precision: 0.9588 - Recall: 0.9511 - TP: 3206.9700 - TN: 5528.7002 - FP: 118.3000 - FN: 165.0300 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9623 - val_Recall: 0.9446 - val_TP: 759.4300 - val_TN: 1081.7800 - val_FP: 24.2200 - val_FN: 44.5700\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0473 - Accuracy: 0.9837 - Precision: 0.9584 - Recall: 0.9513 - TP: 3207.8999 - TN: 5526.7598 - FP: 120.2400 - FN: 164.1000 - val_loss: 0.0737 - val_Accuracy: 0.9770 - val_Precision: 0.9634 - val_Recall: 0.9445 - val_TP: 759.3500 - val_TN: 1083.0100 - val_FP: 22.9900 - val_FN: 44.6500\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0476 - Accuracy: 0.9835 - Precision: 0.9585 - Recall: 0.9511 - TP: 3207.2600 - TN: 5527.7002 - FP: 119.3000 - FN: 164.7400 - val_loss: 0.0745 - val_Accuracy: 0.9770 - val_Precision: 0.9622 - val_Recall: 0.9445 - val_TP: 759.3700 - val_TN: 1081.6500 - val_FP: 24.3500 - val_FN: 44.6300\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0473 - Accuracy: 0.9834 - Precision: 0.9586 - Recall: 0.9511 - TP: 3207.0500 - TN: 5527.6899 - FP: 119.3100 - FN: 164.9500 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9621 - val_Recall: 0.9446 - val_TP: 759.4200 - val_TN: 1081.5800 - val_FP: 24.4200 - val_FN: 44.5800\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0473 - Accuracy: 0.9835 - Precision: 0.9586 - Recall: 0.9512 - TP: 3207.3999 - TN: 5527.5400 - FP: 119.4600 - FN: 164.6000 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9445 - val_TP: 759.3400 - val_TN: 1082.7600 - val_FP: 23.2400 - val_FN: 44.6600\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0471 - Accuracy: 0.9836 - Precision: 0.9589 - Recall: 0.9512 - TP: 3207.4099 - TN: 5529.1699 - FP: 117.8300 - FN: 164.5900 - val_loss: 0.0753 - val_Accuracy: 0.9770 - val_Precision: 0.9611 - val_Recall: 0.9445 - val_TP: 759.4000 - val_TN: 1080.5300 - val_FP: 25.4700 - val_FN: 44.6000\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0473 - Accuracy: 0.9835 - Precision: 0.9582 - Recall: 0.9514 - TP: 3208.2000 - TN: 5526.0298 - FP: 120.9700 - FN: 163.8000 - val_loss: 0.0752 - val_Accuracy: 0.9764 - val_Precision: 0.9612 - val_Recall: 0.9445 - val_TP: 759.4000 - val_TN: 1080.5500 - val_FP: 25.4500 - val_FN: 44.6000\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0472 - Accuracy: 0.9836 - Precision: 0.9586 - Recall: 0.9514 - TP: 3208.1599 - TN: 5527.4702 - FP: 119.5300 - FN: 163.8400 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9625 - val_Recall: 0.9445 - val_TP: 759.3800 - val_TN: 1082.0000 - val_FP: 24.0000 - val_FN: 44.6200\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0470 - Accuracy: 0.9837 - Precision: 0.9587 - Recall: 0.9514 - TP: 3208.2400 - TN: 5528.1099 - FP: 118.8900 - FN: 163.7600 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9626 - val_Recall: 0.9445 - val_TP: 759.3500 - val_TN: 1082.0900 - val_FP: 23.9100 - val_FN: 44.6500\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0471 - Accuracy: 0.9836 - Precision: 0.9587 - Recall: 0.9511 - TP: 3207.1899 - TN: 5528.0400 - FP: 118.9600 - FN: 164.8100 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9444 - val_TP: 759.3200 - val_TN: 1082.9100 - val_FP: 23.0900 - val_FN: 44.6800\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0471 - Accuracy: 0.9836 - Precision: 0.9584 - Recall: 0.9515 - TP: 3208.3401 - TN: 5526.8701 - FP: 120.1300 - FN: 163.6600 - val_loss: 0.0748 - val_Accuracy: 0.9770 - val_Precision: 0.9622 - val_Recall: 0.9444 - val_TP: 759.2800 - val_TN: 1081.7000 - val_FP: 24.3000 - val_FN: 44.7200\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0470 - Accuracy: 0.9838 - Precision: 0.9585 - Recall: 0.9514 - TP: 3208.2500 - TN: 5527.2402 - FP: 119.7600 - FN: 163.7500 - val_loss: 0.0740 - val_Accuracy: 0.9764 - val_Precision: 0.9633 - val_Recall: 0.9445 - val_TP: 759.3800 - val_TN: 1082.8900 - val_FP: 23.1100 - val_FN: 44.6200\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0470 - Accuracy: 0.9837 - Precision: 0.9588 - Recall: 0.9514 - TP: 3208.0801 - TN: 5528.2598 - FP: 118.7400 - FN: 163.9200 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9634 - val_Recall: 0.9445 - val_TP: 759.3400 - val_TN: 1083.0300 - val_FP: 22.9700 - val_FN: 44.6600\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0470 - Accuracy: 0.9838 - Precision: 0.9590 - Recall: 0.9514 - TP: 3207.9900 - TN: 5529.1899 - FP: 117.8100 - FN: 164.0100 - val_loss: 0.0745 - val_Accuracy: 0.9764 - val_Precision: 0.9625 - val_Recall: 0.9445 - val_TP: 759.3600 - val_TN: 1081.9500 - val_FP: 24.0500 - val_FN: 44.6400\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0471 - Accuracy: 0.9837 - Precision: 0.9588 - Recall: 0.9516 - TP: 3208.6299 - TN: 5528.3101 - FP: 118.6900 - FN: 163.3700 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9445 - val_TP: 759.3800 - val_TN: 1082.8600 - val_FP: 23.1400 - val_FN: 44.6200\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0470 - Accuracy: 0.9838 - Precision: 0.9587 - Recall: 0.9515 - TP: 3208.3899 - TN: 5528.4102 - FP: 118.5900 - FN: 163.6100 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9630 - val_Recall: 0.9445 - val_TP: 759.4100 - val_TN: 1082.5900 - val_FP: 23.4100 - val_FN: 44.5900\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0466 - Accuracy: 0.9838 - Precision: 0.9588 - Recall: 0.9517 - TP: 3209.1101 - TN: 5528.8599 - FP: 118.1400 - FN: 162.8900 - val_loss: 0.0749 - val_Accuracy: 0.9764 - val_Precision: 0.9614 - val_Recall: 0.9447 - val_TP: 759.5400 - val_TN: 1080.8400 - val_FP: 25.1600 - val_FN: 44.4600\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0469 - Accuracy: 0.9836 - Precision: 0.9589 - Recall: 0.9514 - TP: 3207.9800 - TN: 5528.9902 - FP: 118.0100 - FN: 164.0200 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9627 - val_Recall: 0.9443 - val_TP: 759.2300 - val_TN: 1082.1200 - val_FP: 23.8800 - val_FN: 44.7700\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0468 - Accuracy: 0.9837 - Precision: 0.9586 - Recall: 0.9517 - TP: 3209.3000 - TN: 5527.7900 - FP: 119.2100 - FN: 162.7000 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9625 - val_Recall: 0.9445 - val_TP: 759.3700 - val_TN: 1082.0100 - val_FP: 23.9900 - val_FN: 44.6300\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0467 - Accuracy: 0.9838 - Precision: 0.9590 - Recall: 0.9517 - TP: 3209.0400 - TN: 5529.0298 - FP: 117.9700 - FN: 162.9600 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9444 - val_TP: 759.3300 - val_TN: 1082.8800 - val_FP: 23.1200 - val_FN: 44.6700\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0470 - Accuracy: 0.9836 - Precision: 0.9589 - Recall: 0.9514 - TP: 3208.0500 - TN: 5528.8101 - FP: 118.1900 - FN: 163.9500 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9625 - val_Recall: 0.9446 - val_TP: 759.4900 - val_TN: 1082.0000 - val_FP: 24.0000 - val_FN: 44.5100\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0466 - Accuracy: 0.9838 - Precision: 0.9588 - Recall: 0.9518 - TP: 3209.6201 - TN: 5528.6899 - FP: 118.3100 - FN: 162.3800 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9625 - val_Recall: 0.9446 - val_TP: 759.4800 - val_TN: 1081.9600 - val_FP: 24.0400 - val_FN: 44.5200\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 4ms/step - loss: 0.0476 - Accuracy: 0.9834 - Precision: 0.9588 - Recall: 0.9512 - TP: 3207.5901 - TN: 5528.6001 - FP: 118.4000 - FN: 164.4100 - val_loss: 0.0737 - val_Accuracy: 0.9770 - val_Precision: 0.9635 - val_Recall: 0.9444 - val_TP: 759.3300 - val_TN: 1083.1300 - val_FP: 22.8700 - val_FN: 44.6700\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0472 - Accuracy: 0.9835 - Precision: 0.9587 - Recall: 0.9514 - TP: 3207.9700 - TN: 5528.2100 - FP: 118.7900 - FN: 164.0300 - val_loss: 0.0745 - val_Accuracy: 0.9764 - val_Precision: 0.9618 - val_Recall: 0.9448 - val_TP: 759.5900 - val_TN: 1081.3000 - val_FP: 24.7000 - val_FN: 44.4100\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0472 - Accuracy: 0.9834 - Precision: 0.9588 - Recall: 0.9511 - TP: 3207.0100 - TN: 5528.5098 - FP: 118.4900 - FN: 164.9900 - val_loss: 0.0748 - val_Accuracy: 0.9770 - val_Precision: 0.9620 - val_Recall: 0.9445 - val_TP: 759.3700 - val_TN: 1081.5100 - val_FP: 24.4900 - val_FN: 44.6300\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0474 - Accuracy: 0.9835 - Precision: 0.9585 - Recall: 0.9514 - TP: 3208.1001 - TN: 5527.3198 - FP: 119.6800 - FN: 163.9000 - val_loss: 0.0749 - val_Accuracy: 0.9764 - val_Precision: 0.9613 - val_Recall: 0.9447 - val_TP: 759.5500 - val_TN: 1080.7200 - val_FP: 25.2800 - val_FN: 44.4500\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0472 - Accuracy: 0.9838 - Precision: 0.9587 - Recall: 0.9514 - TP: 3208.0500 - TN: 5527.6802 - FP: 119.3200 - FN: 163.9500 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9626 - val_Recall: 0.9445 - val_TP: 759.4000 - val_TN: 1082.0100 - val_FP: 23.9900 - val_FN: 44.6000\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0470 - Accuracy: 0.9838 - Precision: 0.9588 - Recall: 0.9514 - TP: 3208.0901 - TN: 5528.5400 - FP: 118.4600 - FN: 163.9100 - val_loss: 0.0759 - val_Accuracy: 0.9759 - val_Precision: 0.9597 - val_Recall: 0.9448 - val_TP: 759.6200 - val_TN: 1079.1400 - val_FP: 26.8600 - val_FN: 44.3800\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0470 - Accuracy: 0.9836 - Precision: 0.9586 - Recall: 0.9513 - TP: 3207.7300 - TN: 5527.6299 - FP: 119.3700 - FN: 164.2700 - val_loss: 0.0752 - val_Accuracy: 0.9764 - val_Precision: 0.9610 - val_Recall: 0.9448 - val_TP: 759.5900 - val_TN: 1080.4100 - val_FP: 25.5900 - val_FN: 44.4100\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0471 - Accuracy: 0.9838 - Precision: 0.9583 - Recall: 0.9517 - TP: 3209.1499 - TN: 5526.4902 - FP: 120.5100 - FN: 162.8500 - val_loss: 0.0742 - val_Accuracy: 0.9764 - val_Precision: 0.9631 - val_Recall: 0.9445 - val_TP: 759.3800 - val_TN: 1082.6801 - val_FP: 23.3200 - val_FN: 44.6200\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0472 - Accuracy: 0.9837 - Precision: 0.9588 - Recall: 0.9514 - TP: 3208.0400 - TN: 5528.7500 - FP: 118.2500 - FN: 163.9600 - val_loss: 0.0743 - val_Accuracy: 0.9764 - val_Precision: 0.9625 - val_Recall: 0.9446 - val_TP: 759.4600 - val_TN: 1081.9600 - val_FP: 24.0400 - val_FN: 44.5400\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0470 - Accuracy: 0.9838 - Precision: 0.9587 - Recall: 0.9515 - TP: 3208.3601 - TN: 5528.2500 - FP: 118.7500 - FN: 163.6400 - val_loss: 0.0754 - val_Accuracy: 0.9764 - val_Precision: 0.9612 - val_Recall: 0.9445 - val_TP: 759.3500 - val_TN: 1080.5601 - val_FP: 25.4400 - val_FN: 44.6500\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0471 - Accuracy: 0.9836 - Precision: 0.9587 - Recall: 0.9513 - TP: 3207.7200 - TN: 5528.1602 - FP: 118.8400 - FN: 164.2800 - val_loss: 0.0745 - val_Accuracy: 0.9764 - val_Precision: 0.9625 - val_Recall: 0.9445 - val_TP: 759.4100 - val_TN: 1081.9200 - val_FP: 24.0800 - val_FN: 44.5900\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0468 - Accuracy: 0.9838 - Precision: 0.9586 - Recall: 0.9518 - TP: 3209.5200 - TN: 5527.6699 - FP: 119.3300 - FN: 162.4800 - val_loss: 0.0740 - val_Accuracy: 0.9775 - val_Precision: 0.9637 - val_Recall: 0.9444 - val_TP: 759.2600 - val_TN: 1083.2600 - val_FP: 22.7400 - val_FN: 44.7400\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0470 - Accuracy: 0.9837 - Precision: 0.9588 - Recall: 0.9513 - TP: 3207.8201 - TN: 5528.7002 - FP: 118.3000 - FN: 164.1800 - val_loss: 0.0750 - val_Accuracy: 0.9764 - val_Precision: 0.9615 - val_Recall: 0.9446 - val_TP: 759.4200 - val_TN: 1080.8600 - val_FP: 25.1400 - val_FN: 44.5800\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0470 - Accuracy: 0.9838 - Precision: 0.9591 - Recall: 0.9514 - TP: 3208.1499 - TN: 5529.6299 - FP: 117.3700 - FN: 163.8500 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9445 - val_TP: 759.3600 - val_TN: 1082.7700 - val_FP: 23.2300 - val_FN: 44.6400\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0468 - Accuracy: 0.9834 - Precision: 0.9587 - Recall: 0.9514 - TP: 3208.2700 - TN: 5528.3599 - FP: 118.6400 - FN: 163.7300 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9626 - val_Recall: 0.9445 - val_TP: 759.3800 - val_TN: 1082.0400 - val_FP: 23.9600 - val_FN: 44.6200\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0468 - Accuracy: 0.9837 - Precision: 0.9590 - Recall: 0.9514 - TP: 3208.1899 - TN: 5529.3398 - FP: 117.6600 - FN: 163.8100 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9630 - val_Recall: 0.9447 - val_TP: 759.5100 - val_TN: 1082.5900 - val_FP: 23.4100 - val_FN: 44.4900\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0469 - Accuracy: 0.9838 - Precision: 0.9584 - Recall: 0.9519 - TP: 3209.7200 - TN: 5526.7202 - FP: 120.2800 - FN: 162.2800 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9631 - val_Recall: 0.9446 - val_TP: 759.4300 - val_TN: 1082.7400 - val_FP: 23.2600 - val_FN: 44.5700\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0468 - Accuracy: 0.9835 - Precision: 0.9590 - Recall: 0.9515 - TP: 3208.3701 - TN: 5529.3501 - FP: 117.6500 - FN: 163.6300 - val_loss: 0.0753 - val_Accuracy: 0.9770 - val_Precision: 0.9610 - val_Recall: 0.9447 - val_TP: 759.5500 - val_TN: 1080.4900 - val_FP: 25.5100 - val_FN: 44.4500\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0468 - Accuracy: 0.9837 - Precision: 0.9585 - Recall: 0.9516 - TP: 3208.9299 - TN: 5527.0298 - FP: 119.9700 - FN: 163.0700 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9626 - val_Recall: 0.9445 - val_TP: 759.3900 - val_TN: 1082.1000 - val_FP: 23.9000 - val_FN: 44.6100\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0468 - Accuracy: 0.9837 - Precision: 0.9588 - Recall: 0.9516 - TP: 3208.8000 - TN: 5528.4702 - FP: 118.5300 - FN: 163.2000 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9637 - val_Recall: 0.9444 - val_TP: 759.2600 - val_TN: 1083.2900 - val_FP: 22.7100 - val_FN: 44.7400\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0467 - Accuracy: 0.9839 - Precision: 0.9591 - Recall: 0.9517 - TP: 3209.1299 - TN: 5529.7300 - FP: 117.2700 - FN: 162.8700 - val_loss: 0.0745 - val_Accuracy: 0.9770 - val_Precision: 0.9626 - val_Recall: 0.9445 - val_TP: 759.3800 - val_TN: 1082.0800 - val_FP: 23.9200 - val_FN: 44.6200\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0478 - Accuracy: 0.9834 - Precision: 0.9589 - Recall: 0.9513 - TP: 3207.7800 - TN: 5529.3701 - FP: 117.6300 - FN: 164.2200 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9631 - val_Recall: 0.9444 - val_TP: 759.3200 - val_TN: 1082.7100 - val_FP: 23.2900 - val_FN: 44.6800\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0472 - Accuracy: 0.9838 - Precision: 0.9588 - Recall: 0.9513 - TP: 3207.7000 - TN: 5528.5498 - FP: 118.4500 - FN: 164.3000 - val_loss: 0.0747 - val_Accuracy: 0.9764 - val_Precision: 0.9621 - val_Recall: 0.9446 - val_TP: 759.4300 - val_TN: 1081.5601 - val_FP: 24.4400 - val_FN: 44.5700\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0473 - Accuracy: 0.9836 - Precision: 0.9587 - Recall: 0.9514 - TP: 3208.0100 - TN: 5528.1499 - FP: 118.8500 - FN: 163.9900 - val_loss: 0.0754 - val_Accuracy: 0.9764 - val_Precision: 0.9604 - val_Recall: 0.9447 - val_TP: 759.5700 - val_TN: 1079.7900 - val_FP: 26.2100 - val_FN: 44.4300\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0473 - Accuracy: 0.9836 - Precision: 0.9583 - Recall: 0.9515 - TP: 3208.3701 - TN: 5526.7300 - FP: 120.2700 - FN: 163.6300 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9627 - val_Recall: 0.9445 - val_TP: 759.3900 - val_TN: 1082.1200 - val_FP: 23.8800 - val_FN: 44.6100\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0472 - Accuracy: 0.9834 - Precision: 0.9584 - Recall: 0.9514 - TP: 3208.2500 - TN: 5527.0400 - FP: 119.9600 - FN: 163.7500 - val_loss: 0.0737 - val_Accuracy: 0.9770 - val_Precision: 0.9636 - val_Recall: 0.9445 - val_TP: 759.3900 - val_TN: 1083.2400 - val_FP: 22.7600 - val_FN: 44.6100\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0472 - Accuracy: 0.9836 - Precision: 0.9587 - Recall: 0.9513 - TP: 3207.6201 - TN: 5527.9199 - FP: 119.0800 - FN: 164.3800 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9634 - val_Recall: 0.9444 - val_TP: 759.3000 - val_TN: 1082.9600 - val_FP: 23.0400 - val_FN: 44.7000\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0470 - Accuracy: 0.9837 - Precision: 0.9590 - Recall: 0.9513 - TP: 3207.7800 - TN: 5529.6602 - FP: 117.3400 - FN: 164.2200 - val_loss: 0.0760 - val_Accuracy: 0.9759 - val_Precision: 0.9600 - val_Recall: 0.9447 - val_TP: 759.5700 - val_TN: 1079.4301 - val_FP: 26.5700 - val_FN: 44.4300\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0472 - Accuracy: 0.9836 - Precision: 0.9586 - Recall: 0.9513 - TP: 3207.9500 - TN: 5527.2500 - FP: 119.7500 - FN: 164.0500 - val_loss: 0.0737 - val_Accuracy: 0.9764 - val_Precision: 0.9636 - val_Recall: 0.9445 - val_TP: 759.3900 - val_TN: 1083.2200 - val_FP: 22.7800 - val_FN: 44.6100\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0471 - Accuracy: 0.9836 - Precision: 0.9589 - Recall: 0.9515 - TP: 3208.4900 - TN: 5529.1299 - FP: 117.8700 - FN: 163.5100 - val_loss: 0.0753 - val_Accuracy: 0.9764 - val_Precision: 0.9612 - val_Recall: 0.9446 - val_TP: 759.4700 - val_TN: 1080.5900 - val_FP: 25.4100 - val_FN: 44.5300\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0472 - Accuracy: 0.9837 - Precision: 0.9585 - Recall: 0.9516 - TP: 3208.7800 - TN: 5527.0400 - FP: 119.9600 - FN: 163.2200 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9627 - val_Recall: 0.9444 - val_TP: 759.3100 - val_TN: 1082.1200 - val_FP: 23.8800 - val_FN: 44.6900\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0470 - Accuracy: 0.9836 - Precision: 0.9585 - Recall: 0.9518 - TP: 3209.3601 - TN: 5527.2402 - FP: 119.7600 - FN: 162.6400 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9446 - val_TP: 759.4200 - val_TN: 1082.8101 - val_FP: 23.1900 - val_FN: 44.5800\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0470 - Accuracy: 0.9837 - Precision: 0.9591 - Recall: 0.9513 - TP: 3207.6599 - TN: 5529.8599 - FP: 117.1400 - FN: 164.3400 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9627 - val_Recall: 0.9446 - val_TP: 759.4200 - val_TN: 1082.1500 - val_FP: 23.8500 - val_FN: 44.5800\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0469 - Accuracy: 0.9837 - Precision: 0.9587 - Recall: 0.9516 - TP: 3208.8201 - TN: 5528.2202 - FP: 118.7800 - FN: 163.1800 - val_loss: 0.0737 - val_Accuracy: 0.9770 - val_Precision: 0.9637 - val_Recall: 0.9446 - val_TP: 759.4200 - val_TN: 1083.3199 - val_FP: 22.6800 - val_FN: 44.5800\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0470 - Accuracy: 0.9836 - Precision: 0.9589 - Recall: 0.9514 - TP: 3208.2400 - TN: 5528.9502 - FP: 118.0500 - FN: 163.7600 - val_loss: 0.0751 - val_Accuracy: 0.9764 - val_Precision: 0.9612 - val_Recall: 0.9447 - val_TP: 759.5700 - val_TN: 1080.5900 - val_FP: 25.4100 - val_FN: 44.4300\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0470 - Accuracy: 0.9836 - Precision: 0.9588 - Recall: 0.9515 - TP: 3208.3899 - TN: 5528.4702 - FP: 118.5300 - FN: 163.6100 - val_loss: 0.0743 - val_Accuracy: 0.9764 - val_Precision: 0.9623 - val_Recall: 0.9448 - val_TP: 759.6100 - val_TN: 1081.8199 - val_FP: 24.1800 - val_FN: 44.3900\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0467 - Accuracy: 0.9838 - Precision: 0.9586 - Recall: 0.9518 - TP: 3209.3501 - TN: 5527.6802 - FP: 119.3200 - FN: 162.6500 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9625 - val_Recall: 0.9447 - val_TP: 759.5200 - val_TN: 1082.0100 - val_FP: 23.9900 - val_FN: 44.4800\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0467 - Accuracy: 0.9837 - Precision: 0.9588 - Recall: 0.9518 - TP: 3209.3301 - TN: 5528.5400 - FP: 118.4600 - FN: 162.6700 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9634 - val_Recall: 0.9445 - val_TP: 759.3900 - val_TN: 1083.0200 - val_FP: 22.9800 - val_FN: 44.6100\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0467 - Accuracy: 0.9836 - Precision: 0.9589 - Recall: 0.9517 - TP: 3209.0100 - TN: 5528.9702 - FP: 118.0300 - FN: 162.9900 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9630 - val_Recall: 0.9447 - val_TP: 759.5000 - val_TN: 1082.6000 - val_FP: 23.4000 - val_FN: 44.5000\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0467 - Accuracy: 0.9838 - Precision: 0.9590 - Recall: 0.9517 - TP: 3208.9700 - TN: 5529.1602 - FP: 117.8400 - FN: 163.0300 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9634 - val_Recall: 0.9446 - val_TP: 759.4300 - val_TN: 1083.0500 - val_FP: 22.9500 - val_FN: 44.5700\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0469 - Accuracy: 0.9839 - Precision: 0.9592 - Recall: 0.9515 - TP: 3208.6001 - TN: 5530.1802 - FP: 116.8200 - FN: 163.4000 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9626 - val_Recall: 0.9447 - val_TP: 759.5200 - val_TN: 1082.0699 - val_FP: 23.9300 - val_FN: 44.4800\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0468 - Accuracy: 0.9837 - Precision: 0.9589 - Recall: 0.9517 - TP: 3208.9700 - TN: 5528.7202 - FP: 118.2800 - FN: 163.0300 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9623 - val_Recall: 0.9448 - val_TP: 759.6400 - val_TN: 1081.8101 - val_FP: 24.1900 - val_FN: 44.3600\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0466 - Accuracy: 0.9838 - Precision: 0.9587 - Recall: 0.9518 - TP: 3209.5601 - TN: 5528.3101 - FP: 118.6900 - FN: 162.4400 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9621 - val_Recall: 0.9448 - val_TP: 759.6100 - val_TN: 1081.5800 - val_FP: 24.4200 - val_FN: 44.3900\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0466 - Accuracy: 0.9836 - Precision: 0.9590 - Recall: 0.9517 - TP: 3209.0400 - TN: 5529.2202 - FP: 117.7800 - FN: 162.9600 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9630 - val_Recall: 0.9446 - val_TP: 759.4900 - val_TN: 1082.6300 - val_FP: 23.3700 - val_FN: 44.5100\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0466 - Accuracy: 0.9840 - Precision: 0.9591 - Recall: 0.9518 - TP: 3209.4199 - TN: 5530.1201 - FP: 116.8800 - FN: 162.5800 - val_loss: 0.0751 - val_Accuracy: 0.9770 - val_Precision: 0.9614 - val_Recall: 0.9448 - val_TP: 759.5800 - val_TN: 1080.8101 - val_FP: 25.1900 - val_FN: 44.4200\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0466 - Accuracy: 0.9837 - Precision: 0.9590 - Recall: 0.9518 - TP: 3209.3701 - TN: 5528.9902 - FP: 118.0100 - FN: 162.6300 - val_loss: 0.0745 - val_Accuracy: 0.9770 - val_Precision: 0.9624 - val_Recall: 0.9447 - val_TP: 759.5500 - val_TN: 1081.9000 - val_FP: 24.1000 - val_FN: 44.4500\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0465 - Accuracy: 0.9840 - Precision: 0.9591 - Recall: 0.9518 - TP: 3209.5801 - TN: 5529.6201 - FP: 117.3800 - FN: 162.4200 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9629 - val_Recall: 0.9448 - val_TP: 759.6100 - val_TN: 1082.5200 - val_FP: 23.4800 - val_FN: 44.3900\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0465 - Accuracy: 0.9838 - Precision: 0.9586 - Recall: 0.9521 - TP: 3210.4299 - TN: 5527.4302 - FP: 119.5700 - FN: 161.5700 - val_loss: 0.0739 - val_Accuracy: 0.9770 - val_Precision: 0.9638 - val_Recall: 0.9445 - val_TP: 759.4100 - val_TN: 1083.4000 - val_FP: 22.6000 - val_FN: 44.5900\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0464 - Accuracy: 0.9837 - Precision: 0.9588 - Recall: 0.9521 - TP: 3210.4099 - TN: 5528.7598 - FP: 118.2400 - FN: 161.5900 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9445 - val_TP: 759.3700 - val_TN: 1082.9500 - val_FP: 23.0500 - val_FN: 44.6300\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0465 - Accuracy: 0.9838 - Precision: 0.9591 - Recall: 0.9518 - TP: 3209.5000 - TN: 5529.8999 - FP: 117.1000 - FN: 162.5000 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9631 - val_Recall: 0.9447 - val_TP: 759.5000 - val_TN: 1082.7400 - val_FP: 23.2600 - val_FN: 44.5000\n",
      "Epoch 30/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0463 - Accuracy: 0.9839 - Precision: 0.9594 - Recall: 0.9518 - TP: 3209.5801 - TN: 5530.9199 - FP: 116.0800 - FN: 162.4200 - val_loss: 0.0751 - val_Accuracy: 0.9770 - val_Precision: 0.9616 - val_Recall: 0.9448 - val_TP: 759.6100 - val_TN: 1080.9800 - val_FP: 25.0200 - val_FN: 44.3900\n",
      "Epoch 31/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0463 - Accuracy: 0.9838 - Precision: 0.9588 - Recall: 0.9521 - TP: 3210.5601 - TN: 5528.4902 - FP: 118.5100 - FN: 161.4400 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9446 - val_TP: 759.4800 - val_TN: 1082.9200 - val_FP: 23.0800 - val_FN: 44.5200\n",
      "Epoch 32/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0462 - Accuracy: 0.9837 - Precision: 0.9597 - Recall: 0.9518 - TP: 3209.6299 - TN: 5532.2998 - FP: 114.7000 - FN: 162.3700 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9629 - val_Recall: 0.9450 - val_TP: 759.7800 - val_TN: 1082.6000 - val_FP: 23.4000 - val_FN: 44.2200\n",
      "Epoch 33/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0463 - Accuracy: 0.9839 - Precision: 0.9589 - Recall: 0.9522 - TP: 3210.8301 - TN: 5529.3198 - FP: 117.6800 - FN: 161.1700 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9448 - val_TP: 759.6000 - val_TN: 1082.8000 - val_FP: 23.2000 - val_FN: 44.4000\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 7ms/step - loss: 0.0474 - Accuracy: 0.9837 - Precision: 0.9593 - Recall: 0.9512 - TP: 3207.3201 - TN: 5531.0298 - FP: 115.9700 - FN: 164.6800 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9627 - val_Recall: 0.9446 - val_TP: 759.4600 - val_TN: 1082.1700 - val_FP: 23.8300 - val_FN: 44.5400\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0470 - Accuracy: 0.9838 - Precision: 0.9586 - Recall: 0.9516 - TP: 3208.7800 - TN: 5527.5400 - FP: 119.4600 - FN: 163.2200 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9623 - val_Recall: 0.9446 - val_TP: 759.4500 - val_TN: 1081.8199 - val_FP: 24.1800 - val_FN: 44.5500\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0468 - Accuracy: 0.9836 - Precision: 0.9591 - Recall: 0.9515 - TP: 3208.4800 - TN: 5529.7798 - FP: 117.2200 - FN: 163.5200 - val_loss: 0.0745 - val_Accuracy: 0.9770 - val_Precision: 0.9624 - val_Recall: 0.9446 - val_TP: 759.4700 - val_TN: 1081.8600 - val_FP: 24.1400 - val_FN: 44.5300\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0467 - Accuracy: 0.9837 - Precision: 0.9589 - Recall: 0.9517 - TP: 3209.2400 - TN: 5529.0601 - FP: 117.9400 - FN: 162.7600 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9620 - val_Recall: 0.9448 - val_TP: 759.5900 - val_TN: 1081.5500 - val_FP: 24.4500 - val_FN: 44.4100\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0466 - Accuracy: 0.9837 - Precision: 0.9590 - Recall: 0.9516 - TP: 3208.7400 - TN: 5529.2798 - FP: 117.7200 - FN: 163.2600 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9625 - val_Recall: 0.9447 - val_TP: 759.5600 - val_TN: 1081.9700 - val_FP: 24.0300 - val_FN: 44.4400\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0466 - Accuracy: 0.9838 - Precision: 0.9590 - Recall: 0.9517 - TP: 3209.1899 - TN: 5529.2998 - FP: 117.7000 - FN: 162.8100 - val_loss: 0.0755 - val_Accuracy: 0.9770 - val_Precision: 0.9611 - val_Recall: 0.9446 - val_TP: 759.4900 - val_TN: 1080.5400 - val_FP: 25.4600 - val_FN: 44.5100\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0468 - Accuracy: 0.9837 - Precision: 0.9590 - Recall: 0.9515 - TP: 3208.3701 - TN: 5529.4302 - FP: 117.5700 - FN: 163.6300 - val_loss: 0.0748 - val_Accuracy: 0.9770 - val_Precision: 0.9619 - val_Recall: 0.9448 - val_TP: 759.6400 - val_TN: 1081.3800 - val_FP: 24.6200 - val_FN: 44.3600\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0465 - Accuracy: 0.9837 - Precision: 0.9587 - Recall: 0.9521 - TP: 3210.5200 - TN: 5528.0298 - FP: 118.9700 - FN: 161.4800 - val_loss: 0.0747 - val_Accuracy: 0.9770 - val_Precision: 0.9619 - val_Recall: 0.9448 - val_TP: 759.6200 - val_TN: 1081.4600 - val_FP: 24.5400 - val_FN: 44.3800\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0467 - Accuracy: 0.9837 - Precision: 0.9588 - Recall: 0.9518 - TP: 3209.3999 - TN: 5528.9102 - FP: 118.0900 - FN: 162.6000 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9625 - val_Recall: 0.9447 - val_TP: 759.5400 - val_TN: 1082.0300 - val_FP: 23.9700 - val_FN: 44.4600\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0466 - Accuracy: 0.9838 - Precision: 0.9591 - Recall: 0.9517 - TP: 3209.0801 - TN: 5529.9199 - FP: 117.0800 - FN: 162.9200 - val_loss: 0.0755 - val_Accuracy: 0.9770 - val_Precision: 0.9611 - val_Recall: 0.9447 - val_TP: 759.5700 - val_TN: 1080.5200 - val_FP: 25.4800 - val_FN: 44.4300\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0465 - Accuracy: 0.9839 - Precision: 0.9589 - Recall: 0.9519 - TP: 3209.6499 - TN: 5528.7300 - FP: 118.2700 - FN: 162.3500 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9634 - val_Recall: 0.9446 - val_TP: 759.4600 - val_TN: 1083.0500 - val_FP: 22.9500 - val_FN: 44.5400\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0464 - Accuracy: 0.9839 - Precision: 0.9590 - Recall: 0.9520 - TP: 3210.1799 - TN: 5529.6099 - FP: 117.3900 - FN: 161.8200 - val_loss: 0.0750 - val_Accuracy: 0.9770 - val_Precision: 0.9619 - val_Recall: 0.9448 - val_TP: 759.6000 - val_TN: 1081.4399 - val_FP: 24.5600 - val_FN: 44.4000\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0466 - Accuracy: 0.9838 - Precision: 0.9589 - Recall: 0.9516 - TP: 3208.9299 - TN: 5529.0098 - FP: 117.9900 - FN: 163.0700 - val_loss: 0.0747 - val_Accuracy: 0.9770 - val_Precision: 0.9620 - val_Recall: 0.9449 - val_TP: 759.7000 - val_TN: 1081.4800 - val_FP: 24.5200 - val_FN: 44.3000\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0466 - Accuracy: 0.9838 - Precision: 0.9596 - Recall: 0.9516 - TP: 3208.7800 - TN: 5531.9199 - FP: 115.0800 - FN: 163.2200 - val_loss: 0.0748 - val_Accuracy: 0.9770 - val_Precision: 0.9616 - val_Recall: 0.9451 - val_TP: 759.9000 - val_TN: 1081.1400 - val_FP: 24.8600 - val_FN: 44.1000\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0463 - Accuracy: 0.9839 - Precision: 0.9587 - Recall: 0.9524 - TP: 3211.6001 - TN: 5528.0698 - FP: 118.9300 - FN: 160.4000 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9631 - val_Recall: 0.9447 - val_TP: 759.5300 - val_TN: 1082.7200 - val_FP: 23.2800 - val_FN: 44.4700\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0463 - Accuracy: 0.9838 - Precision: 0.9592 - Recall: 0.9520 - TP: 3210.0400 - TN: 5530.3599 - FP: 116.6400 - FN: 161.9600 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9624 - val_Recall: 0.9448 - val_TP: 759.6400 - val_TN: 1081.8700 - val_FP: 24.1300 - val_FN: 44.3600\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0466 - Accuracy: 0.9837 - Precision: 0.9592 - Recall: 0.9518 - TP: 3209.3201 - TN: 5530.3198 - FP: 116.6800 - FN: 162.6800 - val_loss: 0.0748 - val_Accuracy: 0.9770 - val_Precision: 0.9621 - val_Recall: 0.9449 - val_TP: 759.6800 - val_TN: 1081.6600 - val_FP: 24.3400 - val_FN: 44.3200\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0463 - Accuracy: 0.9838 - Precision: 0.9590 - Recall: 0.9520 - TP: 3210.0000 - TN: 5529.0400 - FP: 117.9600 - FN: 162.0000 - val_loss: 0.0749 - val_Accuracy: 0.9770 - val_Precision: 0.9620 - val_Recall: 0.9449 - val_TP: 759.7000 - val_TN: 1081.5601 - val_FP: 24.4400 - val_FN: 44.3000\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0463 - Accuracy: 0.9838 - Precision: 0.9587 - Recall: 0.9521 - TP: 3210.4800 - TN: 5528.0698 - FP: 118.9300 - FN: 161.5200 - val_loss: 0.0750 - val_Accuracy: 0.9770 - val_Precision: 0.9621 - val_Recall: 0.9448 - val_TP: 759.5800 - val_TN: 1081.6300 - val_FP: 24.3700 - val_FN: 44.4200\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0462 - Accuracy: 0.9839 - Precision: 0.9592 - Recall: 0.9520 - TP: 3210.1699 - TN: 5530.2202 - FP: 116.7800 - FN: 161.8300 - val_loss: 0.0749 - val_Accuracy: 0.9770 - val_Precision: 0.9625 - val_Recall: 0.9446 - val_TP: 759.4900 - val_TN: 1081.9700 - val_FP: 24.0300 - val_FN: 44.5100\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0464 - Accuracy: 0.9838 - Precision: 0.9590 - Recall: 0.9521 - TP: 3210.5000 - TN: 5529.1001 - FP: 117.9000 - FN: 161.5000 - val_loss: 0.0745 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9447 - val_TP: 759.5400 - val_TN: 1082.8000 - val_FP: 23.2000 - val_FN: 44.4600\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0462 - Accuracy: 0.9840 - Precision: 0.9593 - Recall: 0.9520 - TP: 3210.2500 - TN: 5530.4600 - FP: 116.5400 - FN: 161.7500 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9635 - val_Recall: 0.9448 - val_TP: 759.6100 - val_TN: 1083.1300 - val_FP: 22.8700 - val_FN: 44.3900\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0463 - Accuracy: 0.9839 - Precision: 0.9592 - Recall: 0.9518 - TP: 3209.6201 - TN: 5530.2402 - FP: 116.7600 - FN: 162.3800 - val_loss: 0.0752 - val_Accuracy: 0.9770 - val_Precision: 0.9619 - val_Recall: 0.9450 - val_TP: 759.7500 - val_TN: 1081.4399 - val_FP: 24.5600 - val_FN: 44.2500\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0461 - Accuracy: 0.9839 - Precision: 0.9593 - Recall: 0.9519 - TP: 3209.6699 - TN: 5530.4902 - FP: 116.5100 - FN: 162.3300 - val_loss: 0.0745 - val_Accuracy: 0.9770 - val_Precision: 0.9629 - val_Recall: 0.9450 - val_TP: 759.7600 - val_TN: 1082.5699 - val_FP: 23.4300 - val_FN: 44.2400\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0461 - Accuracy: 0.9837 - Precision: 0.9593 - Recall: 0.9519 - TP: 3209.8701 - TN: 5530.4399 - FP: 116.5600 - FN: 162.1300 - val_loss: 0.0749 - val_Accuracy: 0.9770 - val_Precision: 0.9621 - val_Recall: 0.9450 - val_TP: 759.7600 - val_TN: 1081.6400 - val_FP: 24.3600 - val_FN: 44.2400\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0461 - Accuracy: 0.9839 - Precision: 0.9591 - Recall: 0.9521 - TP: 3210.3601 - TN: 5530.0200 - FP: 116.9800 - FN: 161.6400 - val_loss: 0.0762 - val_Accuracy: 0.9764 - val_Precision: 0.9601 - val_Recall: 0.9450 - val_TP: 759.8200 - val_TN: 1079.5300 - val_FP: 26.4700 - val_FN: 44.1800\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0461 - Accuracy: 0.9838 - Precision: 0.9591 - Recall: 0.9522 - TP: 3210.7100 - TN: 5529.4600 - FP: 117.5400 - FN: 161.2900 - val_loss: 0.0754 - val_Accuracy: 0.9770 - val_Precision: 0.9616 - val_Recall: 0.9447 - val_TP: 759.5600 - val_TN: 1081.0699 - val_FP: 24.9300 - val_FN: 44.4400\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0461 - Accuracy: 0.9839 - Precision: 0.9591 - Recall: 0.9522 - TP: 3210.6799 - TN: 5529.7900 - FP: 117.2100 - FN: 161.3200 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9630 - val_Recall: 0.9448 - val_TP: 759.6200 - val_TN: 1082.6600 - val_FP: 23.3400 - val_FN: 44.3800\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0460 - Accuracy: 0.9838 - Precision: 0.9595 - Recall: 0.9521 - TP: 3210.4399 - TN: 5531.2300 - FP: 115.7700 - FN: 161.5600 - val_loss: 0.0745 - val_Accuracy: 0.9770 - val_Precision: 0.9628 - val_Recall: 0.9451 - val_TP: 759.8400 - val_TN: 1082.4600 - val_FP: 23.5400 - val_FN: 44.1600\n",
      "Epoch 30/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0461 - Accuracy: 0.9836 - Precision: 0.9590 - Recall: 0.9519 - TP: 3209.9299 - TN: 5529.3301 - FP: 117.6700 - FN: 162.0700 - val_loss: 0.0756 - val_Accuracy: 0.9764 - val_Precision: 0.9612 - val_Recall: 0.9449 - val_TP: 759.6800 - val_TN: 1080.7200 - val_FP: 25.2800 - val_FN: 44.3200\n",
      "Epoch 31/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0459 - Accuracy: 0.9839 - Precision: 0.9589 - Recall: 0.9524 - TP: 3211.3999 - TN: 5528.9702 - FP: 118.0300 - FN: 160.6000 - val_loss: 0.0747 - val_Accuracy: 0.9770 - val_Precision: 0.9628 - val_Recall: 0.9450 - val_TP: 759.7900 - val_TN: 1082.4500 - val_FP: 23.5500 - val_FN: 44.2100\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 7ms/step - loss: 0.0468 - Accuracy: 0.9835 - Precision: 0.9589 - Recall: 0.9520 - TP: 3210.0901 - TN: 5529.6299 - FP: 117.3700 - FN: 161.9100 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9447 - val_TP: 759.5200 - val_TN: 1082.9100 - val_FP: 23.0900 - val_FN: 44.4800\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0465 - Accuracy: 0.9837 - Precision: 0.9588 - Recall: 0.9519 - TP: 3209.8101 - TN: 5528.8398 - FP: 118.1600 - FN: 162.1900 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9636 - val_Recall: 0.9446 - val_TP: 759.4800 - val_TN: 1083.1801 - val_FP: 22.8200 - val_FN: 44.5200\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0464 - Accuracy: 0.9838 - Precision: 0.9591 - Recall: 0.9518 - TP: 3209.5200 - TN: 5530.2002 - FP: 116.8000 - FN: 162.4800 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9635 - val_Recall: 0.9446 - val_TP: 759.4800 - val_TN: 1083.0800 - val_FP: 22.9200 - val_FN: 44.5200\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0468 - Accuracy: 0.9833 - Precision: 0.9590 - Recall: 0.9515 - TP: 3208.4900 - TN: 5529.5698 - FP: 117.4300 - FN: 163.5100 - val_loss: 0.0751 - val_Accuracy: 0.9770 - val_Precision: 0.9619 - val_Recall: 0.9448 - val_TP: 759.6500 - val_TN: 1081.4000 - val_FP: 24.6000 - val_FN: 44.3500\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0464 - Accuracy: 0.9835 - Precision: 0.9595 - Recall: 0.9515 - TP: 3208.5500 - TN: 5531.4399 - FP: 115.5600 - FN: 163.4500 - val_loss: 0.0760 - val_Accuracy: 0.9764 - val_Precision: 0.9600 - val_Recall: 0.9450 - val_TP: 759.7600 - val_TN: 1079.4600 - val_FP: 26.5400 - val_FN: 44.2400\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0464 - Accuracy: 0.9840 - Precision: 0.9588 - Recall: 0.9522 - TP: 3210.8701 - TN: 5528.4702 - FP: 118.5300 - FN: 161.1300 - val_loss: 0.0748 - val_Accuracy: 0.9770 - val_Precision: 0.9620 - val_Recall: 0.9450 - val_TP: 759.7900 - val_TN: 1081.5000 - val_FP: 24.5000 - val_FN: 44.2100\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0463 - Accuracy: 0.9837 - Precision: 0.9592 - Recall: 0.9518 - TP: 3209.4399 - TN: 5530.2300 - FP: 116.7700 - FN: 162.5600 - val_loss: 0.0758 - val_Accuracy: 0.9764 - val_Precision: 0.9600 - val_Recall: 0.9451 - val_TP: 759.8900 - val_TN: 1079.4500 - val_FP: 26.5500 - val_FN: 44.1100\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0463 - Accuracy: 0.9838 - Precision: 0.9591 - Recall: 0.9521 - TP: 3210.4700 - TN: 5529.5000 - FP: 117.5000 - FN: 161.5300 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9624 - val_Recall: 0.9451 - val_TP: 759.8400 - val_TN: 1081.9000 - val_FP: 24.1000 - val_FN: 44.1600\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0462 - Accuracy: 0.9840 - Precision: 0.9590 - Recall: 0.9524 - TP: 3211.4099 - TN: 5529.7002 - FP: 117.3000 - FN: 160.5900 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9629 - val_Recall: 0.9450 - val_TP: 759.8200 - val_TN: 1082.5699 - val_FP: 23.4300 - val_FN: 44.1800\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0463 - Accuracy: 0.9838 - Precision: 0.9590 - Recall: 0.9519 - TP: 3209.9500 - TN: 5529.2900 - FP: 117.7100 - FN: 162.0500 - val_loss: 0.0749 - val_Accuracy: 0.9770 - val_Precision: 0.9621 - val_Recall: 0.9449 - val_TP: 759.7200 - val_TN: 1081.6700 - val_FP: 24.3300 - val_FN: 44.2800\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0461 - Accuracy: 0.9839 - Precision: 0.9594 - Recall: 0.9521 - TP: 3210.3899 - TN: 5530.8999 - FP: 116.1000 - FN: 161.6100 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9623 - val_Recall: 0.9451 - val_TP: 759.8300 - val_TN: 1081.8199 - val_FP: 24.1800 - val_FN: 44.1700\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0463 - Accuracy: 0.9838 - Precision: 0.9593 - Recall: 0.9519 - TP: 3209.9399 - TN: 5531.0200 - FP: 115.9800 - FN: 162.0600 - val_loss: 0.0748 - val_Accuracy: 0.9770 - val_Precision: 0.9621 - val_Recall: 0.9451 - val_TP: 759.8500 - val_TN: 1081.6300 - val_FP: 24.3700 - val_FN: 44.1500\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0462 - Accuracy: 0.9839 - Precision: 0.9588 - Recall: 0.9522 - TP: 3210.7900 - TN: 5528.3198 - FP: 118.6800 - FN: 161.2100 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9623 - val_Recall: 0.9451 - val_TP: 759.8400 - val_TN: 1081.8600 - val_FP: 24.1400 - val_FN: 44.1600\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0461 - Accuracy: 0.9838 - Precision: 0.9594 - Recall: 0.9519 - TP: 3209.7700 - TN: 5531.1401 - FP: 115.8600 - FN: 162.2300 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9625 - val_Recall: 0.9449 - val_TP: 759.7200 - val_TN: 1082.0500 - val_FP: 23.9500 - val_FN: 44.2800\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0461 - Accuracy: 0.9839 - Precision: 0.9593 - Recall: 0.9521 - TP: 3210.4800 - TN: 5530.7100 - FP: 116.2900 - FN: 161.5200 - val_loss: 0.0756 - val_Accuracy: 0.9770 - val_Precision: 0.9610 - val_Recall: 0.9451 - val_TP: 759.8700 - val_TN: 1080.4800 - val_FP: 25.5200 - val_FN: 44.1300\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0461 - Accuracy: 0.9835 - Precision: 0.9590 - Recall: 0.9517 - TP: 3209.0601 - TN: 5529.8999 - FP: 117.1000 - FN: 162.9400 - val_loss: 0.0749 - val_Accuracy: 0.9770 - val_Precision: 0.9620 - val_Recall: 0.9451 - val_TP: 759.8700 - val_TN: 1081.6000 - val_FP: 24.4000 - val_FN: 44.1300\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0460 - Accuracy: 0.9841 - Precision: 0.9591 - Recall: 0.9522 - TP: 3210.9299 - TN: 5529.8599 - FP: 117.1400 - FN: 161.0700 - val_loss: 0.0751 - val_Accuracy: 0.9770 - val_Precision: 0.9615 - val_Recall: 0.9453 - val_TP: 760.0400 - val_TN: 1081.1000 - val_FP: 24.9000 - val_FN: 43.9600\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0460 - Accuracy: 0.9840 - Precision: 0.9591 - Recall: 0.9525 - TP: 3211.6799 - TN: 5529.7002 - FP: 117.3000 - FN: 160.3200 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9631 - val_Recall: 0.9448 - val_TP: 759.6200 - val_TN: 1082.7100 - val_FP: 23.2900 - val_FN: 44.3800\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0459 - Accuracy: 0.9840 - Precision: 0.9592 - Recall: 0.9524 - TP: 3211.6599 - TN: 5530.3198 - FP: 116.6800 - FN: 160.3400 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9449 - val_TP: 759.6600 - val_TN: 1082.9399 - val_FP: 23.0600 - val_FN: 44.3400\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0460 - Accuracy: 0.9839 - Precision: 0.9593 - Recall: 0.9524 - TP: 3211.3601 - TN: 5530.8501 - FP: 116.1500 - FN: 160.6400 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9450 - val_TP: 759.7400 - val_TN: 1082.8400 - val_FP: 23.1600 - val_FN: 44.2600\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0460 - Accuracy: 0.9838 - Precision: 0.9591 - Recall: 0.9524 - TP: 3211.3899 - TN: 5529.6899 - FP: 117.3100 - FN: 160.6100 - val_loss: 0.0745 - val_Accuracy: 0.9770 - val_Precision: 0.9631 - val_Recall: 0.9450 - val_TP: 759.7500 - val_TN: 1082.7900 - val_FP: 23.2100 - val_FN: 44.2500\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0459 - Accuracy: 0.9839 - Precision: 0.9593 - Recall: 0.9523 - TP: 3211.2600 - TN: 5530.6299 - FP: 116.3700 - FN: 160.7400 - val_loss: 0.0753 - val_Accuracy: 0.9770 - val_Precision: 0.9621 - val_Recall: 0.9448 - val_TP: 759.6500 - val_TN: 1081.6300 - val_FP: 24.3700 - val_FN: 44.3500\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 5ms/step - loss: 0.0470 - Accuracy: 0.9839 - Precision: 0.9595 - Recall: 0.9520 - TP: 3210.0200 - TN: 5531.6602 - FP: 115.3400 - FN: 161.9800 - val_loss: 0.0736 - val_Accuracy: 0.9770 - val_Precision: 0.9635 - val_Recall: 0.9450 - val_TP: 759.7600 - val_TN: 1083.1400 - val_FP: 22.8600 - val_FN: 44.2400\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0466 - Accuracy: 0.9838 - Precision: 0.9592 - Recall: 0.9518 - TP: 3209.5801 - TN: 5530.5801 - FP: 116.4200 - FN: 162.4200 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9631 - val_Recall: 0.9450 - val_TP: 759.7500 - val_TN: 1082.7500 - val_FP: 23.2500 - val_FN: 44.2500\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0464 - Accuracy: 0.9836 - Precision: 0.9593 - Recall: 0.9519 - TP: 3209.8799 - TN: 5531.1899 - FP: 115.8100 - FN: 162.1200 - val_loss: 0.0750 - val_Accuracy: 0.9770 - val_Precision: 0.9617 - val_Recall: 0.9451 - val_TP: 759.8600 - val_TN: 1081.2600 - val_FP: 24.7400 - val_FN: 44.1400\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0464 - Accuracy: 0.9839 - Precision: 0.9588 - Recall: 0.9521 - TP: 3210.4299 - TN: 5528.2998 - FP: 118.7000 - FN: 161.5700 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9449 - val_TP: 759.6600 - val_TN: 1082.9600 - val_FP: 23.0400 - val_FN: 44.3400\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0462 - Accuracy: 0.9839 - Precision: 0.9594 - Recall: 0.9523 - TP: 3211.2100 - TN: 5531.5200 - FP: 115.4800 - FN: 160.7900 - val_loss: 0.0773 - val_Accuracy: 0.9759 - val_Precision: 0.9582 - val_Recall: 0.9451 - val_TP: 759.8700 - val_TN: 1077.6300 - val_FP: 28.3700 - val_FN: 44.1300\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0464 - Accuracy: 0.9834 - Precision: 0.9589 - Recall: 0.9520 - TP: 3210.2100 - TN: 5528.9399 - FP: 118.0600 - FN: 161.7900 - val_loss: 0.0753 - val_Accuracy: 0.9770 - val_Precision: 0.9611 - val_Recall: 0.9451 - val_TP: 759.8800 - val_TN: 1080.5601 - val_FP: 25.4400 - val_FN: 44.1200\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0462 - Accuracy: 0.9838 - Precision: 0.9593 - Recall: 0.9518 - TP: 3209.5300 - TN: 5530.6699 - FP: 116.3300 - FN: 162.4700 - val_loss: 0.0754 - val_Accuracy: 0.9770 - val_Precision: 0.9610 - val_Recall: 0.9451 - val_TP: 759.8400 - val_TN: 1080.5100 - val_FP: 25.4900 - val_FN: 44.1600\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0462 - Accuracy: 0.9837 - Precision: 0.9590 - Recall: 0.9522 - TP: 3210.6899 - TN: 5528.9902 - FP: 118.0100 - FN: 161.3100 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9630 - val_Recall: 0.9450 - val_TP: 759.7900 - val_TN: 1082.6899 - val_FP: 23.3100 - val_FN: 44.2100\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0464 - Accuracy: 0.9837 - Precision: 0.9589 - Recall: 0.9521 - TP: 3210.6001 - TN: 5529.4302 - FP: 117.5700 - FN: 161.4000 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9624 - val_Recall: 0.9450 - val_TP: 759.7600 - val_TN: 1081.9100 - val_FP: 24.0900 - val_FN: 44.2400\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0462 - Accuracy: 0.9838 - Precision: 0.9591 - Recall: 0.9520 - TP: 3210.0200 - TN: 5529.4902 - FP: 117.5100 - FN: 161.9800 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9450 - val_TP: 759.7700 - val_TN: 1082.9000 - val_FP: 23.1000 - val_FN: 44.2300\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0461 - Accuracy: 0.9838 - Precision: 0.9593 - Recall: 0.9522 - TP: 3210.6499 - TN: 5530.8799 - FP: 116.1200 - FN: 161.3500 - val_loss: 0.0764 - val_Accuracy: 0.9764 - val_Precision: 0.9602 - val_Recall: 0.9449 - val_TP: 759.6700 - val_TN: 1079.5900 - val_FP: 26.4100 - val_FN: 44.3300\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0462 - Accuracy: 0.9837 - Precision: 0.9595 - Recall: 0.9518 - TP: 3209.3999 - TN: 5531.4600 - FP: 115.5400 - FN: 162.6000 - val_loss: 0.0762 - val_Accuracy: 0.9764 - val_Precision: 0.9597 - val_Recall: 0.9452 - val_TP: 759.9500 - val_TN: 1079.2100 - val_FP: 26.7900 - val_FN: 44.0500\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0462 - Accuracy: 0.9837 - Precision: 0.9589 - Recall: 0.9521 - TP: 3210.5801 - TN: 5528.6401 - FP: 118.3600 - FN: 161.4200 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9629 - val_Recall: 0.9451 - val_TP: 759.8800 - val_TN: 1082.5900 - val_FP: 23.4100 - val_FN: 44.1200\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0462 - Accuracy: 0.9839 - Precision: 0.9593 - Recall: 0.9521 - TP: 3210.5000 - TN: 5530.7002 - FP: 116.3000 - FN: 161.5000 - val_loss: 0.0752 - val_Accuracy: 0.9770 - val_Precision: 0.9619 - val_Recall: 0.9450 - val_TP: 759.7600 - val_TN: 1081.4600 - val_FP: 24.5400 - val_FN: 44.2400\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0460 - Accuracy: 0.9839 - Precision: 0.9591 - Recall: 0.9524 - TP: 3211.5200 - TN: 5529.6699 - FP: 117.3300 - FN: 160.4800 - val_loss: 0.0752 - val_Accuracy: 0.9770 - val_Precision: 0.9618 - val_Recall: 0.9451 - val_TP: 759.8400 - val_TN: 1081.4000 - val_FP: 24.6000 - val_FN: 44.1600\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0459 - Accuracy: 0.9839 - Precision: 0.9593 - Recall: 0.9521 - TP: 3210.3401 - TN: 5530.5801 - FP: 116.4200 - FN: 161.6600 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9629 - val_Recall: 0.9450 - val_TP: 759.7800 - val_TN: 1082.5601 - val_FP: 23.4400 - val_FN: 44.2200\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0460 - Accuracy: 0.9839 - Precision: 0.9593 - Recall: 0.9523 - TP: 3211.1201 - TN: 5530.5298 - FP: 116.4700 - FN: 160.8800 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9450 - val_TP: 759.7700 - val_TN: 1082.9600 - val_FP: 23.0400 - val_FN: 44.2300\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0458 - Accuracy: 0.9839 - Precision: 0.9594 - Recall: 0.9521 - TP: 3210.5801 - TN: 5531.0601 - FP: 115.9400 - FN: 161.4200 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9637 - val_Recall: 0.9448 - val_TP: 759.6000 - val_TN: 1083.3000 - val_FP: 22.7000 - val_FN: 44.4000\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0460 - Accuracy: 0.9838 - Precision: 0.9597 - Recall: 0.9523 - TP: 3211.1799 - TN: 5532.6699 - FP: 114.3300 - FN: 160.8200 - val_loss: 0.0774 - val_Accuracy: 0.9759 - val_Precision: 0.9582 - val_Recall: 0.9452 - val_TP: 759.9800 - val_TN: 1077.6500 - val_FP: 28.3500 - val_FN: 44.0200\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0460 - Accuracy: 0.9838 - Precision: 0.9592 - Recall: 0.9524 - TP: 3211.5500 - TN: 5530.0000 - FP: 117.0000 - FN: 160.4500 - val_loss: 0.0753 - val_Accuracy: 0.9770 - val_Precision: 0.9619 - val_Recall: 0.9450 - val_TP: 759.8100 - val_TN: 1081.4900 - val_FP: 24.5100 - val_FN: 44.1900\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0458 - Accuracy: 0.9843 - Precision: 0.9593 - Recall: 0.9526 - TP: 3212.1299 - TN: 5530.4399 - FP: 116.5600 - FN: 159.8700 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9635 - val_Recall: 0.9450 - val_TP: 759.7600 - val_TN: 1083.1899 - val_FP: 22.8100 - val_FN: 44.2400\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 8ms/step - loss: 0.0482 - Accuracy: 0.9836 - Precision: 0.9595 - Recall: 0.9516 - TP: 3208.6499 - TN: 5531.9502 - FP: 115.0500 - FN: 163.3500 - val_loss: 0.0744 - val_Accuracy: 0.9764 - val_Precision: 0.9628 - val_Recall: 0.9450 - val_TP: 759.7600 - val_TN: 1082.4600 - val_FP: 23.5400 - val_FN: 44.2400\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0465 - Accuracy: 0.9835 - Precision: 0.9588 - Recall: 0.9522 - TP: 3210.8301 - TN: 5528.6899 - FP: 118.3100 - FN: 161.1700 - val_loss: 0.0747 - val_Accuracy: 0.9770 - val_Precision: 0.9624 - val_Recall: 0.9448 - val_TP: 759.6200 - val_TN: 1081.9000 - val_FP: 24.1000 - val_FN: 44.3800\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0464 - Accuracy: 0.9837 - Precision: 0.9591 - Recall: 0.9519 - TP: 3209.7000 - TN: 5529.9102 - FP: 117.0900 - FN: 162.3000 - val_loss: 0.0748 - val_Accuracy: 0.9770 - val_Precision: 0.9625 - val_Recall: 0.9447 - val_TP: 759.5600 - val_TN: 1082.0000 - val_FP: 24.0000 - val_FN: 44.4400\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0465 - Accuracy: 0.9840 - Precision: 0.9590 - Recall: 0.9519 - TP: 3209.8999 - TN: 5529.4199 - FP: 117.5800 - FN: 162.1000 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9450 - val_TP: 759.7500 - val_TN: 1082.9000 - val_FP: 23.1000 - val_FN: 44.2500\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0462 - Accuracy: 0.9841 - Precision: 0.9591 - Recall: 0.9522 - TP: 3210.8201 - TN: 5530.0400 - FP: 116.9600 - FN: 161.1800 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9634 - val_Recall: 0.9449 - val_TP: 759.6800 - val_TN: 1083.0800 - val_FP: 22.9200 - val_FN: 44.3200\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0464 - Accuracy: 0.9837 - Precision: 0.9592 - Recall: 0.9517 - TP: 3209.0300 - TN: 5530.2402 - FP: 116.7600 - FN: 162.9700 - val_loss: 0.0745 - val_Accuracy: 0.9770 - val_Precision: 0.9625 - val_Recall: 0.9450 - val_TP: 759.7600 - val_TN: 1082.0400 - val_FP: 23.9600 - val_FN: 44.2400\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0462 - Accuracy: 0.9837 - Precision: 0.9592 - Recall: 0.9520 - TP: 3210.2000 - TN: 5530.6299 - FP: 116.3700 - FN: 161.8000 - val_loss: 0.0773 - val_Accuracy: 0.9759 - val_Precision: 0.9580 - val_Recall: 0.9452 - val_TP: 759.9800 - val_TN: 1077.4500 - val_FP: 28.5500 - val_FN: 44.0200\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0463 - Accuracy: 0.9838 - Precision: 0.9587 - Recall: 0.9524 - TP: 3211.3799 - TN: 5528.1001 - FP: 118.9000 - FN: 160.6200 - val_loss: 0.0755 - val_Accuracy: 0.9764 - val_Precision: 0.9608 - val_Recall: 0.9452 - val_TP: 759.9400 - val_TN: 1080.2900 - val_FP: 25.7100 - val_FN: 44.0600\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0463 - Accuracy: 0.9840 - Precision: 0.9591 - Recall: 0.9523 - TP: 3211.0500 - TN: 5529.7100 - FP: 117.2900 - FN: 160.9500 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9638 - val_Recall: 0.9447 - val_TP: 759.5200 - val_TN: 1083.4301 - val_FP: 22.5700 - val_FN: 44.4800\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0462 - Accuracy: 0.9837 - Precision: 0.9595 - Recall: 0.9519 - TP: 3209.6699 - TN: 5531.6802 - FP: 115.3200 - FN: 162.3300 - val_loss: 0.0751 - val_Accuracy: 0.9770 - val_Precision: 0.9620 - val_Recall: 0.9450 - val_TP: 759.7600 - val_TN: 1081.5900 - val_FP: 24.4100 - val_FN: 44.2400\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0461 - Accuracy: 0.9838 - Precision: 0.9590 - Recall: 0.9523 - TP: 3211.1201 - TN: 5529.1499 - FP: 117.8500 - FN: 160.8800 - val_loss: 0.0754 - val_Accuracy: 0.9770 - val_Precision: 0.9615 - val_Recall: 0.9449 - val_TP: 759.7100 - val_TN: 1080.9399 - val_FP: 25.0600 - val_FN: 44.2900\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0463 - Accuracy: 0.9838 - Precision: 0.9591 - Recall: 0.9519 - TP: 3209.7600 - TN: 5529.7300 - FP: 117.2700 - FN: 162.2400 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9635 - val_Recall: 0.9448 - val_TP: 759.6400 - val_TN: 1083.1801 - val_FP: 22.8200 - val_FN: 44.3600\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0463 - Accuracy: 0.9839 - Precision: 0.9593 - Recall: 0.9520 - TP: 3210.0000 - TN: 5530.7798 - FP: 116.2200 - FN: 162.0000 - val_loss: 0.0751 - val_Accuracy: 0.9770 - val_Precision: 0.9620 - val_Recall: 0.9450 - val_TP: 759.8000 - val_TN: 1081.5800 - val_FP: 24.4200 - val_FN: 44.2000\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0461 - Accuracy: 0.9839 - Precision: 0.9593 - Recall: 0.9522 - TP: 3210.8501 - TN: 5530.2598 - FP: 116.7400 - FN: 161.1500 - val_loss: 0.0749 - val_Accuracy: 0.9770 - val_Precision: 0.9621 - val_Recall: 0.9451 - val_TP: 759.8800 - val_TN: 1081.6600 - val_FP: 24.3400 - val_FN: 44.1200\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0460 - Accuracy: 0.9838 - Precision: 0.9588 - Recall: 0.9521 - TP: 3210.5901 - TN: 5528.7002 - FP: 118.3000 - FN: 161.4100 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9636 - val_Recall: 0.9448 - val_TP: 759.6300 - val_TN: 1083.2300 - val_FP: 22.7700 - val_FN: 44.3700\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0460 - Accuracy: 0.9839 - Precision: 0.9593 - Recall: 0.9523 - TP: 3211.0200 - TN: 5530.8501 - FP: 116.1500 - FN: 160.9800 - val_loss: 0.0755 - val_Accuracy: 0.9770 - val_Precision: 0.9613 - val_Recall: 0.9450 - val_TP: 759.7700 - val_TN: 1080.8300 - val_FP: 25.1700 - val_FN: 44.2300\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0459 - Accuracy: 0.9840 - Precision: 0.9594 - Recall: 0.9524 - TP: 3211.5901 - TN: 5531.0098 - FP: 115.9900 - FN: 160.4100 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9450 - val_TP: 759.8200 - val_TN: 1082.9000 - val_FP: 23.1000 - val_FN: 44.1800\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0462 - Accuracy: 0.9837 - Precision: 0.9595 - Recall: 0.9521 - TP: 3210.3899 - TN: 5531.5298 - FP: 115.4700 - FN: 161.6100 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9631 - val_Recall: 0.9449 - val_TP: 759.6900 - val_TN: 1082.7800 - val_FP: 23.2200 - val_FN: 44.3100\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0458 - Accuracy: 0.9840 - Precision: 0.9591 - Recall: 0.9528 - TP: 3212.8201 - TN: 5529.9302 - FP: 117.0700 - FN: 159.1800 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9637 - val_Recall: 0.9450 - val_TP: 759.7800 - val_TN: 1083.4000 - val_FP: 22.6000 - val_FN: 44.2200\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0458 - Accuracy: 0.9840 - Precision: 0.9592 - Recall: 0.9523 - TP: 3211.2200 - TN: 5530.5000 - FP: 116.5000 - FN: 160.7800 - val_loss: 0.0745 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9449 - val_TP: 759.6900 - val_TN: 1082.9600 - val_FP: 23.0400 - val_FN: 44.3100\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0459 - Accuracy: 0.9839 - Precision: 0.9594 - Recall: 0.9522 - TP: 3210.8301 - TN: 5531.0601 - FP: 115.9400 - FN: 161.1700 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9634 - val_Recall: 0.9449 - val_TP: 759.7300 - val_TN: 1083.0400 - val_FP: 22.9600 - val_FN: 44.2700\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0460 - Accuracy: 0.9837 - Precision: 0.9594 - Recall: 0.9521 - TP: 3210.5901 - TN: 5531.2202 - FP: 115.7800 - FN: 161.4100 - val_loss: 0.0745 - val_Accuracy: 0.9770 - val_Precision: 0.9630 - val_Recall: 0.9452 - val_TP: 759.9100 - val_TN: 1082.6899 - val_FP: 23.3100 - val_FN: 44.0900\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0457 - Accuracy: 0.9838 - Precision: 0.9596 - Recall: 0.9523 - TP: 3211.1001 - TN: 5532.1899 - FP: 114.8100 - FN: 160.9000 - val_loss: 0.0749 - val_Accuracy: 0.9770 - val_Precision: 0.9622 - val_Recall: 0.9452 - val_TP: 759.9600 - val_TN: 1081.7200 - val_FP: 24.2800 - val_FN: 44.0400\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0457 - Accuracy: 0.9837 - Precision: 0.9590 - Recall: 0.9528 - TP: 3212.7700 - TN: 5529.1201 - FP: 117.8800 - FN: 159.2300 - val_loss: 0.0747 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9449 - val_TP: 759.7200 - val_TN: 1082.8400 - val_FP: 23.1600 - val_FN: 44.2800\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0457 - Accuracy: 0.9836 - Precision: 0.9596 - Recall: 0.9523 - TP: 3211.2700 - TN: 5531.9702 - FP: 115.0300 - FN: 160.7300 - val_loss: 0.0745 - val_Accuracy: 0.9770 - val_Precision: 0.9636 - val_Recall: 0.9449 - val_TP: 759.6600 - val_TN: 1083.2100 - val_FP: 22.7900 - val_FN: 44.3400\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0456 - Accuracy: 0.9839 - Precision: 0.9597 - Recall: 0.9525 - TP: 3211.8201 - TN: 5532.3398 - FP: 114.6600 - FN: 160.1800 - val_loss: 0.0759 - val_Accuracy: 0.9764 - val_Precision: 0.9607 - val_Recall: 0.9454 - val_TP: 760.1300 - val_TN: 1080.2800 - val_FP: 25.7200 - val_FN: 43.8700\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0455 - Accuracy: 0.9835 - Precision: 0.9592 - Recall: 0.9528 - TP: 3212.7200 - TN: 5529.9600 - FP: 117.0400 - FN: 159.2800 - val_loss: 0.0747 - val_Accuracy: 0.9770 - val_Precision: 0.9629 - val_Recall: 0.9451 - val_TP: 759.9000 - val_TN: 1082.5601 - val_FP: 23.4400 - val_FN: 44.1000\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0456 - Accuracy: 0.9838 - Precision: 0.9596 - Recall: 0.9528 - TP: 3212.8799 - TN: 5531.7598 - FP: 115.2400 - FN: 159.1200 - val_loss: 0.0745 - val_Accuracy: 0.9770 - val_Precision: 0.9636 - val_Recall: 0.9449 - val_TP: 759.6700 - val_TN: 1083.2000 - val_FP: 22.8000 - val_FN: 44.3300\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0456 - Accuracy: 0.9837 - Precision: 0.9594 - Recall: 0.9523 - TP: 3211.2900 - TN: 5531.2998 - FP: 115.7000 - FN: 160.7100 - val_loss: 0.0748 - val_Accuracy: 0.9770 - val_Precision: 0.9631 - val_Recall: 0.9450 - val_TP: 759.7500 - val_TN: 1082.8000 - val_FP: 23.2000 - val_FN: 44.2500\n",
      "Epoch 30/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0456 - Accuracy: 0.9838 - Precision: 0.9595 - Recall: 0.9527 - TP: 3212.3601 - TN: 5531.3301 - FP: 115.6700 - FN: 159.6400 - val_loss: 0.0748 - val_Accuracy: 0.9770 - val_Precision: 0.9629 - val_Recall: 0.9451 - val_TP: 759.9000 - val_TN: 1082.6000 - val_FP: 23.4000 - val_FN: 44.1000\n",
      "Epoch 31/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0456 - Accuracy: 0.9838 - Precision: 0.9600 - Recall: 0.9523 - TP: 3211.2400 - TN: 5533.5000 - FP: 113.5000 - FN: 160.7600 - val_loss: 0.0745 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9452 - val_TP: 759.9100 - val_TN: 1082.9301 - val_FP: 23.0700 - val_FN: 44.0900\n",
      "Epoch 32/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0453 - Accuracy: 0.9838 - Precision: 0.9592 - Recall: 0.9529 - TP: 3213.2200 - TN: 5530.2700 - FP: 116.7300 - FN: 158.7800 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9453 - val_TP: 759.9900 - val_TN: 1082.8800 - val_FP: 23.1200 - val_FN: 44.0100\n",
      "Epoch 33/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0455 - Accuracy: 0.9836 - Precision: 0.9600 - Recall: 0.9524 - TP: 3211.3401 - TN: 5533.6401 - FP: 113.3600 - FN: 160.6600 - val_loss: 0.0756 - val_Accuracy: 0.9770 - val_Precision: 0.9617 - val_Recall: 0.9453 - val_TP: 760.0200 - val_TN: 1081.3000 - val_FP: 24.7000 - val_FN: 43.9800\n",
      "Epoch 34/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0454 - Accuracy: 0.9843 - Precision: 0.9590 - Recall: 0.9531 - TP: 3213.8799 - TN: 5529.5200 - FP: 117.4800 - FN: 158.1200 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9451 - val_TP: 759.8400 - val_TN: 1083.0200 - val_FP: 22.9800 - val_FN: 44.1600\n",
      "Epoch 35/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0456 - Accuracy: 0.9840 - Precision: 0.9598 - Recall: 0.9526 - TP: 3212.0601 - TN: 5532.9800 - FP: 114.0200 - FN: 159.9400 - val_loss: 0.0751 - val_Accuracy: 0.9770 - val_Precision: 0.9626 - val_Recall: 0.9451 - val_TP: 759.8400 - val_TN: 1082.1300 - val_FP: 23.8700 - val_FN: 44.1600\n",
      "Epoch 36/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0453 - Accuracy: 0.9841 - Precision: 0.9597 - Recall: 0.9529 - TP: 3213.0500 - TN: 5532.4199 - FP: 114.5800 - FN: 158.9500 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9451 - val_TP: 759.8900 - val_TN: 1083.0100 - val_FP: 22.9900 - val_FN: 44.1100\n",
      "Epoch 37/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0452 - Accuracy: 0.9840 - Precision: 0.9596 - Recall: 0.9529 - TP: 3213.0601 - TN: 5531.8501 - FP: 115.1500 - FN: 158.9400 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9634 - val_Recall: 0.9451 - val_TP: 759.8500 - val_TN: 1083.1100 - val_FP: 22.8900 - val_FN: 44.1500\n",
      "Epoch 38/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0452 - Accuracy: 0.9840 - Precision: 0.9598 - Recall: 0.9528 - TP: 3212.9199 - TN: 5532.7002 - FP: 114.3000 - FN: 159.0800 - val_loss: 0.0752 - val_Accuracy: 0.9770 - val_Precision: 0.9620 - val_Recall: 0.9454 - val_TP: 760.1200 - val_TN: 1081.6300 - val_FP: 24.3700 - val_FN: 43.8800\n",
      "Epoch 39/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0453 - Accuracy: 0.9838 - Precision: 0.9596 - Recall: 0.9526 - TP: 3212.0601 - TN: 5531.9600 - FP: 115.0400 - FN: 159.9400 - val_loss: 0.0758 - val_Accuracy: 0.9764 - val_Precision: 0.9612 - val_Recall: 0.9453 - val_TP: 760.0400 - val_TN: 1080.7200 - val_FP: 25.2800 - val_FN: 43.9600\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 6ms/step - loss: 0.0463 - Accuracy: 0.9841 - Precision: 0.9596 - Recall: 0.9524 - TP: 3211.6499 - TN: 5532.4199 - FP: 114.5800 - FN: 160.3500 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9634 - val_Recall: 0.9448 - val_TP: 759.6300 - val_TN: 1083.0601 - val_FP: 22.9400 - val_FN: 44.3700\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0458 - Accuracy: 0.9838 - Precision: 0.9592 - Recall: 0.9527 - TP: 3212.5400 - TN: 5530.5200 - FP: 116.4800 - FN: 159.4600 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9635 - val_Recall: 0.9448 - val_TP: 759.6300 - val_TN: 1083.1500 - val_FP: 22.8500 - val_FN: 44.3700\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0459 - Accuracy: 0.9841 - Precision: 0.9596 - Recall: 0.9523 - TP: 3211.0801 - TN: 5532.0298 - FP: 114.9700 - FN: 160.9200 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9637 - val_Recall: 0.9450 - val_TP: 759.8200 - val_TN: 1083.4000 - val_FP: 22.6000 - val_FN: 44.1800\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0459 - Accuracy: 0.9838 - Precision: 0.9598 - Recall: 0.9521 - TP: 3210.3501 - TN: 5532.8301 - FP: 114.1700 - FN: 161.6500 - val_loss: 0.0760 - val_Accuracy: 0.9764 - val_Precision: 0.9607 - val_Recall: 0.9453 - val_TP: 760.0500 - val_TN: 1080.2100 - val_FP: 25.7900 - val_FN: 43.9500\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0458 - Accuracy: 0.9840 - Precision: 0.9595 - Recall: 0.9524 - TP: 3211.5400 - TN: 5531.3501 - FP: 115.6500 - FN: 160.4600 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9453 - val_TP: 760.0200 - val_TN: 1082.8600 - val_FP: 23.1400 - val_FN: 43.9800\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0457 - Accuracy: 0.9836 - Precision: 0.9592 - Recall: 0.9529 - TP: 3213.0701 - TN: 5530.3398 - FP: 116.6600 - FN: 158.9300 - val_loss: 0.0745 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9451 - val_TP: 759.8700 - val_TN: 1082.9600 - val_FP: 23.0400 - val_FN: 44.1300\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0457 - Accuracy: 0.9837 - Precision: 0.9597 - Recall: 0.9522 - TP: 3210.7500 - TN: 5532.3501 - FP: 114.6500 - FN: 161.2500 - val_loss: 0.0748 - val_Accuracy: 0.9770 - val_Precision: 0.9629 - val_Recall: 0.9451 - val_TP: 759.8600 - val_TN: 1082.5900 - val_FP: 23.4100 - val_FN: 44.1400\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0458 - Accuracy: 0.9840 - Precision: 0.9589 - Recall: 0.9527 - TP: 3212.6699 - TN: 5528.6602 - FP: 118.3400 - FN: 159.3300 - val_loss: 0.0750 - val_Accuracy: 0.9770 - val_Precision: 0.9620 - val_Recall: 0.9455 - val_TP: 760.1700 - val_TN: 1081.5800 - val_FP: 24.4200 - val_FN: 43.8300\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0456 - Accuracy: 0.9838 - Precision: 0.9597 - Recall: 0.9524 - TP: 3211.4900 - TN: 5532.5000 - FP: 114.5000 - FN: 160.5100 - val_loss: 0.0748 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9449 - val_TP: 759.7200 - val_TN: 1082.8900 - val_FP: 23.1100 - val_FN: 44.2800\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0456 - Accuracy: 0.9840 - Precision: 0.9596 - Recall: 0.9526 - TP: 3212.1799 - TN: 5531.6602 - FP: 115.3400 - FN: 159.8200 - val_loss: 0.0749 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9449 - val_TP: 759.6800 - val_TN: 1082.9100 - val_FP: 23.0900 - val_FN: 44.3200\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0458 - Accuracy: 0.9838 - Precision: 0.9593 - Recall: 0.9527 - TP: 3212.3401 - TN: 5530.9800 - FP: 116.0200 - FN: 159.6600 - val_loss: 0.0748 - val_Accuracy: 0.9770 - val_Precision: 0.9629 - val_Recall: 0.9452 - val_TP: 759.9200 - val_TN: 1082.6500 - val_FP: 23.3500 - val_FN: 44.0800\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0455 - Accuracy: 0.9838 - Precision: 0.9596 - Recall: 0.9527 - TP: 3212.5701 - TN: 5531.8398 - FP: 115.1600 - FN: 159.4300 - val_loss: 0.0767 - val_Accuracy: 0.9764 - val_Precision: 0.9604 - val_Recall: 0.9449 - val_TP: 759.7200 - val_TN: 1079.9000 - val_FP: 26.1000 - val_FN: 44.2800\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0454 - Accuracy: 0.9840 - Precision: 0.9597 - Recall: 0.9529 - TP: 3213.0200 - TN: 5532.2100 - FP: 114.7900 - FN: 158.9800 - val_loss: 0.0754 - val_Accuracy: 0.9770 - val_Precision: 0.9622 - val_Recall: 0.9450 - val_TP: 759.8100 - val_TN: 1081.7900 - val_FP: 24.2100 - val_FN: 44.1900\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0455 - Accuracy: 0.9835 - Precision: 0.9596 - Recall: 0.9524 - TP: 3211.5000 - TN: 5531.7798 - FP: 115.2200 - FN: 160.5000 - val_loss: 0.0751 - val_Accuracy: 0.9770 - val_Precision: 0.9626 - val_Recall: 0.9450 - val_TP: 759.7900 - val_TN: 1082.2100 - val_FP: 23.7900 - val_FN: 44.2100\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0454 - Accuracy: 0.9838 - Precision: 0.9599 - Recall: 0.9524 - TP: 3211.4299 - TN: 5533.0298 - FP: 113.9700 - FN: 160.5700 - val_loss: 0.0757 - val_Accuracy: 0.9770 - val_Precision: 0.9610 - val_Recall: 0.9455 - val_TP: 760.1600 - val_TN: 1080.5100 - val_FP: 25.4900 - val_FN: 43.8400\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0453 - Accuracy: 0.9840 - Precision: 0.9596 - Recall: 0.9528 - TP: 3212.9299 - TN: 5531.5098 - FP: 115.4900 - FN: 159.0700 - val_loss: 0.0745 - val_Accuracy: 0.9770 - val_Precision: 0.9631 - val_Recall: 0.9453 - val_TP: 760.0200 - val_TN: 1082.8199 - val_FP: 23.1800 - val_FN: 43.9800\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0454 - Accuracy: 0.9840 - Precision: 0.9596 - Recall: 0.9529 - TP: 3213.0500 - TN: 5531.6602 - FP: 115.3400 - FN: 158.9500 - val_loss: 0.0747 - val_Accuracy: 0.9770 - val_Precision: 0.9629 - val_Recall: 0.9453 - val_TP: 760.0600 - val_TN: 1082.5800 - val_FP: 23.4200 - val_FN: 43.9400\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0452 - Accuracy: 0.9840 - Precision: 0.9595 - Recall: 0.9531 - TP: 3213.8501 - TN: 5531.7002 - FP: 115.3000 - FN: 158.1500 - val_loss: 0.0748 - val_Accuracy: 0.9770 - val_Precision: 0.9631 - val_Recall: 0.9452 - val_TP: 759.9400 - val_TN: 1082.7600 - val_FP: 23.2400 - val_FN: 44.0600\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0453 - Accuracy: 0.9837 - Precision: 0.9597 - Recall: 0.9528 - TP: 3212.6899 - TN: 5532.4800 - FP: 114.5200 - FN: 159.3100 - val_loss: 0.0754 - val_Accuracy: 0.9770 - val_Precision: 0.9618 - val_Recall: 0.9454 - val_TP: 760.1200 - val_TN: 1081.4100 - val_FP: 24.5900 - val_FN: 43.8800\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0452 - Accuracy: 0.9840 - Precision: 0.9596 - Recall: 0.9529 - TP: 3213.2300 - TN: 5531.9399 - FP: 115.0600 - FN: 158.7700 - val_loss: 0.0749 - val_Accuracy: 0.9770 - val_Precision: 0.9628 - val_Recall: 0.9453 - val_TP: 760.0400 - val_TN: 1082.5100 - val_FP: 23.4900 - val_FN: 43.9600\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0452 - Accuracy: 0.9840 - Precision: 0.9597 - Recall: 0.9530 - TP: 3213.4800 - TN: 5532.3999 - FP: 114.6000 - FN: 158.5200 - val_loss: 0.0748 - val_Accuracy: 0.9770 - val_Precision: 0.9628 - val_Recall: 0.9454 - val_TP: 760.0800 - val_TN: 1082.5699 - val_FP: 23.4300 - val_FN: 43.9200\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0453 - Accuracy: 0.9840 - Precision: 0.9597 - Recall: 0.9528 - TP: 3212.9900 - TN: 5532.3501 - FP: 114.6500 - FN: 159.0100 - val_loss: 0.0753 - val_Accuracy: 0.9770 - val_Precision: 0.9623 - val_Recall: 0.9452 - val_TP: 759.9400 - val_TN: 1081.8700 - val_FP: 24.1300 - val_FN: 44.0600\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0452 - Accuracy: 0.9838 - Precision: 0.9600 - Recall: 0.9527 - TP: 3212.4299 - TN: 5533.1899 - FP: 113.8100 - FN: 159.5700 - val_loss: 0.0753 - val_Accuracy: 0.9770 - val_Precision: 0.9622 - val_Recall: 0.9454 - val_TP: 760.0700 - val_TN: 1081.7900 - val_FP: 24.2100 - val_FN: 43.9300\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 5ms/step - loss: 0.0465 - Accuracy: 0.9841 - Precision: 0.9600 - Recall: 0.9526 - TP: 3212.0601 - TN: 5534.2100 - FP: 112.7900 - FN: 159.9400 - val_loss: 0.0772 - val_Accuracy: 0.9764 - val_Precision: 0.9581 - val_Recall: 0.9458 - val_TP: 760.4500 - val_TN: 1077.6100 - val_FP: 28.3900 - val_FN: 43.5500\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0460 - Accuracy: 0.9840 - Precision: 0.9587 - Recall: 0.9528 - TP: 3212.7800 - TN: 5528.1802 - FP: 118.8200 - FN: 159.2200 - val_loss: 0.0745 - val_Accuracy: 0.9770 - val_Precision: 0.9630 - val_Recall: 0.9453 - val_TP: 760.0000 - val_TN: 1082.6500 - val_FP: 23.3500 - val_FN: 44.0000\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0458 - Accuracy: 0.9839 - Precision: 0.9599 - Recall: 0.9523 - TP: 3211.1299 - TN: 5533.2002 - FP: 113.8000 - FN: 160.8700 - val_loss: 0.0757 - val_Accuracy: 0.9770 - val_Precision: 0.9611 - val_Recall: 0.9453 - val_TP: 759.9900 - val_TN: 1080.6300 - val_FP: 25.3700 - val_FN: 44.0100\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0456 - Accuracy: 0.9841 - Precision: 0.9592 - Recall: 0.9526 - TP: 3212.1399 - TN: 5530.0200 - FP: 116.9800 - FN: 159.8600 - val_loss: 0.0745 - val_Accuracy: 0.9770 - val_Precision: 0.9636 - val_Recall: 0.9450 - val_TP: 759.7800 - val_TN: 1083.2200 - val_FP: 22.7800 - val_FN: 44.2200\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0457 - Accuracy: 0.9840 - Precision: 0.9595 - Recall: 0.9526 - TP: 3212.0500 - TN: 5531.6602 - FP: 115.3400 - FN: 159.9500 - val_loss: 0.0758 - val_Accuracy: 0.9764 - val_Precision: 0.9609 - val_Recall: 0.9454 - val_TP: 760.1200 - val_TN: 1080.4301 - val_FP: 25.5700 - val_FN: 43.8800\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0457 - Accuracy: 0.9839 - Precision: 0.9590 - Recall: 0.9532 - TP: 3214.2000 - TN: 5529.3501 - FP: 117.6500 - FN: 157.8000 - val_loss: 0.0742 - val_Accuracy: 0.9770 - val_Precision: 0.9641 - val_Recall: 0.9449 - val_TP: 759.6800 - val_TN: 1083.7300 - val_FP: 22.2700 - val_FN: 44.3200\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0456 - Accuracy: 0.9837 - Precision: 0.9597 - Recall: 0.9524 - TP: 3211.5601 - TN: 5532.5801 - FP: 114.4200 - FN: 160.4400 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9453 - val_TP: 760.0300 - val_TN: 1082.9301 - val_FP: 23.0700 - val_FN: 43.9700\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0456 - Accuracy: 0.9839 - Precision: 0.9597 - Recall: 0.9527 - TP: 3212.6499 - TN: 5532.5298 - FP: 114.4700 - FN: 159.3500 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9637 - val_Recall: 0.9450 - val_TP: 759.8000 - val_TN: 1083.3600 - val_FP: 22.6400 - val_FN: 44.2000\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0456 - Accuracy: 0.9841 - Precision: 0.9598 - Recall: 0.9525 - TP: 3211.8799 - TN: 5532.9502 - FP: 114.0500 - FN: 160.1200 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9453 - val_TP: 760.0500 - val_TN: 1082.9100 - val_FP: 23.0900 - val_FN: 43.9500\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0456 - Accuracy: 0.9838 - Precision: 0.9594 - Recall: 0.9528 - TP: 3212.8701 - TN: 5531.2202 - FP: 115.7800 - FN: 159.1300 - val_loss: 0.0752 - val_Accuracy: 0.9770 - val_Precision: 0.9623 - val_Recall: 0.9453 - val_TP: 760.0100 - val_TN: 1081.8600 - val_FP: 24.1400 - val_FN: 43.9900\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0456 - Accuracy: 0.9843 - Precision: 0.9596 - Recall: 0.9528 - TP: 3212.7100 - TN: 5531.8701 - FP: 115.1300 - FN: 159.2900 - val_loss: 0.0751 - val_Accuracy: 0.9770 - val_Precision: 0.9621 - val_Recall: 0.9454 - val_TP: 760.0900 - val_TN: 1081.6700 - val_FP: 24.3300 - val_FN: 43.9100\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0454 - Accuracy: 0.9845 - Precision: 0.9597 - Recall: 0.9527 - TP: 3212.6101 - TN: 5532.3198 - FP: 114.6800 - FN: 159.3900 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9637 - val_Recall: 0.9451 - val_TP: 759.8600 - val_TN: 1083.3500 - val_FP: 22.6500 - val_FN: 44.1400\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0453 - Accuracy: 0.9844 - Precision: 0.9597 - Recall: 0.9530 - TP: 3213.4099 - TN: 5532.4600 - FP: 114.5400 - FN: 158.5900 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9456 - val_TP: 760.2400 - val_TN: 1082.8700 - val_FP: 23.1300 - val_FN: 43.7600\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0454 - Accuracy: 0.9840 - Precision: 0.9596 - Recall: 0.9528 - TP: 3212.9900 - TN: 5532.2598 - FP: 114.7400 - FN: 159.0100 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9630 - val_Recall: 0.9454 - val_TP: 760.1200 - val_TN: 1082.7200 - val_FP: 23.2800 - val_FN: 43.8800\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0454 - Accuracy: 0.9838 - Precision: 0.9597 - Recall: 0.9528 - TP: 3212.7100 - TN: 5532.3599 - FP: 114.6400 - FN: 159.2900 - val_loss: 0.0747 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9453 - val_TP: 759.9900 - val_TN: 1082.9700 - val_FP: 23.0300 - val_FN: 44.0100\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0454 - Accuracy: 0.9844 - Precision: 0.9596 - Recall: 0.9529 - TP: 3213.0801 - TN: 5531.7202 - FP: 115.2800 - FN: 158.9200 - val_loss: 0.0759 - val_Accuracy: 0.9764 - val_Precision: 0.9610 - val_Recall: 0.9455 - val_TP: 760.1500 - val_TN: 1080.5900 - val_FP: 25.4100 - val_FN: 43.8500\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0451 - Accuracy: 0.9840 - Precision: 0.9594 - Recall: 0.9532 - TP: 3214.2700 - TN: 5531.2598 - FP: 115.7400 - FN: 157.7300 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9636 - val_Recall: 0.9451 - val_TP: 759.8600 - val_TN: 1083.2800 - val_FP: 22.7200 - val_FN: 44.1400\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0453 - Accuracy: 0.9840 - Precision: 0.9597 - Recall: 0.9530 - TP: 3213.3601 - TN: 5532.3501 - FP: 114.6500 - FN: 158.6400 - val_loss: 0.0745 - val_Accuracy: 0.9770 - val_Precision: 0.9639 - val_Recall: 0.9450 - val_TP: 759.7900 - val_TN: 1083.5800 - val_FP: 22.4200 - val_FN: 44.2100\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0454 - Accuracy: 0.9840 - Precision: 0.9600 - Recall: 0.9526 - TP: 3212.1699 - TN: 5533.7598 - FP: 113.2400 - FN: 159.8300 - val_loss: 0.0753 - val_Accuracy: 0.9770 - val_Precision: 0.9620 - val_Recall: 0.9455 - val_TP: 760.1800 - val_TN: 1081.5900 - val_FP: 24.4100 - val_FN: 43.8200\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0451 - Accuracy: 0.9840 - Precision: 0.9596 - Recall: 0.9531 - TP: 3213.9600 - TN: 5532.2202 - FP: 114.7800 - FN: 158.0400 - val_loss: 0.0751 - val_Accuracy: 0.9770 - val_Precision: 0.9630 - val_Recall: 0.9452 - val_TP: 759.9200 - val_TN: 1082.7400 - val_FP: 23.2600 - val_FN: 44.0800\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0450 - Accuracy: 0.9841 - Precision: 0.9598 - Recall: 0.9531 - TP: 3213.8701 - TN: 5532.4800 - FP: 114.5200 - FN: 158.1300 - val_loss: 0.0751 - val_Accuracy: 0.9770 - val_Precision: 0.9626 - val_Recall: 0.9452 - val_TP: 759.9700 - val_TN: 1082.1801 - val_FP: 23.8200 - val_FN: 44.0300\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0452 - Accuracy: 0.9841 - Precision: 0.9595 - Recall: 0.9530 - TP: 3213.5701 - TN: 5531.5400 - FP: 115.4600 - FN: 158.4300 - val_loss: 0.0745 - val_Accuracy: 0.9770 - val_Precision: 0.9639 - val_Recall: 0.9451 - val_TP: 759.8600 - val_TN: 1083.6200 - val_FP: 22.3800 - val_FN: 44.1400\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0453 - Accuracy: 0.9841 - Precision: 0.9600 - Recall: 0.9529 - TP: 3213.1699 - TN: 5533.7798 - FP: 113.2200 - FN: 158.8300 - val_loss: 0.0750 - val_Accuracy: 0.9770 - val_Precision: 0.9630 - val_Recall: 0.9453 - val_TP: 760.0200 - val_TN: 1082.6899 - val_FP: 23.3100 - val_FN: 43.9800\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0449 - Accuracy: 0.9840 - Precision: 0.9599 - Recall: 0.9532 - TP: 3214.2500 - TN: 5533.4502 - FP: 113.5500 - FN: 157.7500 - val_loss: 0.0748 - val_Accuracy: 0.9770 - val_Precision: 0.9626 - val_Recall: 0.9456 - val_TP: 760.2800 - val_TN: 1082.3900 - val_FP: 23.6100 - val_FN: 43.7200\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0452 - Accuracy: 0.9838 - Precision: 0.9597 - Recall: 0.9529 - TP: 3213.2600 - TN: 5532.7100 - FP: 114.2900 - FN: 158.7400 - val_loss: 0.0751 - val_Accuracy: 0.9770 - val_Precision: 0.9631 - val_Recall: 0.9452 - val_TP: 759.9700 - val_TN: 1082.8500 - val_FP: 23.1500 - val_FN: 44.0300\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0449 - Accuracy: 0.9845 - Precision: 0.9600 - Recall: 0.9531 - TP: 3213.7700 - TN: 5533.5000 - FP: 113.5000 - FN: 158.2300 - val_loss: 0.0759 - val_Accuracy: 0.9764 - val_Precision: 0.9615 - val_Recall: 0.9455 - val_TP: 760.1800 - val_TN: 1081.2100 - val_FP: 24.7900 - val_FN: 43.8200\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 6ms/step - loss: 0.0464 - Accuracy: 0.9841 - Precision: 0.9601 - Recall: 0.9525 - TP: 3211.7400 - TN: 5534.1401 - FP: 112.8600 - FN: 160.2600 - val_loss: 0.0751 - val_Accuracy: 0.9770 - val_Precision: 0.9620 - val_Recall: 0.9454 - val_TP: 760.1200 - val_TN: 1081.6300 - val_FP: 24.3700 - val_FN: 43.8800\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0456 - Accuracy: 0.9843 - Precision: 0.9595 - Recall: 0.9528 - TP: 3212.8999 - TN: 5531.5698 - FP: 115.4300 - FN: 159.1000 - val_loss: 0.0751 - val_Accuracy: 0.9770 - val_Precision: 0.9625 - val_Recall: 0.9450 - val_TP: 759.8200 - val_TN: 1082.0800 - val_FP: 23.9200 - val_FN: 44.1800\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0454 - Accuracy: 0.9839 - Precision: 0.9598 - Recall: 0.9528 - TP: 3212.6899 - TN: 5532.8901 - FP: 114.1100 - FN: 159.3100 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9640 - val_Recall: 0.9449 - val_TP: 759.7000 - val_TN: 1083.6200 - val_FP: 22.3800 - val_FN: 44.3000\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0455 - Accuracy: 0.9838 - Precision: 0.9595 - Recall: 0.9529 - TP: 3213.2700 - TN: 5531.7998 - FP: 115.2000 - FN: 158.7300 - val_loss: 0.0753 - val_Accuracy: 0.9770 - val_Precision: 0.9624 - val_Recall: 0.9452 - val_TP: 759.9200 - val_TN: 1081.9500 - val_FP: 24.0500 - val_FN: 44.0800\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0456 - Accuracy: 0.9838 - Precision: 0.9598 - Recall: 0.9525 - TP: 3211.9900 - TN: 5532.8799 - FP: 114.1200 - FN: 160.0100 - val_loss: 0.0753 - val_Accuracy: 0.9770 - val_Precision: 0.9620 - val_Recall: 0.9454 - val_TP: 760.0900 - val_TN: 1081.6100 - val_FP: 24.3900 - val_FN: 43.9100\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0456 - Accuracy: 0.9836 - Precision: 0.9593 - Recall: 0.9529 - TP: 3213.1101 - TN: 5531.2300 - FP: 115.7700 - FN: 158.8900 - val_loss: 0.0755 - val_Accuracy: 0.9770 - val_Precision: 0.9619 - val_Recall: 0.9453 - val_TP: 760.0200 - val_TN: 1081.5400 - val_FP: 24.4600 - val_FN: 43.9800\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0452 - Accuracy: 0.9840 - Precision: 0.9595 - Recall: 0.9531 - TP: 3213.8701 - TN: 5532.0098 - FP: 114.9900 - FN: 158.1300 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9637 - val_Recall: 0.9450 - val_TP: 759.7500 - val_TN: 1083.3700 - val_FP: 22.6300 - val_FN: 44.2500\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0455 - Accuracy: 0.9839 - Precision: 0.9598 - Recall: 0.9526 - TP: 3212.0300 - TN: 5532.7202 - FP: 114.2800 - FN: 159.9700 - val_loss: 0.0747 - val_Accuracy: 0.9770 - val_Precision: 0.9631 - val_Recall: 0.9453 - val_TP: 760.0300 - val_TN: 1082.7700 - val_FP: 23.2300 - val_FN: 43.9700\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0453 - Accuracy: 0.9838 - Precision: 0.9597 - Recall: 0.9527 - TP: 3212.5200 - TN: 5532.5400 - FP: 114.4600 - FN: 159.4800 - val_loss: 0.0771 - val_Accuracy: 0.9759 - val_Precision: 0.9590 - val_Recall: 0.9456 - val_TP: 760.2300 - val_TN: 1078.5500 - val_FP: 27.4500 - val_FN: 43.7700\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0454 - Accuracy: 0.9841 - Precision: 0.9596 - Recall: 0.9527 - TP: 3212.5601 - TN: 5531.8701 - FP: 115.1300 - FN: 159.4400 - val_loss: 0.0755 - val_Accuracy: 0.9770 - val_Precision: 0.9616 - val_Recall: 0.9455 - val_TP: 760.2100 - val_TN: 1081.2500 - val_FP: 24.7500 - val_FN: 43.7900\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0452 - Accuracy: 0.9844 - Precision: 0.9596 - Recall: 0.9527 - TP: 3212.4600 - TN: 5531.8599 - FP: 115.1400 - FN: 159.5400 - val_loss: 0.0747 - val_Accuracy: 0.9770 - val_Precision: 0.9628 - val_Recall: 0.9455 - val_TP: 760.2100 - val_TN: 1082.4900 - val_FP: 23.5100 - val_FN: 43.7900\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0452 - Accuracy: 0.9844 - Precision: 0.9595 - Recall: 0.9533 - TP: 3214.3601 - TN: 5531.4600 - FP: 115.5400 - FN: 157.6400 - val_loss: 0.0750 - val_Accuracy: 0.9770 - val_Precision: 0.9630 - val_Recall: 0.9453 - val_TP: 760.0100 - val_TN: 1082.7600 - val_FP: 23.2400 - val_FN: 43.9900\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0453 - Accuracy: 0.9840 - Precision: 0.9594 - Recall: 0.9530 - TP: 3213.4900 - TN: 5531.3701 - FP: 115.6300 - FN: 158.5100 - val_loss: 0.0745 - val_Accuracy: 0.9770 - val_Precision: 0.9635 - val_Recall: 0.9453 - val_TP: 760.0500 - val_TN: 1083.1801 - val_FP: 22.8200 - val_FN: 43.9500\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0452 - Accuracy: 0.9840 - Precision: 0.9597 - Recall: 0.9530 - TP: 3213.4500 - TN: 5532.8501 - FP: 114.1500 - FN: 158.5500 - val_loss: 0.0755 - val_Accuracy: 0.9770 - val_Precision: 0.9623 - val_Recall: 0.9452 - val_TP: 759.9300 - val_TN: 1081.8800 - val_FP: 24.1200 - val_FN: 44.0700\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0451 - Accuracy: 0.9841 - Precision: 0.9601 - Recall: 0.9529 - TP: 3213.3401 - TN: 5534.3999 - FP: 112.6000 - FN: 158.6600 - val_loss: 0.0760 - val_Accuracy: 0.9764 - val_Precision: 0.9610 - val_Recall: 0.9455 - val_TP: 760.1600 - val_TN: 1080.6300 - val_FP: 25.3700 - val_FN: 43.8400\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0452 - Accuracy: 0.9839 - Precision: 0.9593 - Recall: 0.9529 - TP: 3213.1899 - TN: 5530.7402 - FP: 116.2600 - FN: 158.8100 - val_loss: 0.0751 - val_Accuracy: 0.9770 - val_Precision: 0.9630 - val_Recall: 0.9452 - val_TP: 759.9700 - val_TN: 1082.7600 - val_FP: 23.2400 - val_FN: 44.0300\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0450 - Accuracy: 0.9841 - Precision: 0.9597 - Recall: 0.9531 - TP: 3214.0200 - TN: 5532.6499 - FP: 114.3500 - FN: 157.9800 - val_loss: 0.0751 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9452 - val_TP: 759.9100 - val_TN: 1082.8700 - val_FP: 23.1300 - val_FN: 44.0900\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0450 - Accuracy: 0.9844 - Precision: 0.9604 - Recall: 0.9527 - TP: 3212.6201 - TN: 5535.0601 - FP: 111.9400 - FN: 159.3800 - val_loss: 0.0755 - val_Accuracy: 0.9770 - val_Precision: 0.9619 - val_Recall: 0.9455 - val_TP: 760.1800 - val_TN: 1081.5500 - val_FP: 24.4500 - val_FN: 43.8200\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0450 - Accuracy: 0.9844 - Precision: 0.9597 - Recall: 0.9532 - TP: 3214.2300 - TN: 5532.3901 - FP: 114.6100 - FN: 157.7700 - val_loss: 0.0748 - val_Accuracy: 0.9770 - val_Precision: 0.9631 - val_Recall: 0.9454 - val_TP: 760.1400 - val_TN: 1082.8300 - val_FP: 23.1700 - val_FN: 43.8600\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0448 - Accuracy: 0.9839 - Precision: 0.9596 - Recall: 0.9536 - TP: 3215.5000 - TN: 5532.2100 - FP: 114.7900 - FN: 156.5000 - val_loss: 0.0752 - val_Accuracy: 0.9770 - val_Precision: 0.9624 - val_Recall: 0.9454 - val_TP: 760.1100 - val_TN: 1082.0000 - val_FP: 24.0000 - val_FN: 43.8900\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0451 - Accuracy: 0.9843 - Precision: 0.9597 - Recall: 0.9533 - TP: 3214.6599 - TN: 5532.2300 - FP: 114.7700 - FN: 157.3400 - val_loss: 0.0748 - val_Accuracy: 0.9770 - val_Precision: 0.9638 - val_Recall: 0.9451 - val_TP: 759.8600 - val_TN: 1083.4800 - val_FP: 22.5200 - val_FN: 44.1400\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0449 - Accuracy: 0.9845 - Precision: 0.9604 - Recall: 0.9528 - TP: 3212.9700 - TN: 5535.2598 - FP: 111.7400 - FN: 159.0300 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9635 - val_Recall: 0.9454 - val_TP: 760.0800 - val_TN: 1083.2200 - val_FP: 22.7800 - val_FN: 43.9200\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0448 - Accuracy: 0.9839 - Precision: 0.9598 - Recall: 0.9533 - TP: 3214.5200 - TN: 5533.2300 - FP: 113.7700 - FN: 157.4800 - val_loss: 0.0750 - val_Accuracy: 0.9770 - val_Precision: 0.9627 - val_Recall: 0.9456 - val_TP: 760.2700 - val_TN: 1082.5200 - val_FP: 23.4800 - val_FN: 43.7300\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0460 - Accuracy: 0.9839 - Precision: 0.9601 - Recall: 0.9524 - TP: 3211.4900 - TN: 5534.3599 - FP: 112.6400 - FN: 160.5100 - val_loss: 0.0751 - val_Accuracy: 0.9770 - val_Precision: 0.9625 - val_Recall: 0.9453 - val_TP: 759.9900 - val_TN: 1082.0601 - val_FP: 23.9400 - val_FN: 44.0100\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0455 - Accuracy: 0.9844 - Precision: 0.9599 - Recall: 0.9527 - TP: 3212.6201 - TN: 5533.3101 - FP: 113.6900 - FN: 159.3800 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9631 - val_Recall: 0.9456 - val_TP: 760.2800 - val_TN: 1082.7900 - val_FP: 23.2100 - val_FN: 43.7200\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0456 - Accuracy: 0.9839 - Precision: 0.9595 - Recall: 0.9529 - TP: 3213.3201 - TN: 5531.4902 - FP: 115.5100 - FN: 158.6800 - val_loss: 0.0748 - val_Accuracy: 0.9770 - val_Precision: 0.9634 - val_Recall: 0.9451 - val_TP: 759.8600 - val_TN: 1083.0601 - val_FP: 22.9400 - val_FN: 44.1400\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0456 - Accuracy: 0.9840 - Precision: 0.9599 - Recall: 0.9527 - TP: 3212.5200 - TN: 5533.2100 - FP: 113.7900 - FN: 159.4800 - val_loss: 0.0755 - val_Accuracy: 0.9770 - val_Precision: 0.9618 - val_Recall: 0.9454 - val_TP: 760.1400 - val_TN: 1081.4399 - val_FP: 24.5600 - val_FN: 43.8600\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0453 - Accuracy: 0.9839 - Precision: 0.9595 - Recall: 0.9527 - TP: 3212.6101 - TN: 5531.4600 - FP: 115.5400 - FN: 159.3900 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9453 - val_TP: 760.0500 - val_TN: 1083.0200 - val_FP: 22.9800 - val_FN: 43.9500\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0456 - Accuracy: 0.9836 - Precision: 0.9593 - Recall: 0.9530 - TP: 3213.5701 - TN: 5531.1802 - FP: 115.8200 - FN: 158.4300 - val_loss: 0.0752 - val_Accuracy: 0.9770 - val_Precision: 0.9624 - val_Recall: 0.9452 - val_TP: 759.9400 - val_TN: 1082.0200 - val_FP: 23.9800 - val_FN: 44.0600\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0452 - Accuracy: 0.9841 - Precision: 0.9601 - Recall: 0.9527 - TP: 3212.6399 - TN: 5533.7700 - FP: 113.2300 - FN: 159.3600 - val_loss: 0.0757 - val_Accuracy: 0.9770 - val_Precision: 0.9612 - val_Recall: 0.9455 - val_TP: 760.2100 - val_TN: 1080.7900 - val_FP: 25.2100 - val_FN: 43.7900\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0453 - Accuracy: 0.9841 - Precision: 0.9594 - Recall: 0.9531 - TP: 3213.7100 - TN: 5531.3398 - FP: 115.6600 - FN: 158.2900 - val_loss: 0.0748 - val_Accuracy: 0.9770 - val_Precision: 0.9636 - val_Recall: 0.9451 - val_TP: 759.8300 - val_TN: 1083.2500 - val_FP: 22.7500 - val_FN: 44.1700\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0451 - Accuracy: 0.9843 - Precision: 0.9597 - Recall: 0.9532 - TP: 3214.3301 - TN: 5532.2002 - FP: 114.8000 - FN: 157.6700 - val_loss: 0.0745 - val_Accuracy: 0.9770 - val_Precision: 0.9637 - val_Recall: 0.9452 - val_TP: 759.9100 - val_TN: 1083.3800 - val_FP: 22.6200 - val_FN: 44.0900\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0452 - Accuracy: 0.9843 - Precision: 0.9599 - Recall: 0.9528 - TP: 3212.9099 - TN: 5533.2100 - FP: 113.7900 - FN: 159.0900 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9641 - val_Recall: 0.9451 - val_TP: 759.8300 - val_TN: 1083.7500 - val_FP: 22.2500 - val_FN: 44.1700\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0451 - Accuracy: 0.9844 - Precision: 0.9599 - Recall: 0.9529 - TP: 3213.0200 - TN: 5533.3901 - FP: 113.6100 - FN: 158.9800 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9638 - val_Recall: 0.9453 - val_TP: 760.0100 - val_TN: 1083.4900 - val_FP: 22.5100 - val_FN: 43.9900\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0452 - Accuracy: 0.9844 - Precision: 0.9597 - Recall: 0.9531 - TP: 3213.8301 - TN: 5532.3999 - FP: 114.6000 - FN: 158.1700 - val_loss: 0.0747 - val_Accuracy: 0.9770 - val_Precision: 0.9637 - val_Recall: 0.9451 - val_TP: 759.9000 - val_TN: 1083.3700 - val_FP: 22.6300 - val_FN: 44.1000\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0452 - Accuracy: 0.9841 - Precision: 0.9599 - Recall: 0.9528 - TP: 3212.8301 - TN: 5533.7798 - FP: 113.2200 - FN: 159.1700 - val_loss: 0.0747 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9454 - val_TP: 760.0900 - val_TN: 1082.9399 - val_FP: 23.0600 - val_FN: 43.9100\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0448 - Accuracy: 0.9843 - Precision: 0.9598 - Recall: 0.9535 - TP: 3215.0701 - TN: 5533.1699 - FP: 113.8300 - FN: 156.9300 - val_loss: 0.0757 - val_Accuracy: 0.9764 - val_Precision: 0.9609 - val_Recall: 0.9457 - val_TP: 760.3500 - val_TN: 1080.5000 - val_FP: 25.5000 - val_FN: 43.6500\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0451 - Accuracy: 0.9841 - Precision: 0.9597 - Recall: 0.9531 - TP: 3213.8799 - TN: 5532.4702 - FP: 114.5300 - FN: 158.1200 - val_loss: 0.0760 - val_Accuracy: 0.9770 - val_Precision: 0.9617 - val_Recall: 0.9452 - val_TP: 759.9400 - val_TN: 1081.2200 - val_FP: 24.7800 - val_FN: 44.0600\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0451 - Accuracy: 0.9841 - Precision: 0.9598 - Recall: 0.9531 - TP: 3213.9900 - TN: 5532.9902 - FP: 114.0100 - FN: 158.0100 - val_loss: 0.0747 - val_Accuracy: 0.9770 - val_Precision: 0.9636 - val_Recall: 0.9453 - val_TP: 759.9900 - val_TN: 1083.2800 - val_FP: 22.7200 - val_FN: 44.0100\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0448 - Accuracy: 0.9843 - Precision: 0.9600 - Recall: 0.9534 - TP: 3214.7300 - TN: 5533.5098 - FP: 113.4900 - FN: 157.2700 - val_loss: 0.0743 - val_Accuracy: 0.9770 - val_Precision: 0.9638 - val_Recall: 0.9454 - val_TP: 760.1400 - val_TN: 1083.5100 - val_FP: 22.4900 - val_FN: 43.8600\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0449 - Accuracy: 0.9837 - Precision: 0.9600 - Recall: 0.9529 - TP: 3213.2600 - TN: 5533.8799 - FP: 113.1200 - FN: 158.7400 - val_loss: 0.0754 - val_Accuracy: 0.9770 - val_Precision: 0.9625 - val_Recall: 0.9454 - val_TP: 760.0700 - val_TN: 1082.0800 - val_FP: 23.9200 - val_FN: 43.9300\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0450 - Accuracy: 0.9841 - Precision: 0.9597 - Recall: 0.9532 - TP: 3214.3101 - TN: 5532.5898 - FP: 114.4100 - FN: 157.6900 - val_loss: 0.0751 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9453 - val_TP: 760.0300 - val_TN: 1082.9000 - val_FP: 23.1000 - val_FN: 43.9700\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0446 - Accuracy: 0.9846 - Precision: 0.9600 - Recall: 0.9534 - TP: 3214.8101 - TN: 5533.8101 - FP: 113.1900 - FN: 157.1900 - val_loss: 0.0749 - val_Accuracy: 0.9770 - val_Precision: 0.9629 - val_Recall: 0.9455 - val_TP: 760.1900 - val_TN: 1082.6500 - val_FP: 23.3500 - val_FN: 43.8100\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0447 - Accuracy: 0.9844 - Precision: 0.9602 - Recall: 0.9532 - TP: 3214.1299 - TN: 5534.5498 - FP: 112.4500 - FN: 157.8700 - val_loss: 0.0746 - val_Accuracy: 0.9770 - val_Precision: 0.9635 - val_Recall: 0.9455 - val_TP: 760.1500 - val_TN: 1083.2000 - val_FP: 22.8000 - val_FN: 43.8500\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0444 - Accuracy: 0.9844 - Precision: 0.9596 - Recall: 0.9537 - TP: 3215.7400 - TN: 5532.0200 - FP: 114.9800 - FN: 156.2600 - val_loss: 0.0748 - val_Accuracy: 0.9770 - val_Precision: 0.9634 - val_Recall: 0.9454 - val_TP: 760.0700 - val_TN: 1083.1300 - val_FP: 22.8700 - val_FN: 43.9300\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0446 - Accuracy: 0.9845 - Precision: 0.9603 - Recall: 0.9535 - TP: 3215.1201 - TN: 5534.7202 - FP: 112.2800 - FN: 156.8800 - val_loss: 0.0747 - val_Accuracy: 0.9770 - val_Precision: 0.9634 - val_Recall: 0.9454 - val_TP: 760.1300 - val_TN: 1083.1500 - val_FP: 22.8500 - val_FN: 43.8700\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0446 - Accuracy: 0.9841 - Precision: 0.9605 - Recall: 0.9530 - TP: 3213.4800 - TN: 5535.7100 - FP: 111.2900 - FN: 158.5200 - val_loss: 0.0760 - val_Accuracy: 0.9764 - val_Precision: 0.9611 - val_Recall: 0.9456 - val_TP: 760.2800 - val_TN: 1080.6899 - val_FP: 25.3100 - val_FN: 43.7200\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0443 - Accuracy: 0.9844 - Precision: 0.9601 - Recall: 0.9534 - TP: 3214.7700 - TN: 5533.7402 - FP: 113.2600 - FN: 157.2300 - val_loss: 0.0752 - val_Accuracy: 0.9770 - val_Precision: 0.9626 - val_Recall: 0.9456 - val_TP: 760.3000 - val_TN: 1082.3700 - val_FP: 23.6300 - val_FN: 43.7000\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0447 - Accuracy: 0.9845 - Precision: 0.9595 - Recall: 0.9538 - TP: 3216.3401 - TN: 5531.7900 - FP: 115.2100 - FN: 155.6600 - val_loss: 0.0748 - val_Accuracy: 0.9770 - val_Precision: 0.9638 - val_Recall: 0.9454 - val_TP: 760.0700 - val_TN: 1083.5000 - val_FP: 22.5000 - val_FN: 43.9300\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0445 - Accuracy: 0.9844 - Precision: 0.9604 - Recall: 0.9532 - TP: 3214.2800 - TN: 5535.2002 - FP: 111.8000 - FN: 157.7200 - val_loss: 0.0750 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9456 - val_TP: 760.2300 - val_TN: 1082.9301 - val_FP: 23.0700 - val_FN: 43.7700\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0444 - Accuracy: 0.9850 - Precision: 0.9600 - Recall: 0.9537 - TP: 3216.0000 - TN: 5533.7100 - FP: 113.2900 - FN: 156.0000 - val_loss: 0.0751 - val_Accuracy: 0.9770 - val_Precision: 0.9629 - val_Recall: 0.9456 - val_TP: 760.2600 - val_TN: 1082.6700 - val_FP: 23.3300 - val_FN: 43.7400\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0446 - Accuracy: 0.9844 - Precision: 0.9605 - Recall: 0.9533 - TP: 3214.6101 - TN: 5535.8398 - FP: 111.1600 - FN: 157.3900 - val_loss: 0.0749 - val_Accuracy: 0.9770 - val_Precision: 0.9635 - val_Recall: 0.9455 - val_TP: 760.1700 - val_TN: 1083.2000 - val_FP: 22.8000 - val_FN: 43.8300\n",
      "Epoch 30/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0444 - Accuracy: 0.9846 - Precision: 0.9603 - Recall: 0.9534 - TP: 3215.0000 - TN: 5535.0801 - FP: 111.9200 - FN: 157.0000 - val_loss: 0.0753 - val_Accuracy: 0.9764 - val_Precision: 0.9623 - val_Recall: 0.9457 - val_TP: 760.3300 - val_TN: 1081.9399 - val_FP: 24.0600 - val_FN: 43.6700\n",
      "Epoch 31/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0447 - Accuracy: 0.9847 - Precision: 0.9599 - Recall: 0.9538 - TP: 3216.0601 - TN: 5533.1899 - FP: 113.8100 - FN: 155.9400 - val_loss: 0.0748 - val_Accuracy: 0.9764 - val_Precision: 0.9631 - val_Recall: 0.9457 - val_TP: 760.3400 - val_TN: 1082.9200 - val_FP: 23.0800 - val_FN: 43.6600\n",
      "Epoch 32/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0442 - Accuracy: 0.9848 - Precision: 0.9603 - Recall: 0.9538 - TP: 3216.1799 - TN: 5535.0498 - FP: 111.9500 - FN: 155.8200 - val_loss: 0.0748 - val_Accuracy: 0.9770 - val_Precision: 0.9637 - val_Recall: 0.9455 - val_TP: 760.2100 - val_TN: 1083.4000 - val_FP: 22.6000 - val_FN: 43.7900\n",
      "Epoch 33/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0445 - Accuracy: 0.9845 - Precision: 0.9601 - Recall: 0.9537 - TP: 3215.7600 - TN: 5534.2598 - FP: 112.7400 - FN: 156.2400 - val_loss: 0.0753 - val_Accuracy: 0.9764 - val_Precision: 0.9630 - val_Recall: 0.9455 - val_TP: 760.2100 - val_TN: 1082.7400 - val_FP: 23.2600 - val_FN: 43.7900\n",
      "Epoch 34/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0443 - Accuracy: 0.9846 - Precision: 0.9603 - Recall: 0.9535 - TP: 3215.1399 - TN: 5534.8901 - FP: 112.1100 - FN: 156.8600 - val_loss: 0.0752 - val_Accuracy: 0.9764 - val_Precision: 0.9628 - val_Recall: 0.9457 - val_TP: 760.3100 - val_TN: 1082.5699 - val_FP: 23.4300 - val_FN: 43.6900\n",
      "Epoch 35/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0445 - Accuracy: 0.9846 - Precision: 0.9600 - Recall: 0.9536 - TP: 3215.4399 - TN: 5533.9902 - FP: 113.0100 - FN: 156.5600 - val_loss: 0.0770 - val_Accuracy: 0.9754 - val_Precision: 0.9602 - val_Recall: 0.9456 - val_TP: 760.2800 - val_TN: 1079.7800 - val_FP: 26.2200 - val_FN: 43.7200\n",
      "Epoch 36/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0440 - Accuracy: 0.9849 - Precision: 0.9602 - Recall: 0.9539 - TP: 3216.4700 - TN: 5534.8599 - FP: 112.1400 - FN: 155.5300 - val_loss: 0.0763 - val_Accuracy: 0.9759 - val_Precision: 0.9614 - val_Recall: 0.9456 - val_TP: 760.2500 - val_TN: 1081.0300 - val_FP: 24.9700 - val_FN: 43.7500\n",
      "Epoch 37/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0443 - Accuracy: 0.9845 - Precision: 0.9604 - Recall: 0.9533 - TP: 3214.6899 - TN: 5535.5298 - FP: 111.4700 - FN: 157.3100 - val_loss: 0.0757 - val_Accuracy: 0.9764 - val_Precision: 0.9619 - val_Recall: 0.9458 - val_TP: 760.4300 - val_TN: 1081.5699 - val_FP: 24.4300 - val_FN: 43.5700\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 5ms/step - loss: 0.0459 - Accuracy: 0.9841 - Precision: 0.9598 - Recall: 0.9534 - TP: 3214.7300 - TN: 5533.4702 - FP: 113.5300 - FN: 157.2700 - val_loss: 0.0750 - val_Accuracy: 0.9770 - val_Precision: 0.9625 - val_Recall: 0.9458 - val_TP: 760.3900 - val_TN: 1082.2600 - val_FP: 23.7400 - val_FN: 43.6100\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0448 - Accuracy: 0.9840 - Precision: 0.9595 - Recall: 0.9535 - TP: 3215.2700 - TN: 5531.5601 - FP: 115.4400 - FN: 156.7300 - val_loss: 0.0748 - val_Accuracy: 0.9770 - val_Precision: 0.9638 - val_Recall: 0.9451 - val_TP: 759.8800 - val_TN: 1083.4900 - val_FP: 22.5100 - val_FN: 44.1200\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0451 - Accuracy: 0.9843 - Precision: 0.9596 - Recall: 0.9532 - TP: 3214.2100 - TN: 5532.3901 - FP: 114.6100 - FN: 157.7900 - val_loss: 0.0754 - val_Accuracy: 0.9770 - val_Precision: 0.9627 - val_Recall: 0.9453 - val_TP: 760.0300 - val_TN: 1082.2900 - val_FP: 23.7100 - val_FN: 43.9700\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0449 - Accuracy: 0.9845 - Precision: 0.9603 - Recall: 0.9530 - TP: 3213.3799 - TN: 5535.0601 - FP: 111.9400 - FN: 158.6200 - val_loss: 0.0764 - val_Accuracy: 0.9764 - val_Precision: 0.9609 - val_Recall: 0.9455 - val_TP: 760.1800 - val_TN: 1080.5500 - val_FP: 25.4500 - val_FN: 43.8200\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0448 - Accuracy: 0.9845 - Precision: 0.9598 - Recall: 0.9534 - TP: 3214.8000 - TN: 5532.8701 - FP: 114.1300 - FN: 157.2000 - val_loss: 0.0755 - val_Accuracy: 0.9770 - val_Precision: 0.9627 - val_Recall: 0.9453 - val_TP: 760.0200 - val_TN: 1082.3000 - val_FP: 23.7000 - val_FN: 43.9800\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0449 - Accuracy: 0.9841 - Precision: 0.9604 - Recall: 0.9532 - TP: 3214.3301 - TN: 5535.2900 - FP: 111.7100 - FN: 157.6700 - val_loss: 0.0763 - val_Accuracy: 0.9764 - val_Precision: 0.9611 - val_Recall: 0.9454 - val_TP: 760.1100 - val_TN: 1080.7300 - val_FP: 25.2700 - val_FN: 43.8900\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0446 - Accuracy: 0.9849 - Precision: 0.9596 - Recall: 0.9538 - TP: 3216.0601 - TN: 5532.0200 - FP: 114.9800 - FN: 155.9400 - val_loss: 0.0749 - val_Accuracy: 0.9770 - val_Precision: 0.9634 - val_Recall: 0.9454 - val_TP: 760.1000 - val_TN: 1083.1600 - val_FP: 22.8400 - val_FN: 43.9000\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0446 - Accuracy: 0.9839 - Precision: 0.9601 - Recall: 0.9533 - TP: 3214.6299 - TN: 5534.0098 - FP: 112.9900 - FN: 157.3700 - val_loss: 0.0762 - val_Accuracy: 0.9770 - val_Precision: 0.9624 - val_Recall: 0.9450 - val_TP: 759.8200 - val_TN: 1082.0200 - val_FP: 23.9800 - val_FN: 44.1800\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0446 - Accuracy: 0.9845 - Precision: 0.9603 - Recall: 0.9534 - TP: 3214.7000 - TN: 5535.0200 - FP: 111.9800 - FN: 157.3000 - val_loss: 0.0775 - val_Accuracy: 0.9759 - val_Precision: 0.9605 - val_Recall: 0.9452 - val_TP: 759.9100 - val_TN: 1080.0900 - val_FP: 25.9100 - val_FN: 44.0900\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0447 - Accuracy: 0.9841 - Precision: 0.9605 - Recall: 0.9530 - TP: 3213.4099 - TN: 5535.6699 - FP: 111.3300 - FN: 158.5900 - val_loss: 0.0751 - val_Accuracy: 0.9770 - val_Precision: 0.9628 - val_Recall: 0.9457 - val_TP: 760.3200 - val_TN: 1082.6100 - val_FP: 23.3900 - val_FN: 43.6800\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0444 - Accuracy: 0.9848 - Precision: 0.9602 - Recall: 0.9538 - TP: 3216.3401 - TN: 5534.4102 - FP: 112.5900 - FN: 155.6600 - val_loss: 0.0760 - val_Accuracy: 0.9764 - val_Precision: 0.9619 - val_Recall: 0.9455 - val_TP: 760.1800 - val_TN: 1081.6000 - val_FP: 24.4000 - val_FN: 43.8200\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0445 - Accuracy: 0.9845 - Precision: 0.9602 - Recall: 0.9537 - TP: 3216.0300 - TN: 5534.7700 - FP: 112.2300 - FN: 155.9700 - val_loss: 0.0748 - val_Accuracy: 0.9770 - val_Precision: 0.9635 - val_Recall: 0.9455 - val_TP: 760.2100 - val_TN: 1083.2900 - val_FP: 22.7100 - val_FN: 43.7900\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0444 - Accuracy: 0.9846 - Precision: 0.9602 - Recall: 0.9536 - TP: 3215.5701 - TN: 5534.4199 - FP: 112.5800 - FN: 156.4300 - val_loss: 0.0760 - val_Accuracy: 0.9764 - val_Precision: 0.9618 - val_Recall: 0.9456 - val_TP: 760.2600 - val_TN: 1081.4900 - val_FP: 24.5100 - val_FN: 43.7400\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0444 - Accuracy: 0.9844 - Precision: 0.9602 - Recall: 0.9535 - TP: 3215.3601 - TN: 5534.6099 - FP: 112.3900 - FN: 156.6400 - val_loss: 0.0759 - val_Accuracy: 0.9764 - val_Precision: 0.9615 - val_Recall: 0.9458 - val_TP: 760.4100 - val_TN: 1081.2300 - val_FP: 24.7700 - val_FN: 43.5900\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0443 - Accuracy: 0.9849 - Precision: 0.9599 - Recall: 0.9536 - TP: 3215.6699 - TN: 5533.5601 - FP: 113.4400 - FN: 156.3300 - val_loss: 0.0753 - val_Accuracy: 0.9764 - val_Precision: 0.9621 - val_Recall: 0.9458 - val_TP: 760.4200 - val_TN: 1081.7800 - val_FP: 24.2200 - val_FN: 43.5800\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0444 - Accuracy: 0.9846 - Precision: 0.9603 - Recall: 0.9534 - TP: 3214.8000 - TN: 5534.5000 - FP: 112.5000 - FN: 157.2000 - val_loss: 0.0748 - val_Accuracy: 0.9764 - val_Precision: 0.9634 - val_Recall: 0.9456 - val_TP: 760.2900 - val_TN: 1083.1801 - val_FP: 22.8200 - val_FN: 43.7100\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0442 - Accuracy: 0.9847 - Precision: 0.9603 - Recall: 0.9536 - TP: 3215.7000 - TN: 5534.6899 - FP: 112.3100 - FN: 156.3000 - val_loss: 0.0748 - val_Accuracy: 0.9764 - val_Precision: 0.9635 - val_Recall: 0.9457 - val_TP: 760.3400 - val_TN: 1083.2300 - val_FP: 22.7700 - val_FN: 43.6600\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0441 - Accuracy: 0.9846 - Precision: 0.9601 - Recall: 0.9540 - TP: 3216.7300 - TN: 5534.3701 - FP: 112.6300 - FN: 155.2700 - val_loss: 0.0756 - val_Accuracy: 0.9764 - val_Precision: 0.9624 - val_Recall: 0.9456 - val_TP: 760.2700 - val_TN: 1082.0300 - val_FP: 23.9700 - val_FN: 43.7300\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0441 - Accuracy: 0.9849 - Precision: 0.9606 - Recall: 0.9536 - TP: 3215.6001 - TN: 5536.1001 - FP: 110.9000 - FN: 156.4000 - val_loss: 0.0758 - val_Accuracy: 0.9764 - val_Precision: 0.9621 - val_Recall: 0.9457 - val_TP: 760.3200 - val_TN: 1081.8101 - val_FP: 24.1900 - val_FN: 43.6800\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0445 - Accuracy: 0.9849 - Precision: 0.9598 - Recall: 0.9539 - TP: 3216.6299 - TN: 5532.7402 - FP: 114.2600 - FN: 155.3700 - val_loss: 0.0754 - val_Accuracy: 0.9764 - val_Precision: 0.9631 - val_Recall: 0.9456 - val_TP: 760.2300 - val_TN: 1082.9200 - val_FP: 23.0800 - val_FN: 43.7700\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0444 - Accuracy: 0.9843 - Precision: 0.9607 - Recall: 0.9533 - TP: 3214.6001 - TN: 5536.4702 - FP: 110.5300 - FN: 157.4000 - val_loss: 0.0754 - val_Accuracy: 0.9764 - val_Precision: 0.9629 - val_Recall: 0.9457 - val_TP: 760.3100 - val_TN: 1082.6899 - val_FP: 23.3100 - val_FN: 43.6900\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0440 - Accuracy: 0.9855 - Precision: 0.9600 - Recall: 0.9540 - TP: 3216.8899 - TN: 5533.8301 - FP: 113.1700 - FN: 155.1100 - val_loss: 0.0755 - val_Accuracy: 0.9764 - val_Precision: 0.9633 - val_Recall: 0.9454 - val_TP: 760.1000 - val_TN: 1083.0900 - val_FP: 22.9100 - val_FN: 43.9000\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0441 - Accuracy: 0.9847 - Precision: 0.9608 - Recall: 0.9536 - TP: 3215.3999 - TN: 5537.0898 - FP: 109.9100 - FN: 156.6000 - val_loss: 0.0759 - val_Accuracy: 0.9764 - val_Precision: 0.9623 - val_Recall: 0.9455 - val_TP: 760.2000 - val_TN: 1082.0400 - val_FP: 23.9600 - val_FN: 43.8000\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0442 - Accuracy: 0.9849 - Precision: 0.9603 - Recall: 0.9538 - TP: 3216.1699 - TN: 5534.9399 - FP: 112.0600 - FN: 155.8300 - val_loss: 0.0757 - val_Accuracy: 0.9764 - val_Precision: 0.9621 - val_Recall: 0.9457 - val_TP: 760.3700 - val_TN: 1081.8199 - val_FP: 24.1800 - val_FN: 43.6300\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0441 - Accuracy: 0.9846 - Precision: 0.9604 - Recall: 0.9537 - TP: 3215.9700 - TN: 5535.6099 - FP: 111.3900 - FN: 156.0300 - val_loss: 0.0758 - val_Accuracy: 0.9764 - val_Precision: 0.9619 - val_Recall: 0.9460 - val_TP: 760.5500 - val_TN: 1081.6600 - val_FP: 24.3400 - val_FN: 43.4500\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0438 - Accuracy: 0.9847 - Precision: 0.9604 - Recall: 0.9541 - TP: 3217.1399 - TN: 5535.2002 - FP: 111.8000 - FN: 154.8600 - val_loss: 0.0758 - val_Accuracy: 0.9764 - val_Precision: 0.9624 - val_Recall: 0.9456 - val_TP: 760.3000 - val_TN: 1082.0500 - val_FP: 23.9500 - val_FN: 43.7000\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0440 - Accuracy: 0.9849 - Precision: 0.9604 - Recall: 0.9540 - TP: 3216.7600 - TN: 5535.2900 - FP: 111.7100 - FN: 155.2400 - val_loss: 0.0758 - val_Accuracy: 0.9764 - val_Precision: 0.9623 - val_Recall: 0.9457 - val_TP: 760.3400 - val_TN: 1082.0200 - val_FP: 23.9800 - val_FN: 43.6600\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0440 - Accuracy: 0.9850 - Precision: 0.9605 - Recall: 0.9538 - TP: 3216.2500 - TN: 5535.8101 - FP: 111.1900 - FN: 155.7500 - val_loss: 0.0765 - val_Accuracy: 0.9759 - val_Precision: 0.9608 - val_Recall: 0.9460 - val_TP: 760.5900 - val_TN: 1080.4800 - val_FP: 25.5200 - val_FN: 43.4100\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0441 - Accuracy: 0.9846 - Precision: 0.9605 - Recall: 0.9536 - TP: 3215.7000 - TN: 5535.8599 - FP: 111.1400 - FN: 156.3000 - val_loss: 0.0763 - val_Accuracy: 0.9759 - val_Precision: 0.9617 - val_Recall: 0.9459 - val_TP: 760.4900 - val_TN: 1081.3900 - val_FP: 24.6100 - val_FN: 43.5100\n",
      "Epoch 30/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0439 - Accuracy: 0.9850 - Precision: 0.9600 - Recall: 0.9543 - TP: 3217.7500 - TN: 5533.6001 - FP: 113.4000 - FN: 154.2500 - val_loss: 0.0759 - val_Accuracy: 0.9764 - val_Precision: 0.9625 - val_Recall: 0.9456 - val_TP: 760.2700 - val_TN: 1082.2000 - val_FP: 23.8000 - val_FN: 43.7300\n",
      "Epoch 31/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0439 - Accuracy: 0.9848 - Precision: 0.9607 - Recall: 0.9538 - TP: 3216.0701 - TN: 5536.5400 - FP: 110.4600 - FN: 155.9300 - val_loss: 0.0756 - val_Accuracy: 0.9764 - val_Precision: 0.9629 - val_Recall: 0.9457 - val_TP: 760.3800 - val_TN: 1082.6899 - val_FP: 23.3100 - val_FN: 43.6200\n",
      "Epoch 32/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0437 - Accuracy: 0.9849 - Precision: 0.9605 - Recall: 0.9540 - TP: 3216.7800 - TN: 5536.2598 - FP: 110.7400 - FN: 155.2200 - val_loss: 0.0763 - val_Accuracy: 0.9759 - val_Precision: 0.9620 - val_Recall: 0.9456 - val_TP: 760.2900 - val_TN: 1081.7000 - val_FP: 24.3000 - val_FN: 43.7100\n",
      "Epoch 33/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0438 - Accuracy: 0.9850 - Precision: 0.9605 - Recall: 0.9541 - TP: 3217.1799 - TN: 5535.5698 - FP: 111.4300 - FN: 154.8200 - val_loss: 0.0755 - val_Accuracy: 0.9764 - val_Precision: 0.9630 - val_Recall: 0.9458 - val_TP: 760.3900 - val_TN: 1082.7800 - val_FP: 23.2200 - val_FN: 43.6100\n",
      "Epoch 34/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0440 - Accuracy: 0.9853 - Precision: 0.9604 - Recall: 0.9542 - TP: 3217.5701 - TN: 5535.5098 - FP: 111.4900 - FN: 154.4300 - val_loss: 0.0770 - val_Accuracy: 0.9754 - val_Precision: 0.9609 - val_Recall: 0.9457 - val_TP: 760.3700 - val_TN: 1080.5900 - val_FP: 25.4100 - val_FN: 43.6300\n",
      "Epoch 35/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0436 - Accuracy: 0.9849 - Precision: 0.9608 - Recall: 0.9540 - TP: 3216.7500 - TN: 5537.0898 - FP: 109.9100 - FN: 155.2500 - val_loss: 0.0759 - val_Accuracy: 0.9764 - val_Precision: 0.9625 - val_Recall: 0.9457 - val_TP: 760.3500 - val_TN: 1082.1600 - val_FP: 23.8400 - val_FN: 43.6500\n",
      "Epoch 36/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0436 - Accuracy: 0.9849 - Precision: 0.9604 - Recall: 0.9542 - TP: 3217.7100 - TN: 5535.1802 - FP: 111.8200 - FN: 154.2900 - val_loss: 0.0754 - val_Accuracy: 0.9764 - val_Precision: 0.9634 - val_Recall: 0.9457 - val_TP: 760.3800 - val_TN: 1083.1500 - val_FP: 22.8500 - val_FN: 43.6200\n",
      "Epoch 37/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0437 - Accuracy: 0.9848 - Precision: 0.9608 - Recall: 0.9539 - TP: 3216.3999 - TN: 5536.9702 - FP: 110.0300 - FN: 155.6000 - val_loss: 0.0767 - val_Accuracy: 0.9759 - val_Precision: 0.9609 - val_Recall: 0.9460 - val_TP: 760.5600 - val_TN: 1080.6100 - val_FP: 25.3900 - val_FN: 43.4400\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0451 - Accuracy: 0.9847 - Precision: 0.9602 - Recall: 0.9537 - TP: 3216.0200 - TN: 5534.8701 - FP: 112.1300 - FN: 155.9800 - val_loss: 0.0752 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9455 - val_TP: 760.2100 - val_TN: 1083.0100 - val_FP: 22.9900 - val_FN: 43.7900\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0443 - Accuracy: 0.9850 - Precision: 0.9602 - Recall: 0.9537 - TP: 3215.8301 - TN: 5534.5498 - FP: 112.4500 - FN: 156.1700 - val_loss: 0.0756 - val_Accuracy: 0.9770 - val_Precision: 0.9625 - val_Recall: 0.9456 - val_TP: 760.2700 - val_TN: 1082.1300 - val_FP: 23.8700 - val_FN: 43.7300\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0443 - Accuracy: 0.9846 - Precision: 0.9604 - Recall: 0.9537 - TP: 3215.9600 - TN: 5535.2900 - FP: 111.7100 - FN: 156.0400 - val_loss: 0.0753 - val_Accuracy: 0.9764 - val_Precision: 0.9629 - val_Recall: 0.9457 - val_TP: 760.3200 - val_TN: 1082.7300 - val_FP: 23.2700 - val_FN: 43.6800\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0443 - Accuracy: 0.9848 - Precision: 0.9606 - Recall: 0.9535 - TP: 3215.3501 - TN: 5536.0801 - FP: 110.9200 - FN: 156.6500 - val_loss: 0.0756 - val_Accuracy: 0.9764 - val_Precision: 0.9623 - val_Recall: 0.9458 - val_TP: 760.3900 - val_TN: 1081.9900 - val_FP: 24.0100 - val_FN: 43.6100\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0444 - Accuracy: 0.9846 - Precision: 0.9601 - Recall: 0.9539 - TP: 3216.6201 - TN: 5534.0801 - FP: 112.9200 - FN: 155.3800 - val_loss: 0.0769 - val_Accuracy: 0.9754 - val_Precision: 0.9608 - val_Recall: 0.9457 - val_TP: 760.3300 - val_TN: 1080.5200 - val_FP: 25.4800 - val_FN: 43.6700\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0441 - Accuracy: 0.9847 - Precision: 0.9607 - Recall: 0.9536 - TP: 3215.6499 - TN: 5536.1899 - FP: 110.8100 - FN: 156.3500 - val_loss: 0.0768 - val_Accuracy: 0.9754 - val_Precision: 0.9601 - val_Recall: 0.9462 - val_TP: 760.7200 - val_TN: 1079.8400 - val_FP: 26.1600 - val_FN: 43.2800\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0442 - Accuracy: 0.9850 - Precision: 0.9594 - Recall: 0.9544 - TP: 3218.2900 - TN: 5531.2202 - FP: 115.7800 - FN: 153.7100 - val_loss: 0.0749 - val_Accuracy: 0.9764 - val_Precision: 0.9640 - val_Recall: 0.9454 - val_TP: 760.1300 - val_TN: 1083.7800 - val_FP: 22.2200 - val_FN: 43.8700\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0443 - Accuracy: 0.9845 - Precision: 0.9607 - Recall: 0.9533 - TP: 3214.6201 - TN: 5536.6899 - FP: 110.3100 - FN: 157.3800 - val_loss: 0.0754 - val_Accuracy: 0.9764 - val_Precision: 0.9625 - val_Recall: 0.9460 - val_TP: 760.5900 - val_TN: 1082.3500 - val_FP: 23.6500 - val_FN: 43.4100\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0439 - Accuracy: 0.9843 - Precision: 0.9605 - Recall: 0.9537 - TP: 3215.8301 - TN: 5535.7100 - FP: 111.2900 - FN: 156.1700 - val_loss: 0.0759 - val_Accuracy: 0.9764 - val_Precision: 0.9621 - val_Recall: 0.9457 - val_TP: 760.3800 - val_TN: 1081.8500 - val_FP: 24.1500 - val_FN: 43.6200\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0437 - Accuracy: 0.9850 - Precision: 0.9603 - Recall: 0.9541 - TP: 3217.3501 - TN: 5534.8599 - FP: 112.1400 - FN: 154.6500 - val_loss: 0.0768 - val_Accuracy: 0.9754 - val_Precision: 0.9609 - val_Recall: 0.9458 - val_TP: 760.3900 - val_TN: 1080.6100 - val_FP: 25.3900 - val_FN: 43.6100\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0437 - Accuracy: 0.9848 - Precision: 0.9606 - Recall: 0.9540 - TP: 3217.0400 - TN: 5535.9502 - FP: 111.0500 - FN: 154.9600 - val_loss: 0.0757 - val_Accuracy: 0.9764 - val_Precision: 0.9631 - val_Recall: 0.9456 - val_TP: 760.2300 - val_TN: 1082.8900 - val_FP: 23.1100 - val_FN: 43.7700\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0439 - Accuracy: 0.9846 - Precision: 0.9605 - Recall: 0.9539 - TP: 3216.4199 - TN: 5535.5601 - FP: 111.4400 - FN: 155.5800 - val_loss: 0.0753 - val_Accuracy: 0.9764 - val_Precision: 0.9632 - val_Recall: 0.9458 - val_TP: 760.3900 - val_TN: 1083.0000 - val_FP: 23.0000 - val_FN: 43.6100\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0440 - Accuracy: 0.9849 - Precision: 0.9604 - Recall: 0.9542 - TP: 3217.6499 - TN: 5535.6899 - FP: 111.3100 - FN: 154.3500 - val_loss: 0.0752 - val_Accuracy: 0.9764 - val_Precision: 0.9636 - val_Recall: 0.9456 - val_TP: 760.2500 - val_TN: 1083.4200 - val_FP: 22.5800 - val_FN: 43.7500\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0438 - Accuracy: 0.9848 - Precision: 0.9606 - Recall: 0.9542 - TP: 3217.5400 - TN: 5536.7598 - FP: 110.2400 - FN: 154.4600 - val_loss: 0.0756 - val_Accuracy: 0.9764 - val_Precision: 0.9631 - val_Recall: 0.9456 - val_TP: 760.2800 - val_TN: 1082.9301 - val_FP: 23.0700 - val_FN: 43.7200\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0437 - Accuracy: 0.9850 - Precision: 0.9604 - Recall: 0.9542 - TP: 3217.4199 - TN: 5535.7402 - FP: 111.2600 - FN: 154.5800 - val_loss: 0.0751 - val_Accuracy: 0.9764 - val_Precision: 0.9633 - val_Recall: 0.9459 - val_TP: 760.4700 - val_TN: 1083.1200 - val_FP: 22.8800 - val_FN: 43.5300\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0439 - Accuracy: 0.9848 - Precision: 0.9606 - Recall: 0.9540 - TP: 3216.8799 - TN: 5536.2002 - FP: 110.8000 - FN: 155.1200 - val_loss: 0.0758 - val_Accuracy: 0.9764 - val_Precision: 0.9627 - val_Recall: 0.9458 - val_TP: 760.4000 - val_TN: 1082.5601 - val_FP: 23.4400 - val_FN: 43.6000\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0436 - Accuracy: 0.9848 - Precision: 0.9607 - Recall: 0.9541 - TP: 3217.2900 - TN: 5536.7100 - FP: 110.2900 - FN: 154.7100 - val_loss: 0.0755 - val_Accuracy: 0.9764 - val_Precision: 0.9632 - val_Recall: 0.9457 - val_TP: 760.3400 - val_TN: 1083.0200 - val_FP: 22.9800 - val_FN: 43.6600\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0439 - Accuracy: 0.9849 - Precision: 0.9607 - Recall: 0.9539 - TP: 3216.6399 - TN: 5536.6299 - FP: 110.3700 - FN: 155.3600 - val_loss: 0.0757 - val_Accuracy: 0.9764 - val_Precision: 0.9627 - val_Recall: 0.9459 - val_TP: 760.4900 - val_TN: 1082.5601 - val_FP: 23.4400 - val_FN: 43.5100\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0436 - Accuracy: 0.9853 - Precision: 0.9608 - Recall: 0.9545 - TP: 3218.4800 - TN: 5537.0098 - FP: 109.9900 - FN: 153.5200 - val_loss: 0.0756 - val_Accuracy: 0.9764 - val_Precision: 0.9628 - val_Recall: 0.9459 - val_TP: 760.5300 - val_TN: 1082.6400 - val_FP: 23.3600 - val_FN: 43.4700\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0435 - Accuracy: 0.9851 - Precision: 0.9609 - Recall: 0.9541 - TP: 3217.2500 - TN: 5537.5000 - FP: 109.5000 - FN: 154.7500 - val_loss: 0.0772 - val_Accuracy: 0.9754 - val_Precision: 0.9603 - val_Recall: 0.9462 - val_TP: 760.7100 - val_TN: 1080.1300 - val_FP: 25.8700 - val_FN: 43.2900\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0438 - Accuracy: 0.9853 - Precision: 0.9601 - Recall: 0.9545 - TP: 3218.5801 - TN: 5534.1499 - FP: 112.8500 - FN: 153.4200 - val_loss: 0.0755 - val_Accuracy: 0.9764 - val_Precision: 0.9632 - val_Recall: 0.9458 - val_TP: 760.4000 - val_TN: 1083.0100 - val_FP: 22.9900 - val_FN: 43.6000\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0433 - Accuracy: 0.9848 - Precision: 0.9609 - Recall: 0.9540 - TP: 3216.8000 - TN: 5537.1802 - FP: 109.8200 - FN: 155.2000 - val_loss: 0.0757 - val_Accuracy: 0.9764 - val_Precision: 0.9629 - val_Recall: 0.9459 - val_TP: 760.5000 - val_TN: 1082.7300 - val_FP: 23.2700 - val_FN: 43.5000\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0436 - Accuracy: 0.9847 - Precision: 0.9606 - Recall: 0.9544 - TP: 3218.1399 - TN: 5536.2798 - FP: 110.7200 - FN: 153.8600 - val_loss: 0.0764 - val_Accuracy: 0.9764 - val_Precision: 0.9621 - val_Recall: 0.9457 - val_TP: 760.3800 - val_TN: 1081.8800 - val_FP: 24.1200 - val_FN: 43.6200\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0436 - Accuracy: 0.9853 - Precision: 0.9607 - Recall: 0.9542 - TP: 3217.4900 - TN: 5536.7598 - FP: 110.2400 - FN: 154.5100 - val_loss: 0.0763 - val_Accuracy: 0.9764 - val_Precision: 0.9620 - val_Recall: 0.9459 - val_TP: 760.4800 - val_TN: 1081.7800 - val_FP: 24.2200 - val_FN: 43.5200\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0435 - Accuracy: 0.9849 - Precision: 0.9606 - Recall: 0.9544 - TP: 3218.1101 - TN: 5536.0801 - FP: 110.9200 - FN: 153.8900 - val_loss: 0.0759 - val_Accuracy: 0.9764 - val_Precision: 0.9631 - val_Recall: 0.9456 - val_TP: 760.3000 - val_TN: 1082.9000 - val_FP: 23.1000 - val_FN: 43.7000\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0436 - Accuracy: 0.9848 - Precision: 0.9610 - Recall: 0.9541 - TP: 3217.0901 - TN: 5537.6802 - FP: 109.3200 - FN: 154.9100 - val_loss: 0.0767 - val_Accuracy: 0.9759 - val_Precision: 0.9616 - val_Recall: 0.9460 - val_TP: 760.5500 - val_TN: 1081.3700 - val_FP: 24.6300 - val_FN: 43.4500\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0433 - Accuracy: 0.9850 - Precision: 0.9608 - Recall: 0.9541 - TP: 3217.1799 - TN: 5537.0098 - FP: 109.9900 - FN: 154.8200 - val_loss: 0.0765 - val_Accuracy: 0.9754 - val_Precision: 0.9622 - val_Recall: 0.9456 - val_TP: 760.3000 - val_TN: 1081.9800 - val_FP: 24.0200 - val_FN: 43.7000\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0445 - Accuracy: 0.9849 - Precision: 0.9608 - Recall: 0.9536 - TP: 3215.3899 - TN: 5537.1499 - FP: 109.8500 - FN: 156.6100 - val_loss: 0.0760 - val_Accuracy: 0.9764 - val_Precision: 0.9622 - val_Recall: 0.9456 - val_TP: 760.2600 - val_TN: 1081.9301 - val_FP: 24.0700 - val_FN: 43.7400\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0439 - Accuracy: 0.9847 - Precision: 0.9607 - Recall: 0.9538 - TP: 3216.3401 - TN: 5536.2700 - FP: 110.7300 - FN: 155.6600 - val_loss: 0.0751 - val_Accuracy: 0.9764 - val_Precision: 0.9636 - val_Recall: 0.9456 - val_TP: 760.2900 - val_TN: 1083.3199 - val_FP: 22.6800 - val_FN: 43.7100\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0440 - Accuracy: 0.9849 - Precision: 0.9604 - Recall: 0.9540 - TP: 3216.8000 - TN: 5535.6499 - FP: 111.3500 - FN: 155.2000 - val_loss: 0.0759 - val_Accuracy: 0.9764 - val_Precision: 0.9624 - val_Recall: 0.9457 - val_TP: 760.3300 - val_TN: 1082.0601 - val_FP: 23.9400 - val_FN: 43.6700\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0440 - Accuracy: 0.9850 - Precision: 0.9603 - Recall: 0.9539 - TP: 3216.4500 - TN: 5535.0200 - FP: 111.9800 - FN: 155.5500 - val_loss: 0.0760 - val_Accuracy: 0.9764 - val_Precision: 0.9623 - val_Recall: 0.9457 - val_TP: 760.3100 - val_TN: 1082.0200 - val_FP: 23.9800 - val_FN: 43.6900\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0440 - Accuracy: 0.9847 - Precision: 0.9606 - Recall: 0.9537 - TP: 3215.7900 - TN: 5536.2202 - FP: 110.7800 - FN: 156.2100 - val_loss: 0.0758 - val_Accuracy: 0.9764 - val_Precision: 0.9625 - val_Recall: 0.9457 - val_TP: 760.3500 - val_TN: 1082.1700 - val_FP: 23.8300 - val_FN: 43.6500\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0441 - Accuracy: 0.9847 - Precision: 0.9605 - Recall: 0.9539 - TP: 3216.6699 - TN: 5536.1201 - FP: 110.8800 - FN: 155.3300 - val_loss: 0.0772 - val_Accuracy: 0.9754 - val_Precision: 0.9602 - val_Recall: 0.9458 - val_TP: 760.4400 - val_TN: 1079.8500 - val_FP: 26.1500 - val_FN: 43.5600\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0439 - Accuracy: 0.9850 - Precision: 0.9604 - Recall: 0.9541 - TP: 3217.3701 - TN: 5535.2402 - FP: 111.7600 - FN: 154.6300 - val_loss: 0.0750 - val_Accuracy: 0.9764 - val_Precision: 0.9633 - val_Recall: 0.9460 - val_TP: 760.5600 - val_TN: 1083.1300 - val_FP: 22.8700 - val_FN: 43.4400\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0437 - Accuracy: 0.9848 - Precision: 0.9610 - Recall: 0.9541 - TP: 3217.0701 - TN: 5537.8198 - FP: 109.1800 - FN: 154.9300 - val_loss: 0.0756 - val_Accuracy: 0.9764 - val_Precision: 0.9625 - val_Recall: 0.9461 - val_TP: 760.6400 - val_TN: 1082.3300 - val_FP: 23.6700 - val_FN: 43.3600\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0440 - Accuracy: 0.9849 - Precision: 0.9604 - Recall: 0.9541 - TP: 3217.2000 - TN: 5535.3701 - FP: 111.6300 - FN: 154.8000 - val_loss: 0.0750 - val_Accuracy: 0.9764 - val_Precision: 0.9637 - val_Recall: 0.9458 - val_TP: 760.4500 - val_TN: 1083.4500 - val_FP: 22.5500 - val_FN: 43.5500\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0437 - Accuracy: 0.9851 - Precision: 0.9603 - Recall: 0.9543 - TP: 3218.0200 - TN: 5535.3999 - FP: 111.6000 - FN: 153.9800 - val_loss: 0.0750 - val_Accuracy: 0.9764 - val_Precision: 0.9639 - val_Recall: 0.9456 - val_TP: 760.2800 - val_TN: 1083.6600 - val_FP: 22.3400 - val_FN: 43.7200\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0438 - Accuracy: 0.9848 - Precision: 0.9607 - Recall: 0.9539 - TP: 3216.4600 - TN: 5536.3301 - FP: 110.6700 - FN: 155.5400 - val_loss: 0.0751 - val_Accuracy: 0.9764 - val_Precision: 0.9636 - val_Recall: 0.9459 - val_TP: 760.4700 - val_TN: 1083.3800 - val_FP: 22.6200 - val_FN: 43.5300\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0437 - Accuracy: 0.9850 - Precision: 0.9609 - Recall: 0.9541 - TP: 3217.2700 - TN: 5537.5200 - FP: 109.4800 - FN: 154.7300 - val_loss: 0.0756 - val_Accuracy: 0.9764 - val_Precision: 0.9628 - val_Recall: 0.9459 - val_TP: 760.4800 - val_TN: 1082.6801 - val_FP: 23.3200 - val_FN: 43.5200\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0436 - Accuracy: 0.9847 - Precision: 0.9605 - Recall: 0.9542 - TP: 3217.6399 - TN: 5535.8501 - FP: 111.1500 - FN: 154.3600 - val_loss: 0.0757 - val_Accuracy: 0.9764 - val_Precision: 0.9631 - val_Recall: 0.9458 - val_TP: 760.4300 - val_TN: 1082.8800 - val_FP: 23.1200 - val_FN: 43.5700\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0434 - Accuracy: 0.9850 - Precision: 0.9601 - Recall: 0.9544 - TP: 3218.2600 - TN: 5534.4502 - FP: 112.5500 - FN: 153.7400 - val_loss: 0.0757 - val_Accuracy: 0.9764 - val_Precision: 0.9633 - val_Recall: 0.9456 - val_TP: 760.2800 - val_TN: 1083.0900 - val_FP: 22.9100 - val_FN: 43.7200\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0435 - Accuracy: 0.9848 - Precision: 0.9610 - Recall: 0.9540 - TP: 3216.8701 - TN: 5537.9800 - FP: 109.0200 - FN: 155.1300 - val_loss: 0.0772 - val_Accuracy: 0.9754 - val_Precision: 0.9607 - val_Recall: 0.9460 - val_TP: 760.5900 - val_TN: 1080.4600 - val_FP: 25.5400 - val_FN: 43.4100\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0438 - Accuracy: 0.9849 - Precision: 0.9602 - Recall: 0.9542 - TP: 3217.7100 - TN: 5534.8701 - FP: 112.1300 - FN: 154.2900 - val_loss: 0.0751 - val_Accuracy: 0.9764 - val_Precision: 0.9638 - val_Recall: 0.9458 - val_TP: 760.4200 - val_TN: 1083.6100 - val_FP: 22.3900 - val_FN: 43.5800\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0433 - Accuracy: 0.9854 - Precision: 0.9606 - Recall: 0.9546 - TP: 3218.7600 - TN: 5536.3101 - FP: 110.6900 - FN: 153.2400 - val_loss: 0.0755 - val_Accuracy: 0.9770 - val_Precision: 0.9638 - val_Recall: 0.9455 - val_TP: 760.2100 - val_TN: 1083.6200 - val_FP: 22.3800 - val_FN: 43.7900\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0435 - Accuracy: 0.9849 - Precision: 0.9607 - Recall: 0.9542 - TP: 3217.5500 - TN: 5536.7202 - FP: 110.2800 - FN: 154.4500 - val_loss: 0.0756 - val_Accuracy: 0.9764 - val_Precision: 0.9633 - val_Recall: 0.9458 - val_TP: 760.4500 - val_TN: 1083.0900 - val_FP: 22.9100 - val_FN: 43.5500\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0434 - Accuracy: 0.9853 - Precision: 0.9611 - Recall: 0.9541 - TP: 3217.3799 - TN: 5538.3701 - FP: 108.6300 - FN: 154.6200 - val_loss: 0.0762 - val_Accuracy: 0.9764 - val_Precision: 0.9619 - val_Recall: 0.9460 - val_TP: 760.6200 - val_TN: 1081.6801 - val_FP: 24.3200 - val_FN: 43.3800\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0431 - Accuracy: 0.9853 - Precision: 0.9609 - Recall: 0.9546 - TP: 3218.7600 - TN: 5537.4902 - FP: 109.5100 - FN: 153.2400 - val_loss: 0.0769 - val_Accuracy: 0.9754 - val_Precision: 0.9607 - val_Recall: 0.9462 - val_TP: 760.7200 - val_TN: 1080.4900 - val_FP: 25.5100 - val_FN: 43.2800\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0435 - Accuracy: 0.9849 - Precision: 0.9604 - Recall: 0.9543 - TP: 3218.0400 - TN: 5535.6299 - FP: 111.3700 - FN: 153.9600 - val_loss: 0.0752 - val_Accuracy: 0.9764 - val_Precision: 0.9633 - val_Recall: 0.9461 - val_TP: 760.6500 - val_TN: 1083.1100 - val_FP: 22.8900 - val_FN: 43.3500\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0433 - Accuracy: 0.9851 - Precision: 0.9606 - Recall: 0.9546 - TP: 3218.8101 - TN: 5536.3301 - FP: 110.6700 - FN: 153.1900 - val_loss: 0.0768 - val_Accuracy: 0.9759 - val_Precision: 0.9615 - val_Recall: 0.9460 - val_TP: 760.5700 - val_TN: 1081.3300 - val_FP: 24.6700 - val_FN: 43.4300\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0436 - Accuracy: 0.9849 - Precision: 0.9607 - Recall: 0.9545 - TP: 3218.5100 - TN: 5536.8198 - FP: 110.1800 - FN: 153.4900 - val_loss: 0.0753 - val_Accuracy: 0.9764 - val_Precision: 0.9635 - val_Recall: 0.9460 - val_TP: 760.5800 - val_TN: 1083.2800 - val_FP: 22.7200 - val_FN: 43.4200\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0434 - Accuracy: 0.9854 - Precision: 0.9605 - Recall: 0.9545 - TP: 3218.6599 - TN: 5535.9199 - FP: 111.0800 - FN: 153.3400 - val_loss: 0.0757 - val_Accuracy: 0.9764 - val_Precision: 0.9635 - val_Recall: 0.9457 - val_TP: 760.3600 - val_TN: 1083.3101 - val_FP: 22.6900 - val_FN: 43.6400\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0433 - Accuracy: 0.9850 - Precision: 0.9611 - Recall: 0.9542 - TP: 3217.6799 - TN: 5538.3799 - FP: 108.6200 - FN: 154.3200 - val_loss: 0.0756 - val_Accuracy: 0.9764 - val_Precision: 0.9630 - val_Recall: 0.9461 - val_TP: 760.7000 - val_TN: 1082.8300 - val_FP: 23.1700 - val_FN: 43.3000\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0433 - Accuracy: 0.9854 - Precision: 0.9606 - Recall: 0.9546 - TP: 3218.8601 - TN: 5536.2500 - FP: 110.7500 - FN: 153.1400 - val_loss: 0.0754 - val_Accuracy: 0.9764 - val_Precision: 0.9635 - val_Recall: 0.9460 - val_TP: 760.5500 - val_TN: 1083.3101 - val_FP: 22.6900 - val_FN: 43.4500\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0433 - Accuracy: 0.9851 - Precision: 0.9610 - Recall: 0.9545 - TP: 3218.7000 - TN: 5537.8398 - FP: 109.1600 - FN: 153.3000 - val_loss: 0.0766 - val_Accuracy: 0.9764 - val_Precision: 0.9620 - val_Recall: 0.9459 - val_TP: 760.4700 - val_TN: 1081.7800 - val_FP: 24.2200 - val_FN: 43.5300\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0451 - Accuracy: 0.9845 - Precision: 0.9602 - Recall: 0.9544 - TP: 3218.2200 - TN: 5534.9399 - FP: 112.0600 - FN: 153.7800 - val_loss: 0.0757 - val_Accuracy: 0.9764 - val_Precision: 0.9624 - val_Recall: 0.9461 - val_TP: 760.6500 - val_TN: 1082.2900 - val_FP: 23.7100 - val_FN: 43.3500\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0440 - Accuracy: 0.9846 - Precision: 0.9602 - Recall: 0.9541 - TP: 3217.3701 - TN: 5534.8398 - FP: 112.1600 - FN: 154.6300 - val_loss: 0.0757 - val_Accuracy: 0.9764 - val_Precision: 0.9632 - val_Recall: 0.9457 - val_TP: 760.3100 - val_TN: 1082.9800 - val_FP: 23.0200 - val_FN: 43.6900\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0437 - Accuracy: 0.9849 - Precision: 0.9602 - Recall: 0.9544 - TP: 3218.3799 - TN: 5534.8198 - FP: 112.1800 - FN: 153.6200 - val_loss: 0.0771 - val_Accuracy: 0.9754 - val_Precision: 0.9610 - val_Recall: 0.9457 - val_TP: 760.3500 - val_TN: 1080.6801 - val_FP: 25.3200 - val_FN: 43.6500\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0437 - Accuracy: 0.9848 - Precision: 0.9607 - Recall: 0.9541 - TP: 3217.0601 - TN: 5536.5298 - FP: 110.4700 - FN: 154.9400 - val_loss: 0.0750 - val_Accuracy: 0.9764 - val_Precision: 0.9639 - val_Recall: 0.9458 - val_TP: 760.4000 - val_TN: 1083.6600 - val_FP: 22.3400 - val_FN: 43.6000\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0436 - Accuracy: 0.9851 - Precision: 0.9609 - Recall: 0.9539 - TP: 3216.5000 - TN: 5537.1602 - FP: 109.8400 - FN: 155.5000 - val_loss: 0.0751 - val_Accuracy: 0.9764 - val_Precision: 0.9636 - val_Recall: 0.9458 - val_TP: 760.4300 - val_TN: 1083.4200 - val_FP: 22.5800 - val_FN: 43.5700\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0438 - Accuracy: 0.9850 - Precision: 0.9606 - Recall: 0.9545 - TP: 3218.6001 - TN: 5536.4102 - FP: 110.5900 - FN: 153.4000 - val_loss: 0.0756 - val_Accuracy: 0.9764 - val_Precision: 0.9634 - val_Recall: 0.9457 - val_TP: 760.3100 - val_TN: 1083.2400 - val_FP: 22.7600 - val_FN: 43.6900\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0438 - Accuracy: 0.9851 - Precision: 0.9605 - Recall: 0.9543 - TP: 3217.7600 - TN: 5536.0000 - FP: 111.0000 - FN: 154.2400 - val_loss: 0.0755 - val_Accuracy: 0.9764 - val_Precision: 0.9636 - val_Recall: 0.9457 - val_TP: 760.3300 - val_TN: 1083.3700 - val_FP: 22.6300 - val_FN: 43.6700\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0438 - Accuracy: 0.9851 - Precision: 0.9606 - Recall: 0.9541 - TP: 3217.2900 - TN: 5536.2998 - FP: 110.7000 - FN: 154.7100 - val_loss: 0.0754 - val_Accuracy: 0.9764 - val_Precision: 0.9638 - val_Recall: 0.9456 - val_TP: 760.2400 - val_TN: 1083.5900 - val_FP: 22.4100 - val_FN: 43.7600\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0436 - Accuracy: 0.9850 - Precision: 0.9606 - Recall: 0.9543 - TP: 3217.9600 - TN: 5536.4302 - FP: 110.5700 - FN: 154.0400 - val_loss: 0.0754 - val_Accuracy: 0.9764 - val_Precision: 0.9633 - val_Recall: 0.9459 - val_TP: 760.5000 - val_TN: 1083.1600 - val_FP: 22.8400 - val_FN: 43.5000\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0435 - Accuracy: 0.9851 - Precision: 0.9609 - Recall: 0.9542 - TP: 3217.4600 - TN: 5537.2100 - FP: 109.7900 - FN: 154.5400 - val_loss: 0.0755 - val_Accuracy: 0.9764 - val_Precision: 0.9637 - val_Recall: 0.9456 - val_TP: 760.3000 - val_TN: 1083.4399 - val_FP: 22.5600 - val_FN: 43.7000\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0434 - Accuracy: 0.9848 - Precision: 0.9606 - Recall: 0.9546 - TP: 3219.0300 - TN: 5536.6201 - FP: 110.3800 - FN: 152.9700 - val_loss: 0.0781 - val_Accuracy: 0.9754 - val_Precision: 0.9590 - val_Recall: 0.9462 - val_TP: 760.7200 - val_TN: 1078.7800 - val_FP: 27.2200 - val_FN: 43.2800\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0436 - Accuracy: 0.9847 - Precision: 0.9607 - Recall: 0.9542 - TP: 3217.5901 - TN: 5536.5200 - FP: 110.4800 - FN: 154.4100 - val_loss: 0.0765 - val_Accuracy: 0.9759 - val_Precision: 0.9621 - val_Recall: 0.9459 - val_TP: 760.4800 - val_TN: 1081.8600 - val_FP: 24.1400 - val_FN: 43.5200\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0434 - Accuracy: 0.9851 - Precision: 0.9610 - Recall: 0.9545 - TP: 3218.6299 - TN: 5537.6802 - FP: 109.3200 - FN: 153.3700 - val_loss: 0.0757 - val_Accuracy: 0.9764 - val_Precision: 0.9634 - val_Recall: 0.9457 - val_TP: 760.3500 - val_TN: 1083.1700 - val_FP: 22.8300 - val_FN: 43.6500\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0434 - Accuracy: 0.9850 - Precision: 0.9607 - Recall: 0.9545 - TP: 3218.6001 - TN: 5536.6099 - FP: 110.3900 - FN: 153.4000 - val_loss: 0.0760 - val_Accuracy: 0.9764 - val_Precision: 0.9627 - val_Recall: 0.9461 - val_TP: 760.6400 - val_TN: 1082.5400 - val_FP: 23.4600 - val_FN: 43.3600\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0434 - Accuracy: 0.9850 - Precision: 0.9603 - Recall: 0.9548 - TP: 3219.6101 - TN: 5535.0298 - FP: 111.9700 - FN: 152.3900 - val_loss: 0.0756 - val_Accuracy: 0.9764 - val_Precision: 0.9635 - val_Recall: 0.9458 - val_TP: 760.4200 - val_TN: 1083.3000 - val_FP: 22.7000 - val_FN: 43.5800\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0433 - Accuracy: 0.9851 - Precision: 0.9613 - Recall: 0.9541 - TP: 3217.3401 - TN: 5539.3398 - FP: 107.6600 - FN: 154.6600 - val_loss: 0.0759 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9458 - val_TP: 760.4300 - val_TN: 1083.0000 - val_FP: 23.0000 - val_FN: 43.5700\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0433 - Accuracy: 0.9851 - Precision: 0.9610 - Recall: 0.9544 - TP: 3218.3301 - TN: 5537.8301 - FP: 109.1700 - FN: 153.6700 - val_loss: 0.0755 - val_Accuracy: 0.9764 - val_Precision: 0.9633 - val_Recall: 0.9460 - val_TP: 760.5700 - val_TN: 1083.1700 - val_FP: 22.8300 - val_FN: 43.4300\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0432 - Accuracy: 0.9851 - Precision: 0.9609 - Recall: 0.9545 - TP: 3218.6699 - TN: 5537.6499 - FP: 109.3500 - FN: 153.3300 - val_loss: 0.0755 - val_Accuracy: 0.9770 - val_Precision: 0.9637 - val_Recall: 0.9458 - val_TP: 760.4000 - val_TN: 1083.5400 - val_FP: 22.4600 - val_FN: 43.6000\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0432 - Accuracy: 0.9849 - Precision: 0.9610 - Recall: 0.9546 - TP: 3218.9199 - TN: 5538.2300 - FP: 108.7700 - FN: 153.0800 - val_loss: 0.0760 - val_Accuracy: 0.9764 - val_Precision: 0.9626 - val_Recall: 0.9462 - val_TP: 760.7200 - val_TN: 1082.5000 - val_FP: 23.5000 - val_FN: 43.2800\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0432 - Accuracy: 0.9849 - Precision: 0.9608 - Recall: 0.9546 - TP: 3218.8601 - TN: 5537.2598 - FP: 109.7400 - FN: 153.1400 - val_loss: 0.0756 - val_Accuracy: 0.9764 - val_Precision: 0.9633 - val_Recall: 0.9460 - val_TP: 760.6000 - val_TN: 1083.1801 - val_FP: 22.8200 - val_FN: 43.4000\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0430 - Accuracy: 0.9853 - Precision: 0.9609 - Recall: 0.9550 - TP: 3220.2400 - TN: 5537.8599 - FP: 109.1400 - FN: 151.7600 - val_loss: 0.0758 - val_Accuracy: 0.9764 - val_Precision: 0.9629 - val_Recall: 0.9462 - val_TP: 760.7600 - val_TN: 1082.7900 - val_FP: 23.2100 - val_FN: 43.2400\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0430 - Accuracy: 0.9849 - Precision: 0.9608 - Recall: 0.9549 - TP: 3219.7700 - TN: 5537.1802 - FP: 109.8200 - FN: 152.2300 - val_loss: 0.0758 - val_Accuracy: 0.9764 - val_Precision: 0.9633 - val_Recall: 0.9460 - val_TP: 760.5600 - val_TN: 1083.1200 - val_FP: 22.8800 - val_FN: 43.4400\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0433 - Accuracy: 0.9847 - Precision: 0.9612 - Recall: 0.9544 - TP: 3218.0801 - TN: 5538.9199 - FP: 108.0800 - FN: 153.9200 - val_loss: 0.0754 - val_Accuracy: 0.9764 - val_Precision: 0.9635 - val_Recall: 0.9461 - val_TP: 760.7000 - val_TN: 1083.3600 - val_FP: 22.6400 - val_FN: 43.3000\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0433 - Accuracy: 0.9853 - Precision: 0.9606 - Recall: 0.9550 - TP: 3220.2400 - TN: 5536.5298 - FP: 110.4700 - FN: 151.7600 - val_loss: 0.0756 - val_Accuracy: 0.9764 - val_Precision: 0.9634 - val_Recall: 0.9461 - val_TP: 760.6600 - val_TN: 1083.2100 - val_FP: 22.7900 - val_FN: 43.3400\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0443 - Accuracy: 0.9853 - Precision: 0.9608 - Recall: 0.9546 - TP: 3218.7600 - TN: 5537.3701 - FP: 109.6300 - FN: 153.2400 - val_loss: 0.0758 - val_Accuracy: 0.9770 - val_Precision: 0.9624 - val_Recall: 0.9462 - val_TP: 760.7600 - val_TN: 1082.2800 - val_FP: 23.7200 - val_FN: 43.2400\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0435 - Accuracy: 0.9848 - Precision: 0.9615 - Recall: 0.9540 - TP: 3216.7700 - TN: 5540.1499 - FP: 106.8500 - FN: 155.2300 - val_loss: 0.0758 - val_Accuracy: 0.9764 - val_Precision: 0.9622 - val_Recall: 0.9461 - val_TP: 760.6800 - val_TN: 1081.9700 - val_FP: 24.0300 - val_FN: 43.3200\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0440 - Accuracy: 0.9849 - Precision: 0.9602 - Recall: 0.9543 - TP: 3217.7700 - TN: 5534.9902 - FP: 112.0100 - FN: 154.2300 - val_loss: 0.0752 - val_Accuracy: 0.9764 - val_Precision: 0.9639 - val_Recall: 0.9457 - val_TP: 760.3100 - val_TN: 1083.6700 - val_FP: 22.3300 - val_FN: 43.6900\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0437 - Accuracy: 0.9850 - Precision: 0.9604 - Recall: 0.9548 - TP: 3219.6399 - TN: 5535.9399 - FP: 111.0600 - FN: 152.3600 - val_loss: 0.0753 - val_Accuracy: 0.9764 - val_Precision: 0.9637 - val_Recall: 0.9458 - val_TP: 760.4300 - val_TN: 1083.4301 - val_FP: 22.5700 - val_FN: 43.5700\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0436 - Accuracy: 0.9848 - Precision: 0.9604 - Recall: 0.9543 - TP: 3217.8201 - TN: 5535.6299 - FP: 111.3700 - FN: 154.1800 - val_loss: 0.0769 - val_Accuracy: 0.9754 - val_Precision: 0.9610 - val_Recall: 0.9460 - val_TP: 760.5900 - val_TN: 1080.7100 - val_FP: 25.2900 - val_FN: 43.4100\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0436 - Accuracy: 0.9853 - Precision: 0.9608 - Recall: 0.9542 - TP: 3217.4399 - TN: 5536.8799 - FP: 110.1200 - FN: 154.5600 - val_loss: 0.0758 - val_Accuracy: 0.9764 - val_Precision: 0.9627 - val_Recall: 0.9461 - val_TP: 760.6800 - val_TN: 1082.5800 - val_FP: 23.4200 - val_FN: 43.3200\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0433 - Accuracy: 0.9850 - Precision: 0.9608 - Recall: 0.9543 - TP: 3217.7500 - TN: 5537.0498 - FP: 109.9500 - FN: 154.2500 - val_loss: 0.0763 - val_Accuracy: 0.9764 - val_Precision: 0.9624 - val_Recall: 0.9457 - val_TP: 760.3600 - val_TN: 1082.1400 - val_FP: 23.8600 - val_FN: 43.6400\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0434 - Accuracy: 0.9853 - Precision: 0.9607 - Recall: 0.9541 - TP: 3217.3301 - TN: 5536.8501 - FP: 110.1500 - FN: 154.6700 - val_loss: 0.0756 - val_Accuracy: 0.9764 - val_Precision: 0.9629 - val_Recall: 0.9461 - val_TP: 760.6700 - val_TN: 1082.7800 - val_FP: 23.2200 - val_FN: 43.3300\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0434 - Accuracy: 0.9854 - Precision: 0.9606 - Recall: 0.9548 - TP: 3219.5400 - TN: 5536.3799 - FP: 110.6200 - FN: 152.4600 - val_loss: 0.0759 - val_Accuracy: 0.9764 - val_Precision: 0.9633 - val_Recall: 0.9457 - val_TP: 760.3100 - val_TN: 1083.1500 - val_FP: 22.8500 - val_FN: 43.6900\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0432 - Accuracy: 0.9851 - Precision: 0.9612 - Recall: 0.9544 - TP: 3218.2600 - TN: 5538.8398 - FP: 108.1600 - FN: 153.7400 - val_loss: 0.0765 - val_Accuracy: 0.9764 - val_Precision: 0.9618 - val_Recall: 0.9461 - val_TP: 760.6600 - val_TN: 1081.5500 - val_FP: 24.4500 - val_FN: 43.3400\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0436 - Accuracy: 0.9847 - Precision: 0.9607 - Recall: 0.9543 - TP: 3217.8701 - TN: 5536.7998 - FP: 110.2000 - FN: 154.1300 - val_loss: 0.0759 - val_Accuracy: 0.9764 - val_Precision: 0.9626 - val_Recall: 0.9461 - val_TP: 760.6800 - val_TN: 1082.4900 - val_FP: 23.5100 - val_FN: 43.3200\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0432 - Accuracy: 0.9850 - Precision: 0.9610 - Recall: 0.9545 - TP: 3218.7000 - TN: 5537.8599 - FP: 109.1400 - FN: 153.3000 - val_loss: 0.0767 - val_Accuracy: 0.9759 - val_Precision: 0.9617 - val_Recall: 0.9460 - val_TP: 760.5900 - val_TN: 1081.4800 - val_FP: 24.5200 - val_FN: 43.4100\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0432 - Accuracy: 0.9854 - Precision: 0.9608 - Recall: 0.9548 - TP: 3219.6001 - TN: 5537.0098 - FP: 109.9900 - FN: 152.4000 - val_loss: 0.0756 - val_Accuracy: 0.9764 - val_Precision: 0.9632 - val_Recall: 0.9461 - val_TP: 760.6400 - val_TN: 1083.0699 - val_FP: 22.9300 - val_FN: 43.3600\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0433 - Accuracy: 0.9848 - Precision: 0.9608 - Recall: 0.9545 - TP: 3218.6101 - TN: 5537.3799 - FP: 109.6200 - FN: 153.3900 - val_loss: 0.0807 - val_Accuracy: 0.9754 - val_Precision: 0.9556 - val_Recall: 0.9462 - val_TP: 760.7600 - val_TN: 1075.4399 - val_FP: 30.5600 - val_FN: 43.2400\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0437 - Accuracy: 0.9851 - Precision: 0.9602 - Recall: 0.9547 - TP: 3219.3601 - TN: 5534.8599 - FP: 112.1400 - FN: 152.6400 - val_loss: 0.0755 - val_Accuracy: 0.9764 - val_Precision: 0.9638 - val_Recall: 0.9457 - val_TP: 760.3700 - val_TN: 1083.5699 - val_FP: 22.4300 - val_FN: 43.6300\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0431 - Accuracy: 0.9847 - Precision: 0.9611 - Recall: 0.9543 - TP: 3217.9399 - TN: 5538.3501 - FP: 108.6500 - FN: 154.0600 - val_loss: 0.0766 - val_Accuracy: 0.9764 - val_Precision: 0.9622 - val_Recall: 0.9458 - val_TP: 760.4300 - val_TN: 1082.0000 - val_FP: 24.0000 - val_FN: 43.5700\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0433 - Accuracy: 0.9850 - Precision: 0.9605 - Recall: 0.9548 - TP: 3219.7300 - TN: 5536.0298 - FP: 110.9700 - FN: 152.2700 - val_loss: 0.0762 - val_Accuracy: 0.9764 - val_Precision: 0.9630 - val_Recall: 0.9458 - val_TP: 760.4100 - val_TN: 1082.9100 - val_FP: 23.0900 - val_FN: 43.5900\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0431 - Accuracy: 0.9851 - Precision: 0.9612 - Recall: 0.9543 - TP: 3217.7500 - TN: 5538.9302 - FP: 108.0700 - FN: 154.2500 - val_loss: 0.0763 - val_Accuracy: 0.9770 - val_Precision: 0.9617 - val_Recall: 0.9464 - val_TP: 760.9300 - val_TN: 1081.5100 - val_FP: 24.4900 - val_FN: 43.0700\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0428 - Accuracy: 0.9848 - Precision: 0.9606 - Recall: 0.9547 - TP: 3219.2100 - TN: 5536.3701 - FP: 110.6300 - FN: 152.7900 - val_loss: 0.0766 - val_Accuracy: 0.9764 - val_Precision: 0.9621 - val_Recall: 0.9459 - val_TP: 760.5300 - val_TN: 1081.9301 - val_FP: 24.0700 - val_FN: 43.4700\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0428 - Accuracy: 0.9851 - Precision: 0.9607 - Recall: 0.9551 - TP: 3220.5701 - TN: 5537.0400 - FP: 109.9600 - FN: 151.4300 - val_loss: 0.0769 - val_Accuracy: 0.9759 - val_Precision: 0.9617 - val_Recall: 0.9460 - val_TP: 760.5700 - val_TN: 1081.5699 - val_FP: 24.4300 - val_FN: 43.4300\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0431 - Accuracy: 0.9849 - Precision: 0.9613 - Recall: 0.9547 - TP: 3219.1599 - TN: 5539.2300 - FP: 107.7700 - FN: 152.8400 - val_loss: 0.0763 - val_Accuracy: 0.9764 - val_Precision: 0.9627 - val_Recall: 0.9460 - val_TP: 760.5700 - val_TN: 1082.5800 - val_FP: 23.4200 - val_FN: 43.4300\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0429 - Accuracy: 0.9850 - Precision: 0.9611 - Recall: 0.9546 - TP: 3218.8501 - TN: 5538.5498 - FP: 108.4500 - FN: 153.1500 - val_loss: 0.0767 - val_Accuracy: 0.9764 - val_Precision: 0.9618 - val_Recall: 0.9462 - val_TP: 760.7300 - val_TN: 1081.6600 - val_FP: 24.3400 - val_FN: 43.2700\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0428 - Accuracy: 0.9850 - Precision: 0.9608 - Recall: 0.9547 - TP: 3219.3701 - TN: 5537.1201 - FP: 109.8800 - FN: 152.6300 - val_loss: 0.0762 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9459 - val_TP: 760.4800 - val_TN: 1083.0500 - val_FP: 22.9500 - val_FN: 43.5200\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 4ms/step - loss: 0.0443 - Accuracy: 0.9849 - Precision: 0.9615 - Recall: 0.9538 - TP: 3216.3201 - TN: 5540.1001 - FP: 106.9000 - FN: 155.6800 - val_loss: 0.0753 - val_Accuracy: 0.9764 - val_Precision: 0.9631 - val_Recall: 0.9463 - val_TP: 760.8200 - val_TN: 1082.9500 - val_FP: 23.0500 - val_FN: 43.1800\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0437 - Accuracy: 0.9848 - Precision: 0.9602 - Recall: 0.9545 - TP: 3218.4800 - TN: 5534.8501 - FP: 112.1500 - FN: 153.5200 - val_loss: 0.0771 - val_Accuracy: 0.9754 - val_Precision: 0.9608 - val_Recall: 0.9462 - val_TP: 760.7500 - val_TN: 1080.5200 - val_FP: 25.4800 - val_FN: 43.2500\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0437 - Accuracy: 0.9850 - Precision: 0.9609 - Recall: 0.9543 - TP: 3217.7700 - TN: 5537.6699 - FP: 109.3300 - FN: 154.2300 - val_loss: 0.0787 - val_Accuracy: 0.9754 - val_Precision: 0.9589 - val_Recall: 0.9460 - val_TP: 760.5600 - val_TN: 1078.6500 - val_FP: 27.3500 - val_FN: 43.4400\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0437 - Accuracy: 0.9848 - Precision: 0.9607 - Recall: 0.9543 - TP: 3217.7600 - TN: 5536.8701 - FP: 110.1300 - FN: 154.2400 - val_loss: 0.0769 - val_Accuracy: 0.9759 - val_Precision: 0.9612 - val_Recall: 0.9460 - val_TP: 760.5500 - val_TN: 1080.9200 - val_FP: 25.0800 - val_FN: 43.4500\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0437 - Accuracy: 0.9849 - Precision: 0.9606 - Recall: 0.9544 - TP: 3218.1399 - TN: 5536.6401 - FP: 110.3600 - FN: 153.8600 - val_loss: 0.0771 - val_Accuracy: 0.9754 - val_Precision: 0.9609 - val_Recall: 0.9461 - val_TP: 760.6300 - val_TN: 1080.6500 - val_FP: 25.3500 - val_FN: 43.3700\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0436 - Accuracy: 0.9849 - Precision: 0.9607 - Recall: 0.9544 - TP: 3218.1599 - TN: 5536.7798 - FP: 110.2200 - FN: 153.8400 - val_loss: 0.0754 - val_Accuracy: 0.9764 - val_Precision: 0.9630 - val_Recall: 0.9462 - val_TP: 760.7200 - val_TN: 1082.9000 - val_FP: 23.1000 - val_FN: 43.2800\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0434 - Accuracy: 0.9851 - Precision: 0.9609 - Recall: 0.9546 - TP: 3219.0500 - TN: 5537.3701 - FP: 109.6300 - FN: 152.9500 - val_loss: 0.0759 - val_Accuracy: 0.9764 - val_Precision: 0.9635 - val_Recall: 0.9456 - val_TP: 760.2800 - val_TN: 1083.3199 - val_FP: 22.6800 - val_FN: 43.7200\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0435 - Accuracy: 0.9846 - Precision: 0.9604 - Recall: 0.9545 - TP: 3218.6799 - TN: 5535.6699 - FP: 111.3300 - FN: 153.3200 - val_loss: 0.0758 - val_Accuracy: 0.9764 - val_Precision: 0.9634 - val_Recall: 0.9457 - val_TP: 760.3600 - val_TN: 1083.2500 - val_FP: 22.7500 - val_FN: 43.6400\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0435 - Accuracy: 0.9849 - Precision: 0.9606 - Recall: 0.9547 - TP: 3219.2400 - TN: 5536.5000 - FP: 110.5000 - FN: 152.7600 - val_loss: 0.0757 - val_Accuracy: 0.9764 - val_Precision: 0.9638 - val_Recall: 0.9456 - val_TP: 760.2500 - val_TN: 1083.6400 - val_FP: 22.3600 - val_FN: 43.7500\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0437 - Accuracy: 0.9848 - Precision: 0.9608 - Recall: 0.9542 - TP: 3217.4600 - TN: 5537.2100 - FP: 109.7900 - FN: 154.5400 - val_loss: 0.0763 - val_Accuracy: 0.9764 - val_Precision: 0.9624 - val_Recall: 0.9459 - val_TP: 760.5300 - val_TN: 1082.1400 - val_FP: 23.8600 - val_FN: 43.4700\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0433 - Accuracy: 0.9850 - Precision: 0.9608 - Recall: 0.9542 - TP: 3217.7200 - TN: 5536.8101 - FP: 110.1900 - FN: 154.2800 - val_loss: 0.0765 - val_Accuracy: 0.9764 - val_Precision: 0.9623 - val_Recall: 0.9458 - val_TP: 760.4500 - val_TN: 1082.0400 - val_FP: 23.9600 - val_FN: 43.5500\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0432 - Accuracy: 0.9848 - Precision: 0.9613 - Recall: 0.9546 - TP: 3218.9700 - TN: 5539.1001 - FP: 107.9000 - FN: 153.0300 - val_loss: 0.0755 - val_Accuracy: 0.9764 - val_Precision: 0.9637 - val_Recall: 0.9459 - val_TP: 760.5100 - val_TN: 1083.5100 - val_FP: 22.4900 - val_FN: 43.4900\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0431 - Accuracy: 0.9854 - Precision: 0.9607 - Recall: 0.9546 - TP: 3219.0701 - TN: 5537.0801 - FP: 109.9200 - FN: 152.9300 - val_loss: 0.0755 - val_Accuracy: 0.9764 - val_Precision: 0.9632 - val_Recall: 0.9462 - val_TP: 760.7700 - val_TN: 1083.0900 - val_FP: 22.9100 - val_FN: 43.2300\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0436 - Accuracy: 0.9848 - Precision: 0.9606 - Recall: 0.9544 - TP: 3218.1299 - TN: 5536.7002 - FP: 110.3000 - FN: 153.8700 - val_loss: 0.0763 - val_Accuracy: 0.9764 - val_Precision: 0.9626 - val_Recall: 0.9461 - val_TP: 760.6500 - val_TN: 1082.4800 - val_FP: 23.5200 - val_FN: 43.3500\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0430 - Accuracy: 0.9851 - Precision: 0.9609 - Recall: 0.9548 - TP: 3219.5100 - TN: 5537.7500 - FP: 109.2500 - FN: 152.4900 - val_loss: 0.0770 - val_Accuracy: 0.9754 - val_Precision: 0.9616 - val_Recall: 0.9461 - val_TP: 760.6600 - val_TN: 1081.3900 - val_FP: 24.6100 - val_FN: 43.3400\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0431 - Accuracy: 0.9851 - Precision: 0.9608 - Recall: 0.9547 - TP: 3219.0901 - TN: 5537.3901 - FP: 109.6100 - FN: 152.9100 - val_loss: 0.0758 - val_Accuracy: 0.9770 - val_Precision: 0.9638 - val_Recall: 0.9457 - val_TP: 760.3700 - val_TN: 1083.5699 - val_FP: 22.4300 - val_FN: 43.6300\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0431 - Accuracy: 0.9849 - Precision: 0.9614 - Recall: 0.9543 - TP: 3218.0400 - TN: 5539.2798 - FP: 107.7200 - FN: 153.9600 - val_loss: 0.0765 - val_Accuracy: 0.9770 - val_Precision: 0.9613 - val_Recall: 0.9466 - val_TP: 761.0900 - val_TN: 1081.2000 - val_FP: 24.8000 - val_FN: 42.9100\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0432 - Accuracy: 0.9853 - Precision: 0.9604 - Recall: 0.9551 - TP: 3220.6899 - TN: 5535.5601 - FP: 111.4400 - FN: 151.3100 - val_loss: 0.0760 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9460 - val_TP: 760.5500 - val_TN: 1083.1400 - val_FP: 22.8600 - val_FN: 43.4500\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0428 - Accuracy: 0.9851 - Precision: 0.9614 - Recall: 0.9547 - TP: 3219.3701 - TN: 5539.8501 - FP: 107.1500 - FN: 152.6300 - val_loss: 0.0764 - val_Accuracy: 0.9764 - val_Precision: 0.9623 - val_Recall: 0.9461 - val_TP: 760.6600 - val_TN: 1082.1000 - val_FP: 23.9000 - val_FN: 43.3400\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0430 - Accuracy: 0.9854 - Precision: 0.9610 - Recall: 0.9548 - TP: 3219.6201 - TN: 5537.6699 - FP: 109.3300 - FN: 152.3800 - val_loss: 0.0756 - val_Accuracy: 0.9764 - val_Precision: 0.9633 - val_Recall: 0.9463 - val_TP: 760.8100 - val_TN: 1083.1500 - val_FP: 22.8500 - val_FN: 43.1900\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0431 - Accuracy: 0.9851 - Precision: 0.9611 - Recall: 0.9545 - TP: 3218.6799 - TN: 5538.4502 - FP: 108.5500 - FN: 153.3200 - val_loss: 0.0760 - val_Accuracy: 0.9770 - val_Precision: 0.9628 - val_Recall: 0.9464 - val_TP: 760.9000 - val_TN: 1082.6801 - val_FP: 23.3200 - val_FN: 43.1000\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 4ms/step - loss: 0.0437 - Accuracy: 0.9851 - Precision: 0.9609 - Recall: 0.9544 - TP: 3218.1001 - TN: 5537.5098 - FP: 109.4900 - FN: 153.9000 - val_loss: 0.0760 - val_Accuracy: 0.9764 - val_Precision: 0.9623 - val_Recall: 0.9460 - val_TP: 760.5900 - val_TN: 1082.0800 - val_FP: 23.9200 - val_FN: 43.4100\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0436 - Accuracy: 0.9848 - Precision: 0.9605 - Recall: 0.9545 - TP: 3218.4500 - TN: 5535.7402 - FP: 111.2600 - FN: 153.5500 - val_loss: 0.0756 - val_Accuracy: 0.9764 - val_Precision: 0.9633 - val_Recall: 0.9459 - val_TP: 760.4800 - val_TN: 1083.1400 - val_FP: 22.8600 - val_FN: 43.5200\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0434 - Accuracy: 0.9850 - Precision: 0.9607 - Recall: 0.9541 - TP: 3217.3601 - TN: 5536.8198 - FP: 110.1800 - FN: 154.6400 - val_loss: 0.0776 - val_Accuracy: 0.9754 - val_Precision: 0.9595 - val_Recall: 0.9465 - val_TP: 760.9500 - val_TN: 1079.2400 - val_FP: 26.7600 - val_FN: 43.0500\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0436 - Accuracy: 0.9847 - Precision: 0.9610 - Recall: 0.9542 - TP: 3217.5601 - TN: 5538.0098 - FP: 108.9900 - FN: 154.4400 - val_loss: 0.0763 - val_Accuracy: 0.9764 - val_Precision: 0.9621 - val_Recall: 0.9460 - val_TP: 760.5900 - val_TN: 1081.8700 - val_FP: 24.1300 - val_FN: 43.4100\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0435 - Accuracy: 0.9851 - Precision: 0.9607 - Recall: 0.9545 - TP: 3218.5200 - TN: 5537.0898 - FP: 109.9100 - FN: 153.4800 - val_loss: 0.0755 - val_Accuracy: 0.9764 - val_Precision: 0.9631 - val_Recall: 0.9461 - val_TP: 760.6600 - val_TN: 1082.9700 - val_FP: 23.0300 - val_FN: 43.3400\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0434 - Accuracy: 0.9853 - Precision: 0.9603 - Recall: 0.9549 - TP: 3219.8701 - TN: 5535.0400 - FP: 111.9600 - FN: 152.1300 - val_loss: 0.0762 - val_Accuracy: 0.9764 - val_Precision: 0.9632 - val_Recall: 0.9457 - val_TP: 760.3100 - val_TN: 1083.0200 - val_FP: 22.9800 - val_FN: 43.6900\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0433 - Accuracy: 0.9849 - Precision: 0.9609 - Recall: 0.9543 - TP: 3218.0300 - TN: 5537.8101 - FP: 109.1900 - FN: 153.9700 - val_loss: 0.0765 - val_Accuracy: 0.9764 - val_Precision: 0.9624 - val_Recall: 0.9458 - val_TP: 760.3900 - val_TN: 1082.1899 - val_FP: 23.8100 - val_FN: 43.6100\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0434 - Accuracy: 0.9849 - Precision: 0.9608 - Recall: 0.9547 - TP: 3219.4099 - TN: 5537.5298 - FP: 109.4700 - FN: 152.5900 - val_loss: 0.0758 - val_Accuracy: 0.9764 - val_Precision: 0.9633 - val_Recall: 0.9459 - val_TP: 760.4800 - val_TN: 1083.1600 - val_FP: 22.8400 - val_FN: 43.5200\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0437 - Accuracy: 0.9850 - Precision: 0.9605 - Recall: 0.9544 - TP: 3218.3000 - TN: 5535.8901 - FP: 111.1100 - FN: 153.7000 - val_loss: 0.0762 - val_Accuracy: 0.9764 - val_Precision: 0.9624 - val_Recall: 0.9459 - val_TP: 760.5200 - val_TN: 1082.1899 - val_FP: 23.8100 - val_FN: 43.4800\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0438 - Accuracy: 0.9848 - Precision: 0.9610 - Recall: 0.9541 - TP: 3217.3799 - TN: 5537.8901 - FP: 109.1100 - FN: 154.6200 - val_loss: 0.0760 - val_Accuracy: 0.9764 - val_Precision: 0.9631 - val_Recall: 0.9459 - val_TP: 760.5400 - val_TN: 1082.9900 - val_FP: 23.0100 - val_FN: 43.4600\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0432 - Accuracy: 0.9850 - Precision: 0.9607 - Recall: 0.9547 - TP: 3219.2000 - TN: 5536.8901 - FP: 110.1100 - FN: 152.8000 - val_loss: 0.0762 - val_Accuracy: 0.9764 - val_Precision: 0.9627 - val_Recall: 0.9460 - val_TP: 760.6100 - val_TN: 1082.5601 - val_FP: 23.4400 - val_FN: 43.3900\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0432 - Accuracy: 0.9853 - Precision: 0.9607 - Recall: 0.9548 - TP: 3219.6299 - TN: 5536.7598 - FP: 110.2400 - FN: 152.3700 - val_loss: 0.0759 - val_Accuracy: 0.9770 - val_Precision: 0.9637 - val_Recall: 0.9457 - val_TP: 760.3400 - val_TN: 1083.4800 - val_FP: 22.5200 - val_FN: 43.6600\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0431 - Accuracy: 0.9851 - Precision: 0.9614 - Recall: 0.9544 - TP: 3218.3000 - TN: 5539.6802 - FP: 107.3200 - FN: 153.7000 - val_loss: 0.0759 - val_Accuracy: 0.9764 - val_Precision: 0.9633 - val_Recall: 0.9459 - val_TP: 760.5200 - val_TN: 1083.1200 - val_FP: 22.8800 - val_FN: 43.4800\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0432 - Accuracy: 0.9853 - Precision: 0.9606 - Recall: 0.9548 - TP: 3219.4800 - TN: 5536.7998 - FP: 110.2000 - FN: 152.5200 - val_loss: 0.0761 - val_Accuracy: 0.9764 - val_Precision: 0.9627 - val_Recall: 0.9462 - val_TP: 760.7200 - val_TN: 1082.6400 - val_FP: 23.3600 - val_FN: 43.2800\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0431 - Accuracy: 0.9848 - Precision: 0.9616 - Recall: 0.9545 - TP: 3218.5100 - TN: 5540.6499 - FP: 106.3500 - FN: 153.4900 - val_loss: 0.0776 - val_Accuracy: 0.9764 - val_Precision: 0.9594 - val_Recall: 0.9468 - val_TP: 761.2300 - val_TN: 1079.1801 - val_FP: 26.8200 - val_FN: 42.7700\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0431 - Accuracy: 0.9854 - Precision: 0.9606 - Recall: 0.9550 - TP: 3220.2600 - TN: 5536.2598 - FP: 110.7400 - FN: 151.7400 - val_loss: 0.0757 - val_Accuracy: 0.9764 - val_Precision: 0.9630 - val_Recall: 0.9464 - val_TP: 760.9000 - val_TN: 1082.8700 - val_FP: 23.1300 - val_FN: 43.1000\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0431 - Accuracy: 0.9854 - Precision: 0.9611 - Recall: 0.9548 - TP: 3219.4299 - TN: 5538.4800 - FP: 108.5200 - FN: 152.5700 - val_loss: 0.0770 - val_Accuracy: 0.9764 - val_Precision: 0.9607 - val_Recall: 0.9467 - val_TP: 761.1800 - val_TN: 1080.6300 - val_FP: 25.3700 - val_FN: 42.8200\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0433 - Accuracy: 0.9851 - Precision: 0.9606 - Recall: 0.9549 - TP: 3219.9500 - TN: 5536.1201 - FP: 110.8800 - FN: 152.0500 - val_loss: 0.0760 - val_Accuracy: 0.9764 - val_Precision: 0.9631 - val_Recall: 0.9461 - val_TP: 760.6700 - val_TN: 1083.0000 - val_FP: 23.0000 - val_FN: 43.3300\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0428 - Accuracy: 0.9850 - Precision: 0.9609 - Recall: 0.9549 - TP: 3219.9399 - TN: 5537.3599 - FP: 109.6400 - FN: 152.0600 - val_loss: 0.0768 - val_Accuracy: 0.9764 - val_Precision: 0.9623 - val_Recall: 0.9458 - val_TP: 760.4600 - val_TN: 1082.1000 - val_FP: 23.9000 - val_FN: 43.5400\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0431 - Accuracy: 0.9845 - Precision: 0.9615 - Recall: 0.9543 - TP: 3217.7800 - TN: 5540.1699 - FP: 106.8300 - FN: 154.2200 - val_loss: 0.0760 - val_Accuracy: 0.9770 - val_Precision: 0.9628 - val_Recall: 0.9464 - val_TP: 760.9100 - val_TN: 1082.6801 - val_FP: 23.3200 - val_FN: 43.0900\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0429 - Accuracy: 0.9853 - Precision: 0.9606 - Recall: 0.9551 - TP: 3220.4800 - TN: 5536.3101 - FP: 110.6900 - FN: 151.5200 - val_loss: 0.0770 - val_Accuracy: 0.9759 - val_Precision: 0.9620 - val_Recall: 0.9460 - val_TP: 760.5800 - val_TN: 1081.8199 - val_FP: 24.1800 - val_FN: 43.4200\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0427 - Accuracy: 0.9849 - Precision: 0.9611 - Recall: 0.9547 - TP: 3219.1599 - TN: 5538.4102 - FP: 108.5900 - FN: 152.8400 - val_loss: 0.0762 - val_Accuracy: 0.9764 - val_Precision: 0.9629 - val_Recall: 0.9462 - val_TP: 760.7700 - val_TN: 1082.7600 - val_FP: 23.2400 - val_FN: 43.2300\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0427 - Accuracy: 0.9851 - Precision: 0.9611 - Recall: 0.9549 - TP: 3219.8899 - TN: 5538.3701 - FP: 108.6300 - FN: 152.1100 - val_loss: 0.0763 - val_Accuracy: 0.9770 - val_Precision: 0.9630 - val_Recall: 0.9461 - val_TP: 760.6900 - val_TN: 1082.9000 - val_FP: 23.1000 - val_FN: 43.3100\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0427 - Accuracy: 0.9850 - Precision: 0.9610 - Recall: 0.9550 - TP: 3220.1299 - TN: 5538.1299 - FP: 108.8700 - FN: 151.8700 - val_loss: 0.0759 - val_Accuracy: 0.9770 - val_Precision: 0.9634 - val_Recall: 0.9462 - val_TP: 760.7100 - val_TN: 1083.2400 - val_FP: 22.7600 - val_FN: 43.2900\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0430 - Accuracy: 0.9850 - Precision: 0.9612 - Recall: 0.9547 - TP: 3219.1101 - TN: 5539.2402 - FP: 107.7600 - FN: 152.8900 - val_loss: 0.0774 - val_Accuracy: 0.9759 - val_Precision: 0.9613 - val_Recall: 0.9463 - val_TP: 760.8300 - val_TN: 1081.2100 - val_FP: 24.7900 - val_FN: 43.1700\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0435 - Accuracy: 0.9850 - Precision: 0.9612 - Recall: 0.9543 - TP: 3217.7400 - TN: 5538.7100 - FP: 108.2900 - FN: 154.2600 - val_loss: 0.0778 - val_Accuracy: 0.9754 - val_Precision: 0.9603 - val_Recall: 0.9459 - val_TP: 760.4800 - val_TN: 1080.0000 - val_FP: 26.0000 - val_FN: 43.5200\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0434 - Accuracy: 0.9854 - Precision: 0.9602 - Recall: 0.9550 - TP: 3220.2500 - TN: 5534.5898 - FP: 112.4100 - FN: 151.7500 - val_loss: 0.0769 - val_Accuracy: 0.9754 - val_Precision: 0.9608 - val_Recall: 0.9465 - val_TP: 760.9500 - val_TN: 1080.5300 - val_FP: 25.4700 - val_FN: 43.0500\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0436 - Accuracy: 0.9850 - Precision: 0.9608 - Recall: 0.9545 - TP: 3218.5300 - TN: 5537.2202 - FP: 109.7800 - FN: 153.4700 - val_loss: 0.0762 - val_Accuracy: 0.9764 - val_Precision: 0.9632 - val_Recall: 0.9457 - val_TP: 760.3500 - val_TN: 1083.0200 - val_FP: 22.9800 - val_FN: 43.6500\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0433 - Accuracy: 0.9847 - Precision: 0.9612 - Recall: 0.9541 - TP: 3217.2100 - TN: 5538.7798 - FP: 108.2200 - FN: 154.7900 - val_loss: 0.0771 - val_Accuracy: 0.9754 - val_Precision: 0.9614 - val_Recall: 0.9461 - val_TP: 760.6800 - val_TN: 1081.2600 - val_FP: 24.7400 - val_FN: 43.3200\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0432 - Accuracy: 0.9851 - Precision: 0.9605 - Recall: 0.9550 - TP: 3220.1499 - TN: 5535.7500 - FP: 111.2500 - FN: 151.8500 - val_loss: 0.0757 - val_Accuracy: 0.9764 - val_Precision: 0.9637 - val_Recall: 0.9457 - val_TP: 760.3800 - val_TN: 1083.5000 - val_FP: 22.5000 - val_FN: 43.6200\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0436 - Accuracy: 0.9846 - Precision: 0.9605 - Recall: 0.9544 - TP: 3218.3201 - TN: 5535.9702 - FP: 111.0300 - FN: 153.6800 - val_loss: 0.0754 - val_Accuracy: 0.9770 - val_Precision: 0.9645 - val_Recall: 0.9456 - val_TP: 760.2300 - val_TN: 1084.2900 - val_FP: 21.7100 - val_FN: 43.7700\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0432 - Accuracy: 0.9850 - Precision: 0.9612 - Recall: 0.9543 - TP: 3217.9900 - TN: 5538.9702 - FP: 108.0300 - FN: 154.0100 - val_loss: 0.0779 - val_Accuracy: 0.9754 - val_Precision: 0.9600 - val_Recall: 0.9461 - val_TP: 760.6500 - val_TN: 1079.7900 - val_FP: 26.2100 - val_FN: 43.3500\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0433 - Accuracy: 0.9849 - Precision: 0.9609 - Recall: 0.9546 - TP: 3218.8799 - TN: 5537.6201 - FP: 109.3800 - FN: 153.1200 - val_loss: 0.0763 - val_Accuracy: 0.9764 - val_Precision: 0.9630 - val_Recall: 0.9459 - val_TP: 760.5100 - val_TN: 1082.8700 - val_FP: 23.1300 - val_FN: 43.4900\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0431 - Accuracy: 0.9850 - Precision: 0.9616 - Recall: 0.9543 - TP: 3217.8501 - TN: 5540.4902 - FP: 106.5100 - FN: 154.1500 - val_loss: 0.0768 - val_Accuracy: 0.9764 - val_Precision: 0.9611 - val_Recall: 0.9466 - val_TP: 761.0400 - val_TN: 1081.0200 - val_FP: 24.9800 - val_FN: 42.9600\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0427 - Accuracy: 0.9851 - Precision: 0.9605 - Recall: 0.9552 - TP: 3220.9399 - TN: 5536.2598 - FP: 110.7400 - FN: 151.0600 - val_loss: 0.0764 - val_Accuracy: 0.9764 - val_Precision: 0.9621 - val_Recall: 0.9462 - val_TP: 760.7800 - val_TN: 1081.8800 - val_FP: 24.1200 - val_FN: 43.2200\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0430 - Accuracy: 0.9853 - Precision: 0.9607 - Recall: 0.9548 - TP: 3219.5200 - TN: 5537.0200 - FP: 109.9800 - FN: 152.4800 - val_loss: 0.0761 - val_Accuracy: 0.9764 - val_Precision: 0.9626 - val_Recall: 0.9464 - val_TP: 760.9300 - val_TN: 1082.4800 - val_FP: 23.5200 - val_FN: 43.0700\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0430 - Accuracy: 0.9854 - Precision: 0.9611 - Recall: 0.9548 - TP: 3219.5801 - TN: 5538.4199 - FP: 108.5800 - FN: 152.4200 - val_loss: 0.0761 - val_Accuracy: 0.9764 - val_Precision: 0.9628 - val_Recall: 0.9462 - val_TP: 760.7700 - val_TN: 1082.7000 - val_FP: 23.3000 - val_FN: 43.2300\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0430 - Accuracy: 0.9848 - Precision: 0.9610 - Recall: 0.9547 - TP: 3219.1699 - TN: 5538.0000 - FP: 109.0000 - FN: 152.8300 - val_loss: 0.0757 - val_Accuracy: 0.9770 - val_Precision: 0.9641 - val_Recall: 0.9458 - val_TP: 760.4200 - val_TN: 1083.8700 - val_FP: 22.1300 - val_FN: 43.5800\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0429 - Accuracy: 0.9850 - Precision: 0.9610 - Recall: 0.9547 - TP: 3219.0901 - TN: 5537.8999 - FP: 109.1000 - FN: 152.9100 - val_loss: 0.0762 - val_Accuracy: 0.9764 - val_Precision: 0.9627 - val_Recall: 0.9463 - val_TP: 760.8100 - val_TN: 1082.6300 - val_FP: 23.3700 - val_FN: 43.1900\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0428 - Accuracy: 0.9853 - Precision: 0.9611 - Recall: 0.9550 - TP: 3220.2700 - TN: 5538.4502 - FP: 108.5500 - FN: 151.7300 - val_loss: 0.0764 - val_Accuracy: 0.9764 - val_Precision: 0.9629 - val_Recall: 0.9460 - val_TP: 760.6200 - val_TN: 1082.8000 - val_FP: 23.2000 - val_FN: 43.3800\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0430 - Accuracy: 0.9855 - Precision: 0.9609 - Recall: 0.9552 - TP: 3220.8000 - TN: 5537.3799 - FP: 109.6200 - FN: 151.2000 - val_loss: 0.0762 - val_Accuracy: 0.9770 - val_Precision: 0.9638 - val_Recall: 0.9456 - val_TP: 760.2800 - val_TN: 1083.6400 - val_FP: 22.3600 - val_FN: 43.7200\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0431 - Accuracy: 0.9849 - Precision: 0.9613 - Recall: 0.9547 - TP: 3219.3799 - TN: 5539.1401 - FP: 107.8600 - FN: 152.6200 - val_loss: 0.0761 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9461 - val_TP: 760.6700 - val_TN: 1083.0300 - val_FP: 22.9700 - val_FN: 43.3300\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0429 - Accuracy: 0.9850 - Precision: 0.9614 - Recall: 0.9547 - TP: 3219.0901 - TN: 5539.4502 - FP: 107.5500 - FN: 152.9100 - val_loss: 0.0765 - val_Accuracy: 0.9770 - val_Precision: 0.9621 - val_Recall: 0.9466 - val_TP: 761.0400 - val_TN: 1082.0601 - val_FP: 23.9400 - val_FN: 42.9600\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0428 - Accuracy: 0.9850 - Precision: 0.9607 - Recall: 0.9554 - TP: 3221.4800 - TN: 5536.9702 - FP: 110.0300 - FN: 150.5200 - val_loss: 0.0763 - val_Accuracy: 0.9764 - val_Precision: 0.9631 - val_Recall: 0.9461 - val_TP: 760.6500 - val_TN: 1083.0000 - val_FP: 23.0000 - val_FN: 43.3500\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0427 - Accuracy: 0.9849 - Precision: 0.9615 - Recall: 0.9548 - TP: 3219.5000 - TN: 5540.0000 - FP: 107.0000 - FN: 152.5000 - val_loss: 0.0763 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9461 - val_TP: 760.6600 - val_TN: 1083.1500 - val_FP: 22.8500 - val_FN: 43.3400\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0423 - Accuracy: 0.9850 - Precision: 0.9614 - Recall: 0.9552 - TP: 3221.0100 - TN: 5539.6602 - FP: 107.3400 - FN: 150.9900 - val_loss: 0.0758 - val_Accuracy: 0.9775 - val_Precision: 0.9637 - val_Recall: 0.9462 - val_TP: 760.7500 - val_TN: 1083.5100 - val_FP: 22.4900 - val_FN: 43.2500\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0427 - Accuracy: 0.9847 - Precision: 0.9605 - Recall: 0.9550 - TP: 3220.3301 - TN: 5536.0601 - FP: 110.9400 - FN: 151.6700 - val_loss: 0.0775 - val_Accuracy: 0.9759 - val_Precision: 0.9618 - val_Recall: 0.9460 - val_TP: 760.5900 - val_TN: 1081.6200 - val_FP: 24.3800 - val_FN: 43.4100\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0428 - Accuracy: 0.9856 - Precision: 0.9614 - Recall: 0.9550 - TP: 3220.1599 - TN: 5539.5000 - FP: 107.5000 - FN: 151.8400 - val_loss: 0.0778 - val_Accuracy: 0.9759 - val_Precision: 0.9618 - val_Recall: 0.9459 - val_TP: 760.5400 - val_TN: 1081.6400 - val_FP: 24.3600 - val_FN: 43.4600\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0428 - Accuracy: 0.9854 - Precision: 0.9611 - Recall: 0.9550 - TP: 3220.2700 - TN: 5538.4502 - FP: 108.5500 - FN: 151.7300 - val_loss: 0.0769 - val_Accuracy: 0.9770 - val_Precision: 0.9628 - val_Recall: 0.9460 - val_TP: 760.5900 - val_TN: 1082.7300 - val_FP: 23.2700 - val_FN: 43.4100\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0424 - Accuracy: 0.9851 - Precision: 0.9615 - Recall: 0.9548 - TP: 3219.7000 - TN: 5539.9600 - FP: 107.0400 - FN: 152.3000 - val_loss: 0.0784 - val_Accuracy: 0.9754 - val_Precision: 0.9602 - val_Recall: 0.9463 - val_TP: 760.8000 - val_TN: 1080.0800 - val_FP: 25.9200 - val_FN: 43.2000\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0425 - Accuracy: 0.9853 - Precision: 0.9608 - Recall: 0.9552 - TP: 3221.0400 - TN: 5537.2700 - FP: 109.7300 - FN: 150.9600 - val_loss: 0.0773 - val_Accuracy: 0.9764 - val_Precision: 0.9620 - val_Recall: 0.9460 - val_TP: 760.5700 - val_TN: 1081.8700 - val_FP: 24.1300 - val_FN: 43.4300\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0438 - Accuracy: 0.9845 - Precision: 0.9610 - Recall: 0.9543 - TP: 3217.7500 - TN: 5537.9702 - FP: 109.0300 - FN: 154.2500 - val_loss: 0.0769 - val_Accuracy: 0.9759 - val_Precision: 0.9623 - val_Recall: 0.9457 - val_TP: 760.3400 - val_TN: 1082.0800 - val_FP: 23.9200 - val_FN: 43.6600\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0430 - Accuracy: 0.9854 - Precision: 0.9610 - Recall: 0.9548 - TP: 3219.4900 - TN: 5537.7202 - FP: 109.2800 - FN: 152.5100 - val_loss: 0.0761 - val_Accuracy: 0.9764 - val_Precision: 0.9632 - val_Recall: 0.9460 - val_TP: 760.5800 - val_TN: 1083.0500 - val_FP: 22.9500 - val_FN: 43.4200\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0432 - Accuracy: 0.9854 - Precision: 0.9613 - Recall: 0.9547 - TP: 3219.2100 - TN: 5539.5898 - FP: 107.4100 - FN: 152.7900 - val_loss: 0.0809 - val_Accuracy: 0.9754 - val_Precision: 0.9556 - val_Recall: 0.9462 - val_TP: 760.7700 - val_TN: 1075.4700 - val_FP: 30.5300 - val_FN: 43.2300\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0432 - Accuracy: 0.9853 - Precision: 0.9607 - Recall: 0.9549 - TP: 3219.9800 - TN: 5536.8701 - FP: 110.1300 - FN: 152.0200 - val_loss: 0.0767 - val_Accuracy: 0.9759 - val_Precision: 0.9619 - val_Recall: 0.9461 - val_TP: 760.7000 - val_TN: 1081.7600 - val_FP: 24.2400 - val_FN: 43.3000\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0433 - Accuracy: 0.9849 - Precision: 0.9610 - Recall: 0.9543 - TP: 3217.9800 - TN: 5538.3101 - FP: 108.6900 - FN: 154.0200 - val_loss: 0.0762 - val_Accuracy: 0.9764 - val_Precision: 0.9628 - val_Recall: 0.9462 - val_TP: 760.7200 - val_TN: 1082.7300 - val_FP: 23.2700 - val_FN: 43.2800\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0428 - Accuracy: 0.9851 - Precision: 0.9610 - Recall: 0.9550 - TP: 3220.1299 - TN: 5538.0298 - FP: 108.9700 - FN: 151.8700 - val_loss: 0.0764 - val_Accuracy: 0.9764 - val_Precision: 0.9622 - val_Recall: 0.9463 - val_TP: 760.8100 - val_TN: 1082.0400 - val_FP: 23.9600 - val_FN: 43.1900\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0431 - Accuracy: 0.9846 - Precision: 0.9609 - Recall: 0.9547 - TP: 3219.2500 - TN: 5537.7700 - FP: 109.2300 - FN: 152.7500 - val_loss: 0.0776 - val_Accuracy: 0.9759 - val_Precision: 0.9611 - val_Recall: 0.9460 - val_TP: 760.6000 - val_TN: 1080.8600 - val_FP: 25.1400 - val_FN: 43.4000\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0429 - Accuracy: 0.9851 - Precision: 0.9616 - Recall: 0.9546 - TP: 3218.8201 - TN: 5540.6899 - FP: 106.3100 - FN: 153.1800 - val_loss: 0.0770 - val_Accuracy: 0.9759 - val_Precision: 0.9607 - val_Recall: 0.9466 - val_TP: 761.0700 - val_TN: 1080.5100 - val_FP: 25.4900 - val_FN: 42.9300\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0430 - Accuracy: 0.9854 - Precision: 0.9607 - Recall: 0.9549 - TP: 3219.9500 - TN: 5536.8599 - FP: 110.1400 - FN: 152.0500 - val_loss: 0.0757 - val_Accuracy: 0.9770 - val_Precision: 0.9631 - val_Recall: 0.9465 - val_TP: 760.9600 - val_TN: 1082.9900 - val_FP: 23.0100 - val_FN: 43.0400\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0429 - Accuracy: 0.9851 - Precision: 0.9612 - Recall: 0.9547 - TP: 3219.3799 - TN: 5538.7998 - FP: 108.2000 - FN: 152.6200 - val_loss: 0.0759 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9469 - val_TP: 761.2800 - val_TN: 1082.2500 - val_FP: 23.7500 - val_FN: 42.7200\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0429 - Accuracy: 0.9853 - Precision: 0.9610 - Recall: 0.9549 - TP: 3220.0100 - TN: 5538.1699 - FP: 108.8300 - FN: 151.9900 - val_loss: 0.0755 - val_Accuracy: 0.9764 - val_Precision: 0.9636 - val_Recall: 0.9463 - val_TP: 760.8400 - val_TN: 1083.4600 - val_FP: 22.5400 - val_FN: 43.1600\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0427 - Accuracy: 0.9848 - Precision: 0.9609 - Recall: 0.9551 - TP: 3220.6201 - TN: 5537.8101 - FP: 109.1900 - FN: 151.3800 - val_loss: 0.0765 - val_Accuracy: 0.9770 - val_Precision: 0.9622 - val_Recall: 0.9466 - val_TP: 761.0500 - val_TN: 1082.1300 - val_FP: 23.8700 - val_FN: 42.9500\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0426 - Accuracy: 0.9853 - Precision: 0.9607 - Recall: 0.9550 - TP: 3220.2000 - TN: 5536.9399 - FP: 110.0600 - FN: 151.8000 - val_loss: 0.0775 - val_Accuracy: 0.9754 - val_Precision: 0.9615 - val_Recall: 0.9461 - val_TP: 760.6900 - val_TN: 1081.3600 - val_FP: 24.6400 - val_FN: 43.3100\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0426 - Accuracy: 0.9850 - Precision: 0.9615 - Recall: 0.9546 - TP: 3219.0200 - TN: 5539.8599 - FP: 107.1400 - FN: 152.9800 - val_loss: 0.0763 - val_Accuracy: 0.9775 - val_Precision: 0.9619 - val_Recall: 0.9468 - val_TP: 761.2500 - val_TN: 1081.9500 - val_FP: 24.0500 - val_FN: 42.7500\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0427 - Accuracy: 0.9855 - Precision: 0.9607 - Recall: 0.9554 - TP: 3221.5601 - TN: 5537.0898 - FP: 109.9100 - FN: 150.4400 - val_loss: 0.0774 - val_Accuracy: 0.9759 - val_Precision: 0.9619 - val_Recall: 0.9459 - val_TP: 760.5400 - val_TN: 1081.7800 - val_FP: 24.2200 - val_FN: 43.4600\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0426 - Accuracy: 0.9847 - Precision: 0.9611 - Recall: 0.9549 - TP: 3219.8799 - TN: 5538.8198 - FP: 108.1800 - FN: 152.1200 - val_loss: 0.0763 - val_Accuracy: 0.9770 - val_Precision: 0.9628 - val_Recall: 0.9464 - val_TP: 760.8800 - val_TN: 1082.7700 - val_FP: 23.2300 - val_FN: 43.1200\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0428 - Accuracy: 0.9854 - Precision: 0.9614 - Recall: 0.9552 - TP: 3220.8899 - TN: 5539.5801 - FP: 107.4200 - FN: 151.1100 - val_loss: 0.0793 - val_Accuracy: 0.9759 - val_Precision: 0.9587 - val_Recall: 0.9464 - val_TP: 760.8700 - val_TN: 1078.5500 - val_FP: 27.4500 - val_FN: 43.1300\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0426 - Accuracy: 0.9855 - Precision: 0.9610 - Recall: 0.9553 - TP: 3221.1899 - TN: 5538.3198 - FP: 108.6800 - FN: 150.8100 - val_loss: 0.0767 - val_Accuracy: 0.9770 - val_Precision: 0.9623 - val_Recall: 0.9466 - val_TP: 761.0400 - val_TN: 1082.2400 - val_FP: 23.7600 - val_FN: 42.9600\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0427 - Accuracy: 0.9853 - Precision: 0.9610 - Recall: 0.9550 - TP: 3220.3301 - TN: 5538.1899 - FP: 108.8100 - FN: 151.6700 - val_loss: 0.0769 - val_Accuracy: 0.9770 - val_Precision: 0.9617 - val_Recall: 0.9465 - val_TP: 761.0100 - val_TN: 1081.6000 - val_FP: 24.4000 - val_FN: 42.9900\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0425 - Accuracy: 0.9851 - Precision: 0.9614 - Recall: 0.9553 - TP: 3221.2500 - TN: 5539.5400 - FP: 107.4600 - FN: 150.7500 - val_loss: 0.0764 - val_Accuracy: 0.9775 - val_Precision: 0.9632 - val_Recall: 0.9462 - val_TP: 760.7600 - val_TN: 1083.1200 - val_FP: 22.8800 - val_FN: 43.2400\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0426 - Accuracy: 0.9855 - Precision: 0.9613 - Recall: 0.9551 - TP: 3220.6799 - TN: 5539.2798 - FP: 107.7200 - FN: 151.3200 - val_loss: 0.0760 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9466 - val_TP: 761.0800 - val_TN: 1083.1000 - val_FP: 22.9000 - val_FN: 42.9200\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0423 - Accuracy: 0.9855 - Precision: 0.9614 - Recall: 0.9556 - TP: 3222.2900 - TN: 5539.8198 - FP: 107.1800 - FN: 149.7100 - val_loss: 0.0765 - val_Accuracy: 0.9770 - val_Precision: 0.9639 - val_Recall: 0.9459 - val_TP: 760.4800 - val_TN: 1083.7100 - val_FP: 22.2900 - val_FN: 43.5200\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0424 - Accuracy: 0.9854 - Precision: 0.9618 - Recall: 0.9551 - TP: 3220.6001 - TN: 5541.3701 - FP: 105.6300 - FN: 151.4000 - val_loss: 0.0767 - val_Accuracy: 0.9770 - val_Precision: 0.9621 - val_Recall: 0.9467 - val_TP: 761.1600 - val_TN: 1082.1400 - val_FP: 23.8600 - val_FN: 42.8400\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0424 - Accuracy: 0.9853 - Precision: 0.9607 - Recall: 0.9557 - TP: 3222.5200 - TN: 5536.8999 - FP: 110.1000 - FN: 149.4800 - val_loss: 0.0767 - val_Accuracy: 0.9770 - val_Precision: 0.9636 - val_Recall: 0.9458 - val_TP: 760.4400 - val_TN: 1083.4600 - val_FP: 22.5400 - val_FN: 43.5600\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0422 - Accuracy: 0.9853 - Precision: 0.9617 - Recall: 0.9554 - TP: 3221.6599 - TN: 5540.9102 - FP: 106.0900 - FN: 150.3400 - val_loss: 0.0766 - val_Accuracy: 0.9775 - val_Precision: 0.9632 - val_Recall: 0.9462 - val_TP: 760.7500 - val_TN: 1083.1100 - val_FP: 22.8900 - val_FN: 43.2500\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0424 - Accuracy: 0.9851 - Precision: 0.9619 - Recall: 0.9550 - TP: 3220.1799 - TN: 5541.9702 - FP: 105.0300 - FN: 151.8200 - val_loss: 0.0814 - val_Accuracy: 0.9759 - val_Precision: 0.9561 - val_Recall: 0.9465 - val_TP: 760.9600 - val_TN: 1076.1300 - val_FP: 29.8700 - val_FN: 43.0400\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0427 - Accuracy: 0.9851 - Precision: 0.9609 - Recall: 0.9553 - TP: 3221.2200 - TN: 5537.8398 - FP: 109.1600 - FN: 150.7800 - val_loss: 0.0766 - val_Accuracy: 0.9780 - val_Precision: 0.9628 - val_Recall: 0.9466 - val_TP: 761.0500 - val_TN: 1082.7400 - val_FP: 23.2600 - val_FN: 42.9500\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0423 - Accuracy: 0.9858 - Precision: 0.9618 - Recall: 0.9553 - TP: 3221.1399 - TN: 5541.2500 - FP: 105.7500 - FN: 150.8600 - val_loss: 0.0778 - val_Accuracy: 0.9764 - val_Precision: 0.9616 - val_Recall: 0.9464 - val_TP: 760.8900 - val_TN: 1081.4700 - val_FP: 24.5300 - val_FN: 43.1100\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0422 - Accuracy: 0.9854 - Precision: 0.9615 - Recall: 0.9554 - TP: 3221.6499 - TN: 5540.0098 - FP: 106.9900 - FN: 150.3500 - val_loss: 0.0765 - val_Accuracy: 0.9775 - val_Precision: 0.9624 - val_Recall: 0.9470 - val_TP: 761.3600 - val_TN: 1082.3700 - val_FP: 23.6300 - val_FN: 42.6400\n",
      "Epoch 30/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0418 - Accuracy: 0.9859 - Precision: 0.9617 - Recall: 0.9560 - TP: 3223.6699 - TN: 5541.1099 - FP: 105.8900 - FN: 148.3300 - val_loss: 0.0763 - val_Accuracy: 0.9775 - val_Precision: 0.9636 - val_Recall: 0.9464 - val_TP: 760.8700 - val_TN: 1083.4700 - val_FP: 22.5300 - val_FN: 43.1300\n",
      "Epoch 31/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0421 - Accuracy: 0.9855 - Precision: 0.9611 - Recall: 0.9556 - TP: 3222.4299 - TN: 5538.5098 - FP: 108.4900 - FN: 149.5700 - val_loss: 0.0770 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9461 - val_TP: 760.6700 - val_TN: 1083.1200 - val_FP: 22.8800 - val_FN: 43.3300\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 4ms/step - loss: 0.0435 - Accuracy: 0.9849 - Precision: 0.9608 - Recall: 0.9549 - TP: 3219.9399 - TN: 5537.5200 - FP: 109.4800 - FN: 152.0600 - val_loss: 0.0775 - val_Accuracy: 0.9754 - val_Precision: 0.9607 - val_Recall: 0.9463 - val_TP: 760.8300 - val_TN: 1080.5400 - val_FP: 25.4600 - val_FN: 43.1700\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0428 - Accuracy: 0.9854 - Precision: 0.9609 - Recall: 0.9553 - TP: 3221.2400 - TN: 5537.4902 - FP: 109.5100 - FN: 150.7600 - val_loss: 0.0762 - val_Accuracy: 0.9770 - val_Precision: 0.9638 - val_Recall: 0.9458 - val_TP: 760.4300 - val_TN: 1083.6200 - val_FP: 22.3800 - val_FN: 43.5700\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0426 - Accuracy: 0.9850 - Precision: 0.9616 - Recall: 0.9547 - TP: 3219.1799 - TN: 5540.5601 - FP: 106.4400 - FN: 152.8200 - val_loss: 0.0762 - val_Accuracy: 0.9770 - val_Precision: 0.9621 - val_Recall: 0.9468 - val_TP: 761.2500 - val_TN: 1082.1100 - val_FP: 23.8900 - val_FN: 42.7500\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0427 - Accuracy: 0.9854 - Precision: 0.9608 - Recall: 0.9553 - TP: 3221.1399 - TN: 5536.9399 - FP: 110.0600 - FN: 150.8600 - val_loss: 0.0763 - val_Accuracy: 0.9764 - val_Precision: 0.9628 - val_Recall: 0.9464 - val_TP: 760.9200 - val_TN: 1082.7300 - val_FP: 23.2700 - val_FN: 43.0800\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0428 - Accuracy: 0.9851 - Precision: 0.9617 - Recall: 0.9548 - TP: 3219.4500 - TN: 5540.8101 - FP: 106.1900 - FN: 152.5500 - val_loss: 0.0770 - val_Accuracy: 0.9759 - val_Precision: 0.9619 - val_Recall: 0.9462 - val_TP: 760.7400 - val_TN: 1081.7200 - val_FP: 24.2800 - val_FN: 43.2600\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0428 - Accuracy: 0.9851 - Precision: 0.9604 - Recall: 0.9555 - TP: 3222.1001 - TN: 5535.6802 - FP: 111.3200 - FN: 149.9000 - val_loss: 0.0767 - val_Accuracy: 0.9770 - val_Precision: 0.9635 - val_Recall: 0.9457 - val_TP: 760.3500 - val_TN: 1083.3900 - val_FP: 22.6100 - val_FN: 43.6500\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0422 - Accuracy: 0.9847 - Precision: 0.9615 - Recall: 0.9548 - TP: 3219.6799 - TN: 5540.3701 - FP: 106.6300 - FN: 152.3200 - val_loss: 0.0764 - val_Accuracy: 0.9770 - val_Precision: 0.9634 - val_Recall: 0.9460 - val_TP: 760.6100 - val_TN: 1083.3199 - val_FP: 22.6800 - val_FN: 43.3900\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0424 - Accuracy: 0.9858 - Precision: 0.9609 - Recall: 0.9558 - TP: 3222.9700 - TN: 5537.7202 - FP: 109.2800 - FN: 149.0300 - val_loss: 0.0767 - val_Accuracy: 0.9770 - val_Precision: 0.9638 - val_Recall: 0.9457 - val_TP: 760.3200 - val_TN: 1083.6801 - val_FP: 22.3200 - val_FN: 43.6800\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0426 - Accuracy: 0.9851 - Precision: 0.9617 - Recall: 0.9549 - TP: 3219.9900 - TN: 5541.0498 - FP: 105.9500 - FN: 152.0100 - val_loss: 0.0761 - val_Accuracy: 0.9770 - val_Precision: 0.9640 - val_Recall: 0.9460 - val_TP: 760.5700 - val_TN: 1083.8400 - val_FP: 22.1600 - val_FN: 43.4300\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0426 - Accuracy: 0.9849 - Precision: 0.9618 - Recall: 0.9550 - TP: 3220.1001 - TN: 5541.3198 - FP: 105.6800 - FN: 151.9000 - val_loss: 0.0772 - val_Accuracy: 0.9770 - val_Precision: 0.9617 - val_Recall: 0.9464 - val_TP: 760.9100 - val_TN: 1081.6300 - val_FP: 24.3700 - val_FN: 43.0900\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0422 - Accuracy: 0.9854 - Precision: 0.9617 - Recall: 0.9552 - TP: 3220.8601 - TN: 5541.0400 - FP: 105.9600 - FN: 151.1400 - val_loss: 0.0777 - val_Accuracy: 0.9764 - val_Precision: 0.9608 - val_Recall: 0.9465 - val_TP: 761.0100 - val_TN: 1080.6400 - val_FP: 25.3600 - val_FN: 42.9900\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0428 - Accuracy: 0.9854 - Precision: 0.9607 - Recall: 0.9556 - TP: 3222.2300 - TN: 5536.8701 - FP: 110.1300 - FN: 149.7700 - val_loss: 0.0769 - val_Accuracy: 0.9770 - val_Precision: 0.9619 - val_Recall: 0.9468 - val_TP: 761.2200 - val_TN: 1081.9900 - val_FP: 24.0100 - val_FN: 42.7800\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0425 - Accuracy: 0.9851 - Precision: 0.9614 - Recall: 0.9553 - TP: 3221.1799 - TN: 5539.8901 - FP: 107.1100 - FN: 150.8200 - val_loss: 0.0764 - val_Accuracy: 0.9770 - val_Precision: 0.9636 - val_Recall: 0.9461 - val_TP: 760.6300 - val_TN: 1083.5100 - val_FP: 22.4900 - val_FN: 43.3700\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0422 - Accuracy: 0.9851 - Precision: 0.9611 - Recall: 0.9552 - TP: 3221.0701 - TN: 5538.4302 - FP: 108.5700 - FN: 150.9300 - val_loss: 0.0763 - val_Accuracy: 0.9775 - val_Precision: 0.9632 - val_Recall: 0.9465 - val_TP: 760.9600 - val_TN: 1083.1500 - val_FP: 22.8500 - val_FN: 43.0400\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0422 - Accuracy: 0.9848 - Precision: 0.9617 - Recall: 0.9552 - TP: 3221.0901 - TN: 5541.1299 - FP: 105.8700 - FN: 150.9100 - val_loss: 0.0766 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9468 - val_TP: 761.2000 - val_TN: 1082.3400 - val_FP: 23.6600 - val_FN: 42.8000\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0423 - Accuracy: 0.9853 - Precision: 0.9608 - Recall: 0.9556 - TP: 3222.2600 - TN: 5537.3799 - FP: 109.6200 - FN: 149.7400 - val_loss: 0.0767 - val_Accuracy: 0.9775 - val_Precision: 0.9630 - val_Recall: 0.9464 - val_TP: 760.9000 - val_TN: 1082.9399 - val_FP: 23.0600 - val_FN: 43.1000\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0420 - Accuracy: 0.9854 - Precision: 0.9620 - Recall: 0.9553 - TP: 3221.1899 - TN: 5541.9502 - FP: 105.0500 - FN: 150.8100 - val_loss: 0.0776 - val_Accuracy: 0.9764 - val_Precision: 0.9612 - val_Recall: 0.9468 - val_TP: 761.1900 - val_TN: 1081.1500 - val_FP: 24.8500 - val_FN: 42.8100\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0422 - Accuracy: 0.9851 - Precision: 0.9612 - Recall: 0.9557 - TP: 3222.7700 - TN: 5538.5698 - FP: 108.4300 - FN: 149.2300 - val_loss: 0.0770 - val_Accuracy: 0.9770 - val_Precision: 0.9636 - val_Recall: 0.9459 - val_TP: 760.4700 - val_TN: 1083.5000 - val_FP: 22.5000 - val_FN: 43.5300\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0419 - Accuracy: 0.9853 - Precision: 0.9623 - Recall: 0.9551 - TP: 3220.7100 - TN: 5543.2100 - FP: 103.7900 - FN: 151.2900 - val_loss: 0.0764 - val_Accuracy: 0.9775 - val_Precision: 0.9630 - val_Recall: 0.9467 - val_TP: 761.1300 - val_TN: 1082.9399 - val_FP: 23.0600 - val_FN: 42.8700\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0420 - Accuracy: 0.9856 - Precision: 0.9613 - Recall: 0.9559 - TP: 3223.4099 - TN: 5539.4600 - FP: 107.5400 - FN: 148.5900 - val_loss: 0.0763 - val_Accuracy: 0.9775 - val_Precision: 0.9637 - val_Recall: 0.9464 - val_TP: 760.9100 - val_TN: 1083.5699 - val_FP: 22.4300 - val_FN: 43.0900\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0418 - Accuracy: 0.9849 - Precision: 0.9612 - Recall: 0.9555 - TP: 3222.1101 - TN: 5539.0000 - FP: 108.0000 - FN: 149.8900 - val_loss: 0.0768 - val_Accuracy: 0.9770 - val_Precision: 0.9634 - val_Recall: 0.9461 - val_TP: 760.7000 - val_TN: 1083.3300 - val_FP: 22.6700 - val_FN: 43.3000\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0417 - Accuracy: 0.9850 - Precision: 0.9621 - Recall: 0.9555 - TP: 3221.9399 - TN: 5542.5601 - FP: 104.4400 - FN: 150.0600 - val_loss: 0.0781 - val_Accuracy: 0.9764 - val_Precision: 0.9602 - val_Recall: 0.9470 - val_TP: 761.3800 - val_TN: 1080.1700 - val_FP: 25.8300 - val_FN: 42.6200\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0419 - Accuracy: 0.9854 - Precision: 0.9615 - Recall: 0.9555 - TP: 3222.1101 - TN: 5540.2402 - FP: 106.7600 - FN: 149.8900 - val_loss: 0.0777 - val_Accuracy: 0.9764 - val_Precision: 0.9610 - val_Recall: 0.9470 - val_TP: 761.3500 - val_TN: 1080.9700 - val_FP: 25.0300 - val_FN: 42.6500\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0423 - Accuracy: 0.9851 - Precision: 0.9609 - Recall: 0.9556 - TP: 3222.2000 - TN: 5537.5000 - FP: 109.5000 - FN: 149.8000 - val_loss: 0.0767 - val_Accuracy: 0.9770 - val_Precision: 0.9638 - val_Recall: 0.9460 - val_TP: 760.5900 - val_TN: 1083.6801 - val_FP: 22.3200 - val_FN: 43.4100\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0418 - Accuracy: 0.9855 - Precision: 0.9623 - Recall: 0.9555 - TP: 3221.8899 - TN: 5543.5200 - FP: 103.4800 - FN: 150.1100 - val_loss: 0.0780 - val_Accuracy: 0.9764 - val_Precision: 0.9615 - val_Recall: 0.9466 - val_TP: 761.0900 - val_TN: 1081.4200 - val_FP: 24.5800 - val_FN: 42.9100\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0426 - Accuracy: 0.9851 - Precision: 0.9607 - Recall: 0.9555 - TP: 3221.8601 - TN: 5537.1201 - FP: 109.8800 - FN: 150.1400 - val_loss: 0.0768 - val_Accuracy: 0.9775 - val_Precision: 0.9636 - val_Recall: 0.9461 - val_TP: 760.6900 - val_TN: 1083.5200 - val_FP: 22.4800 - val_FN: 43.3100\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0417 - Accuracy: 0.9855 - Precision: 0.9619 - Recall: 0.9558 - TP: 3223.0400 - TN: 5541.6001 - FP: 105.4000 - FN: 148.9600 - val_loss: 0.0789 - val_Accuracy: 0.9759 - val_Precision: 0.9604 - val_Recall: 0.9466 - val_TP: 761.0400 - val_TN: 1080.3101 - val_FP: 25.6900 - val_FN: 42.9600\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0416 - Accuracy: 0.9853 - Precision: 0.9619 - Recall: 0.9560 - TP: 3223.5200 - TN: 5541.8901 - FP: 105.1100 - FN: 148.4800 - val_loss: 0.0780 - val_Accuracy: 0.9759 - val_Precision: 0.9624 - val_Recall: 0.9460 - val_TP: 760.5600 - val_TN: 1082.2300 - val_FP: 23.7700 - val_FN: 43.4400\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0416 - Accuracy: 0.9851 - Precision: 0.9621 - Recall: 0.9558 - TP: 3222.9700 - TN: 5542.7202 - FP: 104.2800 - FN: 149.0300 - val_loss: 0.0773 - val_Accuracy: 0.9775 - val_Precision: 0.9627 - val_Recall: 0.9464 - val_TP: 760.8900 - val_TN: 1082.7500 - val_FP: 23.2500 - val_FN: 43.1100\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 4ms/step - loss: 0.0431 - Accuracy: 0.9857 - Precision: 0.9612 - Recall: 0.9559 - TP: 3223.2800 - TN: 5539.2300 - FP: 107.7700 - FN: 148.7200 - val_loss: 0.0767 - val_Accuracy: 0.9770 - val_Precision: 0.9628 - val_Recall: 0.9463 - val_TP: 760.8500 - val_TN: 1082.7300 - val_FP: 23.2700 - val_FN: 43.1500\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0427 - Accuracy: 0.9851 - Precision: 0.9617 - Recall: 0.9549 - TP: 3219.8799 - TN: 5540.7798 - FP: 106.2200 - FN: 152.1200 - val_loss: 0.0772 - val_Accuracy: 0.9764 - val_Precision: 0.9622 - val_Recall: 0.9462 - val_TP: 760.7100 - val_TN: 1082.0800 - val_FP: 23.9200 - val_FN: 43.2900\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0427 - Accuracy: 0.9849 - Precision: 0.9615 - Recall: 0.9551 - TP: 3220.4500 - TN: 5540.1602 - FP: 106.8400 - FN: 151.5500 - val_loss: 0.0782 - val_Accuracy: 0.9759 - val_Precision: 0.9604 - val_Recall: 0.9466 - val_TP: 761.0900 - val_TN: 1080.2900 - val_FP: 25.7100 - val_FN: 42.9100\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0425 - Accuracy: 0.9850 - Precision: 0.9611 - Recall: 0.9554 - TP: 3221.6599 - TN: 5538.6099 - FP: 108.3900 - FN: 150.3400 - val_loss: 0.0767 - val_Accuracy: 0.9775 - val_Precision: 0.9626 - val_Recall: 0.9466 - val_TP: 761.0600 - val_TN: 1082.5699 - val_FP: 23.4300 - val_FN: 42.9400\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0423 - Accuracy: 0.9855 - Precision: 0.9618 - Recall: 0.9555 - TP: 3221.9399 - TN: 5541.2300 - FP: 105.7700 - FN: 150.0600 - val_loss: 0.0767 - val_Accuracy: 0.9764 - val_Precision: 0.9630 - val_Recall: 0.9463 - val_TP: 760.8400 - val_TN: 1082.9100 - val_FP: 23.0900 - val_FN: 43.1600\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0419 - Accuracy: 0.9856 - Precision: 0.9613 - Recall: 0.9555 - TP: 3221.9600 - TN: 5539.0601 - FP: 107.9400 - FN: 150.0400 - val_loss: 0.0768 - val_Accuracy: 0.9775 - val_Precision: 0.9629 - val_Recall: 0.9464 - val_TP: 760.8900 - val_TN: 1082.8300 - val_FP: 23.1700 - val_FN: 43.1100\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0423 - Accuracy: 0.9851 - Precision: 0.9612 - Recall: 0.9553 - TP: 3221.3301 - TN: 5539.0400 - FP: 107.9600 - FN: 150.6700 - val_loss: 0.0768 - val_Accuracy: 0.9770 - val_Precision: 0.9629 - val_Recall: 0.9463 - val_TP: 760.8500 - val_TN: 1082.8500 - val_FP: 23.1500 - val_FN: 43.1500\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0422 - Accuracy: 0.9853 - Precision: 0.9619 - Recall: 0.9552 - TP: 3220.8799 - TN: 5541.5801 - FP: 105.4200 - FN: 151.1200 - val_loss: 0.0762 - val_Accuracy: 0.9775 - val_Precision: 0.9628 - val_Recall: 0.9469 - val_TP: 761.2700 - val_TN: 1082.7400 - val_FP: 23.2600 - val_FN: 42.7300\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0418 - Accuracy: 0.9856 - Precision: 0.9615 - Recall: 0.9560 - TP: 3223.8000 - TN: 5540.1001 - FP: 106.9000 - FN: 148.2000 - val_loss: 0.0765 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9465 - val_TP: 760.9500 - val_TN: 1083.1200 - val_FP: 22.8800 - val_FN: 43.0500\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0422 - Accuracy: 0.9854 - Precision: 0.9609 - Recall: 0.9557 - TP: 3222.5200 - TN: 5537.7100 - FP: 109.2900 - FN: 149.4800 - val_loss: 0.0770 - val_Accuracy: 0.9775 - val_Precision: 0.9627 - val_Recall: 0.9464 - val_TP: 760.9100 - val_TN: 1082.7000 - val_FP: 23.3000 - val_FN: 43.0900\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0420 - Accuracy: 0.9855 - Precision: 0.9624 - Recall: 0.9552 - TP: 3220.7900 - TN: 5543.9800 - FP: 103.0200 - FN: 151.2100 - val_loss: 0.0776 - val_Accuracy: 0.9764 - val_Precision: 0.9614 - val_Recall: 0.9467 - val_TP: 761.1800 - val_TN: 1081.3300 - val_FP: 24.6700 - val_FN: 42.8200\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0421 - Accuracy: 0.9856 - Precision: 0.9609 - Recall: 0.9559 - TP: 3223.2700 - TN: 5538.2002 - FP: 108.8000 - FN: 148.7300 - val_loss: 0.0771 - val_Accuracy: 0.9775 - val_Precision: 0.9628 - val_Recall: 0.9464 - val_TP: 760.9200 - val_TN: 1082.7500 - val_FP: 23.2500 - val_FN: 43.0800\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0422 - Accuracy: 0.9848 - Precision: 0.9615 - Recall: 0.9554 - TP: 3221.4600 - TN: 5540.3101 - FP: 106.6900 - FN: 150.5400 - val_loss: 0.0768 - val_Accuracy: 0.9770 - val_Precision: 0.9637 - val_Recall: 0.9460 - val_TP: 760.6000 - val_TN: 1083.6200 - val_FP: 22.3800 - val_FN: 43.4000\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0421 - Accuracy: 0.9855 - Precision: 0.9617 - Recall: 0.9556 - TP: 3222.1499 - TN: 5540.8101 - FP: 106.1900 - FN: 149.8500 - val_loss: 0.0775 - val_Accuracy: 0.9764 - val_Precision: 0.9626 - val_Recall: 0.9461 - val_TP: 760.6900 - val_TN: 1082.6400 - val_FP: 23.3600 - val_FN: 43.3100\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0425 - Accuracy: 0.9849 - Precision: 0.9616 - Recall: 0.9552 - TP: 3220.9600 - TN: 5540.7100 - FP: 106.2900 - FN: 151.0400 - val_loss: 0.0792 - val_Accuracy: 0.9759 - val_Precision: 0.9594 - val_Recall: 0.9466 - val_TP: 761.1000 - val_TN: 1079.3800 - val_FP: 26.6200 - val_FN: 42.9000\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0417 - Accuracy: 0.9857 - Precision: 0.9612 - Recall: 0.9558 - TP: 3222.9500 - TN: 5538.9600 - FP: 108.0400 - FN: 149.0500 - val_loss: 0.0764 - val_Accuracy: 0.9775 - val_Precision: 0.9636 - val_Recall: 0.9465 - val_TP: 761.0200 - val_TN: 1083.5400 - val_FP: 22.4600 - val_FN: 42.9800\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0421 - Accuracy: 0.9855 - Precision: 0.9619 - Recall: 0.9556 - TP: 3222.1899 - TN: 5541.9199 - FP: 105.0800 - FN: 149.8100 - val_loss: 0.0776 - val_Accuracy: 0.9770 - val_Precision: 0.9611 - val_Recall: 0.9472 - val_TP: 761.5200 - val_TN: 1081.0400 - val_FP: 24.9600 - val_FN: 42.4800\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0419 - Accuracy: 0.9851 - Precision: 0.9619 - Recall: 0.9557 - TP: 3222.6101 - TN: 5541.6699 - FP: 105.3300 - FN: 149.3900 - val_loss: 0.0783 - val_Accuracy: 0.9770 - val_Precision: 0.9603 - val_Recall: 0.9473 - val_TP: 761.6400 - val_TN: 1080.3400 - val_FP: 25.6600 - val_FN: 42.3600\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0413 - Accuracy: 0.9853 - Precision: 0.9614 - Recall: 0.9562 - TP: 3224.2300 - TN: 5539.5098 - FP: 107.4900 - FN: 147.7700 - val_loss: 0.0766 - val_Accuracy: 0.9775 - val_Precision: 0.9637 - val_Recall: 0.9464 - val_TP: 760.9300 - val_TN: 1083.5900 - val_FP: 22.4100 - val_FN: 43.0700\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0420 - Accuracy: 0.9850 - Precision: 0.9619 - Recall: 0.9556 - TP: 3222.2200 - TN: 5541.7500 - FP: 105.2500 - FN: 149.7800 - val_loss: 0.0774 - val_Accuracy: 0.9775 - val_Precision: 0.9613 - val_Recall: 0.9472 - val_TP: 761.5400 - val_TN: 1081.3101 - val_FP: 24.6900 - val_FN: 42.4600\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0420 - Accuracy: 0.9854 - Precision: 0.9613 - Recall: 0.9556 - TP: 3222.3999 - TN: 5539.6802 - FP: 107.3200 - FN: 149.6000 - val_loss: 0.0767 - val_Accuracy: 0.9775 - val_Precision: 0.9633 - val_Recall: 0.9467 - val_TP: 761.1800 - val_TN: 1083.2600 - val_FP: 22.7400 - val_FN: 42.8200\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0414 - Accuracy: 0.9856 - Precision: 0.9618 - Recall: 0.9560 - TP: 3223.6599 - TN: 5541.3301 - FP: 105.6700 - FN: 148.3400 - val_loss: 0.0777 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9465 - val_TP: 760.9700 - val_TN: 1082.1000 - val_FP: 23.9000 - val_FN: 43.0300\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0417 - Accuracy: 0.9850 - Precision: 0.9621 - Recall: 0.9556 - TP: 3222.2000 - TN: 5542.6401 - FP: 104.3600 - FN: 149.8000 - val_loss: 0.0765 - val_Accuracy: 0.9775 - val_Precision: 0.9634 - val_Recall: 0.9469 - val_TP: 761.3000 - val_TN: 1083.4000 - val_FP: 22.6000 - val_FN: 42.7000\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0414 - Accuracy: 0.9857 - Precision: 0.9619 - Recall: 0.9561 - TP: 3223.9700 - TN: 5541.6401 - FP: 105.3600 - FN: 148.0300 - val_loss: 0.0774 - val_Accuracy: 0.9775 - val_Precision: 0.9631 - val_Recall: 0.9465 - val_TP: 760.9500 - val_TN: 1083.0900 - val_FP: 22.9100 - val_FN: 43.0500\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0416 - Accuracy: 0.9851 - Precision: 0.9618 - Recall: 0.9561 - TP: 3224.0901 - TN: 5541.2598 - FP: 105.7400 - FN: 147.9100 - val_loss: 0.0766 - val_Accuracy: 0.9775 - val_Precision: 0.9638 - val_Recall: 0.9466 - val_TP: 761.1000 - val_TN: 1083.6899 - val_FP: 22.3100 - val_FN: 42.9000\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0414 - Accuracy: 0.9851 - Precision: 0.9618 - Recall: 0.9558 - TP: 3223.0901 - TN: 5541.6499 - FP: 105.3500 - FN: 148.9100 - val_loss: 0.0777 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9467 - val_TP: 761.1400 - val_TN: 1082.3700 - val_FP: 23.6300 - val_FN: 42.8600\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0416 - Accuracy: 0.9855 - Precision: 0.9614 - Recall: 0.9562 - TP: 3224.3999 - TN: 5539.8398 - FP: 107.1600 - FN: 147.6000 - val_loss: 0.0779 - val_Accuracy: 0.9775 - val_Precision: 0.9630 - val_Recall: 0.9463 - val_TP: 760.8100 - val_TN: 1082.9800 - val_FP: 23.0200 - val_FN: 43.1900\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0413 - Accuracy: 0.9855 - Precision: 0.9623 - Recall: 0.9561 - TP: 3223.8401 - TN: 5543.2100 - FP: 103.7900 - FN: 148.1600 - val_loss: 0.0767 - val_Accuracy: 0.9775 - val_Precision: 0.9635 - val_Recall: 0.9469 - val_TP: 761.2700 - val_TN: 1083.4500 - val_FP: 22.5500 - val_FN: 42.7300\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 4ms/step - loss: 0.0430 - Accuracy: 0.9856 - Precision: 0.9610 - Recall: 0.9558 - TP: 3222.7900 - TN: 5538.5498 - FP: 108.4500 - FN: 149.2100 - val_loss: 0.0788 - val_Accuracy: 0.9764 - val_Precision: 0.9597 - val_Recall: 0.9466 - val_TP: 761.0600 - val_TN: 1079.6100 - val_FP: 26.3900 - val_FN: 42.9400\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0420 - Accuracy: 0.9851 - Precision: 0.9620 - Recall: 0.9554 - TP: 3221.5601 - TN: 5542.1699 - FP: 104.8300 - FN: 150.4400 - val_loss: 0.0778 - val_Accuracy: 0.9764 - val_Precision: 0.9613 - val_Recall: 0.9467 - val_TP: 761.1200 - val_TN: 1081.2500 - val_FP: 24.7500 - val_FN: 42.8800\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0422 - Accuracy: 0.9853 - Precision: 0.9617 - Recall: 0.9555 - TP: 3221.9700 - TN: 5541.1099 - FP: 105.8900 - FN: 150.0300 - val_loss: 0.0770 - val_Accuracy: 0.9775 - val_Precision: 0.9625 - val_Recall: 0.9467 - val_TP: 761.1500 - val_TN: 1082.4600 - val_FP: 23.5400 - val_FN: 42.8500\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0419 - Accuracy: 0.9854 - Precision: 0.9614 - Recall: 0.9557 - TP: 3222.4800 - TN: 5540.1099 - FP: 106.8900 - FN: 149.5200 - val_loss: 0.0765 - val_Accuracy: 0.9775 - val_Precision: 0.9627 - val_Recall: 0.9469 - val_TP: 761.3300 - val_TN: 1082.6801 - val_FP: 23.3200 - val_FN: 42.6700\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0416 - Accuracy: 0.9857 - Precision: 0.9614 - Recall: 0.9558 - TP: 3223.0000 - TN: 5540.1201 - FP: 106.8800 - FN: 149.0000 - val_loss: 0.0762 - val_Accuracy: 0.9780 - val_Precision: 0.9630 - val_Recall: 0.9470 - val_TP: 761.4200 - val_TN: 1082.9700 - val_FP: 23.0300 - val_FN: 42.5800\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0421 - Accuracy: 0.9850 - Precision: 0.9615 - Recall: 0.9557 - TP: 3222.4900 - TN: 5540.4902 - FP: 106.5100 - FN: 149.5100 - val_loss: 0.0772 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9467 - val_TP: 761.1800 - val_TN: 1082.2300 - val_FP: 23.7700 - val_FN: 42.8200\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0418 - Accuracy: 0.9853 - Precision: 0.9613 - Recall: 0.9557 - TP: 3222.6399 - TN: 5539.7202 - FP: 107.2800 - FN: 149.3600 - val_loss: 0.0775 - val_Accuracy: 0.9764 - val_Precision: 0.9624 - val_Recall: 0.9464 - val_TP: 760.9300 - val_TN: 1082.4600 - val_FP: 23.5400 - val_FN: 43.0700\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0418 - Accuracy: 0.9856 - Precision: 0.9616 - Recall: 0.9560 - TP: 3223.5200 - TN: 5540.4399 - FP: 106.5600 - FN: 148.4800 - val_loss: 0.0776 - val_Accuracy: 0.9770 - val_Precision: 0.9625 - val_Recall: 0.9463 - val_TP: 760.8600 - val_TN: 1082.4800 - val_FP: 23.5200 - val_FN: 43.1400\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0428 - Accuracy: 0.9844 - Precision: 0.9615 - Recall: 0.9549 - TP: 3219.8301 - TN: 5540.7900 - FP: 106.2100 - FN: 152.1700 - val_loss: 0.0767 - val_Accuracy: 0.9775 - val_Precision: 0.9629 - val_Recall: 0.9467 - val_TP: 761.1700 - val_TN: 1082.8800 - val_FP: 23.1200 - val_FN: 42.8300\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0417 - Accuracy: 0.9850 - Precision: 0.9612 - Recall: 0.9562 - TP: 3224.4399 - TN: 5539.0400 - FP: 107.9600 - FN: 147.5600 - val_loss: 0.0777 - val_Accuracy: 0.9770 - val_Precision: 0.9621 - val_Recall: 0.9464 - val_TP: 760.8800 - val_TN: 1082.0300 - val_FP: 23.9700 - val_FN: 43.1200\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0416 - Accuracy: 0.9854 - Precision: 0.9623 - Recall: 0.9554 - TP: 3221.6599 - TN: 5543.1201 - FP: 103.8800 - FN: 150.3400 - val_loss: 0.0770 - val_Accuracy: 0.9770 - val_Precision: 0.9628 - val_Recall: 0.9467 - val_TP: 761.1800 - val_TN: 1082.7800 - val_FP: 23.2200 - val_FN: 42.8200\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0416 - Accuracy: 0.9853 - Precision: 0.9618 - Recall: 0.9557 - TP: 3222.6899 - TN: 5541.6299 - FP: 105.3700 - FN: 149.3100 - val_loss: 0.0770 - val_Accuracy: 0.9775 - val_Precision: 0.9630 - val_Recall: 0.9467 - val_TP: 761.1500 - val_TN: 1082.9500 - val_FP: 23.0500 - val_FN: 42.8500\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0421 - Accuracy: 0.9853 - Precision: 0.9610 - Recall: 0.9563 - TP: 3224.7100 - TN: 5538.3101 - FP: 108.6900 - FN: 147.2900 - val_loss: 0.0768 - val_Accuracy: 0.9775 - val_Precision: 0.9631 - val_Recall: 0.9468 - val_TP: 761.2100 - val_TN: 1083.1200 - val_FP: 22.8800 - val_FN: 42.7900\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0417 - Accuracy: 0.9853 - Precision: 0.9619 - Recall: 0.9555 - TP: 3222.0500 - TN: 5541.7998 - FP: 105.2000 - FN: 149.9500 - val_loss: 0.0772 - val_Accuracy: 0.9770 - val_Precision: 0.9637 - val_Recall: 0.9461 - val_TP: 760.6300 - val_TN: 1083.5900 - val_FP: 22.4100 - val_FN: 43.3700\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0415 - Accuracy: 0.9855 - Precision: 0.9615 - Recall: 0.9562 - TP: 3224.2400 - TN: 5540.2700 - FP: 106.7300 - FN: 147.7600 - val_loss: 0.0767 - val_Accuracy: 0.9775 - val_Precision: 0.9641 - val_Recall: 0.9463 - val_TP: 760.8000 - val_TN: 1084.0200 - val_FP: 21.9800 - val_FN: 43.2000\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0416 - Accuracy: 0.9853 - Precision: 0.9621 - Recall: 0.9558 - TP: 3222.8101 - TN: 5542.8501 - FP: 104.1500 - FN: 149.1900 - val_loss: 0.0779 - val_Accuracy: 0.9759 - val_Precision: 0.9622 - val_Recall: 0.9466 - val_TP: 761.1000 - val_TN: 1082.3000 - val_FP: 23.7000 - val_FN: 42.9000\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0415 - Accuracy: 0.9853 - Precision: 0.9618 - Recall: 0.9563 - TP: 3224.5400 - TN: 5541.3301 - FP: 105.6700 - FN: 147.4600 - val_loss: 0.0767 - val_Accuracy: 0.9775 - val_Precision: 0.9637 - val_Recall: 0.9466 - val_TP: 761.1000 - val_TN: 1083.6400 - val_FP: 22.3600 - val_FN: 42.9000\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0410 - Accuracy: 0.9851 - Precision: 0.9618 - Recall: 0.9560 - TP: 3223.6699 - TN: 5541.7900 - FP: 105.2100 - FN: 148.3300 - val_loss: 0.0782 - val_Accuracy: 0.9764 - val_Precision: 0.9614 - val_Recall: 0.9468 - val_TP: 761.2500 - val_TN: 1081.4301 - val_FP: 24.5700 - val_FN: 42.7500\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1034s 4s/step - loss: 0.0415 - Accuracy: 0.9853 - Precision: 0.9618 - Recall: 0.9556 - TP: 3222.3401 - TN: 5541.6499 - FP: 105.3500 - FN: 149.6600 - val_loss: 0.0782 - val_Accuracy: 0.9759 - val_Precision: 0.9613 - val_Recall: 0.9470 - val_TP: 761.3600 - val_TN: 1081.2800 - val_FP: 24.7200 - val_FN: 42.6400\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0414 - Accuracy: 0.9854 - Precision: 0.9622 - Recall: 0.9560 - TP: 3223.7700 - TN: 5543.2300 - FP: 103.7700 - FN: 148.2300 - val_loss: 0.0776 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9471 - val_TP: 761.4700 - val_TN: 1082.1700 - val_FP: 23.8300 - val_FN: 42.5300\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0414 - Accuracy: 0.9854 - Precision: 0.9615 - Recall: 0.9565 - TP: 3225.1599 - TN: 5540.3999 - FP: 106.6000 - FN: 146.8400 - val_loss: 0.0785 - val_Accuracy: 0.9764 - val_Precision: 0.9609 - val_Recall: 0.9471 - val_TP: 761.4700 - val_TN: 1080.9399 - val_FP: 25.0600 - val_FN: 42.5300\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 0.0414 - Accuracy: 0.9853 - Precision: 0.9623 - Recall: 0.9560 - TP: 3223.7000 - TN: 5543.1099 - FP: 103.8900 - FN: 148.3000 - val_loss: 0.0768 - val_Accuracy: 0.9775 - val_Precision: 0.9634 - val_Recall: 0.9469 - val_TP: 761.3200 - val_TN: 1083.3800 - val_FP: 22.6200 - val_FN: 42.6800\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 4s 13ms/step - loss: 0.0418 - Accuracy: 0.9851 - Precision: 0.9618 - Recall: 0.9559 - TP: 3223.2700 - TN: 5541.6201 - FP: 105.3800 - FN: 148.7300 - val_loss: 0.0772 - val_Accuracy: 0.9770 - val_Precision: 0.9628 - val_Recall: 0.9470 - val_TP: 761.3600 - val_TN: 1082.8199 - val_FP: 23.1800 - val_FN: 42.6400\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 3s 9ms/step - loss: 0.0411 - Accuracy: 0.9855 - Precision: 0.9617 - Recall: 0.9564 - TP: 3224.9800 - TN: 5541.1699 - FP: 105.8300 - FN: 147.0200 - val_loss: 0.0771 - val_Accuracy: 0.9775 - val_Precision: 0.9635 - val_Recall: 0.9467 - val_TP: 761.1300 - val_TN: 1083.4500 - val_FP: 22.5500 - val_FN: 42.8700\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0420 - Accuracy: 0.9853 - Precision: 0.9615 - Recall: 0.9564 - TP: 3225.0801 - TN: 5540.9600 - FP: 106.0400 - FN: 146.9200 - val_loss: 0.0774 - val_Accuracy: 0.9775 - val_Precision: 0.9638 - val_Recall: 0.9463 - val_TP: 760.8100 - val_TN: 1083.7200 - val_FP: 22.2800 - val_FN: 43.1900\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 6ms/step - loss: 0.0433 - Accuracy: 0.9856 - Precision: 0.9618 - Recall: 0.9559 - TP: 3223.3401 - TN: 5541.8701 - FP: 105.1300 - FN: 148.6600 - val_loss: 0.0767 - val_Accuracy: 0.9775 - val_Precision: 0.9627 - val_Recall: 0.9469 - val_TP: 761.3200 - val_TN: 1082.7000 - val_FP: 23.3000 - val_FN: 42.6800\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0421 - Accuracy: 0.9853 - Precision: 0.9616 - Recall: 0.9553 - TP: 3221.4099 - TN: 5540.6802 - FP: 106.3200 - FN: 150.5900 - val_loss: 0.0763 - val_Accuracy: 0.9770 - val_Precision: 0.9637 - val_Recall: 0.9467 - val_TP: 761.1100 - val_TN: 1083.5800 - val_FP: 22.4200 - val_FN: 42.8900\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0420 - Accuracy: 0.9853 - Precision: 0.9616 - Recall: 0.9558 - TP: 3223.1201 - TN: 5540.8501 - FP: 106.1500 - FN: 148.8800 - val_loss: 0.0767 - val_Accuracy: 0.9775 - val_Precision: 0.9633 - val_Recall: 0.9466 - val_TP: 761.0300 - val_TN: 1083.2000 - val_FP: 22.8000 - val_FN: 42.9700\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0417 - Accuracy: 0.9853 - Precision: 0.9615 - Recall: 0.9559 - TP: 3223.2600 - TN: 5540.0601 - FP: 106.9400 - FN: 148.7400 - val_loss: 0.0766 - val_Accuracy: 0.9770 - val_Precision: 0.9645 - val_Recall: 0.9459 - val_TP: 760.5200 - val_TN: 1084.3600 - val_FP: 21.6400 - val_FN: 43.4800\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0420 - Accuracy: 0.9849 - Precision: 0.9620 - Recall: 0.9555 - TP: 3221.8101 - TN: 5542.2500 - FP: 104.7500 - FN: 150.1900 - val_loss: 0.0774 - val_Accuracy: 0.9775 - val_Precision: 0.9618 - val_Recall: 0.9471 - val_TP: 761.4600 - val_TN: 1081.9100 - val_FP: 24.0900 - val_FN: 42.5400\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0423 - Accuracy: 0.9850 - Precision: 0.9612 - Recall: 0.9558 - TP: 3223.1201 - TN: 5539.5698 - FP: 107.4300 - FN: 148.8800 - val_loss: 0.0778 - val_Accuracy: 0.9764 - val_Precision: 0.9617 - val_Recall: 0.9468 - val_TP: 761.2300 - val_TN: 1081.6700 - val_FP: 24.3300 - val_FN: 42.7700\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0416 - Accuracy: 0.9850 - Precision: 0.9618 - Recall: 0.9556 - TP: 3222.2200 - TN: 5541.6001 - FP: 105.4000 - FN: 149.7800 - val_loss: 0.0785 - val_Accuracy: 0.9764 - val_Precision: 0.9603 - val_Recall: 0.9469 - val_TP: 761.2900 - val_TN: 1080.2800 - val_FP: 25.7200 - val_FN: 42.7100\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0418 - Accuracy: 0.9853 - Precision: 0.9613 - Recall: 0.9560 - TP: 3223.5500 - TN: 5539.5601 - FP: 107.4400 - FN: 148.4500 - val_loss: 0.0770 - val_Accuracy: 0.9770 - val_Precision: 0.9631 - val_Recall: 0.9467 - val_TP: 761.1100 - val_TN: 1083.1000 - val_FP: 22.9000 - val_FN: 42.8900\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0418 - Accuracy: 0.9855 - Precision: 0.9616 - Recall: 0.9559 - TP: 3223.3401 - TN: 5540.5400 - FP: 106.4600 - FN: 148.6600 - val_loss: 0.0771 - val_Accuracy: 0.9775 - val_Precision: 0.9637 - val_Recall: 0.9462 - val_TP: 760.7200 - val_TN: 1083.6100 - val_FP: 22.3900 - val_FN: 43.2800\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0419 - Accuracy: 0.9850 - Precision: 0.9619 - Recall: 0.9556 - TP: 3222.4099 - TN: 5541.7798 - FP: 105.2200 - FN: 149.5900 - val_loss: 0.0771 - val_Accuracy: 0.9775 - val_Precision: 0.9634 - val_Recall: 0.9465 - val_TP: 760.9700 - val_TN: 1083.3500 - val_FP: 22.6500 - val_FN: 43.0300\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0418 - Accuracy: 0.9851 - Precision: 0.9619 - Recall: 0.9557 - TP: 3222.7300 - TN: 5541.7700 - FP: 105.2300 - FN: 149.2700 - val_loss: 0.0775 - val_Accuracy: 0.9770 - val_Precision: 0.9626 - val_Recall: 0.9467 - val_TP: 761.1700 - val_TN: 1082.6600 - val_FP: 23.3400 - val_FN: 42.8300\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0416 - Accuracy: 0.9856 - Precision: 0.9615 - Recall: 0.9564 - TP: 3224.9900 - TN: 5540.4102 - FP: 106.5900 - FN: 147.0100 - val_loss: 0.0774 - val_Accuracy: 0.9775 - val_Precision: 0.9635 - val_Recall: 0.9462 - val_TP: 760.7700 - val_TN: 1083.4600 - val_FP: 22.5400 - val_FN: 43.2300\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0416 - Accuracy: 0.9850 - Precision: 0.9622 - Recall: 0.9559 - TP: 3223.3501 - TN: 5543.1299 - FP: 103.8700 - FN: 148.6500 - val_loss: 0.0772 - val_Accuracy: 0.9775 - val_Precision: 0.9632 - val_Recall: 0.9467 - val_TP: 761.1100 - val_TN: 1083.1500 - val_FP: 22.8500 - val_FN: 42.8900\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0414 - Accuracy: 0.9857 - Precision: 0.9619 - Recall: 0.9564 - TP: 3225.0500 - TN: 5541.7900 - FP: 105.2100 - FN: 146.9500 - val_loss: 0.0778 - val_Accuracy: 0.9775 - val_Precision: 0.9631 - val_Recall: 0.9462 - val_TP: 760.7800 - val_TN: 1083.0699 - val_FP: 22.9300 - val_FN: 43.2200\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0416 - Accuracy: 0.9851 - Precision: 0.9618 - Recall: 0.9558 - TP: 3223.0400 - TN: 5541.6899 - FP: 105.3100 - FN: 148.9600 - val_loss: 0.0784 - val_Accuracy: 0.9764 - val_Precision: 0.9612 - val_Recall: 0.9470 - val_TP: 761.3900 - val_TN: 1081.2500 - val_FP: 24.7500 - val_FN: 42.6100\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0413 - Accuracy: 0.9858 - Precision: 0.9620 - Recall: 0.9565 - TP: 3225.2500 - TN: 5542.3901 - FP: 104.6100 - FN: 146.7500 - val_loss: 0.0772 - val_Accuracy: 0.9775 - val_Precision: 0.9638 - val_Recall: 0.9464 - val_TP: 760.8700 - val_TN: 1083.7000 - val_FP: 22.3000 - val_FN: 43.1300\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0414 - Accuracy: 0.9851 - Precision: 0.9621 - Recall: 0.9559 - TP: 3223.3799 - TN: 5542.8901 - FP: 104.1100 - FN: 148.6200 - val_loss: 0.0780 - val_Accuracy: 0.9770 - val_Precision: 0.9628 - val_Recall: 0.9465 - val_TP: 760.9500 - val_TN: 1082.8400 - val_FP: 23.1600 - val_FN: 43.0500\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0417 - Accuracy: 0.9851 - Precision: 0.9615 - Recall: 0.9561 - TP: 3223.9600 - TN: 5540.0098 - FP: 106.9900 - FN: 148.0400 - val_loss: 0.0771 - val_Accuracy: 0.9775 - val_Precision: 0.9639 - val_Recall: 0.9463 - val_TP: 760.8500 - val_TN: 1083.8500 - val_FP: 22.1500 - val_FN: 43.1500\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0410 - Accuracy: 0.9855 - Precision: 0.9626 - Recall: 0.9562 - TP: 3224.4700 - TN: 5544.5298 - FP: 102.4700 - FN: 147.5300 - val_loss: 0.0785 - val_Accuracy: 0.9764 - val_Precision: 0.9616 - val_Recall: 0.9468 - val_TP: 761.1900 - val_TN: 1081.6300 - val_FP: 24.3700 - val_FN: 42.8100\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0412 - Accuracy: 0.9858 - Precision: 0.9620 - Recall: 0.9567 - TP: 3225.9199 - TN: 5542.2998 - FP: 104.7000 - FN: 146.0800 - val_loss: 0.0786 - val_Accuracy: 0.9759 - val_Precision: 0.9614 - val_Recall: 0.9469 - val_TP: 761.2900 - val_TN: 1081.4200 - val_FP: 24.5800 - val_FN: 42.7100\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0408 - Accuracy: 0.9855 - Precision: 0.9620 - Recall: 0.9563 - TP: 3224.5100 - TN: 5542.4399 - FP: 104.5600 - FN: 147.4900 - val_loss: 0.0780 - val_Accuracy: 0.9775 - val_Precision: 0.9631 - val_Recall: 0.9464 - val_TP: 760.9200 - val_TN: 1083.1000 - val_FP: 22.9000 - val_FN: 43.0800\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0410 - Accuracy: 0.9857 - Precision: 0.9620 - Recall: 0.9562 - TP: 3224.4700 - TN: 5541.8599 - FP: 105.1400 - FN: 147.5300 - val_loss: 0.0781 - val_Accuracy: 0.9764 - val_Precision: 0.9623 - val_Recall: 0.9468 - val_TP: 761.2400 - val_TN: 1082.4100 - val_FP: 23.5900 - val_FN: 42.7600\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 4ms/step - loss: 0.0428 - Accuracy: 0.9855 - Precision: 0.9617 - Recall: 0.9554 - TP: 3221.4600 - TN: 5541.6201 - FP: 105.3800 - FN: 150.5400 - val_loss: 0.0775 - val_Accuracy: 0.9764 - val_Precision: 0.9626 - val_Recall: 0.9464 - val_TP: 760.9300 - val_TN: 1082.5900 - val_FP: 23.4100 - val_FN: 43.0700\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0419 - Accuracy: 0.9850 - Precision: 0.9618 - Recall: 0.9557 - TP: 3222.6101 - TN: 5541.5898 - FP: 105.4100 - FN: 149.3900 - val_loss: 0.0772 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9470 - val_TP: 761.3800 - val_TN: 1082.3600 - val_FP: 23.6400 - val_FN: 42.6200\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0419 - Accuracy: 0.9855 - Precision: 0.9610 - Recall: 0.9560 - TP: 3223.8000 - TN: 5538.2002 - FP: 108.8000 - FN: 148.2000 - val_loss: 0.0768 - val_Accuracy: 0.9770 - val_Precision: 0.9645 - val_Recall: 0.9458 - val_TP: 760.4200 - val_TN: 1084.3500 - val_FP: 21.6500 - val_FN: 43.5800\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0418 - Accuracy: 0.9853 - Precision: 0.9626 - Recall: 0.9553 - TP: 3221.2400 - TN: 5544.7100 - FP: 102.2900 - FN: 150.7600 - val_loss: 0.0771 - val_Accuracy: 0.9770 - val_Precision: 0.9635 - val_Recall: 0.9462 - val_TP: 760.7500 - val_TN: 1083.4600 - val_FP: 22.5400 - val_FN: 43.2500\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0417 - Accuracy: 0.9851 - Precision: 0.9620 - Recall: 0.9555 - TP: 3221.8701 - TN: 5542.2202 - FP: 104.7800 - FN: 150.1300 - val_loss: 0.0768 - val_Accuracy: 0.9775 - val_Precision: 0.9627 - val_Recall: 0.9471 - val_TP: 761.4300 - val_TN: 1082.6700 - val_FP: 23.3300 - val_FN: 42.5700\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0419 - Accuracy: 0.9858 - Precision: 0.9616 - Recall: 0.9561 - TP: 3223.8701 - TN: 5540.7002 - FP: 106.3000 - FN: 148.1300 - val_loss: 0.0783 - val_Accuracy: 0.9770 - val_Precision: 0.9598 - val_Recall: 0.9474 - val_TP: 761.6700 - val_TN: 1079.8400 - val_FP: 26.1600 - val_FN: 42.3300\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0418 - Accuracy: 0.9854 - Precision: 0.9614 - Recall: 0.9562 - TP: 3224.2900 - TN: 5539.7900 - FP: 107.2100 - FN: 147.7100 - val_loss: 0.0772 - val_Accuracy: 0.9770 - val_Precision: 0.9638 - val_Recall: 0.9461 - val_TP: 760.6600 - val_TN: 1083.7100 - val_FP: 22.2900 - val_FN: 43.3400\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0415 - Accuracy: 0.9850 - Precision: 0.9615 - Recall: 0.9557 - TP: 3222.6201 - TN: 5540.5601 - FP: 106.4400 - FN: 149.3800 - val_loss: 0.0774 - val_Accuracy: 0.9775 - val_Precision: 0.9619 - val_Recall: 0.9472 - val_TP: 761.5700 - val_TN: 1081.9500 - val_FP: 24.0500 - val_FN: 42.4300\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0417 - Accuracy: 0.9851 - Precision: 0.9622 - Recall: 0.9556 - TP: 3222.1399 - TN: 5543.1899 - FP: 103.8100 - FN: 149.8600 - val_loss: 0.0770 - val_Accuracy: 0.9775 - val_Precision: 0.9631 - val_Recall: 0.9468 - val_TP: 761.2000 - val_TN: 1083.0500 - val_FP: 22.9500 - val_FN: 42.8000\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0417 - Accuracy: 0.9855 - Precision: 0.9618 - Recall: 0.9561 - TP: 3224.0901 - TN: 5541.4302 - FP: 105.5700 - FN: 147.9100 - val_loss: 0.0770 - val_Accuracy: 0.9775 - val_Precision: 0.9631 - val_Recall: 0.9467 - val_TP: 761.1700 - val_TN: 1083.0900 - val_FP: 22.9100 - val_FN: 42.8300\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0418 - Accuracy: 0.9855 - Precision: 0.9616 - Recall: 0.9565 - TP: 3225.1499 - TN: 5540.9102 - FP: 106.0900 - FN: 146.8500 - val_loss: 0.0770 - val_Accuracy: 0.9775 - val_Precision: 0.9637 - val_Recall: 0.9465 - val_TP: 760.9900 - val_TN: 1083.6200 - val_FP: 22.3800 - val_FN: 43.0100\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0413 - Accuracy: 0.9854 - Precision: 0.9624 - Recall: 0.9557 - TP: 3222.6299 - TN: 5543.9702 - FP: 103.0300 - FN: 149.3700 - val_loss: 0.0769 - val_Accuracy: 0.9780 - val_Precision: 0.9625 - val_Recall: 0.9473 - val_TP: 761.6100 - val_TN: 1082.5900 - val_FP: 23.4100 - val_FN: 42.3900\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0414 - Accuracy: 0.9857 - Precision: 0.9614 - Recall: 0.9566 - TP: 3225.8101 - TN: 5539.7100 - FP: 107.2900 - FN: 146.1900 - val_loss: 0.0769 - val_Accuracy: 0.9775 - val_Precision: 0.9637 - val_Recall: 0.9466 - val_TP: 761.0300 - val_TN: 1083.6500 - val_FP: 22.3500 - val_FN: 42.9700\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0418 - Accuracy: 0.9849 - Precision: 0.9620 - Recall: 0.9558 - TP: 3223.1101 - TN: 5542.3101 - FP: 104.6900 - FN: 148.8900 - val_loss: 0.0781 - val_Accuracy: 0.9764 - val_Precision: 0.9618 - val_Recall: 0.9467 - val_TP: 761.1700 - val_TN: 1081.7800 - val_FP: 24.2200 - val_FN: 42.8300\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0413 - Accuracy: 0.9854 - Precision: 0.9619 - Recall: 0.9563 - TP: 3224.7200 - TN: 5541.7700 - FP: 105.2300 - FN: 147.2800 - val_loss: 0.0779 - val_Accuracy: 0.9775 - val_Precision: 0.9624 - val_Recall: 0.9468 - val_TP: 761.2400 - val_TN: 1082.4700 - val_FP: 23.5300 - val_FN: 42.7600\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0416 - Accuracy: 0.9856 - Precision: 0.9617 - Recall: 0.9560 - TP: 3223.7700 - TN: 5541.1802 - FP: 105.8200 - FN: 148.2300 - val_loss: 0.0773 - val_Accuracy: 0.9775 - val_Precision: 0.9633 - val_Recall: 0.9467 - val_TP: 761.1500 - val_TN: 1083.2500 - val_FP: 22.7500 - val_FN: 42.8500\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0414 - Accuracy: 0.9854 - Precision: 0.9622 - Recall: 0.9561 - TP: 3223.9299 - TN: 5542.8398 - FP: 104.1600 - FN: 148.0700 - val_loss: 0.0774 - val_Accuracy: 0.9775 - val_Precision: 0.9630 - val_Recall: 0.9468 - val_TP: 761.1900 - val_TN: 1083.0601 - val_FP: 22.9400 - val_FN: 42.8100\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0411 - Accuracy: 0.9856 - Precision: 0.9625 - Recall: 0.9563 - TP: 3224.6299 - TN: 5544.6602 - FP: 102.3400 - FN: 147.3700 - val_loss: 0.0780 - val_Accuracy: 0.9770 - val_Precision: 0.9612 - val_Recall: 0.9472 - val_TP: 761.5500 - val_TN: 1081.2600 - val_FP: 24.7400 - val_FN: 42.4500\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0415 - Accuracy: 0.9858 - Precision: 0.9614 - Recall: 0.9566 - TP: 3225.6699 - TN: 5539.8799 - FP: 107.1200 - FN: 146.3300 - val_loss: 0.0791 - val_Accuracy: 0.9764 - val_Precision: 0.9611 - val_Recall: 0.9466 - val_TP: 761.0600 - val_TN: 1081.0100 - val_FP: 24.9900 - val_FN: 42.9400\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0413 - Accuracy: 0.9851 - Precision: 0.9623 - Recall: 0.9563 - TP: 3224.6201 - TN: 5543.8301 - FP: 103.1700 - FN: 147.3800 - val_loss: 0.0781 - val_Accuracy: 0.9770 - val_Precision: 0.9623 - val_Recall: 0.9469 - val_TP: 761.3200 - val_TN: 1082.4100 - val_FP: 23.5900 - val_FN: 42.6800\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0411 - Accuracy: 0.9853 - Precision: 0.9622 - Recall: 0.9565 - TP: 3225.4700 - TN: 5543.0200 - FP: 103.9800 - FN: 146.5300 - val_loss: 0.0783 - val_Accuracy: 0.9770 - val_Precision: 0.9622 - val_Recall: 0.9467 - val_TP: 761.1200 - val_TN: 1082.1700 - val_FP: 23.8300 - val_FN: 42.8800\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0411 - Accuracy: 0.9857 - Precision: 0.9620 - Recall: 0.9566 - TP: 3225.7700 - TN: 5542.2998 - FP: 104.7000 - FN: 146.2300 - val_loss: 0.0786 - val_Accuracy: 0.9764 - val_Precision: 0.9616 - val_Recall: 0.9468 - val_TP: 761.2300 - val_TN: 1081.6100 - val_FP: 24.3900 - val_FN: 42.7700\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0408 - Accuracy: 0.9851 - Precision: 0.9626 - Recall: 0.9559 - TP: 3223.3799 - TN: 5544.5400 - FP: 102.4600 - FN: 148.6200 - val_loss: 0.0780 - val_Accuracy: 0.9775 - val_Precision: 0.9626 - val_Recall: 0.9469 - val_TP: 761.3000 - val_TN: 1082.6700 - val_FP: 23.3300 - val_FN: 42.7000\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0411 - Accuracy: 0.9860 - Precision: 0.9621 - Recall: 0.9570 - TP: 3227.1299 - TN: 5543.0098 - FP: 103.9900 - FN: 144.8700 - val_loss: 0.0773 - val_Accuracy: 0.9770 - val_Precision: 0.9630 - val_Recall: 0.9470 - val_TP: 761.4000 - val_TN: 1083.0601 - val_FP: 22.9400 - val_FN: 42.6000\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0412 - Accuracy: 0.9857 - Precision: 0.9618 - Recall: 0.9571 - TP: 3227.2300 - TN: 5541.3999 - FP: 105.6000 - FN: 144.7700 - val_loss: 0.0782 - val_Accuracy: 0.9775 - val_Precision: 0.9636 - val_Recall: 0.9462 - val_TP: 760.7600 - val_TN: 1083.5601 - val_FP: 22.4400 - val_FN: 43.2400\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 5ms/step - loss: 0.0420 - Accuracy: 0.9849 - Precision: 0.9624 - Recall: 0.9554 - TP: 3221.4700 - TN: 5544.0098 - FP: 102.9900 - FN: 150.5300 - val_loss: 0.0784 - val_Accuracy: 0.9759 - val_Precision: 0.9596 - val_Recall: 0.9476 - val_TP: 761.8600 - val_TN: 1079.5900 - val_FP: 26.4100 - val_FN: 42.1400\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0418 - Accuracy: 0.9857 - Precision: 0.9616 - Recall: 0.9565 - TP: 3225.3601 - TN: 5540.7202 - FP: 106.2800 - FN: 146.6400 - val_loss: 0.0772 - val_Accuracy: 0.9770 - val_Precision: 0.9629 - val_Recall: 0.9468 - val_TP: 761.2400 - val_TN: 1082.8800 - val_FP: 23.1200 - val_FN: 42.7600\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0418 - Accuracy: 0.9854 - Precision: 0.9620 - Recall: 0.9556 - TP: 3222.2100 - TN: 5541.9502 - FP: 105.0500 - FN: 149.7900 - val_loss: 0.0766 - val_Accuracy: 0.9775 - val_Precision: 0.9632 - val_Recall: 0.9471 - val_TP: 761.4700 - val_TN: 1083.1700 - val_FP: 22.8300 - val_FN: 42.5300\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0418 - Accuracy: 0.9856 - Precision: 0.9618 - Recall: 0.9563 - TP: 3224.7800 - TN: 5541.5498 - FP: 105.4500 - FN: 147.2200 - val_loss: 0.0800 - val_Accuracy: 0.9759 - val_Precision: 0.9595 - val_Recall: 0.9467 - val_TP: 761.1400 - val_TN: 1079.4399 - val_FP: 26.5600 - val_FN: 42.8600\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0418 - Accuracy: 0.9853 - Precision: 0.9618 - Recall: 0.9561 - TP: 3224.0901 - TN: 5541.6602 - FP: 105.3400 - FN: 147.9100 - val_loss: 0.0794 - val_Accuracy: 0.9759 - val_Precision: 0.9610 - val_Recall: 0.9463 - val_TP: 760.8000 - val_TN: 1080.9000 - val_FP: 25.1000 - val_FN: 43.2000\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0417 - Accuracy: 0.9850 - Precision: 0.9615 - Recall: 0.9562 - TP: 3224.3201 - TN: 5540.6299 - FP: 106.3700 - FN: 147.6800 - val_loss: 0.0769 - val_Accuracy: 0.9775 - val_Precision: 0.9638 - val_Recall: 0.9466 - val_TP: 761.0600 - val_TN: 1083.7200 - val_FP: 22.2800 - val_FN: 42.9400\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0413 - Accuracy: 0.9855 - Precision: 0.9626 - Recall: 0.9559 - TP: 3223.2700 - TN: 5544.4302 - FP: 102.5700 - FN: 148.7300 - val_loss: 0.0768 - val_Accuracy: 0.9775 - val_Precision: 0.9634 - val_Recall: 0.9469 - val_TP: 761.3100 - val_TN: 1083.3700 - val_FP: 22.6300 - val_FN: 42.6900\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0424 - Accuracy: 0.9846 - Precision: 0.9613 - Recall: 0.9556 - TP: 3222.3101 - TN: 5539.8501 - FP: 107.1500 - FN: 149.6900 - val_loss: 0.0777 - val_Accuracy: 0.9770 - val_Precision: 0.9620 - val_Recall: 0.9470 - val_TP: 761.4200 - val_TN: 1082.0400 - val_FP: 23.9600 - val_FN: 42.5800\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0417 - Accuracy: 0.9854 - Precision: 0.9615 - Recall: 0.9558 - TP: 3222.8101 - TN: 5540.2598 - FP: 106.7400 - FN: 149.1900 - val_loss: 0.0789 - val_Accuracy: 0.9764 - val_Precision: 0.9601 - val_Recall: 0.9471 - val_TP: 761.4900 - val_TN: 1080.1100 - val_FP: 25.8900 - val_FN: 42.5100\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0408 - Accuracy: 0.9851 - Precision: 0.9619 - Recall: 0.9560 - TP: 3223.7200 - TN: 5541.7402 - FP: 105.2600 - FN: 148.2800 - val_loss: 0.0776 - val_Accuracy: 0.9770 - val_Precision: 0.9623 - val_Recall: 0.9470 - val_TP: 761.3800 - val_TN: 1082.4000 - val_FP: 23.6000 - val_FN: 42.6200\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0413 - Accuracy: 0.9858 - Precision: 0.9618 - Recall: 0.9563 - TP: 3224.5901 - TN: 5541.5098 - FP: 105.4900 - FN: 147.4100 - val_loss: 0.0774 - val_Accuracy: 0.9775 - val_Precision: 0.9633 - val_Recall: 0.9467 - val_TP: 761.1100 - val_TN: 1083.3199 - val_FP: 22.6800 - val_FN: 42.8900\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0418 - Accuracy: 0.9857 - Precision: 0.9625 - Recall: 0.9562 - TP: 3224.2900 - TN: 5544.6001 - FP: 102.4000 - FN: 147.7100 - val_loss: 0.0831 - val_Accuracy: 0.9754 - val_Precision: 0.9547 - val_Recall: 0.9472 - val_TP: 761.5200 - val_TN: 1074.8700 - val_FP: 31.1300 - val_FN: 42.4800\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0418 - Accuracy: 0.9857 - Precision: 0.9614 - Recall: 0.9567 - TP: 3226.1201 - TN: 5540.1802 - FP: 106.8200 - FN: 145.8800 - val_loss: 0.0776 - val_Accuracy: 0.9775 - val_Precision: 0.9625 - val_Recall: 0.9470 - val_TP: 761.3900 - val_TN: 1082.5900 - val_FP: 23.4100 - val_FN: 42.6100\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0417 - Accuracy: 0.9858 - Precision: 0.9619 - Recall: 0.9561 - TP: 3223.8201 - TN: 5541.9902 - FP: 105.0100 - FN: 148.1800 - val_loss: 0.0771 - val_Accuracy: 0.9775 - val_Precision: 0.9634 - val_Recall: 0.9469 - val_TP: 761.3100 - val_TN: 1083.4100 - val_FP: 22.5900 - val_FN: 42.6900\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0409 - Accuracy: 0.9855 - Precision: 0.9619 - Recall: 0.9564 - TP: 3225.0000 - TN: 5542.3701 - FP: 104.6300 - FN: 147.0000 - val_loss: 0.0792 - val_Accuracy: 0.9759 - val_Precision: 0.9602 - val_Recall: 0.9471 - val_TP: 761.4400 - val_TN: 1080.2100 - val_FP: 25.7900 - val_FN: 42.5600\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0411 - Accuracy: 0.9855 - Precision: 0.9621 - Recall: 0.9565 - TP: 3225.4299 - TN: 5542.7202 - FP: 104.2800 - FN: 146.5700 - val_loss: 0.0774 - val_Accuracy: 0.9775 - val_Precision: 0.9630 - val_Recall: 0.9470 - val_TP: 761.4200 - val_TN: 1082.9900 - val_FP: 23.0100 - val_FN: 42.5800\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0409 - Accuracy: 0.9856 - Precision: 0.9623 - Recall: 0.9566 - TP: 3225.5200 - TN: 5543.5698 - FP: 103.4300 - FN: 146.4800 - val_loss: 0.0773 - val_Accuracy: 0.9775 - val_Precision: 0.9636 - val_Recall: 0.9468 - val_TP: 761.2300 - val_TN: 1083.5300 - val_FP: 22.4700 - val_FN: 42.7700\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0405 - Accuracy: 0.9857 - Precision: 0.9619 - Recall: 0.9565 - TP: 3225.2800 - TN: 5542.1401 - FP: 104.8600 - FN: 146.7200 - val_loss: 0.0779 - val_Accuracy: 0.9775 - val_Precision: 0.9630 - val_Recall: 0.9467 - val_TP: 761.1800 - val_TN: 1083.0500 - val_FP: 22.9500 - val_FN: 42.8200\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0412 - Accuracy: 0.9854 - Precision: 0.9616 - Recall: 0.9562 - TP: 3224.1899 - TN: 5540.8901 - FP: 106.1100 - FN: 147.8100 - val_loss: 0.0779 - val_Accuracy: 0.9775 - val_Precision: 0.9630 - val_Recall: 0.9468 - val_TP: 761.2100 - val_TN: 1083.0000 - val_FP: 23.0000 - val_FN: 42.7900\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0410 - Accuracy: 0.9856 - Precision: 0.9626 - Recall: 0.9565 - TP: 3225.2600 - TN: 5544.8599 - FP: 102.1400 - FN: 146.7400 - val_loss: 0.0783 - val_Accuracy: 0.9754 - val_Precision: 0.9617 - val_Recall: 0.9473 - val_TP: 761.6200 - val_TN: 1081.8400 - val_FP: 24.1600 - val_FN: 42.3800\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0406 - Accuracy: 0.9859 - Precision: 0.9618 - Recall: 0.9566 - TP: 3225.7700 - TN: 5541.6802 - FP: 105.3200 - FN: 146.2300 - val_loss: 0.0780 - val_Accuracy: 0.9775 - val_Precision: 0.9631 - val_Recall: 0.9467 - val_TP: 761.1400 - val_TN: 1083.1899 - val_FP: 22.8100 - val_FN: 42.8600\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0409 - Accuracy: 0.9857 - Precision: 0.9617 - Recall: 0.9567 - TP: 3225.8701 - TN: 5541.2100 - FP: 105.7900 - FN: 146.1300 - val_loss: 0.0795 - val_Accuracy: 0.9764 - val_Precision: 0.9603 - val_Recall: 0.9470 - val_TP: 761.3900 - val_TN: 1080.2800 - val_FP: 25.7200 - val_FN: 42.6100\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0412 - Accuracy: 0.9855 - Precision: 0.9627 - Recall: 0.9563 - TP: 3224.7100 - TN: 5545.1499 - FP: 101.8500 - FN: 147.2900 - val_loss: 0.0814 - val_Accuracy: 0.9764 - val_Precision: 0.9583 - val_Recall: 0.9468 - val_TP: 761.2500 - val_TN: 1078.4200 - val_FP: 27.5800 - val_FN: 42.7500\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0419 - Accuracy: 0.9851 - Precision: 0.9617 - Recall: 0.9554 - TP: 3221.6101 - TN: 5541.1899 - FP: 105.8100 - FN: 150.3900 - val_loss: 0.0773 - val_Accuracy: 0.9764 - val_Precision: 0.9637 - val_Recall: 0.9462 - val_TP: 760.7800 - val_TN: 1083.6700 - val_FP: 22.3300 - val_FN: 43.2200\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0421 - Accuracy: 0.9848 - Precision: 0.9617 - Recall: 0.9554 - TP: 3221.5200 - TN: 5541.5200 - FP: 105.4800 - FN: 150.4800 - val_loss: 0.0790 - val_Accuracy: 0.9759 - val_Precision: 0.9602 - val_Recall: 0.9470 - val_TP: 761.3800 - val_TN: 1080.1801 - val_FP: 25.8200 - val_FN: 42.6200\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0416 - Accuracy: 0.9855 - Precision: 0.9617 - Recall: 0.9565 - TP: 3225.2500 - TN: 5541.1401 - FP: 105.8600 - FN: 146.7500 - val_loss: 0.0775 - val_Accuracy: 0.9770 - val_Precision: 0.9624 - val_Recall: 0.9470 - val_TP: 761.3900 - val_TN: 1082.4700 - val_FP: 23.5300 - val_FN: 42.6100\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0414 - Accuracy: 0.9853 - Precision: 0.9620 - Recall: 0.9564 - TP: 3224.9900 - TN: 5542.4502 - FP: 104.5500 - FN: 147.0100 - val_loss: 0.0781 - val_Accuracy: 0.9764 - val_Precision: 0.9621 - val_Recall: 0.9466 - val_TP: 761.0700 - val_TN: 1082.0000 - val_FP: 24.0000 - val_FN: 42.9300\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0414 - Accuracy: 0.9858 - Precision: 0.9620 - Recall: 0.9563 - TP: 3224.6799 - TN: 5542.2202 - FP: 104.7800 - FN: 147.3200 - val_loss: 0.0776 - val_Accuracy: 0.9770 - val_Precision: 0.9634 - val_Recall: 0.9463 - val_TP: 760.8600 - val_TN: 1083.3800 - val_FP: 22.6200 - val_FN: 43.1400\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0417 - Accuracy: 0.9854 - Precision: 0.9624 - Recall: 0.9557 - TP: 3222.6599 - TN: 5543.6001 - FP: 103.4000 - FN: 149.3400 - val_loss: 0.0771 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9474 - val_TP: 761.7300 - val_TN: 1082.2500 - val_FP: 23.7500 - val_FN: 42.2700\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0418 - Accuracy: 0.9851 - Precision: 0.9612 - Recall: 0.9564 - TP: 3225.1299 - TN: 5539.6001 - FP: 107.4000 - FN: 146.8700 - val_loss: 0.0768 - val_Accuracy: 0.9775 - val_Precision: 0.9637 - val_Recall: 0.9469 - val_TP: 761.2900 - val_TN: 1083.6600 - val_FP: 22.3400 - val_FN: 42.7100\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0414 - Accuracy: 0.9856 - Precision: 0.9623 - Recall: 0.9562 - TP: 3224.3601 - TN: 5543.1499 - FP: 103.8500 - FN: 147.6400 - val_loss: 0.0774 - val_Accuracy: 0.9775 - val_Precision: 0.9629 - val_Recall: 0.9469 - val_TP: 761.3200 - val_TN: 1082.9301 - val_FP: 23.0700 - val_FN: 42.6800\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0416 - Accuracy: 0.9858 - Precision: 0.9621 - Recall: 0.9563 - TP: 3224.6899 - TN: 5542.8101 - FP: 104.1900 - FN: 147.3100 - val_loss: 0.0781 - val_Accuracy: 0.9775 - val_Precision: 0.9629 - val_Recall: 0.9465 - val_TP: 760.9700 - val_TN: 1082.9000 - val_FP: 23.1000 - val_FN: 43.0300\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0412 - Accuracy: 0.9854 - Precision: 0.9618 - Recall: 0.9563 - TP: 3224.5100 - TN: 5541.3198 - FP: 105.6800 - FN: 147.4900 - val_loss: 0.0790 - val_Accuracy: 0.9764 - val_Precision: 0.9611 - val_Recall: 0.9469 - val_TP: 761.2700 - val_TN: 1081.1100 - val_FP: 24.8900 - val_FN: 42.7300\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0416 - Accuracy: 0.9856 - Precision: 0.9618 - Recall: 0.9564 - TP: 3224.8899 - TN: 5541.3799 - FP: 105.6200 - FN: 147.1100 - val_loss: 0.0771 - val_Accuracy: 0.9775 - val_Precision: 0.9638 - val_Recall: 0.9468 - val_TP: 761.2200 - val_TN: 1083.8000 - val_FP: 22.2000 - val_FN: 42.7800\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0414 - Accuracy: 0.9855 - Precision: 0.9621 - Recall: 0.9567 - TP: 3226.0400 - TN: 5542.7002 - FP: 104.3000 - FN: 145.9600 - val_loss: 0.0783 - val_Accuracy: 0.9770 - val_Precision: 0.9626 - val_Recall: 0.9466 - val_TP: 761.1000 - val_TN: 1082.7000 - val_FP: 23.3000 - val_FN: 42.9000\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0410 - Accuracy: 0.9855 - Precision: 0.9626 - Recall: 0.9560 - TP: 3223.6299 - TN: 5544.7700 - FP: 102.2300 - FN: 148.3700 - val_loss: 0.0805 - val_Accuracy: 0.9759 - val_Precision: 0.9584 - val_Recall: 0.9470 - val_TP: 761.3800 - val_TN: 1078.4600 - val_FP: 27.5400 - val_FN: 42.6200\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0415 - Accuracy: 0.9853 - Precision: 0.9619 - Recall: 0.9561 - TP: 3223.8101 - TN: 5542.0298 - FP: 104.9700 - FN: 148.1900 - val_loss: 0.0780 - val_Accuracy: 0.9764 - val_Precision: 0.9613 - val_Recall: 0.9476 - val_TP: 761.8500 - val_TN: 1081.5200 - val_FP: 24.4800 - val_FN: 42.1500\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0416 - Accuracy: 0.9854 - Precision: 0.9623 - Recall: 0.9560 - TP: 3223.4900 - TN: 5543.7402 - FP: 103.2600 - FN: 148.5100 - val_loss: 0.0797 - val_Accuracy: 0.9759 - val_Precision: 0.9587 - val_Recall: 0.9478 - val_TP: 762.0300 - val_TN: 1078.8400 - val_FP: 27.1600 - val_FN: 41.9700\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0410 - Accuracy: 0.9859 - Precision: 0.9613 - Recall: 0.9573 - TP: 3227.9199 - TN: 5539.3901 - FP: 107.6100 - FN: 144.0800 - val_loss: 0.0775 - val_Accuracy: 0.9775 - val_Precision: 0.9638 - val_Recall: 0.9466 - val_TP: 761.0600 - val_TN: 1083.7800 - val_FP: 22.2200 - val_FN: 42.9400\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0409 - Accuracy: 0.9853 - Precision: 0.9622 - Recall: 0.9561 - TP: 3223.8899 - TN: 5543.0200 - FP: 103.9800 - FN: 148.1100 - val_loss: 0.0785 - val_Accuracy: 0.9764 - val_Precision: 0.9611 - val_Recall: 0.9474 - val_TP: 761.7100 - val_TN: 1081.1300 - val_FP: 24.8700 - val_FN: 42.2900\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0410 - Accuracy: 0.9856 - Precision: 0.9621 - Recall: 0.9567 - TP: 3226.0300 - TN: 5542.6802 - FP: 104.3200 - FN: 145.9700 - val_loss: 0.0784 - val_Accuracy: 0.9775 - val_Precision: 0.9629 - val_Recall: 0.9465 - val_TP: 761.0000 - val_TN: 1083.0000 - val_FP: 23.0000 - val_FN: 43.0000\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0409 - Accuracy: 0.9858 - Precision: 0.9626 - Recall: 0.9560 - TP: 3223.7100 - TN: 5544.7798 - FP: 102.2200 - FN: 148.2900 - val_loss: 0.0783 - val_Accuracy: 0.9764 - val_Precision: 0.9611 - val_Recall: 0.9477 - val_TP: 761.9500 - val_TN: 1081.3101 - val_FP: 24.6900 - val_FN: 42.0500\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0407 - Accuracy: 0.9864 - Precision: 0.9616 - Recall: 0.9573 - TP: 3228.0400 - TN: 5540.5200 - FP: 106.4800 - FN: 143.9600 - val_loss: 0.0795 - val_Accuracy: 0.9764 - val_Precision: 0.9620 - val_Recall: 0.9464 - val_TP: 760.9000 - val_TN: 1081.9900 - val_FP: 24.0100 - val_FN: 43.1000\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0414 - Accuracy: 0.9853 - Precision: 0.9627 - Recall: 0.9559 - TP: 3223.1699 - TN: 5545.2900 - FP: 101.7100 - FN: 148.8300 - val_loss: 0.0779 - val_Accuracy: 0.9775 - val_Precision: 0.9629 - val_Recall: 0.9469 - val_TP: 761.3300 - val_TN: 1082.9800 - val_FP: 23.0200 - val_FN: 42.6700\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0409 - Accuracy: 0.9855 - Precision: 0.9619 - Recall: 0.9565 - TP: 3225.3201 - TN: 5542.0498 - FP: 104.9500 - FN: 146.6800 - val_loss: 0.0790 - val_Accuracy: 0.9764 - val_Precision: 0.9623 - val_Recall: 0.9466 - val_TP: 761.0500 - val_TN: 1082.2600 - val_FP: 23.7400 - val_FN: 42.9500\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0417 - Accuracy: 0.9858 - Precision: 0.9616 - Recall: 0.9566 - TP: 3225.5801 - TN: 5541.3198 - FP: 105.6800 - FN: 146.4200 - val_loss: 0.0790 - val_Accuracy: 0.9764 - val_Precision: 0.9618 - val_Recall: 0.9469 - val_TP: 761.3400 - val_TN: 1082.0200 - val_FP: 23.9800 - val_FN: 42.6600\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0407 - Accuracy: 0.9860 - Precision: 0.9625 - Recall: 0.9568 - TP: 3226.4099 - TN: 5544.5898 - FP: 102.4100 - FN: 145.5900 - val_loss: 0.0797 - val_Accuracy: 0.9754 - val_Precision: 0.9607 - val_Recall: 0.9471 - val_TP: 761.4700 - val_TN: 1080.8400 - val_FP: 25.1600 - val_FN: 42.5300\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0409 - Accuracy: 0.9860 - Precision: 0.9620 - Recall: 0.9570 - TP: 3226.8601 - TN: 5542.1299 - FP: 104.8700 - FN: 145.1400 - val_loss: 0.0789 - val_Accuracy: 0.9764 - val_Precision: 0.9631 - val_Recall: 0.9464 - val_TP: 760.9300 - val_TN: 1083.1801 - val_FP: 22.8200 - val_FN: 43.0700\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0404 - Accuracy: 0.9857 - Precision: 0.9627 - Recall: 0.9569 - TP: 3226.6001 - TN: 5545.4702 - FP: 101.5300 - FN: 145.4000 - val_loss: 0.0784 - val_Accuracy: 0.9775 - val_Precision: 0.9625 - val_Recall: 0.9470 - val_TP: 761.4200 - val_TN: 1082.5900 - val_FP: 23.4100 - val_FN: 42.5800\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0410 - Accuracy: 0.9859 - Precision: 0.9622 - Recall: 0.9566 - TP: 3225.5901 - TN: 5543.6602 - FP: 103.3400 - FN: 146.4100 - val_loss: 0.0783 - val_Accuracy: 0.9775 - val_Precision: 0.9636 - val_Recall: 0.9467 - val_TP: 761.1400 - val_TN: 1083.5699 - val_FP: 22.4300 - val_FN: 42.8600\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0417 - Accuracy: 0.9853 - Precision: 0.9626 - Recall: 0.9559 - TP: 3223.1299 - TN: 5544.6499 - FP: 102.3500 - FN: 148.8700 - val_loss: 0.0784 - val_Accuracy: 0.9764 - val_Precision: 0.9612 - val_Recall: 0.9471 - val_TP: 761.4800 - val_TN: 1081.2600 - val_FP: 24.7400 - val_FN: 42.5200\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0416 - Accuracy: 0.9854 - Precision: 0.9617 - Recall: 0.9561 - TP: 3224.0701 - TN: 5541.0498 - FP: 105.9500 - FN: 147.9300 - val_loss: 0.0773 - val_Accuracy: 0.9775 - val_Precision: 0.9637 - val_Recall: 0.9465 - val_TP: 761.0000 - val_TN: 1083.6801 - val_FP: 22.3200 - val_FN: 43.0000\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0415 - Accuracy: 0.9855 - Precision: 0.9620 - Recall: 0.9562 - TP: 3224.4399 - TN: 5542.1001 - FP: 104.9000 - FN: 147.5600 - val_loss: 0.0779 - val_Accuracy: 0.9775 - val_Precision: 0.9631 - val_Recall: 0.9466 - val_TP: 761.0600 - val_TN: 1083.1500 - val_FP: 22.8500 - val_FN: 42.9400\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0412 - Accuracy: 0.9856 - Precision: 0.9625 - Recall: 0.9563 - TP: 3224.7000 - TN: 5544.3398 - FP: 102.6600 - FN: 147.3000 - val_loss: 0.0778 - val_Accuracy: 0.9775 - val_Precision: 0.9626 - val_Recall: 0.9469 - val_TP: 761.3000 - val_TN: 1082.6801 - val_FP: 23.3200 - val_FN: 42.7000\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0410 - Accuracy: 0.9856 - Precision: 0.9623 - Recall: 0.9566 - TP: 3225.5701 - TN: 5543.5098 - FP: 103.4900 - FN: 146.4300 - val_loss: 0.0780 - val_Accuracy: 0.9764 - val_Precision: 0.9615 - val_Recall: 0.9475 - val_TP: 761.7800 - val_TN: 1081.7000 - val_FP: 24.3000 - val_FN: 42.2200\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0409 - Accuracy: 0.9855 - Precision: 0.9620 - Recall: 0.9564 - TP: 3225.0801 - TN: 5542.2300 - FP: 104.7700 - FN: 146.9200 - val_loss: 0.0796 - val_Accuracy: 0.9764 - val_Precision: 0.9608 - val_Recall: 0.9467 - val_TP: 761.1200 - val_TN: 1080.7700 - val_FP: 25.2300 - val_FN: 42.8800\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0413 - Accuracy: 0.9855 - Precision: 0.9619 - Recall: 0.9565 - TP: 3225.4500 - TN: 5542.1499 - FP: 104.8500 - FN: 146.5500 - val_loss: 0.0778 - val_Accuracy: 0.9775 - val_Precision: 0.9629 - val_Recall: 0.9468 - val_TP: 761.2600 - val_TN: 1082.9500 - val_FP: 23.0500 - val_FN: 42.7400\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0412 - Accuracy: 0.9853 - Precision: 0.9620 - Recall: 0.9561 - TP: 3224.0100 - TN: 5542.6499 - FP: 104.3500 - FN: 147.9900 - val_loss: 0.0786 - val_Accuracy: 0.9770 - val_Precision: 0.9630 - val_Recall: 0.9463 - val_TP: 760.8600 - val_TN: 1083.0900 - val_FP: 22.9100 - val_FN: 43.1400\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0411 - Accuracy: 0.9855 - Precision: 0.9623 - Recall: 0.9563 - TP: 3224.7100 - TN: 5543.2500 - FP: 103.7500 - FN: 147.2900 - val_loss: 0.0792 - val_Accuracy: 0.9759 - val_Precision: 0.9607 - val_Recall: 0.9471 - val_TP: 761.4500 - val_TN: 1080.8101 - val_FP: 25.1900 - val_FN: 42.5500\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0412 - Accuracy: 0.9859 - Precision: 0.9620 - Recall: 0.9566 - TP: 3225.7100 - TN: 5542.4902 - FP: 104.5100 - FN: 146.2900 - val_loss: 0.0777 - val_Accuracy: 0.9775 - val_Precision: 0.9628 - val_Recall: 0.9470 - val_TP: 761.3800 - val_TN: 1082.8300 - val_FP: 23.1700 - val_FN: 42.6200\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0410 - Accuracy: 0.9850 - Precision: 0.9623 - Recall: 0.9563 - TP: 3224.8000 - TN: 5543.4199 - FP: 103.5800 - FN: 147.2000 - val_loss: 0.0772 - val_Accuracy: 0.9775 - val_Precision: 0.9632 - val_Recall: 0.9473 - val_TP: 761.5900 - val_TN: 1083.2300 - val_FP: 22.7700 - val_FN: 42.4100\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0409 - Accuracy: 0.9859 - Precision: 0.9624 - Recall: 0.9566 - TP: 3225.8000 - TN: 5543.7798 - FP: 103.2200 - FN: 146.2000 - val_loss: 0.0781 - val_Accuracy: 0.9775 - val_Precision: 0.9618 - val_Recall: 0.9474 - val_TP: 761.6900 - val_TN: 1081.9500 - val_FP: 24.0500 - val_FN: 42.3100\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0406 - Accuracy: 0.9853 - Precision: 0.9623 - Recall: 0.9570 - TP: 3226.9800 - TN: 5543.4902 - FP: 103.5100 - FN: 145.0200 - val_loss: 0.0781 - val_Accuracy: 0.9775 - val_Precision: 0.9632 - val_Recall: 0.9468 - val_TP: 761.1900 - val_TN: 1083.2800 - val_FP: 22.7200 - val_FN: 42.8100\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0411 - Accuracy: 0.9854 - Precision: 0.9623 - Recall: 0.9565 - TP: 3225.3201 - TN: 5543.6201 - FP: 103.3800 - FN: 146.6800 - val_loss: 0.0784 - val_Accuracy: 0.9775 - val_Precision: 0.9627 - val_Recall: 0.9468 - val_TP: 761.2200 - val_TN: 1082.8400 - val_FP: 23.1600 - val_FN: 42.7800\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0412 - Accuracy: 0.9856 - Precision: 0.9621 - Recall: 0.9569 - TP: 3226.6799 - TN: 5542.7798 - FP: 104.2200 - FN: 145.3200 - val_loss: 0.0787 - val_Accuracy: 0.9764 - val_Precision: 0.9624 - val_Recall: 0.9468 - val_TP: 761.2300 - val_TN: 1082.5601 - val_FP: 23.4400 - val_FN: 42.7700\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0407 - Accuracy: 0.9858 - Precision: 0.9622 - Recall: 0.9567 - TP: 3226.0100 - TN: 5543.2798 - FP: 103.7200 - FN: 145.9900 - val_loss: 0.0790 - val_Accuracy: 0.9764 - val_Precision: 0.9624 - val_Recall: 0.9468 - val_TP: 761.2300 - val_TN: 1082.5500 - val_FP: 23.4500 - val_FN: 42.7700\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0411 - Accuracy: 0.9858 - Precision: 0.9621 - Recall: 0.9567 - TP: 3226.1399 - TN: 5542.5098 - FP: 104.4900 - FN: 145.8600 - val_loss: 0.0779 - val_Accuracy: 0.9775 - val_Precision: 0.9645 - val_Recall: 0.9464 - val_TP: 760.8800 - val_TN: 1084.4100 - val_FP: 21.5900 - val_FN: 43.1200\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0407 - Accuracy: 0.9851 - Precision: 0.9619 - Recall: 0.9567 - TP: 3226.0500 - TN: 5542.2900 - FP: 104.7100 - FN: 145.9500 - val_loss: 0.0787 - val_Accuracy: 0.9764 - val_Precision: 0.9625 - val_Recall: 0.9469 - val_TP: 761.2900 - val_TN: 1082.6700 - val_FP: 23.3300 - val_FN: 42.7100\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0408 - Accuracy: 0.9855 - Precision: 0.9622 - Recall: 0.9565 - TP: 3225.2100 - TN: 5543.4199 - FP: 103.5800 - FN: 146.7900 - val_loss: 0.0786 - val_Accuracy: 0.9764 - val_Precision: 0.9620 - val_Recall: 0.9472 - val_TP: 761.5700 - val_TN: 1082.1899 - val_FP: 23.8100 - val_FN: 42.4300\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0411 - Accuracy: 0.9859 - Precision: 0.9626 - Recall: 0.9568 - TP: 3226.4399 - TN: 5544.7202 - FP: 102.2800 - FN: 145.5600 - val_loss: 0.0842 - val_Accuracy: 0.9759 - val_Precision: 0.9551 - val_Recall: 0.9469 - val_TP: 761.2700 - val_TN: 1075.4000 - val_FP: 30.6000 - val_FN: 42.7300\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0410 - Accuracy: 0.9853 - Precision: 0.9619 - Recall: 0.9568 - TP: 3226.1699 - TN: 5542.0498 - FP: 104.9500 - FN: 145.8300 - val_loss: 0.0779 - val_Accuracy: 0.9775 - val_Precision: 0.9637 - val_Recall: 0.9469 - val_TP: 761.2800 - val_TN: 1083.7300 - val_FP: 22.2700 - val_FN: 42.7200\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0399 - Accuracy: 0.9857 - Precision: 0.9624 - Recall: 0.9569 - TP: 3226.6299 - TN: 5543.9302 - FP: 103.0700 - FN: 145.3700 - val_loss: 0.0780 - val_Accuracy: 0.9775 - val_Precision: 0.9639 - val_Recall: 0.9467 - val_TP: 761.1500 - val_TN: 1083.9000 - val_FP: 22.1000 - val_FN: 42.8500\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0406 - Accuracy: 0.9858 - Precision: 0.9629 - Recall: 0.9562 - TP: 3224.4199 - TN: 5546.0298 - FP: 100.9700 - FN: 147.5800 - val_loss: 0.0794 - val_Accuracy: 0.9764 - val_Precision: 0.9608 - val_Recall: 0.9475 - val_TP: 761.8000 - val_TN: 1080.9600 - val_FP: 25.0400 - val_FN: 42.2000\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0403 - Accuracy: 0.9863 - Precision: 0.9620 - Recall: 0.9575 - TP: 3228.6499 - TN: 5542.3101 - FP: 104.6900 - FN: 143.3500 - val_loss: 0.0784 - val_Accuracy: 0.9775 - val_Precision: 0.9639 - val_Recall: 0.9466 - val_TP: 761.0400 - val_TN: 1083.8600 - val_FP: 22.1400 - val_FN: 42.9600\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0403 - Accuracy: 0.9863 - Precision: 0.9629 - Recall: 0.9573 - TP: 3228.0601 - TN: 5545.7300 - FP: 101.2700 - FN: 143.9400 - val_loss: 0.0781 - val_Accuracy: 0.9780 - val_Precision: 0.9630 - val_Recall: 0.9473 - val_TP: 761.6200 - val_TN: 1083.0800 - val_FP: 22.9200 - val_FN: 42.3800\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0404 - Accuracy: 0.9860 - Precision: 0.9625 - Recall: 0.9569 - TP: 3226.6699 - TN: 5544.6802 - FP: 102.3200 - FN: 145.3300 - val_loss: 0.0790 - val_Accuracy: 0.9764 - val_Precision: 0.9627 - val_Recall: 0.9469 - val_TP: 761.2800 - val_TN: 1082.8800 - val_FP: 23.1200 - val_FN: 42.7200\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0411 - Accuracy: 0.9856 - Precision: 0.9628 - Recall: 0.9567 - TP: 3225.9399 - TN: 5546.1201 - FP: 100.8800 - FN: 146.0600 - val_loss: 0.0779 - val_Accuracy: 0.9775 - val_Precision: 0.9627 - val_Recall: 0.9476 - val_TP: 761.8800 - val_TN: 1082.7900 - val_FP: 23.2100 - val_FN: 42.1200\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0402 - Accuracy: 0.9863 - Precision: 0.9620 - Recall: 0.9576 - TP: 3228.8701 - TN: 5542.1699 - FP: 104.8300 - FN: 143.1300 - val_loss: 0.0784 - val_Accuracy: 0.9775 - val_Precision: 0.9639 - val_Recall: 0.9467 - val_TP: 761.1600 - val_TN: 1083.9301 - val_FP: 22.0700 - val_FN: 42.8400\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0403 - Accuracy: 0.9860 - Precision: 0.9628 - Recall: 0.9568 - TP: 3226.3401 - TN: 5545.9199 - FP: 101.0800 - FN: 145.6600 - val_loss: 0.0791 - val_Accuracy: 0.9759 - val_Precision: 0.9623 - val_Recall: 0.9471 - val_TP: 761.4700 - val_TN: 1082.5300 - val_FP: 23.4700 - val_FN: 42.5300\n",
      "Epoch 30/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0402 - Accuracy: 0.9863 - Precision: 0.9624 - Recall: 0.9574 - TP: 3228.4299 - TN: 5544.2002 - FP: 102.8000 - FN: 143.5700 - val_loss: 0.0800 - val_Accuracy: 0.9764 - val_Precision: 0.9615 - val_Recall: 0.9470 - val_TP: 761.3600 - val_TN: 1081.6100 - val_FP: 24.3900 - val_FN: 42.6400\n",
      "Epoch 31/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0412 - Accuracy: 0.9860 - Precision: 0.9627 - Recall: 0.9570 - TP: 3226.9700 - TN: 5545.5000 - FP: 101.5000 - FN: 145.0300 - val_loss: 0.0785 - val_Accuracy: 0.9770 - val_Precision: 0.9631 - val_Recall: 0.9471 - val_TP: 761.4900 - val_TN: 1083.2300 - val_FP: 22.7700 - val_FN: 42.5100\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 5ms/step - loss: 0.0417 - Accuracy: 0.9857 - Precision: 0.9622 - Recall: 0.9562 - TP: 3224.2700 - TN: 5543.0898 - FP: 103.9100 - FN: 147.7300 - val_loss: 0.0797 - val_Accuracy: 0.9764 - val_Precision: 0.9592 - val_Recall: 0.9478 - val_TP: 762.0100 - val_TN: 1079.3101 - val_FP: 26.6900 - val_FN: 41.9900\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0410 - Accuracy: 0.9858 - Precision: 0.9617 - Recall: 0.9571 - TP: 3227.3999 - TN: 5540.9600 - FP: 106.0400 - FN: 144.6000 - val_loss: 0.0782 - val_Accuracy: 0.9775 - val_Precision: 0.9633 - val_Recall: 0.9466 - val_TP: 761.0900 - val_TN: 1083.3300 - val_FP: 22.6700 - val_FN: 42.9100\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0409 - Accuracy: 0.9858 - Precision: 0.9625 - Recall: 0.9563 - TP: 3224.7800 - TN: 5544.4302 - FP: 102.5700 - FN: 147.2200 - val_loss: 0.0786 - val_Accuracy: 0.9764 - val_Precision: 0.9618 - val_Recall: 0.9472 - val_TP: 761.5300 - val_TN: 1081.9900 - val_FP: 24.0100 - val_FN: 42.4700\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0419 - Accuracy: 0.9853 - Precision: 0.9614 - Recall: 0.9560 - TP: 3223.6399 - TN: 5540.6201 - FP: 106.3800 - FN: 148.3600 - val_loss: 0.0774 - val_Accuracy: 0.9775 - val_Precision: 0.9628 - val_Recall: 0.9474 - val_TP: 761.7100 - val_TN: 1082.9000 - val_FP: 23.1000 - val_FN: 42.2900\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0412 - Accuracy: 0.9864 - Precision: 0.9622 - Recall: 0.9568 - TP: 3226.3701 - TN: 5543.5698 - FP: 103.4300 - FN: 145.6300 - val_loss: 0.0782 - val_Accuracy: 0.9775 - val_Precision: 0.9634 - val_Recall: 0.9467 - val_TP: 761.1700 - val_TN: 1083.4500 - val_FP: 22.5500 - val_FN: 42.8300\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0406 - Accuracy: 0.9859 - Precision: 0.9624 - Recall: 0.9569 - TP: 3226.7300 - TN: 5543.8301 - FP: 103.1700 - FN: 145.2700 - val_loss: 0.0780 - val_Accuracy: 0.9770 - val_Precision: 0.9627 - val_Recall: 0.9472 - val_TP: 761.5100 - val_TN: 1082.7900 - val_FP: 23.2100 - val_FN: 42.4900\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0410 - Accuracy: 0.9860 - Precision: 0.9620 - Recall: 0.9569 - TP: 3226.6599 - TN: 5542.1602 - FP: 104.8400 - FN: 145.3400 - val_loss: 0.0779 - val_Accuracy: 0.9775 - val_Precision: 0.9645 - val_Recall: 0.9464 - val_TP: 760.9300 - val_TN: 1084.4100 - val_FP: 21.5900 - val_FN: 43.0700\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0409 - Accuracy: 0.9858 - Precision: 0.9623 - Recall: 0.9570 - TP: 3226.9199 - TN: 5543.9902 - FP: 103.0100 - FN: 145.0800 - val_loss: 0.0822 - val_Accuracy: 0.9764 - val_Precision: 0.9580 - val_Recall: 0.9467 - val_TP: 761.1300 - val_TN: 1078.1801 - val_FP: 27.8200 - val_FN: 42.8700\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0418 - Accuracy: 0.9853 - Precision: 0.9624 - Recall: 0.9557 - TP: 3222.6299 - TN: 5544.2402 - FP: 102.7600 - FN: 149.3700 - val_loss: 0.0781 - val_Accuracy: 0.9775 - val_Precision: 0.9632 - val_Recall: 0.9470 - val_TP: 761.3500 - val_TN: 1083.2500 - val_FP: 22.7500 - val_FN: 42.6500\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0407 - Accuracy: 0.9858 - Precision: 0.9622 - Recall: 0.9569 - TP: 3226.5601 - TN: 5543.1499 - FP: 103.8500 - FN: 145.4400 - val_loss: 0.0804 - val_Accuracy: 0.9754 - val_Precision: 0.9595 - val_Recall: 0.9473 - val_TP: 761.6500 - val_TN: 1079.6600 - val_FP: 26.3400 - val_FN: 42.3500\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0403 - Accuracy: 0.9859 - Precision: 0.9621 - Recall: 0.9573 - TP: 3227.9900 - TN: 5542.8599 - FP: 104.1400 - FN: 144.0100 - val_loss: 0.0788 - val_Accuracy: 0.9754 - val_Precision: 0.9621 - val_Recall: 0.9472 - val_TP: 761.5500 - val_TN: 1082.2900 - val_FP: 23.7100 - val_FN: 42.4500\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0407 - Accuracy: 0.9859 - Precision: 0.9625 - Recall: 0.9567 - TP: 3226.1399 - TN: 5544.6299 - FP: 102.3700 - FN: 145.8600 - val_loss: 0.0787 - val_Accuracy: 0.9775 - val_Precision: 0.9628 - val_Recall: 0.9469 - val_TP: 761.2700 - val_TN: 1082.9100 - val_FP: 23.0900 - val_FN: 42.7300\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0403 - Accuracy: 0.9853 - Precision: 0.9625 - Recall: 0.9569 - TP: 3226.7300 - TN: 5544.5601 - FP: 102.4400 - FN: 145.2700 - val_loss: 0.0780 - val_Accuracy: 0.9775 - val_Precision: 0.9632 - val_Recall: 0.9473 - val_TP: 761.6300 - val_TN: 1083.2400 - val_FP: 22.7600 - val_FN: 42.3700\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0402 - Accuracy: 0.9857 - Precision: 0.9621 - Recall: 0.9571 - TP: 3227.2600 - TN: 5543.0698 - FP: 103.9300 - FN: 144.7400 - val_loss: 0.0783 - val_Accuracy: 0.9775 - val_Precision: 0.9635 - val_Recall: 0.9469 - val_TP: 761.2800 - val_TN: 1083.5800 - val_FP: 22.4200 - val_FN: 42.7200\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0411 - Accuracy: 0.9855 - Precision: 0.9625 - Recall: 0.9564 - TP: 3225.0100 - TN: 5544.9800 - FP: 102.0200 - FN: 146.9900 - val_loss: 0.0791 - val_Accuracy: 0.9759 - val_Precision: 0.9613 - val_Recall: 0.9475 - val_TP: 761.8000 - val_TN: 1081.6000 - val_FP: 24.4000 - val_FN: 42.2000\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0402 - Accuracy: 0.9859 - Precision: 0.9626 - Recall: 0.9574 - TP: 3228.4600 - TN: 5544.8398 - FP: 102.1600 - FN: 143.5400 - val_loss: 0.0785 - val_Accuracy: 0.9775 - val_Precision: 0.9625 - val_Recall: 0.9473 - val_TP: 761.6400 - val_TN: 1082.6500 - val_FP: 23.3500 - val_FN: 42.3600\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0406 - Accuracy: 0.9855 - Precision: 0.9621 - Recall: 0.9566 - TP: 3225.6599 - TN: 5542.9902 - FP: 104.0100 - FN: 146.3400 - val_loss: 0.0781 - val_Accuracy: 0.9770 - val_Precision: 0.9639 - val_Recall: 0.9470 - val_TP: 761.3900 - val_TN: 1083.9500 - val_FP: 22.0500 - val_FN: 42.6100\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0402 - Accuracy: 0.9864 - Precision: 0.9624 - Recall: 0.9576 - TP: 3229.0901 - TN: 5544.1299 - FP: 102.8700 - FN: 142.9100 - val_loss: 0.0799 - val_Accuracy: 0.9764 - val_Precision: 0.9620 - val_Recall: 0.9467 - val_TP: 761.1100 - val_TN: 1082.0699 - val_FP: 23.9300 - val_FN: 42.8900\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0403 - Accuracy: 0.9863 - Precision: 0.9627 - Recall: 0.9573 - TP: 3228.1101 - TN: 5545.0298 - FP: 101.9700 - FN: 143.8900 - val_loss: 0.0792 - val_Accuracy: 0.9764 - val_Precision: 0.9628 - val_Recall: 0.9469 - val_TP: 761.2800 - val_TN: 1082.9301 - val_FP: 23.0700 - val_FN: 42.7200\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0402 - Accuracy: 0.9859 - Precision: 0.9629 - Recall: 0.9569 - TP: 3226.5300 - TN: 5546.2002 - FP: 100.8000 - FN: 145.4700 - val_loss: 0.0781 - val_Accuracy: 0.9775 - val_Precision: 0.9629 - val_Recall: 0.9476 - val_TP: 761.9000 - val_TN: 1083.0300 - val_FP: 22.9700 - val_FN: 42.1000\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0403 - Accuracy: 0.9861 - Precision: 0.9624 - Recall: 0.9573 - TP: 3227.9900 - TN: 5544.2202 - FP: 102.7800 - FN: 144.0100 - val_loss: 0.0782 - val_Accuracy: 0.9770 - val_Precision: 0.9640 - val_Recall: 0.9469 - val_TP: 761.3300 - val_TN: 1084.0400 - val_FP: 21.9600 - val_FN: 42.6700\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0407 - Accuracy: 0.9860 - Precision: 0.9627 - Recall: 0.9571 - TP: 3227.3899 - TN: 5545.8198 - FP: 101.1800 - FN: 144.6100 - val_loss: 0.0791 - val_Accuracy: 0.9770 - val_Precision: 0.9621 - val_Recall: 0.9473 - val_TP: 761.6500 - val_TN: 1082.3400 - val_FP: 23.6600 - val_FN: 42.3500\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0407 - Accuracy: 0.9859 - Precision: 0.9624 - Recall: 0.9572 - TP: 3227.5200 - TN: 5543.9800 - FP: 103.0200 - FN: 144.4800 - val_loss: 0.0790 - val_Accuracy: 0.9780 - val_Precision: 0.9623 - val_Recall: 0.9474 - val_TP: 761.7400 - val_TN: 1082.5200 - val_FP: 23.4800 - val_FN: 42.2600\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0396 - Accuracy: 0.9861 - Precision: 0.9624 - Recall: 0.9579 - TP: 3229.9500 - TN: 5544.3701 - FP: 102.6300 - FN: 142.0500 - val_loss: 0.0803 - val_Accuracy: 0.9764 - val_Precision: 0.9607 - val_Recall: 0.9475 - val_TP: 761.7500 - val_TN: 1080.9200 - val_FP: 25.0800 - val_FN: 42.2500\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0416 - Accuracy: 0.9853 - Precision: 0.9621 - Recall: 0.9563 - TP: 3224.7300 - TN: 5543.1699 - FP: 103.8300 - FN: 147.2700 - val_loss: 0.0782 - val_Accuracy: 0.9775 - val_Precision: 0.9617 - val_Recall: 0.9475 - val_TP: 761.8300 - val_TN: 1081.8800 - val_FP: 24.1200 - val_FN: 42.1700\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0413 - Accuracy: 0.9855 - Precision: 0.9619 - Recall: 0.9571 - TP: 3227.1799 - TN: 5542.6299 - FP: 104.3700 - FN: 144.8200 - val_loss: 0.0786 - val_Accuracy: 0.9764 - val_Precision: 0.9616 - val_Recall: 0.9474 - val_TP: 761.7100 - val_TN: 1081.8400 - val_FP: 24.1600 - val_FN: 42.2900\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0414 - Accuracy: 0.9856 - Precision: 0.9623 - Recall: 0.9563 - TP: 3224.5000 - TN: 5543.8301 - FP: 103.1700 - FN: 147.5000 - val_loss: 0.0792 - val_Accuracy: 0.9754 - val_Precision: 0.9612 - val_Recall: 0.9473 - val_TP: 761.6500 - val_TN: 1081.4600 - val_FP: 24.5400 - val_FN: 42.3500\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0405 - Accuracy: 0.9863 - Precision: 0.9617 - Recall: 0.9573 - TP: 3227.8701 - TN: 5541.0298 - FP: 105.9700 - FN: 144.1300 - val_loss: 0.0790 - val_Accuracy: 0.9764 - val_Precision: 0.9620 - val_Recall: 0.9469 - val_TP: 761.3400 - val_TN: 1082.1400 - val_FP: 23.8600 - val_FN: 42.6600\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0410 - Accuracy: 0.9861 - Precision: 0.9620 - Recall: 0.9570 - TP: 3227.1399 - TN: 5542.5698 - FP: 104.4300 - FN: 144.8600 - val_loss: 0.0783 - val_Accuracy: 0.9775 - val_Precision: 0.9645 - val_Recall: 0.9462 - val_TP: 760.7800 - val_TN: 1084.4600 - val_FP: 21.5400 - val_FN: 43.2200\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0410 - Accuracy: 0.9859 - Precision: 0.9630 - Recall: 0.9564 - TP: 3225.0200 - TN: 5546.5200 - FP: 100.4800 - FN: 146.9800 - val_loss: 0.0799 - val_Accuracy: 0.9749 - val_Precision: 0.9606 - val_Recall: 0.9473 - val_TP: 761.6100 - val_TN: 1080.8300 - val_FP: 25.1700 - val_FN: 42.3900\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0407 - Accuracy: 0.9858 - Precision: 0.9625 - Recall: 0.9569 - TP: 3226.5801 - TN: 5544.4199 - FP: 102.5800 - FN: 145.4200 - val_loss: 0.0796 - val_Accuracy: 0.9754 - val_Precision: 0.9611 - val_Recall: 0.9472 - val_TP: 761.5400 - val_TN: 1081.2500 - val_FP: 24.7500 - val_FN: 42.4600\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0417 - Accuracy: 0.9858 - Precision: 0.9621 - Recall: 0.9566 - TP: 3225.7400 - TN: 5543.1099 - FP: 103.8900 - FN: 146.2600 - val_loss: 0.0786 - val_Accuracy: 0.9775 - val_Precision: 0.9628 - val_Recall: 0.9470 - val_TP: 761.3900 - val_TN: 1082.9700 - val_FP: 23.0300 - val_FN: 42.6100\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0402 - Accuracy: 0.9856 - Precision: 0.9626 - Recall: 0.9571 - TP: 3227.4299 - TN: 5544.6602 - FP: 102.3400 - FN: 144.5700 - val_loss: 0.0779 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9473 - val_TP: 761.6300 - val_TN: 1083.3600 - val_FP: 22.6400 - val_FN: 42.3700\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0408 - Accuracy: 0.9857 - Precision: 0.9625 - Recall: 0.9569 - TP: 3226.6299 - TN: 5544.6802 - FP: 102.3200 - FN: 145.3700 - val_loss: 0.0782 - val_Accuracy: 0.9780 - val_Precision: 0.9627 - val_Recall: 0.9474 - val_TP: 761.7400 - val_TN: 1082.8700 - val_FP: 23.1300 - val_FN: 42.2600\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0405 - Accuracy: 0.9859 - Precision: 0.9620 - Recall: 0.9571 - TP: 3227.2300 - TN: 5542.7402 - FP: 104.2600 - FN: 144.7700 - val_loss: 0.0783 - val_Accuracy: 0.9775 - val_Precision: 0.9636 - val_Recall: 0.9469 - val_TP: 761.2900 - val_TN: 1083.6700 - val_FP: 22.3300 - val_FN: 42.7100\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0404 - Accuracy: 0.9863 - Precision: 0.9630 - Recall: 0.9568 - TP: 3226.2900 - TN: 5546.2900 - FP: 100.7100 - FN: 145.7100 - val_loss: 0.0781 - val_Accuracy: 0.9775 - val_Precision: 0.9638 - val_Recall: 0.9471 - val_TP: 761.4600 - val_TN: 1083.7700 - val_FP: 22.2300 - val_FN: 42.5400\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0408 - Accuracy: 0.9857 - Precision: 0.9619 - Recall: 0.9573 - TP: 3228.1201 - TN: 5542.5298 - FP: 104.4700 - FN: 143.8800 - val_loss: 0.0799 - val_Accuracy: 0.9759 - val_Precision: 0.9609 - val_Recall: 0.9473 - val_TP: 761.6100 - val_TN: 1081.0800 - val_FP: 24.9200 - val_FN: 42.3900\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0405 - Accuracy: 0.9865 - Precision: 0.9627 - Recall: 0.9575 - TP: 3228.7200 - TN: 5545.3599 - FP: 101.6400 - FN: 143.2800 - val_loss: 0.0784 - val_Accuracy: 0.9775 - val_Precision: 0.9624 - val_Recall: 0.9476 - val_TP: 761.8500 - val_TN: 1082.6100 - val_FP: 23.3900 - val_FN: 42.1500\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0403 - Accuracy: 0.9860 - Precision: 0.9622 - Recall: 0.9573 - TP: 3227.8701 - TN: 5543.3599 - FP: 103.6400 - FN: 144.1300 - val_loss: 0.0795 - val_Accuracy: 0.9764 - val_Precision: 0.9616 - val_Recall: 0.9474 - val_TP: 761.7100 - val_TN: 1081.8300 - val_FP: 24.1700 - val_FN: 42.2900\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0404 - Accuracy: 0.9863 - Precision: 0.9624 - Recall: 0.9571 - TP: 3227.3401 - TN: 5544.2598 - FP: 102.7400 - FN: 144.6600 - val_loss: 0.0799 - val_Accuracy: 0.9759 - val_Precision: 0.9622 - val_Recall: 0.9468 - val_TP: 761.2500 - val_TN: 1082.4100 - val_FP: 23.5900 - val_FN: 42.7500\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0399 - Accuracy: 0.9863 - Precision: 0.9625 - Recall: 0.9573 - TP: 3228.1599 - TN: 5544.2100 - FP: 102.7900 - FN: 143.8400 - val_loss: 0.0789 - val_Accuracy: 0.9775 - val_Precision: 0.9638 - val_Recall: 0.9467 - val_TP: 761.1100 - val_TN: 1083.7900 - val_FP: 22.2100 - val_FN: 42.8900\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0406 - Accuracy: 0.9855 - Precision: 0.9628 - Recall: 0.9570 - TP: 3226.9800 - TN: 5545.8398 - FP: 101.1600 - FN: 145.0200 - val_loss: 0.0790 - val_Accuracy: 0.9770 - val_Precision: 0.9630 - val_Recall: 0.9471 - val_TP: 761.4300 - val_TN: 1083.1600 - val_FP: 22.8400 - val_FN: 42.5700\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0406 - Accuracy: 0.9858 - Precision: 0.9627 - Recall: 0.9566 - TP: 3225.7400 - TN: 5545.2002 - FP: 101.8000 - FN: 146.2600 - val_loss: 0.0787 - val_Accuracy: 0.9770 - val_Precision: 0.9635 - val_Recall: 0.9470 - val_TP: 761.4200 - val_TN: 1083.5500 - val_FP: 22.4500 - val_FN: 42.5800\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0399 - Accuracy: 0.9865 - Precision: 0.9623 - Recall: 0.9577 - TP: 3229.4900 - TN: 5543.5801 - FP: 103.4200 - FN: 142.5100 - val_loss: 0.0803 - val_Accuracy: 0.9764 - val_Precision: 0.9625 - val_Recall: 0.9466 - val_TP: 761.0900 - val_TN: 1082.7100 - val_FP: 23.2900 - val_FN: 42.9100\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0408 - Accuracy: 0.9856 - Precision: 0.9622 - Recall: 0.9567 - TP: 3225.9399 - TN: 5543.7900 - FP: 103.2100 - FN: 146.0600 - val_loss: 0.0799 - val_Accuracy: 0.9759 - val_Precision: 0.9623 - val_Recall: 0.9469 - val_TP: 761.2900 - val_TN: 1082.5300 - val_FP: 23.4700 - val_FN: 42.7100\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0407 - Accuracy: 0.9861 - Precision: 0.9624 - Recall: 0.9575 - TP: 3228.7300 - TN: 5544.0000 - FP: 103.0000 - FN: 143.2700 - val_loss: 0.0813 - val_Accuracy: 0.9764 - val_Precision: 0.9616 - val_Recall: 0.9465 - val_TP: 760.9500 - val_TN: 1081.7400 - val_FP: 24.2600 - val_FN: 43.0500\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0401 - Accuracy: 0.9866 - Precision: 0.9633 - Recall: 0.9573 - TP: 3227.9199 - TN: 5547.5200 - FP: 99.4800 - FN: 144.0800 - val_loss: 0.0803 - val_Accuracy: 0.9764 - val_Precision: 0.9626 - val_Recall: 0.9466 - val_TP: 761.1000 - val_TN: 1082.7700 - val_FP: 23.2300 - val_FN: 42.9000\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0399 - Accuracy: 0.9860 - Precision: 0.9631 - Recall: 0.9567 - TP: 3226.1201 - TN: 5546.7700 - FP: 100.2300 - FN: 145.8800 - val_loss: 0.0790 - val_Accuracy: 0.9770 - val_Precision: 0.9623 - val_Recall: 0.9477 - val_TP: 761.9400 - val_TN: 1082.5300 - val_FP: 23.4700 - val_FN: 42.0600\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0400 - Accuracy: 0.9859 - Precision: 0.9623 - Recall: 0.9579 - TP: 3229.8999 - TN: 5543.6201 - FP: 103.3800 - FN: 142.1000 - val_loss: 0.0805 - val_Accuracy: 0.9759 - val_Precision: 0.9605 - val_Recall: 0.9477 - val_TP: 761.9400 - val_TN: 1080.7600 - val_FP: 25.2400 - val_FN: 42.0600\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0398 - Accuracy: 0.9861 - Precision: 0.9629 - Recall: 0.9573 - TP: 3228.0901 - TN: 5545.7798 - FP: 101.2200 - FN: 143.9100 - val_loss: 0.0792 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9471 - val_TP: 761.4300 - val_TN: 1083.4200 - val_FP: 22.5800 - val_FN: 42.5700\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0399 - Accuracy: 0.9858 - Precision: 0.9624 - Recall: 0.9576 - TP: 3229.0300 - TN: 5544.5000 - FP: 102.5000 - FN: 142.9700 - val_loss: 0.0798 - val_Accuracy: 0.9759 - val_Precision: 0.9627 - val_Recall: 0.9471 - val_TP: 761.4400 - val_TN: 1082.8400 - val_FP: 23.1600 - val_FN: 42.5600\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0397 - Accuracy: 0.9864 - Precision: 0.9633 - Recall: 0.9575 - TP: 3228.7900 - TN: 5547.4502 - FP: 99.5500 - FN: 143.2100 - val_loss: 0.0799 - val_Accuracy: 0.9764 - val_Precision: 0.9619 - val_Recall: 0.9475 - val_TP: 761.8200 - val_TN: 1082.1100 - val_FP: 23.8900 - val_FN: 42.1800\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0397 - Accuracy: 0.9859 - Precision: 0.9626 - Recall: 0.9579 - TP: 3229.9800 - TN: 5544.8799 - FP: 102.1200 - FN: 142.0200 - val_loss: 0.0803 - val_Accuracy: 0.9764 - val_Precision: 0.9631 - val_Recall: 0.9467 - val_TP: 761.1300 - val_TN: 1083.2400 - val_FP: 22.7600 - val_FN: 42.8700\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 6ms/step - loss: 0.0414 - Accuracy: 0.9857 - Precision: 0.9627 - Recall: 0.9569 - TP: 3226.6799 - TN: 5545.7998 - FP: 101.2000 - FN: 145.3200 - val_loss: 0.0784 - val_Accuracy: 0.9775 - val_Precision: 0.9625 - val_Recall: 0.9475 - val_TP: 761.7800 - val_TN: 1082.6400 - val_FP: 23.3600 - val_FN: 42.2200\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0414 - Accuracy: 0.9857 - Precision: 0.9621 - Recall: 0.9567 - TP: 3226.0701 - TN: 5542.8398 - FP: 104.1600 - FN: 145.9300 - val_loss: 0.0791 - val_Accuracy: 0.9764 - val_Precision: 0.9617 - val_Recall: 0.9475 - val_TP: 761.8000 - val_TN: 1081.9800 - val_FP: 24.0200 - val_FN: 42.2000\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0405 - Accuracy: 0.9858 - Precision: 0.9625 - Recall: 0.9573 - TP: 3227.9600 - TN: 5544.5098 - FP: 102.4900 - FN: 144.0400 - val_loss: 0.0783 - val_Accuracy: 0.9775 - val_Precision: 0.9636 - val_Recall: 0.9470 - val_TP: 761.4100 - val_TN: 1083.6400 - val_FP: 22.3600 - val_FN: 42.5900\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0402 - Accuracy: 0.9860 - Precision: 0.9626 - Recall: 0.9573 - TP: 3227.9199 - TN: 5545.0200 - FP: 101.9800 - FN: 144.0800 - val_loss: 0.0793 - val_Accuracy: 0.9759 - val_Precision: 0.9620 - val_Recall: 0.9473 - val_TP: 761.6500 - val_TN: 1082.2100 - val_FP: 23.7900 - val_FN: 42.3500\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0413 - Accuracy: 0.9860 - Precision: 0.9622 - Recall: 0.9567 - TP: 3226.0100 - TN: 5543.4302 - FP: 103.5700 - FN: 145.9900 - val_loss: 0.0784 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9473 - val_TP: 761.6100 - val_TN: 1083.2700 - val_FP: 22.7300 - val_FN: 42.3900\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0405 - Accuracy: 0.9858 - Precision: 0.9623 - Recall: 0.9569 - TP: 3226.5901 - TN: 5543.5898 - FP: 103.4100 - FN: 145.4100 - val_loss: 0.0790 - val_Accuracy: 0.9775 - val_Precision: 0.9629 - val_Recall: 0.9469 - val_TP: 761.3300 - val_TN: 1083.0200 - val_FP: 22.9800 - val_FN: 42.6700\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0406 - Accuracy: 0.9861 - Precision: 0.9625 - Recall: 0.9570 - TP: 3227.0901 - TN: 5544.6001 - FP: 102.4000 - FN: 144.9100 - val_loss: 0.0785 - val_Accuracy: 0.9775 - val_Precision: 0.9635 - val_Recall: 0.9471 - val_TP: 761.4500 - val_TN: 1083.5699 - val_FP: 22.4300 - val_FN: 42.5500\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0408 - Accuracy: 0.9858 - Precision: 0.9621 - Recall: 0.9572 - TP: 3227.6899 - TN: 5543.1401 - FP: 103.8600 - FN: 144.3100 - val_loss: 0.0791 - val_Accuracy: 0.9770 - val_Precision: 0.9627 - val_Recall: 0.9471 - val_TP: 761.4300 - val_TN: 1082.8700 - val_FP: 23.1300 - val_FN: 42.5700\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0402 - Accuracy: 0.9859 - Precision: 0.9636 - Recall: 0.9565 - TP: 3225.4399 - TN: 5548.7998 - FP: 98.2000 - FN: 146.5600 - val_loss: 0.0790 - val_Accuracy: 0.9759 - val_Precision: 0.9616 - val_Recall: 0.9479 - val_TP: 762.1400 - val_TN: 1081.8300 - val_FP: 24.1700 - val_FN: 41.8600\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0403 - Accuracy: 0.9866 - Precision: 0.9622 - Recall: 0.9578 - TP: 3229.6201 - TN: 5543.1802 - FP: 103.8200 - FN: 142.3800 - val_loss: 0.0784 - val_Accuracy: 0.9780 - val_Precision: 0.9636 - val_Recall: 0.9472 - val_TP: 761.5400 - val_TN: 1083.6200 - val_FP: 22.3800 - val_FN: 42.4600\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0402 - Accuracy: 0.9864 - Precision: 0.9631 - Recall: 0.9576 - TP: 3229.0500 - TN: 5547.0298 - FP: 99.9700 - FN: 142.9500 - val_loss: 0.0805 - val_Accuracy: 0.9764 - val_Precision: 0.9607 - val_Recall: 0.9475 - val_TP: 761.7600 - val_TN: 1080.8900 - val_FP: 25.1100 - val_FN: 42.2400\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0401 - Accuracy: 0.9867 - Precision: 0.9624 - Recall: 0.9578 - TP: 3229.7400 - TN: 5544.0098 - FP: 102.9900 - FN: 142.2600 - val_loss: 0.0799 - val_Accuracy: 0.9764 - val_Precision: 0.9627 - val_Recall: 0.9468 - val_TP: 761.2500 - val_TN: 1082.9200 - val_FP: 23.0800 - val_FN: 42.7500\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0406 - Accuracy: 0.9859 - Precision: 0.9623 - Recall: 0.9571 - TP: 3227.3899 - TN: 5544.4600 - FP: 102.5400 - FN: 144.6100 - val_loss: 0.0793 - val_Accuracy: 0.9770 - val_Precision: 0.9626 - val_Recall: 0.9474 - val_TP: 761.6700 - val_TN: 1082.7500 - val_FP: 23.2500 - val_FN: 42.3300\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0400 - Accuracy: 0.9859 - Precision: 0.9627 - Recall: 0.9569 - TP: 3226.6499 - TN: 5545.1602 - FP: 101.8400 - FN: 145.3500 - val_loss: 0.0820 - val_Accuracy: 0.9749 - val_Precision: 0.9584 - val_Recall: 0.9475 - val_TP: 761.8200 - val_TN: 1078.6700 - val_FP: 27.3300 - val_FN: 42.1800\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0395 - Accuracy: 0.9860 - Precision: 0.9623 - Recall: 0.9575 - TP: 3228.7700 - TN: 5543.4302 - FP: 103.5700 - FN: 143.2300 - val_loss: 0.0794 - val_Accuracy: 0.9770 - val_Precision: 0.9630 - val_Recall: 0.9471 - val_TP: 761.4600 - val_TN: 1083.0900 - val_FP: 22.9100 - val_FN: 42.5400\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0399 - Accuracy: 0.9864 - Precision: 0.9636 - Recall: 0.9572 - TP: 3227.7700 - TN: 5548.7300 - FP: 98.2700 - FN: 144.2300 - val_loss: 0.0819 - val_Accuracy: 0.9759 - val_Precision: 0.9598 - val_Recall: 0.9472 - val_TP: 761.5300 - val_TN: 1080.0699 - val_FP: 25.9300 - val_FN: 42.4700\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0399 - Accuracy: 0.9859 - Precision: 0.9625 - Recall: 0.9580 - TP: 3230.2800 - TN: 5544.7700 - FP: 102.2300 - FN: 141.7200 - val_loss: 0.0814 - val_Accuracy: 0.9759 - val_Precision: 0.9594 - val_Recall: 0.9478 - val_TP: 762.0100 - val_TN: 1079.6801 - val_FP: 26.3200 - val_FN: 41.9900\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0397 - Accuracy: 0.9861 - Precision: 0.9627 - Recall: 0.9576 - TP: 3228.8701 - TN: 5545.2500 - FP: 101.7500 - FN: 143.1300 - val_loss: 0.0796 - val_Accuracy: 0.9775 - val_Precision: 0.9634 - val_Recall: 0.9468 - val_TP: 761.2600 - val_TN: 1083.5400 - val_FP: 22.4600 - val_FN: 42.7400\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0396 - Accuracy: 0.9864 - Precision: 0.9629 - Recall: 0.9575 - TP: 3228.5901 - TN: 5545.9399 - FP: 101.0600 - FN: 143.4100 - val_loss: 0.0793 - val_Accuracy: 0.9775 - val_Precision: 0.9626 - val_Recall: 0.9476 - val_TP: 761.9100 - val_TN: 1082.7500 - val_FP: 23.2500 - val_FN: 42.0900\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0396 - Accuracy: 0.9863 - Precision: 0.9631 - Recall: 0.9570 - TP: 3226.9399 - TN: 5547.2202 - FP: 99.7800 - FN: 145.0600 - val_loss: 0.0790 - val_Accuracy: 0.9775 - val_Precision: 0.9626 - val_Recall: 0.9478 - val_TP: 762.0600 - val_TN: 1082.7900 - val_FP: 23.2100 - val_FN: 41.9400\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0397 - Accuracy: 0.9861 - Precision: 0.9624 - Recall: 0.9580 - TP: 3230.3101 - TN: 5544.3701 - FP: 102.6300 - FN: 141.6900 - val_loss: 0.0806 - val_Accuracy: 0.9764 - val_Precision: 0.9617 - val_Recall: 0.9475 - val_TP: 761.7500 - val_TN: 1081.9800 - val_FP: 24.0200 - val_FN: 42.2500\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0394 - Accuracy: 0.9860 - Precision: 0.9632 - Recall: 0.9574 - TP: 3228.3101 - TN: 5547.4702 - FP: 99.5300 - FN: 143.6900 - val_loss: 0.0805 - val_Accuracy: 0.9754 - val_Precision: 0.9603 - val_Recall: 0.9481 - val_TP: 762.2700 - val_TN: 1080.6100 - val_FP: 25.3900 - val_FN: 41.7300\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0402 - Accuracy: 0.9855 - Precision: 0.9621 - Recall: 0.9579 - TP: 3230.0500 - TN: 5543.2900 - FP: 103.7100 - FN: 141.9500 - val_loss: 0.0805 - val_Accuracy: 0.9759 - val_Precision: 0.9624 - val_Recall: 0.9471 - val_TP: 761.4400 - val_TN: 1082.5699 - val_FP: 23.4300 - val_FN: 42.5600\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 4ms/step - loss: 0.0411 - Accuracy: 0.9863 - Precision: 0.9632 - Recall: 0.9565 - TP: 3225.3401 - TN: 5547.2900 - FP: 99.7100 - FN: 146.6600 - val_loss: 0.0787 - val_Accuracy: 0.9775 - val_Precision: 0.9635 - val_Recall: 0.9468 - val_TP: 761.2100 - val_TN: 1083.5699 - val_FP: 22.4300 - val_FN: 42.7900\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0410 - Accuracy: 0.9860 - Precision: 0.9624 - Recall: 0.9572 - TP: 3227.7800 - TN: 5544.3198 - FP: 102.6800 - FN: 144.2200 - val_loss: 0.0779 - val_Accuracy: 0.9764 - val_Precision: 0.9639 - val_Recall: 0.9472 - val_TP: 761.5500 - val_TN: 1083.9000 - val_FP: 22.1000 - val_FN: 42.4500\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0409 - Accuracy: 0.9857 - Precision: 0.9628 - Recall: 0.9568 - TP: 3226.3101 - TN: 5545.8501 - FP: 101.1500 - FN: 145.6900 - val_loss: 0.0788 - val_Accuracy: 0.9775 - val_Precision: 0.9620 - val_Recall: 0.9477 - val_TP: 761.9400 - val_TN: 1082.2300 - val_FP: 23.7700 - val_FN: 42.0600\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0403 - Accuracy: 0.9860 - Precision: 0.9625 - Recall: 0.9574 - TP: 3228.3000 - TN: 5544.5400 - FP: 102.4600 - FN: 143.7000 - val_loss: 0.0802 - val_Accuracy: 0.9764 - val_Precision: 0.9615 - val_Recall: 0.9470 - val_TP: 761.3900 - val_TN: 1081.6000 - val_FP: 24.4000 - val_FN: 42.6100\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0402 - Accuracy: 0.9856 - Precision: 0.9621 - Recall: 0.9572 - TP: 3227.8301 - TN: 5542.7598 - FP: 104.2400 - FN: 144.1700 - val_loss: 0.0792 - val_Accuracy: 0.9775 - val_Precision: 0.9629 - val_Recall: 0.9470 - val_TP: 761.3700 - val_TN: 1083.0601 - val_FP: 22.9400 - val_FN: 42.6300\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0408 - Accuracy: 0.9855 - Precision: 0.9635 - Recall: 0.9562 - TP: 3224.1499 - TN: 5548.3999 - FP: 98.6000 - FN: 147.8500 - val_loss: 0.0783 - val_Accuracy: 0.9770 - val_Precision: 0.9620 - val_Recall: 0.9481 - val_TP: 762.2800 - val_TN: 1082.2200 - val_FP: 23.7800 - val_FN: 41.7200\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0400 - Accuracy: 0.9865 - Precision: 0.9622 - Recall: 0.9579 - TP: 3230.0100 - TN: 5543.2002 - FP: 103.8000 - FN: 141.9900 - val_loss: 0.0794 - val_Accuracy: 0.9764 - val_Precision: 0.9612 - val_Recall: 0.9479 - val_TP: 762.1300 - val_TN: 1081.5300 - val_FP: 24.4700 - val_FN: 41.8700\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0408 - Accuracy: 0.9858 - Precision: 0.9624 - Recall: 0.9573 - TP: 3228.0100 - TN: 5544.3501 - FP: 102.6500 - FN: 143.9900 - val_loss: 0.0790 - val_Accuracy: 0.9770 - val_Precision: 0.9627 - val_Recall: 0.9473 - val_TP: 761.6600 - val_TN: 1082.8300 - val_FP: 23.1700 - val_FN: 42.3400\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0401 - Accuracy: 0.9858 - Precision: 0.9625 - Recall: 0.9576 - TP: 3228.8601 - TN: 5544.7300 - FP: 102.2700 - FN: 143.1400 - val_loss: 0.0789 - val_Accuracy: 0.9780 - val_Precision: 0.9626 - val_Recall: 0.9476 - val_TP: 761.8700 - val_TN: 1082.7300 - val_FP: 23.2700 - val_FN: 42.1300\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0397 - Accuracy: 0.9860 - Precision: 0.9625 - Recall: 0.9574 - TP: 3228.3000 - TN: 5544.8999 - FP: 102.1000 - FN: 143.7000 - val_loss: 0.0793 - val_Accuracy: 0.9775 - val_Precision: 0.9632 - val_Recall: 0.9470 - val_TP: 761.3500 - val_TN: 1083.3300 - val_FP: 22.6700 - val_FN: 42.6500\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0398 - Accuracy: 0.9859 - Precision: 0.9630 - Recall: 0.9570 - TP: 3227.1499 - TN: 5546.2500 - FP: 100.7500 - FN: 144.8500 - val_loss: 0.0812 - val_Accuracy: 0.9759 - val_Precision: 0.9601 - val_Recall: 0.9473 - val_TP: 761.6000 - val_TN: 1080.3000 - val_FP: 25.7000 - val_FN: 42.4000\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0398 - Accuracy: 0.9863 - Precision: 0.9632 - Recall: 0.9576 - TP: 3229.0100 - TN: 5546.9800 - FP: 100.0200 - FN: 142.9900 - val_loss: 0.0811 - val_Accuracy: 0.9759 - val_Precision: 0.9602 - val_Recall: 0.9476 - val_TP: 761.8800 - val_TN: 1080.5100 - val_FP: 25.4900 - val_FN: 42.1200\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0404 - Accuracy: 0.9861 - Precision: 0.9622 - Recall: 0.9577 - TP: 3229.4900 - TN: 5543.6499 - FP: 103.3500 - FN: 142.5100 - val_loss: 0.0852 - val_Accuracy: 0.9749 - val_Precision: 0.9541 - val_Recall: 0.9479 - val_TP: 762.1500 - val_TN: 1074.5601 - val_FP: 31.4400 - val_FN: 41.8500\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0410 - Accuracy: 0.9860 - Precision: 0.9625 - Recall: 0.9572 - TP: 3227.5500 - TN: 5544.4199 - FP: 102.5800 - FN: 144.4500 - val_loss: 0.0795 - val_Accuracy: 0.9770 - val_Precision: 0.9625 - val_Recall: 0.9474 - val_TP: 761.7300 - val_TN: 1082.6700 - val_FP: 23.3300 - val_FN: 42.2700\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0399 - Accuracy: 0.9860 - Precision: 0.9628 - Recall: 0.9577 - TP: 3229.4900 - TN: 5545.8799 - FP: 101.1200 - FN: 142.5100 - val_loss: 0.0806 - val_Accuracy: 0.9764 - val_Precision: 0.9623 - val_Recall: 0.9468 - val_TP: 761.2600 - val_TN: 1082.5601 - val_FP: 23.4400 - val_FN: 42.7400\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0398 - Accuracy: 0.9859 - Precision: 0.9635 - Recall: 0.9573 - TP: 3228.0901 - TN: 5548.4102 - FP: 98.5900 - FN: 143.9100 - val_loss: 0.0794 - val_Accuracy: 0.9775 - val_Precision: 0.9620 - val_Recall: 0.9478 - val_TP: 762.0500 - val_TN: 1082.2600 - val_FP: 23.7400 - val_FN: 41.9500\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0400 - Accuracy: 0.9863 - Precision: 0.9626 - Recall: 0.9576 - TP: 3228.9500 - TN: 5545.0698 - FP: 101.9300 - FN: 143.0500 - val_loss: 0.0806 - val_Accuracy: 0.9759 - val_Precision: 0.9617 - val_Recall: 0.9472 - val_TP: 761.5200 - val_TN: 1081.8199 - val_FP: 24.1800 - val_FN: 42.4800\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0398 - Accuracy: 0.9861 - Precision: 0.9622 - Recall: 0.9580 - TP: 3230.4199 - TN: 5543.3501 - FP: 103.6500 - FN: 141.5800 - val_loss: 0.0792 - val_Accuracy: 0.9775 - val_Precision: 0.9641 - val_Recall: 0.9468 - val_TP: 761.2300 - val_TN: 1084.1700 - val_FP: 21.8300 - val_FN: 42.7700\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0404 - Accuracy: 0.9863 - Precision: 0.9630 - Recall: 0.9575 - TP: 3228.7500 - TN: 5546.9800 - FP: 100.0200 - FN: 143.2500 - val_loss: 0.0792 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9474 - val_TP: 761.7300 - val_TN: 1083.4399 - val_FP: 22.5600 - val_FN: 42.2700\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0401 - Accuracy: 0.9860 - Precision: 0.9634 - Recall: 0.9570 - TP: 3226.9500 - TN: 5547.9302 - FP: 99.0700 - FN: 145.0500 - val_loss: 0.0807 - val_Accuracy: 0.9754 - val_Precision: 0.9606 - val_Recall: 0.9478 - val_TP: 762.0200 - val_TN: 1080.8800 - val_FP: 25.1200 - val_FN: 41.9800\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0398 - Accuracy: 0.9864 - Precision: 0.9619 - Recall: 0.9579 - TP: 3230.0000 - TN: 5542.4800 - FP: 104.5200 - FN: 142.0000 - val_loss: 0.0790 - val_Accuracy: 0.9770 - val_Precision: 0.9645 - val_Recall: 0.9470 - val_TP: 761.4000 - val_TN: 1084.5100 - val_FP: 21.4900 - val_FN: 42.6000\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0407 - Accuracy: 0.9860 - Precision: 0.9635 - Recall: 0.9577 - TP: 3229.3601 - TN: 5548.7598 - FP: 98.2400 - FN: 142.6400 - val_loss: 0.0794 - val_Accuracy: 0.9770 - val_Precision: 0.9622 - val_Recall: 0.9480 - val_TP: 762.1800 - val_TN: 1082.4800 - val_FP: 23.5200 - val_FN: 41.8200\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0405 - Accuracy: 0.9858 - Precision: 0.9631 - Recall: 0.9571 - TP: 3227.2900 - TN: 5546.9702 - FP: 100.0300 - FN: 144.7100 - val_loss: 0.0796 - val_Accuracy: 0.9764 - val_Precision: 0.9615 - val_Recall: 0.9474 - val_TP: 761.6900 - val_TN: 1081.6600 - val_FP: 24.3400 - val_FN: 42.3100\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0411 - Accuracy: 0.9856 - Precision: 0.9623 - Recall: 0.9569 - TP: 3226.6599 - TN: 5543.8101 - FP: 103.1900 - FN: 145.3400 - val_loss: 0.0791 - val_Accuracy: 0.9754 - val_Precision: 0.9607 - val_Recall: 0.9484 - val_TP: 762.5100 - val_TN: 1081.0200 - val_FP: 24.9800 - val_FN: 41.4900\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0402 - Accuracy: 0.9863 - Precision: 0.9624 - Recall: 0.9574 - TP: 3228.2400 - TN: 5543.8398 - FP: 103.1600 - FN: 143.7600 - val_loss: 0.0790 - val_Accuracy: 0.9770 - val_Precision: 0.9627 - val_Recall: 0.9472 - val_TP: 761.5100 - val_TN: 1082.8700 - val_FP: 23.1300 - val_FN: 42.4900\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0406 - Accuracy: 0.9863 - Precision: 0.9621 - Recall: 0.9577 - TP: 3229.4299 - TN: 5543.0601 - FP: 103.9400 - FN: 142.5700 - val_loss: 0.0799 - val_Accuracy: 0.9754 - val_Precision: 0.9621 - val_Recall: 0.9471 - val_TP: 761.4800 - val_TN: 1082.3500 - val_FP: 23.6500 - val_FN: 42.5200\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0402 - Accuracy: 0.9861 - Precision: 0.9634 - Recall: 0.9567 - TP: 3225.9500 - TN: 5548.0000 - FP: 99.0000 - FN: 146.0500 - val_loss: 0.0795 - val_Accuracy: 0.9764 - val_Precision: 0.9618 - val_Recall: 0.9476 - val_TP: 761.8700 - val_TN: 1082.0400 - val_FP: 23.9600 - val_FN: 42.1300\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0401 - Accuracy: 0.9858 - Precision: 0.9622 - Recall: 0.9575 - TP: 3228.8201 - TN: 5543.1201 - FP: 103.8800 - FN: 143.1800 - val_loss: 0.0790 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9471 - val_TP: 761.4300 - val_TN: 1083.3101 - val_FP: 22.6900 - val_FN: 42.5700\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0408 - Accuracy: 0.9860 - Precision: 0.9621 - Recall: 0.9571 - TP: 3227.3999 - TN: 5543.2402 - FP: 103.7600 - FN: 144.6000 - val_loss: 0.0793 - val_Accuracy: 0.9775 - val_Precision: 0.9630 - val_Recall: 0.9470 - val_TP: 761.3600 - val_TN: 1083.1700 - val_FP: 22.8300 - val_FN: 42.6400\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0394 - Accuracy: 0.9861 - Precision: 0.9629 - Recall: 0.9575 - TP: 3228.5901 - TN: 5546.2402 - FP: 100.7600 - FN: 143.4100 - val_loss: 0.0787 - val_Accuracy: 0.9775 - val_Precision: 0.9642 - val_Recall: 0.9469 - val_TP: 761.2700 - val_TN: 1084.2400 - val_FP: 21.7600 - val_FN: 42.7300\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0399 - Accuracy: 0.9863 - Precision: 0.9632 - Recall: 0.9573 - TP: 3227.9299 - TN: 5547.5801 - FP: 99.4200 - FN: 144.0700 - val_loss: 0.0789 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9472 - val_TP: 761.5600 - val_TN: 1083.4301 - val_FP: 22.5700 - val_FN: 42.4400\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0395 - Accuracy: 0.9867 - Precision: 0.9625 - Recall: 0.9580 - TP: 3230.3899 - TN: 5544.5400 - FP: 102.4600 - FN: 141.6100 - val_loss: 0.0800 - val_Accuracy: 0.9764 - val_Precision: 0.9630 - val_Recall: 0.9468 - val_TP: 761.2500 - val_TN: 1083.1100 - val_FP: 22.8900 - val_FN: 42.7500\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0403 - Accuracy: 0.9861 - Precision: 0.9633 - Recall: 0.9574 - TP: 3228.2100 - TN: 5547.6699 - FP: 99.3300 - FN: 143.7900 - val_loss: 0.0794 - val_Accuracy: 0.9764 - val_Precision: 0.9619 - val_Recall: 0.9478 - val_TP: 762.0600 - val_TN: 1082.1899 - val_FP: 23.8100 - val_FN: 41.9400\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0397 - Accuracy: 0.9863 - Precision: 0.9625 - Recall: 0.9574 - TP: 3228.4900 - TN: 5544.3701 - FP: 102.6300 - FN: 143.5100 - val_loss: 0.0809 - val_Accuracy: 0.9754 - val_Precision: 0.9612 - val_Recall: 0.9473 - val_TP: 761.5900 - val_TN: 1081.3500 - val_FP: 24.6500 - val_FN: 42.4100\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0399 - Accuracy: 0.9856 - Precision: 0.9627 - Recall: 0.9575 - TP: 3228.6899 - TN: 5545.1602 - FP: 101.8400 - FN: 143.3100 - val_loss: 0.0796 - val_Accuracy: 0.9770 - val_Precision: 0.9630 - val_Recall: 0.9472 - val_TP: 761.5300 - val_TN: 1083.1801 - val_FP: 22.8200 - val_FN: 42.4700\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0401 - Accuracy: 0.9861 - Precision: 0.9626 - Recall: 0.9574 - TP: 3228.3799 - TN: 5545.4102 - FP: 101.5900 - FN: 143.6200 - val_loss: 0.0807 - val_Accuracy: 0.9759 - val_Precision: 0.9620 - val_Recall: 0.9471 - val_TP: 761.5000 - val_TN: 1082.2500 - val_FP: 23.7500 - val_FN: 42.5000\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0402 - Accuracy: 0.9861 - Precision: 0.9630 - Recall: 0.9574 - TP: 3228.4600 - TN: 5546.2998 - FP: 100.7000 - FN: 143.5400 - val_loss: 0.0797 - val_Accuracy: 0.9775 - val_Precision: 0.9625 - val_Recall: 0.9475 - val_TP: 761.7700 - val_TN: 1082.7200 - val_FP: 23.2800 - val_FN: 42.2300\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0391 - Accuracy: 0.9864 - Precision: 0.9630 - Recall: 0.9580 - TP: 3230.2600 - TN: 5546.3701 - FP: 100.6300 - FN: 141.7400 - val_loss: 0.0798 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9471 - val_TP: 761.4600 - val_TN: 1083.3500 - val_FP: 22.6500 - val_FN: 42.5400\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0398 - Accuracy: 0.9860 - Precision: 0.9629 - Recall: 0.9575 - TP: 3228.8201 - TN: 5546.3799 - FP: 100.6200 - FN: 143.1800 - val_loss: 0.0801 - val_Accuracy: 0.9759 - val_Precision: 0.9615 - val_Recall: 0.9480 - val_TP: 762.2100 - val_TN: 1081.8199 - val_FP: 24.1800 - val_FN: 41.7900\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0401 - Accuracy: 0.9858 - Precision: 0.9627 - Recall: 0.9577 - TP: 3229.2400 - TN: 5545.4600 - FP: 101.5400 - FN: 142.7600 - val_loss: 0.0799 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9471 - val_TP: 761.4400 - val_TN: 1083.3101 - val_FP: 22.6900 - val_FN: 42.5600\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0394 - Accuracy: 0.9868 - Precision: 0.9630 - Recall: 0.9581 - TP: 3230.7300 - TN: 5546.5498 - FP: 100.4500 - FN: 141.2700 - val_loss: 0.0808 - val_Accuracy: 0.9759 - val_Precision: 0.9625 - val_Recall: 0.9470 - val_TP: 761.3500 - val_TN: 1082.7300 - val_FP: 23.2700 - val_FN: 42.6500\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0413 - Accuracy: 0.9858 - Precision: 0.9625 - Recall: 0.9573 - TP: 3228.0701 - TN: 5545.0898 - FP: 101.9100 - FN: 143.9300 - val_loss: 0.0805 - val_Accuracy: 0.9759 - val_Precision: 0.9622 - val_Recall: 0.9473 - val_TP: 761.6400 - val_TN: 1082.4200 - val_FP: 23.5800 - val_FN: 42.3600\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0394 - Accuracy: 0.9860 - Precision: 0.9633 - Recall: 0.9575 - TP: 3228.8301 - TN: 5547.5498 - FP: 99.4500 - FN: 143.1700 - val_loss: 0.0806 - val_Accuracy: 0.9754 - val_Precision: 0.9618 - val_Recall: 0.9475 - val_TP: 761.8200 - val_TN: 1082.1400 - val_FP: 23.8600 - val_FN: 42.1800\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0396 - Accuracy: 0.9857 - Precision: 0.9628 - Recall: 0.9577 - TP: 3229.4800 - TN: 5546.1499 - FP: 100.8500 - FN: 142.5200 - val_loss: 0.0793 - val_Accuracy: 0.9770 - val_Precision: 0.9641 - val_Recall: 0.9472 - val_TP: 761.5200 - val_TN: 1084.1899 - val_FP: 21.8100 - val_FN: 42.4800\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0392 - Accuracy: 0.9861 - Precision: 0.9631 - Recall: 0.9579 - TP: 3229.9900 - TN: 5546.9302 - FP: 100.0700 - FN: 142.0100 - val_loss: 0.0792 - val_Accuracy: 0.9764 - val_Precision: 0.9622 - val_Recall: 0.9484 - val_TP: 762.5300 - val_TN: 1082.4600 - val_FP: 23.5400 - val_FN: 41.4700\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0408 - Accuracy: 0.9857 - Precision: 0.9621 - Recall: 0.9576 - TP: 3228.8799 - TN: 5543.4600 - FP: 103.5400 - FN: 143.1200 - val_loss: 0.0803 - val_Accuracy: 0.9754 - val_Precision: 0.9612 - val_Recall: 0.9483 - val_TP: 762.4000 - val_TN: 1081.5300 - val_FP: 24.4700 - val_FN: 41.6000\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0390 - Accuracy: 0.9864 - Precision: 0.9638 - Recall: 0.9577 - TP: 3229.2700 - TN: 5549.9199 - FP: 97.0800 - FN: 142.7300 - val_loss: 0.0799 - val_Accuracy: 0.9764 - val_Precision: 0.9616 - val_Recall: 0.9483 - val_TP: 762.4600 - val_TN: 1081.9100 - val_FP: 24.0900 - val_FN: 41.5400\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0388 - Accuracy: 0.9861 - Precision: 0.9628 - Recall: 0.9586 - TP: 3232.4700 - TN: 5545.7598 - FP: 101.2400 - FN: 139.5300 - val_loss: 0.0805 - val_Accuracy: 0.9754 - val_Precision: 0.9619 - val_Recall: 0.9478 - val_TP: 762.0400 - val_TN: 1082.2400 - val_FP: 23.7600 - val_FN: 41.9600\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0395 - Accuracy: 0.9861 - Precision: 0.9632 - Recall: 0.9578 - TP: 3229.6001 - TN: 5547.6699 - FP: 99.3300 - FN: 142.4000 - val_loss: 0.0798 - val_Accuracy: 0.9764 - val_Precision: 0.9622 - val_Recall: 0.9481 - val_TP: 762.3000 - val_TN: 1082.4700 - val_FP: 23.5300 - val_FN: 41.7000\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0397 - Accuracy: 0.9858 - Precision: 0.9628 - Recall: 0.9578 - TP: 3229.6799 - TN: 5546.1201 - FP: 100.8800 - FN: 142.3200 - val_loss: 0.0804 - val_Accuracy: 0.9754 - val_Precision: 0.9618 - val_Recall: 0.9480 - val_TP: 762.1900 - val_TN: 1082.1000 - val_FP: 23.9000 - val_FN: 41.8100\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 5ms/step - loss: 0.0408 - Accuracy: 0.9864 - Precision: 0.9630 - Recall: 0.9576 - TP: 3229.1201 - TN: 5546.9600 - FP: 100.0400 - FN: 142.8800 - val_loss: 0.0796 - val_Accuracy: 0.9759 - val_Precision: 0.9626 - val_Recall: 0.9472 - val_TP: 761.5100 - val_TN: 1082.8000 - val_FP: 23.2000 - val_FN: 42.4900\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0403 - Accuracy: 0.9858 - Precision: 0.9628 - Recall: 0.9575 - TP: 3228.7400 - TN: 5546.0498 - FP: 100.9500 - FN: 143.2600 - val_loss: 0.0789 - val_Accuracy: 0.9775 - val_Precision: 0.9642 - val_Recall: 0.9468 - val_TP: 761.2400 - val_TN: 1084.2500 - val_FP: 21.7500 - val_FN: 42.7600\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0397 - Accuracy: 0.9863 - Precision: 0.9630 - Recall: 0.9578 - TP: 3229.5901 - TN: 5546.8501 - FP: 100.1500 - FN: 142.4100 - val_loss: 0.0790 - val_Accuracy: 0.9775 - val_Precision: 0.9628 - val_Recall: 0.9476 - val_TP: 761.8600 - val_TN: 1083.0000 - val_FP: 23.0000 - val_FN: 42.1400\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0403 - Accuracy: 0.9863 - Precision: 0.9628 - Recall: 0.9576 - TP: 3229.1201 - TN: 5546.0801 - FP: 100.9200 - FN: 142.8800 - val_loss: 0.0791 - val_Accuracy: 0.9775 - val_Precision: 0.9631 - val_Recall: 0.9474 - val_TP: 761.6800 - val_TN: 1083.2800 - val_FP: 22.7200 - val_FN: 42.3200\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0402 - Accuracy: 0.9865 - Precision: 0.9625 - Recall: 0.9577 - TP: 3229.3401 - TN: 5544.7002 - FP: 102.3000 - FN: 142.6600 - val_loss: 0.0799 - val_Accuracy: 0.9770 - val_Precision: 0.9628 - val_Recall: 0.9470 - val_TP: 761.3500 - val_TN: 1083.0100 - val_FP: 22.9900 - val_FN: 42.6500\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0400 - Accuracy: 0.9864 - Precision: 0.9635 - Recall: 0.9571 - TP: 3227.3301 - TN: 5548.6499 - FP: 98.3500 - FN: 144.6700 - val_loss: 0.0800 - val_Accuracy: 0.9754 - val_Precision: 0.9603 - val_Recall: 0.9485 - val_TP: 762.6000 - val_TN: 1080.7000 - val_FP: 25.3000 - val_FN: 41.4000\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0400 - Accuracy: 0.9864 - Precision: 0.9619 - Recall: 0.9581 - TP: 3230.7500 - TN: 5542.2798 - FP: 104.7200 - FN: 141.2500 - val_loss: 0.0795 - val_Accuracy: 0.9775 - val_Precision: 0.9641 - val_Recall: 0.9468 - val_TP: 761.1900 - val_TN: 1084.1100 - val_FP: 21.8900 - val_FN: 42.8100\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0399 - Accuracy: 0.9860 - Precision: 0.9637 - Recall: 0.9572 - TP: 3227.5400 - TN: 5549.0801 - FP: 97.9200 - FN: 144.4600 - val_loss: 0.0789 - val_Accuracy: 0.9764 - val_Precision: 0.9622 - val_Recall: 0.9483 - val_TP: 762.4500 - val_TN: 1082.4700 - val_FP: 23.5300 - val_FN: 41.5500\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0400 - Accuracy: 0.9860 - Precision: 0.9628 - Recall: 0.9577 - TP: 3229.5300 - TN: 5546.0698 - FP: 100.9300 - FN: 142.4700 - val_loss: 0.0796 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9479 - val_TP: 762.0900 - val_TN: 1082.3400 - val_FP: 23.6600 - val_FN: 41.9100\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0399 - Accuracy: 0.9864 - Precision: 0.9627 - Recall: 0.9580 - TP: 3230.3899 - TN: 5545.4302 - FP: 101.5700 - FN: 141.6100 - val_loss: 0.0805 - val_Accuracy: 0.9759 - val_Precision: 0.9621 - val_Recall: 0.9473 - val_TP: 761.6300 - val_TN: 1082.3600 - val_FP: 23.6400 - val_FN: 42.3700\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0398 - Accuracy: 0.9863 - Precision: 0.9625 - Recall: 0.9577 - TP: 3229.2100 - TN: 5544.6299 - FP: 102.3700 - FN: 142.7900 - val_loss: 0.0789 - val_Accuracy: 0.9770 - val_Precision: 0.9643 - val_Recall: 0.9473 - val_TP: 761.6400 - val_TN: 1084.3600 - val_FP: 21.6400 - val_FN: 42.3600\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0401 - Accuracy: 0.9863 - Precision: 0.9636 - Recall: 0.9574 - TP: 3228.4299 - TN: 5548.9702 - FP: 98.0300 - FN: 143.5700 - val_loss: 0.0799 - val_Accuracy: 0.9754 - val_Precision: 0.9614 - val_Recall: 0.9483 - val_TP: 762.4100 - val_TN: 1081.7500 - val_FP: 24.2500 - val_FN: 41.5900\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0402 - Accuracy: 0.9860 - Precision: 0.9624 - Recall: 0.9574 - TP: 3228.3101 - TN: 5544.0498 - FP: 102.9500 - FN: 143.6900 - val_loss: 0.0813 - val_Accuracy: 0.9759 - val_Precision: 0.9614 - val_Recall: 0.9474 - val_TP: 761.7300 - val_TN: 1081.7500 - val_FP: 24.2500 - val_FN: 42.2700\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0415 - Accuracy: 0.9859 - Precision: 0.9626 - Recall: 0.9576 - TP: 3229.0400 - TN: 5545.2700 - FP: 101.7300 - FN: 142.9600 - val_loss: 0.0800 - val_Accuracy: 0.9770 - val_Precision: 0.9629 - val_Recall: 0.9473 - val_TP: 761.6100 - val_TN: 1083.0400 - val_FP: 22.9600 - val_FN: 42.3900\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0390 - Accuracy: 0.9863 - Precision: 0.9627 - Recall: 0.9579 - TP: 3229.8999 - TN: 5545.2402 - FP: 101.7600 - FN: 142.1000 - val_loss: 0.0812 - val_Accuracy: 0.9754 - val_Precision: 0.9615 - val_Recall: 0.9475 - val_TP: 761.7600 - val_TN: 1081.8600 - val_FP: 24.1400 - val_FN: 42.2400\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0391 - Accuracy: 0.9861 - Precision: 0.9631 - Recall: 0.9581 - TP: 3230.5801 - TN: 5547.0298 - FP: 99.9700 - FN: 141.4200 - val_loss: 0.0795 - val_Accuracy: 0.9770 - val_Precision: 0.9635 - val_Recall: 0.9475 - val_TP: 761.7800 - val_TN: 1083.6600 - val_FP: 22.3400 - val_FN: 42.2200\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0391 - Accuracy: 0.9861 - Precision: 0.9631 - Recall: 0.9576 - TP: 3228.8899 - TN: 5547.1899 - FP: 99.8100 - FN: 143.1100 - val_loss: 0.0799 - val_Accuracy: 0.9764 - val_Precision: 0.9619 - val_Recall: 0.9482 - val_TP: 762.3400 - val_TN: 1082.2100 - val_FP: 23.7900 - val_FN: 41.6600\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0396 - Accuracy: 0.9863 - Precision: 0.9627 - Recall: 0.9585 - TP: 3231.9600 - TN: 5545.4800 - FP: 101.5200 - FN: 140.0400 - val_loss: 0.0818 - val_Accuracy: 0.9759 - val_Precision: 0.9625 - val_Recall: 0.9466 - val_TP: 761.0600 - val_TN: 1082.7800 - val_FP: 23.2200 - val_FN: 42.9400\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0395 - Accuracy: 0.9867 - Precision: 0.9635 - Recall: 0.9581 - TP: 3230.5901 - TN: 5548.7402 - FP: 98.2600 - FN: 141.4100 - val_loss: 0.0806 - val_Accuracy: 0.9759 - val_Precision: 0.9628 - val_Recall: 0.9473 - val_TP: 761.6000 - val_TN: 1083.0400 - val_FP: 22.9600 - val_FN: 42.4000\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0391 - Accuracy: 0.9864 - Precision: 0.9628 - Recall: 0.9584 - TP: 3231.6699 - TN: 5545.8999 - FP: 101.1000 - FN: 140.3300 - val_loss: 0.0806 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9471 - val_TP: 761.4300 - val_TN: 1083.3700 - val_FP: 22.6300 - val_FN: 42.5700\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0387 - Accuracy: 0.9866 - Precision: 0.9636 - Recall: 0.9577 - TP: 3229.4199 - TN: 5549.2700 - FP: 97.7300 - FN: 142.5800 - val_loss: 0.0794 - val_Accuracy: 0.9780 - val_Precision: 0.9633 - val_Recall: 0.9479 - val_TP: 762.1200 - val_TN: 1083.4100 - val_FP: 22.5900 - val_FN: 41.8800\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0390 - Accuracy: 0.9863 - Precision: 0.9632 - Recall: 0.9581 - TP: 3230.6699 - TN: 5547.3599 - FP: 99.6400 - FN: 141.3300 - val_loss: 0.0914 - val_Accuracy: 0.9743 - val_Precision: 0.9478 - val_Recall: 0.9478 - val_TP: 762.0200 - val_TN: 1068.8300 - val_FP: 37.1700 - val_FN: 41.9800\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0411 - Accuracy: 0.9867 - Precision: 0.9626 - Recall: 0.9583 - TP: 3231.2400 - TN: 5545.2402 - FP: 101.7600 - FN: 140.7600 - val_loss: 0.0811 - val_Accuracy: 0.9759 - val_Precision: 0.9616 - val_Recall: 0.9479 - val_TP: 762.0800 - val_TN: 1081.9399 - val_FP: 24.0600 - val_FN: 41.9200\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0395 - Accuracy: 0.9860 - Precision: 0.9631 - Recall: 0.9580 - TP: 3230.2300 - TN: 5547.1802 - FP: 99.8200 - FN: 141.7700 - val_loss: 0.0815 - val_Accuracy: 0.9759 - val_Precision: 0.9621 - val_Recall: 0.9474 - val_TP: 761.6900 - val_TN: 1082.4600 - val_FP: 23.5400 - val_FN: 42.3100\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0395 - Accuracy: 0.9864 - Precision: 0.9640 - Recall: 0.9579 - TP: 3229.8799 - TN: 5550.3501 - FP: 96.6500 - FN: 142.1200 - val_loss: 0.0799 - val_Accuracy: 0.9775 - val_Precision: 0.9634 - val_Recall: 0.9477 - val_TP: 761.9700 - val_TN: 1083.5100 - val_FP: 22.4900 - val_FN: 42.0300\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0392 - Accuracy: 0.9865 - Precision: 0.9633 - Recall: 0.9582 - TP: 3231.1399 - TN: 5547.9502 - FP: 99.0500 - FN: 140.8600 - val_loss: 0.0824 - val_Accuracy: 0.9754 - val_Precision: 0.9594 - val_Recall: 0.9484 - val_TP: 762.4900 - val_TN: 1079.8500 - val_FP: 26.1500 - val_FN: 41.5100\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0387 - Accuracy: 0.9864 - Precision: 0.9631 - Recall: 0.9588 - TP: 3233.0400 - TN: 5547.1099 - FP: 99.8900 - FN: 138.9600 - val_loss: 0.0804 - val_Accuracy: 0.9770 - val_Precision: 0.9642 - val_Recall: 0.9471 - val_TP: 761.4600 - val_TN: 1084.2400 - val_FP: 21.7600 - val_FN: 42.5400\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0386 - Accuracy: 0.9865 - Precision: 0.9637 - Recall: 0.9586 - TP: 3232.3601 - TN: 5549.3398 - FP: 97.6600 - FN: 139.6400 - val_loss: 0.0819 - val_Accuracy: 0.9759 - val_Precision: 0.9623 - val_Recall: 0.9471 - val_TP: 761.4900 - val_TN: 1082.6200 - val_FP: 23.3800 - val_FN: 42.5100\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 5ms/step - loss: 0.0411 - Accuracy: 0.9861 - Precision: 0.9622 - Recall: 0.9580 - TP: 3230.3601 - TN: 5544.0400 - FP: 102.9600 - FN: 141.6400 - val_loss: 0.0799 - val_Accuracy: 0.9764 - val_Precision: 0.9630 - val_Recall: 0.9473 - val_TP: 761.6600 - val_TN: 1083.2000 - val_FP: 22.8000 - val_FN: 42.3400\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0400 - Accuracy: 0.9860 - Precision: 0.9630 - Recall: 0.9571 - TP: 3227.2500 - TN: 5546.8599 - FP: 100.1400 - FN: 144.7500 - val_loss: 0.0797 - val_Accuracy: 0.9770 - val_Precision: 0.9623 - val_Recall: 0.9478 - val_TP: 762.0600 - val_TN: 1082.5400 - val_FP: 23.4600 - val_FN: 41.9400\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0394 - Accuracy: 0.9863 - Precision: 0.9630 - Recall: 0.9579 - TP: 3230.0400 - TN: 5546.5000 - FP: 100.5000 - FN: 141.9600 - val_loss: 0.0803 - val_Accuracy: 0.9754 - val_Precision: 0.9618 - val_Recall: 0.9476 - val_TP: 761.8700 - val_TN: 1082.0800 - val_FP: 23.9200 - val_FN: 42.1300\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0402 - Accuracy: 0.9864 - Precision: 0.9625 - Recall: 0.9581 - TP: 3230.7100 - TN: 5544.8999 - FP: 102.1000 - FN: 141.2900 - val_loss: 0.0797 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9472 - val_TP: 761.5700 - val_TN: 1083.3900 - val_FP: 22.6100 - val_FN: 42.4300\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0394 - Accuracy: 0.9869 - Precision: 0.9634 - Recall: 0.9578 - TP: 3229.8401 - TN: 5548.4502 - FP: 98.5500 - FN: 142.1600 - val_loss: 0.0808 - val_Accuracy: 0.9754 - val_Precision: 0.9613 - val_Recall: 0.9479 - val_TP: 762.1000 - val_TN: 1081.6500 - val_FP: 24.3500 - val_FN: 41.9000\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0395 - Accuracy: 0.9863 - Precision: 0.9636 - Recall: 0.9576 - TP: 3228.8799 - TN: 5548.9102 - FP: 98.0900 - FN: 143.1200 - val_loss: 0.0817 - val_Accuracy: 0.9754 - val_Precision: 0.9596 - val_Recall: 0.9481 - val_TP: 762.2600 - val_TN: 1079.8600 - val_FP: 26.1400 - val_FN: 41.7400\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0400 - Accuracy: 0.9863 - Precision: 0.9626 - Recall: 0.9581 - TP: 3230.7600 - TN: 5545.1802 - FP: 101.8200 - FN: 141.2400 - val_loss: 0.0824 - val_Accuracy: 0.9754 - val_Precision: 0.9592 - val_Recall: 0.9479 - val_TP: 762.1000 - val_TN: 1079.5100 - val_FP: 26.4900 - val_FN: 41.9000\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0394 - Accuracy: 0.9859 - Precision: 0.9628 - Recall: 0.9576 - TP: 3229.0400 - TN: 5546.2402 - FP: 100.7600 - FN: 142.9600 - val_loss: 0.0845 - val_Accuracy: 0.9749 - val_Precision: 0.9571 - val_Recall: 0.9475 - val_TP: 761.8000 - val_TN: 1077.4500 - val_FP: 28.5500 - val_FN: 42.2000\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0392 - Accuracy: 0.9865 - Precision: 0.9629 - Recall: 0.9584 - TP: 3231.8899 - TN: 5546.5200 - FP: 100.4800 - FN: 140.1100 - val_loss: 0.0806 - val_Accuracy: 0.9775 - val_Precision: 0.9633 - val_Recall: 0.9468 - val_TP: 761.2600 - val_TN: 1083.5000 - val_FP: 22.5000 - val_FN: 42.7400\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0391 - Accuracy: 0.9860 - Precision: 0.9636 - Recall: 0.9576 - TP: 3229.0400 - TN: 5548.8599 - FP: 98.1400 - FN: 142.9600 - val_loss: 0.0800 - val_Accuracy: 0.9770 - val_Precision: 0.9634 - val_Recall: 0.9473 - val_TP: 761.6000 - val_TN: 1083.5699 - val_FP: 22.4300 - val_FN: 42.4000\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0392 - Accuracy: 0.9865 - Precision: 0.9634 - Recall: 0.9584 - TP: 3231.7600 - TN: 5548.1299 - FP: 98.8700 - FN: 140.2400 - val_loss: 0.0832 - val_Accuracy: 0.9759 - val_Precision: 0.9582 - val_Recall: 0.9481 - val_TP: 762.2600 - val_TN: 1078.5400 - val_FP: 27.4600 - val_FN: 41.7400\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0399 - Accuracy: 0.9858 - Precision: 0.9627 - Recall: 0.9577 - TP: 3229.3301 - TN: 5545.5698 - FP: 101.4300 - FN: 142.6700 - val_loss: 0.0803 - val_Accuracy: 0.9764 - val_Precision: 0.9625 - val_Recall: 0.9477 - val_TP: 761.9400 - val_TN: 1082.7300 - val_FP: 23.2700 - val_FN: 42.0600\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0392 - Accuracy: 0.9861 - Precision: 0.9632 - Recall: 0.9581 - TP: 3230.8201 - TN: 5547.2002 - FP: 99.8000 - FN: 141.1800 - val_loss: 0.0807 - val_Accuracy: 0.9754 - val_Precision: 0.9621 - val_Recall: 0.9476 - val_TP: 761.8900 - val_TN: 1082.4100 - val_FP: 23.5900 - val_FN: 42.1100\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0392 - Accuracy: 0.9866 - Precision: 0.9634 - Recall: 0.9582 - TP: 3231.0200 - TN: 5548.2900 - FP: 98.7100 - FN: 140.9800 - val_loss: 0.0799 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9475 - val_TP: 761.8200 - val_TN: 1083.4399 - val_FP: 22.5600 - val_FN: 42.1800\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0406 - Accuracy: 0.9855 - Precision: 0.9626 - Recall: 0.9575 - TP: 3228.7700 - TN: 5545.5200 - FP: 101.4800 - FN: 143.2300 - val_loss: 0.0802 - val_Accuracy: 0.9764 - val_Precision: 0.9623 - val_Recall: 0.9480 - val_TP: 762.2200 - val_TN: 1082.5800 - val_FP: 23.4200 - val_FN: 41.7800\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0393 - Accuracy: 0.9863 - Precision: 0.9634 - Recall: 0.9584 - TP: 3231.6499 - TN: 5548.4702 - FP: 98.5300 - FN: 140.3500 - val_loss: 0.0828 - val_Accuracy: 0.9754 - val_Precision: 0.9590 - val_Recall: 0.9482 - val_TP: 762.3500 - val_TN: 1079.3700 - val_FP: 26.6300 - val_FN: 41.6500\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0414 - Accuracy: 0.9857 - Precision: 0.9623 - Recall: 0.9579 - TP: 3229.9700 - TN: 5544.2402 - FP: 102.7600 - FN: 142.0300 - val_loss: 0.0814 - val_Accuracy: 0.9764 - val_Precision: 0.9623 - val_Recall: 0.9472 - val_TP: 761.5800 - val_TN: 1082.5200 - val_FP: 23.4800 - val_FN: 42.4200\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0392 - Accuracy: 0.9864 - Precision: 0.9635 - Recall: 0.9584 - TP: 3231.6899 - TN: 5548.3101 - FP: 98.6900 - FN: 140.3100 - val_loss: 0.0803 - val_Accuracy: 0.9770 - val_Precision: 0.9627 - val_Recall: 0.9478 - val_TP: 762.0300 - val_TN: 1082.9600 - val_FP: 23.0400 - val_FN: 41.9700\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0391 - Accuracy: 0.9864 - Precision: 0.9636 - Recall: 0.9583 - TP: 3231.4099 - TN: 5548.9600 - FP: 98.0400 - FN: 140.5900 - val_loss: 0.0816 - val_Accuracy: 0.9754 - val_Precision: 0.9618 - val_Recall: 0.9476 - val_TP: 761.8900 - val_TN: 1082.1801 - val_FP: 23.8200 - val_FN: 42.1100\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0388 - Accuracy: 0.9864 - Precision: 0.9640 - Recall: 0.9586 - TP: 3232.4900 - TN: 5550.7598 - FP: 96.2400 - FN: 139.5100 - val_loss: 0.0800 - val_Accuracy: 0.9770 - val_Precision: 0.9630 - val_Recall: 0.9480 - val_TP: 762.1900 - val_TN: 1083.2400 - val_FP: 22.7600 - val_FN: 41.8100\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0391 - Accuracy: 0.9863 - Precision: 0.9635 - Recall: 0.9582 - TP: 3231.0000 - TN: 5548.4302 - FP: 98.5700 - FN: 141.0000 - val_loss: 0.0803 - val_Accuracy: 0.9770 - val_Precision: 0.9621 - val_Recall: 0.9483 - val_TP: 762.4300 - val_TN: 1082.4399 - val_FP: 23.5600 - val_FN: 41.5700\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0390 - Accuracy: 0.9869 - Precision: 0.9634 - Recall: 0.9583 - TP: 3231.5500 - TN: 5548.0898 - FP: 98.9100 - FN: 140.4500 - val_loss: 0.0801 - val_Accuracy: 0.9764 - val_Precision: 0.9620 - val_Recall: 0.9487 - val_TP: 762.7200 - val_TN: 1082.3000 - val_FP: 23.7000 - val_FN: 41.2800\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 6ms/step - loss: 0.0404 - Accuracy: 0.9863 - Precision: 0.9629 - Recall: 0.9573 - TP: 3228.0601 - TN: 5546.4502 - FP: 100.5500 - FN: 143.9400 - val_loss: 0.0799 - val_Accuracy: 0.9775 - val_Precision: 0.9646 - val_Recall: 0.9465 - val_TP: 760.9800 - val_TN: 1084.6200 - val_FP: 21.3800 - val_FN: 43.0200\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0403 - Accuracy: 0.9860 - Precision: 0.9630 - Recall: 0.9572 - TP: 3227.6699 - TN: 5546.8101 - FP: 100.1900 - FN: 144.3300 - val_loss: 0.0801 - val_Accuracy: 0.9754 - val_Precision: 0.9611 - val_Recall: 0.9484 - val_TP: 762.5300 - val_TN: 1081.4399 - val_FP: 24.5600 - val_FN: 41.4700\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0402 - Accuracy: 0.9859 - Precision: 0.9626 - Recall: 0.9578 - TP: 3229.6899 - TN: 5545.1299 - FP: 101.8700 - FN: 142.3100 - val_loss: 0.0815 - val_Accuracy: 0.9754 - val_Precision: 0.9608 - val_Recall: 0.9474 - val_TP: 761.7400 - val_TN: 1081.0800 - val_FP: 24.9200 - val_FN: 42.2600\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0401 - Accuracy: 0.9865 - Precision: 0.9629 - Recall: 0.9578 - TP: 3229.8501 - TN: 5546.2202 - FP: 100.7800 - FN: 142.1500 - val_loss: 0.0801 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9471 - val_TP: 761.4900 - val_TN: 1083.4000 - val_FP: 22.6000 - val_FN: 42.5100\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0392 - Accuracy: 0.9868 - Precision: 0.9629 - Recall: 0.9582 - TP: 3231.0500 - TN: 5546.2500 - FP: 100.7500 - FN: 140.9500 - val_loss: 0.0807 - val_Accuracy: 0.9775 - val_Precision: 0.9639 - val_Recall: 0.9465 - val_TP: 761.0100 - val_TN: 1083.9700 - val_FP: 22.0300 - val_FN: 42.9900\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0394 - Accuracy: 0.9863 - Precision: 0.9635 - Recall: 0.9579 - TP: 3229.8899 - TN: 5548.8901 - FP: 98.1100 - FN: 142.1100 - val_loss: 0.0799 - val_Accuracy: 0.9770 - val_Precision: 0.9636 - val_Recall: 0.9472 - val_TP: 761.5400 - val_TN: 1083.7600 - val_FP: 22.2400 - val_FN: 42.4600\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0393 - Accuracy: 0.9869 - Precision: 0.9629 - Recall: 0.9580 - TP: 3230.2600 - TN: 5546.4800 - FP: 100.5200 - FN: 141.7400 - val_loss: 0.0805 - val_Accuracy: 0.9754 - val_Precision: 0.9623 - val_Recall: 0.9475 - val_TP: 761.8100 - val_TN: 1082.5900 - val_FP: 23.4100 - val_FN: 42.1900\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0396 - Accuracy: 0.9867 - Precision: 0.9633 - Recall: 0.9581 - TP: 3230.7200 - TN: 5547.9502 - FP: 99.0500 - FN: 141.2800 - val_loss: 0.0799 - val_Accuracy: 0.9764 - val_Precision: 0.9632 - val_Recall: 0.9475 - val_TP: 761.8000 - val_TN: 1083.3600 - val_FP: 22.6400 - val_FN: 42.2000\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0401 - Accuracy: 0.9861 - Precision: 0.9622 - Recall: 0.9578 - TP: 3229.8701 - TN: 5543.7500 - FP: 103.2500 - FN: 142.1300 - val_loss: 0.0806 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9469 - val_TP: 761.3200 - val_TN: 1083.5000 - val_FP: 22.5000 - val_FN: 42.6800\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0394 - Accuracy: 0.9860 - Precision: 0.9631 - Recall: 0.9582 - TP: 3231.0500 - TN: 5547.0200 - FP: 99.9800 - FN: 140.9500 - val_loss: 0.0811 - val_Accuracy: 0.9759 - val_Precision: 0.9631 - val_Recall: 0.9469 - val_TP: 761.3200 - val_TN: 1083.2700 - val_FP: 22.7300 - val_FN: 42.6800\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0392 - Accuracy: 0.9864 - Precision: 0.9638 - Recall: 0.9578 - TP: 3229.5801 - TN: 5549.7500 - FP: 97.2500 - FN: 142.4200 - val_loss: 0.0812 - val_Accuracy: 0.9759 - val_Precision: 0.9617 - val_Recall: 0.9477 - val_TP: 761.9500 - val_TN: 1082.0500 - val_FP: 23.9500 - val_FN: 42.0500\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0386 - Accuracy: 0.9863 - Precision: 0.9633 - Recall: 0.9583 - TP: 3231.5000 - TN: 5547.8599 - FP: 99.1400 - FN: 140.5000 - val_loss: 0.0843 - val_Accuracy: 0.9749 - val_Precision: 0.9579 - val_Recall: 0.9478 - val_TP: 762.0200 - val_TN: 1078.3400 - val_FP: 27.6600 - val_FN: 41.9800\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0392 - Accuracy: 0.9860 - Precision: 0.9634 - Recall: 0.9583 - TP: 3231.5500 - TN: 5548.6001 - FP: 98.4000 - FN: 140.4500 - val_loss: 0.0800 - val_Accuracy: 0.9770 - val_Precision: 0.9635 - val_Recall: 0.9476 - val_TP: 761.9100 - val_TN: 1083.6100 - val_FP: 22.3900 - val_FN: 42.0900\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0388 - Accuracy: 0.9863 - Precision: 0.9635 - Recall: 0.9583 - TP: 3231.3701 - TN: 5548.8501 - FP: 98.1500 - FN: 140.6300 - val_loss: 0.0824 - val_Accuracy: 0.9754 - val_Precision: 0.9598 - val_Recall: 0.9482 - val_TP: 762.3400 - val_TN: 1080.2200 - val_FP: 25.7800 - val_FN: 41.6600\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0391 - Accuracy: 0.9858 - Precision: 0.9629 - Recall: 0.9583 - TP: 3231.3701 - TN: 5546.4502 - FP: 100.5500 - FN: 140.6300 - val_loss: 0.0815 - val_Accuracy: 0.9759 - val_Precision: 0.9623 - val_Recall: 0.9473 - val_TP: 761.6400 - val_TN: 1082.6500 - val_FP: 23.3500 - val_FN: 42.3600\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0388 - Accuracy: 0.9866 - Precision: 0.9632 - Recall: 0.9587 - TP: 3232.6299 - TN: 5547.6401 - FP: 99.3600 - FN: 139.3700 - val_loss: 0.0807 - val_Accuracy: 0.9770 - val_Precision: 0.9631 - val_Recall: 0.9475 - val_TP: 761.7700 - val_TN: 1083.2700 - val_FP: 22.7300 - val_FN: 42.2300\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0387 - Accuracy: 0.9869 - Precision: 0.9641 - Recall: 0.9579 - TP: 3230.1001 - TN: 5551.1401 - FP: 95.8600 - FN: 141.9000 - val_loss: 0.0815 - val_Accuracy: 0.9754 - val_Precision: 0.9593 - val_Recall: 0.9492 - val_TP: 763.1400 - val_TN: 1079.7500 - val_FP: 26.2500 - val_FN: 40.8600\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0393 - Accuracy: 0.9861 - Precision: 0.9628 - Recall: 0.9585 - TP: 3232.1699 - TN: 5546.1099 - FP: 100.8900 - FN: 139.8300 - val_loss: 0.0805 - val_Accuracy: 0.9770 - val_Precision: 0.9644 - val_Recall: 0.9470 - val_TP: 761.4000 - val_TN: 1084.4700 - val_FP: 21.5300 - val_FN: 42.6000\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0386 - Accuracy: 0.9864 - Precision: 0.9639 - Recall: 0.9584 - TP: 3231.6699 - TN: 5550.1201 - FP: 96.8800 - FN: 140.3300 - val_loss: 0.0811 - val_Accuracy: 0.9754 - val_Precision: 0.9613 - val_Recall: 0.9484 - val_TP: 762.4900 - val_TN: 1081.7200 - val_FP: 24.2800 - val_FN: 41.5100\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0390 - Accuracy: 0.9865 - Precision: 0.9631 - Recall: 0.9586 - TP: 3232.2400 - TN: 5547.0801 - FP: 99.9200 - FN: 139.7600 - val_loss: 0.0828 - val_Accuracy: 0.9754 - val_Precision: 0.9603 - val_Recall: 0.9479 - val_TP: 762.1200 - val_TN: 1080.6700 - val_FP: 25.3300 - val_FN: 41.8800\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0392 - Accuracy: 0.9863 - Precision: 0.9636 - Recall: 0.9581 - TP: 3230.6899 - TN: 5548.7798 - FP: 98.2200 - FN: 141.3100 - val_loss: 0.0807 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9476 - val_TP: 761.8500 - val_TN: 1083.4500 - val_FP: 22.5500 - val_FN: 42.1500\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0394 - Accuracy: 0.9863 - Precision: 0.9630 - Recall: 0.9585 - TP: 3232.2100 - TN: 5546.8101 - FP: 100.1900 - FN: 139.7900 - val_loss: 0.0822 - val_Accuracy: 0.9759 - val_Precision: 0.9618 - val_Recall: 0.9476 - val_TP: 761.8900 - val_TN: 1082.1801 - val_FP: 23.8200 - val_FN: 42.1100\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0398 - Accuracy: 0.9868 - Precision: 0.9632 - Recall: 0.9584 - TP: 3231.7200 - TN: 5548.0000 - FP: 99.0000 - FN: 140.2800 - val_loss: 0.0830 - val_Accuracy: 0.9764 - val_Precision: 0.9603 - val_Recall: 0.9479 - val_TP: 762.1200 - val_TN: 1080.7100 - val_FP: 25.2900 - val_FN: 41.8800\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0390 - Accuracy: 0.9863 - Precision: 0.9640 - Recall: 0.9578 - TP: 3229.5901 - TN: 5550.6299 - FP: 96.3700 - FN: 142.4100 - val_loss: 0.0828 - val_Accuracy: 0.9754 - val_Precision: 0.9593 - val_Recall: 0.9487 - val_TP: 762.7400 - val_TN: 1079.7200 - val_FP: 26.2800 - val_FN: 41.2600\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0384 - Accuracy: 0.9867 - Precision: 0.9628 - Recall: 0.9592 - TP: 3234.5801 - TN: 5545.9800 - FP: 101.0200 - FN: 137.4200 - val_loss: 0.0813 - val_Accuracy: 0.9775 - val_Precision: 0.9631 - val_Recall: 0.9475 - val_TP: 761.8100 - val_TN: 1083.3199 - val_FP: 22.6800 - val_FN: 42.1900\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0381 - Accuracy: 0.9865 - Precision: 0.9642 - Recall: 0.9585 - TP: 3231.8999 - TN: 5551.5498 - FP: 95.4500 - FN: 140.1000 - val_loss: 0.0816 - val_Accuracy: 0.9754 - val_Precision: 0.9622 - val_Recall: 0.9479 - val_TP: 762.1100 - val_TN: 1082.5400 - val_FP: 23.4600 - val_FN: 41.8900\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0392 - Accuracy: 0.9860 - Precision: 0.9634 - Recall: 0.9583 - TP: 3231.4500 - TN: 5548.5801 - FP: 98.4200 - FN: 140.5500 - val_loss: 0.0824 - val_Accuracy: 0.9754 - val_Precision: 0.9610 - val_Recall: 0.9481 - val_TP: 762.3000 - val_TN: 1081.4900 - val_FP: 24.5100 - val_FN: 41.7000\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0403 - Accuracy: 0.9864 - Precision: 0.9622 - Recall: 0.9587 - TP: 3232.8899 - TN: 5544.2202 - FP: 102.7800 - FN: 139.1100 - val_loss: 0.0812 - val_Accuracy: 0.9764 - val_Precision: 0.9635 - val_Recall: 0.9476 - val_TP: 761.8400 - val_TN: 1083.6600 - val_FP: 22.3400 - val_FN: 42.1600\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0398 - Accuracy: 0.9868 - Precision: 0.9633 - Recall: 0.9579 - TP: 3230.1599 - TN: 5548.0098 - FP: 98.9900 - FN: 141.8400 - val_loss: 0.0803 - val_Accuracy: 0.9754 - val_Precision: 0.9607 - val_Recall: 0.9486 - val_TP: 762.7100 - val_TN: 1081.1700 - val_FP: 24.8300 - val_FN: 41.2900\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0402 - Accuracy: 0.9856 - Precision: 0.9625 - Recall: 0.9577 - TP: 3229.2300 - TN: 5544.9502 - FP: 102.0500 - FN: 142.7700 - val_loss: 0.0805 - val_Accuracy: 0.9759 - val_Precision: 0.9619 - val_Recall: 0.9478 - val_TP: 762.0700 - val_TN: 1082.2200 - val_FP: 23.7800 - val_FN: 41.9300\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0395 - Accuracy: 0.9860 - Precision: 0.9634 - Recall: 0.9579 - TP: 3230.1599 - TN: 5548.2202 - FP: 98.7800 - FN: 141.8400 - val_loss: 0.0810 - val_Accuracy: 0.9749 - val_Precision: 0.9615 - val_Recall: 0.9479 - val_TP: 762.0900 - val_TN: 1081.8900 - val_FP: 24.1100 - val_FN: 41.9100\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0394 - Accuracy: 0.9859 - Precision: 0.9627 - Recall: 0.9582 - TP: 3231.1399 - TN: 5545.8398 - FP: 101.1600 - FN: 140.8600 - val_loss: 0.0800 - val_Accuracy: 0.9770 - val_Precision: 0.9622 - val_Recall: 0.9481 - val_TP: 762.3100 - val_TN: 1082.4500 - val_FP: 23.5500 - val_FN: 41.6900\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0389 - Accuracy: 0.9864 - Precision: 0.9630 - Recall: 0.9581 - TP: 3230.6799 - TN: 5546.7402 - FP: 100.2600 - FN: 141.3200 - val_loss: 0.0803 - val_Accuracy: 0.9770 - val_Precision: 0.9630 - val_Recall: 0.9475 - val_TP: 761.7900 - val_TN: 1083.1899 - val_FP: 22.8100 - val_FN: 42.2100\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0390 - Accuracy: 0.9866 - Precision: 0.9635 - Recall: 0.9586 - TP: 3232.3899 - TN: 5548.8101 - FP: 98.1900 - FN: 139.6100 - val_loss: 0.0806 - val_Accuracy: 0.9770 - val_Precision: 0.9630 - val_Recall: 0.9475 - val_TP: 761.7500 - val_TN: 1083.1899 - val_FP: 22.8100 - val_FN: 42.2500\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0390 - Accuracy: 0.9875 - Precision: 0.9635 - Recall: 0.9582 - TP: 3230.9299 - TN: 5548.7500 - FP: 98.2500 - FN: 141.0700 - val_loss: 0.0805 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9474 - val_TP: 761.7400 - val_TN: 1083.4900 - val_FP: 22.5100 - val_FN: 42.2600\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0404 - Accuracy: 0.9859 - Precision: 0.9627 - Recall: 0.9579 - TP: 3230.0701 - TN: 5545.9199 - FP: 101.0800 - FN: 141.9300 - val_loss: 0.0803 - val_Accuracy: 0.9770 - val_Precision: 0.9636 - val_Recall: 0.9474 - val_TP: 761.7300 - val_TN: 1083.7100 - val_FP: 22.2900 - val_FN: 42.2700\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0386 - Accuracy: 0.9868 - Precision: 0.9641 - Recall: 0.9580 - TP: 3230.3899 - TN: 5550.9902 - FP: 96.0100 - FN: 141.6100 - val_loss: 0.0801 - val_Accuracy: 0.9775 - val_Precision: 0.9630 - val_Recall: 0.9479 - val_TP: 762.0900 - val_TN: 1083.1801 - val_FP: 22.8200 - val_FN: 41.9100\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0387 - Accuracy: 0.9863 - Precision: 0.9630 - Recall: 0.9588 - TP: 3232.9199 - TN: 5546.7998 - FP: 100.2000 - FN: 139.0800 - val_loss: 0.0820 - val_Accuracy: 0.9759 - val_Precision: 0.9615 - val_Recall: 0.9476 - val_TP: 761.8900 - val_TN: 1081.9399 - val_FP: 24.0600 - val_FN: 42.1100\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0388 - Accuracy: 0.9868 - Precision: 0.9635 - Recall: 0.9581 - TP: 3230.8501 - TN: 5548.7002 - FP: 98.3000 - FN: 141.1500 - val_loss: 0.0817 - val_Accuracy: 0.9764 - val_Precision: 0.9615 - val_Recall: 0.9477 - val_TP: 761.9900 - val_TN: 1081.8900 - val_FP: 24.1100 - val_FN: 42.0100\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0390 - Accuracy: 0.9866 - Precision: 0.9633 - Recall: 0.9588 - TP: 3232.9700 - TN: 5547.5498 - FP: 99.4500 - FN: 139.0300 - val_loss: 0.0804 - val_Accuracy: 0.9775 - val_Precision: 0.9634 - val_Recall: 0.9477 - val_TP: 761.9700 - val_TN: 1083.5500 - val_FP: 22.4500 - val_FN: 42.0300\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0389 - Accuracy: 0.9866 - Precision: 0.9631 - Recall: 0.9586 - TP: 3232.2500 - TN: 5547.2202 - FP: 99.7800 - FN: 139.7500 - val_loss: 0.0817 - val_Accuracy: 0.9770 - val_Precision: 0.9642 - val_Recall: 0.9465 - val_TP: 760.9500 - val_TN: 1084.2800 - val_FP: 21.7200 - val_FN: 43.0500\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0399 - Accuracy: 0.9863 - Precision: 0.9630 - Recall: 0.9580 - TP: 3230.4900 - TN: 5547.3301 - FP: 99.6700 - FN: 141.5100 - val_loss: 0.0842 - val_Accuracy: 0.9754 - val_Precision: 0.9594 - val_Recall: 0.9478 - val_TP: 762.0500 - val_TN: 1079.8199 - val_FP: 26.1800 - val_FN: 41.9500\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0393 - Accuracy: 0.9865 - Precision: 0.9630 - Recall: 0.9584 - TP: 3231.8401 - TN: 5546.9600 - FP: 100.0400 - FN: 140.1600 - val_loss: 0.0810 - val_Accuracy: 0.9770 - val_Precision: 0.9644 - val_Recall: 0.9469 - val_TP: 761.2700 - val_TN: 1084.4900 - val_FP: 21.5100 - val_FN: 42.7300\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0390 - Accuracy: 0.9858 - Precision: 0.9634 - Recall: 0.9580 - TP: 3230.3999 - TN: 5548.9302 - FP: 98.0700 - FN: 141.6000 - val_loss: 0.0813 - val_Accuracy: 0.9770 - val_Precision: 0.9635 - val_Recall: 0.9472 - val_TP: 761.5500 - val_TN: 1083.7400 - val_FP: 22.2600 - val_FN: 42.4500\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0382 - Accuracy: 0.9865 - Precision: 0.9640 - Recall: 0.9587 - TP: 3232.7700 - TN: 5550.5801 - FP: 96.4200 - FN: 139.2300 - val_loss: 0.0818 - val_Accuracy: 0.9754 - val_Precision: 0.9614 - val_Recall: 0.9482 - val_TP: 762.3700 - val_TN: 1081.8400 - val_FP: 24.1600 - val_FN: 41.6300\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0384 - Accuracy: 0.9865 - Precision: 0.9637 - Recall: 0.9587 - TP: 3232.7700 - TN: 5549.7798 - FP: 97.2200 - FN: 139.2300 - val_loss: 0.0820 - val_Accuracy: 0.9764 - val_Precision: 0.9619 - val_Recall: 0.9478 - val_TP: 762.0000 - val_TN: 1082.3101 - val_FP: 23.6900 - val_FN: 42.0000\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0389 - Accuracy: 0.9863 - Precision: 0.9636 - Recall: 0.9586 - TP: 3232.4700 - TN: 5549.4902 - FP: 97.5100 - FN: 139.5300 - val_loss: 0.0817 - val_Accuracy: 0.9759 - val_Precision: 0.9621 - val_Recall: 0.9479 - val_TP: 762.1400 - val_TN: 1082.4301 - val_FP: 23.5700 - val_FN: 41.8600\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0385 - Accuracy: 0.9866 - Precision: 0.9633 - Recall: 0.9589 - TP: 3233.3701 - TN: 5548.0298 - FP: 98.9700 - FN: 138.6300 - val_loss: 0.0816 - val_Accuracy: 0.9775 - val_Precision: 0.9630 - val_Recall: 0.9476 - val_TP: 761.8400 - val_TN: 1083.2300 - val_FP: 22.7700 - val_FN: 42.1600\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0385 - Accuracy: 0.9869 - Precision: 0.9637 - Recall: 0.9592 - TP: 3234.3799 - TN: 5549.5000 - FP: 97.5000 - FN: 137.6200 - val_loss: 0.0816 - val_Accuracy: 0.9770 - val_Precision: 0.9628 - val_Recall: 0.9477 - val_TP: 761.9900 - val_TN: 1083.0699 - val_FP: 22.9300 - val_FN: 42.0100\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0391 - Accuracy: 0.9863 - Precision: 0.9638 - Recall: 0.9581 - TP: 3230.5601 - TN: 5550.2100 - FP: 96.7900 - FN: 141.4400 - val_loss: 0.0829 - val_Accuracy: 0.9759 - val_Precision: 0.9613 - val_Recall: 0.9478 - val_TP: 762.0300 - val_TN: 1081.7400 - val_FP: 24.2600 - val_FN: 41.9700\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0389 - Accuracy: 0.9867 - Precision: 0.9636 - Recall: 0.9591 - TP: 3233.9900 - TN: 5549.1802 - FP: 97.8200 - FN: 138.0100 - val_loss: 0.0820 - val_Accuracy: 0.9754 - val_Precision: 0.9612 - val_Recall: 0.9486 - val_TP: 762.6500 - val_TN: 1081.6600 - val_FP: 24.3400 - val_FN: 41.3500\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0384 - Accuracy: 0.9864 - Precision: 0.9639 - Recall: 0.9588 - TP: 3233.1599 - TN: 5550.3901 - FP: 96.6100 - FN: 138.8400 - val_loss: 0.0838 - val_Accuracy: 0.9759 - val_Precision: 0.9601 - val_Recall: 0.9480 - val_TP: 762.1900 - val_TN: 1080.5300 - val_FP: 25.4700 - val_FN: 41.8100\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0412 - Accuracy: 0.9859 - Precision: 0.9636 - Recall: 0.9584 - TP: 3231.8000 - TN: 5549.7998 - FP: 97.2000 - FN: 140.2000 - val_loss: 0.0800 - val_Accuracy: 0.9759 - val_Precision: 0.9639 - val_Recall: 0.9476 - val_TP: 761.8700 - val_TN: 1084.0200 - val_FP: 21.9800 - val_FN: 42.1300\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0397 - Accuracy: 0.9861 - Precision: 0.9630 - Recall: 0.9586 - TP: 3232.4900 - TN: 5546.6499 - FP: 100.3500 - FN: 139.5100 - val_loss: 0.0812 - val_Accuracy: 0.9759 - val_Precision: 0.9633 - val_Recall: 0.9471 - val_TP: 761.4300 - val_TN: 1083.5000 - val_FP: 22.5000 - val_FN: 42.5700\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0395 - Accuracy: 0.9864 - Precision: 0.9636 - Recall: 0.9584 - TP: 3231.7000 - TN: 5549.3599 - FP: 97.6400 - FN: 140.3000 - val_loss: 0.0808 - val_Accuracy: 0.9759 - val_Precision: 0.9627 - val_Recall: 0.9477 - val_TP: 761.9300 - val_TN: 1082.9399 - val_FP: 23.0600 - val_FN: 42.0700\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0405 - Accuracy: 0.9864 - Precision: 0.9630 - Recall: 0.9577 - TP: 3229.4800 - TN: 5547.1299 - FP: 99.8700 - FN: 142.5200 - val_loss: 0.0798 - val_Accuracy: 0.9764 - val_Precision: 0.9630 - val_Recall: 0.9482 - val_TP: 762.3600 - val_TN: 1083.2300 - val_FP: 22.7700 - val_FN: 41.6400\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0399 - Accuracy: 0.9867 - Precision: 0.9627 - Recall: 0.9582 - TP: 3231.0200 - TN: 5545.7100 - FP: 101.2900 - FN: 140.9800 - val_loss: 0.0810 - val_Accuracy: 0.9770 - val_Precision: 0.9628 - val_Recall: 0.9475 - val_TP: 761.7600 - val_TN: 1083.0300 - val_FP: 22.9700 - val_FN: 42.2400\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0397 - Accuracy: 0.9860 - Precision: 0.9634 - Recall: 0.9582 - TP: 3231.1599 - TN: 5548.3599 - FP: 98.6400 - FN: 140.8400 - val_loss: 0.0808 - val_Accuracy: 0.9764 - val_Precision: 0.9630 - val_Recall: 0.9477 - val_TP: 761.9300 - val_TN: 1083.1899 - val_FP: 22.8100 - val_FN: 42.0700\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0392 - Accuracy: 0.9855 - Precision: 0.9628 - Recall: 0.9583 - TP: 3231.4399 - TN: 5546.7100 - FP: 100.2900 - FN: 140.5600 - val_loss: 0.0818 - val_Accuracy: 0.9759 - val_Precision: 0.9627 - val_Recall: 0.9471 - val_TP: 761.4900 - val_TN: 1082.9500 - val_FP: 23.0500 - val_FN: 42.5100\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0400 - Accuracy: 0.9860 - Precision: 0.9636 - Recall: 0.9579 - TP: 3230.0100 - TN: 5549.5298 - FP: 97.4700 - FN: 141.9900 - val_loss: 0.0806 - val_Accuracy: 0.9764 - val_Precision: 0.9623 - val_Recall: 0.9481 - val_TP: 762.2800 - val_TN: 1082.6000 - val_FP: 23.4000 - val_FN: 41.7200\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0402 - Accuracy: 0.9860 - Precision: 0.9632 - Recall: 0.9579 - TP: 3230.1399 - TN: 5548.1499 - FP: 98.8500 - FN: 141.8600 - val_loss: 0.0803 - val_Accuracy: 0.9764 - val_Precision: 0.9617 - val_Recall: 0.9487 - val_TP: 762.7900 - val_TN: 1082.0500 - val_FP: 23.9500 - val_FN: 41.2100\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0392 - Accuracy: 0.9866 - Precision: 0.9630 - Recall: 0.9589 - TP: 3233.5200 - TN: 5546.8101 - FP: 100.1900 - FN: 138.4800 - val_loss: 0.0808 - val_Accuracy: 0.9764 - val_Precision: 0.9636 - val_Recall: 0.9475 - val_TP: 761.7700 - val_TN: 1083.7900 - val_FP: 22.2100 - val_FN: 42.2300\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0385 - Accuracy: 0.9864 - Precision: 0.9637 - Recall: 0.9586 - TP: 3232.5000 - TN: 5549.4800 - FP: 97.5200 - FN: 139.5000 - val_loss: 0.0817 - val_Accuracy: 0.9759 - val_Precision: 0.9629 - val_Recall: 0.9474 - val_TP: 761.6700 - val_TN: 1083.1400 - val_FP: 22.8600 - val_FN: 42.3300\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0388 - Accuracy: 0.9865 - Precision: 0.9639 - Recall: 0.9584 - TP: 3231.5701 - TN: 5550.4399 - FP: 96.5600 - FN: 140.4300 - val_loss: 0.0801 - val_Accuracy: 0.9764 - val_Precision: 0.9630 - val_Recall: 0.9485 - val_TP: 762.6000 - val_TN: 1083.2300 - val_FP: 22.7700 - val_FN: 41.4000\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0384 - Accuracy: 0.9869 - Precision: 0.9629 - Recall: 0.9595 - TP: 3235.5300 - TN: 5546.3101 - FP: 100.6900 - FN: 136.4700 - val_loss: 0.0810 - val_Accuracy: 0.9770 - val_Precision: 0.9639 - val_Recall: 0.9474 - val_TP: 761.7000 - val_TN: 1084.0400 - val_FP: 21.9600 - val_FN: 42.3000\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0402 - Accuracy: 0.9860 - Precision: 0.9630 - Recall: 0.9584 - TP: 3231.5701 - TN: 5547.0801 - FP: 99.9200 - FN: 140.4300 - val_loss: 0.0814 - val_Accuracy: 0.9770 - val_Precision: 0.9643 - val_Recall: 0.9469 - val_TP: 761.3200 - val_TN: 1084.3700 - val_FP: 21.6300 - val_FN: 42.6800\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0390 - Accuracy: 0.9865 - Precision: 0.9634 - Recall: 0.9584 - TP: 3231.7300 - TN: 5548.4302 - FP: 98.5700 - FN: 140.2700 - val_loss: 0.0818 - val_Accuracy: 0.9770 - val_Precision: 0.9648 - val_Recall: 0.9464 - val_TP: 760.8800 - val_TN: 1084.8600 - val_FP: 21.1400 - val_FN: 43.1200\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0388 - Accuracy: 0.9868 - Precision: 0.9640 - Recall: 0.9582 - TP: 3231.2100 - TN: 5550.7598 - FP: 96.2400 - FN: 140.7900 - val_loss: 0.0812 - val_Accuracy: 0.9770 - val_Precision: 0.9621 - val_Recall: 0.9483 - val_TP: 762.4700 - val_TN: 1082.4301 - val_FP: 23.5700 - val_FN: 41.5300\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0392 - Accuracy: 0.9864 - Precision: 0.9631 - Recall: 0.9589 - TP: 3233.5000 - TN: 5547.6099 - FP: 99.3900 - FN: 138.5000 - val_loss: 0.0813 - val_Accuracy: 0.9770 - val_Precision: 0.9654 - val_Recall: 0.9466 - val_TP: 761.0900 - val_TN: 1085.3500 - val_FP: 20.6500 - val_FN: 42.9100\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0385 - Accuracy: 0.9872 - Precision: 0.9639 - Recall: 0.9594 - TP: 3235.1499 - TN: 5550.3301 - FP: 96.6700 - FN: 136.8500 - val_loss: 0.0815 - val_Accuracy: 0.9770 - val_Precision: 0.9653 - val_Recall: 0.9465 - val_TP: 761.0200 - val_TN: 1085.3000 - val_FP: 20.7000 - val_FN: 42.9800\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0397 - Accuracy: 0.9870 - Precision: 0.9637 - Recall: 0.9579 - TP: 3229.9600 - TN: 5549.7798 - FP: 97.2200 - FN: 142.0400 - val_loss: 0.0810 - val_Accuracy: 0.9775 - val_Precision: 0.9632 - val_Recall: 0.9482 - val_TP: 762.3700 - val_TN: 1083.3800 - val_FP: 22.6200 - val_FN: 41.6300\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0390 - Accuracy: 0.9869 - Precision: 0.9633 - Recall: 0.9595 - TP: 3235.5000 - TN: 5548.1099 - FP: 98.8900 - FN: 136.5000 - val_loss: 0.0832 - val_Accuracy: 0.9759 - val_Precision: 0.9632 - val_Recall: 0.9468 - val_TP: 761.1900 - val_TN: 1083.4700 - val_FP: 22.5300 - val_FN: 42.8100\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0382 - Accuracy: 0.9870 - Precision: 0.9647 - Recall: 0.9582 - TP: 3231.0500 - TN: 5553.6299 - FP: 93.3700 - FN: 140.9500 - val_loss: 0.0838 - val_Accuracy: 0.9759 - val_Precision: 0.9590 - val_Recall: 0.9488 - val_TP: 762.8400 - val_TN: 1079.5300 - val_FP: 26.4700 - val_FN: 41.1600\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0382 - Accuracy: 0.9868 - Precision: 0.9638 - Recall: 0.9596 - TP: 3235.7100 - TN: 5549.8901 - FP: 97.1100 - FN: 136.2900 - val_loss: 0.0823 - val_Accuracy: 0.9759 - val_Precision: 0.9620 - val_Recall: 0.9480 - val_TP: 762.1700 - val_TN: 1082.3900 - val_FP: 23.6100 - val_FN: 41.8300\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0387 - Accuracy: 0.9860 - Precision: 0.9638 - Recall: 0.9584 - TP: 3231.7600 - TN: 5550.2798 - FP: 96.7200 - FN: 140.2400 - val_loss: 0.0822 - val_Accuracy: 0.9759 - val_Precision: 0.9616 - val_Recall: 0.9482 - val_TP: 762.3900 - val_TN: 1082.0601 - val_FP: 23.9400 - val_FN: 41.6100\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0402 - Accuracy: 0.9864 - Precision: 0.9628 - Recall: 0.9586 - TP: 3232.2400 - TN: 5546.1001 - FP: 100.9000 - FN: 139.7600 - val_loss: 0.0819 - val_Accuracy: 0.9770 - val_Precision: 0.9638 - val_Recall: 0.9475 - val_TP: 761.7600 - val_TN: 1083.9800 - val_FP: 22.0200 - val_FN: 42.2400\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0408 - Accuracy: 0.9860 - Precision: 0.9624 - Recall: 0.9585 - TP: 3232.1499 - TN: 5545.2798 - FP: 101.7200 - FN: 139.8500 - val_loss: 0.0811 - val_Accuracy: 0.9764 - val_Precision: 0.9634 - val_Recall: 0.9472 - val_TP: 761.5800 - val_TN: 1083.5699 - val_FP: 22.4300 - val_FN: 42.4200\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0389 - Accuracy: 0.9866 - Precision: 0.9636 - Recall: 0.9585 - TP: 3231.9099 - TN: 5549.1201 - FP: 97.8800 - FN: 140.0900 - val_loss: 0.0808 - val_Accuracy: 0.9759 - val_Precision: 0.9631 - val_Recall: 0.9476 - val_TP: 761.8600 - val_TN: 1083.3300 - val_FP: 22.6700 - val_FN: 42.1400\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0390 - Accuracy: 0.9868 - Precision: 0.9640 - Recall: 0.9586 - TP: 3232.4399 - TN: 5550.6401 - FP: 96.3600 - FN: 139.5600 - val_loss: 0.0826 - val_Accuracy: 0.9743 - val_Precision: 0.9606 - val_Recall: 0.9478 - val_TP: 762.0400 - val_TN: 1080.9600 - val_FP: 25.0400 - val_FN: 41.9600\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0396 - Accuracy: 0.9858 - Precision: 0.9636 - Recall: 0.9578 - TP: 3229.5901 - TN: 5549.7100 - FP: 97.2900 - FN: 142.4100 - val_loss: 0.0806 - val_Accuracy: 0.9764 - val_Precision: 0.9614 - val_Recall: 0.9489 - val_TP: 762.8800 - val_TN: 1081.7600 - val_FP: 24.2400 - val_FN: 41.1200\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0386 - Accuracy: 0.9865 - Precision: 0.9630 - Recall: 0.9590 - TP: 3233.7200 - TN: 5546.8901 - FP: 100.1100 - FN: 138.2800 - val_loss: 0.0802 - val_Accuracy: 0.9759 - val_Precision: 0.9640 - val_Recall: 0.9477 - val_TP: 761.9600 - val_TN: 1084.1400 - val_FP: 21.8600 - val_FN: 42.0400\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0390 - Accuracy: 0.9861 - Precision: 0.9630 - Recall: 0.9584 - TP: 3231.8000 - TN: 5547.0098 - FP: 99.9900 - FN: 140.2000 - val_loss: 0.0815 - val_Accuracy: 0.9749 - val_Precision: 0.9625 - val_Recall: 0.9476 - val_TP: 761.8600 - val_TN: 1082.8000 - val_FP: 23.2000 - val_FN: 42.1400\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0389 - Accuracy: 0.9866 - Precision: 0.9643 - Recall: 0.9582 - TP: 3231.1799 - TN: 5551.9102 - FP: 95.0900 - FN: 140.8200 - val_loss: 0.0801 - val_Accuracy: 0.9764 - val_Precision: 0.9630 - val_Recall: 0.9484 - val_TP: 762.5400 - val_TN: 1083.2000 - val_FP: 22.8000 - val_FN: 41.4600\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0391 - Accuracy: 0.9866 - Precision: 0.9630 - Recall: 0.9587 - TP: 3232.6001 - TN: 5546.9600 - FP: 100.0400 - FN: 139.4000 - val_loss: 0.0822 - val_Accuracy: 0.9754 - val_Precision: 0.9597 - val_Recall: 0.9489 - val_TP: 762.9200 - val_TN: 1080.1300 - val_FP: 25.8700 - val_FN: 41.0800\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0386 - Accuracy: 0.9867 - Precision: 0.9632 - Recall: 0.9591 - TP: 3233.9299 - TN: 5547.6699 - FP: 99.3300 - FN: 138.0700 - val_loss: 0.0807 - val_Accuracy: 0.9764 - val_Precision: 0.9636 - val_Recall: 0.9479 - val_TP: 762.1200 - val_TN: 1083.7500 - val_FP: 22.2500 - val_FN: 41.8800\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0405 - Accuracy: 0.9863 - Precision: 0.9633 - Recall: 0.9586 - TP: 3232.2800 - TN: 5548.1699 - FP: 98.8300 - FN: 139.7200 - val_loss: 0.0815 - val_Accuracy: 0.9775 - val_Precision: 0.9644 - val_Recall: 0.9467 - val_TP: 761.1600 - val_TN: 1084.5100 - val_FP: 21.4900 - val_FN: 42.8400\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0384 - Accuracy: 0.9867 - Precision: 0.9643 - Recall: 0.9585 - TP: 3232.0000 - TN: 5551.6499 - FP: 95.3500 - FN: 140.0000 - val_loss: 0.0822 - val_Accuracy: 0.9749 - val_Precision: 0.9613 - val_Recall: 0.9483 - val_TP: 762.4000 - val_TN: 1081.7100 - val_FP: 24.2900 - val_FN: 41.6000\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0386 - Accuracy: 0.9867 - Precision: 0.9635 - Recall: 0.9589 - TP: 3233.5701 - TN: 5548.6099 - FP: 98.3900 - FN: 138.4300 - val_loss: 0.0813 - val_Accuracy: 0.9764 - val_Precision: 0.9631 - val_Recall: 0.9477 - val_TP: 761.9800 - val_TN: 1083.3199 - val_FP: 22.6800 - val_FN: 42.0200\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0383 - Accuracy: 0.9865 - Precision: 0.9637 - Recall: 0.9588 - TP: 3232.9800 - TN: 5549.6299 - FP: 97.3700 - FN: 139.0200 - val_loss: 0.0817 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9475 - val_TP: 761.8000 - val_TN: 1083.4600 - val_FP: 22.5400 - val_FN: 42.2000\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0383 - Accuracy: 0.9868 - Precision: 0.9641 - Recall: 0.9588 - TP: 3233.2100 - TN: 5551.1099 - FP: 95.8900 - FN: 138.7900 - val_loss: 0.0833 - val_Accuracy: 0.9754 - val_Precision: 0.9618 - val_Recall: 0.9473 - val_TP: 761.6600 - val_TN: 1082.0500 - val_FP: 23.9500 - val_FN: 42.3400\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0384 - Accuracy: 0.9866 - Precision: 0.9637 - Recall: 0.9590 - TP: 3233.6201 - TN: 5549.6699 - FP: 97.3300 - FN: 138.3800 - val_loss: 0.0811 - val_Accuracy: 0.9770 - val_Precision: 0.9636 - val_Recall: 0.9479 - val_TP: 762.1400 - val_TN: 1083.7500 - val_FP: 22.2500 - val_FN: 41.8600\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0389 - Accuracy: 0.9861 - Precision: 0.9637 - Recall: 0.9585 - TP: 3232.0000 - TN: 5550.0298 - FP: 96.9700 - FN: 140.0000 - val_loss: 0.0811 - val_Accuracy: 0.9759 - val_Precision: 0.9635 - val_Recall: 0.9479 - val_TP: 762.1300 - val_TN: 1083.6801 - val_FP: 22.3200 - val_FN: 41.8700\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0381 - Accuracy: 0.9869 - Precision: 0.9642 - Recall: 0.9593 - TP: 3234.7800 - TN: 5551.7500 - FP: 95.2500 - FN: 137.2200 - val_loss: 0.0818 - val_Accuracy: 0.9749 - val_Precision: 0.9617 - val_Recall: 0.9484 - val_TP: 762.5500 - val_TN: 1082.0699 - val_FP: 23.9300 - val_FN: 41.4500\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0391 - Accuracy: 0.9865 - Precision: 0.9642 - Recall: 0.9584 - TP: 3231.6699 - TN: 5551.7202 - FP: 95.2800 - FN: 140.3300 - val_loss: 0.0911 - val_Accuracy: 0.9738 - val_Precision: 0.9485 - val_Recall: 0.9496 - val_TP: 763.4900 - val_TN: 1069.4600 - val_FP: 36.5400 - val_FN: 40.5100\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0381 - Accuracy: 0.9864 - Precision: 0.9636 - Recall: 0.9593 - TP: 3234.8899 - TN: 5549.1401 - FP: 97.8600 - FN: 137.1100 - val_loss: 0.0817 - val_Accuracy: 0.9770 - val_Precision: 0.9626 - val_Recall: 0.9482 - val_TP: 762.3600 - val_TN: 1082.8800 - val_FP: 23.1200 - val_FN: 41.6400\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0380 - Accuracy: 0.9865 - Precision: 0.9642 - Recall: 0.9592 - TP: 3234.3201 - TN: 5551.3301 - FP: 95.6700 - FN: 137.6800 - val_loss: 0.0809 - val_Accuracy: 0.9764 - val_Precision: 0.9609 - val_Recall: 0.9498 - val_TP: 763.6400 - val_TN: 1081.3500 - val_FP: 24.6500 - val_FN: 40.3600\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0385 - Accuracy: 0.9868 - Precision: 0.9638 - Recall: 0.9600 - TP: 3237.1201 - TN: 5549.9800 - FP: 97.0200 - FN: 134.8800 - val_loss: 0.0840 - val_Accuracy: 0.9759 - val_Precision: 0.9606 - val_Recall: 0.9480 - val_TP: 762.1700 - val_TN: 1081.0400 - val_FP: 24.9600 - val_FN: 41.8300\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0382 - Accuracy: 0.9864 - Precision: 0.9640 - Recall: 0.9589 - TP: 3233.2800 - TN: 5550.7402 - FP: 96.2600 - FN: 138.7200 - val_loss: 0.0821 - val_Accuracy: 0.9770 - val_Precision: 0.9638 - val_Recall: 0.9474 - val_TP: 761.7400 - val_TN: 1083.9900 - val_FP: 22.0100 - val_FN: 42.2600\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0384 - Accuracy: 0.9867 - Precision: 0.9633 - Recall: 0.9591 - TP: 3233.9299 - TN: 5548.0498 - FP: 98.9500 - FN: 138.0700 - val_loss: 0.0820 - val_Accuracy: 0.9770 - val_Precision: 0.9659 - val_Recall: 0.9464 - val_TP: 760.9100 - val_TN: 1085.8700 - val_FP: 20.1300 - val_FN: 43.0900\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0395 - Accuracy: 0.9866 - Precision: 0.9638 - Recall: 0.9590 - TP: 3233.7300 - TN: 5550.4502 - FP: 96.5500 - FN: 138.2700 - val_loss: 0.0849 - val_Accuracy: 0.9754 - val_Precision: 0.9608 - val_Recall: 0.9476 - val_TP: 761.8700 - val_TN: 1081.2000 - val_FP: 24.8000 - val_FN: 42.1300\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0381 - Accuracy: 0.9871 - Precision: 0.9643 - Recall: 0.9589 - TP: 3233.3899 - TN: 5551.6699 - FP: 95.3300 - FN: 138.6100 - val_loss: 0.0822 - val_Accuracy: 0.9764 - val_Precision: 0.9627 - val_Recall: 0.9481 - val_TP: 762.2900 - val_TN: 1083.0300 - val_FP: 22.9700 - val_FN: 41.7100\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0388 - Accuracy: 0.9865 - Precision: 0.9637 - Recall: 0.9587 - TP: 3232.6899 - TN: 5550.0000 - FP: 97.0000 - FN: 139.3100 - val_loss: 0.0824 - val_Accuracy: 0.9759 - val_Precision: 0.9622 - val_Recall: 0.9483 - val_TP: 762.4400 - val_TN: 1082.5699 - val_FP: 23.4300 - val_FN: 41.5600\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0378 - Accuracy: 0.9874 - Precision: 0.9646 - Recall: 0.9594 - TP: 3234.9299 - TN: 5552.8799 - FP: 94.1200 - FN: 137.0700 - val_loss: 0.0818 - val_Accuracy: 0.9764 - val_Precision: 0.9617 - val_Recall: 0.9490 - val_TP: 763.0300 - val_TN: 1082.0900 - val_FP: 23.9100 - val_FN: 40.9700\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 6ms/step - loss: 0.0401 - Accuracy: 0.9863 - Precision: 0.9633 - Recall: 0.9586 - TP: 3232.3000 - TN: 5548.4199 - FP: 98.5800 - FN: 139.7000 - val_loss: 0.0803 - val_Accuracy: 0.9764 - val_Precision: 0.9624 - val_Recall: 0.9488 - val_TP: 762.8000 - val_TN: 1082.6801 - val_FP: 23.3200 - val_FN: 41.2000\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0391 - Accuracy: 0.9866 - Precision: 0.9630 - Recall: 0.9591 - TP: 3233.9900 - TN: 5547.2300 - FP: 99.7700 - FN: 138.0100 - val_loss: 0.0817 - val_Accuracy: 0.9749 - val_Precision: 0.9617 - val_Recall: 0.9482 - val_TP: 762.3600 - val_TN: 1082.0800 - val_FP: 23.9200 - val_FN: 41.6400\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0385 - Accuracy: 0.9863 - Precision: 0.9638 - Recall: 0.9585 - TP: 3231.9099 - TN: 5549.7998 - FP: 97.2000 - FN: 140.0900 - val_loss: 0.0840 - val_Accuracy: 0.9754 - val_Precision: 0.9586 - val_Recall: 0.9486 - val_TP: 762.6500 - val_TN: 1079.0400 - val_FP: 26.9600 - val_FN: 41.3500\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0392 - Accuracy: 0.9860 - Precision: 0.9630 - Recall: 0.9584 - TP: 3231.8601 - TN: 5547.2998 - FP: 99.7000 - FN: 140.1400 - val_loss: 0.0810 - val_Accuracy: 0.9770 - val_Precision: 0.9636 - val_Recall: 0.9477 - val_TP: 761.9400 - val_TN: 1083.7400 - val_FP: 22.2600 - val_FN: 42.0600\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0396 - Accuracy: 0.9865 - Precision: 0.9631 - Recall: 0.9588 - TP: 3233.1001 - TN: 5547.8599 - FP: 99.1400 - FN: 138.9000 - val_loss: 0.0824 - val_Accuracy: 0.9749 - val_Precision: 0.9620 - val_Recall: 0.9477 - val_TP: 761.9500 - val_TN: 1082.4000 - val_FP: 23.6000 - val_FN: 42.0500\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0390 - Accuracy: 0.9865 - Precision: 0.9642 - Recall: 0.9583 - TP: 3231.3799 - TN: 5551.5200 - FP: 95.4800 - FN: 140.6200 - val_loss: 0.0811 - val_Accuracy: 0.9764 - val_Precision: 0.9619 - val_Recall: 0.9487 - val_TP: 762.7800 - val_TN: 1082.3101 - val_FP: 23.6900 - val_FN: 41.2200\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0383 - Accuracy: 0.9869 - Precision: 0.9639 - Recall: 0.9588 - TP: 3233.2000 - TN: 5550.3799 - FP: 96.6200 - FN: 138.8000 - val_loss: 0.0812 - val_Accuracy: 0.9759 - val_Precision: 0.9611 - val_Recall: 0.9491 - val_TP: 763.0700 - val_TN: 1081.5699 - val_FP: 24.4300 - val_FN: 40.9300\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0393 - Accuracy: 0.9857 - Precision: 0.9629 - Recall: 0.9587 - TP: 3232.8799 - TN: 5546.6899 - FP: 100.3100 - FN: 139.1200 - val_loss: 0.0842 - val_Accuracy: 0.9743 - val_Precision: 0.9599 - val_Recall: 0.9479 - val_TP: 762.1200 - val_TN: 1080.4100 - val_FP: 25.5900 - val_FN: 41.8800\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0382 - Accuracy: 0.9868 - Precision: 0.9642 - Recall: 0.9591 - TP: 3234.0100 - TN: 5551.5801 - FP: 95.4200 - FN: 137.9900 - val_loss: 0.0817 - val_Accuracy: 0.9770 - val_Precision: 0.9630 - val_Recall: 0.9477 - val_TP: 761.9900 - val_TN: 1083.2800 - val_FP: 22.7200 - val_FN: 42.0100\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0401 - Accuracy: 0.9855 - Precision: 0.9634 - Recall: 0.9583 - TP: 3231.4500 - TN: 5548.5298 - FP: 98.4700 - FN: 140.5500 - val_loss: 0.0811 - val_Accuracy: 0.9764 - val_Precision: 0.9625 - val_Recall: 0.9486 - val_TP: 762.7000 - val_TN: 1082.7700 - val_FP: 23.2300 - val_FN: 41.3000\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0396 - Accuracy: 0.9864 - Precision: 0.9631 - Recall: 0.9596 - TP: 3235.7100 - TN: 5547.4102 - FP: 99.5900 - FN: 136.2900 - val_loss: 0.0822 - val_Accuracy: 0.9770 - val_Precision: 0.9647 - val_Recall: 0.9466 - val_TP: 761.0600 - val_TN: 1084.8101 - val_FP: 21.1900 - val_FN: 42.9400\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0389 - Accuracy: 0.9871 - Precision: 0.9647 - Recall: 0.9588 - TP: 3233.0200 - TN: 5553.9702 - FP: 93.0300 - FN: 138.9800 - val_loss: 0.0817 - val_Accuracy: 0.9770 - val_Precision: 0.9627 - val_Recall: 0.9482 - val_TP: 762.3500 - val_TN: 1083.0300 - val_FP: 22.9700 - val_FN: 41.6500\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0384 - Accuracy: 0.9866 - Precision: 0.9636 - Recall: 0.9591 - TP: 3234.0300 - TN: 5549.5298 - FP: 97.4700 - FN: 137.9700 - val_loss: 0.0811 - val_Accuracy: 0.9770 - val_Precision: 0.9635 - val_Recall: 0.9483 - val_TP: 762.4000 - val_TN: 1083.7500 - val_FP: 22.2500 - val_FN: 41.6000\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0382 - Accuracy: 0.9870 - Precision: 0.9641 - Recall: 0.9598 - TP: 3236.3201 - TN: 5551.1299 - FP: 95.8700 - FN: 135.6800 - val_loss: 0.0826 - val_Accuracy: 0.9754 - val_Precision: 0.9630 - val_Recall: 0.9476 - val_TP: 761.8600 - val_TN: 1083.2900 - val_FP: 22.7100 - val_FN: 42.1400\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0377 - Accuracy: 0.9866 - Precision: 0.9642 - Recall: 0.9591 - TP: 3234.0701 - TN: 5551.8101 - FP: 95.1900 - FN: 137.9300 - val_loss: 0.0824 - val_Accuracy: 0.9759 - val_Precision: 0.9627 - val_Recall: 0.9478 - val_TP: 762.0500 - val_TN: 1083.0601 - val_FP: 22.9400 - val_FN: 41.9500\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0382 - Accuracy: 0.9870 - Precision: 0.9641 - Recall: 0.9590 - TP: 3233.8401 - TN: 5551.0298 - FP: 95.9700 - FN: 138.1600 - val_loss: 0.0830 - val_Accuracy: 0.9754 - val_Precision: 0.9603 - val_Recall: 0.9489 - val_TP: 762.9300 - val_TN: 1080.9200 - val_FP: 25.0800 - val_FN: 41.0700\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0375 - Accuracy: 0.9871 - Precision: 0.9644 - Recall: 0.9596 - TP: 3235.6399 - TN: 5552.2402 - FP: 94.7600 - FN: 136.3600 - val_loss: 0.0900 - val_Accuracy: 0.9743 - val_Precision: 0.9517 - val_Recall: 0.9490 - val_TP: 763.0300 - val_TN: 1072.5300 - val_FP: 33.4700 - val_FN: 40.9700\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0390 - Accuracy: 0.9865 - Precision: 0.9635 - Recall: 0.9589 - TP: 3233.5200 - TN: 5548.7900 - FP: 98.2100 - FN: 138.4800 - val_loss: 0.0818 - val_Accuracy: 0.9764 - val_Precision: 0.9622 - val_Recall: 0.9487 - val_TP: 762.7800 - val_TN: 1082.5400 - val_FP: 23.4600 - val_FN: 41.2200\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0388 - Accuracy: 0.9863 - Precision: 0.9637 - Recall: 0.9591 - TP: 3234.0801 - TN: 5549.8599 - FP: 97.1400 - FN: 137.9200 - val_loss: 0.0828 - val_Accuracy: 0.9754 - val_Precision: 0.9627 - val_Recall: 0.9478 - val_TP: 762.0600 - val_TN: 1083.0900 - val_FP: 22.9100 - val_FN: 41.9400\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0389 - Accuracy: 0.9867 - Precision: 0.9631 - Recall: 0.9589 - TP: 3233.3201 - TN: 5547.2700 - FP: 99.7300 - FN: 138.6800 - val_loss: 0.0834 - val_Accuracy: 0.9759 - val_Precision: 0.9630 - val_Recall: 0.9474 - val_TP: 761.6700 - val_TN: 1083.2700 - val_FP: 22.7300 - val_FN: 42.3300\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0378 - Accuracy: 0.9874 - Precision: 0.9646 - Recall: 0.9594 - TP: 3235.1399 - TN: 5553.0200 - FP: 93.9800 - FN: 136.8600 - val_loss: 0.0828 - val_Accuracy: 0.9764 - val_Precision: 0.9638 - val_Recall: 0.9474 - val_TP: 761.7100 - val_TN: 1083.9900 - val_FP: 22.0100 - val_FN: 42.2900\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0409 - Accuracy: 0.9864 - Precision: 0.9630 - Recall: 0.9587 - TP: 3232.8401 - TN: 5547.1802 - FP: 99.8200 - FN: 139.1600 - val_loss: 0.0815 - val_Accuracy: 0.9764 - val_Precision: 0.9636 - val_Recall: 0.9474 - val_TP: 761.6700 - val_TN: 1083.8101 - val_FP: 22.1900 - val_FN: 42.3300\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0382 - Accuracy: 0.9875 - Precision: 0.9638 - Recall: 0.9590 - TP: 3233.7700 - TN: 5550.3301 - FP: 96.6700 - FN: 138.2300 - val_loss: 0.0817 - val_Accuracy: 0.9749 - val_Precision: 0.9618 - val_Recall: 0.9482 - val_TP: 762.3600 - val_TN: 1082.2500 - val_FP: 23.7500 - val_FN: 41.6400\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0392 - Accuracy: 0.9865 - Precision: 0.9639 - Recall: 0.9590 - TP: 3233.6001 - TN: 5550.5098 - FP: 96.4900 - FN: 138.4000 - val_loss: 0.0858 - val_Accuracy: 0.9759 - val_Precision: 0.9600 - val_Recall: 0.9467 - val_TP: 761.1600 - val_TN: 1080.3600 - val_FP: 25.6400 - val_FN: 42.8400\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0390 - Accuracy: 0.9865 - Precision: 0.9634 - Recall: 0.9584 - TP: 3231.6001 - TN: 5548.6602 - FP: 98.3400 - FN: 140.4000 - val_loss: 0.0832 - val_Accuracy: 0.9754 - val_Precision: 0.9603 - val_Recall: 0.9485 - val_TP: 762.5600 - val_TN: 1080.8900 - val_FP: 25.1100 - val_FN: 41.4400\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0389 - Accuracy: 0.9865 - Precision: 0.9641 - Recall: 0.9585 - TP: 3232.1399 - TN: 5551.3301 - FP: 95.6700 - FN: 139.8600 - val_loss: 0.0800 - val_Accuracy: 0.9764 - val_Precision: 0.9633 - val_Recall: 0.9488 - val_TP: 762.8100 - val_TN: 1083.5699 - val_FP: 22.4300 - val_FN: 41.1900\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0384 - Accuracy: 0.9865 - Precision: 0.9635 - Recall: 0.9587 - TP: 3232.8799 - TN: 5548.7998 - FP: 98.2000 - FN: 139.1200 - val_loss: 0.0808 - val_Accuracy: 0.9764 - val_Precision: 0.9626 - val_Recall: 0.9486 - val_TP: 762.6600 - val_TN: 1082.9399 - val_FP: 23.0600 - val_FN: 41.3400\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0391 - Accuracy: 0.9866 - Precision: 0.9638 - Recall: 0.9589 - TP: 3233.3899 - TN: 5549.8901 - FP: 97.1100 - FN: 138.6100 - val_loss: 0.0813 - val_Accuracy: 0.9759 - val_Precision: 0.9622 - val_Recall: 0.9485 - val_TP: 762.6100 - val_TN: 1082.5000 - val_FP: 23.5000 - val_FN: 41.3900\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0381 - Accuracy: 0.9869 - Precision: 0.9637 - Recall: 0.9594 - TP: 3235.2200 - TN: 5549.5601 - FP: 97.4400 - FN: 136.7800 - val_loss: 0.0825 - val_Accuracy: 0.9754 - val_Precision: 0.9629 - val_Recall: 0.9475 - val_TP: 761.7700 - val_TN: 1083.2300 - val_FP: 22.7700 - val_FN: 42.2300\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0389 - Accuracy: 0.9859 - Precision: 0.9640 - Recall: 0.9584 - TP: 3231.7300 - TN: 5551.5601 - FP: 95.4400 - FN: 140.2700 - val_loss: 0.0815 - val_Accuracy: 0.9764 - val_Precision: 0.9618 - val_Recall: 0.9487 - val_TP: 762.7900 - val_TN: 1082.2100 - val_FP: 23.7900 - val_FN: 41.2100\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0381 - Accuracy: 0.9868 - Precision: 0.9635 - Recall: 0.9592 - TP: 3234.4399 - TN: 5549.0000 - FP: 98.0000 - FN: 137.5600 - val_loss: 0.0831 - val_Accuracy: 0.9759 - val_Precision: 0.9611 - val_Recall: 0.9483 - val_TP: 762.4300 - val_TN: 1081.6300 - val_FP: 24.3700 - val_FN: 41.5700\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0383 - Accuracy: 0.9864 - Precision: 0.9636 - Recall: 0.9593 - TP: 3234.8501 - TN: 5549.5298 - FP: 97.4700 - FN: 137.1500 - val_loss: 0.0817 - val_Accuracy: 0.9764 - val_Precision: 0.9639 - val_Recall: 0.9475 - val_TP: 761.8200 - val_TN: 1084.1200 - val_FP: 21.8800 - val_FN: 42.1800\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0386 - Accuracy: 0.9867 - Precision: 0.9642 - Recall: 0.9586 - TP: 3232.4199 - TN: 5551.8701 - FP: 95.1300 - FN: 139.5800 - val_loss: 0.0829 - val_Accuracy: 0.9759 - val_Precision: 0.9606 - val_Recall: 0.9487 - val_TP: 762.7200 - val_TN: 1081.1300 - val_FP: 24.8700 - val_FN: 41.2800\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0389 - Accuracy: 0.9864 - Precision: 0.9636 - Recall: 0.9590 - TP: 3233.6899 - TN: 5549.6099 - FP: 97.3900 - FN: 138.3100 - val_loss: 0.0821 - val_Accuracy: 0.9754 - val_Precision: 0.9616 - val_Recall: 0.9486 - val_TP: 762.6400 - val_TN: 1082.0500 - val_FP: 23.9500 - val_FN: 41.3600\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0398 - Accuracy: 0.9870 - Precision: 0.9638 - Recall: 0.9595 - TP: 3235.2900 - TN: 5550.3701 - FP: 96.6300 - FN: 136.7100 - val_loss: 0.0819 - val_Accuracy: 0.9764 - val_Precision: 0.9615 - val_Recall: 0.9490 - val_TP: 762.9700 - val_TN: 1081.9600 - val_FP: 24.0400 - val_FN: 41.0300\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0380 - Accuracy: 0.9869 - Precision: 0.9647 - Recall: 0.9593 - TP: 3234.6001 - TN: 5553.6899 - FP: 93.3100 - FN: 137.4000 - val_loss: 0.0833 - val_Accuracy: 0.9754 - val_Precision: 0.9605 - val_Recall: 0.9488 - val_TP: 762.8200 - val_TN: 1081.1200 - val_FP: 24.8800 - val_FN: 41.1800\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0377 - Accuracy: 0.9866 - Precision: 0.9639 - Recall: 0.9588 - TP: 3232.9600 - TN: 5550.5098 - FP: 96.4900 - FN: 139.0400 - val_loss: 0.0816 - val_Accuracy: 0.9764 - val_Precision: 0.9612 - val_Recall: 0.9493 - val_TP: 763.2100 - val_TN: 1081.6300 - val_FP: 24.3700 - val_FN: 40.7900\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0385 - Accuracy: 0.9871 - Precision: 0.9636 - Recall: 0.9596 - TP: 3235.9099 - TN: 5549.3301 - FP: 97.6700 - FN: 136.0900 - val_loss: 0.0818 - val_Accuracy: 0.9775 - val_Precision: 0.9636 - val_Recall: 0.9480 - val_TP: 762.1900 - val_TN: 1083.7900 - val_FP: 22.2100 - val_FN: 41.8100\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0374 - Accuracy: 0.9877 - Precision: 0.9639 - Recall: 0.9601 - TP: 3237.3101 - TN: 5550.2500 - FP: 96.7500 - FN: 134.6900 - val_loss: 0.0824 - val_Accuracy: 0.9775 - val_Precision: 0.9654 - val_Recall: 0.9467 - val_TP: 761.1400 - val_TN: 1085.4200 - val_FP: 20.5800 - val_FN: 42.8600\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0387 - Accuracy: 0.9871 - Precision: 0.9645 - Recall: 0.9588 - TP: 3232.9700 - TN: 5552.9102 - FP: 94.0900 - FN: 139.0300 - val_loss: 0.0836 - val_Accuracy: 0.9754 - val_Precision: 0.9610 - val_Recall: 0.9486 - val_TP: 762.6400 - val_TN: 1081.5699 - val_FP: 24.4300 - val_FN: 41.3600\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0376 - Accuracy: 0.9869 - Precision: 0.9644 - Recall: 0.9593 - TP: 3234.6101 - TN: 5552.3599 - FP: 94.6400 - FN: 137.3900 - val_loss: 0.0826 - val_Accuracy: 0.9754 - val_Precision: 0.9614 - val_Recall: 0.9488 - val_TP: 762.8600 - val_TN: 1081.8800 - val_FP: 24.1200 - val_FN: 41.1400\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0391 - Accuracy: 0.9866 - Precision: 0.9638 - Recall: 0.9590 - TP: 3233.6599 - TN: 5550.3701 - FP: 96.6300 - FN: 138.3400 - val_loss: 0.0821 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9482 - val_TP: 762.3900 - val_TN: 1083.4900 - val_FP: 22.5100 - val_FN: 41.6100\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0378 - Accuracy: 0.9872 - Precision: 0.9642 - Recall: 0.9596 - TP: 3235.6799 - TN: 5551.3701 - FP: 95.6300 - FN: 136.3200 - val_loss: 0.0822 - val_Accuracy: 0.9764 - val_Precision: 0.9616 - val_Recall: 0.9491 - val_TP: 763.0500 - val_TN: 1082.0500 - val_FP: 23.9500 - val_FN: 40.9500\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0370 - Accuracy: 0.9868 - Precision: 0.9643 - Recall: 0.9594 - TP: 3235.0500 - TN: 5552.2100 - FP: 94.7900 - FN: 136.9500 - val_loss: 0.0850 - val_Accuracy: 0.9749 - val_Precision: 0.9594 - val_Recall: 0.9488 - val_TP: 762.8400 - val_TN: 1079.9800 - val_FP: 26.0200 - val_FN: 41.1600\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0384 - Accuracy: 0.9870 - Precision: 0.9638 - Recall: 0.9596 - TP: 3235.9099 - TN: 5550.0898 - FP: 96.9100 - FN: 136.0900 - val_loss: 0.0840 - val_Accuracy: 0.9759 - val_Precision: 0.9620 - val_Recall: 0.9479 - val_TP: 762.1300 - val_TN: 1082.4700 - val_FP: 23.5300 - val_FN: 41.8700\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0376 - Accuracy: 0.9869 - Precision: 0.9639 - Recall: 0.9595 - TP: 3235.5200 - TN: 5550.7002 - FP: 96.3000 - FN: 136.4800 - val_loss: 0.0838 - val_Accuracy: 0.9759 - val_Precision: 0.9619 - val_Recall: 0.9481 - val_TP: 762.2800 - val_TN: 1082.3700 - val_FP: 23.6300 - val_FN: 41.7200\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0411 - Accuracy: 0.9863 - Precision: 0.9635 - Recall: 0.9592 - TP: 3234.5300 - TN: 5549.1602 - FP: 97.8400 - FN: 137.4700 - val_loss: 0.0840 - val_Accuracy: 0.9759 - val_Precision: 0.9594 - val_Recall: 0.9483 - val_TP: 762.4000 - val_TN: 1079.8600 - val_FP: 26.1400 - val_FN: 41.6000\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0388 - Accuracy: 0.9867 - Precision: 0.9634 - Recall: 0.9593 - TP: 3234.6899 - TN: 5548.6499 - FP: 98.3500 - FN: 137.3100 - val_loss: 0.0818 - val_Accuracy: 0.9770 - val_Precision: 0.9643 - val_Recall: 0.9471 - val_TP: 761.4800 - val_TN: 1084.4500 - val_FP: 21.5500 - val_FN: 42.5200\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0387 - Accuracy: 0.9870 - Precision: 0.9643 - Recall: 0.9585 - TP: 3232.0901 - TN: 5552.2402 - FP: 94.7600 - FN: 139.9100 - val_loss: 0.0813 - val_Accuracy: 0.9764 - val_Precision: 0.9620 - val_Recall: 0.9486 - val_TP: 762.6900 - val_TN: 1082.4100 - val_FP: 23.5900 - val_FN: 41.3100\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0400 - Accuracy: 0.9860 - Precision: 0.9630 - Recall: 0.9586 - TP: 3232.4399 - TN: 5547.5400 - FP: 99.4600 - FN: 139.5600 - val_loss: 0.0826 - val_Accuracy: 0.9759 - val_Precision: 0.9631 - val_Recall: 0.9472 - val_TP: 761.5600 - val_TN: 1083.4200 - val_FP: 22.5800 - val_FN: 42.4400\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0381 - Accuracy: 0.9869 - Precision: 0.9640 - Recall: 0.9589 - TP: 3233.3799 - TN: 5551.0000 - FP: 96.0000 - FN: 138.6200 - val_loss: 0.0830 - val_Accuracy: 0.9749 - val_Precision: 0.9617 - val_Recall: 0.9480 - val_TP: 762.1600 - val_TN: 1082.1600 - val_FP: 23.8400 - val_FN: 41.8400\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0387 - Accuracy: 0.9869 - Precision: 0.9640 - Recall: 0.9591 - TP: 3234.0400 - TN: 5550.8198 - FP: 96.1800 - FN: 137.9600 - val_loss: 0.0814 - val_Accuracy: 0.9770 - val_Precision: 0.9642 - val_Recall: 0.9475 - val_TP: 761.8000 - val_TN: 1084.3800 - val_FP: 21.6200 - val_FN: 42.2000\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0394 - Accuracy: 0.9869 - Precision: 0.9635 - Recall: 0.9588 - TP: 3232.9500 - TN: 5548.9800 - FP: 98.0200 - FN: 139.0500 - val_loss: 0.0828 - val_Accuracy: 0.9754 - val_Precision: 0.9618 - val_Recall: 0.9479 - val_TP: 762.1400 - val_TN: 1082.2500 - val_FP: 23.7500 - val_FN: 41.8600\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0394 - Accuracy: 0.9867 - Precision: 0.9637 - Recall: 0.9587 - TP: 3232.6399 - TN: 5549.8198 - FP: 97.1800 - FN: 139.3600 - val_loss: 0.0813 - val_Accuracy: 0.9764 - val_Precision: 0.9631 - val_Recall: 0.9485 - val_TP: 762.5600 - val_TN: 1083.3700 - val_FP: 22.6300 - val_FN: 41.4400\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0392 - Accuracy: 0.9860 - Precision: 0.9631 - Recall: 0.9588 - TP: 3233.0200 - TN: 5547.6401 - FP: 99.3600 - FN: 138.9800 - val_loss: 0.0830 - val_Accuracy: 0.9754 - val_Precision: 0.9620 - val_Recall: 0.9479 - val_TP: 762.1500 - val_TN: 1082.4100 - val_FP: 23.5900 - val_FN: 41.8500\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0377 - Accuracy: 0.9871 - Precision: 0.9644 - Recall: 0.9590 - TP: 3233.8000 - TN: 5552.1499 - FP: 94.8500 - FN: 138.2000 - val_loss: 0.0822 - val_Accuracy: 0.9764 - val_Precision: 0.9620 - val_Recall: 0.9485 - val_TP: 762.5700 - val_TN: 1082.4399 - val_FP: 23.5600 - val_FN: 41.4300\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0390 - Accuracy: 0.9864 - Precision: 0.9639 - Recall: 0.9588 - TP: 3233.2200 - TN: 5550.5400 - FP: 96.4600 - FN: 138.7800 - val_loss: 0.0821 - val_Accuracy: 0.9764 - val_Precision: 0.9615 - val_Recall: 0.9489 - val_TP: 762.9500 - val_TN: 1081.9100 - val_FP: 24.0900 - val_FN: 41.0500\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0386 - Accuracy: 0.9866 - Precision: 0.9641 - Recall: 0.9592 - TP: 3234.5500 - TN: 5551.5000 - FP: 95.5000 - FN: 137.4500 - val_loss: 0.0843 - val_Accuracy: 0.9749 - val_Precision: 0.9594 - val_Recall: 0.9488 - val_TP: 762.8200 - val_TN: 1079.9900 - val_FP: 26.0100 - val_FN: 41.1800\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0385 - Accuracy: 0.9860 - Precision: 0.9641 - Recall: 0.9587 - TP: 3232.7200 - TN: 5551.6299 - FP: 95.3700 - FN: 139.2800 - val_loss: 0.0851 - val_Accuracy: 0.9754 - val_Precision: 0.9570 - val_Recall: 0.9497 - val_TP: 763.5900 - val_TN: 1077.6700 - val_FP: 28.3300 - val_FN: 40.4100\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0384 - Accuracy: 0.9865 - Precision: 0.9630 - Recall: 0.9592 - TP: 3234.3999 - TN: 5547.3799 - FP: 99.6200 - FN: 137.6000 - val_loss: 0.0831 - val_Accuracy: 0.9754 - val_Precision: 0.9601 - val_Recall: 0.9493 - val_TP: 763.2200 - val_TN: 1080.7200 - val_FP: 25.2800 - val_FN: 40.7800\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0388 - Accuracy: 0.9866 - Precision: 0.9632 - Recall: 0.9594 - TP: 3235.2500 - TN: 5547.8101 - FP: 99.1900 - FN: 136.7500 - val_loss: 0.0836 - val_Accuracy: 0.9759 - val_Precision: 0.9632 - val_Recall: 0.9472 - val_TP: 761.5500 - val_TN: 1083.4800 - val_FP: 22.5200 - val_FN: 42.4500\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0379 - Accuracy: 0.9867 - Precision: 0.9647 - Recall: 0.9589 - TP: 3233.4099 - TN: 5553.9199 - FP: 93.0800 - FN: 138.5900 - val_loss: 0.0834 - val_Accuracy: 0.9749 - val_Precision: 0.9607 - val_Recall: 0.9489 - val_TP: 762.8800 - val_TN: 1081.2400 - val_FP: 24.7600 - val_FN: 41.1200\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0396 - Accuracy: 0.9864 - Precision: 0.9625 - Recall: 0.9592 - TP: 3234.5500 - TN: 5545.6899 - FP: 101.3100 - FN: 137.4500 - val_loss: 0.0837 - val_Accuracy: 0.9759 - val_Precision: 0.9636 - val_Recall: 0.9469 - val_TP: 761.3400 - val_TN: 1083.8500 - val_FP: 22.1500 - val_FN: 42.6600\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0380 - Accuracy: 0.9868 - Precision: 0.9643 - Recall: 0.9592 - TP: 3234.5500 - TN: 5552.2500 - FP: 94.7500 - FN: 137.4500 - val_loss: 0.0826 - val_Accuracy: 0.9780 - val_Precision: 0.9657 - val_Recall: 0.9468 - val_TP: 761.2500 - val_TN: 1085.6899 - val_FP: 20.3100 - val_FN: 42.7500\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0390 - Accuracy: 0.9877 - Precision: 0.9639 - Recall: 0.9592 - TP: 3234.4500 - TN: 5550.7900 - FP: 96.2100 - FN: 137.5500 - val_loss: 0.0833 - val_Accuracy: 0.9764 - val_Precision: 0.9627 - val_Recall: 0.9479 - val_TP: 762.1000 - val_TN: 1083.0800 - val_FP: 22.9200 - val_FN: 41.9000\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0380 - Accuracy: 0.9869 - Precision: 0.9639 - Recall: 0.9597 - TP: 3236.1399 - TN: 5550.9302 - FP: 96.0700 - FN: 135.8600 - val_loss: 0.0825 - val_Accuracy: 0.9770 - val_Precision: 0.9640 - val_Recall: 0.9479 - val_TP: 762.1200 - val_TN: 1084.1801 - val_FP: 21.8200 - val_FN: 41.8800\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0380 - Accuracy: 0.9875 - Precision: 0.9642 - Recall: 0.9594 - TP: 3235.0400 - TN: 5552.0498 - FP: 94.9500 - FN: 136.9600 - val_loss: 0.0829 - val_Accuracy: 0.9775 - val_Precision: 0.9648 - val_Recall: 0.9473 - val_TP: 761.6200 - val_TN: 1084.8700 - val_FP: 21.1300 - val_FN: 42.3800\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0382 - Accuracy: 0.9868 - Precision: 0.9643 - Recall: 0.9596 - TP: 3235.6599 - TN: 5552.2202 - FP: 94.7800 - FN: 136.3400 - val_loss: 0.0839 - val_Accuracy: 0.9759 - val_Precision: 0.9630 - val_Recall: 0.9475 - val_TP: 761.8200 - val_TN: 1083.3600 - val_FP: 22.6400 - val_FN: 42.1800\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0376 - Accuracy: 0.9874 - Precision: 0.9645 - Recall: 0.9597 - TP: 3236.0300 - TN: 5553.0298 - FP: 93.9700 - FN: 135.9700 - val_loss: 0.0833 - val_Accuracy: 0.9764 - val_Precision: 0.9622 - val_Recall: 0.9486 - val_TP: 762.6700 - val_TN: 1082.6000 - val_FP: 23.4000 - val_FN: 41.3300\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0375 - Accuracy: 0.9866 - Precision: 0.9648 - Recall: 0.9594 - TP: 3235.0901 - TN: 5554.1201 - FP: 92.8800 - FN: 136.9100 - val_loss: 0.0837 - val_Accuracy: 0.9754 - val_Precision: 0.9600 - val_Recall: 0.9497 - val_TP: 763.5400 - val_TN: 1080.6600 - val_FP: 25.3400 - val_FN: 40.4600\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0374 - Accuracy: 0.9868 - Precision: 0.9640 - Recall: 0.9598 - TP: 3236.6001 - TN: 5551.1699 - FP: 95.8300 - FN: 135.4000 - val_loss: 0.0868 - val_Accuracy: 0.9749 - val_Precision: 0.9587 - val_Recall: 0.9486 - val_TP: 762.6900 - val_TN: 1079.2500 - val_FP: 26.7500 - val_FN: 41.3100\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0376 - Accuracy: 0.9878 - Precision: 0.9647 - Recall: 0.9599 - TP: 3236.8000 - TN: 5553.5898 - FP: 93.4100 - FN: 135.2000 - val_loss: 0.0828 - val_Accuracy: 0.9764 - val_Precision: 0.9619 - val_Recall: 0.9491 - val_TP: 763.0800 - val_TN: 1082.3900 - val_FP: 23.6100 - val_FN: 40.9200\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0382 - Accuracy: 0.9871 - Precision: 0.9642 - Recall: 0.9594 - TP: 3235.1799 - TN: 5552.0400 - FP: 94.9600 - FN: 136.8200 - val_loss: 0.0846 - val_Accuracy: 0.9754 - val_Precision: 0.9593 - val_Recall: 0.9498 - val_TP: 763.6500 - val_TN: 1080.0800 - val_FP: 25.9200 - val_FN: 40.3500\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0383 - Accuracy: 0.9865 - Precision: 0.9641 - Recall: 0.9595 - TP: 3235.4099 - TN: 5551.1699 - FP: 95.8300 - FN: 136.5900 - val_loss: 0.0829 - val_Accuracy: 0.9764 - val_Precision: 0.9612 - val_Recall: 0.9495 - val_TP: 763.4000 - val_TN: 1081.7200 - val_FP: 24.2800 - val_FN: 40.6000\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0399 - Accuracy: 0.9866 - Precision: 0.9638 - Recall: 0.9590 - TP: 3233.8000 - TN: 5550.4702 - FP: 96.5300 - FN: 138.2000 - val_loss: 0.0815 - val_Accuracy: 0.9764 - val_Precision: 0.9639 - val_Recall: 0.9480 - val_TP: 762.2200 - val_TN: 1084.1100 - val_FP: 21.8900 - val_FN: 41.7800\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0388 - Accuracy: 0.9868 - Precision: 0.9644 - Recall: 0.9590 - TP: 3233.8401 - TN: 5552.3599 - FP: 94.6400 - FN: 138.1600 - val_loss: 0.0813 - val_Accuracy: 0.9764 - val_Precision: 0.9612 - val_Recall: 0.9498 - val_TP: 763.6300 - val_TN: 1081.6400 - val_FP: 24.3600 - val_FN: 40.3700\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0402 - Accuracy: 0.9863 - Precision: 0.9632 - Recall: 0.9589 - TP: 3233.4099 - TN: 5548.3701 - FP: 98.6300 - FN: 138.5900 - val_loss: 0.0813 - val_Accuracy: 0.9764 - val_Precision: 0.9627 - val_Recall: 0.9489 - val_TP: 762.9100 - val_TN: 1083.0200 - val_FP: 22.9800 - val_FN: 41.0900\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0380 - Accuracy: 0.9867 - Precision: 0.9639 - Recall: 0.9599 - TP: 3236.8401 - TN: 5550.6899 - FP: 96.3100 - FN: 135.1600 - val_loss: 0.0999 - val_Accuracy: 0.9723 - val_Precision: 0.9413 - val_Recall: 0.9478 - val_TP: 762.0600 - val_TN: 1063.1200 - val_FP: 42.8800 - val_FN: 41.9400\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0400 - Accuracy: 0.9865 - Precision: 0.9640 - Recall: 0.9585 - TP: 3231.9900 - TN: 5551.2900 - FP: 95.7100 - FN: 140.0100 - val_loss: 0.0819 - val_Accuracy: 0.9770 - val_Precision: 0.9627 - val_Recall: 0.9485 - val_TP: 762.5900 - val_TN: 1083.0800 - val_FP: 22.9200 - val_FN: 41.4100\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0381 - Accuracy: 0.9866 - Precision: 0.9638 - Recall: 0.9597 - TP: 3236.2700 - TN: 5550.4199 - FP: 96.5800 - FN: 135.7300 - val_loss: 0.0823 - val_Accuracy: 0.9764 - val_Precision: 0.9640 - val_Recall: 0.9476 - val_TP: 761.8500 - val_TN: 1084.1801 - val_FP: 21.8200 - val_FN: 42.1500\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0380 - Accuracy: 0.9870 - Precision: 0.9637 - Recall: 0.9594 - TP: 3235.1699 - TN: 5549.7002 - FP: 97.3000 - FN: 136.8300 - val_loss: 0.0866 - val_Accuracy: 0.9754 - val_Precision: 0.9594 - val_Recall: 0.9477 - val_TP: 761.9800 - val_TN: 1079.9301 - val_FP: 26.0700 - val_FN: 42.0200\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0381 - Accuracy: 0.9878 - Precision: 0.9639 - Recall: 0.9593 - TP: 3234.8899 - TN: 5550.3901 - FP: 96.6100 - FN: 137.1100 - val_loss: 0.0848 - val_Accuracy: 0.9754 - val_Precision: 0.9612 - val_Recall: 0.9479 - val_TP: 762.1400 - val_TN: 1081.7600 - val_FP: 24.2400 - val_FN: 41.8600\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0384 - Accuracy: 0.9872 - Precision: 0.9643 - Recall: 0.9590 - TP: 3233.7300 - TN: 5552.7500 - FP: 94.2500 - FN: 138.2700 - val_loss: 0.0831 - val_Accuracy: 0.9754 - val_Precision: 0.9623 - val_Recall: 0.9481 - val_TP: 762.2500 - val_TN: 1082.7000 - val_FP: 23.3000 - val_FN: 41.7500\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0380 - Accuracy: 0.9869 - Precision: 0.9644 - Recall: 0.9596 - TP: 3235.8799 - TN: 5552.3398 - FP: 94.6600 - FN: 136.1200 - val_loss: 0.0838 - val_Accuracy: 0.9754 - val_Precision: 0.9622 - val_Recall: 0.9480 - val_TP: 762.1600 - val_TN: 1082.6801 - val_FP: 23.3200 - val_FN: 41.8400\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0373 - Accuracy: 0.9868 - Precision: 0.9640 - Recall: 0.9596 - TP: 3235.6699 - TN: 5550.9102 - FP: 96.0900 - FN: 136.3300 - val_loss: 0.0821 - val_Accuracy: 0.9770 - val_Precision: 0.9638 - val_Recall: 0.9483 - val_TP: 762.4600 - val_TN: 1083.9800 - val_FP: 22.0200 - val_FN: 41.5400\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0408 - Accuracy: 0.9861 - Precision: 0.9632 - Recall: 0.9591 - TP: 3234.2000 - TN: 5548.2998 - FP: 98.7000 - FN: 137.8000 - val_loss: 0.0839 - val_Accuracy: 0.9754 - val_Precision: 0.9619 - val_Recall: 0.9481 - val_TP: 762.2900 - val_TN: 1082.3600 - val_FP: 23.6400 - val_FN: 41.7100\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0372 - Accuracy: 0.9869 - Precision: 0.9644 - Recall: 0.9595 - TP: 3235.2700 - TN: 5552.5200 - FP: 94.4800 - FN: 136.7300 - val_loss: 0.0835 - val_Accuracy: 0.9775 - val_Precision: 0.9637 - val_Recall: 0.9474 - val_TP: 761.7400 - val_TN: 1083.9800 - val_FP: 22.0200 - val_FN: 42.2600\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0395 - Accuracy: 0.9865 - Precision: 0.9639 - Recall: 0.9589 - TP: 3233.3999 - TN: 5550.8799 - FP: 96.1200 - FN: 138.6000 - val_loss: 0.0835 - val_Accuracy: 0.9754 - val_Precision: 0.9612 - val_Recall: 0.9489 - val_TP: 762.9000 - val_TN: 1081.7700 - val_FP: 24.2300 - val_FN: 41.1000\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0376 - Accuracy: 0.9866 - Precision: 0.9642 - Recall: 0.9592 - TP: 3234.4600 - TN: 5552.0498 - FP: 94.9500 - FN: 137.5400 - val_loss: 0.0842 - val_Accuracy: 0.9749 - val_Precision: 0.9591 - val_Recall: 0.9498 - val_TP: 763.6600 - val_TN: 1079.8400 - val_FP: 26.1600 - val_FN: 40.3400\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0374 - Accuracy: 0.9869 - Precision: 0.9636 - Recall: 0.9602 - TP: 3237.7400 - TN: 5549.5498 - FP: 97.4500 - FN: 134.2600 - val_loss: 0.0837 - val_Accuracy: 0.9754 - val_Precision: 0.9623 - val_Recall: 0.9483 - val_TP: 762.4100 - val_TN: 1082.7300 - val_FP: 23.2700 - val_FN: 41.5900\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0390 - Accuracy: 0.9876 - Precision: 0.9645 - Recall: 0.9595 - TP: 3235.4399 - TN: 5553.1802 - FP: 93.8200 - FN: 136.5600 - val_loss: 0.0832 - val_Accuracy: 0.9770 - val_Precision: 0.9631 - val_Recall: 0.9483 - val_TP: 762.4500 - val_TN: 1083.4500 - val_FP: 22.5500 - val_FN: 41.5500\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0373 - Accuracy: 0.9868 - Precision: 0.9645 - Recall: 0.9595 - TP: 3235.5500 - TN: 5552.6802 - FP: 94.3200 - FN: 136.4500 - val_loss: 0.0832 - val_Accuracy: 0.9770 - val_Precision: 0.9623 - val_Recall: 0.9487 - val_TP: 762.7900 - val_TN: 1082.7100 - val_FP: 23.2900 - val_FN: 41.2100\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0381 - Accuracy: 0.9875 - Precision: 0.9645 - Recall: 0.9593 - TP: 3234.8899 - TN: 5552.9800 - FP: 94.0200 - FN: 137.1100 - val_loss: 0.0838 - val_Accuracy: 0.9764 - val_Precision: 0.9624 - val_Recall: 0.9484 - val_TP: 762.5300 - val_TN: 1082.7700 - val_FP: 23.2300 - val_FN: 41.4700\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0376 - Accuracy: 0.9874 - Precision: 0.9642 - Recall: 0.9602 - TP: 3237.7900 - TN: 5551.8101 - FP: 95.1900 - FN: 134.2100 - val_loss: 0.0829 - val_Accuracy: 0.9775 - val_Precision: 0.9637 - val_Recall: 0.9485 - val_TP: 762.5600 - val_TN: 1083.9500 - val_FP: 22.0500 - val_FN: 41.4400\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0380 - Accuracy: 0.9876 - Precision: 0.9644 - Recall: 0.9597 - TP: 3236.0400 - TN: 5552.8398 - FP: 94.1600 - FN: 135.9600 - val_loss: 0.0846 - val_Accuracy: 0.9770 - val_Precision: 0.9622 - val_Recall: 0.9481 - val_TP: 762.2500 - val_TN: 1082.6600 - val_FP: 23.3400 - val_FN: 41.7500\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0384 - Accuracy: 0.9876 - Precision: 0.9644 - Recall: 0.9594 - TP: 3235.2400 - TN: 5552.5601 - FP: 94.4400 - FN: 136.7600 - val_loss: 0.0842 - val_Accuracy: 0.9754 - val_Precision: 0.9608 - val_Recall: 0.9491 - val_TP: 763.0700 - val_TN: 1081.4200 - val_FP: 24.5800 - val_FN: 40.9300\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 6ms/step - loss: 0.0408 - Accuracy: 0.9861 - Precision: 0.9635 - Recall: 0.9595 - TP: 3235.4099 - TN: 5549.8398 - FP: 97.1600 - FN: 136.5900 - val_loss: 0.0819 - val_Accuracy: 0.9764 - val_Precision: 0.9645 - val_Recall: 0.9476 - val_TP: 761.8700 - val_TN: 1084.6500 - val_FP: 21.3500 - val_FN: 42.1300\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0386 - Accuracy: 0.9860 - Precision: 0.9644 - Recall: 0.9593 - TP: 3234.7200 - TN: 5552.5601 - FP: 94.4400 - FN: 137.2800 - val_loss: 0.0820 - val_Accuracy: 0.9764 - val_Precision: 0.9642 - val_Recall: 0.9477 - val_TP: 761.9700 - val_TN: 1084.4000 - val_FP: 21.6000 - val_FN: 42.0300\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0378 - Accuracy: 0.9866 - Precision: 0.9645 - Recall: 0.9595 - TP: 3235.2700 - TN: 5552.9302 - FP: 94.0700 - FN: 136.7300 - val_loss: 0.0816 - val_Accuracy: 0.9770 - val_Precision: 0.9628 - val_Recall: 0.9487 - val_TP: 762.7600 - val_TN: 1083.1200 - val_FP: 22.8800 - val_FN: 41.2400\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0397 - Accuracy: 0.9864 - Precision: 0.9635 - Recall: 0.9592 - TP: 3234.2900 - TN: 5549.2500 - FP: 97.7500 - FN: 137.7100 - val_loss: 0.0833 - val_Accuracy: 0.9754 - val_Precision: 0.9612 - val_Recall: 0.9485 - val_TP: 762.5800 - val_TN: 1081.7700 - val_FP: 24.2300 - val_FN: 41.4200\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0375 - Accuracy: 0.9869 - Precision: 0.9643 - Recall: 0.9597 - TP: 3236.1001 - TN: 5551.8901 - FP: 95.1100 - FN: 135.9000 - val_loss: 0.0836 - val_Accuracy: 0.9754 - val_Precision: 0.9616 - val_Recall: 0.9482 - val_TP: 762.3800 - val_TN: 1082.1500 - val_FP: 23.8500 - val_FN: 41.6200\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0399 - Accuracy: 0.9865 - Precision: 0.9635 - Recall: 0.9586 - TP: 3232.2400 - TN: 5549.6499 - FP: 97.3500 - FN: 139.7600 - val_loss: 0.0829 - val_Accuracy: 0.9775 - val_Precision: 0.9635 - val_Recall: 0.9474 - val_TP: 761.7400 - val_TN: 1083.7500 - val_FP: 22.2500 - val_FN: 42.2600\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0378 - Accuracy: 0.9869 - Precision: 0.9638 - Recall: 0.9588 - TP: 3232.9800 - TN: 5550.4102 - FP: 96.5900 - FN: 139.0200 - val_loss: 0.0823 - val_Accuracy: 0.9764 - val_Precision: 0.9616 - val_Recall: 0.9491 - val_TP: 763.1000 - val_TN: 1082.0300 - val_FP: 23.9700 - val_FN: 40.9000\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0382 - Accuracy: 0.9869 - Precision: 0.9635 - Recall: 0.9595 - TP: 3235.5300 - TN: 5549.1099 - FP: 97.8900 - FN: 136.4700 - val_loss: 0.0827 - val_Accuracy: 0.9764 - val_Precision: 0.9634 - val_Recall: 0.9479 - val_TP: 762.1200 - val_TN: 1083.6700 - val_FP: 22.3300 - val_FN: 41.8800\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0386 - Accuracy: 0.9868 - Precision: 0.9645 - Recall: 0.9590 - TP: 3233.6201 - TN: 5553.1899 - FP: 93.8100 - FN: 138.3800 - val_loss: 0.0840 - val_Accuracy: 0.9754 - val_Precision: 0.9611 - val_Recall: 0.9486 - val_TP: 762.6600 - val_TN: 1081.6899 - val_FP: 24.3100 - val_FN: 41.3400\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0379 - Accuracy: 0.9872 - Precision: 0.9640 - Recall: 0.9596 - TP: 3235.6799 - TN: 5550.8599 - FP: 96.1400 - FN: 136.3200 - val_loss: 0.0929 - val_Accuracy: 0.9728 - val_Precision: 0.9511 - val_Recall: 0.9486 - val_TP: 762.6400 - val_TN: 1072.0500 - val_FP: 33.9500 - val_FN: 41.3600\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0398 - Accuracy: 0.9868 - Precision: 0.9631 - Recall: 0.9591 - TP: 3234.2500 - TN: 5547.4102 - FP: 99.5900 - FN: 137.7500 - val_loss: 0.0851 - val_Accuracy: 0.9759 - val_Precision: 0.9628 - val_Recall: 0.9472 - val_TP: 761.5100 - val_TN: 1083.1801 - val_FP: 22.8200 - val_FN: 42.4900\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0382 - Accuracy: 0.9867 - Precision: 0.9646 - Recall: 0.9597 - TP: 3236.0100 - TN: 5553.6201 - FP: 93.3800 - FN: 135.9900 - val_loss: 0.0852 - val_Accuracy: 0.9754 - val_Precision: 0.9620 - val_Recall: 0.9477 - val_TP: 761.9500 - val_TN: 1082.4700 - val_FP: 23.5300 - val_FN: 42.0500\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0397 - Accuracy: 0.9869 - Precision: 0.9638 - Recall: 0.9597 - TP: 3236.1001 - TN: 5550.8198 - FP: 96.1800 - FN: 135.9000 - val_loss: 0.0849 - val_Accuracy: 0.9764 - val_Precision: 0.9633 - val_Recall: 0.9470 - val_TP: 761.3500 - val_TN: 1083.6200 - val_FP: 22.3800 - val_FN: 42.6500\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0389 - Accuracy: 0.9867 - Precision: 0.9651 - Recall: 0.9584 - TP: 3231.7300 - TN: 5555.4800 - FP: 91.5200 - FN: 140.2700 - val_loss: 0.0841 - val_Accuracy: 0.9754 - val_Precision: 0.9593 - val_Recall: 0.9499 - val_TP: 763.7500 - val_TN: 1080.0300 - val_FP: 25.9700 - val_FN: 40.2500\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0380 - Accuracy: 0.9864 - Precision: 0.9632 - Recall: 0.9610 - TP: 3240.3601 - TN: 5548.2998 - FP: 98.7000 - FN: 131.6400 - val_loss: 0.0829 - val_Accuracy: 0.9770 - val_Precision: 0.9644 - val_Recall: 0.9477 - val_TP: 761.9300 - val_TN: 1084.5900 - val_FP: 21.4100 - val_FN: 42.0700\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0386 - Accuracy: 0.9872 - Precision: 0.9646 - Recall: 0.9589 - TP: 3233.3701 - TN: 5554.0400 - FP: 92.9600 - FN: 138.6300 - val_loss: 0.0852 - val_Accuracy: 0.9754 - val_Precision: 0.9602 - val_Recall: 0.9490 - val_TP: 762.9700 - val_TN: 1080.9301 - val_FP: 25.0700 - val_FN: 41.0300\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0372 - Accuracy: 0.9870 - Precision: 0.9644 - Recall: 0.9597 - TP: 3236.2200 - TN: 5552.6401 - FP: 94.3600 - FN: 135.7800 - val_loss: 0.0834 - val_Accuracy: 0.9754 - val_Precision: 0.9612 - val_Recall: 0.9493 - val_TP: 763.2100 - val_TN: 1081.7900 - val_FP: 24.2100 - val_FN: 40.7900\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0371 - Accuracy: 0.9872 - Precision: 0.9644 - Recall: 0.9600 - TP: 3237.1299 - TN: 5552.6001 - FP: 94.4000 - FN: 134.8700 - val_loss: 0.0857 - val_Accuracy: 0.9754 - val_Precision: 0.9588 - val_Recall: 0.9495 - val_TP: 763.4000 - val_TN: 1079.4700 - val_FP: 26.5300 - val_FN: 40.6000\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0377 - Accuracy: 0.9874 - Precision: 0.9640 - Recall: 0.9604 - TP: 3238.3701 - TN: 5551.1401 - FP: 95.8600 - FN: 133.6300 - val_loss: 0.0835 - val_Accuracy: 0.9775 - val_Precision: 0.9654 - val_Recall: 0.9471 - val_TP: 761.4700 - val_TN: 1085.4700 - val_FP: 20.5300 - val_FN: 42.5300\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0383 - Accuracy: 0.9877 - Precision: 0.9656 - Recall: 0.9600 - TP: 3236.9600 - TN: 5557.5898 - FP: 89.4100 - FN: 135.0400 - val_loss: 0.0838 - val_Accuracy: 0.9754 - val_Precision: 0.9593 - val_Recall: 0.9505 - val_TP: 764.1900 - val_TN: 1080.0200 - val_FP: 25.9800 - val_FN: 39.8100\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0401 - Accuracy: 0.9866 - Precision: 0.9633 - Recall: 0.9595 - TP: 3235.5801 - TN: 5548.8101 - FP: 98.1900 - FN: 136.4200 - val_loss: 0.0836 - val_Accuracy: 0.9770 - val_Precision: 0.9621 - val_Recall: 0.9488 - val_TP: 762.8400 - val_TN: 1082.5601 - val_FP: 23.4400 - val_FN: 41.1600\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0372 - Accuracy: 0.9871 - Precision: 0.9641 - Recall: 0.9604 - TP: 3238.5000 - TN: 5551.4702 - FP: 95.5300 - FN: 133.5000 - val_loss: 0.0877 - val_Accuracy: 0.9759 - val_Precision: 0.9594 - val_Recall: 0.9480 - val_TP: 762.2100 - val_TN: 1080.0200 - val_FP: 25.9800 - val_FN: 41.7900\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0373 - Accuracy: 0.9865 - Precision: 0.9649 - Recall: 0.9595 - TP: 3235.3501 - TN: 5554.7002 - FP: 92.3000 - FN: 136.6500 - val_loss: 0.0836 - val_Accuracy: 0.9770 - val_Precision: 0.9620 - val_Recall: 0.9490 - val_TP: 762.9900 - val_TN: 1082.4800 - val_FP: 23.5200 - val_FN: 41.0100\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 4ms/step - loss: 0.0397 - Accuracy: 0.9860 - Precision: 0.9631 - Recall: 0.9592 - TP: 3234.3101 - TN: 5548.0698 - FP: 98.9300 - FN: 137.6900 - val_loss: 0.0813 - val_Accuracy: 0.9770 - val_Precision: 0.9628 - val_Recall: 0.9490 - val_TP: 763.0000 - val_TN: 1083.1000 - val_FP: 22.9000 - val_FN: 41.0000\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0389 - Accuracy: 0.9860 - Precision: 0.9640 - Recall: 0.9591 - TP: 3234.2100 - TN: 5551.2300 - FP: 95.7700 - FN: 137.7900 - val_loss: 0.0840 - val_Accuracy: 0.9754 - val_Precision: 0.9610 - val_Recall: 0.9484 - val_TP: 762.4900 - val_TN: 1081.6000 - val_FP: 24.4000 - val_FN: 41.5100\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0387 - Accuracy: 0.9869 - Precision: 0.9647 - Recall: 0.9589 - TP: 3233.3000 - TN: 5553.6099 - FP: 93.3900 - FN: 138.7000 - val_loss: 0.0831 - val_Accuracy: 0.9754 - val_Precision: 0.9600 - val_Recall: 0.9496 - val_TP: 763.4800 - val_TN: 1080.6400 - val_FP: 25.3600 - val_FN: 40.5200\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0384 - Accuracy: 0.9872 - Precision: 0.9638 - Recall: 0.9596 - TP: 3235.8501 - TN: 5550.2202 - FP: 96.7800 - FN: 136.1500 - val_loss: 0.0832 - val_Accuracy: 0.9754 - val_Precision: 0.9600 - val_Recall: 0.9495 - val_TP: 763.3700 - val_TN: 1080.6899 - val_FP: 25.3100 - val_FN: 40.6300\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0394 - Accuracy: 0.9860 - Precision: 0.9633 - Recall: 0.9587 - TP: 3232.8501 - TN: 5548.1802 - FP: 98.8200 - FN: 139.1500 - val_loss: 0.0915 - val_Accuracy: 0.9738 - val_Precision: 0.9538 - val_Recall: 0.9482 - val_TP: 762.3800 - val_TN: 1074.4900 - val_FP: 31.5100 - val_FN: 41.6200\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0385 - Accuracy: 0.9870 - Precision: 0.9639 - Recall: 0.9595 - TP: 3235.3401 - TN: 5550.8901 - FP: 96.1100 - FN: 136.6600 - val_loss: 0.0838 - val_Accuracy: 0.9754 - val_Precision: 0.9620 - val_Recall: 0.9480 - val_TP: 762.2300 - val_TN: 1082.4500 - val_FP: 23.5500 - val_FN: 41.7700\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0389 - Accuracy: 0.9864 - Precision: 0.9634 - Recall: 0.9597 - TP: 3236.0100 - TN: 5549.3501 - FP: 97.6500 - FN: 135.9900 - val_loss: 0.0831 - val_Accuracy: 0.9759 - val_Precision: 0.9626 - val_Recall: 0.9482 - val_TP: 762.3800 - val_TN: 1082.9600 - val_FP: 23.0400 - val_FN: 41.6200\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0375 - Accuracy: 0.9868 - Precision: 0.9645 - Recall: 0.9596 - TP: 3235.8999 - TN: 5552.9600 - FP: 94.0400 - FN: 136.1000 - val_loss: 0.0832 - val_Accuracy: 0.9764 - val_Precision: 0.9631 - val_Recall: 0.9479 - val_TP: 762.1500 - val_TN: 1083.4200 - val_FP: 22.5800 - val_FN: 41.8500\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0388 - Accuracy: 0.9866 - Precision: 0.9641 - Recall: 0.9590 - TP: 3233.5901 - TN: 5551.6001 - FP: 95.4000 - FN: 138.4100 - val_loss: 0.0831 - val_Accuracy: 0.9764 - val_Precision: 0.9619 - val_Recall: 0.9487 - val_TP: 762.7800 - val_TN: 1082.3800 - val_FP: 23.6200 - val_FN: 41.2200\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0382 - Accuracy: 0.9867 - Precision: 0.9639 - Recall: 0.9597 - TP: 3236.0300 - TN: 5550.7300 - FP: 96.2700 - FN: 135.9700 - val_loss: 0.0828 - val_Accuracy: 0.9775 - val_Precision: 0.9629 - val_Recall: 0.9487 - val_TP: 762.7800 - val_TN: 1083.2200 - val_FP: 22.7800 - val_FN: 41.2200\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0370 - Accuracy: 0.9874 - Precision: 0.9644 - Recall: 0.9601 - TP: 3237.5300 - TN: 5552.7002 - FP: 94.3000 - FN: 134.4700 - val_loss: 0.0844 - val_Accuracy: 0.9759 - val_Precision: 0.9625 - val_Recall: 0.9478 - val_TP: 762.0000 - val_TN: 1082.9399 - val_FP: 23.0600 - val_FN: 42.0000\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0377 - Accuracy: 0.9868 - Precision: 0.9645 - Recall: 0.9590 - TP: 3233.8899 - TN: 5552.7900 - FP: 94.2100 - FN: 138.1100 - val_loss: 0.0843 - val_Accuracy: 0.9759 - val_Precision: 0.9623 - val_Recall: 0.9479 - val_TP: 762.1100 - val_TN: 1082.7800 - val_FP: 23.2200 - val_FN: 41.8900\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0374 - Accuracy: 0.9869 - Precision: 0.9646 - Recall: 0.9597 - TP: 3236.1499 - TN: 5553.4102 - FP: 93.5900 - FN: 135.8500 - val_loss: 0.0856 - val_Accuracy: 0.9754 - val_Precision: 0.9586 - val_Recall: 0.9495 - val_TP: 763.4300 - val_TN: 1079.2700 - val_FP: 26.7300 - val_FN: 40.5700\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0382 - Accuracy: 0.9869 - Precision: 0.9638 - Recall: 0.9601 - TP: 3237.5000 - TN: 5550.2100 - FP: 96.7900 - FN: 134.5000 - val_loss: 0.0837 - val_Accuracy: 0.9770 - val_Precision: 0.9628 - val_Recall: 0.9482 - val_TP: 762.3400 - val_TN: 1083.2100 - val_FP: 22.7900 - val_FN: 41.6600\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0376 - Accuracy: 0.9870 - Precision: 0.9646 - Recall: 0.9595 - TP: 3235.3101 - TN: 5553.4600 - FP: 93.5400 - FN: 136.6900 - val_loss: 0.0869 - val_Accuracy: 0.9759 - val_Precision: 0.9589 - val_Recall: 0.9489 - val_TP: 762.9400 - val_TN: 1079.6300 - val_FP: 26.3700 - val_FN: 41.0600\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0387 - Accuracy: 0.9868 - Precision: 0.9641 - Recall: 0.9601 - TP: 3237.3799 - TN: 5551.5698 - FP: 95.4300 - FN: 134.6200 - val_loss: 0.0837 - val_Accuracy: 0.9770 - val_Precision: 0.9642 - val_Recall: 0.9477 - val_TP: 761.9900 - val_TN: 1084.3700 - val_FP: 21.6300 - val_FN: 42.0100\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0376 - Accuracy: 0.9875 - Precision: 0.9641 - Recall: 0.9602 - TP: 3237.9500 - TN: 5551.7998 - FP: 95.2000 - FN: 134.0500 - val_loss: 0.0868 - val_Accuracy: 0.9764 - val_Precision: 0.9614 - val_Recall: 0.9474 - val_TP: 761.6700 - val_TN: 1081.8300 - val_FP: 24.1700 - val_FN: 42.3300\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0383 - Accuracy: 0.9869 - Precision: 0.9645 - Recall: 0.9597 - TP: 3236.2500 - TN: 5553.3101 - FP: 93.6900 - FN: 135.7500 - val_loss: 0.0859 - val_Accuracy: 0.9764 - val_Precision: 0.9620 - val_Recall: 0.9477 - val_TP: 761.9200 - val_TN: 1082.5300 - val_FP: 23.4700 - val_FN: 42.0800\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0370 - Accuracy: 0.9877 - Precision: 0.9648 - Recall: 0.9602 - TP: 3237.8899 - TN: 5554.0498 - FP: 92.9500 - FN: 134.1100 - val_loss: 0.0842 - val_Accuracy: 0.9775 - val_Precision: 0.9646 - val_Recall: 0.9472 - val_TP: 761.5300 - val_TN: 1084.8000 - val_FP: 21.2000 - val_FN: 42.4700\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0374 - Accuracy: 0.9877 - Precision: 0.9651 - Recall: 0.9599 - TP: 3236.9199 - TN: 5555.3799 - FP: 91.6200 - FN: 135.0800 - val_loss: 0.0847 - val_Accuracy: 0.9764 - val_Precision: 0.9617 - val_Recall: 0.9486 - val_TP: 762.7000 - val_TN: 1082.1899 - val_FP: 23.8100 - val_FN: 41.3000\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0424 - Accuracy: 0.9859 - Precision: 0.9628 - Recall: 0.9587 - TP: 3232.8999 - TN: 5547.3398 - FP: 99.6600 - FN: 139.1000 - val_loss: 0.0925 - val_Accuracy: 0.9728 - val_Precision: 0.9532 - val_Recall: 0.9489 - val_TP: 762.9400 - val_TN: 1074.1200 - val_FP: 31.8800 - val_FN: 41.0600\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0394 - Accuracy: 0.9870 - Precision: 0.9637 - Recall: 0.9598 - TP: 3236.5300 - TN: 5550.2798 - FP: 96.7200 - FN: 135.4700 - val_loss: 0.0839 - val_Accuracy: 0.9743 - val_Precision: 0.9616 - val_Recall: 0.9481 - val_TP: 762.2500 - val_TN: 1082.1500 - val_FP: 23.8500 - val_FN: 41.7500\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0383 - Accuracy: 0.9863 - Precision: 0.9641 - Recall: 0.9590 - TP: 3233.5901 - TN: 5551.5200 - FP: 95.4800 - FN: 138.4100 - val_loss: 0.0820 - val_Accuracy: 0.9770 - val_Precision: 0.9626 - val_Recall: 0.9487 - val_TP: 762.7900 - val_TN: 1082.9700 - val_FP: 23.0300 - val_FN: 41.2100\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0380 - Accuracy: 0.9871 - Precision: 0.9638 - Recall: 0.9598 - TP: 3236.6101 - TN: 5550.2100 - FP: 96.7900 - FN: 135.3900 - val_loss: 0.0832 - val_Accuracy: 0.9770 - val_Precision: 0.9640 - val_Recall: 0.9471 - val_TP: 761.4500 - val_TN: 1084.2600 - val_FP: 21.7400 - val_FN: 42.5500\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0382 - Accuracy: 0.9877 - Precision: 0.9642 - Recall: 0.9594 - TP: 3234.9600 - TN: 5551.7002 - FP: 95.3000 - FN: 137.0400 - val_loss: 0.0825 - val_Accuracy: 0.9770 - val_Precision: 0.9642 - val_Recall: 0.9475 - val_TP: 761.8200 - val_TN: 1084.3900 - val_FP: 21.6100 - val_FN: 42.1800\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0390 - Accuracy: 0.9877 - Precision: 0.9646 - Recall: 0.9586 - TP: 3232.3301 - TN: 5553.5801 - FP: 93.4200 - FN: 139.6700 - val_loss: 0.0860 - val_Accuracy: 0.9749 - val_Precision: 0.9570 - val_Recall: 0.9496 - val_TP: 763.4800 - val_TN: 1077.7400 - val_FP: 28.2600 - val_FN: 40.5200\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0391 - Accuracy: 0.9865 - Precision: 0.9632 - Recall: 0.9593 - TP: 3234.6499 - TN: 5548.2998 - FP: 98.7000 - FN: 137.3500 - val_loss: 0.0819 - val_Accuracy: 0.9764 - val_Precision: 0.9624 - val_Recall: 0.9492 - val_TP: 763.1200 - val_TN: 1082.7200 - val_FP: 23.2800 - val_FN: 40.8800\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0408 - Accuracy: 0.9860 - Precision: 0.9628 - Recall: 0.9591 - TP: 3233.9299 - TN: 5547.0400 - FP: 99.9600 - FN: 138.0700 - val_loss: 0.0839 - val_Accuracy: 0.9754 - val_Precision: 0.9624 - val_Recall: 0.9478 - val_TP: 762.0500 - val_TN: 1082.8400 - val_FP: 23.1600 - val_FN: 41.9500\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0382 - Accuracy: 0.9870 - Precision: 0.9651 - Recall: 0.9591 - TP: 3234.1799 - TN: 5555.5200 - FP: 91.4800 - FN: 137.8200 - val_loss: 0.0843 - val_Accuracy: 0.9749 - val_Precision: 0.9593 - val_Recall: 0.9497 - val_TP: 763.5700 - val_TN: 1080.0300 - val_FP: 25.9700 - val_FN: 40.4300\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0374 - Accuracy: 0.9875 - Precision: 0.9640 - Recall: 0.9601 - TP: 3237.3799 - TN: 5551.1401 - FP: 95.8600 - FN: 134.6200 - val_loss: 0.0831 - val_Accuracy: 0.9754 - val_Precision: 0.9614 - val_Recall: 0.9490 - val_TP: 762.9800 - val_TN: 1081.9200 - val_FP: 24.0800 - val_FN: 41.0200\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0382 - Accuracy: 0.9869 - Precision: 0.9636 - Recall: 0.9599 - TP: 3236.6499 - TN: 5549.9702 - FP: 97.0300 - FN: 135.3500 - val_loss: 0.0831 - val_Accuracy: 0.9770 - val_Precision: 0.9646 - val_Recall: 0.9475 - val_TP: 761.7800 - val_TN: 1084.7600 - val_FP: 21.2400 - val_FN: 42.2200\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0394 - Accuracy: 0.9866 - Precision: 0.9637 - Recall: 0.9593 - TP: 3234.7100 - TN: 5550.2998 - FP: 96.7000 - FN: 137.2900 - val_loss: 0.0828 - val_Accuracy: 0.9770 - val_Precision: 0.9630 - val_Recall: 0.9486 - val_TP: 762.6900 - val_TN: 1083.3400 - val_FP: 22.6600 - val_FN: 41.3100\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0377 - Accuracy: 0.9871 - Precision: 0.9648 - Recall: 0.9599 - TP: 3236.7700 - TN: 5554.4902 - FP: 92.5100 - FN: 135.2300 - val_loss: 0.0851 - val_Accuracy: 0.9754 - val_Precision: 0.9605 - val_Recall: 0.9489 - val_TP: 762.8900 - val_TN: 1081.1801 - val_FP: 24.8200 - val_FN: 41.1100\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0390 - Accuracy: 0.9868 - Precision: 0.9639 - Recall: 0.9590 - TP: 3233.8101 - TN: 5550.6602 - FP: 96.3400 - FN: 138.1900 - val_loss: 0.0824 - val_Accuracy: 0.9770 - val_Precision: 0.9635 - val_Recall: 0.9488 - val_TP: 762.8300 - val_TN: 1083.8000 - val_FP: 22.2000 - val_FN: 41.1700\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0379 - Accuracy: 0.9870 - Precision: 0.9647 - Recall: 0.9604 - TP: 3238.5400 - TN: 5553.8501 - FP: 93.1500 - FN: 133.4600 - val_loss: 0.0831 - val_Accuracy: 0.9770 - val_Precision: 0.9645 - val_Recall: 0.9479 - val_TP: 762.1200 - val_TN: 1084.6400 - val_FP: 21.3600 - val_FN: 41.8800\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0386 - Accuracy: 0.9870 - Precision: 0.9647 - Recall: 0.9596 - TP: 3235.9099 - TN: 5553.8501 - FP: 93.1500 - FN: 136.0900 - val_loss: 0.0843 - val_Accuracy: 0.9754 - val_Precision: 0.9599 - val_Recall: 0.9496 - val_TP: 763.4600 - val_TN: 1080.6100 - val_FP: 25.3900 - val_FN: 40.5400\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0381 - Accuracy: 0.9869 - Precision: 0.9645 - Recall: 0.9600 - TP: 3237.1101 - TN: 5552.9302 - FP: 94.0700 - FN: 134.8900 - val_loss: 0.0854 - val_Accuracy: 0.9759 - val_Precision: 0.9603 - val_Recall: 0.9490 - val_TP: 762.9900 - val_TN: 1080.9700 - val_FP: 25.0300 - val_FN: 41.0100\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0391 - Accuracy: 0.9867 - Precision: 0.9639 - Recall: 0.9607 - TP: 3239.4700 - TN: 5550.8799 - FP: 96.1200 - FN: 132.5300 - val_loss: 0.0869 - val_Accuracy: 0.9759 - val_Precision: 0.9638 - val_Recall: 0.9460 - val_TP: 760.5900 - val_TN: 1084.1899 - val_FP: 21.8100 - val_FN: 43.4100\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0381 - Accuracy: 0.9879 - Precision: 0.9648 - Recall: 0.9602 - TP: 3237.7200 - TN: 5554.1001 - FP: 92.9000 - FN: 134.2800 - val_loss: 0.0976 - val_Accuracy: 0.9738 - val_Precision: 0.9492 - val_Recall: 0.9474 - val_TP: 761.7100 - val_TN: 1070.4000 - val_FP: 35.6000 - val_FN: 42.2900\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0411 - Accuracy: 0.9872 - Precision: 0.9642 - Recall: 0.9593 - TP: 3234.6101 - TN: 5552.4600 - FP: 94.5400 - FN: 137.3900 - val_loss: 0.0834 - val_Accuracy: 0.9764 - val_Precision: 0.9619 - val_Recall: 0.9494 - val_TP: 763.2800 - val_TN: 1082.3600 - val_FP: 23.6400 - val_FN: 40.7200\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0370 - Accuracy: 0.9876 - Precision: 0.9642 - Recall: 0.9606 - TP: 3239.2400 - TN: 5552.1201 - FP: 94.8800 - FN: 132.7600 - val_loss: 0.0854 - val_Accuracy: 0.9759 - val_Precision: 0.9621 - val_Recall: 0.9481 - val_TP: 762.2600 - val_TN: 1082.5601 - val_FP: 23.4400 - val_FN: 41.7400\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0388 - Accuracy: 0.9872 - Precision: 0.9657 - Recall: 0.9593 - TP: 3234.6101 - TN: 5557.7202 - FP: 89.2800 - FN: 137.3900 - val_loss: 0.0842 - val_Accuracy: 0.9775 - val_Precision: 0.9620 - val_Recall: 0.9490 - val_TP: 763.0000 - val_TN: 1082.4600 - val_FP: 23.5400 - val_FN: 41.0000\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0377 - Accuracy: 0.9859 - Precision: 0.9635 - Recall: 0.9602 - TP: 3237.7000 - TN: 5549.1001 - FP: 97.9000 - FN: 134.3000 - val_loss: 0.0864 - val_Accuracy: 0.9754 - val_Precision: 0.9612 - val_Recall: 0.9481 - val_TP: 762.3000 - val_TN: 1081.7800 - val_FP: 24.2200 - val_FN: 41.7000\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0389 - Accuracy: 0.9865 - Precision: 0.9638 - Recall: 0.9592 - TP: 3234.5801 - TN: 5550.3501 - FP: 96.6500 - FN: 137.4200 - val_loss: 0.0842 - val_Accuracy: 0.9775 - val_Precision: 0.9632 - val_Recall: 0.9484 - val_TP: 762.4800 - val_TN: 1083.5601 - val_FP: 22.4400 - val_FN: 41.5200\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0384 - Accuracy: 0.9867 - Precision: 0.9648 - Recall: 0.9598 - TP: 3236.3101 - TN: 5554.4302 - FP: 92.5700 - FN: 135.6900 - val_loss: 0.0870 - val_Accuracy: 0.9759 - val_Precision: 0.9602 - val_Recall: 0.9486 - val_TP: 762.6600 - val_TN: 1080.9200 - val_FP: 25.0800 - val_FN: 41.3400\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0371 - Accuracy: 0.9868 - Precision: 0.9650 - Recall: 0.9605 - TP: 3238.8999 - TN: 5554.8101 - FP: 92.1900 - FN: 133.1000 - val_loss: 0.0855 - val_Accuracy: 0.9770 - val_Precision: 0.9618 - val_Recall: 0.9485 - val_TP: 762.5700 - val_TN: 1082.4000 - val_FP: 23.6000 - val_FN: 41.4300\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0393 - Accuracy: 0.9869 - Precision: 0.9636 - Recall: 0.9603 - TP: 3238.0601 - TN: 5549.9399 - FP: 97.0600 - FN: 133.9400 - val_loss: 0.0850 - val_Accuracy: 0.9770 - val_Precision: 0.9634 - val_Recall: 0.9480 - val_TP: 762.1700 - val_TN: 1083.7900 - val_FP: 22.2100 - val_FN: 41.8300\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0392 - Accuracy: 0.9874 - Precision: 0.9634 - Recall: 0.9604 - TP: 3238.5000 - TN: 5548.8501 - FP: 98.1500 - FN: 133.5000 - val_loss: 0.0845 - val_Accuracy: 0.9764 - val_Precision: 0.9631 - val_Recall: 0.9473 - val_TP: 761.5900 - val_TN: 1083.4100 - val_FP: 22.5900 - val_FN: 42.4100\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0392 - Accuracy: 0.9869 - Precision: 0.9640 - Recall: 0.9589 - TP: 3233.3401 - TN: 5551.0898 - FP: 95.9100 - FN: 138.6600 - val_loss: 0.0833 - val_Accuracy: 0.9770 - val_Precision: 0.9639 - val_Recall: 0.9475 - val_TP: 761.7800 - val_TN: 1084.1300 - val_FP: 21.8700 - val_FN: 42.2200\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0381 - Accuracy: 0.9869 - Precision: 0.9646 - Recall: 0.9591 - TP: 3234.1799 - TN: 5553.6899 - FP: 93.3100 - FN: 137.8200 - val_loss: 0.0905 - val_Accuracy: 0.9738 - val_Precision: 0.9545 - val_Recall: 0.9489 - val_TP: 762.9200 - val_TN: 1075.3300 - val_FP: 30.6700 - val_FN: 41.0800\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0386 - Accuracy: 0.9866 - Precision: 0.9639 - Recall: 0.9590 - TP: 3233.7800 - TN: 5550.8101 - FP: 96.1900 - FN: 138.2200 - val_loss: 0.0842 - val_Accuracy: 0.9754 - val_Precision: 0.9611 - val_Recall: 0.9488 - val_TP: 762.8000 - val_TN: 1081.7000 - val_FP: 24.3000 - val_FN: 41.2000\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0394 - Accuracy: 0.9864 - Precision: 0.9637 - Recall: 0.9596 - TP: 3235.9099 - TN: 5550.5298 - FP: 96.4700 - FN: 136.0900 - val_loss: 0.0834 - val_Accuracy: 0.9764 - val_Precision: 0.9624 - val_Recall: 0.9486 - val_TP: 762.6500 - val_TN: 1082.7800 - val_FP: 23.2200 - val_FN: 41.3500\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0393 - Accuracy: 0.9859 - Precision: 0.9642 - Recall: 0.9596 - TP: 3235.8899 - TN: 5552.2100 - FP: 94.7900 - FN: 136.1100 - val_loss: 0.0850 - val_Accuracy: 0.9754 - val_Precision: 0.9605 - val_Recall: 0.9488 - val_TP: 762.8400 - val_TN: 1081.1500 - val_FP: 24.8500 - val_FN: 41.1600\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0390 - Accuracy: 0.9872 - Precision: 0.9637 - Recall: 0.9599 - TP: 3236.9199 - TN: 5549.7402 - FP: 97.2600 - FN: 135.0800 - val_loss: 0.0835 - val_Accuracy: 0.9770 - val_Precision: 0.9627 - val_Recall: 0.9485 - val_TP: 762.6100 - val_TN: 1083.0900 - val_FP: 22.9100 - val_FN: 41.3900\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0380 - Accuracy: 0.9868 - Precision: 0.9646 - Recall: 0.9597 - TP: 3236.1899 - TN: 5553.6802 - FP: 93.3200 - FN: 135.8100 - val_loss: 0.0829 - val_Accuracy: 0.9775 - val_Precision: 0.9637 - val_Recall: 0.9486 - val_TP: 762.6900 - val_TN: 1083.9301 - val_FP: 22.0700 - val_FN: 41.3100\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0420 - Accuracy: 0.9859 - Precision: 0.9638 - Recall: 0.9592 - TP: 3234.3999 - TN: 5551.0898 - FP: 95.9100 - FN: 137.6000 - val_loss: 0.0842 - val_Accuracy: 0.9749 - val_Precision: 0.9600 - val_Recall: 0.9497 - val_TP: 763.5700 - val_TN: 1080.6801 - val_FP: 25.3200 - val_FN: 40.4300\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0386 - Accuracy: 0.9866 - Precision: 0.9642 - Recall: 0.9599 - TP: 3236.6899 - TN: 5551.9399 - FP: 95.0600 - FN: 135.3100 - val_loss: 0.0839 - val_Accuracy: 0.9770 - val_Precision: 0.9626 - val_Recall: 0.9484 - val_TP: 762.5500 - val_TN: 1083.0100 - val_FP: 22.9900 - val_FN: 41.4500\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0374 - Accuracy: 0.9872 - Precision: 0.9647 - Recall: 0.9597 - TP: 3235.9800 - TN: 5554.1201 - FP: 92.8800 - FN: 136.0200 - val_loss: 0.0836 - val_Accuracy: 0.9775 - val_Precision: 0.9628 - val_Recall: 0.9486 - val_TP: 762.6500 - val_TN: 1083.1700 - val_FP: 22.8300 - val_FN: 41.3500\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0368 - Accuracy: 0.9872 - Precision: 0.9644 - Recall: 0.9607 - TP: 3239.5000 - TN: 5552.9199 - FP: 94.0800 - FN: 132.5000 - val_loss: 0.0845 - val_Accuracy: 0.9770 - val_Precision: 0.9636 - val_Recall: 0.9476 - val_TP: 761.8400 - val_TN: 1083.9399 - val_FP: 22.0600 - val_FN: 42.1600\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0386 - Accuracy: 0.9879 - Precision: 0.9646 - Recall: 0.9603 - TP: 3238.0100 - TN: 5553.5200 - FP: 93.4800 - FN: 133.9900 - val_loss: 0.0849 - val_Accuracy: 0.9759 - val_Precision: 0.9620 - val_Recall: 0.9485 - val_TP: 762.6000 - val_TN: 1082.5500 - val_FP: 23.4500 - val_FN: 41.4000\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0375 - Accuracy: 0.9868 - Precision: 0.9648 - Recall: 0.9602 - TP: 3237.7200 - TN: 5554.6899 - FP: 92.3100 - FN: 134.2800 - val_loss: 0.0870 - val_Accuracy: 0.9759 - val_Precision: 0.9602 - val_Recall: 0.9482 - val_TP: 762.3900 - val_TN: 1080.8199 - val_FP: 25.1800 - val_FN: 41.6100\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0374 - Accuracy: 0.9868 - Precision: 0.9643 - Recall: 0.9599 - TP: 3236.8301 - TN: 5552.2002 - FP: 94.8000 - FN: 135.1700 - val_loss: 0.0857 - val_Accuracy: 0.9759 - val_Precision: 0.9624 - val_Recall: 0.9478 - val_TP: 762.0200 - val_TN: 1082.9100 - val_FP: 23.0900 - val_FN: 41.9800\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0386 - Accuracy: 0.9872 - Precision: 0.9643 - Recall: 0.9597 - TP: 3236.0801 - TN: 5552.3501 - FP: 94.6500 - FN: 135.9200 - val_loss: 0.0844 - val_Accuracy: 0.9770 - val_Precision: 0.9622 - val_Recall: 0.9488 - val_TP: 762.8000 - val_TN: 1082.6700 - val_FP: 23.3300 - val_FN: 41.2000\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0379 - Accuracy: 0.9871 - Precision: 0.9647 - Recall: 0.9599 - TP: 3236.7200 - TN: 5553.7202 - FP: 93.2800 - FN: 135.2800 - val_loss: 0.0838 - val_Accuracy: 0.9764 - val_Precision: 0.9623 - val_Recall: 0.9493 - val_TP: 763.2000 - val_TN: 1082.6899 - val_FP: 23.3100 - val_FN: 40.8000\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0382 - Accuracy: 0.9875 - Precision: 0.9651 - Recall: 0.9602 - TP: 3237.7900 - TN: 5555.6099 - FP: 91.3900 - FN: 134.2100 - val_loss: 0.0850 - val_Accuracy: 0.9764 - val_Precision: 0.9621 - val_Recall: 0.9485 - val_TP: 762.6000 - val_TN: 1082.6000 - val_FP: 23.4000 - val_FN: 41.4000\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0376 - Accuracy: 0.9874 - Precision: 0.9644 - Recall: 0.9608 - TP: 3239.6599 - TN: 5552.4600 - FP: 94.5400 - FN: 132.3400 - val_loss: 0.0843 - val_Accuracy: 0.9770 - val_Precision: 0.9640 - val_Recall: 0.9480 - val_TP: 762.2300 - val_TN: 1084.2600 - val_FP: 21.7400 - val_FN: 41.7700\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0374 - Accuracy: 0.9871 - Precision: 0.9649 - Recall: 0.9600 - TP: 3237.2200 - TN: 5554.8301 - FP: 92.1700 - FN: 134.7800 - val_loss: 0.0850 - val_Accuracy: 0.9770 - val_Precision: 0.9623 - val_Recall: 0.9486 - val_TP: 762.6800 - val_TN: 1082.7500 - val_FP: 23.2500 - val_FN: 41.3200\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0370 - Accuracy: 0.9869 - Precision: 0.9644 - Recall: 0.9601 - TP: 3237.4399 - TN: 5552.8398 - FP: 94.1600 - FN: 134.5600 - val_loss: 0.0849 - val_Accuracy: 0.9770 - val_Precision: 0.9657 - val_Recall: 0.9470 - val_TP: 761.3600 - val_TN: 1085.7700 - val_FP: 20.2300 - val_FN: 42.6400\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0379 - Accuracy: 0.9874 - Precision: 0.9642 - Recall: 0.9601 - TP: 3237.5801 - TN: 5552.0000 - FP: 95.0000 - FN: 134.4200 - val_loss: 0.0875 - val_Accuracy: 0.9759 - val_Precision: 0.9612 - val_Recall: 0.9480 - val_TP: 762.1700 - val_TN: 1081.8700 - val_FP: 24.1300 - val_FN: 41.8300\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0373 - Accuracy: 0.9879 - Precision: 0.9649 - Recall: 0.9602 - TP: 3237.8101 - TN: 5554.3999 - FP: 92.6000 - FN: 134.1900 - val_loss: 0.0859 - val_Accuracy: 0.9759 - val_Precision: 0.9627 - val_Recall: 0.9480 - val_TP: 762.1600 - val_TN: 1083.1700 - val_FP: 22.8300 - val_FN: 41.8400\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0368 - Accuracy: 0.9877 - Precision: 0.9650 - Recall: 0.9606 - TP: 3239.1399 - TN: 5554.9502 - FP: 92.0500 - FN: 132.8600 - val_loss: 0.0857 - val_Accuracy: 0.9770 - val_Precision: 0.9622 - val_Recall: 0.9486 - val_TP: 762.6500 - val_TN: 1082.6899 - val_FP: 23.3100 - val_FN: 41.3500\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0390 - Accuracy: 0.9870 - Precision: 0.9645 - Recall: 0.9603 - TP: 3238.2600 - TN: 5553.8501 - FP: 93.1500 - FN: 133.7400 - val_loss: 0.0857 - val_Accuracy: 0.9770 - val_Precision: 0.9629 - val_Recall: 0.9480 - val_TP: 762.1900 - val_TN: 1083.3199 - val_FP: 22.6800 - val_FN: 41.8100\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0372 - Accuracy: 0.9871 - Precision: 0.9647 - Recall: 0.9603 - TP: 3238.1599 - TN: 5554.0400 - FP: 92.9600 - FN: 133.8400 - val_loss: 0.0883 - val_Accuracy: 0.9759 - val_Precision: 0.9603 - val_Recall: 0.9482 - val_TP: 762.3800 - val_TN: 1080.9500 - val_FP: 25.0500 - val_FN: 41.6200\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0389 - Accuracy: 0.9868 - Precision: 0.9649 - Recall: 0.9598 - TP: 3236.4800 - TN: 5555.3398 - FP: 91.6600 - FN: 135.5200 - val_loss: 0.0896 - val_Accuracy: 0.9749 - val_Precision: 0.9570 - val_Recall: 0.9499 - val_TP: 763.6800 - val_TN: 1077.8800 - val_FP: 28.1200 - val_FN: 40.3200\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0372 - Accuracy: 0.9871 - Precision: 0.9638 - Recall: 0.9609 - TP: 3240.2000 - TN: 5550.4399 - FP: 96.5600 - FN: 131.8000 - val_loss: 0.0866 - val_Accuracy: 0.9764 - val_Precision: 0.9647 - val_Recall: 0.9468 - val_TP: 761.2600 - val_TN: 1084.9100 - val_FP: 21.0900 - val_FN: 42.7400\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0400 - Accuracy: 0.9870 - Precision: 0.9646 - Recall: 0.9597 - TP: 3236.1101 - TN: 5553.3701 - FP: 93.6300 - FN: 135.8900 - val_loss: 0.0830 - val_Accuracy: 0.9764 - val_Precision: 0.9628 - val_Recall: 0.9490 - val_TP: 763.0100 - val_TN: 1083.1899 - val_FP: 22.8100 - val_FN: 40.9900\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0384 - Accuracy: 0.9868 - Precision: 0.9644 - Recall: 0.9600 - TP: 3237.1699 - TN: 5553.0000 - FP: 94.0000 - FN: 134.8300 - val_loss: 0.0852 - val_Accuracy: 0.9759 - val_Precision: 0.9622 - val_Recall: 0.9479 - val_TP: 762.1300 - val_TN: 1082.6700 - val_FP: 23.3300 - val_FN: 41.8700\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0384 - Accuracy: 0.9870 - Precision: 0.9644 - Recall: 0.9600 - TP: 3237.2000 - TN: 5552.9502 - FP: 94.0500 - FN: 134.8000 - val_loss: 0.0845 - val_Accuracy: 0.9764 - val_Precision: 0.9634 - val_Recall: 0.9477 - val_TP: 761.9800 - val_TN: 1083.7700 - val_FP: 22.2300 - val_FN: 42.0200\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0376 - Accuracy: 0.9872 - Precision: 0.9647 - Recall: 0.9604 - TP: 3238.5901 - TN: 5553.6602 - FP: 93.3400 - FN: 133.4100 - val_loss: 0.0854 - val_Accuracy: 0.9759 - val_Precision: 0.9632 - val_Recall: 0.9474 - val_TP: 761.7000 - val_TN: 1083.6100 - val_FP: 22.3900 - val_FN: 42.3000\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0383 - Accuracy: 0.9870 - Precision: 0.9644 - Recall: 0.9595 - TP: 3235.4700 - TN: 5552.8398 - FP: 94.1600 - FN: 136.5300 - val_loss: 0.0848 - val_Accuracy: 0.9754 - val_Precision: 0.9607 - val_Recall: 0.9495 - val_TP: 763.3900 - val_TN: 1081.3400 - val_FP: 24.6600 - val_FN: 40.6100\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0378 - Accuracy: 0.9875 - Precision: 0.9648 - Recall: 0.9603 - TP: 3238.2400 - TN: 5554.2500 - FP: 92.7500 - FN: 133.7600 - val_loss: 0.0860 - val_Accuracy: 0.9754 - val_Precision: 0.9626 - val_Recall: 0.9474 - val_TP: 761.7400 - val_TN: 1083.1100 - val_FP: 22.8900 - val_FN: 42.2600\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0376 - Accuracy: 0.9870 - Precision: 0.9641 - Recall: 0.9604 - TP: 3238.3301 - TN: 5551.7900 - FP: 95.2100 - FN: 133.6700 - val_loss: 0.0857 - val_Accuracy: 0.9759 - val_Precision: 0.9634 - val_Recall: 0.9473 - val_TP: 761.6300 - val_TN: 1083.7900 - val_FP: 22.2100 - val_FN: 42.3700\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0376 - Accuracy: 0.9879 - Precision: 0.9652 - Recall: 0.9594 - TP: 3235.0901 - TN: 5555.4902 - FP: 91.5100 - FN: 136.9100 - val_loss: 0.0843 - val_Accuracy: 0.9764 - val_Precision: 0.9614 - val_Recall: 0.9494 - val_TP: 763.3500 - val_TN: 1082.0100 - val_FP: 23.9900 - val_FN: 40.6500\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0385 - Accuracy: 0.9866 - Precision: 0.9636 - Recall: 0.9597 - TP: 3236.2100 - TN: 5549.6899 - FP: 97.3100 - FN: 135.7900 - val_loss: 0.0861 - val_Accuracy: 0.9764 - val_Precision: 0.9603 - val_Recall: 0.9491 - val_TP: 763.0600 - val_TN: 1081.0400 - val_FP: 24.9600 - val_FN: 40.9400\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0378 - Accuracy: 0.9870 - Precision: 0.9645 - Recall: 0.9599 - TP: 3236.8899 - TN: 5553.4800 - FP: 93.5200 - FN: 135.1100 - val_loss: 0.0845 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9491 - val_TP: 763.0700 - val_TN: 1082.6899 - val_FP: 23.3100 - val_FN: 40.9300\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0369 - Accuracy: 0.9871 - Precision: 0.9653 - Recall: 0.9600 - TP: 3237.2200 - TN: 5556.4399 - FP: 90.5600 - FN: 134.7800 - val_loss: 0.0841 - val_Accuracy: 0.9770 - val_Precision: 0.9603 - val_Recall: 0.9504 - val_TP: 764.0900 - val_TN: 1081.0100 - val_FP: 24.9900 - val_FN: 39.9100\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0376 - Accuracy: 0.9866 - Precision: 0.9640 - Recall: 0.9603 - TP: 3238.2800 - TN: 5551.5000 - FP: 95.5000 - FN: 133.7200 - val_loss: 0.0864 - val_Accuracy: 0.9764 - val_Precision: 0.9601 - val_Recall: 0.9492 - val_TP: 763.1600 - val_TN: 1080.8199 - val_FP: 25.1800 - val_FN: 40.8400\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0370 - Accuracy: 0.9875 - Precision: 0.9646 - Recall: 0.9601 - TP: 3237.5901 - TN: 5553.7100 - FP: 93.2900 - FN: 134.4100 - val_loss: 0.0841 - val_Accuracy: 0.9780 - val_Precision: 0.9636 - val_Recall: 0.9488 - val_TP: 762.8500 - val_TN: 1083.9200 - val_FP: 22.0800 - val_FN: 41.1500\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0370 - Accuracy: 0.9872 - Precision: 0.9651 - Recall: 0.9601 - TP: 3237.4500 - TN: 5555.3701 - FP: 91.6300 - FN: 134.5500 - val_loss: 0.0871 - val_Accuracy: 0.9749 - val_Precision: 0.9594 - val_Recall: 0.9496 - val_TP: 763.5000 - val_TN: 1080.2100 - val_FP: 25.7900 - val_FN: 40.5000\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0382 - Accuracy: 0.9871 - Precision: 0.9643 - Recall: 0.9605 - TP: 3238.7700 - TN: 5552.7402 - FP: 94.2600 - FN: 133.2300 - val_loss: 0.0859 - val_Accuracy: 0.9749 - val_Precision: 0.9597 - val_Recall: 0.9500 - val_TP: 763.8000 - val_TN: 1080.5300 - val_FP: 25.4700 - val_FN: 40.2000\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0362 - Accuracy: 0.9875 - Precision: 0.9644 - Recall: 0.9610 - TP: 3240.6599 - TN: 5552.8799 - FP: 94.1200 - FN: 131.3400 - val_loss: 0.0853 - val_Accuracy: 0.9770 - val_Precision: 0.9647 - val_Recall: 0.9474 - val_TP: 761.6900 - val_TN: 1084.9399 - val_FP: 21.0600 - val_FN: 42.3100\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0371 - Accuracy: 0.9871 - Precision: 0.9653 - Recall: 0.9599 - TP: 3236.6799 - TN: 5556.1099 - FP: 90.8900 - FN: 135.3200 - val_loss: 0.0878 - val_Accuracy: 0.9754 - val_Precision: 0.9593 - val_Recall: 0.9492 - val_TP: 763.1900 - val_TN: 1080.1500 - val_FP: 25.8500 - val_FN: 40.8100\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0369 - Accuracy: 0.9872 - Precision: 0.9649 - Recall: 0.9606 - TP: 3239.2800 - TN: 5554.5498 - FP: 92.4500 - FN: 132.7200 - val_loss: 0.0941 - val_Accuracy: 0.9743 - val_Precision: 0.9538 - val_Recall: 0.9483 - val_TP: 762.4700 - val_TN: 1074.7500 - val_FP: 31.2500 - val_FN: 41.5300\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0377 - Accuracy: 0.9878 - Precision: 0.9648 - Recall: 0.9609 - TP: 3240.2700 - TN: 5554.3101 - FP: 92.6900 - FN: 131.7300 - val_loss: 0.0854 - val_Accuracy: 0.9770 - val_Precision: 0.9615 - val_Recall: 0.9494 - val_TP: 763.3300 - val_TN: 1082.1200 - val_FP: 23.8800 - val_FN: 40.6700\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0364 - Accuracy: 0.9874 - Precision: 0.9651 - Recall: 0.9609 - TP: 3240.1299 - TN: 5555.3799 - FP: 91.6200 - FN: 131.8700 - val_loss: 0.0862 - val_Accuracy: 0.9764 - val_Precision: 0.9627 - val_Recall: 0.9483 - val_TP: 762.4300 - val_TN: 1083.1899 - val_FP: 22.8100 - val_FN: 41.5700\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0400 - Accuracy: 0.9861 - Precision: 0.9641 - Recall: 0.9599 - TP: 3236.9099 - TN: 5552.5400 - FP: 94.4600 - FN: 135.0900 - val_loss: 0.0865 - val_Accuracy: 0.9775 - val_Precision: 0.9672 - val_Recall: 0.9456 - val_TP: 760.2900 - val_TN: 1087.0900 - val_FP: 18.9100 - val_FN: 43.7100\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 7ms/step - loss: 0.0412 - Accuracy: 0.9865 - Precision: 0.9647 - Recall: 0.9587 - TP: 3232.8000 - TN: 5554.8398 - FP: 92.1600 - FN: 139.2000 - val_loss: 0.0834 - val_Accuracy: 0.9764 - val_Precision: 0.9589 - val_Recall: 0.9512 - val_TP: 764.7300 - val_TN: 1079.6700 - val_FP: 26.3300 - val_FN: 39.2700\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0387 - Accuracy: 0.9870 - Precision: 0.9633 - Recall: 0.9602 - TP: 3237.8201 - TN: 5548.4502 - FP: 98.5500 - FN: 134.1800 - val_loss: 0.0847 - val_Accuracy: 0.9770 - val_Precision: 0.9666 - val_Recall: 0.9460 - val_TP: 760.5900 - val_TN: 1086.5400 - val_FP: 19.4600 - val_FN: 43.4100\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0391 - Accuracy: 0.9870 - Precision: 0.9649 - Recall: 0.9594 - TP: 3235.0000 - TN: 5555.2900 - FP: 91.7100 - FN: 137.0000 - val_loss: 0.0846 - val_Accuracy: 0.9749 - val_Precision: 0.9598 - val_Recall: 0.9499 - val_TP: 763.7400 - val_TN: 1080.5900 - val_FP: 25.4100 - val_FN: 40.2600\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0394 - Accuracy: 0.9876 - Precision: 0.9638 - Recall: 0.9602 - TP: 3237.8000 - TN: 5550.8301 - FP: 96.1700 - FN: 134.2000 - val_loss: 0.0885 - val_Accuracy: 0.9749 - val_Precision: 0.9568 - val_Recall: 0.9495 - val_TP: 763.3600 - val_TN: 1077.6400 - val_FP: 28.3600 - val_FN: 40.6400\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0384 - Accuracy: 0.9871 - Precision: 0.9647 - Recall: 0.9599 - TP: 3236.9299 - TN: 5553.9302 - FP: 93.0700 - FN: 135.0700 - val_loss: 0.0838 - val_Accuracy: 0.9764 - val_Precision: 0.9621 - val_Recall: 0.9493 - val_TP: 763.2000 - val_TN: 1082.5800 - val_FP: 23.4200 - val_FN: 40.8000\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0393 - Accuracy: 0.9864 - Precision: 0.9633 - Recall: 0.9600 - TP: 3237.0300 - TN: 5548.4302 - FP: 98.5700 - FN: 134.9700 - val_loss: 0.0872 - val_Accuracy: 0.9754 - val_Precision: 0.9614 - val_Recall: 0.9477 - val_TP: 761.9600 - val_TN: 1082.0000 - val_FP: 24.0000 - val_FN: 42.0400\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0374 - Accuracy: 0.9870 - Precision: 0.9645 - Recall: 0.9599 - TP: 3236.7900 - TN: 5553.2402 - FP: 93.7600 - FN: 135.2100 - val_loss: 0.0851 - val_Accuracy: 0.9775 - val_Precision: 0.9655 - val_Recall: 0.9465 - val_TP: 761.0000 - val_TN: 1085.6000 - val_FP: 20.4000 - val_FN: 43.0000\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0377 - Accuracy: 0.9875 - Precision: 0.9647 - Recall: 0.9595 - TP: 3235.3301 - TN: 5553.6099 - FP: 93.3900 - FN: 136.6700 - val_loss: 0.0849 - val_Accuracy: 0.9780 - val_Precision: 0.9631 - val_Recall: 0.9483 - val_TP: 762.4500 - val_TN: 1083.4700 - val_FP: 22.5300 - val_FN: 41.5500\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0391 - Accuracy: 0.9875 - Precision: 0.9638 - Recall: 0.9603 - TP: 3237.9900 - TN: 5550.9199 - FP: 96.0800 - FN: 134.0100 - val_loss: 0.0878 - val_Accuracy: 0.9749 - val_Precision: 0.9609 - val_Recall: 0.9482 - val_TP: 762.3300 - val_TN: 1081.6000 - val_FP: 24.4000 - val_FN: 41.6700\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0396 - Accuracy: 0.9866 - Precision: 0.9638 - Recall: 0.9596 - TP: 3235.8101 - TN: 5550.8599 - FP: 96.1400 - FN: 136.1900 - val_loss: 0.0843 - val_Accuracy: 0.9770 - val_Precision: 0.9648 - val_Recall: 0.9478 - val_TP: 762.0400 - val_TN: 1085.0200 - val_FP: 20.9800 - val_FN: 41.9600\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0380 - Accuracy: 0.9865 - Precision: 0.9650 - Recall: 0.9598 - TP: 3236.4900 - TN: 5555.2700 - FP: 91.7300 - FN: 135.5100 - val_loss: 0.0847 - val_Accuracy: 0.9775 - val_Precision: 0.9647 - val_Recall: 0.9476 - val_TP: 761.8600 - val_TN: 1084.8700 - val_FP: 21.1300 - val_FN: 42.1400\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0372 - Accuracy: 0.9876 - Precision: 0.9652 - Recall: 0.9603 - TP: 3238.2000 - TN: 5555.7100 - FP: 91.2900 - FN: 133.8000 - val_loss: 0.0853 - val_Accuracy: 0.9759 - val_Precision: 0.9617 - val_Recall: 0.9490 - val_TP: 762.9900 - val_TN: 1082.2400 - val_FP: 23.7600 - val_FN: 41.0100\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0369 - Accuracy: 0.9870 - Precision: 0.9644 - Recall: 0.9607 - TP: 3239.4600 - TN: 5552.5801 - FP: 94.4200 - FN: 132.5400 - val_loss: 0.0860 - val_Accuracy: 0.9764 - val_Precision: 0.9626 - val_Recall: 0.9481 - val_TP: 762.2700 - val_TN: 1083.1000 - val_FP: 22.9000 - val_FN: 41.7300\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0370 - Accuracy: 0.9869 - Precision: 0.9653 - Recall: 0.9597 - TP: 3236.1101 - TN: 5556.3799 - FP: 90.6200 - FN: 135.8900 - val_loss: 0.0857 - val_Accuracy: 0.9754 - val_Precision: 0.9612 - val_Recall: 0.9493 - val_TP: 763.2000 - val_TN: 1081.8600 - val_FP: 24.1400 - val_FN: 40.8000\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0377 - Accuracy: 0.9876 - Precision: 0.9645 - Recall: 0.9604 - TP: 3238.6101 - TN: 5553.2100 - FP: 93.7900 - FN: 133.3900 - val_loss: 0.0861 - val_Accuracy: 0.9764 - val_Precision: 0.9610 - val_Recall: 0.9492 - val_TP: 763.1900 - val_TN: 1081.7200 - val_FP: 24.2800 - val_FN: 40.8100\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0370 - Accuracy: 0.9876 - Precision: 0.9651 - Recall: 0.9605 - TP: 3238.6499 - TN: 5555.5698 - FP: 91.4300 - FN: 133.3500 - val_loss: 0.0852 - val_Accuracy: 0.9764 - val_Precision: 0.9608 - val_Recall: 0.9500 - val_TP: 763.8400 - val_TN: 1081.4700 - val_FP: 24.5300 - val_FN: 40.1600\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0386 - Accuracy: 0.9877 - Precision: 0.9646 - Recall: 0.9606 - TP: 3239.2700 - TN: 5553.8701 - FP: 93.1300 - FN: 132.7300 - val_loss: 0.0857 - val_Accuracy: 0.9759 - val_Precision: 0.9613 - val_Recall: 0.9493 - val_TP: 763.2500 - val_TN: 1081.9200 - val_FP: 24.0800 - val_FN: 40.7500\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0379 - Accuracy: 0.9870 - Precision: 0.9649 - Recall: 0.9606 - TP: 3239.2100 - TN: 5554.8701 - FP: 92.1300 - FN: 132.7900 - val_loss: 0.0857 - val_Accuracy: 0.9754 - val_Precision: 0.9600 - val_Recall: 0.9503 - val_TP: 764.0500 - val_TN: 1080.7100 - val_FP: 25.2900 - val_FN: 39.9500\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0363 - Accuracy: 0.9872 - Precision: 0.9646 - Recall: 0.9608 - TP: 3239.8301 - TN: 5553.2700 - FP: 93.7300 - FN: 132.1700 - val_loss: 0.0855 - val_Accuracy: 0.9780 - val_Precision: 0.9629 - val_Recall: 0.9488 - val_TP: 762.8300 - val_TN: 1083.3300 - val_FP: 22.6700 - val_FN: 41.1700\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0373 - Accuracy: 0.9870 - Precision: 0.9651 - Recall: 0.9600 - TP: 3237.0701 - TN: 5555.7700 - FP: 91.2300 - FN: 134.9300 - val_loss: 0.0856 - val_Accuracy: 0.9764 - val_Precision: 0.9598 - val_Recall: 0.9508 - val_TP: 764.4100 - val_TN: 1080.5800 - val_FP: 25.4200 - val_FN: 39.5900\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0395 - Accuracy: 0.9866 - Precision: 0.9636 - Recall: 0.9604 - TP: 3238.4800 - TN: 5549.9502 - FP: 97.0500 - FN: 133.5200 - val_loss: 0.0860 - val_Accuracy: 0.9775 - val_Precision: 0.9642 - val_Recall: 0.9478 - val_TP: 762.0600 - val_TN: 1084.4399 - val_FP: 21.5600 - val_FN: 41.9400\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 5ms/step - loss: 0.0411 - Accuracy: 0.9864 - Precision: 0.9641 - Recall: 0.9600 - TP: 3237.2700 - TN: 5552.0098 - FP: 94.9900 - FN: 134.7300 - val_loss: 0.0848 - val_Accuracy: 0.9749 - val_Precision: 0.9609 - val_Recall: 0.9492 - val_TP: 763.1700 - val_TN: 1081.5400 - val_FP: 24.4600 - val_FN: 40.8300\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0379 - Accuracy: 0.9870 - Precision: 0.9643 - Recall: 0.9603 - TP: 3238.1001 - TN: 5552.2202 - FP: 94.7800 - FN: 133.9000 - val_loss: 0.0864 - val_Accuracy: 0.9743 - val_Precision: 0.9595 - val_Recall: 0.9493 - val_TP: 763.2000 - val_TN: 1080.3199 - val_FP: 25.6800 - val_FN: 40.8000\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0382 - Accuracy: 0.9869 - Precision: 0.9645 - Recall: 0.9598 - TP: 3236.3999 - TN: 5552.9800 - FP: 94.0200 - FN: 135.6000 - val_loss: 0.0860 - val_Accuracy: 0.9749 - val_Precision: 0.9613 - val_Recall: 0.9484 - val_TP: 762.5000 - val_TN: 1081.9200 - val_FP: 24.0800 - val_FN: 41.5000\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0430 - Accuracy: 0.9864 - Precision: 0.9635 - Recall: 0.9595 - TP: 3235.5200 - TN: 5550.0098 - FP: 96.9900 - FN: 136.4800 - val_loss: 0.0843 - val_Accuracy: 0.9764 - val_Precision: 0.9640 - val_Recall: 0.9480 - val_TP: 762.1700 - val_TN: 1084.2700 - val_FP: 21.7300 - val_FN: 41.8300\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0364 - Accuracy: 0.9872 - Precision: 0.9654 - Recall: 0.9600 - TP: 3236.9700 - TN: 5556.9800 - FP: 90.0200 - FN: 135.0300 - val_loss: 0.0841 - val_Accuracy: 0.9764 - val_Precision: 0.9611 - val_Recall: 0.9499 - val_TP: 763.7200 - val_TN: 1081.6600 - val_FP: 24.3400 - val_FN: 40.2800\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0379 - Accuracy: 0.9868 - Precision: 0.9641 - Recall: 0.9603 - TP: 3237.9900 - TN: 5551.6899 - FP: 95.3100 - FN: 134.0100 - val_loss: 0.0844 - val_Accuracy: 0.9775 - val_Precision: 0.9636 - val_Recall: 0.9483 - val_TP: 762.4100 - val_TN: 1083.8900 - val_FP: 22.1100 - val_FN: 41.5900\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0398 - Accuracy: 0.9869 - Precision: 0.9643 - Recall: 0.9596 - TP: 3235.7900 - TN: 5553.3101 - FP: 93.6900 - FN: 136.2100 - val_loss: 0.0863 - val_Accuracy: 0.9749 - val_Precision: 0.9591 - val_Recall: 0.9498 - val_TP: 763.6000 - val_TN: 1079.9301 - val_FP: 26.0700 - val_FN: 40.4000\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0377 - Accuracy: 0.9866 - Precision: 0.9640 - Recall: 0.9606 - TP: 3239.0100 - TN: 5551.4702 - FP: 95.5300 - FN: 132.9900 - val_loss: 0.0847 - val_Accuracy: 0.9775 - val_Precision: 0.9651 - val_Recall: 0.9472 - val_TP: 761.5500 - val_TN: 1085.2500 - val_FP: 20.7500 - val_FN: 42.4500\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0408 - Accuracy: 0.9866 - Precision: 0.9640 - Recall: 0.9593 - TP: 3234.8201 - TN: 5551.6499 - FP: 95.3500 - FN: 137.1800 - val_loss: 0.0854 - val_Accuracy: 0.9764 - val_Precision: 0.9630 - val_Recall: 0.9481 - val_TP: 762.2400 - val_TN: 1083.4399 - val_FP: 22.5600 - val_FN: 41.7600\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0387 - Accuracy: 0.9877 - Precision: 0.9648 - Recall: 0.9600 - TP: 3237.1499 - TN: 5554.4800 - FP: 92.5200 - FN: 134.8500 - val_loss: 0.0851 - val_Accuracy: 0.9759 - val_Precision: 0.9597 - val_Recall: 0.9504 - val_TP: 764.1300 - val_TN: 1080.5100 - val_FP: 25.4900 - val_FN: 39.8700\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0379 - Accuracy: 0.9874 - Precision: 0.9643 - Recall: 0.9600 - TP: 3237.1299 - TN: 5552.6001 - FP: 94.4000 - FN: 134.8700 - val_loss: 0.0856 - val_Accuracy: 0.9764 - val_Precision: 0.9615 - val_Recall: 0.9491 - val_TP: 763.0500 - val_TN: 1082.0900 - val_FP: 23.9100 - val_FN: 40.9500\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0380 - Accuracy: 0.9866 - Precision: 0.9643 - Recall: 0.9600 - TP: 3237.2600 - TN: 5552.6201 - FP: 94.3800 - FN: 134.7400 - val_loss: 0.0867 - val_Accuracy: 0.9759 - val_Precision: 0.9614 - val_Recall: 0.9485 - val_TP: 762.5900 - val_TN: 1082.0900 - val_FP: 23.9100 - val_FN: 41.4100\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0382 - Accuracy: 0.9870 - Precision: 0.9640 - Recall: 0.9604 - TP: 3238.4099 - TN: 5551.0898 - FP: 95.9100 - FN: 133.5900 - val_loss: 0.0852 - val_Accuracy: 0.9775 - val_Precision: 0.9656 - val_Recall: 0.9471 - val_TP: 761.4800 - val_TN: 1085.6801 - val_FP: 20.3200 - val_FN: 42.5200\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0365 - Accuracy: 0.9875 - Precision: 0.9659 - Recall: 0.9598 - TP: 3236.3000 - TN: 5558.6299 - FP: 88.3700 - FN: 135.7000 - val_loss: 0.0882 - val_Accuracy: 0.9754 - val_Precision: 0.9578 - val_Recall: 0.9501 - val_TP: 763.8900 - val_TN: 1078.6801 - val_FP: 27.3200 - val_FN: 40.1100\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0372 - Accuracy: 0.9872 - Precision: 0.9636 - Recall: 0.9609 - TP: 3240.3201 - TN: 5549.6099 - FP: 97.3900 - FN: 131.6800 - val_loss: 0.0866 - val_Accuracy: 0.9764 - val_Precision: 0.9648 - val_Recall: 0.9468 - val_TP: 761.2000 - val_TN: 1085.0500 - val_FP: 20.9500 - val_FN: 42.8000\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0362 - Accuracy: 0.9880 - Precision: 0.9660 - Recall: 0.9601 - TP: 3237.5500 - TN: 5558.7500 - FP: 88.2500 - FN: 134.4500 - val_loss: 0.0888 - val_Accuracy: 0.9754 - val_Precision: 0.9571 - val_Recall: 0.9505 - val_TP: 764.2000 - val_TN: 1077.9900 - val_FP: 28.0100 - val_FN: 39.8000\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0381 - Accuracy: 0.9870 - Precision: 0.9645 - Recall: 0.9611 - TP: 3240.9900 - TN: 5553.4302 - FP: 93.5700 - FN: 131.0100 - val_loss: 0.0851 - val_Accuracy: 0.9775 - val_Precision: 0.9631 - val_Recall: 0.9489 - val_TP: 762.9000 - val_TN: 1083.5200 - val_FP: 22.4800 - val_FN: 41.1000\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0454 - Accuracy: 0.9863 - Precision: 0.9644 - Recall: 0.9596 - TP: 3235.6499 - TN: 5553.5400 - FP: 93.4600 - FN: 136.3500 - val_loss: 0.0862 - val_Accuracy: 0.9754 - val_Precision: 0.9608 - val_Recall: 0.9495 - val_TP: 763.3800 - val_TN: 1081.5200 - val_FP: 24.4800 - val_FN: 40.6200\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0373 - Accuracy: 0.9871 - Precision: 0.9651 - Recall: 0.9610 - TP: 3240.5400 - TN: 5555.7300 - FP: 91.2700 - FN: 131.4600 - val_loss: 0.0869 - val_Accuracy: 0.9764 - val_Precision: 0.9608 - val_Recall: 0.9493 - val_TP: 763.2700 - val_TN: 1081.5000 - val_FP: 24.5000 - val_FN: 40.7300\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0379 - Accuracy: 0.9870 - Precision: 0.9647 - Recall: 0.9607 - TP: 3239.3401 - TN: 5554.2202 - FP: 92.7800 - FN: 132.6600 - val_loss: 0.0892 - val_Accuracy: 0.9754 - val_Precision: 0.9588 - val_Recall: 0.9496 - val_TP: 763.4900 - val_TN: 1079.7800 - val_FP: 26.2200 - val_FN: 40.5100\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0374 - Accuracy: 0.9876 - Precision: 0.9647 - Recall: 0.9609 - TP: 3239.9900 - TN: 5554.4102 - FP: 92.5900 - FN: 132.0100 - val_loss: 0.0915 - val_Accuracy: 0.9754 - val_Precision: 0.9573 - val_Recall: 0.9492 - val_TP: 763.1400 - val_TN: 1078.1200 - val_FP: 27.8800 - val_FN: 40.8600\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0411 - Accuracy: 0.9868 - Precision: 0.9642 - Recall: 0.9600 - TP: 3237.0300 - TN: 5552.5298 - FP: 94.4700 - FN: 134.9700 - val_loss: 0.0871 - val_Accuracy: 0.9759 - val_Precision: 0.9616 - val_Recall: 0.9487 - val_TP: 762.7900 - val_TN: 1082.2300 - val_FP: 23.7700 - val_FN: 41.2100\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0401 - Accuracy: 0.9868 - Precision: 0.9638 - Recall: 0.9600 - TP: 3237.2700 - TN: 5550.9302 - FP: 96.0700 - FN: 134.7300 - val_loss: 0.0912 - val_Accuracy: 0.9749 - val_Precision: 0.9605 - val_Recall: 0.9480 - val_TP: 762.1700 - val_TN: 1081.2800 - val_FP: 24.7200 - val_FN: 41.8300\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0383 - Accuracy: 0.9875 - Precision: 0.9657 - Recall: 0.9604 - TP: 3238.4099 - TN: 5558.2002 - FP: 88.8000 - FN: 133.5900 - val_loss: 0.0864 - val_Accuracy: 0.9749 - val_Precision: 0.9605 - val_Recall: 0.9501 - val_TP: 763.8700 - val_TN: 1081.2900 - val_FP: 24.7100 - val_FN: 40.1300\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0367 - Accuracy: 0.9877 - Precision: 0.9642 - Recall: 0.9616 - TP: 3242.4099 - TN: 5552.0298 - FP: 94.9700 - FN: 129.5900 - val_loss: 0.0902 - val_Accuracy: 0.9754 - val_Precision: 0.9620 - val_Recall: 0.9476 - val_TP: 761.8500 - val_TN: 1082.6300 - val_FP: 23.3700 - val_FN: 42.1500\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 6ms/step - loss: 0.0411 - Accuracy: 0.9868 - Precision: 0.9643 - Recall: 0.9592 - TP: 3234.5601 - TN: 5552.6699 - FP: 94.3300 - FN: 137.4400 - val_loss: 0.0842 - val_Accuracy: 0.9764 - val_Precision: 0.9607 - val_Recall: 0.9502 - val_TP: 763.9600 - val_TN: 1081.2400 - val_FP: 24.7600 - val_FN: 40.0400\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0369 - Accuracy: 0.9876 - Precision: 0.9650 - Recall: 0.9605 - TP: 3238.7600 - TN: 5554.9800 - FP: 92.0200 - FN: 133.2400 - val_loss: 0.0899 - val_Accuracy: 0.9743 - val_Precision: 0.9552 - val_Recall: 0.9502 - val_TP: 763.9500 - val_TN: 1076.1700 - val_FP: 29.8300 - val_FN: 40.0500\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0380 - Accuracy: 0.9871 - Precision: 0.9642 - Recall: 0.9608 - TP: 3239.6499 - TN: 5551.8999 - FP: 95.1000 - FN: 132.3500 - val_loss: 0.0869 - val_Accuracy: 0.9759 - val_Precision: 0.9617 - val_Recall: 0.9480 - val_TP: 762.2200 - val_TN: 1082.3400 - val_FP: 23.6600 - val_FN: 41.7800\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0368 - Accuracy: 0.9871 - Precision: 0.9652 - Recall: 0.9602 - TP: 3237.6699 - TN: 5556.2598 - FP: 90.7400 - FN: 134.3300 - val_loss: 0.0840 - val_Accuracy: 0.9770 - val_Precision: 0.9628 - val_Recall: 0.9491 - val_TP: 763.0900 - val_TN: 1083.2200 - val_FP: 22.7800 - val_FN: 40.9100\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0382 - Accuracy: 0.9871 - Precision: 0.9642 - Recall: 0.9603 - TP: 3238.0000 - TN: 5552.2002 - FP: 94.8000 - FN: 134.0000 - val_loss: 0.0852 - val_Accuracy: 0.9764 - val_Precision: 0.9619 - val_Recall: 0.9490 - val_TP: 762.9600 - val_TN: 1082.4301 - val_FP: 23.5700 - val_FN: 41.0400\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0399 - Accuracy: 0.9868 - Precision: 0.9641 - Recall: 0.9597 - TP: 3235.9800 - TN: 5551.7998 - FP: 95.2000 - FN: 136.0200 - val_loss: 0.0865 - val_Accuracy: 0.9759 - val_Precision: 0.9614 - val_Recall: 0.9484 - val_TP: 762.5200 - val_TN: 1082.0200 - val_FP: 23.9800 - val_FN: 41.4800\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0393 - Accuracy: 0.9872 - Precision: 0.9640 - Recall: 0.9597 - TP: 3236.1001 - TN: 5551.2700 - FP: 95.7300 - FN: 135.9000 - val_loss: 0.0852 - val_Accuracy: 0.9770 - val_Precision: 0.9644 - val_Recall: 0.9478 - val_TP: 762.0300 - val_TN: 1084.6500 - val_FP: 21.3500 - val_FN: 41.9700\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0375 - Accuracy: 0.9874 - Precision: 0.9646 - Recall: 0.9604 - TP: 3238.5000 - TN: 5553.6699 - FP: 93.3300 - FN: 133.5000 - val_loss: 0.0852 - val_Accuracy: 0.9775 - val_Precision: 0.9658 - val_Recall: 0.9471 - val_TP: 761.4500 - val_TN: 1085.8300 - val_FP: 20.1700 - val_FN: 42.5500\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0394 - Accuracy: 0.9867 - Precision: 0.9652 - Recall: 0.9595 - TP: 3235.3899 - TN: 5556.2202 - FP: 90.7800 - FN: 136.6100 - val_loss: 0.0877 - val_Accuracy: 0.9754 - val_Precision: 0.9573 - val_Recall: 0.9505 - val_TP: 764.2300 - val_TN: 1078.1801 - val_FP: 27.8200 - val_FN: 39.7700\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0407 - Accuracy: 0.9866 - Precision: 0.9636 - Recall: 0.9603 - TP: 3238.0701 - TN: 5550.0601 - FP: 96.9400 - FN: 133.9300 - val_loss: 0.0904 - val_Accuracy: 0.9749 - val_Precision: 0.9556 - val_Recall: 0.9505 - val_TP: 764.1900 - val_TN: 1076.6000 - val_FP: 29.4000 - val_FN: 39.8100\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0364 - Accuracy: 0.9878 - Precision: 0.9655 - Recall: 0.9602 - TP: 3237.9399 - TN: 5556.8501 - FP: 90.1500 - FN: 134.0600 - val_loss: 0.0847 - val_Accuracy: 0.9770 - val_Precision: 0.9593 - val_Recall: 0.9513 - val_TP: 764.8300 - val_TN: 1080.0699 - val_FP: 25.9300 - val_FN: 39.1700\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0366 - Accuracy: 0.9868 - Precision: 0.9643 - Recall: 0.9603 - TP: 3238.1399 - TN: 5552.2598 - FP: 94.7400 - FN: 133.8600 - val_loss: 0.0861 - val_Accuracy: 0.9754 - val_Precision: 0.9608 - val_Recall: 0.9495 - val_TP: 763.3700 - val_TN: 1081.4800 - val_FP: 24.5200 - val_FN: 40.6300\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0391 - Accuracy: 0.9867 - Precision: 0.9644 - Recall: 0.9608 - TP: 3239.8000 - TN: 5552.9702 - FP: 94.0300 - FN: 132.2000 - val_loss: 0.0852 - val_Accuracy: 0.9775 - val_Precision: 0.9634 - val_Recall: 0.9488 - val_TP: 762.8000 - val_TN: 1083.7600 - val_FP: 22.2400 - val_FN: 41.2000\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0371 - Accuracy: 0.9870 - Precision: 0.9651 - Recall: 0.9604 - TP: 3238.5500 - TN: 5555.4399 - FP: 91.5600 - FN: 133.4500 - val_loss: 0.0863 - val_Accuracy: 0.9764 - val_Precision: 0.9624 - val_Recall: 0.9486 - val_TP: 762.6700 - val_TN: 1082.9700 - val_FP: 23.0300 - val_FN: 41.3300\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0388 - Accuracy: 0.9869 - Precision: 0.9640 - Recall: 0.9604 - TP: 3238.5100 - TN: 5551.8999 - FP: 95.1000 - FN: 133.4900 - val_loss: 0.0868 - val_Accuracy: 0.9759 - val_Precision: 0.9629 - val_Recall: 0.9480 - val_TP: 762.2100 - val_TN: 1083.4000 - val_FP: 22.6000 - val_FN: 41.7900\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0368 - Accuracy: 0.9874 - Precision: 0.9652 - Recall: 0.9608 - TP: 3239.6499 - TN: 5555.7998 - FP: 91.2000 - FN: 132.3500 - val_loss: 0.0877 - val_Accuracy: 0.9759 - val_Precision: 0.9609 - val_Recall: 0.9490 - val_TP: 763.0200 - val_TN: 1081.6000 - val_FP: 24.4000 - val_FN: 40.9800\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0369 - Accuracy: 0.9879 - Precision: 0.9655 - Recall: 0.9609 - TP: 3240.0901 - TN: 5556.9902 - FP: 90.0100 - FN: 131.9100 - val_loss: 0.0880 - val_Accuracy: 0.9764 - val_Precision: 0.9612 - val_Recall: 0.9486 - val_TP: 762.7100 - val_TN: 1081.9399 - val_FP: 24.0600 - val_FN: 41.2900\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0407 - Accuracy: 0.9869 - Precision: 0.9641 - Recall: 0.9614 - TP: 3241.7200 - TN: 5552.2998 - FP: 94.7000 - FN: 130.2800 - val_loss: 0.0881 - val_Accuracy: 0.9754 - val_Precision: 0.9637 - val_Recall: 0.9472 - val_TP: 761.5100 - val_TN: 1084.0900 - val_FP: 21.9100 - val_FN: 42.4900\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0380 - Accuracy: 0.9868 - Precision: 0.9653 - Recall: 0.9601 - TP: 3237.5300 - TN: 5556.6802 - FP: 90.3200 - FN: 134.4700 - val_loss: 0.0866 - val_Accuracy: 0.9770 - val_Precision: 0.9614 - val_Recall: 0.9494 - val_TP: 763.3500 - val_TN: 1081.9900 - val_FP: 24.0100 - val_FN: 40.6500\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0362 - Accuracy: 0.9876 - Precision: 0.9648 - Recall: 0.9607 - TP: 3239.4700 - TN: 5554.8599 - FP: 92.1400 - FN: 132.5300 - val_loss: 0.0868 - val_Accuracy: 0.9775 - val_Precision: 0.9624 - val_Recall: 0.9489 - val_TP: 762.9000 - val_TN: 1082.9600 - val_FP: 23.0400 - val_FN: 41.1000\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0385 - Accuracy: 0.9865 - Precision: 0.9641 - Recall: 0.9604 - TP: 3238.4399 - TN: 5552.4102 - FP: 94.5900 - FN: 133.5600 - val_loss: 0.0863 - val_Accuracy: 0.9770 - val_Precision: 0.9662 - val_Recall: 0.9470 - val_TP: 761.4200 - val_TN: 1086.2500 - val_FP: 19.7500 - val_FN: 42.5800\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0396 - Accuracy: 0.9869 - Precision: 0.9659 - Recall: 0.9605 - TP: 3238.8401 - TN: 5558.9702 - FP: 88.0300 - FN: 133.1600 - val_loss: 0.0871 - val_Accuracy: 0.9759 - val_Precision: 0.9619 - val_Recall: 0.9491 - val_TP: 763.0500 - val_TN: 1082.5400 - val_FP: 23.4600 - val_FN: 40.9500\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0379 - Accuracy: 0.9872 - Precision: 0.9646 - Recall: 0.9610 - TP: 3240.3799 - TN: 5553.5698 - FP: 93.4300 - FN: 131.6200 - val_loss: 0.0880 - val_Accuracy: 0.9754 - val_Precision: 0.9602 - val_Recall: 0.9498 - val_TP: 763.6700 - val_TN: 1081.0000 - val_FP: 25.0000 - val_FN: 40.3300\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0380 - Accuracy: 0.9867 - Precision: 0.9654 - Recall: 0.9612 - TP: 3241.0300 - TN: 5557.2798 - FP: 89.7200 - FN: 130.9700 - val_loss: 0.0860 - val_Accuracy: 0.9775 - val_Precision: 0.9627 - val_Recall: 0.9498 - val_TP: 763.6400 - val_TN: 1083.1300 - val_FP: 22.8700 - val_FN: 40.3600\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0415 - Accuracy: 0.9869 - Precision: 0.9647 - Recall: 0.9603 - TP: 3238.3000 - TN: 5554.2598 - FP: 92.7400 - FN: 133.7000 - val_loss: 0.0882 - val_Accuracy: 0.9759 - val_Precision: 0.9591 - val_Recall: 0.9489 - val_TP: 762.9000 - val_TN: 1079.7900 - val_FP: 26.2100 - val_FN: 41.1000\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0393 - Accuracy: 0.9871 - Precision: 0.9649 - Recall: 0.9593 - TP: 3234.8899 - TN: 5555.0200 - FP: 91.9800 - FN: 137.1100 - val_loss: 0.0942 - val_Accuracy: 0.9728 - val_Precision: 0.9494 - val_Recall: 0.9515 - val_TP: 764.9800 - val_TN: 1070.5400 - val_FP: 35.4600 - val_FN: 39.0200\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0448 - Accuracy: 0.9863 - Precision: 0.9629 - Recall: 0.9596 - TP: 3235.7300 - TN: 5547.3501 - FP: 99.6500 - FN: 136.2700 - val_loss: 0.0856 - val_Accuracy: 0.9759 - val_Precision: 0.9622 - val_Recall: 0.9486 - val_TP: 762.6400 - val_TN: 1082.7000 - val_FP: 23.3000 - val_FN: 41.3600\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0381 - Accuracy: 0.9871 - Precision: 0.9638 - Recall: 0.9600 - TP: 3237.0701 - TN: 5550.5000 - FP: 96.5000 - FN: 134.9300 - val_loss: 0.0879 - val_Accuracy: 0.9754 - val_Precision: 0.9615 - val_Recall: 0.9476 - val_TP: 761.9100 - val_TN: 1082.0800 - val_FP: 23.9200 - val_FN: 42.0900\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0414 - Accuracy: 0.9868 - Precision: 0.9644 - Recall: 0.9599 - TP: 3236.6299 - TN: 5553.2300 - FP: 93.7700 - FN: 135.3700 - val_loss: 0.0873 - val_Accuracy: 0.9759 - val_Precision: 0.9625 - val_Recall: 0.9476 - val_TP: 761.8600 - val_TN: 1083.0100 - val_FP: 22.9900 - val_FN: 42.1400\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0370 - Accuracy: 0.9870 - Precision: 0.9654 - Recall: 0.9602 - TP: 3237.8401 - TN: 5556.6499 - FP: 90.3500 - FN: 134.1600 - val_loss: 0.0860 - val_Accuracy: 0.9754 - val_Precision: 0.9603 - val_Recall: 0.9499 - val_TP: 763.7100 - val_TN: 1081.0699 - val_FP: 24.9300 - val_FN: 40.2900\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0371 - Accuracy: 0.9876 - Precision: 0.9650 - Recall: 0.9609 - TP: 3240.1201 - TN: 5555.0098 - FP: 91.9900 - FN: 131.8800 - val_loss: 0.0985 - val_Accuracy: 0.9738 - val_Precision: 0.9467 - val_Recall: 0.9499 - val_TP: 763.6800 - val_TN: 1068.1500 - val_FP: 37.8500 - val_FN: 40.3200\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0387 - Accuracy: 0.9868 - Precision: 0.9643 - Recall: 0.9601 - TP: 3237.5400 - TN: 5552.6099 - FP: 94.3900 - FN: 134.4600 - val_loss: 0.0857 - val_Accuracy: 0.9775 - val_Precision: 0.9633 - val_Recall: 0.9484 - val_TP: 762.5300 - val_TN: 1083.7200 - val_FP: 22.2800 - val_FN: 41.4700\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0384 - Accuracy: 0.9868 - Precision: 0.9640 - Recall: 0.9603 - TP: 3238.1201 - TN: 5551.7002 - FP: 95.3000 - FN: 133.8800 - val_loss: 0.0856 - val_Accuracy: 0.9764 - val_Precision: 0.9657 - val_Recall: 0.9473 - val_TP: 761.6200 - val_TN: 1085.8000 - val_FP: 20.2000 - val_FN: 42.3800\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0368 - Accuracy: 0.9872 - Precision: 0.9656 - Recall: 0.9602 - TP: 3237.6399 - TN: 5557.5298 - FP: 89.4700 - FN: 134.3600 - val_loss: 0.0880 - val_Accuracy: 0.9759 - val_Precision: 0.9585 - val_Recall: 0.9507 - val_TP: 764.3700 - val_TN: 1079.4399 - val_FP: 26.5600 - val_FN: 39.6300\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0380 - Accuracy: 0.9867 - Precision: 0.9642 - Recall: 0.9609 - TP: 3240.1101 - TN: 5552.3198 - FP: 94.6800 - FN: 131.8900 - val_loss: 0.0887 - val_Accuracy: 0.9759 - val_Precision: 0.9615 - val_Recall: 0.9483 - val_TP: 762.4000 - val_TN: 1082.1700 - val_FP: 23.8300 - val_FN: 41.6000\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0386 - Accuracy: 0.9876 - Precision: 0.9650 - Recall: 0.9605 - TP: 3238.9299 - TN: 5555.3901 - FP: 91.6100 - FN: 133.0700 - val_loss: 0.0856 - val_Accuracy: 0.9770 - val_Precision: 0.9643 - val_Recall: 0.9483 - val_TP: 762.4500 - val_TN: 1084.5300 - val_FP: 21.4700 - val_FN: 41.5500\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0368 - Accuracy: 0.9872 - Precision: 0.9652 - Recall: 0.9613 - TP: 3241.3799 - TN: 5555.8301 - FP: 91.1700 - FN: 130.6200 - val_loss: 0.0866 - val_Accuracy: 0.9770 - val_Precision: 0.9639 - val_Recall: 0.9479 - val_TP: 762.0800 - val_TN: 1084.2600 - val_FP: 21.7400 - val_FN: 41.9200\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0380 - Accuracy: 0.9874 - Precision: 0.9658 - Recall: 0.9606 - TP: 3239.2500 - TN: 5558.6699 - FP: 88.3300 - FN: 132.7500 - val_loss: 0.0880 - val_Accuracy: 0.9759 - val_Precision: 0.9584 - val_Recall: 0.9506 - val_TP: 764.2900 - val_TN: 1079.4200 - val_FP: 26.5800 - val_FN: 39.7100\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0378 - Accuracy: 0.9878 - Precision: 0.9650 - Recall: 0.9607 - TP: 3239.5901 - TN: 5555.2798 - FP: 91.7200 - FN: 132.4100 - val_loss: 0.0878 - val_Accuracy: 0.9759 - val_Precision: 0.9597 - val_Recall: 0.9501 - val_TP: 763.9000 - val_TN: 1080.5601 - val_FP: 25.4400 - val_FN: 40.1000\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0380 - Accuracy: 0.9871 - Precision: 0.9649 - Recall: 0.9607 - TP: 3239.5601 - TN: 5554.8501 - FP: 92.1500 - FN: 132.4400 - val_loss: 0.0877 - val_Accuracy: 0.9759 - val_Precision: 0.9592 - val_Recall: 0.9505 - val_TP: 764.1900 - val_TN: 1080.0800 - val_FP: 25.9200 - val_FN: 39.8100\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0375 - Accuracy: 0.9869 - Precision: 0.9649 - Recall: 0.9606 - TP: 3238.9900 - TN: 5555.0698 - FP: 91.9300 - FN: 133.0100 - val_loss: 0.0917 - val_Accuracy: 0.9749 - val_Precision: 0.9552 - val_Recall: 0.9504 - val_TP: 764.1600 - val_TN: 1076.2200 - val_FP: 29.7800 - val_FN: 39.8400\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0385 - Accuracy: 0.9871 - Precision: 0.9638 - Recall: 0.9610 - TP: 3240.4199 - TN: 5550.8301 - FP: 96.1700 - FN: 131.5800 - val_loss: 0.0889 - val_Accuracy: 0.9764 - val_Precision: 0.9607 - val_Recall: 0.9490 - val_TP: 763.0300 - val_TN: 1081.5000 - val_FP: 24.5000 - val_FN: 40.9700\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0369 - Accuracy: 0.9867 - Precision: 0.9656 - Recall: 0.9605 - TP: 3238.9700 - TN: 5557.9399 - FP: 89.0600 - FN: 133.0300 - val_loss: 0.0885 - val_Accuracy: 0.9754 - val_Precision: 0.9591 - val_Recall: 0.9502 - val_TP: 764.0000 - val_TN: 1080.0400 - val_FP: 25.9600 - val_FN: 40.0000\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0360 - Accuracy: 0.9875 - Precision: 0.9648 - Recall: 0.9612 - TP: 3241.1001 - TN: 5554.4199 - FP: 92.5800 - FN: 130.9000 - val_loss: 0.0930 - val_Accuracy: 0.9749 - val_Precision: 0.9580 - val_Recall: 0.9485 - val_TP: 762.5600 - val_TN: 1078.9200 - val_FP: 27.0800 - val_FN: 41.4400\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0369 - Accuracy: 0.9877 - Precision: 0.9655 - Recall: 0.9613 - TP: 3241.4199 - TN: 5557.0601 - FP: 89.9400 - FN: 130.5800 - val_loss: 0.0869 - val_Accuracy: 0.9780 - val_Precision: 0.9622 - val_Recall: 0.9494 - val_TP: 763.3000 - val_TN: 1082.7200 - val_FP: 23.2800 - val_FN: 40.7000\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0369 - Accuracy: 0.9870 - Precision: 0.9650 - Recall: 0.9609 - TP: 3240.1499 - TN: 5555.9800 - FP: 91.0200 - FN: 131.8500 - val_loss: 0.0868 - val_Accuracy: 0.9775 - val_Precision: 0.9633 - val_Recall: 0.9489 - val_TP: 762.8800 - val_TN: 1083.6500 - val_FP: 22.3500 - val_FN: 41.1200\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0365 - Accuracy: 0.9877 - Precision: 0.9653 - Recall: 0.9616 - TP: 3242.4700 - TN: 5556.6401 - FP: 90.3600 - FN: 129.5300 - val_loss: 0.0888 - val_Accuracy: 0.9759 - val_Precision: 0.9625 - val_Recall: 0.9482 - val_TP: 762.3600 - val_TN: 1083.0500 - val_FP: 22.9500 - val_FN: 41.6400\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0394 - Accuracy: 0.9880 - Precision: 0.9655 - Recall: 0.9608 - TP: 3239.8301 - TN: 5557.3198 - FP: 89.6800 - FN: 132.1700 - val_loss: 0.0882 - val_Accuracy: 0.9754 - val_Precision: 0.9595 - val_Recall: 0.9504 - val_TP: 764.1400 - val_TN: 1080.3300 - val_FP: 25.6700 - val_FN: 39.8600\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0381 - Accuracy: 0.9877 - Precision: 0.9643 - Recall: 0.9609 - TP: 3240.1599 - TN: 5552.7002 - FP: 94.3000 - FN: 131.8400 - val_loss: 0.0886 - val_Accuracy: 0.9759 - val_Precision: 0.9619 - val_Recall: 0.9487 - val_TP: 762.7600 - val_TN: 1082.5500 - val_FP: 23.4500 - val_FN: 41.2400\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0363 - Accuracy: 0.9876 - Precision: 0.9655 - Recall: 0.9612 - TP: 3241.0701 - TN: 5557.0498 - FP: 89.9500 - FN: 130.9300 - val_loss: 0.0885 - val_Accuracy: 0.9770 - val_Precision: 0.9615 - val_Recall: 0.9494 - val_TP: 763.2800 - val_TN: 1082.1801 - val_FP: 23.8200 - val_FN: 40.7200\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0369 - Accuracy: 0.9877 - Precision: 0.9650 - Recall: 0.9611 - TP: 3240.9500 - TN: 5555.0400 - FP: 91.9600 - FN: 131.0500 - val_loss: 0.0906 - val_Accuracy: 0.9754 - val_Precision: 0.9619 - val_Recall: 0.9479 - val_TP: 762.1400 - val_TN: 1082.5500 - val_FP: 23.4500 - val_FN: 41.8600\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0354 - Accuracy: 0.9878 - Precision: 0.9658 - Recall: 0.9614 - TP: 3241.8301 - TN: 5558.4702 - FP: 88.5300 - FN: 130.1700 - val_loss: 0.0882 - val_Accuracy: 0.9770 - val_Precision: 0.9623 - val_Recall: 0.9490 - val_TP: 763.0200 - val_TN: 1082.8400 - val_FP: 23.1600 - val_FN: 40.9800\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0376 - Accuracy: 0.9878 - Precision: 0.9657 - Recall: 0.9601 - TP: 3237.3201 - TN: 5557.8501 - FP: 89.1500 - FN: 134.6800 - val_loss: 0.0867 - val_Accuracy: 0.9775 - val_Precision: 0.9602 - val_Recall: 0.9514 - val_TP: 764.9100 - val_TN: 1080.8500 - val_FP: 25.1500 - val_FN: 39.0900\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 5ms/step - loss: 0.0406 - Accuracy: 0.9871 - Precision: 0.9650 - Recall: 0.9606 - TP: 3239.1001 - TN: 5555.5098 - FP: 91.4900 - FN: 132.9000 - val_loss: 0.0872 - val_Accuracy: 0.9754 - val_Precision: 0.9645 - val_Recall: 0.9469 - val_TP: 761.3400 - val_TN: 1084.8000 - val_FP: 21.2000 - val_FN: 42.6600\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0371 - Accuracy: 0.9875 - Precision: 0.9653 - Recall: 0.9609 - TP: 3240.0100 - TN: 5556.4399 - FP: 90.5600 - FN: 131.9900 - val_loss: 0.0862 - val_Accuracy: 0.9770 - val_Precision: 0.9645 - val_Recall: 0.9477 - val_TP: 761.9600 - val_TN: 1084.7700 - val_FP: 21.2300 - val_FN: 42.0400\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0384 - Accuracy: 0.9872 - Precision: 0.9646 - Recall: 0.9599 - TP: 3236.8401 - TN: 5554.2202 - FP: 92.7800 - FN: 135.1600 - val_loss: 0.1014 - val_Accuracy: 0.9712 - val_Precision: 0.9442 - val_Recall: 0.9500 - val_TP: 763.8200 - val_TN: 1065.8300 - val_FP: 40.1700 - val_FN: 40.1800\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0378 - Accuracy: 0.9874 - Precision: 0.9653 - Recall: 0.9607 - TP: 3239.4199 - TN: 5556.3999 - FP: 90.6000 - FN: 132.5800 - val_loss: 0.0864 - val_Accuracy: 0.9764 - val_Precision: 0.9617 - val_Recall: 0.9495 - val_TP: 763.4100 - val_TN: 1082.2900 - val_FP: 23.7100 - val_FN: 40.5900\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0367 - Accuracy: 0.9869 - Precision: 0.9650 - Recall: 0.9604 - TP: 3238.4500 - TN: 5555.6899 - FP: 91.3100 - FN: 133.5500 - val_loss: 0.0853 - val_Accuracy: 0.9764 - val_Precision: 0.9619 - val_Recall: 0.9504 - val_TP: 764.1100 - val_TN: 1082.4301 - val_FP: 23.5700 - val_FN: 39.8900\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0434 - Accuracy: 0.9864 - Precision: 0.9633 - Recall: 0.9601 - TP: 3237.3301 - TN: 5549.3198 - FP: 97.6800 - FN: 134.6700 - val_loss: 0.0915 - val_Accuracy: 0.9754 - val_Precision: 0.9573 - val_Recall: 0.9500 - val_TP: 763.8300 - val_TN: 1078.3300 - val_FP: 27.6700 - val_FN: 40.1700\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0396 - Accuracy: 0.9876 - Precision: 0.9650 - Recall: 0.9606 - TP: 3239.1201 - TN: 5555.2100 - FP: 91.7900 - FN: 132.8800 - val_loss: 0.0882 - val_Accuracy: 0.9764 - val_Precision: 0.9621 - val_Recall: 0.9485 - val_TP: 762.5700 - val_TN: 1082.7700 - val_FP: 23.2300 - val_FN: 41.4300\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0365 - Accuracy: 0.9875 - Precision: 0.9651 - Recall: 0.9614 - TP: 3241.9299 - TN: 5555.9902 - FP: 91.0100 - FN: 130.0700 - val_loss: 0.0910 - val_Accuracy: 0.9759 - val_Precision: 0.9603 - val_Recall: 0.9482 - val_TP: 762.3600 - val_TN: 1081.0200 - val_FP: 24.9800 - val_FN: 41.6400\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0411 - Accuracy: 0.9868 - Precision: 0.9647 - Recall: 0.9604 - TP: 3238.4199 - TN: 5554.6699 - FP: 92.3300 - FN: 133.5800 - val_loss: 0.0872 - val_Accuracy: 0.9764 - val_Precision: 0.9605 - val_Recall: 0.9501 - val_TP: 763.8500 - val_TN: 1081.2700 - val_FP: 24.7300 - val_FN: 40.1500\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0361 - Accuracy: 0.9877 - Precision: 0.9658 - Recall: 0.9608 - TP: 3239.6699 - TN: 5558.3398 - FP: 88.6600 - FN: 132.3300 - val_loss: 0.0869 - val_Accuracy: 0.9754 - val_Precision: 0.9583 - val_Recall: 0.9518 - val_TP: 765.2600 - val_TN: 1079.2900 - val_FP: 26.7100 - val_FN: 38.7400\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0364 - Accuracy: 0.9876 - Precision: 0.9648 - Recall: 0.9609 - TP: 3240.2500 - TN: 5554.5801 - FP: 92.4200 - FN: 131.7500 - val_loss: 0.0900 - val_Accuracy: 0.9759 - val_Precision: 0.9566 - val_Recall: 0.9508 - val_TP: 764.4300 - val_TN: 1077.6700 - val_FP: 28.3300 - val_FN: 39.5700\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0376 - Accuracy: 0.9874 - Precision: 0.9649 - Recall: 0.9611 - TP: 3240.7800 - TN: 5554.7598 - FP: 92.2400 - FN: 131.2200 - val_loss: 0.0864 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9497 - val_TP: 763.5800 - val_TN: 1082.8300 - val_FP: 23.1700 - val_FN: 40.4200\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0357 - Accuracy: 0.9878 - Precision: 0.9653 - Recall: 0.9613 - TP: 3241.4199 - TN: 5556.5898 - FP: 90.4100 - FN: 130.5800 - val_loss: 0.0888 - val_Accuracy: 0.9759 - val_Precision: 0.9626 - val_Recall: 0.9481 - val_TP: 762.2400 - val_TN: 1083.1899 - val_FP: 22.8100 - val_FN: 41.7600\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0366 - Accuracy: 0.9870 - Precision: 0.9654 - Recall: 0.9603 - TP: 3238.2900 - TN: 5556.6699 - FP: 90.3300 - FN: 133.7100 - val_loss: 0.0880 - val_Accuracy: 0.9764 - val_Precision: 0.9607 - val_Recall: 0.9499 - val_TP: 763.6900 - val_TN: 1081.4900 - val_FP: 24.5100 - val_FN: 40.3100\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0395 - Accuracy: 0.9869 - Precision: 0.9637 - Recall: 0.9606 - TP: 3239.0801 - TN: 5550.7002 - FP: 96.3000 - FN: 132.9200 - val_loss: 0.0882 - val_Accuracy: 0.9770 - val_Precision: 0.9651 - val_Recall: 0.9473 - val_TP: 761.5900 - val_TN: 1085.3199 - val_FP: 20.6800 - val_FN: 42.4100\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0363 - Accuracy: 0.9880 - Precision: 0.9660 - Recall: 0.9610 - TP: 3240.3401 - TN: 5559.2900 - FP: 87.7100 - FN: 131.6600 - val_loss: 0.0871 - val_Accuracy: 0.9775 - val_Precision: 0.9626 - val_Recall: 0.9494 - val_TP: 763.3300 - val_TN: 1083.0800 - val_FP: 22.9200 - val_FN: 40.6700\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0378 - Accuracy: 0.9874 - Precision: 0.9647 - Recall: 0.9616 - TP: 3242.5300 - TN: 5554.5601 - FP: 92.4400 - FN: 129.4700 - val_loss: 0.0977 - val_Accuracy: 0.9743 - val_Precision: 0.9522 - val_Recall: 0.9492 - val_TP: 763.1600 - val_TN: 1073.3199 - val_FP: 32.6800 - val_FN: 40.8400\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0394 - Accuracy: 0.9875 - Precision: 0.9655 - Recall: 0.9603 - TP: 3238.2100 - TN: 5557.7500 - FP: 89.2500 - FN: 133.7900 - val_loss: 0.0887 - val_Accuracy: 0.9764 - val_Precision: 0.9605 - val_Recall: 0.9500 - val_TP: 763.7800 - val_TN: 1081.2800 - val_FP: 24.7200 - val_FN: 40.2200\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0356 - Accuracy: 0.9880 - Precision: 0.9650 - Recall: 0.9620 - TP: 3243.9500 - TN: 5555.0498 - FP: 91.9500 - FN: 128.0500 - val_loss: 0.0872 - val_Accuracy: 0.9780 - val_Precision: 0.9639 - val_Recall: 0.9489 - val_TP: 762.9200 - val_TN: 1084.2200 - val_FP: 21.7800 - val_FN: 41.0800\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0363 - Accuracy: 0.9879 - Precision: 0.9659 - Recall: 0.9617 - TP: 3242.8601 - TN: 5558.7900 - FP: 88.2100 - FN: 129.1400 - val_loss: 0.0903 - val_Accuracy: 0.9770 - val_Precision: 0.9609 - val_Recall: 0.9490 - val_TP: 762.9800 - val_TN: 1081.6899 - val_FP: 24.3100 - val_FN: 41.0200\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0365 - Accuracy: 0.9876 - Precision: 0.9656 - Recall: 0.9617 - TP: 3242.7200 - TN: 5557.8999 - FP: 89.1000 - FN: 129.2800 - val_loss: 0.0899 - val_Accuracy: 0.9754 - val_Precision: 0.9645 - val_Recall: 0.9469 - val_TP: 761.2900 - val_TN: 1084.8400 - val_FP: 21.1600 - val_FN: 42.7100\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0390 - Accuracy: 0.9872 - Precision: 0.9654 - Recall: 0.9608 - TP: 3239.8301 - TN: 5557.2900 - FP: 89.7100 - FN: 132.1700 - val_loss: 0.0873 - val_Accuracy: 0.9775 - val_Precision: 0.9625 - val_Recall: 0.9500 - val_TP: 763.7700 - val_TN: 1083.0200 - val_FP: 22.9800 - val_FN: 40.2300\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0372 - Accuracy: 0.9872 - Precision: 0.9655 - Recall: 0.9609 - TP: 3240.2000 - TN: 5557.2798 - FP: 89.7200 - FN: 131.8000 - val_loss: 0.0896 - val_Accuracy: 0.9754 - val_Precision: 0.9585 - val_Recall: 0.9511 - val_TP: 764.6500 - val_TN: 1079.4700 - val_FP: 26.5300 - val_FN: 39.3500\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0395 - Accuracy: 0.9872 - Precision: 0.9639 - Recall: 0.9611 - TP: 3240.8999 - TN: 5551.5498 - FP: 95.4500 - FN: 131.1000 - val_loss: 0.0894 - val_Accuracy: 0.9764 - val_Precision: 0.9611 - val_Recall: 0.9494 - val_TP: 763.3500 - val_TN: 1081.8600 - val_FP: 24.1400 - val_FN: 40.6500\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0352 - Accuracy: 0.9879 - Precision: 0.9658 - Recall: 0.9616 - TP: 3242.6799 - TN: 5558.7202 - FP: 88.2800 - FN: 129.3200 - val_loss: 0.0891 - val_Accuracy: 0.9759 - val_Precision: 0.9630 - val_Recall: 0.9485 - val_TP: 762.5700 - val_TN: 1083.5500 - val_FP: 22.4500 - val_FN: 41.4300\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 4ms/step - loss: 0.0397 - Accuracy: 0.9868 - Precision: 0.9651 - Recall: 0.9607 - TP: 3239.6201 - TN: 5556.1401 - FP: 90.8600 - FN: 132.3800 - val_loss: 0.0870 - val_Accuracy: 0.9764 - val_Precision: 0.9606 - val_Recall: 0.9499 - val_TP: 763.7000 - val_TN: 1081.3101 - val_FP: 24.6900 - val_FN: 40.3000\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0370 - Accuracy: 0.9872 - Precision: 0.9642 - Recall: 0.9612 - TP: 3241.0300 - TN: 5552.1899 - FP: 94.8100 - FN: 130.9700 - val_loss: 0.0889 - val_Accuracy: 0.9759 - val_Precision: 0.9628 - val_Recall: 0.9477 - val_TP: 761.9300 - val_TN: 1083.3400 - val_FP: 22.6600 - val_FN: 42.0700\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0388 - Accuracy: 0.9874 - Precision: 0.9652 - Recall: 0.9601 - TP: 3237.5701 - TN: 5556.4199 - FP: 90.5800 - FN: 134.4300 - val_loss: 0.0879 - val_Accuracy: 0.9759 - val_Precision: 0.9614 - val_Recall: 0.9488 - val_TP: 762.8300 - val_TN: 1082.0900 - val_FP: 23.9100 - val_FN: 41.1700\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0378 - Accuracy: 0.9877 - Precision: 0.9645 - Recall: 0.9616 - TP: 3242.6499 - TN: 5553.3901 - FP: 93.6100 - FN: 129.3500 - val_loss: 0.0907 - val_Accuracy: 0.9759 - val_Precision: 0.9620 - val_Recall: 0.9475 - val_TP: 761.8000 - val_TN: 1082.6600 - val_FP: 23.3400 - val_FN: 42.2000\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0361 - Accuracy: 0.9875 - Precision: 0.9660 - Recall: 0.9602 - TP: 3237.7400 - TN: 5559.5298 - FP: 87.4700 - FN: 134.2600 - val_loss: 0.0860 - val_Accuracy: 0.9780 - val_Precision: 0.9623 - val_Recall: 0.9499 - val_TP: 763.6900 - val_TN: 1082.8199 - val_FP: 23.1800 - val_FN: 40.3100\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0370 - Accuracy: 0.9874 - Precision: 0.9643 - Recall: 0.9616 - TP: 3242.4199 - TN: 5552.6899 - FP: 94.3100 - FN: 129.5800 - val_loss: 0.0894 - val_Accuracy: 0.9754 - val_Precision: 0.9639 - val_Recall: 0.9470 - val_TP: 761.3600 - val_TN: 1084.3600 - val_FP: 21.6400 - val_FN: 42.6400\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0379 - Accuracy: 0.9870 - Precision: 0.9650 - Recall: 0.9609 - TP: 3240.2400 - TN: 5556.0298 - FP: 90.9700 - FN: 131.7600 - val_loss: 0.0877 - val_Accuracy: 0.9764 - val_Precision: 0.9661 - val_Recall: 0.9467 - val_TP: 761.1500 - val_TN: 1086.2200 - val_FP: 19.7800 - val_FN: 42.8500\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0389 - Accuracy: 0.9871 - Precision: 0.9647 - Recall: 0.9602 - TP: 3237.7600 - TN: 5554.7402 - FP: 92.2600 - FN: 134.2400 - val_loss: 0.0918 - val_Accuracy: 0.9754 - val_Precision: 0.9607 - val_Recall: 0.9479 - val_TP: 762.0800 - val_TN: 1081.5100 - val_FP: 24.4900 - val_FN: 41.9200\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0365 - Accuracy: 0.9879 - Precision: 0.9657 - Recall: 0.9608 - TP: 3239.7800 - TN: 5557.9600 - FP: 89.0400 - FN: 132.2200 - val_loss: 0.0865 - val_Accuracy: 0.9775 - val_Precision: 0.9623 - val_Recall: 0.9499 - val_TP: 763.7300 - val_TN: 1082.7700 - val_FP: 23.2300 - val_FN: 40.2700\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0368 - Accuracy: 0.9877 - Precision: 0.9653 - Recall: 0.9615 - TP: 3242.0200 - TN: 5556.5000 - FP: 90.5000 - FN: 129.9800 - val_loss: 0.0866 - val_Accuracy: 0.9770 - val_Precision: 0.9612 - val_Recall: 0.9505 - val_TP: 764.1700 - val_TN: 1081.8101 - val_FP: 24.1900 - val_FN: 39.8300\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0377 - Accuracy: 0.9868 - Precision: 0.9645 - Recall: 0.9605 - TP: 3238.6699 - TN: 5553.5498 - FP: 93.4500 - FN: 133.3300 - val_loss: 0.0900 - val_Accuracy: 0.9764 - val_Precision: 0.9611 - val_Recall: 0.9486 - val_TP: 762.6900 - val_TN: 1081.8300 - val_FP: 24.1700 - val_FN: 41.3100\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0367 - Accuracy: 0.9874 - Precision: 0.9650 - Recall: 0.9613 - TP: 3241.6299 - TN: 5555.3301 - FP: 91.6700 - FN: 130.3700 - val_loss: 0.0881 - val_Accuracy: 0.9770 - val_Precision: 0.9634 - val_Recall: 0.9482 - val_TP: 762.3800 - val_TN: 1083.8800 - val_FP: 22.1200 - val_FN: 41.6200\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0415 - Accuracy: 0.9875 - Precision: 0.9651 - Recall: 0.9610 - TP: 3240.5100 - TN: 5556.4600 - FP: 90.5400 - FN: 131.4900 - val_loss: 0.0875 - val_Accuracy: 0.9780 - val_Precision: 0.9633 - val_Recall: 0.9490 - val_TP: 762.9900 - val_TN: 1083.7100 - val_FP: 22.2900 - val_FN: 41.0100\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0400 - Accuracy: 0.9872 - Precision: 0.9648 - Recall: 0.9604 - TP: 3238.5400 - TN: 5554.6401 - FP: 92.3600 - FN: 133.4600 - val_loss: 0.0896 - val_Accuracy: 0.9764 - val_Precision: 0.9612 - val_Recall: 0.9489 - val_TP: 762.9300 - val_TN: 1081.9200 - val_FP: 24.0800 - val_FN: 41.0700\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0375 - Accuracy: 0.9881 - Precision: 0.9653 - Recall: 0.9619 - TP: 3243.4900 - TN: 5556.7002 - FP: 90.3000 - FN: 128.5100 - val_loss: 0.0931 - val_Accuracy: 0.9749 - val_Precision: 0.9606 - val_Recall: 0.9480 - val_TP: 762.1600 - val_TN: 1081.4700 - val_FP: 24.5300 - val_FN: 41.8400\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0360 - Accuracy: 0.9875 - Precision: 0.9662 - Recall: 0.9612 - TP: 3241.1599 - TN: 5560.1602 - FP: 86.8400 - FN: 130.8400 - val_loss: 0.0871 - val_Accuracy: 0.9770 - val_Precision: 0.9641 - val_Recall: 0.9490 - val_TP: 762.9900 - val_TN: 1084.4301 - val_FP: 21.5700 - val_FN: 41.0100\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0368 - Accuracy: 0.9877 - Precision: 0.9651 - Recall: 0.9610 - TP: 3240.4600 - TN: 5555.8301 - FP: 91.1700 - FN: 131.5400 - val_loss: 0.0890 - val_Accuracy: 0.9759 - val_Precision: 0.9601 - val_Recall: 0.9502 - val_TP: 763.9300 - val_TN: 1080.9100 - val_FP: 25.0900 - val_FN: 40.0700\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0381 - Accuracy: 0.9871 - Precision: 0.9646 - Recall: 0.9615 - TP: 3242.3201 - TN: 5554.0400 - FP: 92.9600 - FN: 129.6800 - val_loss: 0.0929 - val_Accuracy: 0.9749 - val_Precision: 0.9610 - val_Recall: 0.9480 - val_TP: 762.1900 - val_TN: 1081.8199 - val_FP: 24.1800 - val_FN: 41.8100\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0380 - Accuracy: 0.9875 - Precision: 0.9657 - Recall: 0.9608 - TP: 3239.7000 - TN: 5558.3799 - FP: 88.6200 - FN: 132.3000 - val_loss: 0.0891 - val_Accuracy: 0.9764 - val_Precision: 0.9623 - val_Recall: 0.9490 - val_TP: 762.9900 - val_TN: 1082.9600 - val_FP: 23.0400 - val_FN: 41.0100\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0368 - Accuracy: 0.9877 - Precision: 0.9656 - Recall: 0.9616 - TP: 3242.4500 - TN: 5557.9702 - FP: 89.0300 - FN: 129.5500 - val_loss: 0.0927 - val_Accuracy: 0.9754 - val_Precision: 0.9576 - val_Recall: 0.9507 - val_TP: 764.3600 - val_TN: 1078.7500 - val_FP: 27.2500 - val_FN: 39.6400\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0360 - Accuracy: 0.9882 - Precision: 0.9654 - Recall: 0.9625 - TP: 3245.5300 - TN: 5557.3301 - FP: 89.6700 - FN: 126.4700 - val_loss: 0.0890 - val_Accuracy: 0.9770 - val_Precision: 0.9642 - val_Recall: 0.9481 - val_TP: 762.2800 - val_TN: 1084.5699 - val_FP: 21.4300 - val_FN: 41.7200\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0370 - Accuracy: 0.9870 - Precision: 0.9656 - Recall: 0.9612 - TP: 3241.0901 - TN: 5558.1899 - FP: 88.8100 - FN: 130.9100 - val_loss: 0.0897 - val_Accuracy: 0.9759 - val_Precision: 0.9624 - val_Recall: 0.9488 - val_TP: 762.8600 - val_TN: 1083.0200 - val_FP: 22.9800 - val_FN: 41.1400\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0362 - Accuracy: 0.9880 - Precision: 0.9655 - Recall: 0.9622 - TP: 3244.6001 - TN: 5557.5498 - FP: 89.4500 - FN: 127.4000 - val_loss: 0.0929 - val_Accuracy: 0.9754 - val_Precision: 0.9613 - val_Recall: 0.9481 - val_TP: 762.2700 - val_TN: 1082.0699 - val_FP: 23.9300 - val_FN: 41.7300\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0378 - Accuracy: 0.9870 - Precision: 0.9653 - Recall: 0.9611 - TP: 3240.8701 - TN: 5556.8901 - FP: 90.1100 - FN: 131.1300 - val_loss: 0.0920 - val_Accuracy: 0.9764 - val_Precision: 0.9605 - val_Recall: 0.9488 - val_TP: 762.8100 - val_TN: 1081.3700 - val_FP: 24.6300 - val_FN: 41.1900\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0363 - Accuracy: 0.9879 - Precision: 0.9660 - Recall: 0.9620 - TP: 3244.0100 - TN: 5559.7002 - FP: 87.3000 - FN: 127.9900 - val_loss: 0.0937 - val_Accuracy: 0.9759 - val_Precision: 0.9585 - val_Recall: 0.9497 - val_TP: 763.5200 - val_TN: 1079.4600 - val_FP: 26.5400 - val_FN: 40.4800\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0405 - Accuracy: 0.9869 - Precision: 0.9650 - Recall: 0.9608 - TP: 3239.6799 - TN: 5555.7500 - FP: 91.2500 - FN: 132.3200 - val_loss: 0.0894 - val_Accuracy: 0.9759 - val_Precision: 0.9598 - val_Recall: 0.9495 - val_TP: 763.3900 - val_TN: 1080.6801 - val_FP: 25.3200 - val_FN: 40.6100\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0377 - Accuracy: 0.9874 - Precision: 0.9648 - Recall: 0.9605 - TP: 3238.6899 - TN: 5554.5200 - FP: 92.4800 - FN: 133.3100 - val_loss: 0.0948 - val_Accuracy: 0.9749 - val_Precision: 0.9546 - val_Recall: 0.9494 - val_TP: 763.2900 - val_TN: 1075.6801 - val_FP: 30.3200 - val_FN: 40.7100\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0378 - Accuracy: 0.9876 - Precision: 0.9646 - Recall: 0.9614 - TP: 3241.9299 - TN: 5554.0801 - FP: 92.9200 - FN: 130.0700 - val_loss: 0.0873 - val_Accuracy: 0.9770 - val_Precision: 0.9643 - val_Recall: 0.9480 - val_TP: 762.1800 - val_TN: 1084.6400 - val_FP: 21.3600 - val_FN: 41.8200\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0380 - Accuracy: 0.9872 - Precision: 0.9648 - Recall: 0.9607 - TP: 3239.5200 - TN: 5554.8301 - FP: 92.1700 - FN: 132.4800 - val_loss: 0.0878 - val_Accuracy: 0.9770 - val_Precision: 0.9634 - val_Recall: 0.9484 - val_TP: 762.4800 - val_TN: 1083.7900 - val_FP: 22.2100 - val_FN: 41.5200\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0368 - Accuracy: 0.9881 - Precision: 0.9659 - Recall: 0.9615 - TP: 3242.2800 - TN: 5558.9102 - FP: 88.0900 - FN: 129.7200 - val_loss: 0.0880 - val_Accuracy: 0.9770 - val_Precision: 0.9637 - val_Recall: 0.9482 - val_TP: 762.3400 - val_TN: 1084.1100 - val_FP: 21.8900 - val_FN: 41.6600\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0377 - Accuracy: 0.9871 - Precision: 0.9650 - Recall: 0.9611 - TP: 3240.7900 - TN: 5555.3799 - FP: 91.6200 - FN: 131.2100 - val_loss: 0.0868 - val_Accuracy: 0.9775 - val_Precision: 0.9641 - val_Recall: 0.9488 - val_TP: 762.8700 - val_TN: 1084.4000 - val_FP: 21.6000 - val_FN: 41.1300\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0404 - Accuracy: 0.9871 - Precision: 0.9656 - Recall: 0.9604 - TP: 3238.5100 - TN: 5557.8398 - FP: 89.1600 - FN: 133.4900 - val_loss: 0.0974 - val_Accuracy: 0.9738 - val_Precision: 0.9491 - val_Recall: 0.9516 - val_TP: 765.0700 - val_TN: 1070.4700 - val_FP: 35.5300 - val_FN: 38.9300\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0536 - Accuracy: 0.9855 - Precision: 0.9617 - Recall: 0.9600 - TP: 3237.1899 - TN: 5544.2002 - FP: 102.8000 - FN: 134.8100 - val_loss: 0.0885 - val_Accuracy: 0.9764 - val_Precision: 0.9654 - val_Recall: 0.9470 - val_TP: 761.3800 - val_TN: 1085.5699 - val_FP: 20.4300 - val_FN: 42.6200\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0377 - Accuracy: 0.9877 - Precision: 0.9658 - Recall: 0.9607 - TP: 3239.5200 - TN: 5558.1299 - FP: 88.8700 - FN: 132.4800 - val_loss: 0.0883 - val_Accuracy: 0.9770 - val_Precision: 0.9644 - val_Recall: 0.9477 - val_TP: 761.9900 - val_TN: 1084.6600 - val_FP: 21.3400 - val_FN: 42.0100\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0373 - Accuracy: 0.9878 - Precision: 0.9656 - Recall: 0.9616 - TP: 3242.4199 - TN: 5557.8999 - FP: 89.1000 - FN: 129.5800 - val_loss: 0.0891 - val_Accuracy: 0.9770 - val_Precision: 0.9619 - val_Recall: 0.9491 - val_TP: 763.0400 - val_TN: 1082.5900 - val_FP: 23.4100 - val_FN: 40.9600\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0397 - Accuracy: 0.9867 - Precision: 0.9653 - Recall: 0.9596 - TP: 3235.6299 - TN: 5557.0898 - FP: 89.9100 - FN: 136.3700 - val_loss: 0.0886 - val_Accuracy: 0.9764 - val_Precision: 0.9587 - val_Recall: 0.9511 - val_TP: 764.7200 - val_TN: 1079.6700 - val_FP: 26.3300 - val_FN: 39.2800\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0372 - Accuracy: 0.9870 - Precision: 0.9643 - Recall: 0.9618 - TP: 3243.3101 - TN: 5552.7900 - FP: 94.2100 - FN: 128.6900 - val_loss: 0.0918 - val_Accuracy: 0.9759 - val_Precision: 0.9597 - val_Recall: 0.9492 - val_TP: 763.1300 - val_TN: 1080.6400 - val_FP: 25.3600 - val_FN: 40.8700\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0356 - Accuracy: 0.9876 - Precision: 0.9653 - Recall: 0.9615 - TP: 3242.1101 - TN: 5556.5898 - FP: 90.4100 - FN: 129.8900 - val_loss: 0.0888 - val_Accuracy: 0.9770 - val_Precision: 0.9634 - val_Recall: 0.9483 - val_TP: 762.4400 - val_TN: 1083.8400 - val_FP: 22.1600 - val_FN: 41.5600\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0369 - Accuracy: 0.9877 - Precision: 0.9654 - Recall: 0.9615 - TP: 3242.0400 - TN: 5556.9399 - FP: 90.0600 - FN: 129.9600 - val_loss: 0.0888 - val_Accuracy: 0.9770 - val_Precision: 0.9635 - val_Recall: 0.9485 - val_TP: 762.5700 - val_TN: 1083.9500 - val_FP: 22.0500 - val_FN: 41.4300\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0367 - Accuracy: 0.9877 - Precision: 0.9653 - Recall: 0.9612 - TP: 3241.3101 - TN: 5556.8398 - FP: 90.1600 - FN: 130.6900 - val_loss: 0.0896 - val_Accuracy: 0.9764 - val_Precision: 0.9608 - val_Recall: 0.9499 - val_TP: 763.6800 - val_TN: 1081.6100 - val_FP: 24.3900 - val_FN: 40.3200\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0359 - Accuracy: 0.9884 - Precision: 0.9665 - Recall: 0.9616 - TP: 3242.4099 - TN: 5561.2100 - FP: 85.7900 - FN: 129.5900 - val_loss: 0.0901 - val_Accuracy: 0.9754 - val_Precision: 0.9568 - val_Recall: 0.9523 - val_TP: 765.6100 - val_TN: 1077.9500 - val_FP: 28.0500 - val_FN: 38.3900\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0363 - Accuracy: 0.9874 - Precision: 0.9654 - Recall: 0.9618 - TP: 3243.2800 - TN: 5557.2700 - FP: 89.7300 - FN: 128.7200 - val_loss: 0.1056 - val_Accuracy: 0.9743 - val_Precision: 0.9441 - val_Recall: 0.9500 - val_TP: 763.8100 - val_TN: 1065.9900 - val_FP: 40.0100 - val_FN: 40.1900\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0380 - Accuracy: 0.9875 - Precision: 0.9656 - Recall: 0.9616 - TP: 3242.3601 - TN: 5557.9902 - FP: 89.0100 - FN: 129.6400 - val_loss: 0.0895 - val_Accuracy: 0.9764 - val_Precision: 0.9600 - val_Recall: 0.9507 - val_TP: 764.4000 - val_TN: 1080.9000 - val_FP: 25.1000 - val_FN: 39.6000\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0376 - Accuracy: 0.9876 - Precision: 0.9647 - Recall: 0.9618 - TP: 3243.2500 - TN: 5554.2900 - FP: 92.7100 - FN: 128.7500 - val_loss: 0.0899 - val_Accuracy: 0.9764 - val_Precision: 0.9647 - val_Recall: 0.9475 - val_TP: 761.8300 - val_TN: 1085.0300 - val_FP: 20.9700 - val_FN: 42.1700\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0352 - Accuracy: 0.9878 - Precision: 0.9659 - Recall: 0.9611 - TP: 3240.9600 - TN: 5558.9702 - FP: 88.0300 - FN: 131.0400 - val_loss: 0.0944 - val_Accuracy: 0.9759 - val_Precision: 0.9580 - val_Recall: 0.9498 - val_TP: 763.6100 - val_TN: 1079.0400 - val_FP: 26.9600 - val_FN: 40.3900\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0383 - Accuracy: 0.9871 - Precision: 0.9647 - Recall: 0.9617 - TP: 3242.9199 - TN: 5554.8599 - FP: 92.1400 - FN: 129.0800 - val_loss: 0.0913 - val_Accuracy: 0.9754 - val_Precision: 0.9626 - val_Recall: 0.9481 - val_TP: 762.2500 - val_TN: 1083.2200 - val_FP: 22.7800 - val_FN: 41.7500\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0357 - Accuracy: 0.9881 - Precision: 0.9660 - Recall: 0.9618 - TP: 3243.1799 - TN: 5559.4199 - FP: 87.5800 - FN: 128.8200 - val_loss: 0.0900 - val_Accuracy: 0.9770 - val_Precision: 0.9612 - val_Recall: 0.9496 - val_TP: 763.5000 - val_TN: 1082.0000 - val_FP: 24.0000 - val_FN: 40.5000\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0361 - Accuracy: 0.9880 - Precision: 0.9661 - Recall: 0.9616 - TP: 3242.5400 - TN: 5559.7100 - FP: 87.2900 - FN: 129.4600 - val_loss: 0.0892 - val_Accuracy: 0.9770 - val_Precision: 0.9607 - val_Recall: 0.9506 - val_TP: 764.2600 - val_TN: 1081.4500 - val_FP: 24.5500 - val_FN: 39.7400\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0459 - Accuracy: 0.9868 - Precision: 0.9642 - Recall: 0.9609 - TP: 3240.3000 - TN: 5553.3799 - FP: 93.6200 - FN: 131.7000 - val_loss: 0.0918 - val_Accuracy: 0.9759 - val_Precision: 0.9592 - val_Recall: 0.9500 - val_TP: 763.8000 - val_TN: 1080.1400 - val_FP: 25.8600 - val_FN: 40.2000\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0515 - Accuracy: 0.9867 - Precision: 0.9643 - Recall: 0.9608 - TP: 3239.8601 - TN: 5553.3398 - FP: 93.6600 - FN: 132.1400 - val_loss: 0.0922 - val_Accuracy: 0.9754 - val_Precision: 0.9619 - val_Recall: 0.9482 - val_TP: 762.3800 - val_TN: 1082.6600 - val_FP: 23.3400 - val_FN: 41.6200\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0378 - Accuracy: 0.9878 - Precision: 0.9661 - Recall: 0.9621 - TP: 3244.2500 - TN: 5559.6099 - FP: 87.3900 - FN: 127.7500 - val_loss: 0.0954 - val_Accuracy: 0.9754 - val_Precision: 0.9593 - val_Recall: 0.9488 - val_TP: 762.8600 - val_TN: 1080.3900 - val_FP: 25.6100 - val_FN: 41.1400\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 4ms/step - loss: 0.0383 - Accuracy: 0.9874 - Precision: 0.9652 - Recall: 0.9608 - TP: 3239.8899 - TN: 5556.4502 - FP: 90.5500 - FN: 132.1100 - val_loss: 0.0876 - val_Accuracy: 0.9754 - val_Precision: 0.9597 - val_Recall: 0.9509 - val_TP: 764.5400 - val_TN: 1080.5800 - val_FP: 25.4200 - val_FN: 39.4600\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0358 - Accuracy: 0.9877 - Precision: 0.9655 - Recall: 0.9620 - TP: 3244.0300 - TN: 5557.1001 - FP: 89.9000 - FN: 127.9700 - val_loss: 0.0906 - val_Accuracy: 0.9749 - val_Precision: 0.9584 - val_Recall: 0.9503 - val_TP: 764.0200 - val_TN: 1079.3199 - val_FP: 26.6800 - val_FN: 39.9800\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0448 - Accuracy: 0.9865 - Precision: 0.9643 - Recall: 0.9602 - TP: 3237.8999 - TN: 5553.5801 - FP: 93.4200 - FN: 134.1000 - val_loss: 0.1029 - val_Accuracy: 0.9728 - val_Precision: 0.9479 - val_Recall: 0.9496 - val_TP: 763.4900 - val_TN: 1069.2200 - val_FP: 36.7800 - val_FN: 40.5100\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0399 - Accuracy: 0.9876 - Precision: 0.9645 - Recall: 0.9613 - TP: 3241.5400 - TN: 5553.3701 - FP: 93.6300 - FN: 130.4600 - val_loss: 0.0909 - val_Accuracy: 0.9749 - val_Precision: 0.9654 - val_Recall: 0.9460 - val_TP: 760.5800 - val_TN: 1085.6300 - val_FP: 20.3700 - val_FN: 43.4200\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0386 - Accuracy: 0.9876 - Precision: 0.9653 - Recall: 0.9606 - TP: 3239.2000 - TN: 5557.0298 - FP: 89.9700 - FN: 132.8000 - val_loss: 0.0885 - val_Accuracy: 0.9770 - val_Precision: 0.9636 - val_Recall: 0.9487 - val_TP: 762.7400 - val_TN: 1084.0100 - val_FP: 21.9900 - val_FN: 41.2600\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0382 - Accuracy: 0.9872 - Precision: 0.9656 - Recall: 0.9613 - TP: 3241.5601 - TN: 5557.7100 - FP: 89.2900 - FN: 130.4400 - val_loss: 0.0890 - val_Accuracy: 0.9759 - val_Precision: 0.9617 - val_Recall: 0.9494 - val_TP: 763.3000 - val_TN: 1082.3500 - val_FP: 23.6500 - val_FN: 40.7000\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0366 - Accuracy: 0.9876 - Precision: 0.9649 - Recall: 0.9619 - TP: 3243.6101 - TN: 5555.1499 - FP: 91.8500 - FN: 128.3900 - val_loss: 0.0891 - val_Accuracy: 0.9764 - val_Precision: 0.9667 - val_Recall: 0.9466 - val_TP: 761.0300 - val_TN: 1086.7900 - val_FP: 19.2100 - val_FN: 42.9700\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0389 - Accuracy: 0.9865 - Precision: 0.9651 - Recall: 0.9610 - TP: 3240.3799 - TN: 5556.2998 - FP: 90.7000 - FN: 131.6200 - val_loss: 0.0902 - val_Accuracy: 0.9764 - val_Precision: 0.9621 - val_Recall: 0.9485 - val_TP: 762.5600 - val_TN: 1082.7300 - val_FP: 23.2700 - val_FN: 41.4400\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0371 - Accuracy: 0.9877 - Precision: 0.9660 - Recall: 0.9607 - TP: 3239.4800 - TN: 5559.6201 - FP: 87.3800 - FN: 132.5200 - val_loss: 0.1002 - val_Accuracy: 0.9733 - val_Precision: 0.9501 - val_Recall: 0.9501 - val_TP: 763.8500 - val_TN: 1071.4000 - val_FP: 34.6000 - val_FN: 40.1500\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0372 - Accuracy: 0.9874 - Precision: 0.9646 - Recall: 0.9617 - TP: 3242.9800 - TN: 5553.9902 - FP: 93.0100 - FN: 129.0200 - val_loss: 0.0894 - val_Accuracy: 0.9759 - val_Precision: 0.9607 - val_Recall: 0.9503 - val_TP: 764.0400 - val_TN: 1081.5400 - val_FP: 24.4600 - val_FN: 39.9600\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0366 - Accuracy: 0.9872 - Precision: 0.9657 - Recall: 0.9617 - TP: 3243.0100 - TN: 5558.4302 - FP: 88.5700 - FN: 128.9900 - val_loss: 0.0909 - val_Accuracy: 0.9759 - val_Precision: 0.9604 - val_Recall: 0.9498 - val_TP: 763.6500 - val_TN: 1081.2300 - val_FP: 24.7700 - val_FN: 40.3500\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0383 - Accuracy: 0.9874 - Precision: 0.9646 - Recall: 0.9610 - TP: 3240.5000 - TN: 5554.1699 - FP: 92.8300 - FN: 131.5000 - val_loss: 0.0906 - val_Accuracy: 0.9764 - val_Precision: 0.9621 - val_Recall: 0.9485 - val_TP: 762.6300 - val_TN: 1082.7300 - val_FP: 23.2700 - val_FN: 41.3700\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0361 - Accuracy: 0.9878 - Precision: 0.9659 - Recall: 0.9612 - TP: 3241.0701 - TN: 5559.1001 - FP: 87.9000 - FN: 130.9300 - val_loss: 0.0894 - val_Accuracy: 0.9759 - val_Precision: 0.9598 - val_Recall: 0.9509 - val_TP: 764.5400 - val_TN: 1080.6801 - val_FP: 25.3200 - val_FN: 39.4600\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0343 - Accuracy: 0.9876 - Precision: 0.9658 - Recall: 0.9623 - TP: 3244.8101 - TN: 5558.7100 - FP: 88.2900 - FN: 127.1900 - val_loss: 0.0897 - val_Accuracy: 0.9775 - val_Precision: 0.9634 - val_Recall: 0.9484 - val_TP: 762.5500 - val_TN: 1083.8500 - val_FP: 22.1500 - val_FN: 41.4500\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0349 - Accuracy: 0.9877 - Precision: 0.9659 - Recall: 0.9621 - TP: 3244.1201 - TN: 5558.8799 - FP: 88.1200 - FN: 127.8800 - val_loss: 0.0892 - val_Accuracy: 0.9770 - val_Precision: 0.9650 - val_Recall: 0.9481 - val_TP: 762.2500 - val_TN: 1085.2500 - val_FP: 20.7500 - val_FN: 41.7500\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0377 - Accuracy: 0.9870 - Precision: 0.9653 - Recall: 0.9615 - TP: 3242.2600 - TN: 5556.9302 - FP: 90.0700 - FN: 129.7400 - val_loss: 0.1151 - val_Accuracy: 0.9723 - val_Precision: 0.9345 - val_Recall: 0.9495 - val_TP: 763.4000 - val_TN: 1057.2900 - val_FP: 48.7100 - val_FN: 40.6000\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0373 - Accuracy: 0.9881 - Precision: 0.9658 - Recall: 0.9618 - TP: 3243.0300 - TN: 5558.4399 - FP: 88.5600 - FN: 128.9700 - val_loss: 0.0956 - val_Accuracy: 0.9749 - val_Precision: 0.9581 - val_Recall: 0.9487 - val_TP: 762.7500 - val_TN: 1079.0900 - val_FP: 26.9100 - val_FN: 41.2500\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0366 - Accuracy: 0.9881 - Precision: 0.9666 - Recall: 0.9614 - TP: 3241.9299 - TN: 5561.6001 - FP: 85.4000 - FN: 130.0700 - val_loss: 0.0899 - val_Accuracy: 0.9749 - val_Precision: 0.9604 - val_Recall: 0.9504 - val_TP: 764.1600 - val_TN: 1081.2100 - val_FP: 24.7900 - val_FN: 39.8400\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0365 - Accuracy: 0.9871 - Precision: 0.9648 - Recall: 0.9619 - TP: 3243.5000 - TN: 5554.7300 - FP: 92.2700 - FN: 128.5000 - val_loss: 0.0893 - val_Accuracy: 0.9770 - val_Precision: 0.9623 - val_Recall: 0.9501 - val_TP: 763.9100 - val_TN: 1082.9000 - val_FP: 23.1000 - val_FN: 40.0900\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0382 - Accuracy: 0.9871 - Precision: 0.9654 - Recall: 0.9609 - TP: 3240.0601 - TN: 5557.0698 - FP: 89.9300 - FN: 131.9400 - val_loss: 0.0953 - val_Accuracy: 0.9759 - val_Precision: 0.9588 - val_Recall: 0.9495 - val_TP: 763.4100 - val_TN: 1079.9200 - val_FP: 26.0800 - val_FN: 40.5900\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0362 - Accuracy: 0.9880 - Precision: 0.9656 - Recall: 0.9624 - TP: 3245.1799 - TN: 5558.2100 - FP: 88.7900 - FN: 126.8200 - val_loss: 0.0924 - val_Accuracy: 0.9754 - val_Precision: 0.9637 - val_Recall: 0.9473 - val_TP: 761.6200 - val_TN: 1084.2900 - val_FP: 21.7100 - val_FN: 42.3800\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0382 - Accuracy: 0.9866 - Precision: 0.9643 - Recall: 0.9606 - TP: 3239.0500 - TN: 5553.3701 - FP: 93.6300 - FN: 132.9500 - val_loss: 0.0878 - val_Accuracy: 0.9775 - val_Precision: 0.9636 - val_Recall: 0.9488 - val_TP: 762.8600 - val_TN: 1084.0100 - val_FP: 21.9900 - val_FN: 41.1400\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0368 - Accuracy: 0.9871 - Precision: 0.9657 - Recall: 0.9607 - TP: 3239.5801 - TN: 5558.3799 - FP: 88.6200 - FN: 132.4200 - val_loss: 0.0869 - val_Accuracy: 0.9764 - val_Precision: 0.9593 - val_Recall: 0.9520 - val_TP: 765.4200 - val_TN: 1080.1500 - val_FP: 25.8500 - val_FN: 38.5800\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0377 - Accuracy: 0.9871 - Precision: 0.9651 - Recall: 0.9618 - TP: 3243.0500 - TN: 5556.1001 - FP: 90.9000 - FN: 128.9500 - val_loss: 0.0880 - val_Accuracy: 0.9770 - val_Precision: 0.9641 - val_Recall: 0.9484 - val_TP: 762.5500 - val_TN: 1084.4100 - val_FP: 21.5900 - val_FN: 41.4500\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0366 - Accuracy: 0.9880 - Precision: 0.9659 - Recall: 0.9614 - TP: 3241.7600 - TN: 5559.2998 - FP: 87.7000 - FN: 130.2400 - val_loss: 0.1205 - val_Accuracy: 0.9717 - val_Precision: 0.9258 - val_Recall: 0.9499 - val_TP: 763.7500 - val_TN: 1049.4301 - val_FP: 56.5700 - val_FN: 40.2500\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0388 - Accuracy: 0.9878 - Precision: 0.9646 - Recall: 0.9619 - TP: 3243.6899 - TN: 5554.2402 - FP: 92.7600 - FN: 128.3100 - val_loss: 0.0899 - val_Accuracy: 0.9759 - val_Precision: 0.9651 - val_Recall: 0.9466 - val_TP: 761.0700 - val_TN: 1085.3400 - val_FP: 20.6600 - val_FN: 42.9300\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0392 - Accuracy: 0.9876 - Precision: 0.9658 - Recall: 0.9612 - TP: 3241.0000 - TN: 5558.6299 - FP: 88.3700 - FN: 131.0000 - val_loss: 0.0888 - val_Accuracy: 0.9770 - val_Precision: 0.9626 - val_Recall: 0.9489 - val_TP: 762.9200 - val_TN: 1083.2300 - val_FP: 22.7700 - val_FN: 41.0800\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0422 - Accuracy: 0.9876 - Precision: 0.9654 - Recall: 0.9610 - TP: 3240.4099 - TN: 5557.2402 - FP: 89.7600 - FN: 131.5900 - val_loss: 0.0880 - val_Accuracy: 0.9759 - val_Precision: 0.9587 - val_Recall: 0.9519 - val_TP: 765.3600 - val_TN: 1079.6600 - val_FP: 26.3400 - val_FN: 38.6400\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0378 - Accuracy: 0.9881 - Precision: 0.9649 - Recall: 0.9621 - TP: 3244.1499 - TN: 5555.3101 - FP: 91.6900 - FN: 127.8500 - val_loss: 0.1024 - val_Accuracy: 0.9738 - val_Precision: 0.9511 - val_Recall: 0.9477 - val_TP: 761.9400 - val_TN: 1072.4200 - val_FP: 33.5800 - val_FN: 42.0600\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0370 - Accuracy: 0.9877 - Precision: 0.9657 - Recall: 0.9617 - TP: 3242.8301 - TN: 5558.2598 - FP: 88.7400 - FN: 129.1700 - val_loss: 0.0904 - val_Accuracy: 0.9754 - val_Precision: 0.9620 - val_Recall: 0.9486 - val_TP: 762.6500 - val_TN: 1082.6500 - val_FP: 23.3500 - val_FN: 41.3500\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0378 - Accuracy: 0.9874 - Precision: 0.9653 - Recall: 0.9615 - TP: 3242.0500 - TN: 5556.6899 - FP: 90.3100 - FN: 129.9500 - val_loss: 0.0891 - val_Accuracy: 0.9775 - val_Precision: 0.9626 - val_Recall: 0.9492 - val_TP: 763.1200 - val_TN: 1083.1200 - val_FP: 22.8800 - val_FN: 40.8800\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0387 - Accuracy: 0.9875 - Precision: 0.9652 - Recall: 0.9613 - TP: 3241.6201 - TN: 5556.5098 - FP: 90.4900 - FN: 130.3800 - val_loss: 0.0927 - val_Accuracy: 0.9759 - val_Precision: 0.9602 - val_Recall: 0.9492 - val_TP: 763.1600 - val_TN: 1081.1400 - val_FP: 24.8600 - val_FN: 40.8400\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0360 - Accuracy: 0.9877 - Precision: 0.9657 - Recall: 0.9613 - TP: 3241.6201 - TN: 5558.2798 - FP: 88.7200 - FN: 130.3800 - val_loss: 0.0893 - val_Accuracy: 0.9764 - val_Precision: 0.9615 - val_Recall: 0.9500 - val_TP: 763.8100 - val_TN: 1082.2300 - val_FP: 23.7700 - val_FN: 40.1900\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0368 - Accuracy: 0.9871 - Precision: 0.9648 - Recall: 0.9612 - TP: 3241.0801 - TN: 5554.5000 - FP: 92.5000 - FN: 130.9200 - val_loss: 0.0887 - val_Accuracy: 0.9770 - val_Precision: 0.9628 - val_Recall: 0.9497 - val_TP: 763.5700 - val_TN: 1083.3000 - val_FP: 22.7000 - val_FN: 40.4300\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0369 - Accuracy: 0.9875 - Precision: 0.9663 - Recall: 0.9617 - TP: 3242.7800 - TN: 5560.7002 - FP: 86.3000 - FN: 129.2200 - val_loss: 0.0902 - val_Accuracy: 0.9754 - val_Precision: 0.9599 - val_Recall: 0.9506 - val_TP: 764.2500 - val_TN: 1080.7600 - val_FP: 25.2400 - val_FN: 39.7500\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0381 - Accuracy: 0.9868 - Precision: 0.9647 - Recall: 0.9613 - TP: 3241.3999 - TN: 5554.4502 - FP: 92.5500 - FN: 130.6000 - val_loss: 0.0901 - val_Accuracy: 0.9764 - val_Precision: 0.9632 - val_Recall: 0.9486 - val_TP: 762.6700 - val_TN: 1083.7000 - val_FP: 22.3000 - val_FN: 41.3300\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0365 - Accuracy: 0.9879 - Precision: 0.9656 - Recall: 0.9616 - TP: 3242.4600 - TN: 5557.8398 - FP: 89.1600 - FN: 129.5400 - val_loss: 0.0908 - val_Accuracy: 0.9754 - val_Precision: 0.9602 - val_Recall: 0.9503 - val_TP: 764.0200 - val_TN: 1081.0699 - val_FP: 24.9300 - val_FN: 39.9800\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0365 - Accuracy: 0.9879 - Precision: 0.9657 - Recall: 0.9619 - TP: 3243.6001 - TN: 5558.1699 - FP: 88.8300 - FN: 128.4000 - val_loss: 0.0906 - val_Accuracy: 0.9759 - val_Precision: 0.9609 - val_Recall: 0.9499 - val_TP: 763.6800 - val_TN: 1081.7000 - val_FP: 24.3000 - val_FN: 40.3200\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0412 - Accuracy: 0.9870 - Precision: 0.9648 - Recall: 0.9616 - TP: 3242.6699 - TN: 5555.3701 - FP: 91.6300 - FN: 129.3300 - val_loss: 0.0931 - val_Accuracy: 0.9754 - val_Precision: 0.9608 - val_Recall: 0.9489 - val_TP: 762.9300 - val_TN: 1081.6899 - val_FP: 24.3100 - val_FN: 41.0700\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0352 - Accuracy: 0.9880 - Precision: 0.9661 - Recall: 0.9618 - TP: 3243.2000 - TN: 5559.4902 - FP: 87.5100 - FN: 128.8000 - val_loss: 0.0958 - val_Accuracy: 0.9754 - val_Precision: 0.9591 - val_Recall: 0.9491 - val_TP: 763.0600 - val_TN: 1080.0601 - val_FP: 25.9400 - val_FN: 40.9400\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0384 - Accuracy: 0.9868 - Precision: 0.9654 - Recall: 0.9610 - TP: 3240.4600 - TN: 5557.4702 - FP: 89.5300 - FN: 131.5400 - val_loss: 0.0906 - val_Accuracy: 0.9759 - val_Precision: 0.9612 - val_Recall: 0.9499 - val_TP: 763.7000 - val_TN: 1081.9500 - val_FP: 24.0500 - val_FN: 40.3000\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0410 - Accuracy: 0.9877 - Precision: 0.9650 - Recall: 0.9620 - TP: 3243.7200 - TN: 5556.0498 - FP: 90.9500 - FN: 128.2800 - val_loss: 0.0926 - val_Accuracy: 0.9754 - val_Precision: 0.9633 - val_Recall: 0.9475 - val_TP: 761.8200 - val_TN: 1083.8700 - val_FP: 22.1300 - val_FN: 42.1800\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0359 - Accuracy: 0.9879 - Precision: 0.9665 - Recall: 0.9622 - TP: 3244.7000 - TN: 5561.3901 - FP: 85.6100 - FN: 127.3000 - val_loss: 0.0907 - val_Accuracy: 0.9770 - val_Precision: 0.9619 - val_Recall: 0.9496 - val_TP: 763.4800 - val_TN: 1082.5500 - val_FP: 23.4500 - val_FN: 40.5200\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0392 - Accuracy: 0.9869 - Precision: 0.9650 - Recall: 0.9606 - TP: 3239.1699 - TN: 5556.0298 - FP: 90.9700 - FN: 132.8300 - val_loss: 0.0901 - val_Accuracy: 0.9754 - val_Precision: 0.9579 - val_Recall: 0.9513 - val_TP: 764.8800 - val_TN: 1079.0500 - val_FP: 26.9500 - val_FN: 39.1200\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0374 - Accuracy: 0.9871 - Precision: 0.9652 - Recall: 0.9615 - TP: 3242.1599 - TN: 5556.3799 - FP: 90.6200 - FN: 129.8400 - val_loss: 0.0890 - val_Accuracy: 0.9754 - val_Precision: 0.9588 - val_Recall: 0.9513 - val_TP: 764.8500 - val_TN: 1079.7900 - val_FP: 26.2100 - val_FN: 39.1500\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0378 - Accuracy: 0.9868 - Precision: 0.9648 - Recall: 0.9612 - TP: 3241.2800 - TN: 5554.6899 - FP: 92.3100 - FN: 130.7200 - val_loss: 0.0879 - val_Accuracy: 0.9775 - val_Precision: 0.9634 - val_Recall: 0.9492 - val_TP: 763.1800 - val_TN: 1083.8700 - val_FP: 22.1300 - val_FN: 40.8200\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0365 - Accuracy: 0.9887 - Precision: 0.9661 - Recall: 0.9612 - TP: 3241.2100 - TN: 5560.0601 - FP: 86.9400 - FN: 130.7900 - val_loss: 0.1023 - val_Accuracy: 0.9743 - val_Precision: 0.9448 - val_Recall: 0.9513 - val_TP: 764.8300 - val_TN: 1066.5000 - val_FP: 39.5000 - val_FN: 39.1700\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0389 - Accuracy: 0.9867 - Precision: 0.9642 - Recall: 0.9620 - TP: 3243.7100 - TN: 5552.6401 - FP: 94.3600 - FN: 128.2900 - val_loss: 0.0894 - val_Accuracy: 0.9770 - val_Precision: 0.9662 - val_Recall: 0.9467 - val_TP: 761.1800 - val_TN: 1086.3199 - val_FP: 19.6800 - val_FN: 42.8200\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0375 - Accuracy: 0.9879 - Precision: 0.9659 - Recall: 0.9617 - TP: 3242.9099 - TN: 5558.9102 - FP: 88.0900 - FN: 129.0900 - val_loss: 0.0900 - val_Accuracy: 0.9754 - val_Precision: 0.9635 - val_Recall: 0.9483 - val_TP: 762.4200 - val_TN: 1083.9600 - val_FP: 22.0400 - val_FN: 41.5800\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0369 - Accuracy: 0.9880 - Precision: 0.9656 - Recall: 0.9614 - TP: 3241.9600 - TN: 5557.7700 - FP: 89.2300 - FN: 130.0400 - val_loss: 0.0909 - val_Accuracy: 0.9759 - val_Precision: 0.9599 - val_Recall: 0.9501 - val_TP: 763.9100 - val_TN: 1080.8300 - val_FP: 25.1700 - val_FN: 40.0900\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0394 - Accuracy: 0.9871 - Precision: 0.9649 - Recall: 0.9612 - TP: 3241.1699 - TN: 5555.2598 - FP: 91.7400 - FN: 130.8300 - val_loss: 0.0901 - val_Accuracy: 0.9764 - val_Precision: 0.9660 - val_Recall: 0.9469 - val_TP: 761.3100 - val_TN: 1086.1801 - val_FP: 19.8200 - val_FN: 42.6900\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0401 - Accuracy: 0.9876 - Precision: 0.9652 - Recall: 0.9608 - TP: 3239.6599 - TN: 5556.7998 - FP: 90.2000 - FN: 132.3400 - val_loss: 0.0909 - val_Accuracy: 0.9764 - val_Precision: 0.9589 - val_Recall: 0.9507 - val_TP: 764.3600 - val_TN: 1079.9800 - val_FP: 26.0200 - val_FN: 39.6400\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0371 - Accuracy: 0.9875 - Precision: 0.9651 - Recall: 0.9617 - TP: 3242.7400 - TN: 5556.1299 - FP: 90.8700 - FN: 129.2600 - val_loss: 0.0893 - val_Accuracy: 0.9770 - val_Precision: 0.9648 - val_Recall: 0.9483 - val_TP: 762.4600 - val_TN: 1085.1100 - val_FP: 20.8900 - val_FN: 41.5400\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0369 - Accuracy: 0.9878 - Precision: 0.9655 - Recall: 0.9618 - TP: 3243.0901 - TN: 5557.5400 - FP: 89.4600 - FN: 128.9100 - val_loss: 0.0916 - val_Accuracy: 0.9770 - val_Precision: 0.9619 - val_Recall: 0.9490 - val_TP: 762.9800 - val_TN: 1082.6100 - val_FP: 23.3900 - val_FN: 41.0200\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0362 - Accuracy: 0.9875 - Precision: 0.9657 - Recall: 0.9617 - TP: 3242.9199 - TN: 5558.4702 - FP: 88.5300 - FN: 129.0800 - val_loss: 0.0901 - val_Accuracy: 0.9775 - val_Precision: 0.9641 - val_Recall: 0.9484 - val_TP: 762.5000 - val_TN: 1084.5100 - val_FP: 21.4900 - val_FN: 41.5000\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0417 - Accuracy: 0.9868 - Precision: 0.9647 - Recall: 0.9604 - TP: 3238.5701 - TN: 5555.2598 - FP: 91.7400 - FN: 133.4300 - val_loss: 0.0956 - val_Accuracy: 0.9749 - val_Precision: 0.9559 - val_Recall: 0.9511 - val_TP: 764.6700 - val_TN: 1077.1899 - val_FP: 28.8100 - val_FN: 39.3300\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0396 - Accuracy: 0.9863 - Precision: 0.9643 - Recall: 0.9600 - TP: 3237.2700 - TN: 5553.6099 - FP: 93.3900 - FN: 134.7300 - val_loss: 0.0900 - val_Accuracy: 0.9775 - val_Precision: 0.9631 - val_Recall: 0.9490 - val_TP: 762.9800 - val_TN: 1083.6200 - val_FP: 22.3800 - val_FN: 41.0200\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0391 - Accuracy: 0.9880 - Precision: 0.9663 - Recall: 0.9619 - TP: 3243.5801 - TN: 5560.5601 - FP: 86.4400 - FN: 128.4200 - val_loss: 0.0902 - val_Accuracy: 0.9764 - val_Precision: 0.9565 - val_Recall: 0.9533 - val_TP: 766.4300 - val_TN: 1077.7800 - val_FP: 28.2200 - val_FN: 37.5700\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0357 - Accuracy: 0.9874 - Precision: 0.9649 - Recall: 0.9629 - TP: 3246.8201 - TN: 5555.3999 - FP: 91.6000 - FN: 125.1800 - val_loss: 0.0908 - val_Accuracy: 0.9764 - val_Precision: 0.9629 - val_Recall: 0.9487 - val_TP: 762.7400 - val_TN: 1083.4700 - val_FP: 22.5300 - val_FN: 41.2600\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0360 - Accuracy: 0.9878 - Precision: 0.9666 - Recall: 0.9619 - TP: 3243.5100 - TN: 5561.9302 - FP: 85.0700 - FN: 128.4900 - val_loss: 0.0914 - val_Accuracy: 0.9759 - val_Precision: 0.9589 - val_Recall: 0.9513 - val_TP: 764.8700 - val_TN: 1079.9301 - val_FP: 26.0700 - val_FN: 39.1300\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0368 - Accuracy: 0.9881 - Precision: 0.9655 - Recall: 0.9622 - TP: 3244.4900 - TN: 5557.5200 - FP: 89.4800 - FN: 127.5100 - val_loss: 0.0917 - val_Accuracy: 0.9759 - val_Precision: 0.9637 - val_Recall: 0.9482 - val_TP: 762.3500 - val_TN: 1084.2300 - val_FP: 21.7700 - val_FN: 41.6500\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0356 - Accuracy: 0.9875 - Precision: 0.9653 - Recall: 0.9619 - TP: 3243.5500 - TN: 5556.8301 - FP: 90.1700 - FN: 128.4500 - val_loss: 0.0920 - val_Accuracy: 0.9764 - val_Precision: 0.9674 - val_Recall: 0.9460 - val_TP: 760.5900 - val_TN: 1087.4100 - val_FP: 18.5900 - val_FN: 43.4100\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0379 - Accuracy: 0.9884 - Precision: 0.9663 - Recall: 0.9620 - TP: 3243.8301 - TN: 5560.6499 - FP: 86.3500 - FN: 128.1700 - val_loss: 0.0910 - val_Accuracy: 0.9764 - val_Precision: 0.9655 - val_Recall: 0.9476 - val_TP: 761.8400 - val_TN: 1085.7100 - val_FP: 20.2900 - val_FN: 42.1600\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0377 - Accuracy: 0.9878 - Precision: 0.9652 - Recall: 0.9619 - TP: 3243.5300 - TN: 5556.5898 - FP: 90.4100 - FN: 128.4700 - val_loss: 0.0940 - val_Accuracy: 0.9759 - val_Precision: 0.9651 - val_Recall: 0.9460 - val_TP: 760.5600 - val_TN: 1085.4600 - val_FP: 20.5400 - val_FN: 43.4400\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0410 - Accuracy: 0.9875 - Precision: 0.9655 - Recall: 0.9617 - TP: 3242.7500 - TN: 5558.0000 - FP: 89.0000 - FN: 129.2500 - val_loss: 0.0985 - val_Accuracy: 0.9754 - val_Precision: 0.9581 - val_Recall: 0.9487 - val_TP: 762.7500 - val_TN: 1079.0800 - val_FP: 26.9200 - val_FN: 41.2500\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0410 - Accuracy: 0.9872 - Precision: 0.9652 - Recall: 0.9610 - TP: 3240.6201 - TN: 5556.8101 - FP: 90.1900 - FN: 131.3800 - val_loss: 0.0967 - val_Accuracy: 0.9759 - val_Precision: 0.9598 - val_Recall: 0.9486 - val_TP: 762.6900 - val_TN: 1080.8700 - val_FP: 25.1300 - val_FN: 41.3100\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0378 - Accuracy: 0.9872 - Precision: 0.9657 - Recall: 0.9613 - TP: 3241.6201 - TN: 5558.6201 - FP: 88.3800 - FN: 130.3800 - val_loss: 0.0897 - val_Accuracy: 0.9764 - val_Precision: 0.9622 - val_Recall: 0.9489 - val_TP: 762.9100 - val_TN: 1082.8300 - val_FP: 23.1700 - val_FN: 41.0900\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0402 - Accuracy: 0.9870 - Precision: 0.9651 - Recall: 0.9603 - TP: 3238.2900 - TN: 5556.0298 - FP: 90.9700 - FN: 133.7100 - val_loss: 0.0877 - val_Accuracy: 0.9770 - val_Precision: 0.9588 - val_Recall: 0.9523 - val_TP: 765.6200 - val_TN: 1079.7000 - val_FP: 26.3000 - val_FN: 38.3800\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0372 - Accuracy: 0.9876 - Precision: 0.9653 - Recall: 0.9620 - TP: 3244.0300 - TN: 5556.3701 - FP: 90.6300 - FN: 127.9700 - val_loss: 0.0890 - val_Accuracy: 0.9780 - val_Precision: 0.9631 - val_Recall: 0.9492 - val_TP: 763.1700 - val_TN: 1083.6300 - val_FP: 22.3700 - val_FN: 40.8300\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0377 - Accuracy: 0.9867 - Precision: 0.9652 - Recall: 0.9612 - TP: 3241.2700 - TN: 5556.5801 - FP: 90.4200 - FN: 130.7300 - val_loss: 0.0903 - val_Accuracy: 0.9770 - val_Precision: 0.9603 - val_Recall: 0.9502 - val_TP: 763.9300 - val_TN: 1081.1700 - val_FP: 24.8300 - val_FN: 40.0700\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0372 - Accuracy: 0.9880 - Precision: 0.9660 - Recall: 0.9617 - TP: 3242.8101 - TN: 5559.2700 - FP: 87.7300 - FN: 129.1900 - val_loss: 0.0895 - val_Accuracy: 0.9775 - val_Precision: 0.9618 - val_Recall: 0.9498 - val_TP: 763.6000 - val_TN: 1082.4399 - val_FP: 23.5600 - val_FN: 40.4000\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0384 - Accuracy: 0.9875 - Precision: 0.9663 - Recall: 0.9614 - TP: 3242.0000 - TN: 5560.4702 - FP: 86.5300 - FN: 130.0000 - val_loss: 0.0898 - val_Accuracy: 0.9759 - val_Precision: 0.9584 - val_Recall: 0.9518 - val_TP: 765.2800 - val_TN: 1079.4000 - val_FP: 26.6000 - val_FN: 38.7200\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0423 - Accuracy: 0.9865 - Precision: 0.9640 - Recall: 0.9604 - TP: 3238.3999 - TN: 5552.1899 - FP: 94.8100 - FN: 133.6000 - val_loss: 0.0887 - val_Accuracy: 0.9770 - val_Precision: 0.9589 - val_Recall: 0.9521 - val_TP: 765.5100 - val_TN: 1079.7500 - val_FP: 26.2500 - val_FN: 38.4900\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0386 - Accuracy: 0.9872 - Precision: 0.9643 - Recall: 0.9618 - TP: 3243.1699 - TN: 5553.1699 - FP: 93.8300 - FN: 128.8300 - val_loss: 0.0952 - val_Accuracy: 0.9749 - val_Precision: 0.9617 - val_Recall: 0.9473 - val_TP: 761.6400 - val_TN: 1082.4900 - val_FP: 23.5100 - val_FN: 42.3600\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0377 - Accuracy: 0.9877 - Precision: 0.9662 - Recall: 0.9617 - TP: 3242.7300 - TN: 5560.4902 - FP: 86.5100 - FN: 129.2700 - val_loss: 0.0916 - val_Accuracy: 0.9759 - val_Precision: 0.9602 - val_Recall: 0.9500 - val_TP: 763.8400 - val_TN: 1081.1100 - val_FP: 24.8900 - val_FN: 40.1600\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0390 - Accuracy: 0.9869 - Precision: 0.9651 - Recall: 0.9611 - TP: 3240.8301 - TN: 5556.3999 - FP: 90.6000 - FN: 131.1700 - val_loss: 0.0922 - val_Accuracy: 0.9754 - val_Precision: 0.9579 - val_Recall: 0.9511 - val_TP: 764.6700 - val_TN: 1079.0601 - val_FP: 26.9400 - val_FN: 39.3300\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0366 - Accuracy: 0.9877 - Precision: 0.9653 - Recall: 0.9621 - TP: 3244.1899 - TN: 5556.6499 - FP: 90.3500 - FN: 127.8100 - val_loss: 0.0907 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9485 - val_TP: 762.6000 - val_TN: 1083.7900 - val_FP: 22.2100 - val_FN: 41.4000\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0375 - Accuracy: 0.9878 - Precision: 0.9659 - Recall: 0.9613 - TP: 3241.6201 - TN: 5559.1299 - FP: 87.8700 - FN: 130.3800 - val_loss: 0.0934 - val_Accuracy: 0.9754 - val_Precision: 0.9570 - val_Recall: 0.9516 - val_TP: 765.0800 - val_TN: 1078.2600 - val_FP: 27.7400 - val_FN: 38.9200\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0361 - Accuracy: 0.9878 - Precision: 0.9656 - Recall: 0.9615 - TP: 3242.1799 - TN: 5557.7700 - FP: 89.2300 - FN: 129.8200 - val_loss: 0.0889 - val_Accuracy: 0.9775 - val_Precision: 0.9614 - val_Recall: 0.9511 - val_TP: 764.7100 - val_TN: 1082.0699 - val_FP: 23.9300 - val_FN: 39.2900\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0360 - Accuracy: 0.9877 - Precision: 0.9650 - Recall: 0.9623 - TP: 3244.7100 - TN: 5555.7402 - FP: 91.2600 - FN: 127.2900 - val_loss: 0.0926 - val_Accuracy: 0.9764 - val_Precision: 0.9613 - val_Recall: 0.9492 - val_TP: 763.1500 - val_TN: 1082.1700 - val_FP: 23.8300 - val_FN: 40.8500\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0399 - Accuracy: 0.9868 - Precision: 0.9652 - Recall: 0.9616 - TP: 3242.5000 - TN: 5556.4502 - FP: 90.5500 - FN: 129.5000 - val_loss: 0.0937 - val_Accuracy: 0.9754 - val_Precision: 0.9640 - val_Recall: 0.9467 - val_TP: 761.1700 - val_TN: 1084.5300 - val_FP: 21.4700 - val_FN: 42.8300\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0418 - Accuracy: 0.9871 - Precision: 0.9656 - Recall: 0.9606 - TP: 3239.3000 - TN: 5557.9800 - FP: 89.0200 - FN: 132.7000 - val_loss: 0.0990 - val_Accuracy: 0.9738 - val_Precision: 0.9548 - val_Recall: 0.9509 - val_TP: 764.5000 - val_TN: 1076.1801 - val_FP: 29.8200 - val_FN: 39.5000\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0369 - Accuracy: 0.9875 - Precision: 0.9656 - Recall: 0.9622 - TP: 3244.6899 - TN: 5557.8799 - FP: 89.1200 - FN: 127.3100 - val_loss: 0.0906 - val_Accuracy: 0.9775 - val_Precision: 0.9648 - val_Recall: 0.9483 - val_TP: 762.4300 - val_TN: 1085.1100 - val_FP: 20.8900 - val_FN: 41.5700\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0351 - Accuracy: 0.9876 - Precision: 0.9663 - Recall: 0.9624 - TP: 3245.2900 - TN: 5560.6201 - FP: 86.3800 - FN: 126.7100 - val_loss: 0.0973 - val_Accuracy: 0.9749 - val_Precision: 0.9577 - val_Recall: 0.9496 - val_TP: 763.4900 - val_TN: 1078.8101 - val_FP: 27.1900 - val_FN: 40.5100\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0360 - Accuracy: 0.9882 - Precision: 0.9659 - Recall: 0.9621 - TP: 3244.1299 - TN: 5559.1401 - FP: 87.8600 - FN: 127.8700 - val_loss: 0.0914 - val_Accuracy: 0.9770 - val_Precision: 0.9627 - val_Recall: 0.9492 - val_TP: 763.1600 - val_TN: 1083.3199 - val_FP: 22.6800 - val_FN: 40.8400\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0381 - Accuracy: 0.9875 - Precision: 0.9648 - Recall: 0.9618 - TP: 3243.2400 - TN: 5555.5098 - FP: 91.4900 - FN: 128.7600 - val_loss: 0.0924 - val_Accuracy: 0.9754 - val_Precision: 0.9636 - val_Recall: 0.9480 - val_TP: 762.1900 - val_TN: 1084.1100 - val_FP: 21.8900 - val_FN: 41.8100\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0354 - Accuracy: 0.9885 - Precision: 0.9666 - Recall: 0.9625 - TP: 3245.4099 - TN: 5561.8901 - FP: 85.1100 - FN: 126.5900 - val_loss: 0.0907 - val_Accuracy: 0.9775 - val_Precision: 0.9644 - val_Recall: 0.9491 - val_TP: 763.0900 - val_TN: 1084.7500 - val_FP: 21.2500 - val_FN: 40.9100\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0385 - Accuracy: 0.9876 - Precision: 0.9664 - Recall: 0.9618 - TP: 3243.2500 - TN: 5561.1499 - FP: 85.8500 - FN: 128.7500 - val_loss: 0.0947 - val_Accuracy: 0.9759 - val_Precision: 0.9563 - val_Recall: 0.9521 - val_TP: 765.5100 - val_TN: 1077.5900 - val_FP: 28.4100 - val_FN: 38.4900\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0382 - Accuracy: 0.9876 - Precision: 0.9648 - Recall: 0.9612 - TP: 3241.2100 - TN: 5554.8999 - FP: 92.1000 - FN: 130.7900 - val_loss: 0.0900 - val_Accuracy: 0.9764 - val_Precision: 0.9626 - val_Recall: 0.9490 - val_TP: 763.0000 - val_TN: 1083.2800 - val_FP: 22.7200 - val_FN: 41.0000\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0381 - Accuracy: 0.9879 - Precision: 0.9653 - Recall: 0.9616 - TP: 3242.5601 - TN: 5557.0400 - FP: 89.9600 - FN: 129.4400 - val_loss: 0.0915 - val_Accuracy: 0.9754 - val_Precision: 0.9614 - val_Recall: 0.9486 - val_TP: 762.7000 - val_TN: 1082.1700 - val_FP: 23.8300 - val_FN: 41.3000\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0395 - Accuracy: 0.9870 - Precision: 0.9640 - Recall: 0.9604 - TP: 3238.5100 - TN: 5552.5000 - FP: 94.5000 - FN: 133.4900 - val_loss: 0.0908 - val_Accuracy: 0.9743 - val_Precision: 0.9592 - val_Recall: 0.9502 - val_TP: 763.9700 - val_TN: 1080.2000 - val_FP: 25.8000 - val_FN: 40.0300\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0396 - Accuracy: 0.9870 - Precision: 0.9651 - Recall: 0.9608 - TP: 3239.9399 - TN: 5556.3101 - FP: 90.6900 - FN: 132.0600 - val_loss: 0.0893 - val_Accuracy: 0.9754 - val_Precision: 0.9581 - val_Recall: 0.9520 - val_TP: 765.4200 - val_TN: 1079.1400 - val_FP: 26.8600 - val_FN: 38.5800\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0362 - Accuracy: 0.9877 - Precision: 0.9659 - Recall: 0.9623 - TP: 3244.7800 - TN: 5559.0200 - FP: 87.9800 - FN: 127.2200 - val_loss: 0.0906 - val_Accuracy: 0.9764 - val_Precision: 0.9605 - val_Recall: 0.9499 - val_TP: 763.7300 - val_TN: 1081.3500 - val_FP: 24.6500 - val_FN: 40.2700\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0385 - Accuracy: 0.9875 - Precision: 0.9653 - Recall: 0.9612 - TP: 3241.0000 - TN: 5556.8599 - FP: 90.1400 - FN: 131.0000 - val_loss: 0.0945 - val_Accuracy: 0.9749 - val_Precision: 0.9587 - val_Recall: 0.9491 - val_TP: 763.0500 - val_TN: 1079.6300 - val_FP: 26.3700 - val_FN: 40.9500\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0379 - Accuracy: 0.9872 - Precision: 0.9652 - Recall: 0.9616 - TP: 3242.4099 - TN: 5556.7500 - FP: 90.2500 - FN: 129.5900 - val_loss: 0.0895 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9500 - val_TP: 763.8400 - val_TN: 1082.7700 - val_FP: 23.2300 - val_FN: 40.1600\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0379 - Accuracy: 0.9878 - Precision: 0.9650 - Recall: 0.9616 - TP: 3242.4399 - TN: 5555.6899 - FP: 91.3100 - FN: 129.5600 - val_loss: 0.0974 - val_Accuracy: 0.9743 - val_Precision: 0.9596 - val_Recall: 0.9478 - val_TP: 762.0100 - val_TN: 1080.4600 - val_FP: 25.5400 - val_FN: 41.9900\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0407 - Accuracy: 0.9875 - Precision: 0.9658 - Recall: 0.9607 - TP: 3239.3799 - TN: 5559.0098 - FP: 87.9900 - FN: 132.6200 - val_loss: 0.0897 - val_Accuracy: 0.9764 - val_Precision: 0.9613 - val_Recall: 0.9502 - val_TP: 763.9900 - val_TN: 1081.9900 - val_FP: 24.0100 - val_FN: 40.0100\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0395 - Accuracy: 0.9870 - Precision: 0.9652 - Recall: 0.9614 - TP: 3241.7300 - TN: 5556.5000 - FP: 90.5000 - FN: 130.2700 - val_loss: 0.0893 - val_Accuracy: 0.9770 - val_Precision: 0.9609 - val_Recall: 0.9508 - val_TP: 764.4500 - val_TN: 1081.6400 - val_FP: 24.3600 - val_FN: 39.5500\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0362 - Accuracy: 0.9875 - Precision: 0.9655 - Recall: 0.9621 - TP: 3244.1201 - TN: 5557.5298 - FP: 89.4700 - FN: 127.8800 - val_loss: 0.0928 - val_Accuracy: 0.9764 - val_Precision: 0.9618 - val_Recall: 0.9485 - val_TP: 762.5700 - val_TN: 1082.5200 - val_FP: 23.4800 - val_FN: 41.4300\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0397 - Accuracy: 0.9870 - Precision: 0.9650 - Recall: 0.9608 - TP: 3239.9199 - TN: 5555.9800 - FP: 91.0200 - FN: 132.0800 - val_loss: 0.0908 - val_Accuracy: 0.9759 - val_Precision: 0.9587 - val_Recall: 0.9513 - val_TP: 764.8800 - val_TN: 1079.7900 - val_FP: 26.2100 - val_FN: 39.1200\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0413 - Accuracy: 0.9867 - Precision: 0.9652 - Recall: 0.9612 - TP: 3241.2700 - TN: 5556.6001 - FP: 90.4000 - FN: 130.7300 - val_loss: 0.0899 - val_Accuracy: 0.9770 - val_Precision: 0.9637 - val_Recall: 0.9491 - val_TP: 763.0800 - val_TN: 1084.1600 - val_FP: 21.8400 - val_FN: 40.9200\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0358 - Accuracy: 0.9876 - Precision: 0.9659 - Recall: 0.9623 - TP: 3244.8301 - TN: 5559.0898 - FP: 87.9100 - FN: 127.1700 - val_loss: 0.0905 - val_Accuracy: 0.9764 - val_Precision: 0.9591 - val_Recall: 0.9518 - val_TP: 765.2700 - val_TN: 1080.0699 - val_FP: 25.9300 - val_FN: 38.7300\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0416 - Accuracy: 0.9867 - Precision: 0.9644 - Recall: 0.9611 - TP: 3240.9199 - TN: 5553.8198 - FP: 93.1800 - FN: 131.0800 - val_loss: 0.1028 - val_Accuracy: 0.9738 - val_Precision: 0.9536 - val_Recall: 0.9498 - val_TP: 763.6600 - val_TN: 1075.0400 - val_FP: 30.9600 - val_FN: 40.3400\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0394 - Accuracy: 0.9872 - Precision: 0.9661 - Recall: 0.9613 - TP: 3241.3601 - TN: 5559.8701 - FP: 87.1300 - FN: 130.6400 - val_loss: 0.0910 - val_Accuracy: 0.9764 - val_Precision: 0.9613 - val_Recall: 0.9502 - val_TP: 763.9500 - val_TN: 1082.0200 - val_FP: 23.9800 - val_FN: 40.0500\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0362 - Accuracy: 0.9877 - Precision: 0.9657 - Recall: 0.9627 - TP: 3246.3401 - TN: 5558.2402 - FP: 88.7600 - FN: 125.6600 - val_loss: 0.0905 - val_Accuracy: 0.9775 - val_Precision: 0.9626 - val_Recall: 0.9500 - val_TP: 763.7700 - val_TN: 1083.1700 - val_FP: 22.8300 - val_FN: 40.2300\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0392 - Accuracy: 0.9869 - Precision: 0.9660 - Recall: 0.9621 - TP: 3244.0701 - TN: 5559.6899 - FP: 87.3100 - FN: 127.9300 - val_loss: 0.0943 - val_Accuracy: 0.9759 - val_Precision: 0.9600 - val_Recall: 0.9500 - val_TP: 763.7700 - val_TN: 1081.0000 - val_FP: 25.0000 - val_FN: 40.2300\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0366 - Accuracy: 0.9880 - Precision: 0.9654 - Recall: 0.9623 - TP: 3244.8401 - TN: 5557.5200 - FP: 89.4800 - FN: 127.1600 - val_loss: 0.0927 - val_Accuracy: 0.9764 - val_Precision: 0.9619 - val_Recall: 0.9492 - val_TP: 763.1600 - val_TN: 1082.6000 - val_FP: 23.4000 - val_FN: 40.8400\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0384 - Accuracy: 0.9879 - Precision: 0.9661 - Recall: 0.9623 - TP: 3244.7700 - TN: 5560.0601 - FP: 86.9400 - FN: 127.2300 - val_loss: 0.0906 - val_Accuracy: 0.9775 - val_Precision: 0.9640 - val_Recall: 0.9497 - val_TP: 763.5900 - val_TN: 1084.4100 - val_FP: 21.5900 - val_FN: 40.4100\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0363 - Accuracy: 0.9884 - Precision: 0.9663 - Recall: 0.9623 - TP: 3244.9500 - TN: 5560.8101 - FP: 86.1900 - FN: 127.0500 - val_loss: 0.0918 - val_Accuracy: 0.9770 - val_Precision: 0.9624 - val_Recall: 0.9493 - val_TP: 763.2700 - val_TN: 1082.9900 - val_FP: 23.0100 - val_FN: 40.7300\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0362 - Accuracy: 0.9879 - Precision: 0.9661 - Recall: 0.9627 - TP: 3246.3501 - TN: 5560.0000 - FP: 87.0000 - FN: 125.6500 - val_loss: 0.0937 - val_Accuracy: 0.9754 - val_Precision: 0.9638 - val_Recall: 0.9476 - val_TP: 761.8400 - val_TN: 1084.3700 - val_FP: 21.6300 - val_FN: 42.1600\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0414 - Accuracy: 0.9879 - Precision: 0.9660 - Recall: 0.9620 - TP: 3243.8999 - TN: 5559.6602 - FP: 87.3400 - FN: 128.1000 - val_loss: 0.0921 - val_Accuracy: 0.9754 - val_Precision: 0.9606 - val_Recall: 0.9507 - val_TP: 764.3600 - val_TN: 1081.4800 - val_FP: 24.5200 - val_FN: 39.6400\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0349 - Accuracy: 0.9875 - Precision: 0.9661 - Recall: 0.9629 - TP: 3247.0200 - TN: 5559.9199 - FP: 87.0800 - FN: 124.9800 - val_loss: 0.0931 - val_Accuracy: 0.9754 - val_Precision: 0.9634 - val_Recall: 0.9483 - val_TP: 762.4200 - val_TN: 1083.9500 - val_FP: 22.0500 - val_FN: 41.5800\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0389 - Accuracy: 0.9865 - Precision: 0.9654 - Recall: 0.9616 - TP: 3242.4600 - TN: 5557.6401 - FP: 89.3600 - FN: 129.5400 - val_loss: 0.1041 - val_Accuracy: 0.9728 - val_Precision: 0.9464 - val_Recall: 0.9506 - val_TP: 764.2700 - val_TN: 1068.0699 - val_FP: 37.9300 - val_FN: 39.7300\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0398 - Accuracy: 0.9874 - Precision: 0.9648 - Recall: 0.9617 - TP: 3242.7800 - TN: 5554.9199 - FP: 92.0800 - FN: 129.2200 - val_loss: 0.0956 - val_Accuracy: 0.9749 - val_Precision: 0.9583 - val_Recall: 0.9493 - val_TP: 763.2500 - val_TN: 1079.3900 - val_FP: 26.6100 - val_FN: 40.7500\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0386 - Accuracy: 0.9867 - Precision: 0.9652 - Recall: 0.9607 - TP: 3239.3999 - TN: 5556.6201 - FP: 90.3800 - FN: 132.6000 - val_loss: 0.0893 - val_Accuracy: 0.9764 - val_Precision: 0.9658 - val_Recall: 0.9480 - val_TP: 762.1900 - val_TN: 1085.9900 - val_FP: 20.0100 - val_FN: 41.8100\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0394 - Accuracy: 0.9871 - Precision: 0.9654 - Recall: 0.9618 - TP: 3243.1201 - TN: 5557.6401 - FP: 89.3600 - FN: 128.8800 - val_loss: 0.0886 - val_Accuracy: 0.9770 - val_Precision: 0.9604 - val_Recall: 0.9515 - val_TP: 764.9900 - val_TN: 1081.2300 - val_FP: 24.7700 - val_FN: 39.0100\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0365 - Accuracy: 0.9877 - Precision: 0.9660 - Recall: 0.9618 - TP: 3243.0601 - TN: 5559.9502 - FP: 87.0500 - FN: 128.9400 - val_loss: 0.0892 - val_Accuracy: 0.9759 - val_Precision: 0.9579 - val_Recall: 0.9529 - val_TP: 766.1000 - val_TN: 1079.0200 - val_FP: 26.9800 - val_FN: 37.9000\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0408 - Accuracy: 0.9870 - Precision: 0.9645 - Recall: 0.9614 - TP: 3241.7800 - TN: 5553.9199 - FP: 93.0800 - FN: 130.2200 - val_loss: 0.0895 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9492 - val_TP: 763.1300 - val_TN: 1083.7200 - val_FP: 22.2800 - val_FN: 40.8700\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0372 - Accuracy: 0.9874 - Precision: 0.9655 - Recall: 0.9616 - TP: 3242.6599 - TN: 5557.6899 - FP: 89.3100 - FN: 129.3400 - val_loss: 0.0914 - val_Accuracy: 0.9759 - val_Precision: 0.9620 - val_Recall: 0.9491 - val_TP: 763.1000 - val_TN: 1082.7100 - val_FP: 23.2900 - val_FN: 40.9000\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0366 - Accuracy: 0.9879 - Precision: 0.9667 - Recall: 0.9615 - TP: 3242.3101 - TN: 5562.4302 - FP: 84.5700 - FN: 129.6900 - val_loss: 0.0965 - val_Accuracy: 0.9754 - val_Precision: 0.9534 - val_Recall: 0.9526 - val_TP: 765.9300 - val_TN: 1074.8600 - val_FP: 31.1400 - val_FN: 38.0700\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0440 - Accuracy: 0.9861 - Precision: 0.9641 - Recall: 0.9617 - TP: 3242.9700 - TN: 5552.6401 - FP: 94.3600 - FN: 129.0300 - val_loss: 0.0949 - val_Accuracy: 0.9770 - val_Precision: 0.9588 - val_Recall: 0.9502 - val_TP: 763.9800 - val_TN: 1079.9100 - val_FP: 26.0900 - val_FN: 40.0200\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0381 - Accuracy: 0.9875 - Precision: 0.9653 - Recall: 0.9622 - TP: 3244.6899 - TN: 5557.5698 - FP: 89.4300 - FN: 127.3100 - val_loss: 0.0948 - val_Accuracy: 0.9749 - val_Precision: 0.9622 - val_Recall: 0.9478 - val_TP: 762.0200 - val_TN: 1082.9600 - val_FP: 23.0400 - val_FN: 41.9800\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0367 - Accuracy: 0.9884 - Precision: 0.9666 - Recall: 0.9619 - TP: 3243.6799 - TN: 5561.8999 - FP: 85.1000 - FN: 128.3200 - val_loss: 0.0922 - val_Accuracy: 0.9764 - val_Precision: 0.9604 - val_Recall: 0.9502 - val_TP: 763.9600 - val_TN: 1081.3101 - val_FP: 24.6900 - val_FN: 40.0400\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0364 - Accuracy: 0.9872 - Precision: 0.9653 - Recall: 0.9623 - TP: 3244.7600 - TN: 5556.9302 - FP: 90.0700 - FN: 127.2400 - val_loss: 0.0912 - val_Accuracy: 0.9775 - val_Precision: 0.9622 - val_Recall: 0.9495 - val_TP: 763.3800 - val_TN: 1082.8800 - val_FP: 23.1200 - val_FN: 40.6200\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0357 - Accuracy: 0.9876 - Precision: 0.9659 - Recall: 0.9626 - TP: 3245.7500 - TN: 5559.0698 - FP: 87.9300 - FN: 126.2500 - val_loss: 0.0921 - val_Accuracy: 0.9764 - val_Precision: 0.9627 - val_Recall: 0.9490 - val_TP: 762.9700 - val_TN: 1083.3000 - val_FP: 22.7000 - val_FN: 41.0300\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0405 - Accuracy: 0.9870 - Precision: 0.9656 - Recall: 0.9616 - TP: 3242.4099 - TN: 5558.3901 - FP: 88.6100 - FN: 129.5900 - val_loss: 0.0919 - val_Accuracy: 0.9770 - val_Precision: 0.9628 - val_Recall: 0.9491 - val_TP: 763.0700 - val_TN: 1083.4100 - val_FP: 22.5900 - val_FN: 40.9300\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0362 - Accuracy: 0.9874 - Precision: 0.9656 - Recall: 0.9625 - TP: 3245.3999 - TN: 5558.2798 - FP: 88.7200 - FN: 126.6000 - val_loss: 0.0934 - val_Accuracy: 0.9754 - val_Precision: 0.9641 - val_Recall: 0.9476 - val_TP: 761.9000 - val_TN: 1084.5400 - val_FP: 21.4600 - val_FN: 42.1000\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0397 - Accuracy: 0.9872 - Precision: 0.9653 - Recall: 0.9604 - TP: 3238.5300 - TN: 5557.3999 - FP: 89.6000 - FN: 133.4700 - val_loss: 0.0941 - val_Accuracy: 0.9749 - val_Precision: 0.9594 - val_Recall: 0.9504 - val_TP: 764.1100 - val_TN: 1080.5100 - val_FP: 25.4900 - val_FN: 39.8900\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0361 - Accuracy: 0.9872 - Precision: 0.9660 - Recall: 0.9621 - TP: 3244.3601 - TN: 5559.7002 - FP: 87.3000 - FN: 127.6400 - val_loss: 0.0905 - val_Accuracy: 0.9775 - val_Precision: 0.9616 - val_Recall: 0.9515 - val_TP: 765.0300 - val_TN: 1082.2600 - val_FP: 23.7400 - val_FN: 38.9700\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0376 - Accuracy: 0.9876 - Precision: 0.9657 - Recall: 0.9624 - TP: 3245.2700 - TN: 5558.3398 - FP: 88.6600 - FN: 126.7300 - val_loss: 0.0922 - val_Accuracy: 0.9770 - val_Precision: 0.9619 - val_Recall: 0.9499 - val_TP: 763.7300 - val_TN: 1082.5300 - val_FP: 23.4700 - val_FN: 40.2700\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0391 - Accuracy: 0.9869 - Precision: 0.9654 - Recall: 0.9619 - TP: 3243.3601 - TN: 5557.5698 - FP: 89.4300 - FN: 128.6400 - val_loss: 0.0940 - val_Accuracy: 0.9759 - val_Precision: 0.9613 - val_Recall: 0.9493 - val_TP: 763.2300 - val_TN: 1082.1300 - val_FP: 23.8700 - val_FN: 40.7700\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0423 - Accuracy: 0.9879 - Precision: 0.9663 - Recall: 0.9618 - TP: 3243.2900 - TN: 5560.9399 - FP: 86.0600 - FN: 128.7100 - val_loss: 0.0929 - val_Accuracy: 0.9759 - val_Precision: 0.9601 - val_Recall: 0.9508 - val_TP: 764.4400 - val_TN: 1081.0400 - val_FP: 24.9600 - val_FN: 39.5600\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0384 - Accuracy: 0.9864 - Precision: 0.9646 - Recall: 0.9622 - TP: 3244.3799 - TN: 5554.5801 - FP: 92.4200 - FN: 127.6200 - val_loss: 0.0930 - val_Accuracy: 0.9770 - val_Precision: 0.9669 - val_Recall: 0.9466 - val_TP: 761.1000 - val_TN: 1086.9399 - val_FP: 19.0600 - val_FN: 42.9000\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0382 - Accuracy: 0.9884 - Precision: 0.9667 - Recall: 0.9625 - TP: 3245.7000 - TN: 5562.5200 - FP: 84.4800 - FN: 126.3000 - val_loss: 0.0913 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9519 - val_TP: 765.3400 - val_TN: 1081.2000 - val_FP: 24.8000 - val_FN: 38.6600\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0365 - Accuracy: 0.9875 - Precision: 0.9659 - Recall: 0.9624 - TP: 3245.0801 - TN: 5559.5498 - FP: 87.4500 - FN: 126.9200 - val_loss: 0.0923 - val_Accuracy: 0.9770 - val_Precision: 0.9653 - val_Recall: 0.9484 - val_TP: 762.5500 - val_TN: 1085.5699 - val_FP: 20.4300 - val_FN: 41.4500\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0382 - Accuracy: 0.9876 - Precision: 0.9661 - Recall: 0.9627 - TP: 3246.2700 - TN: 5560.3398 - FP: 86.6600 - FN: 125.7300 - val_loss: 0.0950 - val_Accuracy: 0.9754 - val_Precision: 0.9624 - val_Recall: 0.9487 - val_TP: 762.7200 - val_TN: 1083.1400 - val_FP: 22.8600 - val_FN: 41.2800\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0428 - Accuracy: 0.9861 - Precision: 0.9649 - Recall: 0.9612 - TP: 3241.0200 - TN: 5555.8701 - FP: 91.1300 - FN: 130.9800 - val_loss: 0.0908 - val_Accuracy: 0.9754 - val_Precision: 0.9616 - val_Recall: 0.9493 - val_TP: 763.2000 - val_TN: 1082.3500 - val_FP: 23.6500 - val_FN: 40.8000\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0377 - Accuracy: 0.9869 - Precision: 0.9662 - Recall: 0.9612 - TP: 3241.2400 - TN: 5560.3701 - FP: 86.6300 - FN: 130.7600 - val_loss: 0.0924 - val_Accuracy: 0.9749 - val_Precision: 0.9581 - val_Recall: 0.9515 - val_TP: 765.0400 - val_TN: 1079.2500 - val_FP: 26.7500 - val_FN: 38.9600\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0380 - Accuracy: 0.9869 - Precision: 0.9645 - Recall: 0.9626 - TP: 3245.8000 - TN: 5553.7700 - FP: 93.2300 - FN: 126.2000 - val_loss: 0.0931 - val_Accuracy: 0.9749 - val_Precision: 0.9657 - val_Recall: 0.9458 - val_TP: 760.4300 - val_TN: 1085.9200 - val_FP: 20.0800 - val_FN: 43.5700\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0420 - Accuracy: 0.9863 - Precision: 0.9650 - Recall: 0.9607 - TP: 3239.4099 - TN: 5556.1602 - FP: 90.8400 - FN: 132.5900 - val_loss: 0.0921 - val_Accuracy: 0.9770 - val_Precision: 0.9661 - val_Recall: 0.9463 - val_TP: 760.8100 - val_TN: 1086.2900 - val_FP: 19.7100 - val_FN: 43.1900\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0378 - Accuracy: 0.9871 - Precision: 0.9648 - Recall: 0.9617 - TP: 3242.8101 - TN: 5555.4502 - FP: 91.5500 - FN: 129.1900 - val_loss: 0.0919 - val_Accuracy: 0.9754 - val_Precision: 0.9636 - val_Recall: 0.9480 - val_TP: 762.1600 - val_TN: 1084.1400 - val_FP: 21.8600 - val_FN: 41.8400\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0351 - Accuracy: 0.9879 - Precision: 0.9662 - Recall: 0.9623 - TP: 3245.0000 - TN: 5560.1499 - FP: 86.8500 - FN: 127.0000 - val_loss: 0.0918 - val_Accuracy: 0.9764 - val_Precision: 0.9631 - val_Recall: 0.9488 - val_TP: 762.8600 - val_TN: 1083.6899 - val_FP: 22.3100 - val_FN: 41.1400\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0393 - Accuracy: 0.9875 - Precision: 0.9651 - Recall: 0.9612 - TP: 3241.2300 - TN: 5556.1802 - FP: 90.8200 - FN: 130.7700 - val_loss: 0.0929 - val_Accuracy: 0.9754 - val_Precision: 0.9621 - val_Recall: 0.9482 - val_TP: 762.3300 - val_TN: 1082.7900 - val_FP: 23.2100 - val_FN: 41.6700\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0371 - Accuracy: 0.9877 - Precision: 0.9661 - Recall: 0.9612 - TP: 3241.3101 - TN: 5559.8901 - FP: 87.1100 - FN: 130.6900 - val_loss: 0.0912 - val_Accuracy: 0.9770 - val_Precision: 0.9627 - val_Recall: 0.9490 - val_TP: 763.0200 - val_TN: 1083.3000 - val_FP: 22.7000 - val_FN: 40.9800\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0360 - Accuracy: 0.9874 - Precision: 0.9656 - Recall: 0.9624 - TP: 3245.1001 - TN: 5557.8701 - FP: 89.1300 - FN: 126.9000 - val_loss: 0.0911 - val_Accuracy: 0.9764 - val_Precision: 0.9651 - val_Recall: 0.9483 - val_TP: 762.4200 - val_TN: 1085.3900 - val_FP: 20.6100 - val_FN: 41.5800\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0371 - Accuracy: 0.9872 - Precision: 0.9657 - Recall: 0.9616 - TP: 3242.5701 - TN: 5558.6802 - FP: 88.3200 - FN: 129.4300 - val_loss: 0.0915 - val_Accuracy: 0.9759 - val_Precision: 0.9602 - val_Recall: 0.9508 - val_TP: 764.4800 - val_TN: 1081.1000 - val_FP: 24.9000 - val_FN: 39.5200\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0421 - Accuracy: 0.9874 - Precision: 0.9647 - Recall: 0.9617 - TP: 3242.8899 - TN: 5555.1299 - FP: 91.8700 - FN: 129.1100 - val_loss: 0.0929 - val_Accuracy: 0.9749 - val_Precision: 0.9617 - val_Recall: 0.9490 - val_TP: 762.9700 - val_TN: 1082.4700 - val_FP: 23.5300 - val_FN: 41.0300\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0391 - Accuracy: 0.9872 - Precision: 0.9656 - Recall: 0.9610 - TP: 3240.4800 - TN: 5558.3599 - FP: 88.6400 - FN: 131.5200 - val_loss: 0.0994 - val_Accuracy: 0.9738 - val_Precision: 0.9587 - val_Recall: 0.9483 - val_TP: 762.4600 - val_TN: 1079.7900 - val_FP: 26.2100 - val_FN: 41.5400\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0369 - Accuracy: 0.9875 - Precision: 0.9666 - Recall: 0.9620 - TP: 3243.8999 - TN: 5562.1899 - FP: 84.8100 - FN: 128.1000 - val_loss: 0.0951 - val_Accuracy: 0.9749 - val_Precision: 0.9586 - val_Recall: 0.9508 - val_TP: 764.4100 - val_TN: 1079.7300 - val_FP: 26.2700 - val_FN: 39.5900\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0402 - Accuracy: 0.9871 - Precision: 0.9646 - Recall: 0.9620 - TP: 3243.7400 - TN: 5554.4902 - FP: 92.5100 - FN: 128.2600 - val_loss: 0.0914 - val_Accuracy: 0.9775 - val_Precision: 0.9640 - val_Recall: 0.9492 - val_TP: 763.1200 - val_TN: 1084.3800 - val_FP: 21.6200 - val_FN: 40.8800\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0362 - Accuracy: 0.9879 - Precision: 0.9661 - Recall: 0.9626 - TP: 3245.7400 - TN: 5559.8799 - FP: 87.1200 - FN: 126.2600 - val_loss: 0.0933 - val_Accuracy: 0.9764 - val_Precision: 0.9623 - val_Recall: 0.9491 - val_TP: 763.1100 - val_TN: 1083.0300 - val_FP: 22.9700 - val_FN: 40.8900\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0373 - Accuracy: 0.9874 - Precision: 0.9664 - Recall: 0.9616 - TP: 3242.4199 - TN: 5561.4902 - FP: 85.5100 - FN: 129.5800 - val_loss: 0.0914 - val_Accuracy: 0.9770 - val_Precision: 0.9599 - val_Recall: 0.9520 - val_TP: 765.3900 - val_TN: 1080.7600 - val_FP: 25.2400 - val_FN: 38.6100\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0397 - Accuracy: 0.9876 - Precision: 0.9645 - Recall: 0.9629 - TP: 3247.0300 - TN: 5553.9302 - FP: 93.0700 - FN: 124.9700 - val_loss: 0.0944 - val_Accuracy: 0.9749 - val_Precision: 0.9626 - val_Recall: 0.9485 - val_TP: 762.5700 - val_TN: 1083.3000 - val_FP: 22.7000 - val_FN: 41.4300\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0360 - Accuracy: 0.9878 - Precision: 0.9666 - Recall: 0.9627 - TP: 3246.2100 - TN: 5561.9399 - FP: 85.0600 - FN: 125.7900 - val_loss: 0.0935 - val_Accuracy: 0.9754 - val_Precision: 0.9642 - val_Recall: 0.9482 - val_TP: 762.3300 - val_TN: 1084.6200 - val_FP: 21.3800 - val_FN: 41.6700\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0408 - Accuracy: 0.9874 - Precision: 0.9653 - Recall: 0.9622 - TP: 3244.5901 - TN: 5557.2900 - FP: 89.7100 - FN: 127.4100 - val_loss: 0.0998 - val_Accuracy: 0.9754 - val_Precision: 0.9593 - val_Recall: 0.9484 - val_TP: 762.5100 - val_TN: 1080.4200 - val_FP: 25.5800 - val_FN: 41.4900\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0373 - Accuracy: 0.9877 - Precision: 0.9661 - Recall: 0.9617 - TP: 3242.8501 - TN: 5560.2402 - FP: 86.7600 - FN: 129.1500 - val_loss: 0.0939 - val_Accuracy: 0.9764 - val_Precision: 0.9634 - val_Recall: 0.9484 - val_TP: 762.5200 - val_TN: 1083.9399 - val_FP: 22.0600 - val_FN: 41.4800\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0359 - Accuracy: 0.9884 - Precision: 0.9671 - Recall: 0.9626 - TP: 3245.7400 - TN: 5563.9199 - FP: 83.0800 - FN: 126.2600 - val_loss: 0.0929 - val_Accuracy: 0.9759 - val_Precision: 0.9605 - val_Recall: 0.9510 - val_TP: 764.6300 - val_TN: 1081.3800 - val_FP: 24.6200 - val_FN: 39.3700\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0400 - Accuracy: 0.9875 - Precision: 0.9657 - Recall: 0.9617 - TP: 3242.8101 - TN: 5558.5298 - FP: 88.4700 - FN: 129.1900 - val_loss: 0.0901 - val_Accuracy: 0.9770 - val_Precision: 0.9647 - val_Recall: 0.9482 - val_TP: 762.3700 - val_TN: 1085.0100 - val_FP: 20.9900 - val_FN: 41.6300\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0360 - Accuracy: 0.9867 - Precision: 0.9654 - Recall: 0.9619 - TP: 3243.3701 - TN: 5557.2900 - FP: 89.7100 - FN: 128.6300 - val_loss: 0.0913 - val_Accuracy: 0.9759 - val_Precision: 0.9663 - val_Recall: 0.9467 - val_TP: 761.1500 - val_TN: 1086.4500 - val_FP: 19.5500 - val_FN: 42.8500\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0404 - Accuracy: 0.9867 - Precision: 0.9650 - Recall: 0.9615 - TP: 3242.1001 - TN: 5556.2402 - FP: 90.7600 - FN: 129.9000 - val_loss: 0.0970 - val_Accuracy: 0.9743 - val_Precision: 0.9582 - val_Recall: 0.9487 - val_TP: 762.7800 - val_TN: 1079.3500 - val_FP: 26.6500 - val_FN: 41.2200\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0391 - Accuracy: 0.9878 - Precision: 0.9655 - Recall: 0.9606 - TP: 3239.0100 - TN: 5557.6499 - FP: 89.3500 - FN: 132.9900 - val_loss: 0.0950 - val_Accuracy: 0.9754 - val_Precision: 0.9568 - val_Recall: 0.9510 - val_TP: 764.6000 - val_TN: 1078.0300 - val_FP: 27.9700 - val_FN: 39.4000\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0412 - Accuracy: 0.9868 - Precision: 0.9649 - Recall: 0.9614 - TP: 3241.7600 - TN: 5555.3701 - FP: 91.6300 - FN: 130.2400 - val_loss: 0.1113 - val_Accuracy: 0.9707 - val_Precision: 0.9454 - val_Recall: 0.9486 - val_TP: 762.6500 - val_TN: 1067.2200 - val_FP: 38.7800 - val_FN: 41.3500\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0421 - Accuracy: 0.9870 - Precision: 0.9653 - Recall: 0.9610 - TP: 3240.5200 - TN: 5557.6201 - FP: 89.3800 - FN: 131.4800 - val_loss: 0.0924 - val_Accuracy: 0.9749 - val_Precision: 0.9600 - val_Recall: 0.9504 - val_TP: 764.1000 - val_TN: 1080.9301 - val_FP: 25.0700 - val_FN: 39.9000\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0368 - Accuracy: 0.9874 - Precision: 0.9651 - Recall: 0.9624 - TP: 3245.0901 - TN: 5556.2700 - FP: 90.7300 - FN: 126.9100 - val_loss: 0.0910 - val_Accuracy: 0.9764 - val_Precision: 0.9656 - val_Recall: 0.9480 - val_TP: 762.1600 - val_TN: 1085.7800 - val_FP: 20.2200 - val_FN: 41.8400\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0387 - Accuracy: 0.9876 - Precision: 0.9658 - Recall: 0.9621 - TP: 3244.1799 - TN: 5559.0298 - FP: 87.9700 - FN: 127.8200 - val_loss: 0.0926 - val_Accuracy: 0.9754 - val_Precision: 0.9623 - val_Recall: 0.9489 - val_TP: 762.9300 - val_TN: 1083.0400 - val_FP: 22.9600 - val_FN: 41.0700\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0399 - Accuracy: 0.9871 - Precision: 0.9648 - Recall: 0.9614 - TP: 3241.8701 - TN: 5555.5400 - FP: 91.4600 - FN: 130.1300 - val_loss: 0.0934 - val_Accuracy: 0.9749 - val_Precision: 0.9628 - val_Recall: 0.9480 - val_TP: 762.2100 - val_TN: 1083.4399 - val_FP: 22.5600 - val_FN: 41.7900\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0431 - Accuracy: 0.9871 - Precision: 0.9657 - Recall: 0.9613 - TP: 3241.5801 - TN: 5559.1201 - FP: 87.8800 - FN: 130.4200 - val_loss: 0.0952 - val_Accuracy: 0.9759 - val_Precision: 0.9608 - val_Recall: 0.9494 - val_TP: 763.2800 - val_TN: 1081.7500 - val_FP: 24.2500 - val_FN: 40.7200\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0375 - Accuracy: 0.9871 - Precision: 0.9651 - Recall: 0.9617 - TP: 3242.7700 - TN: 5556.1802 - FP: 90.8200 - FN: 129.2300 - val_loss: 0.0986 - val_Accuracy: 0.9759 - val_Precision: 0.9592 - val_Recall: 0.9491 - val_TP: 763.1000 - val_TN: 1080.2900 - val_FP: 25.7100 - val_FN: 40.9000\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0450 - Accuracy: 0.9861 - Precision: 0.9659 - Recall: 0.9612 - TP: 3241.1101 - TN: 5559.8799 - FP: 87.1200 - FN: 130.8900 - val_loss: 0.0949 - val_Accuracy: 0.9759 - val_Precision: 0.9551 - val_Recall: 0.9534 - val_TP: 766.5600 - val_TN: 1076.5500 - val_FP: 29.4500 - val_FN: 37.4400\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0362 - Accuracy: 0.9882 - Precision: 0.9651 - Recall: 0.9632 - TP: 3248.0400 - TN: 5556.2300 - FP: 90.7700 - FN: 123.9600 - val_loss: 0.0965 - val_Accuracy: 0.9749 - val_Precision: 0.9631 - val_Recall: 0.9471 - val_TP: 761.4400 - val_TN: 1083.7500 - val_FP: 22.2500 - val_FN: 42.5600\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0449 - Accuracy: 0.9876 - Precision: 0.9657 - Recall: 0.9615 - TP: 3242.0200 - TN: 5558.6299 - FP: 88.3700 - FN: 129.9800 - val_loss: 0.0930 - val_Accuracy: 0.9759 - val_Precision: 0.9622 - val_Recall: 0.9495 - val_TP: 763.3900 - val_TN: 1082.8600 - val_FP: 23.1400 - val_FN: 40.6100\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0373 - Accuracy: 0.9879 - Precision: 0.9663 - Recall: 0.9627 - TP: 3246.2100 - TN: 5561.0898 - FP: 85.9100 - FN: 125.7900 - val_loss: 0.0942 - val_Accuracy: 0.9754 - val_Precision: 0.9600 - val_Recall: 0.9503 - val_TP: 764.0700 - val_TN: 1081.0000 - val_FP: 25.0000 - val_FN: 39.9300\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0388 - Accuracy: 0.9872 - Precision: 0.9659 - Recall: 0.9615 - TP: 3242.1699 - TN: 5559.8701 - FP: 87.1300 - FN: 129.8300 - val_loss: 0.0911 - val_Accuracy: 0.9775 - val_Precision: 0.9615 - val_Recall: 0.9517 - val_TP: 765.1300 - val_TN: 1082.2600 - val_FP: 23.7400 - val_FN: 38.8700\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0369 - Accuracy: 0.9878 - Precision: 0.9661 - Recall: 0.9630 - TP: 3247.0901 - TN: 5560.1899 - FP: 86.8100 - FN: 124.9100 - val_loss: 0.0925 - val_Accuracy: 0.9770 - val_Precision: 0.9588 - val_Recall: 0.9524 - val_TP: 765.6900 - val_TN: 1079.8300 - val_FP: 26.1700 - val_FN: 38.3100\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0367 - Accuracy: 0.9874 - Precision: 0.9658 - Recall: 0.9617 - TP: 3242.9399 - TN: 5558.9399 - FP: 88.0600 - FN: 129.0600 - val_loss: 0.0943 - val_Accuracy: 0.9754 - val_Precision: 0.9548 - val_Recall: 0.9536 - val_TP: 766.7100 - val_TN: 1076.2400 - val_FP: 29.7600 - val_FN: 37.2900\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0355 - Accuracy: 0.9886 - Precision: 0.9658 - Recall: 0.9625 - TP: 3245.4399 - TN: 5558.8999 - FP: 88.1000 - FN: 126.5600 - val_loss: 0.0937 - val_Accuracy: 0.9759 - val_Precision: 0.9584 - val_Recall: 0.9519 - val_TP: 765.3100 - val_TN: 1079.5500 - val_FP: 26.4500 - val_FN: 38.6900\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0408 - Accuracy: 0.9875 - Precision: 0.9654 - Recall: 0.9618 - TP: 3243.2100 - TN: 5557.7002 - FP: 89.3000 - FN: 128.7900 - val_loss: 0.0935 - val_Accuracy: 0.9775 - val_Precision: 0.9584 - val_Recall: 0.9519 - val_TP: 765.3100 - val_TN: 1079.4200 - val_FP: 26.5800 - val_FN: 38.6900\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0361 - Accuracy: 0.9882 - Precision: 0.9662 - Recall: 0.9631 - TP: 3247.6101 - TN: 5560.6001 - FP: 86.4000 - FN: 124.3900 - val_loss: 0.0976 - val_Accuracy: 0.9749 - val_Precision: 0.9638 - val_Recall: 0.9470 - val_TP: 761.3500 - val_TN: 1084.4600 - val_FP: 21.5400 - val_FN: 42.6500\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0417 - Accuracy: 0.9865 - Precision: 0.9660 - Recall: 0.9611 - TP: 3240.9600 - TN: 5560.2202 - FP: 86.7800 - FN: 131.0400 - val_loss: 0.0906 - val_Accuracy: 0.9749 - val_Precision: 0.9607 - val_Recall: 0.9505 - val_TP: 764.1900 - val_TN: 1081.5900 - val_FP: 24.4100 - val_FN: 39.8100\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0363 - Accuracy: 0.9877 - Precision: 0.9658 - Recall: 0.9623 - TP: 3244.7300 - TN: 5558.8501 - FP: 88.1500 - FN: 127.2700 - val_loss: 0.0910 - val_Accuracy: 0.9754 - val_Precision: 0.9623 - val_Recall: 0.9496 - val_TP: 763.4500 - val_TN: 1083.0000 - val_FP: 23.0000 - val_FN: 40.5500\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0387 - Accuracy: 0.9866 - Precision: 0.9651 - Recall: 0.9618 - TP: 3243.0300 - TN: 5556.5601 - FP: 90.4400 - FN: 128.9700 - val_loss: 0.0945 - val_Accuracy: 0.9749 - val_Precision: 0.9574 - val_Recall: 0.9509 - val_TP: 764.5000 - val_TN: 1078.6300 - val_FP: 27.3700 - val_FN: 39.5000\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0386 - Accuracy: 0.9869 - Precision: 0.9650 - Recall: 0.9617 - TP: 3242.9700 - TN: 5555.8101 - FP: 91.1900 - FN: 129.0300 - val_loss: 0.0966 - val_Accuracy: 0.9754 - val_Precision: 0.9643 - val_Recall: 0.9453 - val_TP: 759.9900 - val_TN: 1084.8000 - val_FP: 21.2000 - val_FN: 44.0100\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0377 - Accuracy: 0.9872 - Precision: 0.9655 - Recall: 0.9610 - TP: 3240.3999 - TN: 5557.8101 - FP: 89.1900 - FN: 131.6000 - val_loss: 0.0902 - val_Accuracy: 0.9770 - val_Precision: 0.9641 - val_Recall: 0.9489 - val_TP: 762.9200 - val_TN: 1084.4600 - val_FP: 21.5400 - val_FN: 41.0800\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0409 - Accuracy: 0.9870 - Precision: 0.9657 - Recall: 0.9616 - TP: 3242.6001 - TN: 5558.7202 - FP: 88.2800 - FN: 129.4000 - val_loss: 0.0949 - val_Accuracy: 0.9759 - val_Precision: 0.9573 - val_Recall: 0.9515 - val_TP: 764.9900 - val_TN: 1078.5699 - val_FP: 27.4300 - val_FN: 39.0100\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0391 - Accuracy: 0.9869 - Precision: 0.9645 - Recall: 0.9619 - TP: 3243.4399 - TN: 5554.2002 - FP: 92.8000 - FN: 128.5600 - val_loss: 0.0915 - val_Accuracy: 0.9770 - val_Precision: 0.9662 - val_Recall: 0.9472 - val_TP: 761.5300 - val_TN: 1086.3500 - val_FP: 19.6500 - val_FN: 42.4700\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0404 - Accuracy: 0.9870 - Precision: 0.9668 - Recall: 0.9618 - TP: 3243.2300 - TN: 5562.8301 - FP: 84.1700 - FN: 128.7700 - val_loss: 0.0936 - val_Accuracy: 0.9754 - val_Precision: 0.9592 - val_Recall: 0.9507 - val_TP: 764.3700 - val_TN: 1080.3199 - val_FP: 25.6800 - val_FN: 39.6300\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0416 - Accuracy: 0.9877 - Precision: 0.9649 - Recall: 0.9619 - TP: 3243.6799 - TN: 5555.9502 - FP: 91.0500 - FN: 128.3200 - val_loss: 0.0944 - val_Accuracy: 0.9749 - val_Precision: 0.9581 - val_Recall: 0.9511 - val_TP: 764.7000 - val_TN: 1079.3199 - val_FP: 26.6800 - val_FN: 39.3000\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0373 - Accuracy: 0.9877 - Precision: 0.9657 - Recall: 0.9625 - TP: 3245.7000 - TN: 5558.7002 - FP: 88.3000 - FN: 126.3000 - val_loss: 0.1013 - val_Accuracy: 0.9738 - val_Precision: 0.9552 - val_Recall: 0.9495 - val_TP: 763.3800 - val_TN: 1076.4700 - val_FP: 29.5300 - val_FN: 40.6200\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0538 - Accuracy: 0.9866 - Precision: 0.9645 - Recall: 0.9616 - TP: 3242.4199 - TN: 5554.6499 - FP: 92.3500 - FN: 129.5800 - val_loss: 0.0928 - val_Accuracy: 0.9770 - val_Precision: 0.9635 - val_Recall: 0.9489 - val_TP: 762.9100 - val_TN: 1083.9700 - val_FP: 22.0300 - val_FN: 41.0900\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0454 - Accuracy: 0.9863 - Precision: 0.9657 - Recall: 0.9603 - TP: 3238.1499 - TN: 5559.3501 - FP: 87.6500 - FN: 133.8500 - val_loss: 0.0923 - val_Accuracy: 0.9759 - val_Precision: 0.9562 - val_Recall: 0.9532 - val_TP: 766.4100 - val_TN: 1077.4800 - val_FP: 28.5200 - val_FN: 37.5900\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0439 - Accuracy: 0.9866 - Precision: 0.9646 - Recall: 0.9623 - TP: 3244.8701 - TN: 5554.9600 - FP: 92.0400 - FN: 127.1300 - val_loss: 0.0927 - val_Accuracy: 0.9749 - val_Precision: 0.9620 - val_Recall: 0.9498 - val_TP: 763.6600 - val_TN: 1082.7300 - val_FP: 23.2700 - val_FN: 40.3400\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0345 - Accuracy: 0.9882 - Precision: 0.9660 - Recall: 0.9626 - TP: 3245.8401 - TN: 5559.6001 - FP: 87.4000 - FN: 126.1600 - val_loss: 0.0936 - val_Accuracy: 0.9759 - val_Precision: 0.9614 - val_Recall: 0.9498 - val_TP: 763.6700 - val_TN: 1082.2100 - val_FP: 23.7900 - val_FN: 40.3300\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0361 - Accuracy: 0.9867 - Precision: 0.9657 - Recall: 0.9620 - TP: 3243.9299 - TN: 5559.0400 - FP: 87.9600 - FN: 128.0700 - val_loss: 0.0928 - val_Accuracy: 0.9764 - val_Precision: 0.9620 - val_Recall: 0.9499 - val_TP: 763.7300 - val_TN: 1082.6500 - val_FP: 23.3500 - val_FN: 40.2700\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0402 - Accuracy: 0.9870 - Precision: 0.9656 - Recall: 0.9620 - TP: 3243.7700 - TN: 5558.5898 - FP: 88.4100 - FN: 128.2300 - val_loss: 0.0938 - val_Accuracy: 0.9759 - val_Precision: 0.9601 - val_Recall: 0.9507 - val_TP: 764.3500 - val_TN: 1081.0400 - val_FP: 24.9600 - val_FN: 39.6500\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0377 - Accuracy: 0.9877 - Precision: 0.9659 - Recall: 0.9625 - TP: 3245.5300 - TN: 5559.3901 - FP: 87.6100 - FN: 126.4700 - val_loss: 0.0978 - val_Accuracy: 0.9749 - val_Precision: 0.9589 - val_Recall: 0.9501 - val_TP: 763.9200 - val_TN: 1080.1000 - val_FP: 25.9000 - val_FN: 40.0800\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0626 - Accuracy: 0.9856 - Precision: 0.9632 - Recall: 0.9599 - TP: 3236.8601 - TN: 5550.1499 - FP: 96.8500 - FN: 135.1400 - val_loss: 0.1009 - val_Accuracy: 0.9754 - val_Precision: 0.9565 - val_Recall: 0.9500 - val_TP: 763.8100 - val_TN: 1077.8400 - val_FP: 28.1600 - val_FN: 40.1900\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0370 - Accuracy: 0.9874 - Precision: 0.9661 - Recall: 0.9617 - TP: 3242.8899 - TN: 5560.5498 - FP: 86.4500 - FN: 129.1100 - val_loss: 0.0938 - val_Accuracy: 0.9759 - val_Precision: 0.9586 - val_Recall: 0.9517 - val_TP: 765.1600 - val_TN: 1079.7800 - val_FP: 26.2200 - val_FN: 38.8400\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0368 - Accuracy: 0.9874 - Precision: 0.9655 - Recall: 0.9624 - TP: 3245.3101 - TN: 5557.8901 - FP: 89.1100 - FN: 126.6900 - val_loss: 0.0944 - val_Accuracy: 0.9759 - val_Precision: 0.9615 - val_Recall: 0.9499 - val_TP: 763.7400 - val_TN: 1082.3101 - val_FP: 23.6900 - val_FN: 40.2600\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0393 - Accuracy: 0.9877 - Precision: 0.9663 - Recall: 0.9629 - TP: 3246.8799 - TN: 5561.1001 - FP: 85.9000 - FN: 125.1200 - val_loss: 0.0932 - val_Accuracy: 0.9770 - val_Precision: 0.9600 - val_Recall: 0.9513 - val_TP: 764.8700 - val_TN: 1080.9301 - val_FP: 25.0700 - val_FN: 39.1300\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0422 - Accuracy: 0.9879 - Precision: 0.9654 - Recall: 0.9613 - TP: 3241.4800 - TN: 5557.5098 - FP: 89.4900 - FN: 130.5200 - val_loss: 0.0969 - val_Accuracy: 0.9764 - val_Precision: 0.9586 - val_Recall: 0.9510 - val_TP: 764.5900 - val_TN: 1079.8500 - val_FP: 26.1500 - val_FN: 39.4100\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0422 - Accuracy: 0.9874 - Precision: 0.9655 - Recall: 0.9628 - TP: 3246.5801 - TN: 5558.3701 - FP: 88.6300 - FN: 125.4200 - val_loss: 0.0939 - val_Accuracy: 0.9775 - val_Precision: 0.9651 - val_Recall: 0.9483 - val_TP: 762.4500 - val_TN: 1085.4600 - val_FP: 20.5400 - val_FN: 41.5500\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0359 - Accuracy: 0.9885 - Precision: 0.9673 - Recall: 0.9631 - TP: 3247.7300 - TN: 5564.7598 - FP: 82.2400 - FN: 124.2700 - val_loss: 0.0926 - val_Accuracy: 0.9775 - val_Precision: 0.9596 - val_Recall: 0.9526 - val_TP: 765.9000 - val_TN: 1080.5300 - val_FP: 25.4700 - val_FN: 38.1000\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0372 - Accuracy: 0.9878 - Precision: 0.9659 - Recall: 0.9629 - TP: 3246.8999 - TN: 5559.0698 - FP: 87.9300 - FN: 125.1000 - val_loss: 0.0950 - val_Accuracy: 0.9775 - val_Precision: 0.9644 - val_Recall: 0.9484 - val_TP: 762.5400 - val_TN: 1084.7700 - val_FP: 21.2300 - val_FN: 41.4600\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0390 - Accuracy: 0.9874 - Precision: 0.9661 - Recall: 0.9621 - TP: 3244.2300 - TN: 5560.0698 - FP: 86.9300 - FN: 127.7700 - val_loss: 0.0946 - val_Accuracy: 0.9754 - val_Precision: 0.9572 - val_Recall: 0.9515 - val_TP: 765.0000 - val_TN: 1078.4800 - val_FP: 27.5200 - val_FN: 39.0000\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0430 - Accuracy: 0.9871 - Precision: 0.9645 - Recall: 0.9616 - TP: 3242.5601 - TN: 5554.5200 - FP: 92.4800 - FN: 129.4400 - val_loss: 0.0912 - val_Accuracy: 0.9764 - val_Precision: 0.9646 - val_Recall: 0.9486 - val_TP: 762.6400 - val_TN: 1084.9500 - val_FP: 21.0500 - val_FN: 41.3600\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0640 - Accuracy: 0.9858 - Precision: 0.9636 - Recall: 0.9598 - TP: 3236.5000 - TN: 5551.8599 - FP: 95.1400 - FN: 135.5000 - val_loss: 0.0933 - val_Accuracy: 0.9754 - val_Precision: 0.9623 - val_Recall: 0.9483 - val_TP: 762.4100 - val_TN: 1082.9600 - val_FP: 23.0400 - val_FN: 41.5900\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0377 - Accuracy: 0.9874 - Precision: 0.9657 - Recall: 0.9621 - TP: 3244.1399 - TN: 5558.1899 - FP: 88.8100 - FN: 127.8600 - val_loss: 0.0931 - val_Accuracy: 0.9754 - val_Precision: 0.9636 - val_Recall: 0.9478 - val_TP: 762.0000 - val_TN: 1084.1801 - val_FP: 21.8200 - val_FN: 42.0000\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0366 - Accuracy: 0.9872 - Precision: 0.9659 - Recall: 0.9621 - TP: 3244.2400 - TN: 5559.4199 - FP: 87.5800 - FN: 127.7600 - val_loss: 0.0930 - val_Accuracy: 0.9754 - val_Precision: 0.9641 - val_Recall: 0.9480 - val_TP: 762.2000 - val_TN: 1084.5699 - val_FP: 21.4300 - val_FN: 41.8000\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0382 - Accuracy: 0.9871 - Precision: 0.9651 - Recall: 0.9615 - TP: 3242.0801 - TN: 5556.6602 - FP: 90.3400 - FN: 129.9200 - val_loss: 0.0987 - val_Accuracy: 0.9743 - val_Precision: 0.9576 - val_Recall: 0.9494 - val_TP: 763.3300 - val_TN: 1078.7900 - val_FP: 27.2100 - val_FN: 40.6700\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0380 - Accuracy: 0.9875 - Precision: 0.9656 - Recall: 0.9624 - TP: 3245.1799 - TN: 5558.2798 - FP: 88.7200 - FN: 126.8200 - val_loss: 0.0959 - val_Accuracy: 0.9759 - val_Precision: 0.9603 - val_Recall: 0.9495 - val_TP: 763.3700 - val_TN: 1081.3300 - val_FP: 24.6700 - val_FN: 40.6300\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0434 - Accuracy: 0.9866 - Precision: 0.9656 - Recall: 0.9610 - TP: 3240.3999 - TN: 5558.8599 - FP: 88.1400 - FN: 131.6000 - val_loss: 0.0915 - val_Accuracy: 0.9770 - val_Precision: 0.9633 - val_Recall: 0.9497 - val_TP: 763.5600 - val_TN: 1083.8400 - val_FP: 22.1600 - val_FN: 40.4400\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0350 - Accuracy: 0.9875 - Precision: 0.9655 - Recall: 0.9628 - TP: 3246.4700 - TN: 5557.9702 - FP: 89.0300 - FN: 125.5300 - val_loss: 0.0925 - val_Accuracy: 0.9770 - val_Precision: 0.9637 - val_Recall: 0.9490 - val_TP: 763.0300 - val_TN: 1084.1801 - val_FP: 21.8200 - val_FN: 40.9700\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0354 - Accuracy: 0.9877 - Precision: 0.9658 - Recall: 0.9626 - TP: 3245.9099 - TN: 5558.9302 - FP: 88.0700 - FN: 126.0900 - val_loss: 0.0985 - val_Accuracy: 0.9743 - val_Precision: 0.9639 - val_Recall: 0.9460 - val_TP: 760.6200 - val_TN: 1084.5400 - val_FP: 21.4600 - val_FN: 43.3800\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0366 - Accuracy: 0.9878 - Precision: 0.9668 - Recall: 0.9622 - TP: 3244.6399 - TN: 5563.0200 - FP: 83.9800 - FN: 127.3600 - val_loss: 0.0932 - val_Accuracy: 0.9775 - val_Precision: 0.9638 - val_Recall: 0.9489 - val_TP: 762.9000 - val_TN: 1084.2900 - val_FP: 21.7100 - val_FN: 41.1000\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0380 - Accuracy: 0.9870 - Precision: 0.9657 - Recall: 0.9624 - TP: 3245.2300 - TN: 5558.4702 - FP: 88.5300 - FN: 126.7700 - val_loss: 0.0938 - val_Accuracy: 0.9759 - val_Precision: 0.9598 - val_Recall: 0.9509 - val_TP: 764.5100 - val_TN: 1080.8199 - val_FP: 25.1800 - val_FN: 39.4900\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0353 - Accuracy: 0.9874 - Precision: 0.9658 - Recall: 0.9622 - TP: 3244.6899 - TN: 5558.9902 - FP: 88.0100 - FN: 127.3100 - val_loss: 0.0943 - val_Accuracy: 0.9775 - val_Precision: 0.9675 - val_Recall: 0.9465 - val_TP: 760.9500 - val_TN: 1087.5500 - val_FP: 18.4500 - val_FN: 43.0500\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0358 - Accuracy: 0.9882 - Precision: 0.9670 - Recall: 0.9629 - TP: 3247.0601 - TN: 5563.6001 - FP: 83.4000 - FN: 124.9400 - val_loss: 0.0938 - val_Accuracy: 0.9759 - val_Precision: 0.9576 - val_Recall: 0.9525 - val_TP: 765.8300 - val_TN: 1078.8500 - val_FP: 27.1500 - val_FN: 38.1700\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0477 - Accuracy: 0.9864 - Precision: 0.9639 - Recall: 0.9613 - TP: 3241.4399 - TN: 5552.6401 - FP: 94.3600 - FN: 130.5600 - val_loss: 0.0948 - val_Accuracy: 0.9770 - val_Precision: 0.9667 - val_Recall: 0.9466 - val_TP: 761.0400 - val_TN: 1086.8101 - val_FP: 19.1900 - val_FN: 42.9600\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0382 - Accuracy: 0.9882 - Precision: 0.9653 - Recall: 0.9624 - TP: 3245.3101 - TN: 5557.5298 - FP: 89.4700 - FN: 126.6900 - val_loss: 0.1013 - val_Accuracy: 0.9754 - val_Precision: 0.9628 - val_Recall: 0.9465 - val_TP: 760.9900 - val_TN: 1083.5800 - val_FP: 22.4200 - val_FN: 43.0100\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0353 - Accuracy: 0.9878 - Precision: 0.9669 - Recall: 0.9632 - TP: 3247.8301 - TN: 5563.1401 - FP: 83.8600 - FN: 124.1700 - val_loss: 0.0980 - val_Accuracy: 0.9754 - val_Precision: 0.9666 - val_Recall: 0.9450 - val_TP: 759.7800 - val_TN: 1086.8600 - val_FP: 19.1400 - val_FN: 44.2200\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0396 - Accuracy: 0.9871 - Precision: 0.9659 - Recall: 0.9622 - TP: 3244.6699 - TN: 5559.9199 - FP: 87.0800 - FN: 127.3300 - val_loss: 0.0954 - val_Accuracy: 0.9759 - val_Precision: 0.9650 - val_Recall: 0.9478 - val_TP: 762.0500 - val_TN: 1085.3101 - val_FP: 20.6900 - val_FN: 41.9500\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0390 - Accuracy: 0.9880 - Precision: 0.9657 - Recall: 0.9619 - TP: 3243.4299 - TN: 5558.8198 - FP: 88.1800 - FN: 128.5700 - val_loss: 0.0952 - val_Accuracy: 0.9770 - val_Precision: 0.9647 - val_Recall: 0.9484 - val_TP: 762.5400 - val_TN: 1085.0200 - val_FP: 20.9800 - val_FN: 41.4600\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0410 - Accuracy: 0.9870 - Precision: 0.9656 - Recall: 0.9621 - TP: 3244.0400 - TN: 5558.6401 - FP: 88.3600 - FN: 127.9600 - val_loss: 0.0946 - val_Accuracy: 0.9764 - val_Precision: 0.9644 - val_Recall: 0.9489 - val_TP: 762.9000 - val_TN: 1084.8300 - val_FP: 21.1700 - val_FN: 41.1000\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0430 - Accuracy: 0.9870 - Precision: 0.9655 - Recall: 0.9619 - TP: 3243.3701 - TN: 5558.3501 - FP: 88.6500 - FN: 128.6300 - val_loss: 0.0989 - val_Accuracy: 0.9743 - val_Precision: 0.9595 - val_Recall: 0.9502 - val_TP: 763.9800 - val_TN: 1080.6500 - val_FP: 25.3500 - val_FN: 40.0200\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0376 - Accuracy: 0.9876 - Precision: 0.9652 - Recall: 0.9623 - TP: 3245.0200 - TN: 5557.6499 - FP: 89.3500 - FN: 126.9800 - val_loss: 0.0957 - val_Accuracy: 0.9770 - val_Precision: 0.9670 - val_Recall: 0.9470 - val_TP: 761.3800 - val_TN: 1087.1500 - val_FP: 18.8500 - val_FN: 42.6200\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 4ms/step - loss: 0.0391 - Accuracy: 0.9872 - Precision: 0.9654 - Recall: 0.9619 - TP: 3243.5400 - TN: 5557.3901 - FP: 89.6100 - FN: 128.4600 - val_loss: 0.0929 - val_Accuracy: 0.9764 - val_Precision: 0.9663 - val_Recall: 0.9468 - val_TP: 761.2000 - val_TN: 1086.4399 - val_FP: 19.5600 - val_FN: 42.8000\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0389 - Accuracy: 0.9866 - Precision: 0.9657 - Recall: 0.9621 - TP: 3244.1799 - TN: 5558.7998 - FP: 88.2000 - FN: 127.8200 - val_loss: 0.0921 - val_Accuracy: 0.9775 - val_Precision: 0.9660 - val_Recall: 0.9475 - val_TP: 761.8000 - val_TN: 1086.2200 - val_FP: 19.7800 - val_FN: 42.2000\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0427 - Accuracy: 0.9869 - Precision: 0.9650 - Recall: 0.9609 - TP: 3239.9900 - TN: 5556.3901 - FP: 90.6100 - FN: 132.0100 - val_loss: 0.0945 - val_Accuracy: 0.9743 - val_Precision: 0.9626 - val_Recall: 0.9481 - val_TP: 762.2400 - val_TN: 1083.2800 - val_FP: 22.7200 - val_FN: 41.7600\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0387 - Accuracy: 0.9870 - Precision: 0.9656 - Recall: 0.9619 - TP: 3243.5100 - TN: 5558.3198 - FP: 88.6800 - FN: 128.4900 - val_loss: 0.0939 - val_Accuracy: 0.9754 - val_Precision: 0.9612 - val_Recall: 0.9492 - val_TP: 763.1400 - val_TN: 1082.1000 - val_FP: 23.9000 - val_FN: 40.8600\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0492 - Accuracy: 0.9866 - Precision: 0.9641 - Recall: 0.9609 - TP: 3240.2300 - TN: 5553.1099 - FP: 93.8900 - FN: 131.7700 - val_loss: 0.0938 - val_Accuracy: 0.9743 - val_Precision: 0.9622 - val_Recall: 0.9484 - val_TP: 762.5300 - val_TN: 1082.9399 - val_FP: 23.0600 - val_FN: 41.4700\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0368 - Accuracy: 0.9878 - Precision: 0.9661 - Recall: 0.9623 - TP: 3244.8301 - TN: 5560.1699 - FP: 86.8300 - FN: 127.1700 - val_loss: 0.0955 - val_Accuracy: 0.9754 - val_Precision: 0.9618 - val_Recall: 0.9490 - val_TP: 762.9700 - val_TN: 1082.6200 - val_FP: 23.3800 - val_FN: 41.0300\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0490 - Accuracy: 0.9864 - Precision: 0.9637 - Recall: 0.9600 - TP: 3237.0000 - TN: 5552.0200 - FP: 94.9800 - FN: 135.0000 - val_loss: 0.1035 - val_Accuracy: 0.9733 - val_Precision: 0.9566 - val_Recall: 0.9491 - val_TP: 763.0600 - val_TN: 1078.0400 - val_FP: 27.9600 - val_FN: 40.9400\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0370 - Accuracy: 0.9878 - Precision: 0.9659 - Recall: 0.9626 - TP: 3245.7900 - TN: 5559.4902 - FP: 87.5100 - FN: 126.2100 - val_loss: 0.0996 - val_Accuracy: 0.9749 - val_Precision: 0.9599 - val_Recall: 0.9487 - val_TP: 762.7200 - val_TN: 1081.0300 - val_FP: 24.9700 - val_FN: 41.2800\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0355 - Accuracy: 0.9879 - Precision: 0.9668 - Recall: 0.9637 - TP: 3249.5300 - TN: 5563.0601 - FP: 83.9400 - FN: 122.4700 - val_loss: 0.0973 - val_Accuracy: 0.9749 - val_Precision: 0.9626 - val_Recall: 0.9477 - val_TP: 761.9500 - val_TN: 1083.3500 - val_FP: 22.6500 - val_FN: 42.0500\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0455 - Accuracy: 0.9867 - Precision: 0.9651 - Recall: 0.9616 - TP: 3242.6399 - TN: 5556.7002 - FP: 90.3000 - FN: 129.3600 - val_loss: 0.0938 - val_Accuracy: 0.9764 - val_Precision: 0.9656 - val_Recall: 0.9476 - val_TP: 761.8600 - val_TN: 1085.8199 - val_FP: 20.1800 - val_FN: 42.1400\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0356 - Accuracy: 0.9884 - Precision: 0.9667 - Recall: 0.9628 - TP: 3246.5200 - TN: 5562.2598 - FP: 84.7400 - FN: 125.4800 - val_loss: 0.0925 - val_Accuracy: 0.9770 - val_Precision: 0.9636 - val_Recall: 0.9497 - val_TP: 763.5700 - val_TN: 1084.0699 - val_FP: 21.9300 - val_FN: 40.4300\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0374 - Accuracy: 0.9872 - Precision: 0.9662 - Recall: 0.9623 - TP: 3244.7700 - TN: 5560.5400 - FP: 86.4600 - FN: 127.2300 - val_loss: 0.0931 - val_Accuracy: 0.9759 - val_Precision: 0.9623 - val_Recall: 0.9499 - val_TP: 763.6800 - val_TN: 1082.9700 - val_FP: 23.0300 - val_FN: 40.3200\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0437 - Accuracy: 0.9865 - Precision: 0.9649 - Recall: 0.9619 - TP: 3243.4199 - TN: 5556.2500 - FP: 90.7500 - FN: 128.5800 - val_loss: 0.0939 - val_Accuracy: 0.9780 - val_Precision: 0.9662 - val_Recall: 0.9476 - val_TP: 761.8500 - val_TN: 1086.3400 - val_FP: 19.6600 - val_FN: 42.1500\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0400 - Accuracy: 0.9870 - Precision: 0.9659 - Recall: 0.9620 - TP: 3244.0200 - TN: 5559.8101 - FP: 87.1900 - FN: 127.9800 - val_loss: 0.0949 - val_Accuracy: 0.9759 - val_Precision: 0.9614 - val_Recall: 0.9499 - val_TP: 763.6900 - val_TN: 1082.1899 - val_FP: 23.8100 - val_FN: 40.3100\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0364 - Accuracy: 0.9881 - Precision: 0.9659 - Recall: 0.9630 - TP: 3247.1201 - TN: 5559.4102 - FP: 87.5900 - FN: 124.8800 - val_loss: 0.0995 - val_Accuracy: 0.9749 - val_Precision: 0.9613 - val_Recall: 0.9483 - val_TP: 762.4000 - val_TN: 1082.2400 - val_FP: 23.7600 - val_FN: 41.6000\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0364 - Accuracy: 0.9875 - Precision: 0.9667 - Recall: 0.9627 - TP: 3246.1799 - TN: 5562.5298 - FP: 84.4700 - FN: 125.8200 - val_loss: 0.0958 - val_Accuracy: 0.9743 - val_Precision: 0.9605 - val_Recall: 0.9503 - val_TP: 764.0100 - val_TN: 1081.4700 - val_FP: 24.5300 - val_FN: 39.9900\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0407 - Accuracy: 0.9865 - Precision: 0.9649 - Recall: 0.9617 - TP: 3242.8799 - TN: 5556.0400 - FP: 90.9600 - FN: 129.1200 - val_loss: 0.0945 - val_Accuracy: 0.9770 - val_Precision: 0.9642 - val_Recall: 0.9486 - val_TP: 762.7000 - val_TN: 1084.6100 - val_FP: 21.3900 - val_FN: 41.3000\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0387 - Accuracy: 0.9871 - Precision: 0.9653 - Recall: 0.9621 - TP: 3244.0400 - TN: 5557.2798 - FP: 89.7200 - FN: 127.9600 - val_loss: 0.1005 - val_Accuracy: 0.9759 - val_Precision: 0.9654 - val_Recall: 0.9454 - val_TP: 760.0700 - val_TN: 1085.8400 - val_FP: 20.1600 - val_FN: 43.9300\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0391 - Accuracy: 0.9878 - Precision: 0.9661 - Recall: 0.9631 - TP: 3247.5701 - TN: 5560.3901 - FP: 86.6100 - FN: 124.4300 - val_loss: 0.0977 - val_Accuracy: 0.9754 - val_Precision: 0.9650 - val_Recall: 0.9466 - val_TP: 761.0800 - val_TN: 1085.4700 - val_FP: 20.5300 - val_FN: 42.9200\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0350 - Accuracy: 0.9877 - Precision: 0.9667 - Recall: 0.9629 - TP: 3246.9900 - TN: 5562.5000 - FP: 84.5000 - FN: 125.0100 - val_loss: 0.1003 - val_Accuracy: 0.9754 - val_Precision: 0.9595 - val_Recall: 0.9502 - val_TP: 763.9800 - val_TN: 1080.6000 - val_FP: 25.4000 - val_FN: 40.0200\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0378 - Accuracy: 0.9875 - Precision: 0.9664 - Recall: 0.9625 - TP: 3245.6399 - TN: 5561.8901 - FP: 85.1100 - FN: 126.3600 - val_loss: 0.0961 - val_Accuracy: 0.9754 - val_Precision: 0.9605 - val_Recall: 0.9503 - val_TP: 764.0600 - val_TN: 1081.4800 - val_FP: 24.5200 - val_FN: 39.9400\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0361 - Accuracy: 0.9880 - Precision: 0.9661 - Recall: 0.9630 - TP: 3247.2000 - TN: 5560.0698 - FP: 86.9300 - FN: 124.8000 - val_loss: 0.0976 - val_Accuracy: 0.9749 - val_Precision: 0.9636 - val_Recall: 0.9476 - val_TP: 761.8400 - val_TN: 1084.2300 - val_FP: 21.7700 - val_FN: 42.1600\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0413 - Accuracy: 0.9869 - Precision: 0.9658 - Recall: 0.9616 - TP: 3242.4900 - TN: 5559.5298 - FP: 87.4700 - FN: 129.5100 - val_loss: 0.0921 - val_Accuracy: 0.9759 - val_Precision: 0.9575 - val_Recall: 0.9530 - val_TP: 766.2000 - val_TN: 1078.7400 - val_FP: 27.2600 - val_FN: 37.8000\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0375 - Accuracy: 0.9869 - Precision: 0.9654 - Recall: 0.9623 - TP: 3244.8401 - TN: 5557.9199 - FP: 89.0800 - FN: 127.1600 - val_loss: 0.0923 - val_Accuracy: 0.9770 - val_Precision: 0.9625 - val_Recall: 0.9498 - val_TP: 763.6300 - val_TN: 1083.1899 - val_FP: 22.8100 - val_FN: 40.3700\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0389 - Accuracy: 0.9871 - Precision: 0.9660 - Recall: 0.9615 - TP: 3242.2600 - TN: 5559.8999 - FP: 87.1000 - FN: 129.7400 - val_loss: 0.0941 - val_Accuracy: 0.9754 - val_Precision: 0.9556 - val_Recall: 0.9529 - val_TP: 766.1300 - val_TN: 1077.0200 - val_FP: 28.9800 - val_FN: 37.8700\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0464 - Accuracy: 0.9865 - Precision: 0.9641 - Recall: 0.9610 - TP: 3240.3401 - TN: 5552.9199 - FP: 94.0800 - FN: 131.6600 - val_loss: 0.0926 - val_Accuracy: 0.9764 - val_Precision: 0.9599 - val_Recall: 0.9510 - val_TP: 764.5800 - val_TN: 1080.7700 - val_FP: 25.2300 - val_FN: 39.4200\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0378 - Accuracy: 0.9874 - Precision: 0.9658 - Recall: 0.9622 - TP: 3244.6699 - TN: 5558.9902 - FP: 88.0100 - FN: 127.3300 - val_loss: 0.0917 - val_Accuracy: 0.9770 - val_Precision: 0.9628 - val_Recall: 0.9501 - val_TP: 763.9200 - val_TN: 1083.4100 - val_FP: 22.5900 - val_FN: 40.0800\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0488 - Accuracy: 0.9871 - Precision: 0.9642 - Recall: 0.9620 - TP: 3243.7000 - TN: 5553.8999 - FP: 93.1000 - FN: 128.3000 - val_loss: 0.0942 - val_Accuracy: 0.9764 - val_Precision: 0.9668 - val_Recall: 0.9463 - val_TP: 760.8600 - val_TN: 1086.9500 - val_FP: 19.0500 - val_FN: 43.1400\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0384 - Accuracy: 0.9876 - Precision: 0.9664 - Recall: 0.9622 - TP: 3244.3899 - TN: 5561.7598 - FP: 85.2400 - FN: 127.6100 - val_loss: 0.0929 - val_Accuracy: 0.9770 - val_Precision: 0.9593 - val_Recall: 0.9518 - val_TP: 765.2500 - val_TN: 1080.3700 - val_FP: 25.6300 - val_FN: 38.7500\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0420 - Accuracy: 0.9879 - Precision: 0.9658 - Recall: 0.9629 - TP: 3247.0000 - TN: 5559.2598 - FP: 87.7400 - FN: 125.0000 - val_loss: 0.0966 - val_Accuracy: 0.9764 - val_Precision: 0.9599 - val_Recall: 0.9498 - val_TP: 763.6100 - val_TN: 1080.9800 - val_FP: 25.0200 - val_FN: 40.3900\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0397 - Accuracy: 0.9879 - Precision: 0.9660 - Recall: 0.9628 - TP: 3246.3999 - TN: 5559.9199 - FP: 87.0800 - FN: 125.6000 - val_loss: 0.0954 - val_Accuracy: 0.9749 - val_Precision: 0.9621 - val_Recall: 0.9488 - val_TP: 762.8400 - val_TN: 1082.8500 - val_FP: 23.1500 - val_FN: 41.1600\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0376 - Accuracy: 0.9876 - Precision: 0.9657 - Recall: 0.9624 - TP: 3245.1101 - TN: 5559.0698 - FP: 87.9300 - FN: 126.8900 - val_loss: 0.0964 - val_Accuracy: 0.9749 - val_Precision: 0.9646 - val_Recall: 0.9470 - val_TP: 761.3600 - val_TN: 1085.0800 - val_FP: 20.9200 - val_FN: 42.6400\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0408 - Accuracy: 0.9864 - Precision: 0.9654 - Recall: 0.9618 - TP: 3243.1499 - TN: 5558.0801 - FP: 88.9200 - FN: 128.8500 - val_loss: 0.1000 - val_Accuracy: 0.9749 - val_Precision: 0.9619 - val_Recall: 0.9472 - val_TP: 761.5200 - val_TN: 1082.7600 - val_FP: 23.2400 - val_FN: 42.4800\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0347 - Accuracy: 0.9884 - Precision: 0.9667 - Recall: 0.9627 - TP: 3246.2800 - TN: 5562.5601 - FP: 84.4400 - FN: 125.7200 - val_loss: 0.0977 - val_Accuracy: 0.9749 - val_Precision: 0.9599 - val_Recall: 0.9504 - val_TP: 764.1100 - val_TN: 1080.9600 - val_FP: 25.0400 - val_FN: 39.8900\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0448 - Accuracy: 0.9864 - Precision: 0.9654 - Recall: 0.9622 - TP: 3244.7000 - TN: 5558.2598 - FP: 88.7400 - FN: 127.3000 - val_loss: 0.0972 - val_Accuracy: 0.9749 - val_Precision: 0.9621 - val_Recall: 0.9486 - val_TP: 762.7100 - val_TN: 1082.9200 - val_FP: 23.0800 - val_FN: 41.2900\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0360 - Accuracy: 0.9886 - Precision: 0.9661 - Recall: 0.9639 - TP: 3250.2400 - TN: 5560.4800 - FP: 86.5200 - FN: 121.7600 - val_loss: 0.0958 - val_Accuracy: 0.9770 - val_Precision: 0.9660 - val_Recall: 0.9471 - val_TP: 761.4400 - val_TN: 1086.2100 - val_FP: 19.7900 - val_FN: 42.5600\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0463 - Accuracy: 0.9877 - Precision: 0.9664 - Recall: 0.9618 - TP: 3243.2000 - TN: 5561.6899 - FP: 85.3100 - FN: 128.8000 - val_loss: 0.0943 - val_Accuracy: 0.9764 - val_Precision: 0.9591 - val_Recall: 0.9519 - val_TP: 765.3200 - val_TN: 1080.1600 - val_FP: 25.8400 - val_FN: 38.6800\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0375 - Accuracy: 0.9874 - Precision: 0.9661 - Recall: 0.9630 - TP: 3247.2000 - TN: 5559.8198 - FP: 87.1800 - FN: 124.8000 - val_loss: 0.1023 - val_Accuracy: 0.9743 - val_Precision: 0.9594 - val_Recall: 0.9491 - val_TP: 763.0900 - val_TN: 1080.5601 - val_FP: 25.4400 - val_FN: 40.9100\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0344 - Accuracy: 0.9876 - Precision: 0.9667 - Recall: 0.9638 - TP: 3249.8000 - TN: 5562.5498 - FP: 84.4500 - FN: 122.2000 - val_loss: 0.1002 - val_Accuracy: 0.9754 - val_Precision: 0.9619 - val_Recall: 0.9475 - val_TP: 761.8200 - val_TN: 1082.8000 - val_FP: 23.2000 - val_FN: 42.1800\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0488 - Accuracy: 0.9879 - Precision: 0.9661 - Recall: 0.9620 - TP: 3243.8899 - TN: 5560.6899 - FP: 86.3100 - FN: 128.1100 - val_loss: 0.1059 - val_Accuracy: 0.9733 - val_Precision: 0.9565 - val_Recall: 0.9493 - val_TP: 763.2400 - val_TN: 1078.0100 - val_FP: 27.9900 - val_FN: 40.7600\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0466 - Accuracy: 0.9871 - Precision: 0.9652 - Recall: 0.9628 - TP: 3246.6599 - TN: 5557.5000 - FP: 89.5000 - FN: 125.3400 - val_loss: 0.1014 - val_Accuracy: 0.9743 - val_Precision: 0.9623 - val_Recall: 0.9473 - val_TP: 761.6200 - val_TN: 1083.1500 - val_FP: 22.8500 - val_FN: 42.3800\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0387 - Accuracy: 0.9878 - Precision: 0.9670 - Recall: 0.9623 - TP: 3245.0300 - TN: 5563.7100 - FP: 83.2900 - FN: 126.9700 - val_loss: 0.1015 - val_Accuracy: 0.9749 - val_Precision: 0.9576 - val_Recall: 0.9509 - val_TP: 764.5000 - val_TN: 1078.9800 - val_FP: 27.0200 - val_FN: 39.5000\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0417 - Accuracy: 0.9874 - Precision: 0.9659 - Recall: 0.9628 - TP: 3246.6499 - TN: 5560.0601 - FP: 86.9400 - FN: 125.3500 - val_loss: 0.0993 - val_Accuracy: 0.9759 - val_Precision: 0.9580 - val_Recall: 0.9514 - val_TP: 764.9600 - val_TN: 1079.3101 - val_FP: 26.6900 - val_FN: 39.0400\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0440 - Accuracy: 0.9868 - Precision: 0.9658 - Recall: 0.9618 - TP: 3243.0500 - TN: 5559.4102 - FP: 87.5900 - FN: 128.9500 - val_loss: 0.1039 - val_Accuracy: 0.9759 - val_Precision: 0.9515 - val_Recall: 0.9537 - val_TP: 766.7500 - val_TN: 1073.4700 - val_FP: 32.5300 - val_FN: 37.2500\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0375 - Accuracy: 0.9869 - Precision: 0.9654 - Recall: 0.9634 - TP: 3248.6299 - TN: 5557.6401 - FP: 89.3600 - FN: 123.3700 - val_loss: 0.0988 - val_Accuracy: 0.9754 - val_Precision: 0.9632 - val_Recall: 0.9478 - val_TP: 762.0700 - val_TN: 1083.8800 - val_FP: 22.1200 - val_FN: 41.9300\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0390 - Accuracy: 0.9876 - Precision: 0.9660 - Recall: 0.9628 - TP: 3246.5100 - TN: 5560.2798 - FP: 86.7200 - FN: 125.4900 - val_loss: 0.1006 - val_Accuracy: 0.9754 - val_Precision: 0.9588 - val_Recall: 0.9502 - val_TP: 764.0000 - val_TN: 1080.0200 - val_FP: 25.9800 - val_FN: 40.0000\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0438 - Accuracy: 0.9869 - Precision: 0.9674 - Recall: 0.9619 - TP: 3243.5200 - TN: 5565.3701 - FP: 81.6300 - FN: 128.4800 - val_loss: 0.1121 - val_Accuracy: 0.9743 - val_Precision: 0.9466 - val_Recall: 0.9534 - val_TP: 766.5000 - val_TN: 1068.6300 - val_FP: 37.3700 - val_FN: 37.5000\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 8ms/step - loss: 0.0453 - Accuracy: 0.9864 - Precision: 0.9650 - Recall: 0.9611 - TP: 3240.9199 - TN: 5556.7500 - FP: 90.2500 - FN: 131.0800 - val_loss: 0.0927 - val_Accuracy: 0.9754 - val_Precision: 0.9630 - val_Recall: 0.9493 - val_TP: 763.2300 - val_TN: 1083.5500 - val_FP: 22.4500 - val_FN: 40.7700\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0358 - Accuracy: 0.9885 - Precision: 0.9659 - Recall: 0.9629 - TP: 3247.0200 - TN: 5559.1699 - FP: 87.8300 - FN: 124.9800 - val_loss: 0.0969 - val_Accuracy: 0.9754 - val_Precision: 0.9617 - val_Recall: 0.9485 - val_TP: 762.6300 - val_TN: 1082.5699 - val_FP: 23.4300 - val_FN: 41.3700\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1408s 5s/step - loss: 0.0373 - Accuracy: 0.9876 - Precision: 0.9664 - Recall: 0.9620 - TP: 3243.7700 - TN: 5561.4199 - FP: 85.5800 - FN: 128.2300 - val_loss: 0.0922 - val_Accuracy: 0.9775 - val_Precision: 0.9578 - val_Recall: 0.9529 - val_TP: 766.1500 - val_TN: 1078.9500 - val_FP: 27.0500 - val_FN: 37.8500\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 2s 9ms/step - loss: 0.0395 - Accuracy: 0.9874 - Precision: 0.9658 - Recall: 0.9625 - TP: 3245.6799 - TN: 5559.0898 - FP: 87.9100 - FN: 126.3200 - val_loss: 0.0923 - val_Accuracy: 0.9775 - val_Precision: 0.9602 - val_Recall: 0.9520 - val_TP: 765.4200 - val_TN: 1081.1100 - val_FP: 24.8900 - val_FN: 38.5800\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0611 - Accuracy: 0.9848 - Precision: 0.9634 - Recall: 0.9603 - TP: 3238.2800 - TN: 5551.5601 - FP: 95.4400 - FN: 133.7200 - val_loss: 0.0932 - val_Accuracy: 0.9759 - val_Precision: 0.9647 - val_Recall: 0.9489 - val_TP: 762.9100 - val_TN: 1085.0800 - val_FP: 20.9200 - val_FN: 41.0900\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0466 - Accuracy: 0.9877 - Precision: 0.9661 - Recall: 0.9621 - TP: 3244.3101 - TN: 5560.4399 - FP: 86.5600 - FN: 127.6900 - val_loss: 0.0941 - val_Accuracy: 0.9759 - val_Precision: 0.9625 - val_Recall: 0.9498 - val_TP: 763.6400 - val_TN: 1083.1500 - val_FP: 22.8500 - val_FN: 40.3600\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0362 - Accuracy: 0.9880 - Precision: 0.9662 - Recall: 0.9640 - TP: 3250.4900 - TN: 5560.5400 - FP: 86.4600 - FN: 121.5100 - val_loss: 0.0947 - val_Accuracy: 0.9770 - val_Precision: 0.9651 - val_Recall: 0.9479 - val_TP: 762.1300 - val_TN: 1085.4500 - val_FP: 20.5500 - val_FN: 41.8700\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0433 - Accuracy: 0.9870 - Precision: 0.9661 - Recall: 0.9617 - TP: 3242.8899 - TN: 5560.3301 - FP: 86.6700 - FN: 129.1100 - val_loss: 0.0939 - val_Accuracy: 0.9764 - val_Precision: 0.9622 - val_Recall: 0.9505 - val_TP: 764.2000 - val_TN: 1082.8800 - val_FP: 23.1200 - val_FN: 39.8000\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0398 - Accuracy: 0.9871 - Precision: 0.9655 - Recall: 0.9629 - TP: 3246.9199 - TN: 5558.4600 - FP: 88.5400 - FN: 125.0800 - val_loss: 0.0951 - val_Accuracy: 0.9770 - val_Precision: 0.9669 - val_Recall: 0.9467 - val_TP: 761.1700 - val_TN: 1087.0100 - val_FP: 18.9900 - val_FN: 42.8300\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0387 - Accuracy: 0.9871 - Precision: 0.9661 - Recall: 0.9624 - TP: 3245.1699 - TN: 5560.6401 - FP: 86.3600 - FN: 126.8300 - val_loss: 0.0957 - val_Accuracy: 0.9749 - val_Precision: 0.9600 - val_Recall: 0.9508 - val_TP: 764.4300 - val_TN: 1081.0200 - val_FP: 24.9800 - val_FN: 39.5700\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0363 - Accuracy: 0.9878 - Precision: 0.9662 - Recall: 0.9630 - TP: 3247.3501 - TN: 5560.6401 - FP: 86.3600 - FN: 124.6500 - val_loss: 0.0978 - val_Accuracy: 0.9749 - val_Precision: 0.9635 - val_Recall: 0.9474 - val_TP: 761.7200 - val_TN: 1084.1600 - val_FP: 21.8400 - val_FN: 42.2800\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0389 - Accuracy: 0.9874 - Precision: 0.9665 - Recall: 0.9629 - TP: 3247.0500 - TN: 5561.7598 - FP: 85.2400 - FN: 124.9500 - val_loss: 0.0995 - val_Accuracy: 0.9749 - val_Precision: 0.9656 - val_Recall: 0.9453 - val_TP: 760.0500 - val_TN: 1086.0601 - val_FP: 19.9400 - val_FN: 43.9500\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0497 - Accuracy: 0.9872 - Precision: 0.9662 - Recall: 0.9623 - TP: 3245.0400 - TN: 5561.1602 - FP: 85.8400 - FN: 126.9600 - val_loss: 0.0992 - val_Accuracy: 0.9749 - val_Precision: 0.9599 - val_Recall: 0.9498 - val_TP: 763.6400 - val_TN: 1081.0400 - val_FP: 24.9600 - val_FN: 40.3600\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0369 - Accuracy: 0.9876 - Precision: 0.9663 - Recall: 0.9634 - TP: 3248.6799 - TN: 5561.3301 - FP: 85.6700 - FN: 123.3200 - val_loss: 0.0959 - val_Accuracy: 0.9764 - val_Precision: 0.9626 - val_Recall: 0.9497 - val_TP: 763.5500 - val_TN: 1083.2100 - val_FP: 22.7900 - val_FN: 40.4500\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0370 - Accuracy: 0.9879 - Precision: 0.9663 - Recall: 0.9632 - TP: 3247.8799 - TN: 5561.0298 - FP: 85.9700 - FN: 124.1200 - val_loss: 0.1000 - val_Accuracy: 0.9754 - val_Precision: 0.9654 - val_Recall: 0.9457 - val_TP: 760.3300 - val_TN: 1085.8000 - val_FP: 20.2000 - val_FN: 43.6700\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0422 - Accuracy: 0.9877 - Precision: 0.9669 - Recall: 0.9623 - TP: 3244.9399 - TN: 5563.4800 - FP: 83.5200 - FN: 127.0600 - val_loss: 0.0976 - val_Accuracy: 0.9754 - val_Precision: 0.9599 - val_Recall: 0.9504 - val_TP: 764.1600 - val_TN: 1080.9800 - val_FP: 25.0200 - val_FN: 39.8400\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0487 - Accuracy: 0.9863 - Precision: 0.9644 - Recall: 0.9626 - TP: 3245.7200 - TN: 5554.6899 - FP: 92.3100 - FN: 126.2800 - val_loss: 0.0975 - val_Accuracy: 0.9759 - val_Precision: 0.9644 - val_Recall: 0.9480 - val_TP: 762.1700 - val_TN: 1084.8800 - val_FP: 21.1200 - val_FN: 41.8300\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0419 - Accuracy: 0.9872 - Precision: 0.9664 - Recall: 0.9627 - TP: 3246.1499 - TN: 5561.7700 - FP: 85.2300 - FN: 125.8500 - val_loss: 0.1009 - val_Accuracy: 0.9754 - val_Precision: 0.9609 - val_Recall: 0.9492 - val_TP: 763.1200 - val_TN: 1081.9000 - val_FP: 24.1000 - val_FN: 40.8800\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0393 - Accuracy: 0.9877 - Precision: 0.9662 - Recall: 0.9628 - TP: 3246.4500 - TN: 5561.1499 - FP: 85.8500 - FN: 125.5500 - val_loss: 0.0976 - val_Accuracy: 0.9754 - val_Precision: 0.9616 - val_Recall: 0.9497 - val_TP: 763.5200 - val_TN: 1082.4900 - val_FP: 23.5100 - val_FN: 40.4800\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0346 - Accuracy: 0.9872 - Precision: 0.9667 - Recall: 0.9637 - TP: 3249.5701 - TN: 5562.9199 - FP: 84.0800 - FN: 122.4300 - val_loss: 0.1004 - val_Accuracy: 0.9759 - val_Precision: 0.9615 - val_Recall: 0.9490 - val_TP: 763.0100 - val_TN: 1082.4200 - val_FP: 23.5800 - val_FN: 40.9900\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0426 - Accuracy: 0.9872 - Precision: 0.9666 - Recall: 0.9624 - TP: 3245.3501 - TN: 5562.5801 - FP: 84.4200 - FN: 126.6500 - val_loss: 0.0984 - val_Accuracy: 0.9754 - val_Precision: 0.9617 - val_Recall: 0.9495 - val_TP: 763.3800 - val_TN: 1082.6100 - val_FP: 23.3900 - val_FN: 40.6200\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0449 - Accuracy: 0.9875 - Precision: 0.9652 - Recall: 0.9634 - TP: 3248.4700 - TN: 5557.1401 - FP: 89.8600 - FN: 123.5300 - val_loss: 0.0981 - val_Accuracy: 0.9764 - val_Precision: 0.9671 - val_Recall: 0.9465 - val_TP: 760.9500 - val_TN: 1087.2200 - val_FP: 18.7800 - val_FN: 43.0500\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0361 - Accuracy: 0.9876 - Precision: 0.9670 - Recall: 0.9633 - TP: 3248.1699 - TN: 5563.4702 - FP: 83.5300 - FN: 123.8300 - val_loss: 0.1041 - val_Accuracy: 0.9754 - val_Precision: 0.9602 - val_Recall: 0.9488 - val_TP: 762.8100 - val_TN: 1081.3000 - val_FP: 24.7000 - val_FN: 41.1900\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 4ms/step - loss: 0.0431 - Accuracy: 0.9864 - Precision: 0.9651 - Recall: 0.9616 - TP: 3242.3501 - TN: 5557.0200 - FP: 89.9800 - FN: 129.6500 - val_loss: 0.0925 - val_Accuracy: 0.9770 - val_Precision: 0.9635 - val_Recall: 0.9499 - val_TP: 763.7400 - val_TN: 1084.0000 - val_FP: 22.0000 - val_FN: 40.2600\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0473 - Accuracy: 0.9865 - Precision: 0.9651 - Recall: 0.9616 - TP: 3242.4900 - TN: 5556.7100 - FP: 90.2900 - FN: 129.5100 - val_loss: 0.0975 - val_Accuracy: 0.9749 - val_Precision: 0.9600 - val_Recall: 0.9491 - val_TP: 763.1000 - val_TN: 1081.1000 - val_FP: 24.9000 - val_FN: 40.9000\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0392 - Accuracy: 0.9872 - Precision: 0.9664 - Recall: 0.9621 - TP: 3244.3301 - TN: 5561.6602 - FP: 85.3400 - FN: 127.6700 - val_loss: 0.0936 - val_Accuracy: 0.9770 - val_Precision: 0.9575 - val_Recall: 0.9532 - val_TP: 766.4000 - val_TN: 1078.7200 - val_FP: 27.2800 - val_FN: 37.6000\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0526 - Accuracy: 0.9865 - Precision: 0.9637 - Recall: 0.9619 - TP: 3243.6201 - TN: 5551.7300 - FP: 95.2700 - FN: 128.3800 - val_loss: 0.0945 - val_Accuracy: 0.9764 - val_Precision: 0.9671 - val_Recall: 0.9465 - val_TP: 761.0000 - val_TN: 1087.1500 - val_FP: 18.8500 - val_FN: 43.0000\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0388 - Accuracy: 0.9877 - Precision: 0.9663 - Recall: 0.9623 - TP: 3244.8601 - TN: 5561.3398 - FP: 85.6600 - FN: 127.1400 - val_loss: 0.0971 - val_Accuracy: 0.9749 - val_Precision: 0.9634 - val_Recall: 0.9476 - val_TP: 761.8800 - val_TN: 1084.0900 - val_FP: 21.9100 - val_FN: 42.1200\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0395 - Accuracy: 0.9874 - Precision: 0.9660 - Recall: 0.9627 - TP: 3246.3401 - TN: 5560.2700 - FP: 86.7300 - FN: 125.6600 - val_loss: 0.0947 - val_Accuracy: 0.9759 - val_Precision: 0.9654 - val_Recall: 0.9478 - val_TP: 762.0200 - val_TN: 1085.6899 - val_FP: 20.3100 - val_FN: 41.9800\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0400 - Accuracy: 0.9869 - Precision: 0.9650 - Recall: 0.9616 - TP: 3242.6001 - TN: 5556.3501 - FP: 90.6500 - FN: 129.4000 - val_loss: 0.0974 - val_Accuracy: 0.9749 - val_Precision: 0.9623 - val_Recall: 0.9487 - val_TP: 762.7800 - val_TN: 1083.1200 - val_FP: 22.8800 - val_FN: 41.2200\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0360 - Accuracy: 0.9889 - Precision: 0.9665 - Recall: 0.9630 - TP: 3247.1599 - TN: 5561.8799 - FP: 85.1200 - FN: 124.8400 - val_loss: 0.0953 - val_Accuracy: 0.9770 - val_Precision: 0.9646 - val_Recall: 0.9485 - val_TP: 762.5700 - val_TN: 1085.0300 - val_FP: 20.9700 - val_FN: 41.4300\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0359 - Accuracy: 0.9872 - Precision: 0.9661 - Recall: 0.9628 - TP: 3246.6799 - TN: 5560.6201 - FP: 86.3800 - FN: 125.3200 - val_loss: 0.0965 - val_Accuracy: 0.9764 - val_Precision: 0.9602 - val_Recall: 0.9505 - val_TP: 764.1800 - val_TN: 1081.2000 - val_FP: 24.8000 - val_FN: 39.8200\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0420 - Accuracy: 0.9869 - Precision: 0.9654 - Recall: 0.9618 - TP: 3243.2600 - TN: 5557.9800 - FP: 89.0200 - FN: 128.7400 - val_loss: 0.0956 - val_Accuracy: 0.9754 - val_Precision: 0.9618 - val_Recall: 0.9500 - val_TP: 763.7600 - val_TN: 1082.5699 - val_FP: 23.4300 - val_FN: 40.2400\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0360 - Accuracy: 0.9875 - Precision: 0.9663 - Recall: 0.9625 - TP: 3245.4299 - TN: 5561.2998 - FP: 85.7000 - FN: 126.5700 - val_loss: 0.0945 - val_Accuracy: 0.9780 - val_Precision: 0.9629 - val_Recall: 0.9502 - val_TP: 763.9700 - val_TN: 1083.5200 - val_FP: 22.4800 - val_FN: 40.0300\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0372 - Accuracy: 0.9872 - Precision: 0.9654 - Recall: 0.9627 - TP: 3246.1699 - TN: 5558.0698 - FP: 88.9300 - FN: 125.8300 - val_loss: 0.0984 - val_Accuracy: 0.9754 - val_Precision: 0.9607 - val_Recall: 0.9498 - val_TP: 763.6700 - val_TN: 1081.7000 - val_FP: 24.3000 - val_FN: 40.3300\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0345 - Accuracy: 0.9876 - Precision: 0.9670 - Recall: 0.9630 - TP: 3247.2600 - TN: 5563.8701 - FP: 83.1300 - FN: 124.7400 - val_loss: 0.0987 - val_Accuracy: 0.9759 - val_Precision: 0.9598 - val_Recall: 0.9508 - val_TP: 764.4400 - val_TN: 1080.9100 - val_FP: 25.0900 - val_FN: 39.5600\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0386 - Accuracy: 0.9869 - Precision: 0.9662 - Recall: 0.9633 - TP: 3248.1299 - TN: 5561.0098 - FP: 85.9900 - FN: 123.8700 - val_loss: 0.0984 - val_Accuracy: 0.9764 - val_Precision: 0.9609 - val_Recall: 0.9499 - val_TP: 763.7100 - val_TN: 1081.9100 - val_FP: 24.0900 - val_FN: 40.2900\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0375 - Accuracy: 0.9875 - Precision: 0.9666 - Recall: 0.9634 - TP: 3248.7400 - TN: 5562.3398 - FP: 84.6600 - FN: 123.2600 - val_loss: 0.1002 - val_Accuracy: 0.9770 - val_Precision: 0.9569 - val_Recall: 0.9524 - val_TP: 765.7200 - val_TN: 1078.3400 - val_FP: 27.6600 - val_FN: 38.2800\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0423 - Accuracy: 0.9875 - Precision: 0.9658 - Recall: 0.9625 - TP: 3245.5701 - TN: 5559.1099 - FP: 87.8900 - FN: 126.4300 - val_loss: 0.0987 - val_Accuracy: 0.9759 - val_Precision: 0.9594 - val_Recall: 0.9513 - val_TP: 764.8300 - val_TN: 1080.6100 - val_FP: 25.3900 - val_FN: 39.1700\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0365 - Accuracy: 0.9880 - Precision: 0.9670 - Recall: 0.9636 - TP: 3249.2800 - TN: 5563.7798 - FP: 83.2200 - FN: 122.7200 - val_loss: 0.0969 - val_Accuracy: 0.9770 - val_Precision: 0.9629 - val_Recall: 0.9502 - val_TP: 763.9400 - val_TN: 1083.5699 - val_FP: 22.4300 - val_FN: 40.0600\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0398 - Accuracy: 0.9881 - Precision: 0.9667 - Recall: 0.9640 - TP: 3250.6799 - TN: 5562.8398 - FP: 84.1600 - FN: 121.3200 - val_loss: 0.0983 - val_Accuracy: 0.9749 - val_Precision: 0.9618 - val_Recall: 0.9500 - val_TP: 763.7800 - val_TN: 1082.6801 - val_FP: 23.3200 - val_FN: 40.2200\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0586 - Accuracy: 0.9869 - Precision: 0.9655 - Recall: 0.9616 - TP: 3242.4800 - TN: 5559.0601 - FP: 87.9400 - FN: 129.5200 - val_loss: 0.1287 - val_Accuracy: 0.9717 - val_Precision: 0.9355 - val_Recall: 0.9514 - val_TP: 764.9600 - val_TN: 1058.3199 - val_FP: 47.6800 - val_FN: 39.0400\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0439 - Accuracy: 0.9870 - Precision: 0.9656 - Recall: 0.9626 - TP: 3245.7700 - TN: 5558.8901 - FP: 88.1100 - FN: 126.2300 - val_loss: 0.0998 - val_Accuracy: 0.9764 - val_Precision: 0.9606 - val_Recall: 0.9504 - val_TP: 764.1400 - val_TN: 1081.6200 - val_FP: 24.3800 - val_FN: 39.8600\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0364 - Accuracy: 0.9885 - Precision: 0.9671 - Recall: 0.9642 - TP: 3251.1599 - TN: 5564.2998 - FP: 82.7000 - FN: 120.8400 - val_loss: 0.1053 - val_Accuracy: 0.9764 - val_Precision: 0.9575 - val_Recall: 0.9513 - val_TP: 764.8600 - val_TN: 1078.8800 - val_FP: 27.1200 - val_FN: 39.1400\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0455 - Accuracy: 0.9874 - Precision: 0.9668 - Recall: 0.9619 - TP: 3243.4399 - TN: 5563.2202 - FP: 83.7800 - FN: 128.5600 - val_loss: 0.0966 - val_Accuracy: 0.9759 - val_Precision: 0.9571 - val_Recall: 0.9521 - val_TP: 765.4800 - val_TN: 1078.4700 - val_FP: 27.5300 - val_FN: 38.5200\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0371 - Accuracy: 0.9878 - Precision: 0.9652 - Recall: 0.9627 - TP: 3246.2000 - TN: 5557.0898 - FP: 89.9100 - FN: 125.8000 - val_loss: 0.0936 - val_Accuracy: 0.9754 - val_Precision: 0.9640 - val_Recall: 0.9490 - val_TP: 763.0200 - val_TN: 1084.4500 - val_FP: 21.5500 - val_FN: 40.9800\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0449 - Accuracy: 0.9876 - Precision: 0.9657 - Recall: 0.9624 - TP: 3245.3201 - TN: 5559.3599 - FP: 87.6400 - FN: 126.6800 - val_loss: 0.0956 - val_Accuracy: 0.9770 - val_Precision: 0.9584 - val_Recall: 0.9515 - val_TP: 765.0200 - val_TN: 1079.6600 - val_FP: 26.3400 - val_FN: 38.9800\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0426 - Accuracy: 0.9864 - Precision: 0.9650 - Recall: 0.9620 - TP: 3243.9600 - TN: 5556.5298 - FP: 90.4700 - FN: 128.0400 - val_loss: 0.1025 - val_Accuracy: 0.9743 - val_Precision: 0.9590 - val_Recall: 0.9484 - val_TP: 762.5400 - val_TN: 1080.2000 - val_FP: 25.8000 - val_FN: 41.4600\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0436 - Accuracy: 0.9870 - Precision: 0.9660 - Recall: 0.9619 - TP: 3243.3999 - TN: 5560.3799 - FP: 86.6200 - FN: 128.6000 - val_loss: 0.0932 - val_Accuracy: 0.9780 - val_Precision: 0.9606 - val_Recall: 0.9518 - val_TP: 765.2100 - val_TN: 1081.4800 - val_FP: 24.5200 - val_FN: 38.7900\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0366 - Accuracy: 0.9872 - Precision: 0.9657 - Recall: 0.9629 - TP: 3246.9199 - TN: 5559.0400 - FP: 87.9600 - FN: 125.0800 - val_loss: 0.0933 - val_Accuracy: 0.9764 - val_Precision: 0.9657 - val_Recall: 0.9491 - val_TP: 763.1100 - val_TN: 1085.9600 - val_FP: 20.0400 - val_FN: 40.8900\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0437 - Accuracy: 0.9872 - Precision: 0.9656 - Recall: 0.9620 - TP: 3243.7000 - TN: 5558.7900 - FP: 88.2100 - FN: 128.3000 - val_loss: 0.0966 - val_Accuracy: 0.9764 - val_Precision: 0.9599 - val_Recall: 0.9506 - val_TP: 764.3000 - val_TN: 1080.9200 - val_FP: 25.0800 - val_FN: 39.7000\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0567 - Accuracy: 0.9859 - Precision: 0.9645 - Recall: 0.9618 - TP: 3243.0500 - TN: 5554.6602 - FP: 92.3400 - FN: 128.9500 - val_loss: 0.1019 - val_Accuracy: 0.9743 - val_Precision: 0.9647 - val_Recall: 0.9456 - val_TP: 760.2900 - val_TN: 1085.2500 - val_FP: 20.7500 - val_FN: 43.7100\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0398 - Accuracy: 0.9875 - Precision: 0.9664 - Recall: 0.9618 - TP: 3243.2400 - TN: 5561.5400 - FP: 85.4600 - FN: 128.7600 - val_loss: 0.0987 - val_Accuracy: 0.9764 - val_Precision: 0.9576 - val_Recall: 0.9517 - val_TP: 765.1700 - val_TN: 1078.8800 - val_FP: 27.1200 - val_FN: 38.8300\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0419 - Accuracy: 0.9867 - Precision: 0.9653 - Recall: 0.9616 - TP: 3242.3999 - TN: 5557.8999 - FP: 89.1000 - FN: 129.6000 - val_loss: 0.1001 - val_Accuracy: 0.9754 - val_Precision: 0.9575 - val_Recall: 0.9507 - val_TP: 764.3800 - val_TN: 1078.8400 - val_FP: 27.1600 - val_FN: 39.6200\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0392 - Accuracy: 0.9864 - Precision: 0.9654 - Recall: 0.9629 - TP: 3246.7900 - TN: 5557.9702 - FP: 89.0300 - FN: 125.2100 - val_loss: 0.0947 - val_Accuracy: 0.9770 - val_Precision: 0.9624 - val_Recall: 0.9508 - val_TP: 764.4800 - val_TN: 1083.0699 - val_FP: 22.9300 - val_FN: 39.5200\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0418 - Accuracy: 0.9869 - Precision: 0.9654 - Recall: 0.9626 - TP: 3245.7400 - TN: 5558.0601 - FP: 88.9400 - FN: 126.2600 - val_loss: 0.0977 - val_Accuracy: 0.9770 - val_Precision: 0.9663 - val_Recall: 0.9472 - val_TP: 761.5400 - val_TN: 1086.4900 - val_FP: 19.5100 - val_FN: 42.4600\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0432 - Accuracy: 0.9869 - Precision: 0.9663 - Recall: 0.9623 - TP: 3244.9299 - TN: 5561.6201 - FP: 85.3800 - FN: 127.0700 - val_loss: 0.0968 - val_Accuracy: 0.9770 - val_Precision: 0.9574 - val_Recall: 0.9530 - val_TP: 766.2300 - val_TN: 1078.6899 - val_FP: 27.3100 - val_FN: 37.7700\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0367 - Accuracy: 0.9877 - Precision: 0.9667 - Recall: 0.9636 - TP: 3249.3301 - TN: 5562.8101 - FP: 84.1900 - FN: 122.6700 - val_loss: 0.0971 - val_Accuracy: 0.9770 - val_Precision: 0.9643 - val_Recall: 0.9488 - val_TP: 762.8000 - val_TN: 1084.7400 - val_FP: 21.2600 - val_FN: 41.2000\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0380 - Accuracy: 0.9877 - Precision: 0.9661 - Recall: 0.9637 - TP: 3249.4500 - TN: 5560.6001 - FP: 86.4000 - FN: 122.5500 - val_loss: 0.0989 - val_Accuracy: 0.9754 - val_Precision: 0.9641 - val_Recall: 0.9479 - val_TP: 762.0900 - val_TN: 1084.5800 - val_FP: 21.4200 - val_FN: 41.9100\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0391 - Accuracy: 0.9879 - Precision: 0.9669 - Recall: 0.9627 - TP: 3246.2700 - TN: 5563.6201 - FP: 83.3800 - FN: 125.7300 - val_loss: 0.1016 - val_Accuracy: 0.9775 - val_Precision: 0.9575 - val_Recall: 0.9518 - val_TP: 765.2800 - val_TN: 1078.8600 - val_FP: 27.1400 - val_FN: 38.7200\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0410 - Accuracy: 0.9871 - Precision: 0.9655 - Recall: 0.9630 - TP: 3247.2800 - TN: 5558.2700 - FP: 88.7300 - FN: 124.7200 - val_loss: 0.0978 - val_Accuracy: 0.9759 - val_Precision: 0.9651 - val_Recall: 0.9476 - val_TP: 761.8800 - val_TN: 1085.4301 - val_FP: 20.5700 - val_FN: 42.1200\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0430 - Accuracy: 0.9872 - Precision: 0.9654 - Recall: 0.9622 - TP: 3244.6299 - TN: 5558.2100 - FP: 88.7900 - FN: 127.3700 - val_loss: 0.0982 - val_Accuracy: 0.9770 - val_Precision: 0.9621 - val_Recall: 0.9496 - val_TP: 763.5000 - val_TN: 1082.8300 - val_FP: 23.1700 - val_FN: 40.5000\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0523 - Accuracy: 0.9869 - Precision: 0.9648 - Recall: 0.9623 - TP: 3245.0300 - TN: 5556.1001 - FP: 90.9000 - FN: 126.9700 - val_loss: 0.1014 - val_Accuracy: 0.9749 - val_Precision: 0.9638 - val_Recall: 0.9471 - val_TP: 761.4800 - val_TN: 1084.5000 - val_FP: 21.5000 - val_FN: 42.5200\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0412 - Accuracy: 0.9879 - Precision: 0.9673 - Recall: 0.9630 - TP: 3247.1201 - TN: 5565.1802 - FP: 81.8200 - FN: 124.8800 - val_loss: 0.0979 - val_Accuracy: 0.9780 - val_Precision: 0.9618 - val_Recall: 0.9506 - val_TP: 764.2600 - val_TN: 1082.6000 - val_FP: 23.4000 - val_FN: 39.7400\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0396 - Accuracy: 0.9876 - Precision: 0.9663 - Recall: 0.9633 - TP: 3248.2200 - TN: 5561.7202 - FP: 85.2800 - FN: 123.7800 - val_loss: 0.0986 - val_Accuracy: 0.9759 - val_Precision: 0.9624 - val_Recall: 0.9496 - val_TP: 763.4600 - val_TN: 1083.1700 - val_FP: 22.8300 - val_FN: 40.5400\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0412 - Accuracy: 0.9879 - Precision: 0.9664 - Recall: 0.9637 - TP: 3249.4800 - TN: 5561.8101 - FP: 85.1900 - FN: 122.5200 - val_loss: 0.0998 - val_Accuracy: 0.9749 - val_Precision: 0.9633 - val_Recall: 0.9484 - val_TP: 762.4800 - val_TN: 1083.9700 - val_FP: 22.0300 - val_FN: 41.5200\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0387 - Accuracy: 0.9888 - Precision: 0.9680 - Recall: 0.9636 - TP: 3249.4099 - TN: 5567.8198 - FP: 79.1800 - FN: 122.5900 - val_loss: 0.1011 - val_Accuracy: 0.9770 - val_Precision: 0.9543 - val_Recall: 0.9542 - val_TP: 767.2100 - val_TN: 1076.0100 - val_FP: 29.9900 - val_FN: 36.7900\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0365 - Accuracy: 0.9884 - Precision: 0.9668 - Recall: 0.9640 - TP: 3250.5200 - TN: 5562.9600 - FP: 84.0400 - FN: 121.4800 - val_loss: 0.1071 - val_Accuracy: 0.9749 - val_Precision: 0.9612 - val_Recall: 0.9481 - val_TP: 762.3100 - val_TN: 1082.2000 - val_FP: 23.8000 - val_FN: 41.6900\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0418 - Accuracy: 0.9874 - Precision: 0.9657 - Recall: 0.9635 - TP: 3248.9299 - TN: 5559.2202 - FP: 87.7800 - FN: 123.0700 - val_loss: 0.1007 - val_Accuracy: 0.9749 - val_Precision: 0.9642 - val_Recall: 0.9474 - val_TP: 761.7200 - val_TN: 1084.7300 - val_FP: 21.2700 - val_FN: 42.2800\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 4ms/step - loss: 0.0409 - Accuracy: 0.9876 - Precision: 0.9664 - Recall: 0.9626 - TP: 3246.0400 - TN: 5561.5498 - FP: 85.4500 - FN: 125.9600 - val_loss: 0.0952 - val_Accuracy: 0.9770 - val_Precision: 0.9584 - val_Recall: 0.9517 - val_TP: 765.1800 - val_TN: 1079.6600 - val_FP: 26.3400 - val_FN: 38.8200\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0422 - Accuracy: 0.9872 - Precision: 0.9658 - Recall: 0.9624 - TP: 3245.3000 - TN: 5559.1499 - FP: 87.8500 - FN: 126.7000 - val_loss: 0.0989 - val_Accuracy: 0.9764 - val_Precision: 0.9538 - val_Recall: 0.9535 - val_TP: 766.5900 - val_TN: 1075.4200 - val_FP: 30.5800 - val_FN: 37.4100\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0493 - Accuracy: 0.9863 - Precision: 0.9645 - Recall: 0.9620 - TP: 3243.9399 - TN: 5555.1699 - FP: 91.8300 - FN: 128.0600 - val_loss: 0.0962 - val_Accuracy: 0.9759 - val_Precision: 0.9647 - val_Recall: 0.9476 - val_TP: 761.8700 - val_TN: 1085.1700 - val_FP: 20.8300 - val_FN: 42.1300\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0440 - Accuracy: 0.9866 - Precision: 0.9656 - Recall: 0.9617 - TP: 3242.9299 - TN: 5558.6299 - FP: 88.3700 - FN: 129.0700 - val_loss: 0.0955 - val_Accuracy: 0.9764 - val_Precision: 0.9655 - val_Recall: 0.9481 - val_TP: 762.2900 - val_TN: 1085.8300 - val_FP: 20.1700 - val_FN: 41.7100\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0375 - Accuracy: 0.9871 - Precision: 0.9660 - Recall: 0.9629 - TP: 3246.9299 - TN: 5560.0298 - FP: 86.9700 - FN: 125.0700 - val_loss: 0.0973 - val_Accuracy: 0.9749 - val_Precision: 0.9631 - val_Recall: 0.9482 - val_TP: 762.3600 - val_TN: 1083.7800 - val_FP: 22.2200 - val_FN: 41.6400\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0486 - Accuracy: 0.9863 - Precision: 0.9653 - Recall: 0.9603 - TP: 3237.9900 - TN: 5557.9702 - FP: 89.0300 - FN: 134.0100 - val_loss: 0.0966 - val_Accuracy: 0.9770 - val_Precision: 0.9579 - val_Recall: 0.9520 - val_TP: 765.3700 - val_TN: 1079.0100 - val_FP: 26.9900 - val_FN: 38.6300\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0401 - Accuracy: 0.9871 - Precision: 0.9654 - Recall: 0.9634 - TP: 3248.5000 - TN: 5558.1699 - FP: 88.8300 - FN: 123.5000 - val_loss: 0.1006 - val_Accuracy: 0.9749 - val_Precision: 0.9611 - val_Recall: 0.9489 - val_TP: 762.9100 - val_TN: 1082.0601 - val_FP: 23.9400 - val_FN: 41.0900\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0389 - Accuracy: 0.9874 - Precision: 0.9661 - Recall: 0.9635 - TP: 3248.8201 - TN: 5560.5400 - FP: 86.4600 - FN: 123.1800 - val_loss: 0.0982 - val_Accuracy: 0.9754 - val_Precision: 0.9643 - val_Recall: 0.9474 - val_TP: 761.6900 - val_TN: 1084.8600 - val_FP: 21.1400 - val_FN: 42.3100\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0444 - Accuracy: 0.9871 - Precision: 0.9666 - Recall: 0.9626 - TP: 3245.9700 - TN: 5562.6299 - FP: 84.3700 - FN: 126.0300 - val_loss: 0.0971 - val_Accuracy: 0.9754 - val_Precision: 0.9640 - val_Recall: 0.9485 - val_TP: 762.5700 - val_TN: 1084.5200 - val_FP: 21.4800 - val_FN: 41.4300\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0427 - Accuracy: 0.9865 - Precision: 0.9656 - Recall: 0.9621 - TP: 3244.0400 - TN: 5559.1299 - FP: 87.8700 - FN: 127.9600 - val_loss: 0.0979 - val_Accuracy: 0.9759 - val_Precision: 0.9647 - val_Recall: 0.9482 - val_TP: 762.3600 - val_TN: 1085.1700 - val_FP: 20.8300 - val_FN: 41.6400\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0390 - Accuracy: 0.9882 - Precision: 0.9669 - Recall: 0.9634 - TP: 3248.6201 - TN: 5563.6201 - FP: 83.3800 - FN: 123.3800 - val_loss: 0.0994 - val_Accuracy: 0.9770 - val_Precision: 0.9580 - val_Recall: 0.9526 - val_TP: 765.8900 - val_TN: 1079.3500 - val_FP: 26.6500 - val_FN: 38.1100\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0378 - Accuracy: 0.9878 - Precision: 0.9665 - Recall: 0.9637 - TP: 3249.5601 - TN: 5562.3301 - FP: 84.6700 - FN: 122.4400 - val_loss: 0.0963 - val_Accuracy: 0.9764 - val_Precision: 0.9628 - val_Recall: 0.9506 - val_TP: 764.2700 - val_TN: 1083.4600 - val_FP: 22.5400 - val_FN: 39.7300\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0402 - Accuracy: 0.9877 - Precision: 0.9663 - Recall: 0.9633 - TP: 3248.2800 - TN: 5561.2402 - FP: 85.7600 - FN: 123.7200 - val_loss: 0.1075 - val_Accuracy: 0.9738 - val_Precision: 0.9558 - val_Recall: 0.9506 - val_TP: 764.3200 - val_TN: 1077.2900 - val_FP: 28.7100 - val_FN: 39.6800\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0414 - Accuracy: 0.9869 - Precision: 0.9660 - Recall: 0.9625 - TP: 3245.6001 - TN: 5560.4399 - FP: 86.5600 - FN: 126.4000 - val_loss: 0.0980 - val_Accuracy: 0.9775 - val_Precision: 0.9580 - val_Recall: 0.9527 - val_TP: 765.9900 - val_TN: 1079.2300 - val_FP: 26.7700 - val_FN: 38.0100\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0379 - Accuracy: 0.9869 - Precision: 0.9667 - Recall: 0.9634 - TP: 3248.6799 - TN: 5562.8999 - FP: 84.1000 - FN: 123.3200 - val_loss: 0.1053 - val_Accuracy: 0.9754 - val_Precision: 0.9577 - val_Recall: 0.9503 - val_TP: 764.0700 - val_TN: 1079.1200 - val_FP: 26.8800 - val_FN: 39.9300\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0405 - Accuracy: 0.9875 - Precision: 0.9669 - Recall: 0.9635 - TP: 3248.8101 - TN: 5563.6899 - FP: 83.3100 - FN: 123.1900 - val_loss: 0.0976 - val_Accuracy: 0.9780 - val_Precision: 0.9610 - val_Recall: 0.9510 - val_TP: 764.6300 - val_TN: 1081.8300 - val_FP: 24.1700 - val_FN: 39.3700\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0420 - Accuracy: 0.9882 - Precision: 0.9661 - Recall: 0.9637 - TP: 3249.4800 - TN: 5560.6299 - FP: 86.3700 - FN: 122.5200 - val_loss: 0.1164 - val_Accuracy: 0.9717 - val_Precision: 0.9535 - val_Recall: 0.9471 - val_TP: 761.4300 - val_TN: 1075.1100 - val_FP: 30.8900 - val_FN: 42.5700\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0410 - Accuracy: 0.9881 - Precision: 0.9668 - Recall: 0.9627 - TP: 3246.2200 - TN: 5563.4302 - FP: 83.5700 - FN: 125.7800 - val_loss: 0.1082 - val_Accuracy: 0.9754 - val_Precision: 0.9535 - val_Recall: 0.9522 - val_TP: 765.5300 - val_TN: 1075.4000 - val_FP: 30.6000 - val_FN: 38.4700\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0496 - Accuracy: 0.9868 - Precision: 0.9651 - Recall: 0.9626 - TP: 3245.7700 - TN: 5557.0000 - FP: 90.0000 - FN: 126.2300 - val_loss: 0.1017 - val_Accuracy: 0.9759 - val_Precision: 0.9603 - val_Recall: 0.9502 - val_TP: 763.9300 - val_TN: 1081.4399 - val_FP: 24.5600 - val_FN: 40.0700\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0350 - Accuracy: 0.9885 - Precision: 0.9669 - Recall: 0.9647 - TP: 3252.8601 - TN: 5563.3799 - FP: 83.6200 - FN: 119.1400 - val_loss: 0.1098 - val_Accuracy: 0.9738 - val_Precision: 0.9652 - val_Recall: 0.9441 - val_TP: 759.0200 - val_TN: 1085.7600 - val_FP: 20.2400 - val_FN: 44.9800\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0404 - Accuracy: 0.9874 - Precision: 0.9666 - Recall: 0.9621 - TP: 3244.3000 - TN: 5562.5200 - FP: 84.4800 - FN: 127.7000 - val_loss: 0.1002 - val_Accuracy: 0.9764 - val_Precision: 0.9619 - val_Recall: 0.9500 - val_TP: 763.8200 - val_TN: 1082.7200 - val_FP: 23.2800 - val_FN: 40.1800\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0384 - Accuracy: 0.9874 - Precision: 0.9660 - Recall: 0.9631 - TP: 3247.5801 - TN: 5560.2202 - FP: 86.7800 - FN: 124.4200 - val_loss: 0.0961 - val_Accuracy: 0.9764 - val_Precision: 0.9667 - val_Recall: 0.9467 - val_TP: 761.1500 - val_TN: 1086.8700 - val_FP: 19.1300 - val_FN: 42.8500\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0417 - Accuracy: 0.9876 - Precision: 0.9666 - Recall: 0.9625 - TP: 3245.5200 - TN: 5562.5898 - FP: 84.4100 - FN: 126.4800 - val_loss: 0.0945 - val_Accuracy: 0.9759 - val_Precision: 0.9636 - val_Recall: 0.9500 - val_TP: 763.8000 - val_TN: 1084.1500 - val_FP: 21.8500 - val_FN: 40.2000\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0386 - Accuracy: 0.9871 - Precision: 0.9663 - Recall: 0.9635 - TP: 3248.7900 - TN: 5561.2598 - FP: 85.7400 - FN: 123.2100 - val_loss: 0.0982 - val_Accuracy: 0.9749 - val_Precision: 0.9619 - val_Recall: 0.9487 - val_TP: 762.7500 - val_TN: 1082.7900 - val_FP: 23.2100 - val_FN: 41.2500\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0522 - Accuracy: 0.9867 - Precision: 0.9655 - Recall: 0.9619 - TP: 3243.3999 - TN: 5558.4702 - FP: 88.5300 - FN: 128.6000 - val_loss: 0.0963 - val_Accuracy: 0.9770 - val_Precision: 0.9631 - val_Recall: 0.9492 - val_TP: 763.1700 - val_TN: 1083.7500 - val_FP: 22.2500 - val_FN: 40.8300\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0392 - Accuracy: 0.9875 - Precision: 0.9662 - Recall: 0.9626 - TP: 3245.8601 - TN: 5561.2402 - FP: 85.7600 - FN: 126.1400 - val_loss: 0.0962 - val_Accuracy: 0.9764 - val_Precision: 0.9571 - val_Recall: 0.9533 - val_TP: 766.4500 - val_TN: 1078.4000 - val_FP: 27.6000 - val_FN: 37.5500\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0476 - Accuracy: 0.9859 - Precision: 0.9651 - Recall: 0.9618 - TP: 3243.3101 - TN: 5557.1299 - FP: 89.8700 - FN: 128.6900 - val_loss: 0.1067 - val_Accuracy: 0.9749 - val_Precision: 0.9569 - val_Recall: 0.9497 - val_TP: 763.5500 - val_TN: 1078.3199 - val_FP: 27.6800 - val_FN: 40.4500\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0464 - Accuracy: 0.9871 - Precision: 0.9660 - Recall: 0.9631 - TP: 3247.5500 - TN: 5560.6201 - FP: 86.3800 - FN: 124.4500 - val_loss: 0.0971 - val_Accuracy: 0.9764 - val_Precision: 0.9644 - val_Recall: 0.9484 - val_TP: 762.5100 - val_TN: 1084.8300 - val_FP: 21.1700 - val_FN: 41.4900\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0414 - Accuracy: 0.9880 - Precision: 0.9663 - Recall: 0.9628 - TP: 3246.3999 - TN: 5561.2402 - FP: 85.7600 - FN: 125.6000 - val_loss: 0.1035 - val_Accuracy: 0.9749 - val_Precision: 0.9629 - val_Recall: 0.9471 - val_TP: 761.4700 - val_TN: 1083.6899 - val_FP: 22.3100 - val_FN: 42.5300\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0445 - Accuracy: 0.9866 - Precision: 0.9656 - Recall: 0.9629 - TP: 3247.0300 - TN: 5559.2998 - FP: 87.7000 - FN: 124.9700 - val_loss: 0.0985 - val_Accuracy: 0.9764 - val_Precision: 0.9655 - val_Recall: 0.9469 - val_TP: 761.2900 - val_TN: 1085.8000 - val_FP: 20.2000 - val_FN: 42.7100\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0371 - Accuracy: 0.9877 - Precision: 0.9667 - Recall: 0.9627 - TP: 3246.2300 - TN: 5562.7598 - FP: 84.2400 - FN: 125.7700 - val_loss: 0.0966 - val_Accuracy: 0.9775 - val_Precision: 0.9618 - val_Recall: 0.9509 - val_TP: 764.5100 - val_TN: 1082.6000 - val_FP: 23.4000 - val_FN: 39.4900\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0355 - Accuracy: 0.9879 - Precision: 0.9668 - Recall: 0.9633 - TP: 3248.1399 - TN: 5562.9800 - FP: 84.0200 - FN: 123.8600 - val_loss: 0.0983 - val_Accuracy: 0.9759 - val_Precision: 0.9633 - val_Recall: 0.9493 - val_TP: 763.2400 - val_TN: 1083.9200 - val_FP: 22.0800 - val_FN: 40.7600\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0378 - Accuracy: 0.9875 - Precision: 0.9662 - Recall: 0.9630 - TP: 3247.3401 - TN: 5560.8501 - FP: 86.1500 - FN: 124.6600 - val_loss: 0.1002 - val_Accuracy: 0.9749 - val_Precision: 0.9605 - val_Recall: 0.9500 - val_TP: 763.7800 - val_TN: 1081.5601 - val_FP: 24.4400 - val_FN: 40.2200\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0374 - Accuracy: 0.9875 - Precision: 0.9664 - Recall: 0.9632 - TP: 3247.9500 - TN: 5561.8701 - FP: 85.1300 - FN: 124.0500 - val_loss: 0.0986 - val_Accuracy: 0.9764 - val_Precision: 0.9593 - val_Recall: 0.9513 - val_TP: 764.8500 - val_TN: 1080.4000 - val_FP: 25.6000 - val_FN: 39.1500\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0366 - Accuracy: 0.9877 - Precision: 0.9666 - Recall: 0.9641 - TP: 3250.9099 - TN: 5562.2900 - FP: 84.7100 - FN: 121.0900 - val_loss: 0.1030 - val_Accuracy: 0.9754 - val_Precision: 0.9666 - val_Recall: 0.9448 - val_TP: 759.6000 - val_TN: 1086.9200 - val_FP: 19.0800 - val_FN: 44.4000\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0605 - Accuracy: 0.9857 - Precision: 0.9648 - Recall: 0.9613 - TP: 3241.6499 - TN: 5556.5200 - FP: 90.4800 - FN: 130.3500 - val_loss: 0.0993 - val_Accuracy: 0.9775 - val_Precision: 0.9579 - val_Recall: 0.9521 - val_TP: 765.5000 - val_TN: 1079.2000 - val_FP: 26.8000 - val_FN: 38.5000\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0368 - Accuracy: 0.9877 - Precision: 0.9675 - Recall: 0.9630 - TP: 3247.3101 - TN: 5565.6699 - FP: 81.3300 - FN: 124.6900 - val_loss: 0.1018 - val_Accuracy: 0.9775 - val_Precision: 0.9549 - val_Recall: 0.9539 - val_TP: 766.9600 - val_TN: 1076.5500 - val_FP: 29.4500 - val_FN: 37.0400\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0457 - Accuracy: 0.9871 - Precision: 0.9662 - Recall: 0.9639 - TP: 3250.3000 - TN: 5561.0498 - FP: 85.9500 - FN: 121.7000 - val_loss: 0.1013 - val_Accuracy: 0.9759 - val_Precision: 0.9626 - val_Recall: 0.9489 - val_TP: 762.9400 - val_TN: 1083.4301 - val_FP: 22.5700 - val_FN: 41.0600\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0375 - Accuracy: 0.9877 - Precision: 0.9670 - Recall: 0.9637 - TP: 3249.4600 - TN: 5564.1499 - FP: 82.8500 - FN: 122.5400 - val_loss: 0.0983 - val_Accuracy: 0.9780 - val_Precision: 0.9633 - val_Recall: 0.9500 - val_TP: 763.8300 - val_TN: 1083.9399 - val_FP: 22.0600 - val_FN: 40.1700\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0403 - Accuracy: 0.9877 - Precision: 0.9658 - Recall: 0.9634 - TP: 3248.6299 - TN: 5559.4199 - FP: 87.5800 - FN: 123.3700 - val_loss: 0.1009 - val_Accuracy: 0.9759 - val_Precision: 0.9649 - val_Recall: 0.9477 - val_TP: 761.9400 - val_TN: 1085.4000 - val_FP: 20.6000 - val_FN: 42.0600\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0353 - Accuracy: 0.9880 - Precision: 0.9675 - Recall: 0.9636 - TP: 3249.1699 - TN: 5565.5200 - FP: 81.4800 - FN: 122.8300 - val_loss: 0.0996 - val_Accuracy: 0.9780 - val_Precision: 0.9593 - val_Recall: 0.9526 - val_TP: 765.9300 - val_TN: 1080.3900 - val_FP: 25.6100 - val_FN: 38.0700\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0422 - Accuracy: 0.9877 - Precision: 0.9666 - Recall: 0.9640 - TP: 3250.4800 - TN: 5563.0400 - FP: 83.9600 - FN: 121.5200 - val_loss: 0.1040 - val_Accuracy: 0.9759 - val_Precision: 0.9616 - val_Recall: 0.9490 - val_TP: 763.0100 - val_TN: 1082.5601 - val_FP: 23.4400 - val_FN: 40.9900\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0344 - Accuracy: 0.9879 - Precision: 0.9673 - Recall: 0.9643 - TP: 3251.5300 - TN: 5565.1899 - FP: 81.8100 - FN: 120.4700 - val_loss: 0.1016 - val_Accuracy: 0.9754 - val_Precision: 0.9633 - val_Recall: 0.9488 - val_TP: 762.8700 - val_TN: 1084.0500 - val_FP: 21.9500 - val_FN: 41.1300\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 4ms/step - loss: 0.0438 - Accuracy: 0.9863 - Precision: 0.9658 - Recall: 0.9624 - TP: 3245.3501 - TN: 5559.9800 - FP: 87.0200 - FN: 126.6500 - val_loss: 0.1043 - val_Accuracy: 0.9749 - val_Precision: 0.9573 - val_Recall: 0.9501 - val_TP: 763.8600 - val_TN: 1078.7700 - val_FP: 27.2300 - val_FN: 40.1400\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0367 - Accuracy: 0.9871 - Precision: 0.9664 - Recall: 0.9619 - TP: 3243.4700 - TN: 5561.4800 - FP: 85.5200 - FN: 128.5300 - val_loss: 0.1039 - val_Accuracy: 0.9754 - val_Precision: 0.9549 - val_Recall: 0.9519 - val_TP: 765.3400 - val_TN: 1076.4800 - val_FP: 29.5200 - val_FN: 38.6600\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0588 - Accuracy: 0.9864 - Precision: 0.9642 - Recall: 0.9621 - TP: 3244.2700 - TN: 5553.8501 - FP: 93.1500 - FN: 127.7300 - val_loss: 0.0991 - val_Accuracy: 0.9754 - val_Precision: 0.9663 - val_Recall: 0.9459 - val_TP: 760.5200 - val_TN: 1086.5800 - val_FP: 19.4200 - val_FN: 43.4800\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0412 - Accuracy: 0.9865 - Precision: 0.9661 - Recall: 0.9617 - TP: 3242.7800 - TN: 5560.7700 - FP: 86.2300 - FN: 129.2200 - val_loss: 0.1072 - val_Accuracy: 0.9743 - val_Precision: 0.9503 - val_Recall: 0.9537 - val_TP: 766.8100 - val_TN: 1072.2600 - val_FP: 33.7400 - val_FN: 37.1900\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0383 - Accuracy: 0.9876 - Precision: 0.9657 - Recall: 0.9636 - TP: 3249.1599 - TN: 5559.3501 - FP: 87.6500 - FN: 122.8400 - val_loss: 0.0988 - val_Accuracy: 0.9749 - val_Precision: 0.9624 - val_Recall: 0.9487 - val_TP: 762.7500 - val_TN: 1083.2100 - val_FP: 22.7900 - val_FN: 41.2500\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0405 - Accuracy: 0.9865 - Precision: 0.9656 - Recall: 0.9619 - TP: 3243.3601 - TN: 5559.1201 - FP: 87.8800 - FN: 128.6400 - val_loss: 0.1033 - val_Accuracy: 0.9754 - val_Precision: 0.9573 - val_Recall: 0.9511 - val_TP: 764.6700 - val_TN: 1078.6899 - val_FP: 27.3100 - val_FN: 39.3300\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0383 - Accuracy: 0.9871 - Precision: 0.9660 - Recall: 0.9634 - TP: 3248.6899 - TN: 5560.5098 - FP: 86.4900 - FN: 123.3100 - val_loss: 0.0998 - val_Accuracy: 0.9754 - val_Precision: 0.9633 - val_Recall: 0.9479 - val_TP: 762.1300 - val_TN: 1084.0400 - val_FP: 21.9600 - val_FN: 41.8700\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0467 - Accuracy: 0.9879 - Precision: 0.9659 - Recall: 0.9629 - TP: 3246.8899 - TN: 5560.1001 - FP: 86.9000 - FN: 125.1100 - val_loss: 0.0993 - val_Accuracy: 0.9754 - val_Precision: 0.9647 - val_Recall: 0.9477 - val_TP: 761.9200 - val_TN: 1085.1801 - val_FP: 20.8200 - val_FN: 42.0800\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0416 - Accuracy: 0.9871 - Precision: 0.9663 - Recall: 0.9629 - TP: 3246.7500 - TN: 5561.8999 - FP: 85.1000 - FN: 125.2500 - val_loss: 0.1004 - val_Accuracy: 0.9743 - val_Precision: 0.9624 - val_Recall: 0.9490 - val_TP: 762.9700 - val_TN: 1083.2500 - val_FP: 22.7500 - val_FN: 41.0300\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0532 - Accuracy: 0.9864 - Precision: 0.9664 - Recall: 0.9620 - TP: 3243.7400 - TN: 5562.2700 - FP: 84.7300 - FN: 128.2600 - val_loss: 0.1264 - val_Accuracy: 0.9717 - val_Precision: 0.9346 - val_Recall: 0.9563 - val_TP: 768.9000 - val_TN: 1057.5601 - val_FP: 48.4400 - val_FN: 35.1000\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0421 - Accuracy: 0.9868 - Precision: 0.9654 - Recall: 0.9631 - TP: 3247.5601 - TN: 5558.1602 - FP: 88.8400 - FN: 124.4400 - val_loss: 0.1007 - val_Accuracy: 0.9759 - val_Precision: 0.9571 - val_Recall: 0.9526 - val_TP: 765.8800 - val_TN: 1078.5900 - val_FP: 27.4100 - val_FN: 38.1200\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0390 - Accuracy: 0.9871 - Precision: 0.9661 - Recall: 0.9626 - TP: 3245.8799 - TN: 5560.8398 - FP: 86.1600 - FN: 126.1200 - val_loss: 0.1061 - val_Accuracy: 0.9759 - val_Precision: 0.9528 - val_Recall: 0.9535 - val_TP: 766.6100 - val_TN: 1074.6500 - val_FP: 31.3500 - val_FN: 37.3900\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0432 - Accuracy: 0.9875 - Precision: 0.9662 - Recall: 0.9622 - TP: 3244.6001 - TN: 5561.1401 - FP: 85.8600 - FN: 127.4000 - val_loss: 0.0991 - val_Accuracy: 0.9764 - val_Precision: 0.9526 - val_Recall: 0.9566 - val_TP: 769.0800 - val_TN: 1074.2600 - val_FP: 31.7400 - val_FN: 34.9200\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0468 - Accuracy: 0.9870 - Precision: 0.9648 - Recall: 0.9623 - TP: 3245.0200 - TN: 5556.2798 - FP: 90.7200 - FN: 126.9800 - val_loss: 0.1037 - val_Accuracy: 0.9770 - val_Precision: 0.9585 - val_Recall: 0.9511 - val_TP: 764.7200 - val_TN: 1079.8199 - val_FP: 26.1800 - val_FN: 39.2800\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0377 - Accuracy: 0.9872 - Precision: 0.9665 - Recall: 0.9635 - TP: 3248.8301 - TN: 5562.1001 - FP: 84.9000 - FN: 123.1700 - val_loss: 0.1009 - val_Accuracy: 0.9770 - val_Precision: 0.9581 - val_Recall: 0.9521 - val_TP: 765.4600 - val_TN: 1079.4500 - val_FP: 26.5500 - val_FN: 38.5400\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0414 - Accuracy: 0.9875 - Precision: 0.9671 - Recall: 0.9630 - TP: 3247.1799 - TN: 5564.4399 - FP: 82.5600 - FN: 124.8200 - val_loss: 0.0982 - val_Accuracy: 0.9785 - val_Precision: 0.9582 - val_Recall: 0.9538 - val_TP: 766.8900 - val_TN: 1079.4301 - val_FP: 26.5700 - val_FN: 37.1100\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0382 - Accuracy: 0.9865 - Precision: 0.9647 - Recall: 0.9638 - TP: 3250.0000 - TN: 5555.7100 - FP: 91.2900 - FN: 122.0000 - val_loss: 0.1021 - val_Accuracy: 0.9754 - val_Precision: 0.9686 - val_Recall: 0.9449 - val_TP: 759.7200 - val_TN: 1088.5500 - val_FP: 17.4500 - val_FN: 44.2800\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0405 - Accuracy: 0.9871 - Precision: 0.9665 - Recall: 0.9629 - TP: 3247.0400 - TN: 5562.2998 - FP: 84.7000 - FN: 124.9600 - val_loss: 0.0998 - val_Accuracy: 0.9775 - val_Precision: 0.9627 - val_Recall: 0.9499 - val_TP: 763.6800 - val_TN: 1083.3600 - val_FP: 22.6400 - val_FN: 40.3200\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0456 - Accuracy: 0.9867 - Precision: 0.9665 - Recall: 0.9621 - TP: 3244.2000 - TN: 5562.4600 - FP: 84.5400 - FN: 127.8000 - val_loss: 0.1131 - val_Accuracy: 0.9717 - val_Precision: 0.9564 - val_Recall: 0.9484 - val_TP: 762.5400 - val_TN: 1077.9399 - val_FP: 28.0600 - val_FN: 41.4600\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0416 - Accuracy: 0.9876 - Precision: 0.9666 - Recall: 0.9639 - TP: 3250.1699 - TN: 5562.8301 - FP: 84.1700 - FN: 121.8300 - val_loss: 0.1001 - val_Accuracy: 0.9780 - val_Precision: 0.9609 - val_Recall: 0.9518 - val_TP: 765.2300 - val_TN: 1081.8600 - val_FP: 24.1400 - val_FN: 38.7700\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0394 - Accuracy: 0.9872 - Precision: 0.9666 - Recall: 0.9635 - TP: 3249.0300 - TN: 5562.7002 - FP: 84.3000 - FN: 122.9700 - val_loss: 0.1016 - val_Accuracy: 0.9764 - val_Precision: 0.9610 - val_Recall: 0.9502 - val_TP: 763.9800 - val_TN: 1081.9600 - val_FP: 24.0400 - val_FN: 40.0200\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0407 - Accuracy: 0.9878 - Precision: 0.9669 - Recall: 0.9638 - TP: 3249.7700 - TN: 5563.6201 - FP: 83.3800 - FN: 122.2300 - val_loss: 0.1057 - val_Accuracy: 0.9759 - val_Precision: 0.9609 - val_Recall: 0.9495 - val_TP: 763.3900 - val_TN: 1082.0300 - val_FP: 23.9700 - val_FN: 40.6100\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0388 - Accuracy: 0.9869 - Precision: 0.9663 - Recall: 0.9634 - TP: 3248.4199 - TN: 5561.8599 - FP: 85.1400 - FN: 123.5800 - val_loss: 0.1022 - val_Accuracy: 0.9749 - val_Precision: 0.9653 - val_Recall: 0.9477 - val_TP: 761.9400 - val_TN: 1085.7300 - val_FP: 20.2700 - val_FN: 42.0600\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0391 - Accuracy: 0.9875 - Precision: 0.9670 - Recall: 0.9644 - TP: 3251.8401 - TN: 5563.9600 - FP: 83.0400 - FN: 120.1600 - val_loss: 0.1070 - val_Accuracy: 0.9759 - val_Precision: 0.9596 - val_Recall: 0.9497 - val_TP: 763.5400 - val_TN: 1080.8000 - val_FP: 25.2000 - val_FN: 40.4600\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0388 - Accuracy: 0.9875 - Precision: 0.9670 - Recall: 0.9630 - TP: 3247.2000 - TN: 5564.1899 - FP: 82.8100 - FN: 124.8000 - val_loss: 0.1007 - val_Accuracy: 0.9775 - val_Precision: 0.9653 - val_Recall: 0.9489 - val_TP: 762.8900 - val_TN: 1085.7100 - val_FP: 20.2900 - val_FN: 41.1100\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0461 - Accuracy: 0.9877 - Precision: 0.9658 - Recall: 0.9633 - TP: 3248.2000 - TN: 5559.7700 - FP: 87.2300 - FN: 123.8000 - val_loss: 0.1007 - val_Accuracy: 0.9775 - val_Precision: 0.9641 - val_Recall: 0.9500 - val_TP: 763.7900 - val_TN: 1084.7000 - val_FP: 21.3000 - val_FN: 40.2100\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0387 - Accuracy: 0.9891 - Precision: 0.9679 - Recall: 0.9645 - TP: 3252.1399 - TN: 5567.3101 - FP: 79.6900 - FN: 119.8600 - val_loss: 0.1030 - val_Accuracy: 0.9770 - val_Precision: 0.9624 - val_Recall: 0.9498 - val_TP: 763.6600 - val_TN: 1083.2500 - val_FP: 22.7500 - val_FN: 40.3400\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0406 - Accuracy: 0.9872 - Precision: 0.9663 - Recall: 0.9633 - TP: 3248.0801 - TN: 5561.9502 - FP: 85.0500 - FN: 123.9200 - val_loss: 0.1060 - val_Accuracy: 0.9749 - val_Precision: 0.9614 - val_Recall: 0.9485 - val_TP: 762.5600 - val_TN: 1082.4399 - val_FP: 23.5600 - val_FN: 41.4400\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0366 - Accuracy: 0.9871 - Precision: 0.9672 - Recall: 0.9641 - TP: 3250.8301 - TN: 5564.9199 - FP: 82.0800 - FN: 121.1700 - val_loss: 0.1013 - val_Accuracy: 0.9785 - val_Precision: 0.9619 - val_Recall: 0.9515 - val_TP: 765.0400 - val_TN: 1082.7600 - val_FP: 23.2400 - val_FN: 38.9600\n",
      "Epoch 30/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0442 - Accuracy: 0.9877 - Precision: 0.9662 - Recall: 0.9636 - TP: 3249.2200 - TN: 5561.5498 - FP: 85.4500 - FN: 122.7800 - val_loss: 0.1059 - val_Accuracy: 0.9743 - val_Precision: 0.9635 - val_Recall: 0.9476 - val_TP: 761.9100 - val_TN: 1084.2300 - val_FP: 21.7700 - val_FN: 42.0900\n",
      "Epoch 31/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0367 - Accuracy: 0.9881 - Precision: 0.9677 - Recall: 0.9642 - TP: 3251.3301 - TN: 5566.7300 - FP: 80.2700 - FN: 120.6700 - val_loss: 0.1056 - val_Accuracy: 0.9764 - val_Precision: 0.9581 - val_Recall: 0.9522 - val_TP: 765.5600 - val_TN: 1079.5601 - val_FP: 26.4400 - val_FN: 38.4400\n",
      "Epoch 32/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0397 - Accuracy: 0.9876 - Precision: 0.9673 - Recall: 0.9642 - TP: 3251.1299 - TN: 5565.1201 - FP: 81.8800 - FN: 120.8700 - val_loss: 0.1046 - val_Accuracy: 0.9764 - val_Precision: 0.9584 - val_Recall: 0.9518 - val_TP: 765.2700 - val_TN: 1079.7700 - val_FP: 26.2300 - val_FN: 38.7300\n",
      "Epoch 33/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0364 - Accuracy: 0.9874 - Precision: 0.9671 - Recall: 0.9642 - TP: 3251.2900 - TN: 5564.7900 - FP: 82.2100 - FN: 120.7100 - val_loss: 0.1031 - val_Accuracy: 0.9785 - val_Precision: 0.9607 - val_Recall: 0.9513 - val_TP: 764.8700 - val_TN: 1081.6899 - val_FP: 24.3100 - val_FN: 39.1300\n",
      "Epoch 34/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0370 - Accuracy: 0.9877 - Precision: 0.9675 - Recall: 0.9642 - TP: 3251.3401 - TN: 5566.2300 - FP: 80.7700 - FN: 120.6600 - val_loss: 0.1057 - val_Accuracy: 0.9770 - val_Precision: 0.9583 - val_Recall: 0.9524 - val_TP: 765.7500 - val_TN: 1079.6700 - val_FP: 26.3300 - val_FN: 38.2500\n",
      "Epoch 35/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0422 - Accuracy: 0.9891 - Precision: 0.9674 - Recall: 0.9646 - TP: 3252.5901 - TN: 5565.6899 - FP: 81.3100 - FN: 119.4100 - val_loss: 0.1026 - val_Accuracy: 0.9770 - val_Precision: 0.9564 - val_Recall: 0.9543 - val_TP: 767.2700 - val_TN: 1077.8400 - val_FP: 28.1600 - val_FN: 36.7300\n",
      "Epoch 36/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0430 - Accuracy: 0.9871 - Precision: 0.9661 - Recall: 0.9629 - TP: 3246.9700 - TN: 5560.8901 - FP: 86.1100 - FN: 125.0300 - val_loss: 0.1034 - val_Accuracy: 0.9775 - val_Precision: 0.9612 - val_Recall: 0.9512 - val_TP: 764.7500 - val_TN: 1082.1700 - val_FP: 23.8300 - val_FN: 39.2500\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 6ms/step - loss: 0.0456 - Accuracy: 0.9877 - Precision: 0.9673 - Recall: 0.9636 - TP: 3249.3999 - TN: 5565.4702 - FP: 81.5300 - FN: 122.6000 - val_loss: 0.1219 - val_Accuracy: 0.9728 - val_Precision: 0.9413 - val_Recall: 0.9533 - val_TP: 766.4600 - val_TN: 1063.6801 - val_FP: 42.3200 - val_FN: 37.5400\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0445 - Accuracy: 0.9863 - Precision: 0.9650 - Recall: 0.9632 - TP: 3247.7500 - TN: 5556.9399 - FP: 90.0600 - FN: 124.2500 - val_loss: 0.2376 - val_Accuracy: 0.9403 - val_Precision: 0.8902 - val_Recall: 0.9482 - val_TP: 762.3600 - val_TN: 1019.1000 - val_FP: 86.9000 - val_FN: 41.6400\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0660 - Accuracy: 0.9874 - Precision: 0.9657 - Recall: 0.9618 - TP: 3243.0901 - TN: 5559.8398 - FP: 87.1600 - FN: 128.9100 - val_loss: 0.1039 - val_Accuracy: 0.9743 - val_Precision: 0.9613 - val_Recall: 0.9493 - val_TP: 763.2600 - val_TN: 1082.3600 - val_FP: 23.6400 - val_FN: 40.7400\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0434 - Accuracy: 0.9871 - Precision: 0.9667 - Recall: 0.9638 - TP: 3250.0901 - TN: 5563.0200 - FP: 83.9800 - FN: 121.9100 - val_loss: 0.1075 - val_Accuracy: 0.9738 - val_Precision: 0.9641 - val_Recall: 0.9465 - val_TP: 761.0200 - val_TN: 1084.8600 - val_FP: 21.1400 - val_FN: 42.9800\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0418 - Accuracy: 0.9879 - Precision: 0.9679 - Recall: 0.9637 - TP: 3249.4299 - TN: 5567.4800 - FP: 79.5200 - FN: 122.5700 - val_loss: 0.1012 - val_Accuracy: 0.9764 - val_Precision: 0.9551 - val_Recall: 0.9542 - val_TP: 767.2000 - val_TN: 1076.7600 - val_FP: 29.2400 - val_FN: 36.8000\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0422 - Accuracy: 0.9879 - Precision: 0.9657 - Recall: 0.9639 - TP: 3250.1699 - TN: 5559.4399 - FP: 87.5600 - FN: 121.8300 - val_loss: 0.1057 - val_Accuracy: 0.9749 - val_Precision: 0.9629 - val_Recall: 0.9476 - val_TP: 761.8700 - val_TN: 1083.7500 - val_FP: 22.2500 - val_FN: 42.1300\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0419 - Accuracy: 0.9860 - Precision: 0.9656 - Recall: 0.9630 - TP: 3247.1799 - TN: 5559.1899 - FP: 87.8100 - FN: 124.8200 - val_loss: 0.1021 - val_Accuracy: 0.9754 - val_Precision: 0.9659 - val_Recall: 0.9471 - val_TP: 761.4800 - val_TN: 1086.2700 - val_FP: 19.7300 - val_FN: 42.5200\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0589 - Accuracy: 0.9866 - Precision: 0.9668 - Recall: 0.9629 - TP: 3246.8899 - TN: 5564.1299 - FP: 82.8700 - FN: 125.1100 - val_loss: 0.1086 - val_Accuracy: 0.9754 - val_Precision: 0.9577 - val_Recall: 0.9510 - val_TP: 764.6000 - val_TN: 1079.2100 - val_FP: 26.7900 - val_FN: 39.4000\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0437 - Accuracy: 0.9872 - Precision: 0.9652 - Recall: 0.9628 - TP: 3246.4800 - TN: 5557.7798 - FP: 89.2200 - FN: 125.5200 - val_loss: 0.1026 - val_Accuracy: 0.9759 - val_Precision: 0.9651 - val_Recall: 0.9485 - val_TP: 762.5600 - val_TN: 1085.5400 - val_FP: 20.4600 - val_FN: 41.4400\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0362 - Accuracy: 0.9877 - Precision: 0.9676 - Recall: 0.9638 - TP: 3249.9500 - TN: 5566.4199 - FP: 80.5800 - FN: 122.0500 - val_loss: 0.1027 - val_Accuracy: 0.9770 - val_Precision: 0.9591 - val_Recall: 0.9519 - val_TP: 765.3500 - val_TN: 1080.2800 - val_FP: 25.7200 - val_FN: 38.6500\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0346 - Accuracy: 0.9879 - Precision: 0.9670 - Recall: 0.9646 - TP: 3252.6399 - TN: 5564.0601 - FP: 82.9400 - FN: 119.3600 - val_loss: 0.1055 - val_Accuracy: 0.9764 - val_Precision: 0.9617 - val_Recall: 0.9488 - val_TP: 762.8000 - val_TN: 1082.7100 - val_FP: 23.2900 - val_FN: 41.2000\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0433 - Accuracy: 0.9868 - Precision: 0.9666 - Recall: 0.9634 - TP: 3248.5200 - TN: 5562.8901 - FP: 84.1100 - FN: 123.4800 - val_loss: 0.1045 - val_Accuracy: 0.9743 - val_Precision: 0.9626 - val_Recall: 0.9485 - val_TP: 762.6300 - val_TN: 1083.4000 - val_FP: 22.6000 - val_FN: 41.3700\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0400 - Accuracy: 0.9868 - Precision: 0.9658 - Recall: 0.9634 - TP: 3248.5100 - TN: 5559.7798 - FP: 87.2200 - FN: 123.4900 - val_loss: 0.1143 - val_Accuracy: 0.9733 - val_Precision: 0.9606 - val_Recall: 0.9470 - val_TP: 761.4000 - val_TN: 1081.8500 - val_FP: 24.1500 - val_FN: 42.6000\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0383 - Accuracy: 0.9865 - Precision: 0.9661 - Recall: 0.9628 - TP: 3246.5801 - TN: 5561.0298 - FP: 85.9700 - FN: 125.4200 - val_loss: 0.1061 - val_Accuracy: 0.9759 - val_Precision: 0.9616 - val_Recall: 0.9488 - val_TP: 762.8400 - val_TN: 1082.6300 - val_FP: 23.3700 - val_FN: 41.1600\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0354 - Accuracy: 0.9882 - Precision: 0.9677 - Recall: 0.9644 - TP: 3251.8000 - TN: 5566.8501 - FP: 80.1500 - FN: 120.2000 - val_loss: 0.1046 - val_Accuracy: 0.9770 - val_Precision: 0.9635 - val_Recall: 0.9485 - val_TP: 762.5900 - val_TN: 1084.2300 - val_FP: 21.7700 - val_FN: 41.4100\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0367 - Accuracy: 0.9872 - Precision: 0.9665 - Recall: 0.9640 - TP: 3250.6399 - TN: 5562.3101 - FP: 84.6900 - FN: 121.3600 - val_loss: 0.1071 - val_Accuracy: 0.9754 - val_Precision: 0.9613 - val_Recall: 0.9489 - val_TP: 762.9400 - val_TN: 1082.4301 - val_FP: 23.5700 - val_FN: 41.0600\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0448 - Accuracy: 0.9868 - Precision: 0.9673 - Recall: 0.9629 - TP: 3246.9500 - TN: 5565.2700 - FP: 81.7300 - FN: 125.0500 - val_loss: 0.1020 - val_Accuracy: 0.9780 - val_Precision: 0.9590 - val_Recall: 0.9530 - val_TP: 766.2300 - val_TN: 1080.1801 - val_FP: 25.8200 - val_FN: 37.7700\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0401 - Accuracy: 0.9881 - Precision: 0.9668 - Recall: 0.9644 - TP: 3251.9800 - TN: 5563.1299 - FP: 83.8700 - FN: 120.0200 - val_loss: 0.1087 - val_Accuracy: 0.9759 - val_Precision: 0.9588 - val_Recall: 0.9505 - val_TP: 764.1700 - val_TN: 1080.2000 - val_FP: 25.8000 - val_FN: 39.8300\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0375 - Accuracy: 0.9870 - Precision: 0.9665 - Recall: 0.9639 - TP: 3250.2900 - TN: 5562.1602 - FP: 84.8400 - FN: 121.7100 - val_loss: 0.1033 - val_Accuracy: 0.9780 - val_Precision: 0.9601 - val_Recall: 0.9518 - val_TP: 765.2600 - val_TN: 1081.1801 - val_FP: 24.8200 - val_FN: 38.7400\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0403 - Accuracy: 0.9882 - Precision: 0.9677 - Recall: 0.9647 - TP: 3253.1001 - TN: 5566.8301 - FP: 80.1700 - FN: 118.9000 - val_loss: 0.1049 - val_Accuracy: 0.9759 - val_Precision: 0.9604 - val_Recall: 0.9504 - val_TP: 764.1000 - val_TN: 1081.4800 - val_FP: 24.5200 - val_FN: 39.9000\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0441 - Accuracy: 0.9874 - Precision: 0.9673 - Recall: 0.9634 - TP: 3248.7000 - TN: 5565.2900 - FP: 81.7100 - FN: 123.3000 - val_loss: 0.1122 - val_Accuracy: 0.9754 - val_Precision: 0.9579 - val_Recall: 0.9502 - val_TP: 763.9900 - val_TN: 1079.3800 - val_FP: 26.6200 - val_FN: 40.0100\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0390 - Accuracy: 0.9880 - Precision: 0.9665 - Recall: 0.9637 - TP: 3249.5500 - TN: 5562.6099 - FP: 84.3900 - FN: 122.4500 - val_loss: 0.1427 - val_Accuracy: 0.9723 - val_Precision: 0.9319 - val_Recall: 0.9535 - val_TP: 766.6000 - val_TN: 1054.8000 - val_FP: 51.2000 - val_FN: 37.4000\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0388 - Accuracy: 0.9881 - Precision: 0.9668 - Recall: 0.9643 - TP: 3251.6699 - TN: 5563.4702 - FP: 83.5300 - FN: 120.3300 - val_loss: 0.1157 - val_Accuracy: 0.9759 - val_Precision: 0.9589 - val_Recall: 0.9498 - val_TP: 763.6400 - val_TN: 1080.3500 - val_FP: 25.6500 - val_FN: 40.3600\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0401 - Accuracy: 0.9880 - Precision: 0.9681 - Recall: 0.9642 - TP: 3251.4199 - TN: 5568.4702 - FP: 78.5300 - FN: 120.5800 - val_loss: 0.1103 - val_Accuracy: 0.9764 - val_Precision: 0.9539 - val_Recall: 0.9546 - val_TP: 767.4900 - val_TN: 1075.8600 - val_FP: 30.1400 - val_FN: 36.5100\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0393 - Accuracy: 0.9871 - Precision: 0.9669 - Recall: 0.9647 - TP: 3253.0901 - TN: 5564.0298 - FP: 82.9700 - FN: 118.9100 - val_loss: 0.1091 - val_Accuracy: 0.9749 - val_Precision: 0.9580 - val_Recall: 0.9513 - val_TP: 764.8800 - val_TN: 1079.5000 - val_FP: 26.5000 - val_FN: 39.1200\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 6ms/step - loss: 0.0463 - Accuracy: 0.9872 - Precision: 0.9658 - Recall: 0.9631 - TP: 3247.4099 - TN: 5559.8101 - FP: 87.1900 - FN: 124.5900 - val_loss: 0.1009 - val_Accuracy: 0.9775 - val_Precision: 0.9630 - val_Recall: 0.9500 - val_TP: 763.7700 - val_TN: 1083.6801 - val_FP: 22.3200 - val_FN: 40.2300\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0372 - Accuracy: 0.9881 - Precision: 0.9668 - Recall: 0.9639 - TP: 3250.1799 - TN: 5563.2900 - FP: 83.7100 - FN: 121.8200 - val_loss: 0.1020 - val_Accuracy: 0.9770 - val_Precision: 0.9650 - val_Recall: 0.9482 - val_TP: 762.3800 - val_TN: 1085.4800 - val_FP: 20.5200 - val_FN: 41.6200\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0426 - Accuracy: 0.9878 - Precision: 0.9667 - Recall: 0.9635 - TP: 3248.9700 - TN: 5563.2500 - FP: 83.7500 - FN: 123.0300 - val_loss: 0.1055 - val_Accuracy: 0.9770 - val_Precision: 0.9588 - val_Recall: 0.9518 - val_TP: 765.2100 - val_TN: 1080.0900 - val_FP: 25.9100 - val_FN: 38.7900\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0355 - Accuracy: 0.9876 - Precision: 0.9671 - Recall: 0.9644 - TP: 3251.8999 - TN: 5564.6201 - FP: 82.3800 - FN: 120.1000 - val_loss: 0.1137 - val_Accuracy: 0.9743 - val_Precision: 0.9567 - val_Recall: 0.9491 - val_TP: 763.1100 - val_TN: 1078.2900 - val_FP: 27.7100 - val_FN: 40.8900\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0493 - Accuracy: 0.9870 - Precision: 0.9660 - Recall: 0.9623 - TP: 3244.7800 - TN: 5560.7700 - FP: 86.2300 - FN: 127.2200 - val_loss: 0.1046 - val_Accuracy: 0.9764 - val_Precision: 0.9579 - val_Recall: 0.9519 - val_TP: 765.3600 - val_TN: 1079.2900 - val_FP: 26.7100 - val_FN: 38.6400\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0448 - Accuracy: 0.9874 - Precision: 0.9657 - Recall: 0.9626 - TP: 3245.9800 - TN: 5559.4800 - FP: 87.5200 - FN: 126.0200 - val_loss: 0.1013 - val_Accuracy: 0.9785 - val_Precision: 0.9619 - val_Recall: 0.9505 - val_TP: 764.1800 - val_TN: 1082.6600 - val_FP: 23.3400 - val_FN: 39.8200\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0427 - Accuracy: 0.9878 - Precision: 0.9668 - Recall: 0.9639 - TP: 3250.2300 - TN: 5563.4702 - FP: 83.5300 - FN: 121.7700 - val_loss: 0.1096 - val_Accuracy: 0.9759 - val_Precision: 0.9530 - val_Recall: 0.9538 - val_TP: 766.8800 - val_TN: 1074.9700 - val_FP: 31.0300 - val_FN: 37.1200\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0366 - Accuracy: 0.9880 - Precision: 0.9669 - Recall: 0.9643 - TP: 3251.7800 - TN: 5563.8901 - FP: 83.1100 - FN: 120.2200 - val_loss: 0.1164 - val_Accuracy: 0.9728 - val_Precision: 0.9614 - val_Recall: 0.9462 - val_TP: 760.7200 - val_TN: 1082.5800 - val_FP: 23.4200 - val_FN: 43.2800\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0460 - Accuracy: 0.9870 - Precision: 0.9661 - Recall: 0.9633 - TP: 3248.1599 - TN: 5561.2300 - FP: 85.7700 - FN: 123.8400 - val_loss: 0.1071 - val_Accuracy: 0.9749 - val_Precision: 0.9621 - val_Recall: 0.9484 - val_TP: 762.5400 - val_TN: 1083.0800 - val_FP: 22.9200 - val_FN: 41.4600\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0405 - Accuracy: 0.9870 - Precision: 0.9663 - Recall: 0.9630 - TP: 3247.0901 - TN: 5561.8398 - FP: 85.1600 - FN: 124.9100 - val_loss: 0.1159 - val_Accuracy: 0.9733 - val_Precision: 0.9532 - val_Recall: 0.9510 - val_TP: 764.5700 - val_TN: 1075.2200 - val_FP: 30.7800 - val_FN: 39.4300\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0396 - Accuracy: 0.9879 - Precision: 0.9676 - Recall: 0.9642 - TP: 3251.2000 - TN: 5566.2598 - FP: 80.7400 - FN: 120.8000 - val_loss: 0.1049 - val_Accuracy: 0.9775 - val_Precision: 0.9568 - val_Recall: 0.9530 - val_TP: 766.2200 - val_TN: 1078.4000 - val_FP: 27.6000 - val_FN: 37.7800\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0496 - Accuracy: 0.9867 - Precision: 0.9656 - Recall: 0.9635 - TP: 3248.8999 - TN: 5559.2598 - FP: 87.7400 - FN: 123.1000 - val_loss: 0.1064 - val_Accuracy: 0.9749 - val_Precision: 0.9674 - val_Recall: 0.9454 - val_TP: 760.1400 - val_TN: 1087.5300 - val_FP: 18.4700 - val_FN: 43.8600\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0370 - Accuracy: 0.9882 - Precision: 0.9683 - Recall: 0.9647 - TP: 3253.0500 - TN: 5568.8101 - FP: 78.1900 - FN: 118.9500 - val_loss: 0.1097 - val_Accuracy: 0.9764 - val_Precision: 0.9606 - val_Recall: 0.9498 - val_TP: 763.6500 - val_TN: 1081.7900 - val_FP: 24.2100 - val_FN: 40.3500\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0395 - Accuracy: 0.9885 - Precision: 0.9672 - Recall: 0.9646 - TP: 3252.6101 - TN: 5565.3501 - FP: 81.6500 - FN: 119.3900 - val_loss: 0.1044 - val_Accuracy: 0.9764 - val_Precision: 0.9656 - val_Recall: 0.9483 - val_TP: 762.4200 - val_TN: 1086.0100 - val_FP: 19.9900 - val_FN: 41.5800\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0354 - Accuracy: 0.9872 - Precision: 0.9670 - Recall: 0.9640 - TP: 3250.5000 - TN: 5564.3501 - FP: 82.6500 - FN: 121.5000 - val_loss: 0.1049 - val_Accuracy: 0.9770 - val_Precision: 0.9614 - val_Recall: 0.9497 - val_TP: 763.5700 - val_TN: 1082.3900 - val_FP: 23.6100 - val_FN: 40.4300\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0359 - Accuracy: 0.9888 - Precision: 0.9684 - Recall: 0.9652 - TP: 3254.6499 - TN: 5569.2202 - FP: 77.7800 - FN: 117.3500 - val_loss: 0.1057 - val_Accuracy: 0.9770 - val_Precision: 0.9625 - val_Recall: 0.9486 - val_TP: 762.7100 - val_TN: 1083.3800 - val_FP: 22.6200 - val_FN: 41.2900\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0507 - Accuracy: 0.9866 - Precision: 0.9659 - Recall: 0.9637 - TP: 3249.6799 - TN: 5560.4600 - FP: 86.5400 - FN: 122.3200 - val_loss: 0.1056 - val_Accuracy: 0.9749 - val_Precision: 0.9659 - val_Recall: 0.9463 - val_TP: 760.8500 - val_TN: 1086.2200 - val_FP: 19.7800 - val_FN: 43.1500\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0463 - Accuracy: 0.9877 - Precision: 0.9672 - Recall: 0.9627 - TP: 3246.2400 - TN: 5565.0698 - FP: 81.9300 - FN: 125.7600 - val_loss: 0.1049 - val_Accuracy: 0.9775 - val_Precision: 0.9600 - val_Recall: 0.9521 - val_TP: 765.4700 - val_TN: 1081.1100 - val_FP: 24.8900 - val_FN: 38.5300\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0366 - Accuracy: 0.9882 - Precision: 0.9672 - Recall: 0.9654 - TP: 3255.4700 - TN: 5564.7402 - FP: 82.2600 - FN: 116.5300 - val_loss: 0.1108 - val_Accuracy: 0.9764 - val_Precision: 0.9592 - val_Recall: 0.9512 - val_TP: 764.7500 - val_TN: 1080.5300 - val_FP: 25.4700 - val_FN: 39.2500\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0477 - Accuracy: 0.9881 - Precision: 0.9675 - Recall: 0.9645 - TP: 3252.2800 - TN: 5566.3999 - FP: 80.6000 - FN: 119.7200 - val_loss: 0.1101 - val_Accuracy: 0.9759 - val_Precision: 0.9618 - val_Recall: 0.9488 - val_TP: 762.8000 - val_TN: 1082.8400 - val_FP: 23.1600 - val_FN: 41.2000\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0418 - Accuracy: 0.9876 - Precision: 0.9671 - Recall: 0.9649 - TP: 3253.5500 - TN: 5565.2500 - FP: 81.7500 - FN: 118.4500 - val_loss: 0.1066 - val_Accuracy: 0.9759 - val_Precision: 0.9638 - val_Recall: 0.9484 - val_TP: 762.5100 - val_TN: 1084.5300 - val_FP: 21.4700 - val_FN: 41.4900\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 5ms/step - loss: 0.0410 - Accuracy: 0.9874 - Precision: 0.9663 - Recall: 0.9635 - TP: 3249.0500 - TN: 5561.9302 - FP: 85.0700 - FN: 122.9500 - val_loss: 0.1011 - val_Accuracy: 0.9775 - val_Precision: 0.9621 - val_Recall: 0.9510 - val_TP: 764.6100 - val_TN: 1082.9600 - val_FP: 23.0400 - val_FN: 39.3900\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0380 - Accuracy: 0.9872 - Precision: 0.9671 - Recall: 0.9643 - TP: 3251.7100 - TN: 5564.2900 - FP: 82.7100 - FN: 120.2900 - val_loss: 0.1031 - val_Accuracy: 0.9749 - val_Precision: 0.9636 - val_Recall: 0.9484 - val_TP: 762.4900 - val_TN: 1084.3300 - val_FP: 21.6700 - val_FN: 41.5100\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0425 - Accuracy: 0.9874 - Precision: 0.9665 - Recall: 0.9633 - TP: 3248.2700 - TN: 5562.3599 - FP: 84.6400 - FN: 123.7300 - val_loss: 0.1062 - val_Accuracy: 0.9764 - val_Precision: 0.9547 - val_Recall: 0.9534 - val_TP: 766.5000 - val_TN: 1076.4301 - val_FP: 29.5700 - val_FN: 37.5000\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0485 - Accuracy: 0.9866 - Precision: 0.9670 - Recall: 0.9633 - TP: 3248.3799 - TN: 5564.4199 - FP: 82.5800 - FN: 123.6200 - val_loss: 0.1027 - val_Accuracy: 0.9770 - val_Precision: 0.9556 - val_Recall: 0.9536 - val_TP: 766.6700 - val_TN: 1077.2500 - val_FP: 28.7500 - val_FN: 37.3300\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0412 - Accuracy: 0.9875 - Precision: 0.9662 - Recall: 0.9638 - TP: 3249.8799 - TN: 5561.5098 - FP: 85.4900 - FN: 122.1200 - val_loss: 0.1023 - val_Accuracy: 0.9764 - val_Precision: 0.9678 - val_Recall: 0.9464 - val_TP: 760.9400 - val_TN: 1087.9100 - val_FP: 18.0900 - val_FN: 43.0600\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0407 - Accuracy: 0.9866 - Precision: 0.9663 - Recall: 0.9631 - TP: 3247.4099 - TN: 5561.7202 - FP: 85.2800 - FN: 124.5900 - val_loss: 0.1074 - val_Accuracy: 0.9754 - val_Precision: 0.9632 - val_Recall: 0.9476 - val_TP: 761.8800 - val_TN: 1084.1000 - val_FP: 21.9000 - val_FN: 42.1200\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0439 - Accuracy: 0.9881 - Precision: 0.9666 - Recall: 0.9635 - TP: 3248.8601 - TN: 5562.5498 - FP: 84.4500 - FN: 123.1400 - val_loss: 0.1083 - val_Accuracy: 0.9759 - val_Precision: 0.9556 - val_Recall: 0.9531 - val_TP: 766.2700 - val_TN: 1077.3300 - val_FP: 28.6700 - val_FN: 37.7300\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0350 - Accuracy: 0.9885 - Precision: 0.9679 - Recall: 0.9646 - TP: 3252.5500 - TN: 5567.6099 - FP: 79.3900 - FN: 119.4500 - val_loss: 0.1039 - val_Accuracy: 0.9770 - val_Precision: 0.9588 - val_Recall: 0.9520 - val_TP: 765.4300 - val_TN: 1080.1700 - val_FP: 25.8300 - val_FN: 38.5700\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0393 - Accuracy: 0.9875 - Precision: 0.9669 - Recall: 0.9639 - TP: 3250.1899 - TN: 5564.1602 - FP: 82.8400 - FN: 121.8100 - val_loss: 0.1460 - val_Accuracy: 0.9471 - val_Precision: 0.9203 - val_Recall: 0.9528 - val_TP: 766.0900 - val_TN: 1044.8000 - val_FP: 61.2000 - val_FN: 37.9100\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0480 - Accuracy: 0.9880 - Precision: 0.9661 - Recall: 0.9640 - TP: 3250.6201 - TN: 5560.9502 - FP: 86.0500 - FN: 121.3800 - val_loss: 0.1174 - val_Accuracy: 0.9728 - val_Precision: 0.9580 - val_Recall: 0.9476 - val_TP: 761.9100 - val_TN: 1079.5100 - val_FP: 26.4900 - val_FN: 42.0900\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0413 - Accuracy: 0.9881 - Precision: 0.9682 - Recall: 0.9635 - TP: 3249.0200 - TN: 5568.7700 - FP: 78.2300 - FN: 122.9800 - val_loss: 0.1140 - val_Accuracy: 0.9743 - val_Precision: 0.9491 - val_Recall: 0.9562 - val_TP: 768.8200 - val_TN: 1071.4800 - val_FP: 34.5200 - val_FN: 35.1800\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0452 - Accuracy: 0.9874 - Precision: 0.9661 - Recall: 0.9644 - TP: 3252.0500 - TN: 5561.1699 - FP: 85.8300 - FN: 119.9500 - val_loss: 0.1053 - val_Accuracy: 0.9759 - val_Precision: 0.9610 - val_Recall: 0.9502 - val_TP: 763.9700 - val_TN: 1082.0601 - val_FP: 23.9400 - val_FN: 40.0300\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0464 - Accuracy: 0.9863 - Precision: 0.9649 - Recall: 0.9628 - TP: 3246.4099 - TN: 5556.7002 - FP: 90.3000 - FN: 125.5900 - val_loss: 0.1087 - val_Accuracy: 0.9743 - val_Precision: 0.9685 - val_Recall: 0.9443 - val_TP: 759.1800 - val_TN: 1088.5699 - val_FP: 17.4300 - val_FN: 44.8200\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0609 - Accuracy: 0.9867 - Precision: 0.9656 - Recall: 0.9617 - TP: 3242.9500 - TN: 5559.8901 - FP: 87.1100 - FN: 129.0500 - val_loss: 0.1062 - val_Accuracy: 0.9754 - val_Precision: 0.9601 - val_Recall: 0.9508 - val_TP: 764.4300 - val_TN: 1081.2800 - val_FP: 24.7200 - val_FN: 39.5700\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0450 - Accuracy: 0.9871 - Precision: 0.9657 - Recall: 0.9634 - TP: 3248.7300 - TN: 5559.8198 - FP: 87.1800 - FN: 123.2700 - val_loss: 0.1064 - val_Accuracy: 0.9764 - val_Precision: 0.9670 - val_Recall: 0.9466 - val_TP: 761.0700 - val_TN: 1087.2400 - val_FP: 18.7600 - val_FN: 42.9300\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0456 - Accuracy: 0.9877 - Precision: 0.9673 - Recall: 0.9640 - TP: 3250.6299 - TN: 5565.7598 - FP: 81.2400 - FN: 121.3700 - val_loss: 0.1078 - val_Accuracy: 0.9749 - val_Precision: 0.9591 - val_Recall: 0.9515 - val_TP: 764.9900 - val_TN: 1080.5300 - val_FP: 25.4700 - val_FN: 39.0100\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0391 - Accuracy: 0.9878 - Precision: 0.9673 - Recall: 0.9645 - TP: 3252.4099 - TN: 5565.3101 - FP: 81.6900 - FN: 119.5900 - val_loss: 0.1057 - val_Accuracy: 0.9780 - val_Precision: 0.9635 - val_Recall: 0.9490 - val_TP: 763.0300 - val_TN: 1084.2100 - val_FP: 21.7900 - val_FN: 40.9700\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0415 - Accuracy: 0.9866 - Precision: 0.9675 - Recall: 0.9644 - TP: 3252.0200 - TN: 5566.3599 - FP: 80.6400 - FN: 119.9800 - val_loss: 0.1093 - val_Accuracy: 0.9764 - val_Precision: 0.9608 - val_Recall: 0.9496 - val_TP: 763.4500 - val_TN: 1081.9900 - val_FP: 24.0100 - val_FN: 40.5500\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0516 - Accuracy: 0.9869 - Precision: 0.9664 - Recall: 0.9636 - TP: 3249.3899 - TN: 5562.6401 - FP: 84.3600 - FN: 122.6100 - val_loss: 0.1140 - val_Accuracy: 0.9759 - val_Precision: 0.9588 - val_Recall: 0.9498 - val_TP: 763.6400 - val_TN: 1080.1801 - val_FP: 25.8200 - val_FN: 40.3600\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0429 - Accuracy: 0.9866 - Precision: 0.9664 - Recall: 0.9630 - TP: 3247.1201 - TN: 5562.4302 - FP: 84.5700 - FN: 124.8800 - val_loss: 0.1063 - val_Accuracy: 0.9775 - val_Precision: 0.9630 - val_Recall: 0.9494 - val_TP: 763.2900 - val_TN: 1083.7800 - val_FP: 22.2200 - val_FN: 40.7100\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0418 - Accuracy: 0.9874 - Precision: 0.9668 - Recall: 0.9643 - TP: 3251.5200 - TN: 5563.6602 - FP: 83.3400 - FN: 120.4800 - val_loss: 0.1067 - val_Accuracy: 0.9770 - val_Precision: 0.9593 - val_Recall: 0.9519 - val_TP: 765.3400 - val_TN: 1080.5500 - val_FP: 25.4500 - val_FN: 38.6600\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 5ms/step - loss: 0.0401 - Accuracy: 0.9872 - Precision: 0.9664 - Recall: 0.9637 - TP: 3249.5400 - TN: 5562.6201 - FP: 84.3800 - FN: 122.4600 - val_loss: 0.1015 - val_Accuracy: 0.9775 - val_Precision: 0.9638 - val_Recall: 0.9499 - val_TP: 763.7100 - val_TN: 1084.4000 - val_FP: 21.6000 - val_FN: 40.2900\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0395 - Accuracy: 0.9865 - Precision: 0.9665 - Recall: 0.9625 - TP: 3245.6599 - TN: 5562.5000 - FP: 84.5000 - FN: 126.3400 - val_loss: 0.1159 - val_Accuracy: 0.9733 - val_Precision: 0.9532 - val_Recall: 0.9512 - val_TP: 764.7900 - val_TN: 1075.1801 - val_FP: 30.8200 - val_FN: 39.2100\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0557 - Accuracy: 0.9863 - Precision: 0.9654 - Recall: 0.9630 - TP: 3247.2900 - TN: 5558.7500 - FP: 88.2500 - FN: 124.7100 - val_loss: 0.1042 - val_Accuracy: 0.9775 - val_Precision: 0.9553 - val_Recall: 0.9539 - val_TP: 766.9100 - val_TN: 1076.9600 - val_FP: 29.0400 - val_FN: 37.0900\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0357 - Accuracy: 0.9877 - Precision: 0.9667 - Recall: 0.9646 - TP: 3252.4800 - TN: 5563.3701 - FP: 83.6300 - FN: 119.5200 - val_loss: 0.1045 - val_Accuracy: 0.9764 - val_Precision: 0.9585 - val_Recall: 0.9517 - val_TP: 765.1700 - val_TN: 1079.9200 - val_FP: 26.0800 - val_FN: 38.8300\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0470 - Accuracy: 0.9879 - Precision: 0.9664 - Recall: 0.9637 - TP: 3249.6599 - TN: 5562.2300 - FP: 84.7700 - FN: 122.3400 - val_loss: 0.1083 - val_Accuracy: 0.9743 - val_Precision: 0.9619 - val_Recall: 0.9486 - val_TP: 762.6900 - val_TN: 1082.9800 - val_FP: 23.0200 - val_FN: 41.3100\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0590 - Accuracy: 0.9858 - Precision: 0.9658 - Recall: 0.9615 - TP: 3242.0601 - TN: 5560.5000 - FP: 86.5000 - FN: 129.9400 - val_loss: 0.0998 - val_Accuracy: 0.9780 - val_Precision: 0.9614 - val_Recall: 0.9522 - val_TP: 765.5700 - val_TN: 1082.2800 - val_FP: 23.7200 - val_FN: 38.4300\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0487 - Accuracy: 0.9866 - Precision: 0.9652 - Recall: 0.9629 - TP: 3246.8301 - TN: 5557.9302 - FP: 89.0700 - FN: 125.1700 - val_loss: 0.1035 - val_Accuracy: 0.9759 - val_Precision: 0.9619 - val_Recall: 0.9496 - val_TP: 763.4600 - val_TN: 1082.8300 - val_FP: 23.1700 - val_FN: 40.5400\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0354 - Accuracy: 0.9880 - Precision: 0.9673 - Recall: 0.9636 - TP: 3249.3101 - TN: 5565.2998 - FP: 81.7000 - FN: 122.6900 - val_loss: 0.1023 - val_Accuracy: 0.9775 - val_Precision: 0.9571 - val_Recall: 0.9534 - val_TP: 766.5600 - val_TN: 1078.5000 - val_FP: 27.5000 - val_FN: 37.4400\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0445 - Accuracy: 0.9867 - Precision: 0.9656 - Recall: 0.9634 - TP: 3248.5200 - TN: 5559.1001 - FP: 87.9000 - FN: 123.4800 - val_loss: 0.1063 - val_Accuracy: 0.9754 - val_Precision: 0.9683 - val_Recall: 0.9451 - val_TP: 759.8800 - val_TN: 1088.3600 - val_FP: 17.6400 - val_FN: 44.1200\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0383 - Accuracy: 0.9868 - Precision: 0.9672 - Recall: 0.9638 - TP: 3249.7800 - TN: 5565.1602 - FP: 81.8400 - FN: 122.2200 - val_loss: 0.1063 - val_Accuracy: 0.9770 - val_Precision: 0.9583 - val_Recall: 0.9521 - val_TP: 765.4600 - val_TN: 1079.6600 - val_FP: 26.3400 - val_FN: 38.5400\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0394 - Accuracy: 0.9874 - Precision: 0.9667 - Recall: 0.9638 - TP: 3249.9500 - TN: 5563.3301 - FP: 83.6700 - FN: 122.0500 - val_loss: 0.1121 - val_Accuracy: 0.9770 - val_Precision: 0.9532 - val_Recall: 0.9539 - val_TP: 766.9700 - val_TN: 1075.1500 - val_FP: 30.8500 - val_FN: 37.0300\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0398 - Accuracy: 0.9875 - Precision: 0.9663 - Recall: 0.9641 - TP: 3251.1001 - TN: 5562.0000 - FP: 85.0000 - FN: 120.9000 - val_loss: 0.1138 - val_Accuracy: 0.9743 - val_Precision: 0.9626 - val_Recall: 0.9471 - val_TP: 761.4900 - val_TN: 1083.5200 - val_FP: 22.4800 - val_FN: 42.5100\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0425 - Accuracy: 0.9865 - Precision: 0.9664 - Recall: 0.9630 - TP: 3247.3201 - TN: 5562.4800 - FP: 84.5200 - FN: 124.6800 - val_loss: 0.1094 - val_Accuracy: 0.9764 - val_Precision: 0.9612 - val_Recall: 0.9494 - val_TP: 763.3300 - val_TN: 1082.3500 - val_FP: 23.6500 - val_FN: 40.6700\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0435 - Accuracy: 0.9872 - Precision: 0.9667 - Recall: 0.9638 - TP: 3249.9099 - TN: 5563.5400 - FP: 83.4600 - FN: 122.0900 - val_loss: 0.1051 - val_Accuracy: 0.9759 - val_Precision: 0.9668 - val_Recall: 0.9472 - val_TP: 761.5200 - val_TN: 1087.0100 - val_FP: 18.9900 - val_FN: 42.4800\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0428 - Accuracy: 0.9874 - Precision: 0.9663 - Recall: 0.9646 - TP: 3252.6399 - TN: 5561.7998 - FP: 85.2000 - FN: 119.3600 - val_loss: 0.1153 - val_Accuracy: 0.9743 - val_Precision: 0.9626 - val_Recall: 0.9468 - val_TP: 761.2200 - val_TN: 1083.5400 - val_FP: 22.4600 - val_FN: 42.7800\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0440 - Accuracy: 0.9863 - Precision: 0.9667 - Recall: 0.9637 - TP: 3249.5701 - TN: 5563.6401 - FP: 83.3600 - FN: 122.4300 - val_loss: 0.1096 - val_Accuracy: 0.9759 - val_Precision: 0.9711 - val_Recall: 0.9423 - val_TP: 757.6100 - val_TN: 1090.7300 - val_FP: 15.2700 - val_FN: 46.3900\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0460 - Accuracy: 0.9866 - Precision: 0.9665 - Recall: 0.9629 - TP: 3246.8401 - TN: 5562.7798 - FP: 84.2200 - FN: 125.1600 - val_loss: 0.1063 - val_Accuracy: 0.9770 - val_Precision: 0.9577 - val_Recall: 0.9529 - val_TP: 766.1600 - val_TN: 1079.1700 - val_FP: 26.8300 - val_FN: 37.8400\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0424 - Accuracy: 0.9876 - Precision: 0.9669 - Recall: 0.9638 - TP: 3249.7800 - TN: 5563.9902 - FP: 83.0100 - FN: 122.2200 - val_loss: 0.1053 - val_Accuracy: 0.9785 - val_Precision: 0.9625 - val_Recall: 0.9517 - val_TP: 765.1400 - val_TN: 1083.3300 - val_FP: 22.6700 - val_FN: 38.8600\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0380 - Accuracy: 0.9879 - Precision: 0.9673 - Recall: 0.9652 - TP: 3254.6299 - TN: 5565.2798 - FP: 81.7200 - FN: 117.3700 - val_loss: 0.1153 - val_Accuracy: 0.9749 - val_Precision: 0.9598 - val_Recall: 0.9487 - val_TP: 762.7300 - val_TN: 1081.1200 - val_FP: 24.8800 - val_FN: 41.2700\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0421 - Accuracy: 0.9870 - Precision: 0.9665 - Recall: 0.9637 - TP: 3249.6799 - TN: 5562.8198 - FP: 84.1800 - FN: 122.3200 - val_loss: 0.1072 - val_Accuracy: 0.9759 - val_Precision: 0.9655 - val_Recall: 0.9473 - val_TP: 761.6400 - val_TN: 1085.9399 - val_FP: 20.0600 - val_FN: 42.3600\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0573 - Accuracy: 0.9874 - Precision: 0.9668 - Recall: 0.9637 - TP: 3249.7300 - TN: 5564.0298 - FP: 82.9700 - FN: 122.2700 - val_loss: 0.1159 - val_Accuracy: 0.9754 - val_Precision: 0.9582 - val_Recall: 0.9503 - val_TP: 764.0700 - val_TN: 1079.6899 - val_FP: 26.3100 - val_FN: 39.9300\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0437 - Accuracy: 0.9867 - Precision: 0.9672 - Recall: 0.9632 - TP: 3248.0300 - TN: 5565.7202 - FP: 81.2800 - FN: 123.9700 - val_loss: 0.1064 - val_Accuracy: 0.9764 - val_Precision: 0.9555 - val_Recall: 0.9541 - val_TP: 767.0900 - val_TN: 1077.2200 - val_FP: 28.7800 - val_FN: 36.9100\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0370 - Accuracy: 0.9882 - Precision: 0.9673 - Recall: 0.9651 - TP: 3254.2000 - TN: 5565.5601 - FP: 81.4400 - FN: 117.8000 - val_loss: 0.1110 - val_Accuracy: 0.9764 - val_Precision: 0.9597 - val_Recall: 0.9511 - val_TP: 764.6600 - val_TN: 1081.0100 - val_FP: 24.9900 - val_FN: 39.3400\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0380 - Accuracy: 0.9881 - Precision: 0.9669 - Recall: 0.9656 - TP: 3256.1399 - TN: 5564.2100 - FP: 82.7900 - FN: 115.8600 - val_loss: 0.1104 - val_Accuracy: 0.9759 - val_Precision: 0.9698 - val_Recall: 0.9440 - val_TP: 758.9900 - val_TN: 1089.6700 - val_FP: 16.3300 - val_FN: 45.0100\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0595 - Accuracy: 0.9866 - Precision: 0.9660 - Recall: 0.9624 - TP: 3245.1699 - TN: 5561.3101 - FP: 85.6900 - FN: 126.8300 - val_loss: 0.1108 - val_Accuracy: 0.9770 - val_Precision: 0.9622 - val_Recall: 0.9489 - val_TP: 762.8800 - val_TN: 1083.2100 - val_FP: 22.7900 - val_FN: 41.1200\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0385 - Accuracy: 0.9875 - Precision: 0.9679 - Recall: 0.9652 - TP: 3254.6499 - TN: 5567.7998 - FP: 79.2000 - FN: 117.3500 - val_loss: 0.1083 - val_Accuracy: 0.9759 - val_Precision: 0.9603 - val_Recall: 0.9511 - val_TP: 764.6600 - val_TN: 1081.5000 - val_FP: 24.5000 - val_FN: 39.3400\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 5s 14ms/step - loss: 0.0455 - Accuracy: 0.9864 - Precision: 0.9649 - Recall: 0.9621 - TP: 3244.0701 - TN: 5556.8101 - FP: 90.1900 - FN: 127.9300 - val_loss: 0.1129 - val_Accuracy: 0.9749 - val_Precision: 0.9556 - val_Recall: 0.9508 - val_TP: 764.4400 - val_TN: 1077.3700 - val_FP: 28.6300 - val_FN: 39.5600\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0495 - Accuracy: 0.9871 - Precision: 0.9658 - Recall: 0.9629 - TP: 3247.0500 - TN: 5560.1499 - FP: 86.8500 - FN: 124.9500 - val_loss: 0.1061 - val_Accuracy: 0.9749 - val_Precision: 0.9692 - val_Recall: 0.9440 - val_TP: 758.9900 - val_TN: 1089.1000 - val_FP: 16.9000 - val_FN: 45.0100\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0448 - Accuracy: 0.9875 - Precision: 0.9679 - Recall: 0.9631 - TP: 3247.6499 - TN: 5567.5601 - FP: 79.4400 - FN: 124.3500 - val_loss: 0.1014 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9516 - val_TP: 765.1200 - val_TN: 1082.5200 - val_FP: 23.4800 - val_FN: 38.8800\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0476 - Accuracy: 0.9874 - Precision: 0.9654 - Recall: 0.9637 - TP: 3249.5500 - TN: 5558.6899 - FP: 88.3100 - FN: 122.4500 - val_loss: 0.1159 - val_Accuracy: 0.9733 - val_Precision: 0.9513 - val_Recall: 0.9518 - val_TP: 765.2800 - val_TN: 1073.6600 - val_FP: 32.3400 - val_FN: 38.7200\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0477 - Accuracy: 0.9876 - Precision: 0.9659 - Recall: 0.9633 - TP: 3248.3999 - TN: 5560.6499 - FP: 86.3500 - FN: 123.6000 - val_loss: 0.1039 - val_Accuracy: 0.9759 - val_Precision: 0.9643 - val_Recall: 0.9485 - val_TP: 762.5900 - val_TN: 1084.9100 - val_FP: 21.0900 - val_FN: 41.4100\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0402 - Accuracy: 0.9884 - Precision: 0.9674 - Recall: 0.9642 - TP: 3251.1299 - TN: 5566.1099 - FP: 80.8900 - FN: 120.8700 - val_loss: 0.1026 - val_Accuracy: 0.9780 - val_Precision: 0.9615 - val_Recall: 0.9519 - val_TP: 765.3000 - val_TN: 1082.4000 - val_FP: 23.6000 - val_FN: 38.7000\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0422 - Accuracy: 0.9875 - Precision: 0.9664 - Recall: 0.9640 - TP: 3250.7600 - TN: 5562.2998 - FP: 84.7000 - FN: 121.2400 - val_loss: 0.1062 - val_Accuracy: 0.9759 - val_Precision: 0.9685 - val_Recall: 0.9453 - val_TP: 760.0300 - val_TN: 1088.4600 - val_FP: 17.5400 - val_FN: 43.9700\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0383 - Accuracy: 0.9876 - Precision: 0.9670 - Recall: 0.9636 - TP: 3249.2900 - TN: 5564.2300 - FP: 82.7700 - FN: 122.7100 - val_loss: 0.1091 - val_Accuracy: 0.9743 - val_Precision: 0.9623 - val_Recall: 0.9480 - val_TP: 762.1700 - val_TN: 1083.2700 - val_FP: 22.7300 - val_FN: 41.8300\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0418 - Accuracy: 0.9880 - Precision: 0.9668 - Recall: 0.9648 - TP: 3253.4299 - TN: 5563.6401 - FP: 83.3600 - FN: 118.5700 - val_loss: 0.1199 - val_Accuracy: 0.9728 - val_Precision: 0.9631 - val_Recall: 0.9448 - val_TP: 759.6200 - val_TN: 1084.0800 - val_FP: 21.9200 - val_FN: 44.3800\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0391 - Accuracy: 0.9869 - Precision: 0.9670 - Recall: 0.9630 - TP: 3247.3799 - TN: 5564.4399 - FP: 82.5600 - FN: 124.6200 - val_loss: 0.1121 - val_Accuracy: 0.9754 - val_Precision: 0.9575 - val_Recall: 0.9517 - val_TP: 765.1900 - val_TN: 1079.0300 - val_FP: 26.9700 - val_FN: 38.8100\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0412 - Accuracy: 0.9867 - Precision: 0.9668 - Recall: 0.9638 - TP: 3250.0200 - TN: 5563.8501 - FP: 83.1500 - FN: 121.9800 - val_loss: 0.1050 - val_Accuracy: 0.9780 - val_Precision: 0.9590 - val_Recall: 0.9527 - val_TP: 765.9900 - val_TN: 1080.1700 - val_FP: 25.8300 - val_FN: 38.0100\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0422 - Accuracy: 0.9867 - Precision: 0.9671 - Recall: 0.9638 - TP: 3250.0400 - TN: 5564.9102 - FP: 82.0900 - FN: 121.9600 - val_loss: 0.1057 - val_Accuracy: 0.9775 - val_Precision: 0.9615 - val_Recall: 0.9507 - val_TP: 764.3600 - val_TN: 1082.4200 - val_FP: 23.5800 - val_FN: 39.6400\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0568 - Accuracy: 0.9876 - Precision: 0.9662 - Recall: 0.9638 - TP: 3250.0400 - TN: 5561.7998 - FP: 85.2000 - FN: 121.9600 - val_loss: 0.1074 - val_Accuracy: 0.9759 - val_Precision: 0.9598 - val_Recall: 0.9515 - val_TP: 765.0100 - val_TN: 1081.0100 - val_FP: 24.9900 - val_FN: 38.9900\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0357 - Accuracy: 0.9882 - Precision: 0.9679 - Recall: 0.9654 - TP: 3255.2900 - TN: 5567.9302 - FP: 79.0700 - FN: 116.7100 - val_loss: 0.1165 - val_Accuracy: 0.9749 - val_Precision: 0.9582 - val_Recall: 0.9499 - val_TP: 763.7000 - val_TN: 1079.7400 - val_FP: 26.2600 - val_FN: 40.3000\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0424 - Accuracy: 0.9876 - Precision: 0.9677 - Recall: 0.9647 - TP: 3253.1101 - TN: 5567.2402 - FP: 79.7600 - FN: 118.8900 - val_loss: 0.1114 - val_Accuracy: 0.9754 - val_Precision: 0.9584 - val_Recall: 0.9514 - val_TP: 764.9600 - val_TN: 1079.8600 - val_FP: 26.1400 - val_FN: 39.0400\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0413 - Accuracy: 0.9882 - Precision: 0.9673 - Recall: 0.9651 - TP: 3254.2300 - TN: 5565.6099 - FP: 81.3900 - FN: 117.7700 - val_loss: 0.1193 - val_Accuracy: 0.9754 - val_Precision: 0.9580 - val_Recall: 0.9497 - val_TP: 763.5700 - val_TN: 1079.6400 - val_FP: 26.3600 - val_FN: 40.4300\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0472 - Accuracy: 0.9884 - Precision: 0.9672 - Recall: 0.9637 - TP: 3249.6799 - TN: 5565.3901 - FP: 81.6100 - FN: 122.3200 - val_loss: 0.1211 - val_Accuracy: 0.9728 - val_Precision: 0.9593 - val_Recall: 0.9470 - val_TP: 761.3500 - val_TN: 1080.8101 - val_FP: 25.1900 - val_FN: 42.6500\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0400 - Accuracy: 0.9880 - Precision: 0.9669 - Recall: 0.9645 - TP: 3252.3999 - TN: 5564.0000 - FP: 83.0000 - FN: 119.6000 - val_loss: 0.1286 - val_Accuracy: 0.9733 - val_Precision: 0.9513 - val_Recall: 0.9494 - val_TP: 763.3300 - val_TN: 1073.4200 - val_FP: 32.5800 - val_FN: 40.6700\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0581 - Accuracy: 0.9874 - Precision: 0.9665 - Recall: 0.9641 - TP: 3250.9500 - TN: 5563.2700 - FP: 83.7300 - FN: 121.0500 - val_loss: 0.1076 - val_Accuracy: 0.9764 - val_Precision: 0.9622 - val_Recall: 0.9500 - val_TP: 763.7600 - val_TN: 1083.1000 - val_FP: 22.9000 - val_FN: 40.2400\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0385 - Accuracy: 0.9881 - Precision: 0.9682 - Recall: 0.9652 - TP: 3254.6599 - TN: 5568.7300 - FP: 78.2700 - FN: 117.3400 - val_loss: 0.1354 - val_Accuracy: 0.9717 - val_Precision: 0.9420 - val_Recall: 0.9509 - val_TP: 764.5600 - val_TN: 1064.7500 - val_FP: 41.2500 - val_FN: 39.4400\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0562 - Accuracy: 0.9867 - Precision: 0.9656 - Recall: 0.9637 - TP: 3249.7500 - TN: 5559.7002 - FP: 87.3000 - FN: 122.2500 - val_loss: 0.1110 - val_Accuracy: 0.9759 - val_Precision: 0.9700 - val_Recall: 0.9436 - val_TP: 758.6400 - val_TN: 1089.8199 - val_FP: 16.1800 - val_FN: 45.3600\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0694 - Accuracy: 0.9868 - Precision: 0.9667 - Recall: 0.9622 - TP: 3244.7000 - TN: 5563.9399 - FP: 83.0600 - FN: 127.3000 - val_loss: 0.1305 - val_Accuracy: 0.9738 - val_Precision: 0.9405 - val_Recall: 0.9557 - val_TP: 768.4000 - val_TN: 1063.5601 - val_FP: 42.4400 - val_FN: 35.6000\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0416 - Accuracy: 0.9875 - Precision: 0.9675 - Recall: 0.9645 - TP: 3252.3999 - TN: 5566.5200 - FP: 80.4800 - FN: 119.6000 - val_loss: 0.1119 - val_Accuracy: 0.9754 - val_Precision: 0.9495 - val_Recall: 0.9575 - val_TP: 769.7900 - val_TN: 1071.8400 - val_FP: 34.1600 - val_FN: 34.2100\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0512 - Accuracy: 0.9871 - Precision: 0.9660 - Recall: 0.9627 - TP: 3246.1399 - TN: 5561.1802 - FP: 85.8200 - FN: 125.8600 - val_loss: 0.1109 - val_Accuracy: 0.9754 - val_Precision: 0.9580 - val_Recall: 0.9511 - val_TP: 764.6800 - val_TN: 1079.5000 - val_FP: 26.5000 - val_FN: 39.3200\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0404 - Accuracy: 0.9869 - Precision: 0.9665 - Recall: 0.9641 - TP: 3250.8401 - TN: 5562.7900 - FP: 84.2100 - FN: 121.1600 - val_loss: 0.1035 - val_Accuracy: 0.9770 - val_Precision: 0.9615 - val_Recall: 0.9505 - val_TP: 764.2100 - val_TN: 1082.3700 - val_FP: 23.6300 - val_FN: 39.7900\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0484 - Accuracy: 0.9866 - Precision: 0.9663 - Recall: 0.9629 - TP: 3246.8999 - TN: 5562.0400 - FP: 84.9600 - FN: 125.1000 - val_loss: 0.1057 - val_Accuracy: 0.9770 - val_Precision: 0.9571 - val_Recall: 0.9532 - val_TP: 766.3500 - val_TN: 1078.6500 - val_FP: 27.3500 - val_FN: 37.6500\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0716 - Accuracy: 0.9864 - Precision: 0.9655 - Recall: 0.9632 - TP: 3247.7600 - TN: 5559.3301 - FP: 87.6700 - FN: 124.2400 - val_loss: 0.1042 - val_Accuracy: 0.9780 - val_Precision: 0.9563 - val_Recall: 0.9548 - val_TP: 767.6300 - val_TN: 1077.8000 - val_FP: 28.2000 - val_FN: 36.3700\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0411 - Accuracy: 0.9870 - Precision: 0.9670 - Recall: 0.9646 - TP: 3252.7600 - TN: 5564.5698 - FP: 82.4300 - FN: 119.2400 - val_loss: 0.1085 - val_Accuracy: 0.9754 - val_Precision: 0.9626 - val_Recall: 0.9480 - val_TP: 762.2200 - val_TN: 1083.4700 - val_FP: 22.5300 - val_FN: 41.7800\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0531 - Accuracy: 0.9867 - Precision: 0.9664 - Recall: 0.9631 - TP: 3247.4399 - TN: 5562.4702 - FP: 84.5300 - FN: 124.5600 - val_loss: 0.1121 - val_Accuracy: 0.9759 - val_Precision: 0.9574 - val_Recall: 0.9514 - val_TP: 764.9200 - val_TN: 1078.9600 - val_FP: 27.0400 - val_FN: 39.0800\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0400 - Accuracy: 0.9875 - Precision: 0.9672 - Recall: 0.9649 - TP: 3253.7500 - TN: 5565.1699 - FP: 81.8300 - FN: 118.2500 - val_loss: 0.1223 - val_Accuracy: 0.9738 - val_Precision: 0.9562 - val_Recall: 0.9489 - val_TP: 762.8900 - val_TN: 1078.0800 - val_FP: 27.9200 - val_FN: 41.1100\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0436 - Accuracy: 0.9869 - Precision: 0.9665 - Recall: 0.9633 - TP: 3248.4099 - TN: 5563.0801 - FP: 83.9200 - FN: 123.5900 - val_loss: 0.1072 - val_Accuracy: 0.9759 - val_Precision: 0.9611 - val_Recall: 0.9502 - val_TP: 763.9400 - val_TN: 1082.1500 - val_FP: 23.8500 - val_FN: 40.0600\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0393 - Accuracy: 0.9882 - Precision: 0.9674 - Recall: 0.9643 - TP: 3251.5100 - TN: 5565.7700 - FP: 81.2300 - FN: 120.4900 - val_loss: 0.1124 - val_Accuracy: 0.9764 - val_Precision: 0.9603 - val_Recall: 0.9502 - val_TP: 763.9400 - val_TN: 1081.5300 - val_FP: 24.4700 - val_FN: 40.0600\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0411 - Accuracy: 0.9877 - Precision: 0.9675 - Recall: 0.9642 - TP: 3251.3999 - TN: 5566.3198 - FP: 80.6800 - FN: 120.6000 - val_loss: 0.1084 - val_Accuracy: 0.9754 - val_Precision: 0.9570 - val_Recall: 0.9525 - val_TP: 765.8400 - val_TN: 1078.5300 - val_FP: 27.4700 - val_FN: 38.1600\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0390 - Accuracy: 0.9874 - Precision: 0.9655 - Recall: 0.9645 - TP: 3252.2200 - TN: 5559.0200 - FP: 87.9800 - FN: 119.7800 - val_loss: 0.1091 - val_Accuracy: 0.9754 - val_Precision: 0.9677 - val_Recall: 0.9460 - val_TP: 760.5700 - val_TN: 1087.8199 - val_FP: 18.1800 - val_FN: 43.4300\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0600 - Accuracy: 0.9872 - Precision: 0.9662 - Recall: 0.9626 - TP: 3245.7600 - TN: 5561.6499 - FP: 85.3500 - FN: 126.2400 - val_loss: 0.1176 - val_Accuracy: 0.9738 - val_Precision: 0.9586 - val_Recall: 0.9490 - val_TP: 762.9600 - val_TN: 1080.0699 - val_FP: 25.9300 - val_FN: 41.0400\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0442 - Accuracy: 0.9876 - Precision: 0.9678 - Recall: 0.9642 - TP: 3251.1499 - TN: 5567.6802 - FP: 79.3200 - FN: 120.8500 - val_loss: 0.1065 - val_Accuracy: 0.9770 - val_Precision: 0.9637 - val_Recall: 0.9498 - val_TP: 763.6700 - val_TN: 1084.3900 - val_FP: 21.6100 - val_FN: 40.3300\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0449 - Accuracy: 0.9878 - Precision: 0.9666 - Recall: 0.9646 - TP: 3252.5801 - TN: 5563.2002 - FP: 83.8000 - FN: 119.4200 - val_loss: 0.1105 - val_Accuracy: 0.9754 - val_Precision: 0.9618 - val_Recall: 0.9490 - val_TP: 762.9700 - val_TN: 1082.8900 - val_FP: 23.1100 - val_FN: 41.0300\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0392 - Accuracy: 0.9876 - Precision: 0.9673 - Recall: 0.9643 - TP: 3251.7100 - TN: 5565.8999 - FP: 81.1000 - FN: 120.2900 - val_loss: 0.1231 - val_Accuracy: 0.9738 - val_Precision: 0.9590 - val_Recall: 0.9476 - val_TP: 761.8600 - val_TN: 1080.5800 - val_FP: 25.4200 - val_FN: 42.1400\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0467 - Accuracy: 0.9879 - Precision: 0.9669 - Recall: 0.9645 - TP: 3252.2900 - TN: 5564.0698 - FP: 82.9300 - FN: 119.7100 - val_loss: 0.1100 - val_Accuracy: 0.9754 - val_Precision: 0.9589 - val_Recall: 0.9512 - val_TP: 764.7500 - val_TN: 1080.2700 - val_FP: 25.7300 - val_FN: 39.2500\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0388 - Accuracy: 0.9875 - Precision: 0.9682 - Recall: 0.9641 - TP: 3251.1101 - TN: 5568.9600 - FP: 78.0400 - FN: 120.8900 - val_loss: 0.1072 - val_Accuracy: 0.9780 - val_Precision: 0.9565 - val_Recall: 0.9545 - val_TP: 767.4000 - val_TN: 1078.0100 - val_FP: 27.9900 - val_FN: 36.6000\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0416 - Accuracy: 0.9871 - Precision: 0.9666 - Recall: 0.9646 - TP: 3252.6201 - TN: 5563.2598 - FP: 83.7400 - FN: 119.3800 - val_loss: 0.1111 - val_Accuracy: 0.9743 - val_Precision: 0.9596 - val_Recall: 0.9501 - val_TP: 763.8800 - val_TN: 1080.9200 - val_FP: 25.0800 - val_FN: 40.1200\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0375 - Accuracy: 0.9885 - Precision: 0.9687 - Recall: 0.9653 - TP: 3255.1499 - TN: 5570.6201 - FP: 76.3800 - FN: 116.8500 - val_loss: 0.1101 - val_Accuracy: 0.9770 - val_Precision: 0.9553 - val_Recall: 0.9546 - val_TP: 767.4700 - val_TN: 1077.0900 - val_FP: 28.9100 - val_FN: 36.5300\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0634 - Accuracy: 0.9868 - Precision: 0.9658 - Recall: 0.9647 - TP: 3252.8799 - TN: 5560.3901 - FP: 86.6100 - FN: 119.1200 - val_loss: 0.1112 - val_Accuracy: 0.9754 - val_Precision: 0.9642 - val_Recall: 0.9470 - val_TP: 761.4100 - val_TN: 1084.8800 - val_FP: 21.1200 - val_FN: 42.5900\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0390 - Accuracy: 0.9881 - Precision: 0.9684 - Recall: 0.9648 - TP: 3253.2700 - TN: 5569.7202 - FP: 77.2800 - FN: 118.7300 - val_loss: 0.1083 - val_Accuracy: 0.9775 - val_Precision: 0.9631 - val_Recall: 0.9501 - val_TP: 763.8800 - val_TN: 1083.8800 - val_FP: 22.1200 - val_FN: 40.1200\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0460 - Accuracy: 0.9868 - Precision: 0.9669 - Recall: 0.9636 - TP: 3249.3601 - TN: 5564.4600 - FP: 82.5400 - FN: 122.6400 - val_loss: 0.1091 - val_Accuracy: 0.9770 - val_Precision: 0.9628 - val_Recall: 0.9500 - val_TP: 763.8300 - val_TN: 1083.5900 - val_FP: 22.4100 - val_FN: 40.1700\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 5ms/step - loss: 0.0559 - Accuracy: 0.9853 - Precision: 0.9650 - Recall: 0.9625 - TP: 3245.5500 - TN: 5557.5698 - FP: 89.4300 - FN: 126.4500 - val_loss: 0.1159 - val_Accuracy: 0.9743 - val_Precision: 0.9584 - val_Recall: 0.9489 - val_TP: 762.9000 - val_TN: 1079.8300 - val_FP: 26.1700 - val_FN: 41.1000\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0510 - Accuracy: 0.9864 - Precision: 0.9662 - Recall: 0.9622 - TP: 3244.3999 - TN: 5561.7598 - FP: 85.2400 - FN: 127.6000 - val_loss: 0.1222 - val_Accuracy: 0.9728 - val_Precision: 0.9452 - val_Recall: 0.9549 - val_TP: 767.7400 - val_TN: 1067.8700 - val_FP: 38.1300 - val_FN: 36.2600\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0499 - Accuracy: 0.9878 - Precision: 0.9660 - Recall: 0.9638 - TP: 3250.0000 - TN: 5561.2100 - FP: 85.7900 - FN: 122.0000 - val_loss: 0.1060 - val_Accuracy: 0.9764 - val_Precision: 0.9613 - val_Recall: 0.9499 - val_TP: 763.6800 - val_TN: 1082.3101 - val_FP: 23.6900 - val_FN: 40.3200\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0412 - Accuracy: 0.9868 - Precision: 0.9660 - Recall: 0.9637 - TP: 3249.5500 - TN: 5560.9102 - FP: 86.0900 - FN: 122.4500 - val_loss: 0.1113 - val_Accuracy: 0.9759 - val_Precision: 0.9617 - val_Recall: 0.9483 - val_TP: 762.4300 - val_TN: 1082.7500 - val_FP: 23.2500 - val_FN: 41.5700\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0742 - Accuracy: 0.9848 - Precision: 0.9649 - Recall: 0.9618 - TP: 3243.3000 - TN: 5557.2202 - FP: 89.7800 - FN: 128.7000 - val_loss: 0.1205 - val_Accuracy: 0.9728 - val_Precision: 0.9557 - val_Recall: 0.9480 - val_TP: 762.1600 - val_TN: 1077.5601 - val_FP: 28.4400 - val_FN: 41.8400\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0451 - Accuracy: 0.9867 - Precision: 0.9663 - Recall: 0.9635 - TP: 3248.8601 - TN: 5562.3301 - FP: 84.6700 - FN: 123.1400 - val_loss: 0.1072 - val_Accuracy: 0.9770 - val_Precision: 0.9660 - val_Recall: 0.9474 - val_TP: 761.7000 - val_TN: 1086.3800 - val_FP: 19.6200 - val_FN: 42.3000\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0576 - Accuracy: 0.9872 - Precision: 0.9660 - Recall: 0.9635 - TP: 3248.9500 - TN: 5561.0601 - FP: 85.9400 - FN: 123.0500 - val_loss: 0.1149 - val_Accuracy: 0.9743 - val_Precision: 0.9693 - val_Recall: 0.9415 - val_TP: 756.9800 - val_TN: 1089.3500 - val_FP: 16.6500 - val_FN: 47.0200\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0410 - Accuracy: 0.9875 - Precision: 0.9674 - Recall: 0.9641 - TP: 3251.0801 - TN: 5566.4502 - FP: 80.5500 - FN: 120.9200 - val_loss: 0.1101 - val_Accuracy: 0.9764 - val_Precision: 0.9598 - val_Recall: 0.9512 - val_TP: 764.7500 - val_TN: 1081.1400 - val_FP: 24.8600 - val_FN: 39.2500\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0433 - Accuracy: 0.9877 - Precision: 0.9666 - Recall: 0.9639 - TP: 3250.1799 - TN: 5563.1099 - FP: 83.8900 - FN: 121.8200 - val_loss: 0.1099 - val_Accuracy: 0.9764 - val_Precision: 0.9620 - val_Recall: 0.9493 - val_TP: 763.2700 - val_TN: 1083.1000 - val_FP: 22.9000 - val_FN: 40.7300\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0533 - Accuracy: 0.9871 - Precision: 0.9668 - Recall: 0.9641 - TP: 3250.8701 - TN: 5564.1899 - FP: 82.8100 - FN: 121.1300 - val_loss: 0.1091 - val_Accuracy: 0.9770 - val_Precision: 0.9570 - val_Recall: 0.9534 - val_TP: 766.5300 - val_TN: 1078.6200 - val_FP: 27.3800 - val_FN: 37.4700\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0415 - Accuracy: 0.9868 - Precision: 0.9662 - Recall: 0.9645 - TP: 3252.1699 - TN: 5562.0200 - FP: 84.9800 - FN: 119.8300 - val_loss: 0.1188 - val_Accuracy: 0.9723 - val_Precision: 0.9580 - val_Recall: 0.9491 - val_TP: 763.0400 - val_TN: 1079.5601 - val_FP: 26.4400 - val_FN: 40.9600\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0570 - Accuracy: 0.9868 - Precision: 0.9663 - Recall: 0.9629 - TP: 3246.8101 - TN: 5562.4302 - FP: 84.5700 - FN: 125.1900 - val_loss: 0.1110 - val_Accuracy: 0.9754 - val_Precision: 0.9590 - val_Recall: 0.9515 - val_TP: 765.0100 - val_TN: 1080.4399 - val_FP: 25.5600 - val_FN: 38.9900\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0515 - Accuracy: 0.9868 - Precision: 0.9666 - Recall: 0.9635 - TP: 3248.8401 - TN: 5563.5400 - FP: 83.4600 - FN: 123.1600 - val_loss: 0.1161 - val_Accuracy: 0.9749 - val_Precision: 0.9580 - val_Recall: 0.9513 - val_TP: 764.8600 - val_TN: 1079.4900 - val_FP: 26.5100 - val_FN: 39.1400\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0394 - Accuracy: 0.9881 - Precision: 0.9672 - Recall: 0.9650 - TP: 3254.0601 - TN: 5565.2402 - FP: 81.7600 - FN: 117.9400 - val_loss: 0.1155 - val_Accuracy: 0.9754 - val_Precision: 0.9601 - val_Recall: 0.9498 - val_TP: 763.6100 - val_TN: 1081.4399 - val_FP: 24.5600 - val_FN: 40.3900\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0476 - Accuracy: 0.9871 - Precision: 0.9667 - Recall: 0.9639 - TP: 3250.2100 - TN: 5563.6499 - FP: 83.3500 - FN: 121.7900 - val_loss: 0.1134 - val_Accuracy: 0.9754 - val_Precision: 0.9600 - val_Recall: 0.9495 - val_TP: 763.3800 - val_TN: 1081.3300 - val_FP: 24.6700 - val_FN: 40.6200\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0397 - Accuracy: 0.9871 - Precision: 0.9671 - Recall: 0.9645 - TP: 3252.4600 - TN: 5565.3101 - FP: 81.6900 - FN: 119.5400 - val_loss: 0.1171 - val_Accuracy: 0.9738 - val_Precision: 0.9601 - val_Recall: 0.9491 - val_TP: 763.0400 - val_TN: 1081.4301 - val_FP: 24.5700 - val_FN: 40.9600\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0429 - Accuracy: 0.9886 - Precision: 0.9673 - Recall: 0.9648 - TP: 3253.2100 - TN: 5565.7700 - FP: 81.2300 - FN: 118.7900 - val_loss: 0.1164 - val_Accuracy: 0.9749 - val_Precision: 0.9597 - val_Recall: 0.9496 - val_TP: 763.4700 - val_TN: 1081.0800 - val_FP: 24.9200 - val_FN: 40.5300\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0425 - Accuracy: 0.9868 - Precision: 0.9670 - Recall: 0.9636 - TP: 3249.3301 - TN: 5564.9902 - FP: 82.0100 - FN: 122.6700 - val_loss: 0.1268 - val_Accuracy: 0.9728 - val_Precision: 0.9504 - val_Recall: 0.9529 - val_TP: 766.1600 - val_TN: 1072.8400 - val_FP: 33.1600 - val_FN: 37.8400\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0494 - Accuracy: 0.9869 - Precision: 0.9657 - Recall: 0.9641 - TP: 3251.0701 - TN: 5560.1899 - FP: 86.8100 - FN: 120.9300 - val_loss: 0.1113 - val_Accuracy: 0.9749 - val_Precision: 0.9639 - val_Recall: 0.9479 - val_TP: 762.1300 - val_TN: 1084.6300 - val_FP: 21.3700 - val_FN: 41.8700\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0519 - Accuracy: 0.9877 - Precision: 0.9674 - Recall: 0.9634 - TP: 3248.5901 - TN: 5566.2500 - FP: 80.7500 - FN: 123.4100 - val_loss: 0.1155 - val_Accuracy: 0.9743 - val_Precision: 0.9590 - val_Recall: 0.9507 - val_TP: 764.3400 - val_TN: 1080.4900 - val_FP: 25.5100 - val_FN: 39.6600\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0362 - Accuracy: 0.9876 - Precision: 0.9674 - Recall: 0.9653 - TP: 3255.0100 - TN: 5565.9702 - FP: 81.0300 - FN: 116.9900 - val_loss: 0.1087 - val_Accuracy: 0.9780 - val_Precision: 0.9588 - val_Recall: 0.9537 - val_TP: 766.8100 - val_TN: 1080.1000 - val_FP: 25.9000 - val_FN: 37.1900\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0392 - Accuracy: 0.9892 - Precision: 0.9690 - Recall: 0.9659 - TP: 3257.1799 - TN: 5571.7500 - FP: 75.2500 - FN: 114.8200 - val_loss: 0.1155 - val_Accuracy: 0.9764 - val_Precision: 0.9565 - val_Recall: 0.9526 - val_TP: 765.9000 - val_TN: 1078.2800 - val_FP: 27.7200 - val_FN: 38.1000\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0488 - Accuracy: 0.9876 - Precision: 0.9669 - Recall: 0.9642 - TP: 3251.4299 - TN: 5564.2700 - FP: 82.7300 - FN: 120.5700 - val_loss: 0.1093 - val_Accuracy: 0.9770 - val_Precision: 0.9599 - val_Recall: 0.9525 - val_TP: 765.7700 - val_TN: 1081.1400 - val_FP: 24.8600 - val_FN: 38.2300\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 5ms/step - loss: 0.0460 - Accuracy: 0.9872 - Precision: 0.9663 - Recall: 0.9644 - TP: 3251.8701 - TN: 5562.0098 - FP: 84.9900 - FN: 120.1300 - val_loss: 0.1060 - val_Accuracy: 0.9754 - val_Precision: 0.9608 - val_Recall: 0.9502 - val_TP: 764.0000 - val_TN: 1081.8700 - val_FP: 24.1300 - val_FN: 40.0000\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0585 - Accuracy: 0.9866 - Precision: 0.9660 - Recall: 0.9626 - TP: 3245.8999 - TN: 5561.1201 - FP: 85.8800 - FN: 126.1000 - val_loss: 0.1209 - val_Accuracy: 0.9738 - val_Precision: 0.9499 - val_Recall: 0.9536 - val_TP: 766.7100 - val_TN: 1072.3000 - val_FP: 33.7000 - val_FN: 37.2900\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0498 - Accuracy: 0.9874 - Precision: 0.9671 - Recall: 0.9640 - TP: 3250.4900 - TN: 5564.8799 - FP: 82.1200 - FN: 121.5100 - val_loss: 0.1066 - val_Accuracy: 0.9764 - val_Precision: 0.9609 - val_Recall: 0.9508 - val_TP: 764.4300 - val_TN: 1082.0400 - val_FP: 23.9600 - val_FN: 39.5700\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0404 - Accuracy: 0.9874 - Precision: 0.9668 - Recall: 0.9646 - TP: 3252.6799 - TN: 5563.8501 - FP: 83.1500 - FN: 119.3200 - val_loss: 0.1060 - val_Accuracy: 0.9775 - val_Precision: 0.9648 - val_Recall: 0.9493 - val_TP: 763.2700 - val_TN: 1085.3500 - val_FP: 20.6500 - val_FN: 40.7300\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0738 - Accuracy: 0.9867 - Precision: 0.9659 - Recall: 0.9633 - TP: 3248.3000 - TN: 5561.2900 - FP: 85.7100 - FN: 123.7000 - val_loss: 0.1094 - val_Accuracy: 0.9770 - val_Precision: 0.9666 - val_Recall: 0.9459 - val_TP: 760.5000 - val_TN: 1086.9700 - val_FP: 19.0300 - val_FN: 43.5000\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0401 - Accuracy: 0.9884 - Precision: 0.9675 - Recall: 0.9644 - TP: 3251.8101 - TN: 5566.5000 - FP: 80.5000 - FN: 120.1900 - val_loss: 0.1130 - val_Accuracy: 0.9764 - val_Precision: 0.9607 - val_Recall: 0.9499 - val_TP: 763.7300 - val_TN: 1081.8700 - val_FP: 24.1300 - val_FN: 40.2700\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0508 - Accuracy: 0.9870 - Precision: 0.9665 - Recall: 0.9630 - TP: 3247.3501 - TN: 5563.1802 - FP: 83.8200 - FN: 124.6500 - val_loss: 0.1261 - val_Accuracy: 0.9728 - val_Precision: 0.9451 - val_Recall: 0.9559 - val_TP: 768.5700 - val_TN: 1067.6700 - val_FP: 38.3300 - val_FN: 35.4300\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0433 - Accuracy: 0.9875 - Precision: 0.9666 - Recall: 0.9639 - TP: 3250.1799 - TN: 5562.8799 - FP: 84.1200 - FN: 121.8200 - val_loss: 0.1051 - val_Accuracy: 0.9780 - val_Precision: 0.9582 - val_Recall: 0.9544 - val_TP: 767.3600 - val_TN: 1079.6000 - val_FP: 26.4000 - val_FN: 36.6400\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0417 - Accuracy: 0.9875 - Precision: 0.9667 - Recall: 0.9650 - TP: 3253.8301 - TN: 5563.2998 - FP: 83.7000 - FN: 118.1700 - val_loss: 0.1096 - val_Accuracy: 0.9764 - val_Precision: 0.9659 - val_Recall: 0.9474 - val_TP: 761.7300 - val_TN: 1086.2900 - val_FP: 19.7100 - val_FN: 42.2700\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0423 - Accuracy: 0.9879 - Precision: 0.9688 - Recall: 0.9646 - TP: 3252.5601 - TN: 5570.9600 - FP: 76.0400 - FN: 119.4400 - val_loss: 0.1083 - val_Accuracy: 0.9749 - val_Precision: 0.9601 - val_Recall: 0.9517 - val_TP: 765.1600 - val_TN: 1081.3199 - val_FP: 24.6800 - val_FN: 38.8400\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0404 - Accuracy: 0.9880 - Precision: 0.9675 - Recall: 0.9653 - TP: 3254.8501 - TN: 5566.3398 - FP: 80.6600 - FN: 117.1500 - val_loss: 0.1175 - val_Accuracy: 0.9759 - val_Precision: 0.9537 - val_Recall: 0.9538 - val_TP: 766.8700 - val_TN: 1075.6700 - val_FP: 30.3300 - val_FN: 37.1300\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0656 - Accuracy: 0.9868 - Precision: 0.9663 - Recall: 0.9634 - TP: 3248.5601 - TN: 5562.1499 - FP: 84.8500 - FN: 123.4400 - val_loss: 0.1081 - val_Accuracy: 0.9775 - val_Precision: 0.9577 - val_Recall: 0.9538 - val_TP: 766.8300 - val_TN: 1079.1500 - val_FP: 26.8500 - val_FN: 37.1700\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0514 - Accuracy: 0.9867 - Precision: 0.9660 - Recall: 0.9634 - TP: 3248.6499 - TN: 5561.2300 - FP: 85.7700 - FN: 123.3500 - val_loss: 0.1099 - val_Accuracy: 0.9749 - val_Precision: 0.9580 - val_Recall: 0.9520 - val_TP: 765.3900 - val_TN: 1079.4000 - val_FP: 26.6000 - val_FN: 38.6100\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0620 - Accuracy: 0.9868 - Precision: 0.9652 - Recall: 0.9632 - TP: 3247.7700 - TN: 5558.6699 - FP: 88.3300 - FN: 124.2300 - val_loss: 0.1112 - val_Accuracy: 0.9754 - val_Precision: 0.9644 - val_Recall: 0.9482 - val_TP: 762.3700 - val_TN: 1085.0900 - val_FP: 20.9100 - val_FN: 41.6300\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0451 - Accuracy: 0.9867 - Precision: 0.9660 - Recall: 0.9637 - TP: 3249.4299 - TN: 5561.1802 - FP: 85.8200 - FN: 122.5700 - val_loss: 0.1096 - val_Accuracy: 0.9775 - val_Precision: 0.9631 - val_Recall: 0.9503 - val_TP: 764.0800 - val_TN: 1083.9000 - val_FP: 22.1000 - val_FN: 39.9200\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0387 - Accuracy: 0.9885 - Precision: 0.9686 - Recall: 0.9652 - TP: 3254.6899 - TN: 5570.7002 - FP: 76.3000 - FN: 117.3100 - val_loss: 0.1150 - val_Accuracy: 0.9754 - val_Precision: 0.9588 - val_Recall: 0.9516 - val_TP: 765.0800 - val_TN: 1080.2700 - val_FP: 25.7300 - val_FN: 38.9200\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0418 - Accuracy: 0.9870 - Precision: 0.9667 - Recall: 0.9650 - TP: 3254.0000 - TN: 5563.7598 - FP: 83.2400 - FN: 118.0000 - val_loss: 0.1098 - val_Accuracy: 0.9785 - val_Precision: 0.9668 - val_Recall: 0.9482 - val_TP: 762.3400 - val_TN: 1087.1100 - val_FP: 18.8900 - val_FN: 41.6600\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0389 - Accuracy: 0.9885 - Precision: 0.9678 - Recall: 0.9650 - TP: 3253.9700 - TN: 5567.4502 - FP: 79.5500 - FN: 118.0300 - val_loss: 0.1104 - val_Accuracy: 0.9764 - val_Precision: 0.9602 - val_Recall: 0.9519 - val_TP: 765.3200 - val_TN: 1081.4500 - val_FP: 24.5500 - val_FN: 38.6800\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0416 - Accuracy: 0.9878 - Precision: 0.9676 - Recall: 0.9649 - TP: 3253.5901 - TN: 5567.1802 - FP: 79.8200 - FN: 118.4100 - val_loss: 0.1103 - val_Accuracy: 0.9764 - val_Precision: 0.9587 - val_Recall: 0.9521 - val_TP: 765.4500 - val_TN: 1080.0900 - val_FP: 25.9100 - val_FN: 38.5500\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0392 - Accuracy: 0.9884 - Precision: 0.9669 - Recall: 0.9653 - TP: 3255.1101 - TN: 5564.2100 - FP: 82.7900 - FN: 116.8900 - val_loss: 0.1117 - val_Accuracy: 0.9780 - val_Precision: 0.9653 - val_Recall: 0.9487 - val_TP: 762.7300 - val_TN: 1085.8000 - val_FP: 20.2000 - val_FN: 41.2700\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0400 - Accuracy: 0.9870 - Precision: 0.9677 - Recall: 0.9647 - TP: 3252.8000 - TN: 5567.5498 - FP: 79.4500 - FN: 119.2000 - val_loss: 0.1164 - val_Accuracy: 0.9764 - val_Precision: 0.9589 - val_Recall: 0.9511 - val_TP: 764.6500 - val_TN: 1080.4000 - val_FP: 25.6000 - val_FN: 39.3500\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0426 - Accuracy: 0.9891 - Precision: 0.9678 - Recall: 0.9652 - TP: 3254.7300 - TN: 5567.7300 - FP: 79.2700 - FN: 117.2700 - val_loss: 0.1146 - val_Accuracy: 0.9759 - val_Precision: 0.9601 - val_Recall: 0.9501 - val_TP: 763.8800 - val_TN: 1081.4200 - val_FP: 24.5800 - val_FN: 40.1200\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0470 - Accuracy: 0.9880 - Precision: 0.9685 - Recall: 0.9649 - TP: 3253.7100 - TN: 5570.2402 - FP: 76.7600 - FN: 118.2900 - val_loss: 0.1111 - val_Accuracy: 0.9749 - val_Precision: 0.9587 - val_Recall: 0.9534 - val_TP: 766.5500 - val_TN: 1080.0601 - val_FP: 25.9400 - val_FN: 37.4500\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0424 - Accuracy: 0.9871 - Precision: 0.9668 - Recall: 0.9646 - TP: 3252.6899 - TN: 5563.9102 - FP: 83.0900 - FN: 119.3100 - val_loss: 0.1103 - val_Accuracy: 0.9759 - val_Precision: 0.9603 - val_Recall: 0.9524 - val_TP: 765.6900 - val_TN: 1081.4700 - val_FP: 24.5300 - val_FN: 38.3100\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0428 - Accuracy: 0.9872 - Precision: 0.9671 - Recall: 0.9639 - TP: 3250.3201 - TN: 5565.1699 - FP: 81.8300 - FN: 121.6800 - val_loss: 0.1110 - val_Accuracy: 0.9764 - val_Precision: 0.9623 - val_Recall: 0.9506 - val_TP: 764.3200 - val_TN: 1083.1500 - val_FP: 22.8500 - val_FN: 39.6800\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0421 - Accuracy: 0.9882 - Precision: 0.9668 - Recall: 0.9652 - TP: 3254.6899 - TN: 5563.5898 - FP: 83.4100 - FN: 117.3100 - val_loss: 0.1167 - val_Accuracy: 0.9743 - val_Precision: 0.9672 - val_Recall: 0.9446 - val_TP: 759.4300 - val_TN: 1087.5400 - val_FP: 18.4600 - val_FN: 44.5700\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0394 - Accuracy: 0.9872 - Precision: 0.9679 - Recall: 0.9649 - TP: 3253.7000 - TN: 5568.2402 - FP: 78.7600 - FN: 118.3000 - val_loss: 0.1128 - val_Accuracy: 0.9759 - val_Precision: 0.9624 - val_Recall: 0.9504 - val_TP: 764.1500 - val_TN: 1083.3800 - val_FP: 22.6200 - val_FN: 39.8500\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0473 - Accuracy: 0.9874 - Precision: 0.9678 - Recall: 0.9646 - TP: 3252.7700 - TN: 5567.8501 - FP: 79.1500 - FN: 119.2300 - val_loss: 0.1171 - val_Accuracy: 0.9759 - val_Precision: 0.9539 - val_Recall: 0.9545 - val_TP: 767.4400 - val_TN: 1075.9399 - val_FP: 30.0600 - val_FN: 36.5600\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 6ms/step - loss: 0.0509 - Accuracy: 0.9869 - Precision: 0.9658 - Recall: 0.9647 - TP: 3252.8201 - TN: 5560.7998 - FP: 86.2000 - FN: 119.1800 - val_loss: 0.1079 - val_Accuracy: 0.9775 - val_Precision: 0.9655 - val_Recall: 0.9488 - val_TP: 762.8600 - val_TN: 1085.9500 - val_FP: 20.0500 - val_FN: 41.1400\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0522 - Accuracy: 0.9865 - Precision: 0.9668 - Recall: 0.9633 - TP: 3248.1599 - TN: 5564.4102 - FP: 82.5900 - FN: 123.8400 - val_loss: 0.1171 - val_Accuracy: 0.9743 - val_Precision: 0.9603 - val_Recall: 0.9493 - val_TP: 763.2000 - val_TN: 1081.5800 - val_FP: 24.4200 - val_FN: 40.8000\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0439 - Accuracy: 0.9869 - Precision: 0.9662 - Recall: 0.9637 - TP: 3249.6899 - TN: 5562.1099 - FP: 84.8900 - FN: 122.3100 - val_loss: 0.1101 - val_Accuracy: 0.9754 - val_Precision: 0.9614 - val_Recall: 0.9501 - val_TP: 763.8800 - val_TN: 1082.5200 - val_FP: 23.4800 - val_FN: 40.1200\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0455 - Accuracy: 0.9871 - Precision: 0.9670 - Recall: 0.9641 - TP: 3250.9299 - TN: 5564.5698 - FP: 82.4300 - FN: 121.0700 - val_loss: 0.1101 - val_Accuracy: 0.9764 - val_Precision: 0.9663 - val_Recall: 0.9469 - val_TP: 761.2800 - val_TN: 1086.6700 - val_FP: 19.3300 - val_FN: 42.7200\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0497 - Accuracy: 0.9879 - Precision: 0.9669 - Recall: 0.9657 - TP: 3256.2700 - TN: 5564.3999 - FP: 82.6000 - FN: 115.7300 - val_loss: 0.1137 - val_Accuracy: 0.9738 - val_Precision: 0.9664 - val_Recall: 0.9452 - val_TP: 759.9500 - val_TN: 1086.8700 - val_FP: 19.1300 - val_FN: 44.0500\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0422 - Accuracy: 0.9878 - Precision: 0.9677 - Recall: 0.9639 - TP: 3250.2600 - TN: 5567.3701 - FP: 79.6300 - FN: 121.7400 - val_loss: 0.1135 - val_Accuracy: 0.9754 - val_Precision: 0.9529 - val_Recall: 0.9548 - val_TP: 767.6500 - val_TN: 1075.0200 - val_FP: 30.9800 - val_FN: 36.3500\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0689 - Accuracy: 0.9869 - Precision: 0.9660 - Recall: 0.9636 - TP: 3249.1101 - TN: 5561.6602 - FP: 85.3400 - FN: 122.8900 - val_loss: 0.1090 - val_Accuracy: 0.9770 - val_Precision: 0.9639 - val_Recall: 0.9497 - val_TP: 763.5300 - val_TN: 1084.5699 - val_FP: 21.4300 - val_FN: 40.4700\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0420 - Accuracy: 0.9878 - Precision: 0.9672 - Recall: 0.9644 - TP: 3252.0901 - TN: 5565.4399 - FP: 81.5600 - FN: 119.9100 - val_loss: 0.1131 - val_Accuracy: 0.9754 - val_Precision: 0.9532 - val_Recall: 0.9548 - val_TP: 767.6200 - val_TN: 1075.2600 - val_FP: 30.7400 - val_FN: 36.3800\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0459 - Accuracy: 0.9878 - Precision: 0.9670 - Recall: 0.9655 - TP: 3255.5000 - TN: 5564.9502 - FP: 82.0500 - FN: 116.5000 - val_loss: 0.1140 - val_Accuracy: 0.9759 - val_Precision: 0.9654 - val_Recall: 0.9464 - val_TP: 760.9000 - val_TN: 1086.0000 - val_FP: 20.0000 - val_FN: 43.1000\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0424 - Accuracy: 0.9877 - Precision: 0.9678 - Recall: 0.9645 - TP: 3252.2600 - TN: 5567.8398 - FP: 79.1600 - FN: 119.7400 - val_loss: 0.1194 - val_Accuracy: 0.9764 - val_Precision: 0.9545 - val_Recall: 0.9540 - val_TP: 767.0300 - val_TN: 1076.5000 - val_FP: 29.5000 - val_FN: 36.9700\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0484 - Accuracy: 0.9879 - Precision: 0.9666 - Recall: 0.9646 - TP: 3252.6399 - TN: 5563.5801 - FP: 83.4200 - FN: 119.3600 - val_loss: 0.1170 - val_Accuracy: 0.9764 - val_Precision: 0.9623 - val_Recall: 0.9494 - val_TP: 763.3500 - val_TN: 1083.3400 - val_FP: 22.6600 - val_FN: 40.6500\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0397 - Accuracy: 0.9878 - Precision: 0.9675 - Recall: 0.9645 - TP: 3252.4399 - TN: 5566.5601 - FP: 80.4400 - FN: 119.5600 - val_loss: 0.1151 - val_Accuracy: 0.9754 - val_Precision: 0.9583 - val_Recall: 0.9517 - val_TP: 765.1300 - val_TN: 1079.8700 - val_FP: 26.1300 - val_FN: 38.8700\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0438 - Accuracy: 0.9877 - Precision: 0.9673 - Recall: 0.9645 - TP: 3252.1799 - TN: 5565.8101 - FP: 81.1900 - FN: 119.8200 - val_loss: 0.1152 - val_Accuracy: 0.9743 - val_Precision: 0.9557 - val_Recall: 0.9531 - val_TP: 766.2600 - val_TN: 1077.5400 - val_FP: 28.4600 - val_FN: 37.7400\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0397 - Accuracy: 0.9866 - Precision: 0.9665 - Recall: 0.9645 - TP: 3252.3601 - TN: 5563.1802 - FP: 83.8200 - FN: 119.6400 - val_loss: 0.1223 - val_Accuracy: 0.9749 - val_Precision: 0.9632 - val_Recall: 0.9471 - val_TP: 761.4300 - val_TN: 1084.2100 - val_FP: 21.7900 - val_FN: 42.5700\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0418 - Accuracy: 0.9870 - Precision: 0.9675 - Recall: 0.9649 - TP: 3253.6299 - TN: 5566.9902 - FP: 80.0100 - FN: 118.3700 - val_loss: 0.1131 - val_Accuracy: 0.9754 - val_Precision: 0.9640 - val_Recall: 0.9480 - val_TP: 762.2300 - val_TN: 1084.7400 - val_FP: 21.2600 - val_FN: 41.7700\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0437 - Accuracy: 0.9874 - Precision: 0.9679 - Recall: 0.9647 - TP: 3252.8701 - TN: 5568.1802 - FP: 78.8200 - FN: 119.1300 - val_loss: 0.1106 - val_Accuracy: 0.9770 - val_Precision: 0.9613 - val_Recall: 0.9521 - val_TP: 765.4600 - val_TN: 1082.3800 - val_FP: 23.6200 - val_FN: 38.5400\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0369 - Accuracy: 0.9892 - Precision: 0.9679 - Recall: 0.9656 - TP: 3255.9500 - TN: 5567.7100 - FP: 79.2900 - FN: 116.0500 - val_loss: 0.1113 - val_Accuracy: 0.9775 - val_Precision: 0.9619 - val_Recall: 0.9517 - val_TP: 765.1500 - val_TN: 1082.8900 - val_FP: 23.1100 - val_FN: 38.8500\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0464 - Accuracy: 0.9878 - Precision: 0.9667 - Recall: 0.9648 - TP: 3253.3601 - TN: 5563.8398 - FP: 83.1600 - FN: 118.6400 - val_loss: 0.1149 - val_Accuracy: 0.9770 - val_Precision: 0.9634 - val_Recall: 0.9493 - val_TP: 763.2700 - val_TN: 1084.2400 - val_FP: 21.7600 - val_FN: 40.7300\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0558 - Accuracy: 0.9866 - Precision: 0.9662 - Recall: 0.9633 - TP: 3248.2200 - TN: 5562.2100 - FP: 84.7900 - FN: 123.7800 - val_loss: 0.1174 - val_Accuracy: 0.9743 - val_Precision: 0.9630 - val_Recall: 0.9474 - val_TP: 761.6800 - val_TN: 1084.0100 - val_FP: 21.9900 - val_FN: 42.3200\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0504 - Accuracy: 0.9885 - Precision: 0.9682 - Recall: 0.9652 - TP: 3254.6101 - TN: 5569.5801 - FP: 77.4200 - FN: 117.3900 - val_loss: 0.1192 - val_Accuracy: 0.9749 - val_Precision: 0.9584 - val_Recall: 0.9517 - val_TP: 765.1800 - val_TN: 1080.0100 - val_FP: 25.9900 - val_FN: 38.8200\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0586 - Accuracy: 0.9879 - Precision: 0.9668 - Recall: 0.9653 - TP: 3255.1201 - TN: 5564.1201 - FP: 82.8800 - FN: 116.8800 - val_loss: 0.1209 - val_Accuracy: 0.9749 - val_Precision: 0.9615 - val_Recall: 0.9489 - val_TP: 762.9100 - val_TN: 1082.7500 - val_FP: 23.2500 - val_FN: 41.0900\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 5ms/step - loss: 0.0542 - Accuracy: 0.9874 - Precision: 0.9666 - Recall: 0.9637 - TP: 3249.5901 - TN: 5563.3999 - FP: 83.6000 - FN: 122.4100 - val_loss: 0.1077 - val_Accuracy: 0.9743 - val_Precision: 0.9598 - val_Recall: 0.9514 - val_TP: 764.9300 - val_TN: 1081.0200 - val_FP: 24.9800 - val_FN: 39.0700\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0551 - Accuracy: 0.9868 - Precision: 0.9654 - Recall: 0.9636 - TP: 3249.3999 - TN: 5558.8501 - FP: 88.1500 - FN: 122.6000 - val_loss: 0.1151 - val_Accuracy: 0.9743 - val_Precision: 0.9655 - val_Recall: 0.9445 - val_TP: 759.3500 - val_TN: 1086.1400 - val_FP: 19.8600 - val_FN: 44.6500\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0451 - Accuracy: 0.9869 - Precision: 0.9670 - Recall: 0.9640 - TP: 3250.7400 - TN: 5564.9702 - FP: 82.0300 - FN: 121.2600 - val_loss: 0.1096 - val_Accuracy: 0.9749 - val_Precision: 0.9628 - val_Recall: 0.9487 - val_TP: 762.7900 - val_TN: 1083.6700 - val_FP: 22.3300 - val_FN: 41.2100\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0467 - Accuracy: 0.9874 - Precision: 0.9682 - Recall: 0.9646 - TP: 3252.7700 - TN: 5569.0498 - FP: 77.9500 - FN: 119.2300 - val_loss: 0.1127 - val_Accuracy: 0.9764 - val_Precision: 0.9609 - val_Recall: 0.9501 - val_TP: 763.9000 - val_TN: 1082.1100 - val_FP: 23.8900 - val_FN: 40.1000\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0409 - Accuracy: 0.9875 - Precision: 0.9670 - Recall: 0.9642 - TP: 3251.2400 - TN: 5564.6899 - FP: 82.3100 - FN: 120.7600 - val_loss: 0.1077 - val_Accuracy: 0.9791 - val_Precision: 0.9608 - val_Recall: 0.9520 - val_TP: 765.3800 - val_TN: 1081.8400 - val_FP: 24.1600 - val_FN: 38.6200\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0542 - Accuracy: 0.9868 - Precision: 0.9661 - Recall: 0.9642 - TP: 3251.1599 - TN: 5561.4902 - FP: 85.5100 - FN: 120.8400 - val_loss: 0.1221 - val_Accuracy: 0.9749 - val_Precision: 0.9610 - val_Recall: 0.9476 - val_TP: 761.8500 - val_TN: 1082.2300 - val_FP: 23.7700 - val_FN: 42.1500\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0423 - Accuracy: 0.9878 - Precision: 0.9677 - Recall: 0.9651 - TP: 3254.4399 - TN: 5567.2998 - FP: 79.7000 - FN: 117.5600 - val_loss: 0.1129 - val_Accuracy: 0.9754 - val_Precision: 0.9689 - val_Recall: 0.9446 - val_TP: 759.4500 - val_TN: 1088.9500 - val_FP: 17.0500 - val_FN: 44.5500\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0438 - Accuracy: 0.9876 - Precision: 0.9678 - Recall: 0.9639 - TP: 3250.3501 - TN: 5567.9502 - FP: 79.0500 - FN: 121.6500 - val_loss: 0.1080 - val_Accuracy: 0.9780 - val_Precision: 0.9610 - val_Recall: 0.9526 - val_TP: 765.9100 - val_TN: 1082.0601 - val_FP: 23.9400 - val_FN: 38.0900\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0598 - Accuracy: 0.9868 - Precision: 0.9665 - Recall: 0.9638 - TP: 3250.1001 - TN: 5563.2700 - FP: 83.7300 - FN: 121.9000 - val_loss: 0.1189 - val_Accuracy: 0.9749 - val_Precision: 0.9546 - val_Recall: 0.9526 - val_TP: 765.8600 - val_TN: 1076.6300 - val_FP: 29.3700 - val_FN: 38.1400\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0497 - Accuracy: 0.9870 - Precision: 0.9668 - Recall: 0.9650 - TP: 3254.0701 - TN: 5563.8501 - FP: 83.1500 - FN: 117.9300 - val_loss: 0.1126 - val_Accuracy: 0.9764 - val_Precision: 0.9657 - val_Recall: 0.9473 - val_TP: 761.6100 - val_TN: 1086.2300 - val_FP: 19.7700 - val_FN: 42.3900\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0426 - Accuracy: 0.9877 - Precision: 0.9675 - Recall: 0.9648 - TP: 3253.4099 - TN: 5566.6899 - FP: 80.3100 - FN: 118.5900 - val_loss: 0.1175 - val_Accuracy: 0.9733 - val_Precision: 0.9600 - val_Recall: 0.9491 - val_TP: 763.0600 - val_TN: 1081.3500 - val_FP: 24.6500 - val_FN: 40.9400\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0654 - Accuracy: 0.9872 - Precision: 0.9664 - Recall: 0.9637 - TP: 3249.5701 - TN: 5563.0601 - FP: 83.9400 - FN: 122.4300 - val_loss: 0.1096 - val_Accuracy: 0.9764 - val_Precision: 0.9611 - val_Recall: 0.9520 - val_TP: 765.4000 - val_TN: 1082.1400 - val_FP: 23.8600 - val_FN: 38.6000\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0407 - Accuracy: 0.9884 - Precision: 0.9677 - Recall: 0.9655 - TP: 3255.6001 - TN: 5567.4600 - FP: 79.5400 - FN: 116.4000 - val_loss: 0.1153 - val_Accuracy: 0.9759 - val_Precision: 0.9627 - val_Recall: 0.9486 - val_TP: 762.6800 - val_TN: 1083.7200 - val_FP: 22.2800 - val_FN: 41.3200\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0505 - Accuracy: 0.9866 - Precision: 0.9671 - Recall: 0.9640 - TP: 3250.5100 - TN: 5565.1899 - FP: 81.8100 - FN: 121.4900 - val_loss: 0.1122 - val_Accuracy: 0.9764 - val_Precision: 0.9649 - val_Recall: 0.9487 - val_TP: 762.7200 - val_TN: 1085.5200 - val_FP: 20.4800 - val_FN: 41.2800\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0417 - Accuracy: 0.9884 - Precision: 0.9684 - Recall: 0.9659 - TP: 3257.1001 - TN: 5570.1499 - FP: 76.8500 - FN: 114.9000 - val_loss: 0.1144 - val_Accuracy: 0.9749 - val_Precision: 0.9597 - val_Recall: 0.9517 - val_TP: 765.1600 - val_TN: 1081.0601 - val_FP: 24.9400 - val_FN: 38.8400\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0742 - Accuracy: 0.9863 - Precision: 0.9650 - Recall: 0.9632 - TP: 3247.8799 - TN: 5558.1699 - FP: 88.8300 - FN: 124.1200 - val_loss: 0.1133 - val_Accuracy: 0.9749 - val_Precision: 0.9639 - val_Recall: 0.9483 - val_TP: 762.4100 - val_TN: 1084.6400 - val_FP: 21.3600 - val_FN: 41.5900\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0465 - Accuracy: 0.9872 - Precision: 0.9672 - Recall: 0.9648 - TP: 3253.2200 - TN: 5565.3799 - FP: 81.6200 - FN: 118.7800 - val_loss: 0.1139 - val_Accuracy: 0.9770 - val_Precision: 0.9667 - val_Recall: 0.9474 - val_TP: 761.6700 - val_TN: 1087.0200 - val_FP: 18.9800 - val_FN: 42.3300\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0544 - Accuracy: 0.9857 - Precision: 0.9658 - Recall: 0.9635 - TP: 3248.8301 - TN: 5560.8301 - FP: 86.1700 - FN: 123.1700 - val_loss: 0.1187 - val_Accuracy: 0.9743 - val_Precision: 0.9638 - val_Recall: 0.9466 - val_TP: 761.0900 - val_TN: 1084.7100 - val_FP: 21.2900 - val_FN: 42.9100\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0486 - Accuracy: 0.9876 - Precision: 0.9677 - Recall: 0.9648 - TP: 3253.1799 - TN: 5567.8301 - FP: 79.1700 - FN: 118.8200 - val_loss: 0.1121 - val_Accuracy: 0.9780 - val_Precision: 0.9623 - val_Recall: 0.9512 - val_TP: 764.7300 - val_TN: 1083.1700 - val_FP: 22.8300 - val_FN: 39.2700\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0417 - Accuracy: 0.9882 - Precision: 0.9676 - Recall: 0.9654 - TP: 3255.2100 - TN: 5567.2900 - FP: 79.7100 - FN: 116.7900 - val_loss: 0.1154 - val_Accuracy: 0.9749 - val_Precision: 0.9583 - val_Recall: 0.9524 - val_TP: 765.7000 - val_TN: 1079.8300 - val_FP: 26.1700 - val_FN: 38.3000\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0376 - Accuracy: 0.9884 - Precision: 0.9678 - Recall: 0.9656 - TP: 3255.9500 - TN: 5567.8101 - FP: 79.1900 - FN: 116.0500 - val_loss: 0.1211 - val_Accuracy: 0.9754 - val_Precision: 0.9627 - val_Recall: 0.9485 - val_TP: 762.5600 - val_TN: 1083.7800 - val_FP: 22.2200 - val_FN: 41.4400\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0577 - Accuracy: 0.9875 - Precision: 0.9669 - Recall: 0.9643 - TP: 3251.6001 - TN: 5565.0298 - FP: 81.9700 - FN: 120.4000 - val_loss: 0.1165 - val_Accuracy: 0.9743 - val_Precision: 0.9579 - val_Recall: 0.9522 - val_TP: 765.5300 - val_TN: 1079.4800 - val_FP: 26.5200 - val_FN: 38.4700\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0435 - Accuracy: 0.9870 - Precision: 0.9670 - Recall: 0.9654 - TP: 3255.2800 - TN: 5565.2202 - FP: 81.7800 - FN: 116.7200 - val_loss: 0.1223 - val_Accuracy: 0.9749 - val_Precision: 0.9633 - val_Recall: 0.9469 - val_TP: 761.3400 - val_TN: 1084.3199 - val_FP: 21.6800 - val_FN: 42.6600\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0384 - Accuracy: 0.9879 - Precision: 0.9681 - Recall: 0.9652 - TP: 3254.5200 - TN: 5569.0498 - FP: 77.9500 - FN: 117.4800 - val_loss: 0.1172 - val_Accuracy: 0.9759 - val_Precision: 0.9618 - val_Recall: 0.9494 - val_TP: 763.3300 - val_TN: 1082.9000 - val_FP: 23.1000 - val_FN: 40.6700\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0421 - Accuracy: 0.9889 - Precision: 0.9691 - Recall: 0.9657 - TP: 3256.3501 - TN: 5572.5898 - FP: 74.4100 - FN: 115.6500 - val_loss: 0.1199 - val_Accuracy: 0.9759 - val_Precision: 0.9516 - val_Recall: 0.9559 - val_TP: 768.5400 - val_TN: 1073.9600 - val_FP: 32.0400 - val_FN: 35.4600\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 7ms/step - loss: 0.0504 - Accuracy: 0.9869 - Precision: 0.9663 - Recall: 0.9631 - TP: 3247.4600 - TN: 5562.5801 - FP: 84.4200 - FN: 124.5400 - val_loss: 0.1085 - val_Accuracy: 0.9759 - val_Precision: 0.9620 - val_Recall: 0.9506 - val_TP: 764.3100 - val_TN: 1082.9301 - val_FP: 23.0700 - val_FN: 39.6900\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0612 - Accuracy: 0.9871 - Precision: 0.9657 - Recall: 0.9636 - TP: 3249.3000 - TN: 5560.5200 - FP: 86.4800 - FN: 122.7000 - val_loss: 0.1178 - val_Accuracy: 0.9754 - val_Precision: 0.9601 - val_Recall: 0.9500 - val_TP: 763.8300 - val_TN: 1081.3800 - val_FP: 24.6200 - val_FN: 40.1700\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0375 - Accuracy: 0.9877 - Precision: 0.9674 - Recall: 0.9648 - TP: 3253.3601 - TN: 5566.1699 - FP: 80.8300 - FN: 118.6400 - val_loss: 0.1103 - val_Accuracy: 0.9770 - val_Precision: 0.9645 - val_Recall: 0.9492 - val_TP: 763.1800 - val_TN: 1085.1100 - val_FP: 20.8900 - val_FN: 40.8200\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0462 - Accuracy: 0.9867 - Precision: 0.9664 - Recall: 0.9647 - TP: 3253.1001 - TN: 5562.5098 - FP: 84.4900 - FN: 118.9000 - val_loss: 0.1158 - val_Accuracy: 0.9764 - val_Precision: 0.9698 - val_Recall: 0.9421 - val_TP: 757.4700 - val_TN: 1089.6801 - val_FP: 16.3200 - val_FN: 46.5300\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0455 - Accuracy: 0.9871 - Precision: 0.9677 - Recall: 0.9640 - TP: 3250.5200 - TN: 5567.4902 - FP: 79.5100 - FN: 121.4800 - val_loss: 0.1111 - val_Accuracy: 0.9775 - val_Precision: 0.9641 - val_Recall: 0.9498 - val_TP: 763.6600 - val_TN: 1084.8101 - val_FP: 21.1900 - val_FN: 40.3400\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0433 - Accuracy: 0.9878 - Precision: 0.9682 - Recall: 0.9654 - TP: 3255.2000 - TN: 5569.0000 - FP: 78.0000 - FN: 116.8000 - val_loss: 0.1134 - val_Accuracy: 0.9754 - val_Precision: 0.9558 - val_Recall: 0.9540 - val_TP: 766.9800 - val_TN: 1077.6500 - val_FP: 28.3500 - val_FN: 37.0200\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0470 - Accuracy: 0.9874 - Precision: 0.9666 - Recall: 0.9642 - TP: 3251.1899 - TN: 5563.3799 - FP: 83.6200 - FN: 120.8100 - val_loss: 0.1134 - val_Accuracy: 0.9754 - val_Precision: 0.9569 - val_Recall: 0.9528 - val_TP: 766.0800 - val_TN: 1078.4900 - val_FP: 27.5100 - val_FN: 37.9200\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0483 - Accuracy: 0.9876 - Precision: 0.9667 - Recall: 0.9644 - TP: 3252.0500 - TN: 5563.5601 - FP: 83.4400 - FN: 119.9500 - val_loss: 0.1211 - val_Accuracy: 0.9759 - val_Precision: 0.9503 - val_Recall: 0.9563 - val_TP: 768.8400 - val_TN: 1072.7000 - val_FP: 33.3000 - val_FN: 35.1600\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0698 - Accuracy: 0.9859 - Precision: 0.9666 - Recall: 0.9636 - TP: 3249.3601 - TN: 5563.7798 - FP: 83.2200 - FN: 122.6400 - val_loss: 0.1316 - val_Accuracy: 0.9723 - val_Precision: 0.9507 - val_Recall: 0.9537 - val_TP: 766.7500 - val_TN: 1073.2900 - val_FP: 32.7100 - val_FN: 37.2500\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0655 - Accuracy: 0.9857 - Precision: 0.9655 - Recall: 0.9635 - TP: 3248.7600 - TN: 5559.9902 - FP: 87.0100 - FN: 123.2400 - val_loss: 0.1151 - val_Accuracy: 0.9764 - val_Precision: 0.9684 - val_Recall: 0.9461 - val_TP: 760.6600 - val_TN: 1088.5100 - val_FP: 17.4900 - val_FN: 43.3400\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0453 - Accuracy: 0.9880 - Precision: 0.9676 - Recall: 0.9650 - TP: 3253.8799 - TN: 5567.3301 - FP: 79.6700 - FN: 118.1200 - val_loss: 0.1124 - val_Accuracy: 0.9754 - val_Precision: 0.9616 - val_Recall: 0.9518 - val_TP: 765.2700 - val_TN: 1082.6500 - val_FP: 23.3500 - val_FN: 38.7300\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0416 - Accuracy: 0.9872 - Precision: 0.9675 - Recall: 0.9648 - TP: 3253.3601 - TN: 5566.5801 - FP: 80.4200 - FN: 118.6400 - val_loss: 0.1219 - val_Accuracy: 0.9749 - val_Precision: 0.9560 - val_Recall: 0.9528 - val_TP: 766.0800 - val_TN: 1077.8300 - val_FP: 28.1700 - val_FN: 37.9200\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0618 - Accuracy: 0.9872 - Precision: 0.9654 - Recall: 0.9633 - TP: 3248.1599 - TN: 5559.4800 - FP: 87.5200 - FN: 123.8400 - val_loss: 0.1575 - val_Accuracy: 0.9670 - val_Precision: 0.9401 - val_Recall: 0.9520 - val_TP: 765.3900 - val_TN: 1063.9600 - val_FP: 42.0400 - val_FN: 38.6100\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0508 - Accuracy: 0.9876 - Precision: 0.9671 - Recall: 0.9643 - TP: 3251.5100 - TN: 5565.4102 - FP: 81.5900 - FN: 120.4900 - val_loss: 0.1157 - val_Accuracy: 0.9749 - val_Precision: 0.9613 - val_Recall: 0.9501 - val_TP: 763.9200 - val_TN: 1082.4399 - val_FP: 23.5600 - val_FN: 40.0800\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0448 - Accuracy: 0.9869 - Precision: 0.9673 - Recall: 0.9647 - TP: 3252.9900 - TN: 5566.3701 - FP: 80.6300 - FN: 119.0100 - val_loss: 0.1283 - val_Accuracy: 0.9738 - val_Precision: 0.9624 - val_Recall: 0.9469 - val_TP: 761.3000 - val_TN: 1083.5100 - val_FP: 22.4900 - val_FN: 42.7000\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0493 - Accuracy: 0.9871 - Precision: 0.9673 - Recall: 0.9648 - TP: 3253.4399 - TN: 5566.7100 - FP: 80.2900 - FN: 118.5600 - val_loss: 0.1296 - val_Accuracy: 0.9754 - val_Precision: 0.9600 - val_Recall: 0.9496 - val_TP: 763.4700 - val_TN: 1081.4700 - val_FP: 24.5300 - val_FN: 40.5300\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0503 - Accuracy: 0.9872 - Precision: 0.9668 - Recall: 0.9652 - TP: 3254.6899 - TN: 5564.3599 - FP: 82.6400 - FN: 117.3100 - val_loss: 0.1293 - val_Accuracy: 0.9733 - val_Precision: 0.9555 - val_Recall: 0.9517 - val_TP: 765.1500 - val_TN: 1077.5000 - val_FP: 28.5000 - val_FN: 38.8500\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0417 - Accuracy: 0.9879 - Precision: 0.9674 - Recall: 0.9647 - TP: 3252.8899 - TN: 5566.5498 - FP: 80.4500 - FN: 119.1100 - val_loss: 0.1254 - val_Accuracy: 0.9749 - val_Precision: 0.9651 - val_Recall: 0.9455 - val_TP: 760.2200 - val_TN: 1085.8199 - val_FP: 20.1800 - val_FN: 43.7800\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0609 - Accuracy: 0.9887 - Precision: 0.9680 - Recall: 0.9644 - TP: 3251.9900 - TN: 5568.9399 - FP: 78.0600 - FN: 120.0100 - val_loss: 0.1263 - val_Accuracy: 0.9738 - val_Precision: 0.9557 - val_Recall: 0.9516 - val_TP: 765.0900 - val_TN: 1077.6700 - val_FP: 28.3300 - val_FN: 38.9100\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0343 - Accuracy: 0.9877 - Precision: 0.9671 - Recall: 0.9663 - TP: 3258.4199 - TN: 5565.4600 - FP: 81.5400 - FN: 113.5800 - val_loss: 0.1199 - val_Accuracy: 0.9754 - val_Precision: 0.9689 - val_Recall: 0.9445 - val_TP: 759.3800 - val_TN: 1088.9700 - val_FP: 17.0300 - val_FN: 44.6200\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0693 - Accuracy: 0.9870 - Precision: 0.9668 - Recall: 0.9637 - TP: 3249.7100 - TN: 5564.5498 - FP: 82.4500 - FN: 122.2900 - val_loss: 0.1227 - val_Accuracy: 0.9754 - val_Precision: 0.9609 - val_Recall: 0.9500 - val_TP: 763.7700 - val_TN: 1082.2400 - val_FP: 23.7600 - val_FN: 40.2300\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 6ms/step - loss: 0.0519 - Accuracy: 0.9865 - Precision: 0.9665 - Recall: 0.9640 - TP: 3250.6399 - TN: 5563.4399 - FP: 83.5600 - FN: 121.3600 - val_loss: 0.1111 - val_Accuracy: 0.9749 - val_Precision: 0.9556 - val_Recall: 0.9533 - val_TP: 766.4500 - val_TN: 1077.3199 - val_FP: 28.6800 - val_FN: 37.5500\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0624 - Accuracy: 0.9871 - Precision: 0.9663 - Recall: 0.9636 - TP: 3249.3701 - TN: 5562.6899 - FP: 84.3100 - FN: 122.6300 - val_loss: 0.1126 - val_Accuracy: 0.9754 - val_Precision: 0.9614 - val_Recall: 0.9491 - val_TP: 763.0700 - val_TN: 1082.5100 - val_FP: 23.4900 - val_FN: 40.9300\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0499 - Accuracy: 0.9878 - Precision: 0.9672 - Recall: 0.9637 - TP: 3249.6101 - TN: 5565.7402 - FP: 81.2600 - FN: 122.3900 - val_loss: 0.1158 - val_Accuracy: 0.9754 - val_Precision: 0.9607 - val_Recall: 0.9492 - val_TP: 763.1800 - val_TN: 1081.9900 - val_FP: 24.0100 - val_FN: 40.8200\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0549 - Accuracy: 0.9876 - Precision: 0.9666 - Recall: 0.9649 - TP: 3253.6899 - TN: 5563.5898 - FP: 83.4100 - FN: 118.3100 - val_loss: 0.1197 - val_Accuracy: 0.9738 - val_Precision: 0.9546 - val_Recall: 0.9529 - val_TP: 766.1300 - val_TN: 1076.6200 - val_FP: 29.3800 - val_FN: 37.8700\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0433 - Accuracy: 0.9878 - Precision: 0.9677 - Recall: 0.9640 - TP: 3250.5500 - TN: 5567.7798 - FP: 79.2200 - FN: 121.4500 - val_loss: 0.1150 - val_Accuracy: 0.9754 - val_Precision: 0.9530 - val_Recall: 0.9555 - val_TP: 768.1900 - val_TN: 1075.1600 - val_FP: 30.8400 - val_FN: 35.8100\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0423 - Accuracy: 0.9876 - Precision: 0.9670 - Recall: 0.9651 - TP: 3254.2700 - TN: 5564.7202 - FP: 82.2800 - FN: 117.7300 - val_loss: 0.1398 - val_Accuracy: 0.9728 - val_Precision: 0.9494 - val_Recall: 0.9504 - val_TP: 764.1100 - val_TN: 1071.7400 - val_FP: 34.2600 - val_FN: 39.8900\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0438 - Accuracy: 0.9881 - Precision: 0.9676 - Recall: 0.9654 - TP: 3255.2200 - TN: 5567.2900 - FP: 79.7100 - FN: 116.7800 - val_loss: 0.1811 - val_Accuracy: 0.9455 - val_Precision: 0.9037 - val_Recall: 0.9561 - val_TP: 768.7300 - val_TN: 1029.3400 - val_FP: 76.6600 - val_FN: 35.2700\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0503 - Accuracy: 0.9884 - Precision: 0.9670 - Recall: 0.9647 - TP: 3253.0500 - TN: 5564.8599 - FP: 82.1400 - FN: 118.9500 - val_loss: 0.1140 - val_Accuracy: 0.9764 - val_Precision: 0.9661 - val_Recall: 0.9466 - val_TP: 761.0800 - val_TN: 1086.5400 - val_FP: 19.4600 - val_FN: 42.9200\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0510 - Accuracy: 0.9869 - Precision: 0.9665 - Recall: 0.9631 - TP: 3247.4299 - TN: 5563.4399 - FP: 83.5600 - FN: 124.5700 - val_loss: 0.1251 - val_Accuracy: 0.9749 - val_Precision: 0.9526 - val_Recall: 0.9544 - val_TP: 767.3400 - val_TN: 1074.8400 - val_FP: 31.1600 - val_FN: 36.6600\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0384 - Accuracy: 0.9891 - Precision: 0.9678 - Recall: 0.9661 - TP: 3257.6201 - TN: 5567.6299 - FP: 79.3700 - FN: 114.3800 - val_loss: 0.1251 - val_Accuracy: 0.9743 - val_Precision: 0.9562 - val_Recall: 0.9511 - val_TP: 764.7100 - val_TN: 1078.1600 - val_FP: 27.8400 - val_FN: 39.2900\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0432 - Accuracy: 0.9872 - Precision: 0.9673 - Recall: 0.9647 - TP: 3252.9500 - TN: 5566.0200 - FP: 80.9800 - FN: 119.0500 - val_loss: 0.1308 - val_Accuracy: 0.9723 - val_Precision: 0.9496 - val_Recall: 0.9541 - val_TP: 767.0700 - val_TN: 1072.3400 - val_FP: 33.6600 - val_FN: 36.9300\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0575 - Accuracy: 0.9868 - Precision: 0.9665 - Recall: 0.9639 - TP: 3250.4199 - TN: 5563.3701 - FP: 83.6300 - FN: 121.5800 - val_loss: 0.1179 - val_Accuracy: 0.9754 - val_Precision: 0.9580 - val_Recall: 0.9523 - val_TP: 765.6700 - val_TN: 1079.6000 - val_FP: 26.4000 - val_FN: 38.3300\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0535 - Accuracy: 0.9875 - Precision: 0.9671 - Recall: 0.9648 - TP: 3253.3501 - TN: 5565.5698 - FP: 81.4300 - FN: 118.6500 - val_loss: 0.1195 - val_Accuracy: 0.9754 - val_Precision: 0.9548 - val_Recall: 0.9538 - val_TP: 766.8400 - val_TN: 1076.8400 - val_FP: 29.1600 - val_FN: 37.1600\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0532 - Accuracy: 0.9868 - Precision: 0.9668 - Recall: 0.9644 - TP: 3251.9299 - TN: 5564.3999 - FP: 82.6000 - FN: 120.0700 - val_loss: 0.1169 - val_Accuracy: 0.9749 - val_Precision: 0.9556 - val_Recall: 0.9535 - val_TP: 766.6500 - val_TN: 1077.5400 - val_FP: 28.4600 - val_FN: 37.3500\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0406 - Accuracy: 0.9871 - Precision: 0.9670 - Recall: 0.9649 - TP: 3253.5500 - TN: 5564.7798 - FP: 82.2200 - FN: 118.4500 - val_loss: 0.1226 - val_Accuracy: 0.9728 - val_Precision: 0.9602 - val_Recall: 0.9483 - val_TP: 762.4100 - val_TN: 1081.6500 - val_FP: 24.3500 - val_FN: 41.5900\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0493 - Accuracy: 0.9881 - Precision: 0.9670 - Recall: 0.9644 - TP: 3252.0400 - TN: 5565.1299 - FP: 81.8700 - FN: 119.9600 - val_loss: 0.1162 - val_Accuracy: 0.9749 - val_Precision: 0.9638 - val_Recall: 0.9486 - val_TP: 762.6400 - val_TN: 1084.6200 - val_FP: 21.3800 - val_FN: 41.3600\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0619 - Accuracy: 0.9884 - Precision: 0.9681 - Recall: 0.9652 - TP: 3254.4900 - TN: 5569.0098 - FP: 77.9900 - FN: 117.5100 - val_loss: 0.1190 - val_Accuracy: 0.9754 - val_Precision: 0.9557 - val_Recall: 0.9530 - val_TP: 766.2500 - val_TN: 1077.6500 - val_FP: 28.3500 - val_FN: 37.7500\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0694 - Accuracy: 0.9870 - Precision: 0.9666 - Recall: 0.9632 - TP: 3247.8101 - TN: 5563.8198 - FP: 83.1800 - FN: 124.1900 - val_loss: 0.1176 - val_Accuracy: 0.9759 - val_Precision: 0.9511 - val_Recall: 0.9571 - val_TP: 769.5000 - val_TN: 1073.3800 - val_FP: 32.6200 - val_FN: 34.5000\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0426 - Accuracy: 0.9877 - Precision: 0.9673 - Recall: 0.9663 - TP: 3258.2500 - TN: 5566.2100 - FP: 80.7900 - FN: 113.7500 - val_loss: 0.1166 - val_Accuracy: 0.9764 - val_Precision: 0.9652 - val_Recall: 0.9489 - val_TP: 762.8800 - val_TN: 1085.7600 - val_FP: 20.2400 - val_FN: 41.1200\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0437 - Accuracy: 0.9877 - Precision: 0.9680 - Recall: 0.9654 - TP: 3255.2100 - TN: 5568.7500 - FP: 78.2500 - FN: 116.7900 - val_loss: 0.1184 - val_Accuracy: 0.9754 - val_Precision: 0.9625 - val_Recall: 0.9487 - val_TP: 762.7400 - val_TN: 1083.4900 - val_FP: 22.5100 - val_FN: 41.2600\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0489 - Accuracy: 0.9870 - Precision: 0.9679 - Recall: 0.9645 - TP: 3252.4500 - TN: 5568.2002 - FP: 78.8000 - FN: 119.5500 - val_loss: 0.1291 - val_Accuracy: 0.9749 - val_Precision: 0.9483 - val_Recall: 0.9571 - val_TP: 769.5400 - val_TN: 1071.0100 - val_FP: 34.9900 - val_FN: 34.4600\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 5ms/step - loss: 0.0468 - Accuracy: 0.9872 - Precision: 0.9670 - Recall: 0.9641 - TP: 3250.8501 - TN: 5565.1099 - FP: 81.8900 - FN: 121.1500 - val_loss: 0.1127 - val_Accuracy: 0.9754 - val_Precision: 0.9672 - val_Recall: 0.9463 - val_TP: 760.8000 - val_TN: 1087.4900 - val_FP: 18.5100 - val_FN: 43.2000\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0584 - Accuracy: 0.9858 - Precision: 0.9657 - Recall: 0.9636 - TP: 3249.2400 - TN: 5560.7402 - FP: 86.2600 - FN: 122.7600 - val_loss: 0.1256 - val_Accuracy: 0.9733 - val_Precision: 0.9557 - val_Recall: 0.9508 - val_TP: 764.4100 - val_TN: 1077.7400 - val_FP: 28.2600 - val_FN: 39.5900\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0775 - Accuracy: 0.9856 - Precision: 0.9654 - Recall: 0.9621 - TP: 3244.1299 - TN: 5559.7900 - FP: 87.2100 - FN: 127.8700 - val_loss: 0.1131 - val_Accuracy: 0.9754 - val_Precision: 0.9565 - val_Recall: 0.9533 - val_TP: 766.4400 - val_TN: 1078.1100 - val_FP: 27.8900 - val_FN: 37.5600\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0411 - Accuracy: 0.9882 - Precision: 0.9671 - Recall: 0.9655 - TP: 3255.5200 - TN: 5565.4399 - FP: 81.5600 - FN: 116.4800 - val_loss: 0.1121 - val_Accuracy: 0.9770 - val_Precision: 0.9594 - val_Recall: 0.9527 - val_TP: 765.9400 - val_TN: 1080.7600 - val_FP: 25.2400 - val_FN: 38.0600\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0597 - Accuracy: 0.9875 - Precision: 0.9660 - Recall: 0.9633 - TP: 3248.1201 - TN: 5561.7798 - FP: 85.2200 - FN: 123.8800 - val_loss: 0.1190 - val_Accuracy: 0.9743 - val_Precision: 0.9562 - val_Recall: 0.9517 - val_TP: 765.1500 - val_TN: 1078.0699 - val_FP: 27.9300 - val_FN: 38.8500\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0543 - Accuracy: 0.9866 - Precision: 0.9663 - Recall: 0.9635 - TP: 3248.9399 - TN: 5562.5298 - FP: 84.4700 - FN: 123.0600 - val_loss: 0.1228 - val_Accuracy: 0.9743 - val_Precision: 0.9610 - val_Recall: 0.9474 - val_TP: 761.7000 - val_TN: 1082.3300 - val_FP: 23.6700 - val_FN: 42.3000\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0659 - Accuracy: 0.9863 - Precision: 0.9650 - Recall: 0.9636 - TP: 3249.2500 - TN: 5558.5400 - FP: 88.4600 - FN: 122.7500 - val_loss: 0.1162 - val_Accuracy: 0.9759 - val_Precision: 0.9658 - val_Recall: 0.9460 - val_TP: 760.5700 - val_TN: 1086.3101 - val_FP: 19.6900 - val_FN: 43.4300\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0663 - Accuracy: 0.9871 - Precision: 0.9661 - Recall: 0.9634 - TP: 3248.7200 - TN: 5562.0898 - FP: 84.9100 - FN: 123.2800 - val_loss: 0.1180 - val_Accuracy: 0.9749 - val_Precision: 0.9652 - val_Recall: 0.9470 - val_TP: 761.3800 - val_TN: 1085.8600 - val_FP: 20.1400 - val_FN: 42.6200\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0582 - Accuracy: 0.9865 - Precision: 0.9655 - Recall: 0.9634 - TP: 3248.7300 - TN: 5560.0400 - FP: 86.9600 - FN: 123.2700 - val_loss: 0.1256 - val_Accuracy: 0.9743 - val_Precision: 0.9711 - val_Recall: 0.9387 - val_TP: 754.7300 - val_TN: 1090.8700 - val_FP: 15.1300 - val_FN: 49.2700\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0466 - Accuracy: 0.9871 - Precision: 0.9676 - Recall: 0.9642 - TP: 3251.4199 - TN: 5567.4502 - FP: 79.5500 - FN: 120.5800 - val_loss: 0.1155 - val_Accuracy: 0.9770 - val_Precision: 0.9590 - val_Recall: 0.9535 - val_TP: 766.5900 - val_TN: 1080.3600 - val_FP: 25.6400 - val_FN: 37.4100\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0462 - Accuracy: 0.9875 - Precision: 0.9671 - Recall: 0.9650 - TP: 3254.0100 - TN: 5565.6099 - FP: 81.3900 - FN: 117.9900 - val_loss: 0.1164 - val_Accuracy: 0.9764 - val_Precision: 0.9665 - val_Recall: 0.9470 - val_TP: 761.4200 - val_TN: 1086.9399 - val_FP: 19.0600 - val_FN: 42.5800\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0543 - Accuracy: 0.9870 - Precision: 0.9668 - Recall: 0.9643 - TP: 3251.6499 - TN: 5564.4600 - FP: 82.5400 - FN: 120.3500 - val_loss: 0.1156 - val_Accuracy: 0.9759 - val_Precision: 0.9611 - val_Recall: 0.9516 - val_TP: 765.0500 - val_TN: 1082.2300 - val_FP: 23.7700 - val_FN: 38.9500\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0602 - Accuracy: 0.9869 - Precision: 0.9669 - Recall: 0.9642 - TP: 3251.3601 - TN: 5564.8701 - FP: 82.1300 - FN: 120.6400 - val_loss: 0.1310 - val_Accuracy: 0.9738 - val_Precision: 0.9468 - val_Recall: 0.9554 - val_TP: 768.1600 - val_TN: 1069.6100 - val_FP: 36.3900 - val_FN: 35.8400\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0635 - Accuracy: 0.9874 - Precision: 0.9669 - Recall: 0.9647 - TP: 3253.0701 - TN: 5565.0098 - FP: 81.9900 - FN: 118.9300 - val_loss: 0.1158 - val_Accuracy: 0.9754 - val_Precision: 0.9617 - val_Recall: 0.9505 - val_TP: 764.1900 - val_TN: 1082.8101 - val_FP: 23.1900 - val_FN: 39.8100\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0786 - Accuracy: 0.9864 - Precision: 0.9658 - Recall: 0.9624 - TP: 3245.1001 - TN: 5561.5298 - FP: 85.4700 - FN: 126.9000 - val_loss: 0.1157 - val_Accuracy: 0.9764 - val_Precision: 0.9526 - val_Recall: 0.9566 - val_TP: 769.1000 - val_TN: 1074.6700 - val_FP: 31.3300 - val_FN: 34.9000\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0503 - Accuracy: 0.9867 - Precision: 0.9660 - Recall: 0.9645 - TP: 3252.2400 - TN: 5561.6899 - FP: 85.3100 - FN: 119.7600 - val_loss: 0.1223 - val_Accuracy: 0.9738 - val_Precision: 0.9602 - val_Recall: 0.9495 - val_TP: 763.4100 - val_TN: 1081.5900 - val_FP: 24.4100 - val_FN: 40.5900\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0497 - Accuracy: 0.9879 - Precision: 0.9669 - Recall: 0.9648 - TP: 3253.1499 - TN: 5564.9800 - FP: 82.0200 - FN: 118.8500 - val_loss: 0.1177 - val_Accuracy: 0.9743 - val_Precision: 0.9598 - val_Recall: 0.9515 - val_TP: 765.0100 - val_TN: 1081.1000 - val_FP: 24.9000 - val_FN: 38.9900\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0361 - Accuracy: 0.9885 - Precision: 0.9688 - Recall: 0.9662 - TP: 3258.1599 - TN: 5571.5698 - FP: 75.4300 - FN: 113.8400 - val_loss: 0.1225 - val_Accuracy: 0.9749 - val_Precision: 0.9552 - val_Recall: 0.9538 - val_TP: 766.8800 - val_TN: 1077.2400 - val_FP: 28.7600 - val_FN: 37.1200\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0377 - Accuracy: 0.9874 - Precision: 0.9679 - Recall: 0.9660 - TP: 3257.3999 - TN: 5568.3398 - FP: 78.6600 - FN: 114.6000 - val_loss: 0.1178 - val_Accuracy: 0.9764 - val_Precision: 0.9615 - val_Recall: 0.9515 - val_TP: 765.0100 - val_TN: 1082.5601 - val_FP: 23.4400 - val_FN: 38.9900\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0427 - Accuracy: 0.9882 - Precision: 0.9680 - Recall: 0.9649 - TP: 3253.7800 - TN: 5568.3999 - FP: 78.6000 - FN: 118.2200 - val_loss: 0.1238 - val_Accuracy: 0.9743 - val_Precision: 0.9554 - val_Recall: 0.9531 - val_TP: 766.2900 - val_TN: 1077.3500 - val_FP: 28.6500 - val_FN: 37.7100\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0502 - Accuracy: 0.9884 - Precision: 0.9680 - Recall: 0.9667 - TP: 3259.6599 - TN: 5568.6201 - FP: 78.3800 - FN: 112.3400 - val_loss: 0.1268 - val_Accuracy: 0.9759 - val_Precision: 0.9583 - val_Recall: 0.9514 - val_TP: 764.8900 - val_TN: 1079.9500 - val_FP: 26.0500 - val_FN: 39.1100\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0396 - Accuracy: 0.9879 - Precision: 0.9677 - Recall: 0.9652 - TP: 3254.5500 - TN: 5567.5898 - FP: 79.4100 - FN: 117.4500 - val_loss: 0.1364 - val_Accuracy: 0.9717 - val_Precision: 0.9517 - val_Recall: 0.9532 - val_TP: 766.3700 - val_TN: 1074.1801 - val_FP: 31.8200 - val_FN: 37.6300\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0480 - Accuracy: 0.9866 - Precision: 0.9674 - Recall: 0.9645 - TP: 3252.3401 - TN: 5566.8398 - FP: 80.1600 - FN: 119.6600 - val_loss: 0.1244 - val_Accuracy: 0.9754 - val_Precision: 0.9559 - val_Recall: 0.9539 - val_TP: 766.9400 - val_TN: 1077.8101 - val_FP: 28.1900 - val_FN: 37.0600\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0339 - Accuracy: 0.9882 - Precision: 0.9683 - Recall: 0.9664 - TP: 3258.8501 - TN: 5569.6201 - FP: 77.3800 - FN: 113.1500 - val_loss: 0.1328 - val_Accuracy: 0.9733 - val_Precision: 0.9580 - val_Recall: 0.9506 - val_TP: 764.3100 - val_TN: 1079.6801 - val_FP: 26.3200 - val_FN: 39.6900\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 6ms/step - loss: 0.0455 - Accuracy: 0.9871 - Precision: 0.9675 - Recall: 0.9642 - TP: 3251.4099 - TN: 5566.7202 - FP: 80.2800 - FN: 120.5900 - val_loss: 0.1577 - val_Accuracy: 0.9712 - val_Precision: 0.9306 - val_Recall: 0.9557 - val_TP: 768.3600 - val_TN: 1054.1899 - val_FP: 51.8100 - val_FN: 35.6400\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0544 - Accuracy: 0.9876 - Precision: 0.9663 - Recall: 0.9643 - TP: 3251.7600 - TN: 5562.6602 - FP: 84.3400 - FN: 120.2400 - val_loss: 0.1635 - val_Accuracy: 0.9686 - val_Precision: 0.9267 - val_Recall: 0.9521 - val_TP: 765.4500 - val_TN: 1050.8400 - val_FP: 55.1600 - val_FN: 38.5500\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0468 - Accuracy: 0.9878 - Precision: 0.9679 - Recall: 0.9657 - TP: 3256.4700 - TN: 5568.2900 - FP: 78.7100 - FN: 115.5300 - val_loss: 0.1189 - val_Accuracy: 0.9749 - val_Precision: 0.9664 - val_Recall: 0.9446 - val_TP: 759.4200 - val_TN: 1086.9000 - val_FP: 19.1000 - val_FN: 44.5800\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0386 - Accuracy: 0.9874 - Precision: 0.9679 - Recall: 0.9650 - TP: 3253.8999 - TN: 5568.3599 - FP: 78.6400 - FN: 118.1000 - val_loss: 0.1136 - val_Accuracy: 0.9775 - val_Precision: 0.9649 - val_Recall: 0.9494 - val_TP: 763.3500 - val_TN: 1085.4800 - val_FP: 20.5200 - val_FN: 40.6500\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0478 - Accuracy: 0.9870 - Precision: 0.9669 - Recall: 0.9651 - TP: 3254.2800 - TN: 5564.4102 - FP: 82.5900 - FN: 117.7200 - val_loss: 0.1138 - val_Accuracy: 0.9770 - val_Precision: 0.9653 - val_Recall: 0.9488 - val_TP: 762.8000 - val_TN: 1085.8500 - val_FP: 20.1500 - val_FN: 41.2000\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0628 - Accuracy: 0.9877 - Precision: 0.9667 - Recall: 0.9632 - TP: 3247.8101 - TN: 5564.3599 - FP: 82.6400 - FN: 124.1900 - val_loss: 0.1146 - val_Accuracy: 0.9759 - val_Precision: 0.9574 - val_Recall: 0.9537 - val_TP: 766.8100 - val_TN: 1078.9800 - val_FP: 27.0200 - val_FN: 37.1900\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0480 - Accuracy: 0.9877 - Precision: 0.9675 - Recall: 0.9647 - TP: 3253.1101 - TN: 5566.9199 - FP: 80.0800 - FN: 118.8900 - val_loss: 0.1137 - val_Accuracy: 0.9775 - val_Precision: 0.9560 - val_Recall: 0.9554 - val_TP: 768.1300 - val_TN: 1077.7500 - val_FP: 28.2500 - val_FN: 35.8700\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0616 - Accuracy: 0.9860 - Precision: 0.9660 - Recall: 0.9633 - TP: 3248.3799 - TN: 5561.9302 - FP: 85.0700 - FN: 123.6200 - val_loss: 0.1276 - val_Accuracy: 0.9728 - val_Precision: 0.9560 - val_Recall: 0.9522 - val_TP: 765.6000 - val_TN: 1077.9100 - val_FP: 28.0900 - val_FN: 38.4000\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0498 - Accuracy: 0.9863 - Precision: 0.9665 - Recall: 0.9647 - TP: 3253.0801 - TN: 5563.5698 - FP: 83.4300 - FN: 118.9200 - val_loss: 0.1143 - val_Accuracy: 0.9764 - val_Precision: 0.9633 - val_Recall: 0.9504 - val_TP: 764.1300 - val_TN: 1084.1100 - val_FP: 21.8900 - val_FN: 39.8700\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0501 - Accuracy: 0.9871 - Precision: 0.9677 - Recall: 0.9647 - TP: 3253.0701 - TN: 5567.9902 - FP: 79.0100 - FN: 118.9300 - val_loss: 0.1174 - val_Accuracy: 0.9759 - val_Precision: 0.9550 - val_Recall: 0.9548 - val_TP: 767.6200 - val_TN: 1076.9800 - val_FP: 29.0200 - val_FN: 36.3800\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0435 - Accuracy: 0.9875 - Precision: 0.9673 - Recall: 0.9658 - TP: 3256.8401 - TN: 5566.0801 - FP: 80.9200 - FN: 115.1600 - val_loss: 0.1155 - val_Accuracy: 0.9754 - val_Precision: 0.9631 - val_Recall: 0.9501 - val_TP: 763.8600 - val_TN: 1083.9600 - val_FP: 22.0400 - val_FN: 40.1400\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0477 - Accuracy: 0.9866 - Precision: 0.9669 - Recall: 0.9650 - TP: 3253.9900 - TN: 5564.7100 - FP: 82.2900 - FN: 118.0100 - val_loss: 0.1177 - val_Accuracy: 0.9754 - val_Precision: 0.9612 - val_Recall: 0.9509 - val_TP: 764.5100 - val_TN: 1082.3900 - val_FP: 23.6100 - val_FN: 39.4900\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0459 - Accuracy: 0.9879 - Precision: 0.9682 - Recall: 0.9650 - TP: 3254.1299 - TN: 5569.4302 - FP: 77.5700 - FN: 117.8700 - val_loss: 0.1463 - val_Accuracy: 0.9707 - val_Precision: 0.9534 - val_Recall: 0.9483 - val_TP: 762.4500 - val_TN: 1075.8101 - val_FP: 30.1900 - val_FN: 41.5500\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0612 - Accuracy: 0.9877 - Precision: 0.9674 - Recall: 0.9647 - TP: 3252.9299 - TN: 5566.7900 - FP: 80.2100 - FN: 119.0700 - val_loss: 0.1194 - val_Accuracy: 0.9754 - val_Precision: 0.9567 - val_Recall: 0.9533 - val_TP: 766.4200 - val_TN: 1078.5500 - val_FP: 27.4500 - val_FN: 37.5800\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0388 - Accuracy: 0.9886 - Precision: 0.9683 - Recall: 0.9660 - TP: 3257.3799 - TN: 5569.8398 - FP: 77.1600 - FN: 114.6200 - val_loss: 0.1229 - val_Accuracy: 0.9764 - val_Precision: 0.9602 - val_Recall: 0.9516 - val_TP: 765.0600 - val_TN: 1081.6200 - val_FP: 24.3800 - val_FN: 38.9400\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0619 - Accuracy: 0.9880 - Precision: 0.9675 - Recall: 0.9648 - TP: 3253.3999 - TN: 5566.8999 - FP: 80.1000 - FN: 118.6000 - val_loss: 0.1218 - val_Accuracy: 0.9754 - val_Precision: 0.9546 - val_Recall: 0.9543 - val_TP: 767.2500 - val_TN: 1076.7300 - val_FP: 29.2700 - val_FN: 36.7500\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0439 - Accuracy: 0.9884 - Precision: 0.9675 - Recall: 0.9664 - TP: 3258.7200 - TN: 5566.9502 - FP: 80.0500 - FN: 113.2800 - val_loss: 0.1291 - val_Accuracy: 0.9743 - val_Precision: 0.9635 - val_Recall: 0.9468 - val_TP: 761.2300 - val_TN: 1084.4800 - val_FP: 21.5200 - val_FN: 42.7700\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0470 - Accuracy: 0.9874 - Precision: 0.9676 - Recall: 0.9650 - TP: 3253.9800 - TN: 5567.3101 - FP: 79.6900 - FN: 118.0200 - val_loss: 0.1240 - val_Accuracy: 0.9749 - val_Precision: 0.9617 - val_Recall: 0.9491 - val_TP: 763.0900 - val_TN: 1082.9301 - val_FP: 23.0700 - val_FN: 40.9100\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0623 - Accuracy: 0.9859 - Precision: 0.9663 - Recall: 0.9633 - TP: 3248.2800 - TN: 5563.2500 - FP: 83.7500 - FN: 123.7200 - val_loss: 0.1283 - val_Accuracy: 0.9754 - val_Precision: 0.9511 - val_Recall: 0.9559 - val_TP: 768.5400 - val_TN: 1073.5100 - val_FP: 32.4900 - val_FN: 35.4600\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0392 - Accuracy: 0.9888 - Precision: 0.9677 - Recall: 0.9653 - TP: 3254.9600 - TN: 5567.4399 - FP: 79.5600 - FN: 117.0400 - val_loss: 0.1312 - val_Accuracy: 0.9743 - val_Precision: 0.9522 - val_Recall: 0.9550 - val_TP: 767.8600 - val_TN: 1074.6000 - val_FP: 31.4000 - val_FN: 36.1400\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0565 - Accuracy: 0.9887 - Precision: 0.9681 - Recall: 0.9660 - TP: 3257.4199 - TN: 5569.0698 - FP: 77.9300 - FN: 114.5800 - val_loss: 0.1253 - val_Accuracy: 0.9754 - val_Precision: 0.9628 - val_Recall: 0.9479 - val_TP: 762.0900 - val_TN: 1083.8800 - val_FP: 22.1200 - val_FN: 41.9100\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0674 - Accuracy: 0.9871 - Precision: 0.9667 - Recall: 0.9638 - TP: 3250.0400 - TN: 5564.3999 - FP: 82.6000 - FN: 121.9600 - val_loss: 0.1266 - val_Accuracy: 0.9749 - val_Precision: 0.9492 - val_Recall: 0.9566 - val_TP: 769.0800 - val_TN: 1071.8400 - val_FP: 34.1600 - val_FN: 34.9200\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0499 - Accuracy: 0.9863 - Precision: 0.9668 - Recall: 0.9643 - TP: 3251.7800 - TN: 5564.5400 - FP: 82.4600 - FN: 120.2200 - val_loss: 0.1316 - val_Accuracy: 0.9743 - val_Precision: 0.9559 - val_Recall: 0.9529 - val_TP: 766.1300 - val_TN: 1077.8600 - val_FP: 28.1400 - val_FN: 37.8700\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0560 - Accuracy: 0.9869 - Precision: 0.9665 - Recall: 0.9647 - TP: 3253.1201 - TN: 5564.0698 - FP: 82.9300 - FN: 118.8800 - val_loss: 0.1211 - val_Accuracy: 0.9770 - val_Precision: 0.9660 - val_Recall: 0.9480 - val_TP: 762.2000 - val_TN: 1086.5200 - val_FP: 19.4800 - val_FN: 41.8000\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0546 - Accuracy: 0.9871 - Precision: 0.9665 - Recall: 0.9641 - TP: 3251.0601 - TN: 5563.3999 - FP: 83.6000 - FN: 120.9400 - val_loss: 0.1234 - val_Accuracy: 0.9738 - val_Precision: 0.9601 - val_Recall: 0.9492 - val_TP: 763.1800 - val_TN: 1081.5300 - val_FP: 24.4700 - val_FN: 40.8200\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0544 - Accuracy: 0.9876 - Precision: 0.9671 - Recall: 0.9645 - TP: 3252.4600 - TN: 5565.5698 - FP: 81.4300 - FN: 119.5400 - val_loss: 0.1132 - val_Accuracy: 0.9780 - val_Precision: 0.9654 - val_Recall: 0.9494 - val_TP: 763.3000 - val_TN: 1085.9200 - val_FP: 20.0800 - val_FN: 40.7000\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0494 - Accuracy: 0.9876 - Precision: 0.9670 - Recall: 0.9649 - TP: 3253.4800 - TN: 5565.0098 - FP: 81.9900 - FN: 118.5200 - val_loss: 0.1211 - val_Accuracy: 0.9754 - val_Precision: 0.9575 - val_Recall: 0.9528 - val_TP: 766.0300 - val_TN: 1079.2000 - val_FP: 26.8000 - val_FN: 37.9700\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0493 - Accuracy: 0.9880 - Precision: 0.9684 - Recall: 0.9659 - TP: 3256.9900 - TN: 5570.3701 - FP: 76.6300 - FN: 115.0100 - val_loss: 0.1246 - val_Accuracy: 0.9733 - val_Precision: 0.9626 - val_Recall: 0.9469 - val_TP: 761.2700 - val_TN: 1083.7200 - val_FP: 22.2800 - val_FN: 42.7300\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0457 - Accuracy: 0.9870 - Precision: 0.9670 - Recall: 0.9641 - TP: 3250.9500 - TN: 5565.2598 - FP: 81.7400 - FN: 121.0500 - val_loss: 0.1141 - val_Accuracy: 0.9770 - val_Precision: 0.9603 - val_Recall: 0.9521 - val_TP: 765.5000 - val_TN: 1081.5100 - val_FP: 24.4900 - val_FN: 38.5000\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0639 - Accuracy: 0.9864 - Precision: 0.9654 - Recall: 0.9633 - TP: 3248.1101 - TN: 5559.6299 - FP: 87.3700 - FN: 123.8900 - val_loss: 0.1138 - val_Accuracy: 0.9770 - val_Precision: 0.9608 - val_Recall: 0.9517 - val_TP: 765.1700 - val_TN: 1081.9200 - val_FP: 24.0800 - val_FN: 38.8300\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0585 - Accuracy: 0.9870 - Precision: 0.9669 - Recall: 0.9641 - TP: 3251.0300 - TN: 5564.6099 - FP: 82.3900 - FN: 120.9700 - val_loss: 0.1185 - val_Accuracy: 0.9749 - val_Precision: 0.9620 - val_Recall: 0.9503 - val_TP: 764.0100 - val_TN: 1083.1500 - val_FP: 22.8500 - val_FN: 39.9900\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0489 - Accuracy: 0.9875 - Precision: 0.9665 - Recall: 0.9652 - TP: 3254.7400 - TN: 5563.6899 - FP: 83.3100 - FN: 117.2600 - val_loss: 0.1265 - val_Accuracy: 0.9749 - val_Precision: 0.9638 - val_Recall: 0.9464 - val_TP: 760.8800 - val_TN: 1084.7200 - val_FP: 21.2800 - val_FN: 43.1200\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0403 - Accuracy: 0.9874 - Precision: 0.9674 - Recall: 0.9652 - TP: 3254.8000 - TN: 5566.6201 - FP: 80.3800 - FN: 117.2000 - val_loss: 0.1268 - val_Accuracy: 0.9743 - val_Precision: 0.9634 - val_Recall: 0.9461 - val_TP: 760.7000 - val_TN: 1084.3900 - val_FP: 21.6100 - val_FN: 43.3000\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0626 - Accuracy: 0.9872 - Precision: 0.9677 - Recall: 0.9646 - TP: 3252.6599 - TN: 5567.9902 - FP: 79.0100 - FN: 119.3400 - val_loss: 0.1188 - val_Accuracy: 0.9754 - val_Precision: 0.9603 - val_Recall: 0.9508 - val_TP: 764.4600 - val_TN: 1081.6200 - val_FP: 24.3800 - val_FN: 39.5400\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0602 - Accuracy: 0.9880 - Precision: 0.9678 - Recall: 0.9650 - TP: 3254.0500 - TN: 5568.3398 - FP: 78.6600 - FN: 117.9500 - val_loss: 0.1226 - val_Accuracy: 0.9754 - val_Precision: 0.9513 - val_Recall: 0.9558 - val_TP: 768.5000 - val_TN: 1073.7300 - val_FP: 32.2700 - val_FN: 35.5000\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0870 - Accuracy: 0.9876 - Precision: 0.9660 - Recall: 0.9647 - TP: 3253.1001 - TN: 5561.9102 - FP: 85.0900 - FN: 118.9000 - val_loss: 0.1266 - val_Accuracy: 0.9738 - val_Precision: 0.9653 - val_Recall: 0.9446 - val_TP: 759.4700 - val_TN: 1086.0400 - val_FP: 19.9600 - val_FN: 44.5300\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0792 - Accuracy: 0.9875 - Precision: 0.9666 - Recall: 0.9642 - TP: 3251.1899 - TN: 5564.2202 - FP: 82.7800 - FN: 120.8100 - val_loss: 0.1360 - val_Accuracy: 0.9717 - val_Precision: 0.9553 - val_Recall: 0.9504 - val_TP: 764.1400 - val_TN: 1077.4100 - val_FP: 28.5900 - val_FN: 39.8600\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0382 - Accuracy: 0.9870 - Precision: 0.9684 - Recall: 0.9656 - TP: 3255.9199 - TN: 5570.5098 - FP: 76.4900 - FN: 116.0800 - val_loss: 0.1186 - val_Accuracy: 0.9775 - val_Precision: 0.9648 - val_Recall: 0.9489 - val_TP: 762.9000 - val_TN: 1085.4500 - val_FP: 20.5500 - val_FN: 41.1000\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0668 - Accuracy: 0.9870 - Precision: 0.9662 - Recall: 0.9646 - TP: 3252.7000 - TN: 5562.5400 - FP: 84.4600 - FN: 119.3000 - val_loss: 0.1198 - val_Accuracy: 0.9754 - val_Precision: 0.9640 - val_Recall: 0.9499 - val_TP: 763.6800 - val_TN: 1084.8101 - val_FP: 21.1900 - val_FN: 40.3200\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0706 - Accuracy: 0.9868 - Precision: 0.9663 - Recall: 0.9639 - TP: 3250.1299 - TN: 5563.1802 - FP: 83.8200 - FN: 121.8700 - val_loss: 0.1193 - val_Accuracy: 0.9759 - val_Precision: 0.9592 - val_Recall: 0.9526 - val_TP: 765.8800 - val_TN: 1080.6300 - val_FP: 25.3700 - val_FN: 38.1200\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0515 - Accuracy: 0.9871 - Precision: 0.9680 - Recall: 0.9662 - TP: 3257.9399 - TN: 5569.3398 - FP: 77.6600 - FN: 114.0600 - val_loss: 0.1211 - val_Accuracy: 0.9764 - val_Precision: 0.9641 - val_Recall: 0.9499 - val_TP: 763.7400 - val_TN: 1084.8800 - val_FP: 21.1200 - val_FN: 40.2600\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0478 - Accuracy: 0.9871 - Precision: 0.9682 - Recall: 0.9644 - TP: 3251.9700 - TN: 5569.9199 - FP: 77.0800 - FN: 120.0300 - val_loss: 0.1210 - val_Accuracy: 0.9764 - val_Precision: 0.9538 - val_Recall: 0.9566 - val_TP: 769.1100 - val_TN: 1075.8400 - val_FP: 30.1600 - val_FN: 34.8900\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0439 - Accuracy: 0.9882 - Precision: 0.9668 - Recall: 0.9665 - TP: 3258.9900 - TN: 5564.6099 - FP: 82.3900 - FN: 113.0100 - val_loss: 0.1267 - val_Accuracy: 0.9749 - val_Precision: 0.9695 - val_Recall: 0.9429 - val_TP: 758.1100 - val_TN: 1089.5200 - val_FP: 16.4800 - val_FN: 45.8900\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0470 - Accuracy: 0.9859 - Precision: 0.9670 - Recall: 0.9639 - TP: 3250.3501 - TN: 5565.6099 - FP: 81.3900 - FN: 121.6500 - val_loss: 0.1282 - val_Accuracy: 0.9738 - val_Precision: 0.9543 - val_Recall: 0.9531 - val_TP: 766.3100 - val_TN: 1076.4600 - val_FP: 29.5400 - val_FN: 37.6900\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0617 - Accuracy: 0.9869 - Precision: 0.9665 - Recall: 0.9647 - TP: 3253.0000 - TN: 5564.2798 - FP: 82.7200 - FN: 119.0000 - val_loss: 0.1245 - val_Accuracy: 0.9743 - val_Precision: 0.9606 - val_Recall: 0.9500 - val_TP: 763.7900 - val_TN: 1081.9700 - val_FP: 24.0300 - val_FN: 40.2100\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0406 - Accuracy: 0.9885 - Precision: 0.9683 - Recall: 0.9660 - TP: 3257.4500 - TN: 5569.7402 - FP: 77.2600 - FN: 114.5500 - val_loss: 0.1376 - val_Accuracy: 0.9743 - val_Precision: 0.9637 - val_Recall: 0.9457 - val_TP: 760.3600 - val_TN: 1084.7000 - val_FP: 21.3000 - val_FN: 43.6400\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 10ms/step - loss: 0.0464 - Accuracy: 0.9876 - Precision: 0.9677 - Recall: 0.9647 - TP: 3252.9399 - TN: 5567.5498 - FP: 79.4500 - FN: 119.0600 - val_loss: 0.1141 - val_Accuracy: 0.9770 - val_Precision: 0.9621 - val_Recall: 0.9516 - val_TP: 765.0900 - val_TN: 1083.1400 - val_FP: 22.8600 - val_FN: 38.9100\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0616 - Accuracy: 0.9875 - Precision: 0.9672 - Recall: 0.9646 - TP: 3252.6299 - TN: 5565.9399 - FP: 81.0600 - FN: 119.3700 - val_loss: 0.1171 - val_Accuracy: 0.9754 - val_Precision: 0.9603 - val_Recall: 0.9505 - val_TP: 764.2100 - val_TN: 1081.6899 - val_FP: 24.3100 - val_FN: 39.7900\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0578 - Accuracy: 0.9870 - Precision: 0.9661 - Recall: 0.9640 - TP: 3250.6599 - TN: 5562.1802 - FP: 84.8200 - FN: 121.3400 - val_loss: 0.1126 - val_Accuracy: 0.9780 - val_Precision: 0.9596 - val_Recall: 0.9538 - val_TP: 766.8900 - val_TN: 1080.8900 - val_FP: 25.1100 - val_FN: 37.1100\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0457 - Accuracy: 0.9880 - Precision: 0.9675 - Recall: 0.9651 - TP: 3254.3601 - TN: 5566.9600 - FP: 80.0400 - FN: 117.6400 - val_loss: 0.1136 - val_Accuracy: 0.9764 - val_Precision: 0.9564 - val_Recall: 0.9552 - val_TP: 768.0200 - val_TN: 1078.1000 - val_FP: 27.9000 - val_FN: 35.9800\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0828 - Accuracy: 0.9867 - Precision: 0.9657 - Recall: 0.9635 - TP: 3248.9900 - TN: 5561.0098 - FP: 85.9900 - FN: 123.0100 - val_loss: 0.1300 - val_Accuracy: 0.9743 - val_Precision: 0.9630 - val_Recall: 0.9459 - val_TP: 760.5400 - val_TN: 1084.0699 - val_FP: 21.9300 - val_FN: 43.4600\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0443 - Accuracy: 0.9867 - Precision: 0.9676 - Recall: 0.9649 - TP: 3253.5400 - TN: 5567.4800 - FP: 79.5200 - FN: 118.4600 - val_loss: 0.1181 - val_Accuracy: 0.9759 - val_Precision: 0.9649 - val_Recall: 0.9482 - val_TP: 762.3400 - val_TN: 1085.5800 - val_FP: 20.4200 - val_FN: 41.6600\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0604 - Accuracy: 0.9880 - Precision: 0.9675 - Recall: 0.9658 - TP: 3256.6899 - TN: 5566.9502 - FP: 80.0500 - FN: 115.3100 - val_loss: 0.1320 - val_Accuracy: 0.9749 - val_Precision: 0.9656 - val_Recall: 0.9453 - val_TP: 759.9900 - val_TN: 1086.3199 - val_FP: 19.6800 - val_FN: 44.0100\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0405 - Accuracy: 0.9871 - Precision: 0.9682 - Recall: 0.9650 - TP: 3253.9600 - TN: 5569.6499 - FP: 77.3500 - FN: 118.0400 - val_loss: 0.1217 - val_Accuracy: 0.9733 - val_Precision: 0.9592 - val_Recall: 0.9511 - val_TP: 764.7100 - val_TN: 1080.7100 - val_FP: 25.2900 - val_FN: 39.2900\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0628 - Accuracy: 0.9876 - Precision: 0.9666 - Recall: 0.9647 - TP: 3253.0901 - TN: 5563.9302 - FP: 83.0700 - FN: 118.9100 - val_loss: 0.1306 - val_Accuracy: 0.9754 - val_Precision: 0.9605 - val_Recall: 0.9507 - val_TP: 764.3800 - val_TN: 1081.9399 - val_FP: 24.0600 - val_FN: 39.6200\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0514 - Accuracy: 0.9866 - Precision: 0.9670 - Recall: 0.9647 - TP: 3253.0901 - TN: 5565.5298 - FP: 81.4700 - FN: 118.9100 - val_loss: 0.1203 - val_Accuracy: 0.9759 - val_Precision: 0.9648 - val_Recall: 0.9481 - val_TP: 762.3000 - val_TN: 1085.4600 - val_FP: 20.5400 - val_FN: 41.7000\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0495 - Accuracy: 0.9877 - Precision: 0.9672 - Recall: 0.9651 - TP: 3254.3701 - TN: 5565.9199 - FP: 81.0800 - FN: 117.6300 - val_loss: 0.1255 - val_Accuracy: 0.9743 - val_Precision: 0.9647 - val_Recall: 0.9457 - val_TP: 760.3500 - val_TN: 1085.5699 - val_FP: 20.4300 - val_FN: 43.6500\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0492 - Accuracy: 0.9861 - Precision: 0.9674 - Recall: 0.9639 - TP: 3250.1599 - TN: 5567.1499 - FP: 79.8500 - FN: 121.8400 - val_loss: 0.1179 - val_Accuracy: 0.9759 - val_Precision: 0.9574 - val_Recall: 0.9537 - val_TP: 766.7800 - val_TN: 1078.9800 - val_FP: 27.0200 - val_FN: 37.2200\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0728 - Accuracy: 0.9871 - Precision: 0.9659 - Recall: 0.9648 - TP: 3253.1499 - TN: 5561.4199 - FP: 85.5800 - FN: 118.8500 - val_loss: 0.1363 - val_Accuracy: 0.9723 - val_Precision: 0.9558 - val_Recall: 0.9500 - val_TP: 763.8000 - val_TN: 1077.8300 - val_FP: 28.1700 - val_FN: 40.2000\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0397 - Accuracy: 0.9890 - Precision: 0.9692 - Recall: 0.9656 - TP: 3255.8701 - TN: 5573.0298 - FP: 73.9700 - FN: 116.1300 - val_loss: 0.1287 - val_Accuracy: 0.9743 - val_Precision: 0.9560 - val_Recall: 0.9539 - val_TP: 766.9100 - val_TN: 1077.9100 - val_FP: 28.0900 - val_FN: 37.0900\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0545 - Accuracy: 0.9864 - Precision: 0.9659 - Recall: 0.9651 - TP: 3254.1899 - TN: 5561.6299 - FP: 85.3700 - FN: 117.8100 - val_loss: 0.1237 - val_Accuracy: 0.9728 - val_Precision: 0.9587 - val_Recall: 0.9505 - val_TP: 764.1900 - val_TN: 1080.1600 - val_FP: 25.8400 - val_FN: 39.8100\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0519 - Accuracy: 0.9872 - Precision: 0.9673 - Recall: 0.9637 - TP: 3249.7600 - TN: 5566.2202 - FP: 80.7800 - FN: 122.2400 - val_loss: 0.1195 - val_Accuracy: 0.9754 - val_Precision: 0.9585 - val_Recall: 0.9535 - val_TP: 766.6400 - val_TN: 1080.0200 - val_FP: 25.9800 - val_FN: 37.3600\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0534 - Accuracy: 0.9869 - Precision: 0.9665 - Recall: 0.9642 - TP: 3251.1299 - TN: 5563.4702 - FP: 83.5300 - FN: 120.8700 - val_loss: 0.1324 - val_Accuracy: 0.9749 - val_Precision: 0.9515 - val_Recall: 0.9565 - val_TP: 769.0500 - val_TN: 1073.9600 - val_FP: 32.0400 - val_FN: 34.9500\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0692 - Accuracy: 0.9870 - Precision: 0.9664 - Recall: 0.9648 - TP: 3253.2300 - TN: 5563.4800 - FP: 83.5200 - FN: 118.7700 - val_loss: 0.1282 - val_Accuracy: 0.9743 - val_Precision: 0.9571 - val_Recall: 0.9519 - val_TP: 765.3500 - val_TN: 1078.9500 - val_FP: 27.0500 - val_FN: 38.6500\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0476 - Accuracy: 0.9875 - Precision: 0.9677 - Recall: 0.9654 - TP: 3255.4099 - TN: 5567.5698 - FP: 79.4300 - FN: 116.5900 - val_loss: 0.1282 - val_Accuracy: 0.9733 - val_Precision: 0.9625 - val_Recall: 0.9460 - val_TP: 760.5700 - val_TN: 1083.7300 - val_FP: 22.2700 - val_FN: 43.4300\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0640 - Accuracy: 0.9855 - Precision: 0.9672 - Recall: 0.9639 - TP: 3250.1201 - TN: 5566.2300 - FP: 80.7700 - FN: 121.8800 - val_loss: 0.1215 - val_Accuracy: 0.9733 - val_Precision: 0.9578 - val_Recall: 0.9530 - val_TP: 766.1800 - val_TN: 1079.4500 - val_FP: 26.5500 - val_FN: 37.8200\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0652 - Accuracy: 0.9866 - Precision: 0.9664 - Recall: 0.9651 - TP: 3254.4199 - TN: 5563.2002 - FP: 83.8000 - FN: 117.5800 - val_loss: 0.1343 - val_Accuracy: 0.9754 - val_Precision: 0.9621 - val_Recall: 0.9489 - val_TP: 762.9100 - val_TN: 1083.3400 - val_FP: 22.6600 - val_FN: 41.0900\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0468 - Accuracy: 0.9880 - Precision: 0.9682 - Recall: 0.9661 - TP: 3257.7600 - TN: 5569.7798 - FP: 77.2200 - FN: 114.2400 - val_loss: 0.1213 - val_Accuracy: 0.9764 - val_Precision: 0.9600 - val_Recall: 0.9535 - val_TP: 766.6500 - val_TN: 1081.3000 - val_FP: 24.7000 - val_FN: 37.3500\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0451 - Accuracy: 0.9871 - Precision: 0.9677 - Recall: 0.9660 - TP: 3257.2900 - TN: 5568.1401 - FP: 78.8600 - FN: 114.7100 - val_loss: 0.1300 - val_Accuracy: 0.9749 - val_Precision: 0.9707 - val_Recall: 0.9408 - val_TP: 756.4400 - val_TN: 1090.5699 - val_FP: 15.4300 - val_FN: 47.5600\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0566 - Accuracy: 0.9869 - Precision: 0.9668 - Recall: 0.9646 - TP: 3252.6201 - TN: 5564.7402 - FP: 82.2600 - FN: 119.3800 - val_loss: 0.1659 - val_Accuracy: 0.9665 - val_Precision: 0.9310 - val_Recall: 0.9546 - val_TP: 767.4700 - val_TN: 1055.1300 - val_FP: 50.8700 - val_FN: 36.5300\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0514 - Accuracy: 0.9867 - Precision: 0.9664 - Recall: 0.9646 - TP: 3252.7300 - TN: 5563.3799 - FP: 83.6200 - FN: 119.2700 - val_loss: 0.1195 - val_Accuracy: 0.9749 - val_Precision: 0.9703 - val_Recall: 0.9428 - val_TP: 758.0500 - val_TN: 1090.2100 - val_FP: 15.7900 - val_FN: 45.9500\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0608 - Accuracy: 0.9876 - Precision: 0.9674 - Recall: 0.9649 - TP: 3253.5801 - TN: 5566.6802 - FP: 80.3200 - FN: 118.4200 - val_loss: 0.1426 - val_Accuracy: 0.9712 - val_Precision: 0.9445 - val_Recall: 0.9548 - val_TP: 767.6500 - val_TN: 1067.8600 - val_FP: 38.1400 - val_FN: 36.3500\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0760 - Accuracy: 0.9864 - Precision: 0.9662 - Recall: 0.9635 - TP: 3249.0601 - TN: 5562.7998 - FP: 84.2000 - FN: 122.9400 - val_loss: 0.1172 - val_Accuracy: 0.9775 - val_Precision: 0.9661 - val_Recall: 0.9489 - val_TP: 762.9400 - val_TN: 1086.6200 - val_FP: 19.3800 - val_FN: 41.0600\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0432 - Accuracy: 0.9881 - Precision: 0.9672 - Recall: 0.9656 - TP: 3256.0601 - TN: 5565.9302 - FP: 81.0700 - FN: 115.9400 - val_loss: 0.1171 - val_Accuracy: 0.9770 - val_Precision: 0.9644 - val_Recall: 0.9494 - val_TP: 763.3000 - val_TN: 1085.0800 - val_FP: 20.9200 - val_FN: 40.7000\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0490 - Accuracy: 0.9878 - Precision: 0.9678 - Recall: 0.9654 - TP: 3255.2100 - TN: 5568.2598 - FP: 78.7400 - FN: 116.7900 - val_loss: 0.1228 - val_Accuracy: 0.9738 - val_Precision: 0.9617 - val_Recall: 0.9479 - val_TP: 762.1300 - val_TN: 1082.9900 - val_FP: 23.0100 - val_FN: 41.8700\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0627 - Accuracy: 0.9875 - Precision: 0.9671 - Recall: 0.9646 - TP: 3252.6699 - TN: 5565.5298 - FP: 81.4700 - FN: 119.3300 - val_loss: 0.1180 - val_Accuracy: 0.9775 - val_Precision: 0.9588 - val_Recall: 0.9540 - val_TP: 766.9900 - val_TN: 1080.3300 - val_FP: 25.6700 - val_FN: 37.0100\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0591 - Accuracy: 0.9863 - Precision: 0.9662 - Recall: 0.9639 - TP: 3250.1699 - TN: 5562.5098 - FP: 84.4900 - FN: 121.8300 - val_loss: 0.1222 - val_Accuracy: 0.9743 - val_Precision: 0.9655 - val_Recall: 0.9465 - val_TP: 761.0100 - val_TN: 1086.1000 - val_FP: 19.9000 - val_FN: 42.9900\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0491 - Accuracy: 0.9867 - Precision: 0.9670 - Recall: 0.9642 - TP: 3251.1499 - TN: 5565.2100 - FP: 81.7900 - FN: 120.8500 - val_loss: 0.1220 - val_Accuracy: 0.9759 - val_Precision: 0.9642 - val_Recall: 0.9473 - val_TP: 761.6600 - val_TN: 1085.0200 - val_FP: 20.9800 - val_FN: 42.3400\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0846 - Accuracy: 0.9871 - Precision: 0.9661 - Recall: 0.9635 - TP: 3248.9199 - TN: 5562.3701 - FP: 84.6300 - FN: 123.0800 - val_loss: 0.1382 - val_Accuracy: 0.9733 - val_Precision: 0.9552 - val_Recall: 0.9514 - val_TP: 764.8900 - val_TN: 1077.3700 - val_FP: 28.6300 - val_FN: 39.1100\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0429 - Accuracy: 0.9885 - Precision: 0.9677 - Recall: 0.9665 - TP: 3259.0601 - TN: 5567.9902 - FP: 79.0100 - FN: 112.9400 - val_loss: 0.1214 - val_Accuracy: 0.9749 - val_Precision: 0.9625 - val_Recall: 0.9499 - val_TP: 763.6800 - val_TN: 1083.5100 - val_FP: 22.4900 - val_FN: 40.3200\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0438 - Accuracy: 0.9878 - Precision: 0.9689 - Recall: 0.9653 - TP: 3254.9700 - TN: 5572.3398 - FP: 74.6600 - FN: 117.0300 - val_loss: 0.1270 - val_Accuracy: 0.9738 - val_Precision: 0.9470 - val_Recall: 0.9584 - val_TP: 770.5400 - val_TN: 1069.8800 - val_FP: 36.1200 - val_FN: 33.4600\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0488 - Accuracy: 0.9875 - Precision: 0.9669 - Recall: 0.9656 - TP: 3255.8799 - TN: 5564.9502 - FP: 82.0500 - FN: 116.1200 - val_loss: 0.1228 - val_Accuracy: 0.9764 - val_Precision: 0.9608 - val_Recall: 0.9505 - val_TP: 764.1800 - val_TN: 1082.0699 - val_FP: 23.9300 - val_FN: 39.8200\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0599 - Accuracy: 0.9880 - Precision: 0.9675 - Recall: 0.9647 - TP: 3253.1101 - TN: 5567.5498 - FP: 79.4500 - FN: 118.8900 - val_loss: 0.1202 - val_Accuracy: 0.9764 - val_Precision: 0.9609 - val_Recall: 0.9521 - val_TP: 765.4600 - val_TN: 1082.1200 - val_FP: 23.8800 - val_FN: 38.5400\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0435 - Accuracy: 0.9877 - Precision: 0.9673 - Recall: 0.9654 - TP: 3255.3799 - TN: 5566.2202 - FP: 80.7800 - FN: 116.6200 - val_loss: 0.1309 - val_Accuracy: 0.9728 - val_Precision: 0.9570 - val_Recall: 0.9521 - val_TP: 765.4700 - val_TN: 1078.9399 - val_FP: 27.0600 - val_FN: 38.5300\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0794 - Accuracy: 0.9850 - Precision: 0.9653 - Recall: 0.9631 - TP: 3247.4399 - TN: 5559.6401 - FP: 87.3600 - FN: 124.5600 - val_loss: 0.1315 - val_Accuracy: 0.9743 - val_Precision: 0.9590 - val_Recall: 0.9500 - val_TP: 763.8200 - val_TN: 1080.7100 - val_FP: 25.2900 - val_FN: 40.1800\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0344 - Accuracy: 0.9889 - Precision: 0.9695 - Recall: 0.9661 - TP: 3257.5601 - TN: 5574.3599 - FP: 72.6400 - FN: 114.4400 - val_loss: 0.1366 - val_Accuracy: 0.9764 - val_Precision: 0.9506 - val_Recall: 0.9562 - val_TP: 768.7700 - val_TN: 1073.1500 - val_FP: 32.8500 - val_FN: 35.2300\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0525 - Accuracy: 0.9872 - Precision: 0.9662 - Recall: 0.9656 - TP: 3256.1399 - TN: 5562.7798 - FP: 84.2200 - FN: 115.8600 - val_loss: 0.1321 - val_Accuracy: 0.9738 - val_Precision: 0.9626 - val_Recall: 0.9462 - val_TP: 760.7800 - val_TN: 1083.8400 - val_FP: 22.1600 - val_FN: 43.2200\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0663 - Accuracy: 0.9866 - Precision: 0.9672 - Recall: 0.9643 - TP: 3251.4900 - TN: 5566.4702 - FP: 80.5300 - FN: 120.5100 - val_loss: 0.1215 - val_Accuracy: 0.9764 - val_Precision: 0.9631 - val_Recall: 0.9507 - val_TP: 764.3800 - val_TN: 1084.0200 - val_FP: 21.9800 - val_FN: 39.6200\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0570 - Accuracy: 0.9882 - Precision: 0.9679 - Recall: 0.9655 - TP: 3255.6399 - TN: 5568.7998 - FP: 78.2000 - FN: 116.3600 - val_loss: 0.1225 - val_Accuracy: 0.9764 - val_Precision: 0.9623 - val_Recall: 0.9510 - val_TP: 764.6400 - val_TN: 1083.3400 - val_FP: 22.6600 - val_FN: 39.3600\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0430 - Accuracy: 0.9874 - Precision: 0.9671 - Recall: 0.9652 - TP: 3254.5400 - TN: 5565.5400 - FP: 81.4600 - FN: 117.4600 - val_loss: 0.1607 - val_Accuracy: 0.9691 - val_Precision: 0.9497 - val_Recall: 0.9490 - val_TP: 763.0100 - val_TN: 1072.5500 - val_FP: 33.4500 - val_FN: 40.9900\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0550 - Accuracy: 0.9871 - Precision: 0.9683 - Recall: 0.9654 - TP: 3255.4500 - TN: 5570.3901 - FP: 76.6100 - FN: 116.5500 - val_loss: 0.1416 - val_Accuracy: 0.9733 - val_Precision: 0.9485 - val_Recall: 0.9552 - val_TP: 767.9500 - val_TN: 1071.2900 - val_FP: 34.7100 - val_FN: 36.0500\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0407 - Accuracy: 0.9884 - Precision: 0.9686 - Recall: 0.9667 - TP: 3259.8401 - TN: 5571.1699 - FP: 75.8300 - FN: 112.1600 - val_loss: 0.1265 - val_Accuracy: 0.9749 - val_Precision: 0.9550 - val_Recall: 0.9550 - val_TP: 767.7900 - val_TN: 1077.1100 - val_FP: 28.8900 - val_FN: 36.2100\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0743 - Accuracy: 0.9864 - Precision: 0.9657 - Recall: 0.9640 - TP: 3250.7200 - TN: 5561.0200 - FP: 85.9800 - FN: 121.2800 - val_loss: 0.1400 - val_Accuracy: 0.9712 - val_Precision: 0.9454 - val_Recall: 0.9565 - val_TP: 769.0500 - val_TN: 1068.5200 - val_FP: 37.4800 - val_FN: 34.9500\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0674 - Accuracy: 0.9878 - Precision: 0.9683 - Recall: 0.9654 - TP: 3255.4700 - TN: 5570.3301 - FP: 76.6700 - FN: 116.5300 - val_loss: 0.1357 - val_Accuracy: 0.9728 - val_Precision: 0.9467 - val_Recall: 0.9584 - val_TP: 770.5900 - val_TN: 1069.7500 - val_FP: 36.2500 - val_FN: 33.4100\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 4ms/step - loss: 0.0713 - Accuracy: 0.9850 - Precision: 0.9650 - Recall: 0.9631 - TP: 3247.5100 - TN: 5558.9302 - FP: 88.0700 - FN: 124.4900 - val_loss: 0.1225 - val_Accuracy: 0.9733 - val_Precision: 0.9612 - val_Recall: 0.9486 - val_TP: 762.6700 - val_TN: 1082.4399 - val_FP: 23.5600 - val_FN: 41.3300\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0492 - Accuracy: 0.9877 - Precision: 0.9670 - Recall: 0.9648 - TP: 3253.4299 - TN: 5565.3198 - FP: 81.6800 - FN: 118.5700 - val_loss: 0.1182 - val_Accuracy: 0.9775 - val_Precision: 0.9578 - val_Recall: 0.9548 - val_TP: 767.6800 - val_TN: 1079.3900 - val_FP: 26.6100 - val_FN: 36.3200\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0515 - Accuracy: 0.9879 - Precision: 0.9678 - Recall: 0.9655 - TP: 3255.6799 - TN: 5568.2798 - FP: 78.7200 - FN: 116.3200 - val_loss: 0.1250 - val_Accuracy: 0.9728 - val_Precision: 0.9618 - val_Recall: 0.9475 - val_TP: 761.7500 - val_TN: 1082.9900 - val_FP: 23.0100 - val_FN: 42.2500\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0589 - Accuracy: 0.9864 - Precision: 0.9669 - Recall: 0.9645 - TP: 3252.2400 - TN: 5565.1299 - FP: 81.8700 - FN: 119.7600 - val_loss: 0.1240 - val_Accuracy: 0.9759 - val_Precision: 0.9577 - val_Recall: 0.9535 - val_TP: 766.6100 - val_TN: 1079.4500 - val_FP: 26.5500 - val_FN: 37.3900\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0586 - Accuracy: 0.9870 - Precision: 0.9672 - Recall: 0.9643 - TP: 3251.7400 - TN: 5566.5498 - FP: 80.4500 - FN: 120.2600 - val_loss: 0.1192 - val_Accuracy: 0.9780 - val_Precision: 0.9625 - val_Recall: 0.9522 - val_TP: 765.6000 - val_TN: 1083.4600 - val_FP: 22.5400 - val_FN: 38.4000\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0793 - Accuracy: 0.9867 - Precision: 0.9660 - Recall: 0.9648 - TP: 3253.1399 - TN: 5561.9600 - FP: 85.0400 - FN: 118.8600 - val_loss: 0.1226 - val_Accuracy: 0.9754 - val_Precision: 0.9651 - val_Recall: 0.9492 - val_TP: 763.1400 - val_TN: 1085.7700 - val_FP: 20.2300 - val_FN: 40.8600\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0532 - Accuracy: 0.9869 - Precision: 0.9668 - Recall: 0.9652 - TP: 3254.7900 - TN: 5564.8198 - FP: 82.1800 - FN: 117.2100 - val_loss: 0.1347 - val_Accuracy: 0.9743 - val_Precision: 0.9645 - val_Recall: 0.9453 - val_TP: 760.0300 - val_TN: 1085.4200 - val_FP: 20.5800 - val_FN: 43.9700\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0784 - Accuracy: 0.9863 - Precision: 0.9666 - Recall: 0.9629 - TP: 3246.9600 - TN: 5564.5200 - FP: 82.4800 - FN: 125.0400 - val_loss: 0.1248 - val_Accuracy: 0.9764 - val_Precision: 0.9671 - val_Recall: 0.9472 - val_TP: 761.5600 - val_TN: 1087.4800 - val_FP: 18.5200 - val_FN: 42.4400\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0474 - Accuracy: 0.9875 - Precision: 0.9675 - Recall: 0.9655 - TP: 3255.8000 - TN: 5567.3301 - FP: 79.6700 - FN: 116.2000 - val_loss: 0.1416 - val_Accuracy: 0.9723 - val_Precision: 0.9562 - val_Recall: 0.9509 - val_TP: 764.5300 - val_TN: 1078.2900 - val_FP: 27.7100 - val_FN: 39.4700\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0575 - Accuracy: 0.9882 - Precision: 0.9684 - Recall: 0.9659 - TP: 3256.9099 - TN: 5570.3301 - FP: 76.6700 - FN: 115.0900 - val_loss: 0.1291 - val_Accuracy: 0.9749 - val_Precision: 0.9584 - val_Recall: 0.9520 - val_TP: 765.4300 - val_TN: 1080.1000 - val_FP: 25.9000 - val_FN: 38.5700\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0553 - Accuracy: 0.9871 - Precision: 0.9678 - Recall: 0.9662 - TP: 3257.9099 - TN: 5568.2402 - FP: 78.7600 - FN: 114.0900 - val_loss: 0.1405 - val_Accuracy: 0.9728 - val_Precision: 0.9545 - val_Recall: 0.9506 - val_TP: 764.2800 - val_TN: 1076.8000 - val_FP: 29.2000 - val_FN: 39.7200\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0366 - Accuracy: 0.9889 - Precision: 0.9690 - Recall: 0.9667 - TP: 3259.7800 - TN: 5572.1099 - FP: 74.8900 - FN: 112.2200 - val_loss: 0.1294 - val_Accuracy: 0.9743 - val_Precision: 0.9610 - val_Recall: 0.9490 - val_TP: 762.9700 - val_TN: 1082.4000 - val_FP: 23.6000 - val_FN: 41.0300\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0513 - Accuracy: 0.9870 - Precision: 0.9671 - Recall: 0.9648 - TP: 3253.4600 - TN: 5566.0698 - FP: 80.9300 - FN: 118.5400 - val_loss: 0.1222 - val_Accuracy: 0.9770 - val_Precision: 0.9666 - val_Recall: 0.9490 - val_TP: 762.9600 - val_TN: 1087.0699 - val_FP: 18.9300 - val_FN: 41.0400\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0580 - Accuracy: 0.9890 - Precision: 0.9684 - Recall: 0.9664 - TP: 3258.6399 - TN: 5570.3198 - FP: 76.6800 - FN: 113.3600 - val_loss: 0.1319 - val_Accuracy: 0.9754 - val_Precision: 0.9571 - val_Recall: 0.9528 - val_TP: 766.0400 - val_TN: 1079.0000 - val_FP: 27.0000 - val_FN: 37.9600\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0479 - Accuracy: 0.9867 - Precision: 0.9675 - Recall: 0.9647 - TP: 3252.8999 - TN: 5567.3398 - FP: 79.6600 - FN: 119.1000 - val_loss: 0.1438 - val_Accuracy: 0.9728 - val_Precision: 0.9493 - val_Recall: 0.9539 - val_TP: 766.9600 - val_TN: 1072.0699 - val_FP: 33.9300 - val_FN: 37.0400\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0569 - Accuracy: 0.9874 - Precision: 0.9679 - Recall: 0.9660 - TP: 3257.4900 - TN: 5568.9800 - FP: 78.0200 - FN: 114.5100 - val_loss: 0.1422 - val_Accuracy: 0.9717 - val_Precision: 0.9523 - val_Recall: 0.9523 - val_TP: 765.6800 - val_TN: 1074.8400 - val_FP: 31.1600 - val_FN: 38.3200\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0446 - Accuracy: 0.9881 - Precision: 0.9674 - Recall: 0.9661 - TP: 3257.7300 - TN: 5566.6499 - FP: 80.3500 - FN: 114.2700 - val_loss: 0.1395 - val_Accuracy: 0.9749 - val_Precision: 0.9645 - val_Recall: 0.9458 - val_TP: 760.4100 - val_TN: 1085.4100 - val_FP: 20.5900 - val_FN: 43.5900\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0626 - Accuracy: 0.9872 - Precision: 0.9676 - Recall: 0.9640 - TP: 3250.5400 - TN: 5568.0200 - FP: 78.9800 - FN: 121.4600 - val_loss: 0.1251 - val_Accuracy: 0.9743 - val_Precision: 0.9584 - val_Recall: 0.9531 - val_TP: 766.2800 - val_TN: 1079.9200 - val_FP: 26.0800 - val_FN: 37.7200\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0699 - Accuracy: 0.9876 - Precision: 0.9669 - Recall: 0.9657 - TP: 3256.2800 - TN: 5565.1499 - FP: 81.8500 - FN: 115.7200 - val_loss: 0.1379 - val_Accuracy: 0.9738 - val_Precision: 0.9545 - val_Recall: 0.9524 - val_TP: 765.7600 - val_TN: 1076.7000 - val_FP: 29.3000 - val_FN: 38.2400\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0451 - Accuracy: 0.9881 - Precision: 0.9683 - Recall: 0.9655 - TP: 3255.5300 - TN: 5570.2002 - FP: 76.8000 - FN: 116.4700 - val_loss: 0.1341 - val_Accuracy: 0.9743 - val_Precision: 0.9530 - val_Recall: 0.9558 - val_TP: 768.4800 - val_TN: 1075.3700 - val_FP: 30.6300 - val_FN: 35.5200\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0591 - Accuracy: 0.9866 - Precision: 0.9667 - Recall: 0.9652 - TP: 3254.5500 - TN: 5564.2700 - FP: 82.7300 - FN: 117.4500 - val_loss: 0.1300 - val_Accuracy: 0.9749 - val_Precision: 0.9667 - val_Recall: 0.9454 - val_TP: 760.0800 - val_TN: 1087.2000 - val_FP: 18.8000 - val_FN: 43.9200\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0643 - Accuracy: 0.9875 - Precision: 0.9678 - Recall: 0.9654 - TP: 3255.4700 - TN: 5568.5298 - FP: 78.4700 - FN: 116.5300 - val_loss: 0.1243 - val_Accuracy: 0.9759 - val_Precision: 0.9601 - val_Recall: 0.9524 - val_TP: 765.6900 - val_TN: 1081.5100 - val_FP: 24.4900 - val_FN: 38.3100\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0709 - Accuracy: 0.9870 - Precision: 0.9665 - Recall: 0.9649 - TP: 3253.5000 - TN: 5564.1699 - FP: 82.8300 - FN: 118.5000 - val_loss: 0.1218 - val_Accuracy: 0.9743 - val_Precision: 0.9623 - val_Recall: 0.9493 - val_TP: 763.2500 - val_TN: 1083.3700 - val_FP: 22.6300 - val_FN: 40.7500\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0545 - Accuracy: 0.9870 - Precision: 0.9673 - Recall: 0.9637 - TP: 3249.5601 - TN: 5566.7300 - FP: 80.2700 - FN: 122.4400 - val_loss: 0.1229 - val_Accuracy: 0.9733 - val_Precision: 0.9490 - val_Recall: 0.9573 - val_TP: 769.6600 - val_TN: 1071.5699 - val_FP: 34.4300 - val_FN: 34.3400\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0644 - Accuracy: 0.9860 - Precision: 0.9663 - Recall: 0.9641 - TP: 3250.8401 - TN: 5563.2900 - FP: 83.7100 - FN: 121.1600 - val_loss: 0.1267 - val_Accuracy: 0.9738 - val_Precision: 0.9547 - val_Recall: 0.9531 - val_TP: 766.2900 - val_TN: 1076.8400 - val_FP: 29.1600 - val_FN: 37.7100\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0512 - Accuracy: 0.9871 - Precision: 0.9660 - Recall: 0.9653 - TP: 3255.0701 - TN: 5561.3901 - FP: 85.6100 - FN: 116.9300 - val_loss: 0.1248 - val_Accuracy: 0.9749 - val_Precision: 0.9694 - val_Recall: 0.9441 - val_TP: 759.0300 - val_TN: 1089.4600 - val_FP: 16.5400 - val_FN: 44.9700\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0720 - Accuracy: 0.9861 - Precision: 0.9675 - Recall: 0.9634 - TP: 3248.6899 - TN: 5567.4302 - FP: 79.5700 - FN: 123.3100 - val_loss: 0.1209 - val_Accuracy: 0.9764 - val_Precision: 0.9580 - val_Recall: 0.9540 - val_TP: 767.0000 - val_TN: 1079.5699 - val_FP: 26.4300 - val_FN: 37.0000\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0519 - Accuracy: 0.9871 - Precision: 0.9670 - Recall: 0.9648 - TP: 3253.3201 - TN: 5565.3799 - FP: 81.6200 - FN: 118.6800 - val_loss: 0.1307 - val_Accuracy: 0.9733 - val_Precision: 0.9563 - val_Recall: 0.9533 - val_TP: 766.4700 - val_TN: 1078.2400 - val_FP: 27.7600 - val_FN: 37.5300\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0732 - Accuracy: 0.9854 - Precision: 0.9667 - Recall: 0.9637 - TP: 3249.6201 - TN: 5564.6699 - FP: 82.3300 - FN: 122.3800 - val_loss: 0.1268 - val_Accuracy: 0.9733 - val_Precision: 0.9507 - val_Recall: 0.9548 - val_TP: 767.6500 - val_TN: 1073.2500 - val_FP: 32.7500 - val_FN: 36.3500\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0484 - Accuracy: 0.9874 - Precision: 0.9677 - Recall: 0.9655 - TP: 3255.7000 - TN: 5567.9302 - FP: 79.0700 - FN: 116.3000 - val_loss: 0.1250 - val_Accuracy: 0.9733 - val_Precision: 0.9455 - val_Recall: 0.9599 - val_TP: 771.7400 - val_TN: 1068.4100 - val_FP: 37.5900 - val_FN: 32.2600\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0653 - Accuracy: 0.9870 - Precision: 0.9662 - Recall: 0.9656 - TP: 3255.9299 - TN: 5562.7598 - FP: 84.2400 - FN: 116.0700 - val_loss: 0.1316 - val_Accuracy: 0.9728 - val_Precision: 0.9701 - val_Recall: 0.9397 - val_TP: 755.5300 - val_TN: 1090.0900 - val_FP: 15.9100 - val_FN: 48.4700\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0449 - Accuracy: 0.9878 - Precision: 0.9679 - Recall: 0.9657 - TP: 3256.3401 - TN: 5568.8901 - FP: 78.1100 - FN: 115.6600 - val_loss: 0.1276 - val_Accuracy: 0.9749 - val_Precision: 0.9636 - val_Recall: 0.9471 - val_TP: 761.4600 - val_TN: 1084.6300 - val_FP: 21.3700 - val_FN: 42.5400\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0714 - Accuracy: 0.9880 - Precision: 0.9676 - Recall: 0.9646 - TP: 3252.5300 - TN: 5567.3398 - FP: 79.6600 - FN: 119.4700 - val_loss: 0.1300 - val_Accuracy: 0.9733 - val_Precision: 0.9608 - val_Recall: 0.9477 - val_TP: 761.9800 - val_TN: 1082.2000 - val_FP: 23.8000 - val_FN: 42.0200\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0453 - Accuracy: 0.9879 - Precision: 0.9682 - Recall: 0.9660 - TP: 3257.3601 - TN: 5569.5601 - FP: 77.4400 - FN: 114.6400 - val_loss: 0.1263 - val_Accuracy: 0.9759 - val_Precision: 0.9630 - val_Recall: 0.9490 - val_TP: 762.9800 - val_TN: 1083.9900 - val_FP: 22.0100 - val_FN: 41.0200\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0683 - Accuracy: 0.9864 - Precision: 0.9657 - Recall: 0.9640 - TP: 3250.7600 - TN: 5561.1499 - FP: 85.8500 - FN: 121.2400 - val_loss: 0.1275 - val_Accuracy: 0.9754 - val_Precision: 0.9665 - val_Recall: 0.9452 - val_TP: 759.9200 - val_TN: 1087.0000 - val_FP: 19.0000 - val_FN: 44.0800\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0485 - Accuracy: 0.9880 - Precision: 0.9684 - Recall: 0.9661 - TP: 3257.8101 - TN: 5570.4600 - FP: 76.5400 - FN: 114.1900 - val_loss: 0.1260 - val_Accuracy: 0.9764 - val_Precision: 0.9645 - val_Recall: 0.9492 - val_TP: 763.1500 - val_TN: 1085.2400 - val_FP: 20.7600 - val_FN: 40.8500\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0719 - Accuracy: 0.9875 - Precision: 0.9677 - Recall: 0.9647 - TP: 3252.8601 - TN: 5568.1602 - FP: 78.8400 - FN: 119.1400 - val_loss: 0.1497 - val_Accuracy: 0.9717 - val_Precision: 0.9491 - val_Recall: 0.9539 - val_TP: 766.9100 - val_TN: 1072.0500 - val_FP: 33.9500 - val_FN: 37.0900\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0616 - Accuracy: 0.9848 - Precision: 0.9661 - Recall: 0.9638 - TP: 3249.8701 - TN: 5562.8198 - FP: 84.1800 - FN: 122.1300 - val_loss: 0.1302 - val_Accuracy: 0.9743 - val_Precision: 0.9601 - val_Recall: 0.9491 - val_TP: 763.0600 - val_TN: 1081.5699 - val_FP: 24.4300 - val_FN: 40.9400\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0778 - Accuracy: 0.9871 - Precision: 0.9652 - Recall: 0.9637 - TP: 3249.7300 - TN: 5559.3799 - FP: 87.6200 - FN: 122.2700 - val_loss: 0.1487 - val_Accuracy: 0.9728 - val_Precision: 0.9592 - val_Recall: 0.9452 - val_TP: 759.9400 - val_TN: 1081.0400 - val_FP: 24.9600 - val_FN: 44.0600\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0543 - Accuracy: 0.9879 - Precision: 0.9674 - Recall: 0.9650 - TP: 3254.0801 - TN: 5566.8501 - FP: 80.1500 - FN: 117.9200 - val_loss: 0.1332 - val_Accuracy: 0.9749 - val_Precision: 0.9559 - val_Recall: 0.9544 - val_TP: 767.3000 - val_TN: 1077.9200 - val_FP: 28.0800 - val_FN: 36.7000\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0524 - Accuracy: 0.9872 - Precision: 0.9672 - Recall: 0.9653 - TP: 3254.9600 - TN: 5566.3301 - FP: 80.6700 - FN: 117.0400 - val_loss: 0.1324 - val_Accuracy: 0.9749 - val_Precision: 0.9611 - val_Recall: 0.9499 - val_TP: 763.6900 - val_TN: 1082.5000 - val_FP: 23.5000 - val_FN: 40.3100\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0524 - Accuracy: 0.9881 - Precision: 0.9675 - Recall: 0.9665 - TP: 3259.1899 - TN: 5567.1802 - FP: 79.8200 - FN: 112.8100 - val_loss: 0.1332 - val_Accuracy: 0.9749 - val_Precision: 0.9620 - val_Recall: 0.9482 - val_TP: 762.3600 - val_TN: 1083.2500 - val_FP: 22.7500 - val_FN: 41.6400\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0574 - Accuracy: 0.9882 - Precision: 0.9691 - Recall: 0.9652 - TP: 3254.6001 - TN: 5573.1099 - FP: 73.8900 - FN: 117.4000 - val_loss: 0.1365 - val_Accuracy: 0.9738 - val_Precision: 0.9609 - val_Recall: 0.9486 - val_TP: 762.6400 - val_TN: 1082.4000 - val_FP: 23.6000 - val_FN: 41.3600\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0709 - Accuracy: 0.9866 - Precision: 0.9665 - Recall: 0.9661 - TP: 3257.6799 - TN: 5563.9502 - FP: 83.0500 - FN: 114.3200 - val_loss: 0.1307 - val_Accuracy: 0.9743 - val_Precision: 0.9629 - val_Recall: 0.9490 - val_TP: 763.0000 - val_TN: 1083.9100 - val_FP: 22.0900 - val_FN: 41.0000\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0508 - Accuracy: 0.9877 - Precision: 0.9687 - Recall: 0.9657 - TP: 3256.2000 - TN: 5571.8701 - FP: 75.1300 - FN: 115.8000 - val_loss: 0.1608 - val_Accuracy: 0.9696 - val_Precision: 0.9458 - val_Recall: 0.9550 - val_TP: 767.8200 - val_TN: 1069.2400 - val_FP: 36.7600 - val_FN: 36.1800\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0633 - Accuracy: 0.9879 - Precision: 0.9687 - Recall: 0.9665 - TP: 3258.9299 - TN: 5571.7798 - FP: 75.2200 - FN: 113.0700 - val_loss: 0.1406 - val_Accuracy: 0.9743 - val_Precision: 0.9520 - val_Recall: 0.9567 - val_TP: 769.2100 - val_TN: 1074.5000 - val_FP: 31.5000 - val_FN: 34.7900\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0712 - Accuracy: 0.9876 - Precision: 0.9675 - Recall: 0.9653 - TP: 3254.9900 - TN: 5567.6499 - FP: 79.3500 - FN: 117.0100 - val_loss: 0.1292 - val_Accuracy: 0.9738 - val_Precision: 0.9543 - val_Recall: 0.9563 - val_TP: 768.8300 - val_TN: 1076.4301 - val_FP: 29.5700 - val_FN: 35.1700\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0568 - Accuracy: 0.9864 - Precision: 0.9673 - Recall: 0.9650 - TP: 3253.8601 - TN: 5566.9102 - FP: 80.0900 - FN: 118.1400 - val_loss: 0.1298 - val_Accuracy: 0.9733 - val_Precision: 0.9615 - val_Recall: 0.9480 - val_TP: 762.1800 - val_TN: 1082.7800 - val_FP: 23.2200 - val_FN: 41.8200\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0578 - Accuracy: 0.9851 - Precision: 0.9654 - Recall: 0.9639 - TP: 3250.3501 - TN: 5560.0200 - FP: 86.9800 - FN: 121.6500 - val_loss: 0.1350 - val_Accuracy: 0.9738 - val_Precision: 0.9595 - val_Recall: 0.9475 - val_TP: 761.7900 - val_TN: 1081.0900 - val_FP: 24.9100 - val_FN: 42.2100\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0703 - Accuracy: 0.9867 - Precision: 0.9673 - Recall: 0.9643 - TP: 3251.5701 - TN: 5566.9800 - FP: 80.0200 - FN: 120.4300 - val_loss: 0.1268 - val_Accuracy: 0.9733 - val_Precision: 0.9528 - val_Recall: 0.9541 - val_TP: 767.0600 - val_TN: 1075.0400 - val_FP: 30.9600 - val_FN: 36.9400\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0632 - Accuracy: 0.9861 - Precision: 0.9671 - Recall: 0.9649 - TP: 3253.5300 - TN: 5566.4302 - FP: 80.5700 - FN: 118.4700 - val_loss: 0.1236 - val_Accuracy: 0.9754 - val_Precision: 0.9628 - val_Recall: 0.9515 - val_TP: 765.0000 - val_TN: 1083.8199 - val_FP: 22.1800 - val_FN: 39.0000\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1006 - Accuracy: 0.9851 - Precision: 0.9652 - Recall: 0.9634 - TP: 3248.7500 - TN: 5559.3999 - FP: 87.6000 - FN: 123.2500 - val_loss: 0.1339 - val_Accuracy: 0.9733 - val_Precision: 0.9738 - val_Recall: 0.9387 - val_TP: 754.7200 - val_TN: 1093.1801 - val_FP: 12.8200 - val_FN: 49.2800\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0687 - Accuracy: 0.9881 - Precision: 0.9674 - Recall: 0.9658 - TP: 3256.8301 - TN: 5567.3301 - FP: 79.6700 - FN: 115.1700 - val_loss: 0.1310 - val_Accuracy: 0.9759 - val_Precision: 0.9679 - val_Recall: 0.9441 - val_TP: 759.0400 - val_TN: 1088.2600 - val_FP: 17.7400 - val_FN: 44.9600\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0942 - Accuracy: 0.9859 - Precision: 0.9667 - Recall: 0.9635 - TP: 3248.8999 - TN: 5564.7202 - FP: 82.2800 - FN: 123.1000 - val_loss: 0.1524 - val_Accuracy: 0.9707 - val_Precision: 0.9460 - val_Recall: 0.9549 - val_TP: 767.7000 - val_TN: 1069.3400 - val_FP: 36.6600 - val_FN: 36.3000\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0644 - Accuracy: 0.9858 - Precision: 0.9665 - Recall: 0.9634 - TP: 3248.7000 - TN: 5564.2002 - FP: 82.8000 - FN: 123.3000 - val_loss: 0.1362 - val_Accuracy: 0.9728 - val_Precision: 0.9465 - val_Recall: 0.9580 - val_TP: 770.2200 - val_TN: 1069.6100 - val_FP: 36.3900 - val_FN: 33.7800\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0648 - Accuracy: 0.9875 - Precision: 0.9670 - Recall: 0.9666 - TP: 3259.2800 - TN: 5565.7500 - FP: 81.2500 - FN: 112.7200 - val_loss: 0.1356 - val_Accuracy: 0.9749 - val_Precision: 0.9623 - val_Recall: 0.9475 - val_TP: 761.7600 - val_TN: 1083.5400 - val_FP: 22.4600 - val_FN: 42.2400\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0592 - Accuracy: 0.9872 - Precision: 0.9682 - Recall: 0.9651 - TP: 3254.2400 - TN: 5569.8999 - FP: 77.1000 - FN: 117.7600 - val_loss: 0.1292 - val_Accuracy: 0.9733 - val_Precision: 0.9557 - val_Recall: 0.9540 - val_TP: 766.9900 - val_TN: 1077.7000 - val_FP: 28.3000 - val_FN: 37.0100\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0642 - Accuracy: 0.9871 - Precision: 0.9660 - Recall: 0.9651 - TP: 3254.3000 - TN: 5562.0698 - FP: 84.9300 - FN: 117.7000 - val_loss: 0.1507 - val_Accuracy: 0.9702 - val_Precision: 0.9525 - val_Recall: 0.9506 - val_TP: 764.2500 - val_TN: 1075.1200 - val_FP: 30.8800 - val_FN: 39.7500\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0516 - Accuracy: 0.9860 - Precision: 0.9673 - Recall: 0.9646 - TP: 3252.5300 - TN: 5566.9399 - FP: 80.0600 - FN: 119.4700 - val_loss: 0.1409 - val_Accuracy: 0.9733 - val_Precision: 0.9493 - val_Recall: 0.9551 - val_TP: 767.9400 - val_TN: 1072.1000 - val_FP: 33.9000 - val_FN: 36.0600\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0506 - Accuracy: 0.9864 - Precision: 0.9676 - Recall: 0.9650 - TP: 3253.9600 - TN: 5567.9600 - FP: 79.0400 - FN: 118.0400 - val_loss: 0.1444 - val_Accuracy: 0.9717 - val_Precision: 0.9433 - val_Recall: 0.9595 - val_TP: 771.4500 - val_TN: 1066.7400 - val_FP: 39.2600 - val_FN: 32.5500\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0690 - Accuracy: 0.9869 - Precision: 0.9671 - Recall: 0.9655 - TP: 3255.7600 - TN: 5566.1299 - FP: 80.8700 - FN: 116.2400 - val_loss: 0.1449 - val_Accuracy: 0.9728 - val_Precision: 0.9547 - val_Recall: 0.9518 - val_TP: 765.2500 - val_TN: 1077.0200 - val_FP: 28.9800 - val_FN: 38.7500\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0574 - Accuracy: 0.9879 - Precision: 0.9674 - Recall: 0.9657 - TP: 3256.3101 - TN: 5567.2402 - FP: 79.7600 - FN: 115.6900 - val_loss: 0.2319 - val_Accuracy: 0.9634 - val_Precision: 0.9100 - val_Recall: 0.9532 - val_TP: 766.3800 - val_TN: 1035.8500 - val_FP: 70.1500 - val_FN: 37.6200\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0616 - Accuracy: 0.9869 - Precision: 0.9674 - Recall: 0.9653 - TP: 3255.0801 - TN: 5567.1602 - FP: 79.8400 - FN: 116.9200 - val_loss: 0.1291 - val_Accuracy: 0.9764 - val_Precision: 0.9647 - val_Recall: 0.9492 - val_TP: 763.1500 - val_TN: 1085.4500 - val_FP: 20.5500 - val_FN: 40.8500\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0815 - Accuracy: 0.9850 - Precision: 0.9658 - Recall: 0.9630 - TP: 3247.2000 - TN: 5561.9199 - FP: 85.0800 - FN: 124.8000 - val_loss: 0.1311 - val_Accuracy: 0.9770 - val_Precision: 0.9635 - val_Recall: 0.9489 - val_TP: 762.9100 - val_TN: 1084.4800 - val_FP: 21.5200 - val_FN: 41.0900\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0483 - Accuracy: 0.9878 - Precision: 0.9672 - Recall: 0.9663 - TP: 3258.3201 - TN: 5566.3701 - FP: 80.6300 - FN: 113.6800 - val_loss: 0.1391 - val_Accuracy: 0.9749 - val_Precision: 0.9695 - val_Recall: 0.9422 - val_TP: 757.5000 - val_TN: 1089.5800 - val_FP: 16.4200 - val_FN: 46.5000\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0495 - Accuracy: 0.9874 - Precision: 0.9684 - Recall: 0.9662 - TP: 3258.0200 - TN: 5570.7402 - FP: 76.2600 - FN: 113.9800 - val_loss: 0.1416 - val_Accuracy: 0.9749 - val_Precision: 0.9636 - val_Recall: 0.9461 - val_TP: 760.6300 - val_TN: 1084.7200 - val_FP: 21.2800 - val_FN: 43.3700\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0742 - Accuracy: 0.9875 - Precision: 0.9677 - Recall: 0.9655 - TP: 3255.6899 - TN: 5568.4800 - FP: 78.5200 - FN: 116.3100 - val_loss: 0.1451 - val_Accuracy: 0.9738 - val_Precision: 0.9585 - val_Recall: 0.9500 - val_TP: 763.8100 - val_TN: 1080.3101 - val_FP: 25.6900 - val_FN: 40.1900\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0465 - Accuracy: 0.9887 - Precision: 0.9693 - Recall: 0.9669 - TP: 3260.3899 - TN: 5573.9102 - FP: 73.0900 - FN: 111.6100 - val_loss: 0.1354 - val_Accuracy: 0.9738 - val_Precision: 0.9582 - val_Recall: 0.9507 - val_TP: 764.3600 - val_TN: 1080.0000 - val_FP: 26.0000 - val_FN: 39.6400\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0524 - Accuracy: 0.9869 - Precision: 0.9675 - Recall: 0.9659 - TP: 3257.0300 - TN: 5567.9600 - FP: 79.0400 - FN: 114.9700 - val_loss: 0.1358 - val_Accuracy: 0.9738 - val_Precision: 0.9692 - val_Recall: 0.9434 - val_TP: 758.4800 - val_TN: 1089.3800 - val_FP: 16.6200 - val_FN: 45.5200\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0781 - Accuracy: 0.9866 - Precision: 0.9669 - Recall: 0.9641 - TP: 3251.0000 - TN: 5565.7798 - FP: 81.2200 - FN: 121.0000 - val_loss: 0.1353 - val_Accuracy: 0.9738 - val_Precision: 0.9562 - val_Recall: 0.9527 - val_TP: 765.9400 - val_TN: 1078.3000 - val_FP: 27.7000 - val_FN: 38.0600\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0485 - Accuracy: 0.9871 - Precision: 0.9677 - Recall: 0.9663 - TP: 3258.3201 - TN: 5568.2100 - FP: 78.7900 - FN: 113.6800 - val_loss: 0.1345 - val_Accuracy: 0.9754 - val_Precision: 0.9621 - val_Recall: 0.9505 - val_TP: 764.1800 - val_TN: 1083.3300 - val_FP: 22.6700 - val_FN: 39.8200\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0692 - Accuracy: 0.9875 - Precision: 0.9669 - Recall: 0.9653 - TP: 3255.1499 - TN: 5565.8101 - FP: 81.1900 - FN: 116.8500 - val_loss: 0.1253 - val_Accuracy: 0.9738 - val_Precision: 0.9605 - val_Recall: 0.9500 - val_TP: 763.8200 - val_TN: 1081.8300 - val_FP: 24.1700 - val_FN: 40.1800\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0714 - Accuracy: 0.9866 - Precision: 0.9662 - Recall: 0.9644 - TP: 3252.1001 - TN: 5562.6602 - FP: 84.3400 - FN: 119.9000 - val_loss: 0.1389 - val_Accuracy: 0.9728 - val_Precision: 0.9607 - val_Recall: 0.9478 - val_TP: 762.0200 - val_TN: 1082.2100 - val_FP: 23.7900 - val_FN: 41.9800\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0493 - Accuracy: 0.9869 - Precision: 0.9677 - Recall: 0.9653 - TP: 3254.9700 - TN: 5568.1602 - FP: 78.8400 - FN: 117.0300 - val_loss: 0.1318 - val_Accuracy: 0.9733 - val_Precision: 0.9593 - val_Recall: 0.9501 - val_TP: 763.9200 - val_TN: 1080.9500 - val_FP: 25.0500 - val_FN: 40.0800\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0525 - Accuracy: 0.9870 - Precision: 0.9671 - Recall: 0.9647 - TP: 3253.0300 - TN: 5566.1099 - FP: 80.8900 - FN: 118.9700 - val_loss: 0.1370 - val_Accuracy: 0.9738 - val_Precision: 0.9602 - val_Recall: 0.9493 - val_TP: 763.2300 - val_TN: 1081.7600 - val_FP: 24.2400 - val_FN: 40.7700\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0861 - Accuracy: 0.9864 - Precision: 0.9671 - Recall: 0.9647 - TP: 3253.0601 - TN: 5566.1602 - FP: 80.8400 - FN: 118.9400 - val_loss: 0.1356 - val_Accuracy: 0.9743 - val_Precision: 0.9592 - val_Recall: 0.9510 - val_TP: 764.5700 - val_TN: 1080.8500 - val_FP: 25.1500 - val_FN: 39.4300\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0732 - Accuracy: 0.9866 - Precision: 0.9668 - Recall: 0.9649 - TP: 3253.5601 - TN: 5565.0898 - FP: 81.9100 - FN: 118.4400 - val_loss: 0.1526 - val_Accuracy: 0.9723 - val_Precision: 0.9492 - val_Recall: 0.9530 - val_TP: 766.1900 - val_TN: 1072.1500 - val_FP: 33.8500 - val_FN: 37.8100\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0612 - Accuracy: 0.9866 - Precision: 0.9673 - Recall: 0.9652 - TP: 3254.6899 - TN: 5566.9302 - FP: 80.0700 - FN: 117.3100 - val_loss: 0.1302 - val_Accuracy: 0.9728 - val_Precision: 0.9590 - val_Recall: 0.9508 - val_TP: 764.4700 - val_TN: 1080.6700 - val_FP: 25.3300 - val_FN: 39.5300\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0602 - Accuracy: 0.9866 - Precision: 0.9671 - Recall: 0.9654 - TP: 3255.2900 - TN: 5566.0000 - FP: 81.0000 - FN: 116.7100 - val_loss: 0.1440 - val_Accuracy: 0.9738 - val_Precision: 0.9629 - val_Recall: 0.9469 - val_TP: 761.3400 - val_TN: 1084.0500 - val_FP: 21.9500 - val_FN: 42.6600\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0582 - Accuracy: 0.9864 - Precision: 0.9672 - Recall: 0.9646 - TP: 3252.7300 - TN: 5566.5298 - FP: 80.4700 - FN: 119.2700 - val_loss: 0.1245 - val_Accuracy: 0.9743 - val_Precision: 0.9624 - val_Recall: 0.9507 - val_TP: 764.3800 - val_TN: 1083.4500 - val_FP: 22.5500 - val_FN: 39.6200\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0636 - Accuracy: 0.9885 - Precision: 0.9674 - Recall: 0.9657 - TP: 3256.4399 - TN: 5566.8701 - FP: 80.1300 - FN: 115.5600 - val_loss: 0.1302 - val_Accuracy: 0.9733 - val_Precision: 0.9577 - val_Recall: 0.9517 - val_TP: 765.1300 - val_TN: 1079.5400 - val_FP: 26.4600 - val_FN: 38.8700\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0475 - Accuracy: 0.9861 - Precision: 0.9679 - Recall: 0.9650 - TP: 3254.0100 - TN: 5568.8398 - FP: 78.1600 - FN: 117.9900 - val_loss: 0.1373 - val_Accuracy: 0.9738 - val_Precision: 0.9462 - val_Recall: 0.9588 - val_TP: 770.8500 - val_TN: 1069.2600 - val_FP: 36.7400 - val_FN: 33.1500\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1036 - Accuracy: 0.9860 - Precision: 0.9654 - Recall: 0.9644 - TP: 3252.0601 - TN: 5560.2598 - FP: 86.7400 - FN: 119.9400 - val_loss: 0.1433 - val_Accuracy: 0.9728 - val_Precision: 0.9746 - val_Recall: 0.9363 - val_TP: 752.7500 - val_TN: 1093.8900 - val_FP: 12.1100 - val_FN: 51.2500\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0733 - Accuracy: 0.9864 - Precision: 0.9662 - Recall: 0.9649 - TP: 3253.7900 - TN: 5563.0298 - FP: 83.9700 - FN: 118.2100 - val_loss: 0.1398 - val_Accuracy: 0.9738 - val_Precision: 0.9736 - val_Recall: 0.9398 - val_TP: 755.6300 - val_TN: 1092.9900 - val_FP: 13.0100 - val_FN: 48.3700\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0808 - Accuracy: 0.9868 - Precision: 0.9676 - Recall: 0.9645 - TP: 3252.4600 - TN: 5568.0400 - FP: 78.9600 - FN: 119.5400 - val_loss: 0.1393 - val_Accuracy: 0.9723 - val_Precision: 0.9560 - val_Recall: 0.9520 - val_TP: 765.4400 - val_TN: 1078.1300 - val_FP: 27.8700 - val_FN: 38.5600\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0704 - Accuracy: 0.9882 - Precision: 0.9671 - Recall: 0.9655 - TP: 3255.7700 - TN: 5566.1499 - FP: 80.8500 - FN: 116.2300 - val_loss: 0.1451 - val_Accuracy: 0.9717 - val_Precision: 0.9586 - val_Recall: 0.9486 - val_TP: 762.6600 - val_TN: 1080.4600 - val_FP: 25.5400 - val_FN: 41.3400\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0741 - Accuracy: 0.9875 - Precision: 0.9688 - Recall: 0.9656 - TP: 3255.9900 - TN: 5572.2900 - FP: 74.7100 - FN: 116.0100 - val_loss: 0.1321 - val_Accuracy: 0.9759 - val_Precision: 0.9534 - val_Recall: 0.9561 - val_TP: 768.7000 - val_TN: 1075.6899 - val_FP: 30.3100 - val_FN: 35.3000\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0473 - Accuracy: 0.9864 - Precision: 0.9667 - Recall: 0.9653 - TP: 3254.9099 - TN: 5564.6499 - FP: 82.3500 - FN: 117.0900 - val_loss: 0.1523 - val_Accuracy: 0.9723 - val_Precision: 0.9541 - val_Recall: 0.9509 - val_TP: 764.5500 - val_TN: 1076.5400 - val_FP: 29.4600 - val_FN: 39.4500\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0499 - Accuracy: 0.9876 - Precision: 0.9691 - Recall: 0.9668 - TP: 3259.9600 - TN: 5573.1499 - FP: 73.8500 - FN: 112.0400 - val_loss: 0.1344 - val_Accuracy: 0.9738 - val_Precision: 0.9534 - val_Recall: 0.9555 - val_TP: 768.2300 - val_TN: 1075.7600 - val_FP: 30.2400 - val_FN: 35.7700\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0572 - Accuracy: 0.9874 - Precision: 0.9678 - Recall: 0.9662 - TP: 3258.1399 - TN: 5568.5400 - FP: 78.4600 - FN: 113.8600 - val_loss: 0.1489 - val_Accuracy: 0.9733 - val_Precision: 0.9591 - val_Recall: 0.9490 - val_TP: 763.0000 - val_TN: 1080.8700 - val_FP: 25.1300 - val_FN: 41.0000\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0494 - Accuracy: 0.9885 - Precision: 0.9678 - Recall: 0.9658 - TP: 3256.6299 - TN: 5568.5801 - FP: 78.4200 - FN: 115.3700 - val_loss: 0.1402 - val_Accuracy: 0.9743 - val_Precision: 0.9527 - val_Recall: 0.9549 - val_TP: 767.7500 - val_TN: 1075.2000 - val_FP: 30.8000 - val_FN: 36.2500\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0529 - Accuracy: 0.9884 - Precision: 0.9693 - Recall: 0.9669 - TP: 3260.3799 - TN: 5574.1401 - FP: 72.8600 - FN: 111.6200 - val_loss: 0.1576 - val_Accuracy: 0.9723 - val_Precision: 0.9474 - val_Recall: 0.9550 - val_TP: 767.8000 - val_TN: 1070.6899 - val_FP: 35.3100 - val_FN: 36.2000\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0737 - Accuracy: 0.9869 - Precision: 0.9668 - Recall: 0.9652 - TP: 3254.5400 - TN: 5565.3301 - FP: 81.6700 - FN: 117.4600 - val_loss: 0.1326 - val_Accuracy: 0.9770 - val_Precision: 0.9594 - val_Recall: 0.9524 - val_TP: 765.7400 - val_TN: 1080.9100 - val_FP: 25.0900 - val_FN: 38.2600\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0560 - Accuracy: 0.9886 - Precision: 0.9691 - Recall: 0.9668 - TP: 3259.9700 - TN: 5573.1099 - FP: 73.8900 - FN: 112.0300 - val_loss: 0.1473 - val_Accuracy: 0.9733 - val_Precision: 0.9494 - val_Recall: 0.9569 - val_TP: 769.3600 - val_TN: 1072.3101 - val_FP: 33.6900 - val_FN: 34.6400\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0532 - Accuracy: 0.9880 - Precision: 0.9683 - Recall: 0.9667 - TP: 3259.8101 - TN: 5570.4902 - FP: 76.5100 - FN: 112.1900 - val_loss: 0.1337 - val_Accuracy: 0.9754 - val_Precision: 0.9526 - val_Recall: 0.9571 - val_TP: 769.5300 - val_TN: 1074.9800 - val_FP: 31.0200 - val_FN: 34.4700\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0768 - Accuracy: 0.9874 - Precision: 0.9670 - Recall: 0.9652 - TP: 3254.6201 - TN: 5566.0498 - FP: 80.9500 - FN: 117.3800 - val_loss: 0.1400 - val_Accuracy: 0.9728 - val_Precision: 0.9578 - val_Recall: 0.9505 - val_TP: 764.2400 - val_TN: 1079.7000 - val_FP: 26.3000 - val_FN: 39.7600\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0626 - Accuracy: 0.9881 - Precision: 0.9677 - Recall: 0.9664 - TP: 3258.7100 - TN: 5568.3301 - FP: 78.6700 - FN: 113.2900 - val_loss: 0.1652 - val_Accuracy: 0.9728 - val_Precision: 0.9498 - val_Recall: 0.9539 - val_TP: 766.9100 - val_TN: 1072.7900 - val_FP: 33.2100 - val_FN: 37.0900\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0852 - Accuracy: 0.9876 - Precision: 0.9673 - Recall: 0.9653 - TP: 3254.8501 - TN: 5566.8701 - FP: 80.1300 - FN: 117.1500 - val_loss: 0.1498 - val_Accuracy: 0.9743 - val_Precision: 0.9592 - val_Recall: 0.9502 - val_TP: 763.9600 - val_TN: 1080.9700 - val_FP: 25.0300 - val_FN: 40.0400\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0572 - Accuracy: 0.9871 - Precision: 0.9683 - Recall: 0.9664 - TP: 3258.7700 - TN: 5570.5098 - FP: 76.4900 - FN: 113.2300 - val_loss: 0.1522 - val_Accuracy: 0.9728 - val_Precision: 0.9589 - val_Recall: 0.9494 - val_TP: 763.3400 - val_TN: 1080.7500 - val_FP: 25.2500 - val_FN: 40.6600\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0464 - Accuracy: 0.9879 - Precision: 0.9688 - Recall: 0.9671 - TP: 3260.9600 - TN: 5572.1602 - FP: 74.8400 - FN: 111.0400 - val_loss: 0.1464 - val_Accuracy: 0.9712 - val_Precision: 0.9578 - val_Recall: 0.9497 - val_TP: 763.5500 - val_TN: 1079.7800 - val_FP: 26.2200 - val_FN: 40.4500\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0800 - Accuracy: 0.9860 - Precision: 0.9653 - Recall: 0.9633 - TP: 3248.1899 - TN: 5560.0898 - FP: 86.9100 - FN: 123.8100 - val_loss: 0.1291 - val_Accuracy: 0.9749 - val_Precision: 0.9612 - val_Recall: 0.9515 - val_TP: 765.0300 - val_TN: 1082.4600 - val_FP: 23.5400 - val_FN: 38.9700\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0590 - Accuracy: 0.9874 - Precision: 0.9668 - Recall: 0.9651 - TP: 3254.3501 - TN: 5565.2900 - FP: 81.7100 - FN: 117.6500 - val_loss: 0.1365 - val_Accuracy: 0.9749 - val_Precision: 0.9530 - val_Recall: 0.9565 - val_TP: 769.0000 - val_TN: 1075.3900 - val_FP: 30.6100 - val_FN: 35.0000\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0679 - Accuracy: 0.9874 - Precision: 0.9672 - Recall: 0.9658 - TP: 3256.6499 - TN: 5566.5898 - FP: 80.4100 - FN: 115.3500 - val_loss: 0.1390 - val_Accuracy: 0.9733 - val_Precision: 0.9643 - val_Recall: 0.9459 - val_TP: 760.4800 - val_TN: 1085.2600 - val_FP: 20.7400 - val_FN: 43.5200\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0522 - Accuracy: 0.9882 - Precision: 0.9689 - Recall: 0.9667 - TP: 3259.7500 - TN: 5572.5698 - FP: 74.4300 - FN: 112.2500 - val_loss: 0.1391 - val_Accuracy: 0.9728 - val_Precision: 0.9621 - val_Recall: 0.9469 - val_TP: 761.2900 - val_TN: 1083.4399 - val_FP: 22.5600 - val_FN: 42.7100\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0580 - Accuracy: 0.9880 - Precision: 0.9679 - Recall: 0.9655 - TP: 3255.7300 - TN: 5569.0801 - FP: 77.9200 - FN: 116.2700 - val_loss: 0.1362 - val_Accuracy: 0.9738 - val_Precision: 0.9515 - val_Recall: 0.9550 - val_TP: 767.8600 - val_TN: 1074.1300 - val_FP: 31.8700 - val_FN: 36.1400\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0606 - Accuracy: 0.9877 - Precision: 0.9679 - Recall: 0.9661 - TP: 3257.7900 - TN: 5568.9502 - FP: 78.0500 - FN: 114.2100 - val_loss: 0.1316 - val_Accuracy: 0.9749 - val_Precision: 0.9649 - val_Recall: 0.9482 - val_TP: 762.3200 - val_TN: 1085.6700 - val_FP: 20.3300 - val_FN: 41.6800\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0957 - Accuracy: 0.9858 - Precision: 0.9659 - Recall: 0.9646 - TP: 3252.5400 - TN: 5562.4902 - FP: 84.5100 - FN: 119.4600 - val_loss: 0.1495 - val_Accuracy: 0.9733 - val_Precision: 0.9634 - val_Recall: 0.9452 - val_TP: 759.9600 - val_TN: 1084.5000 - val_FP: 21.5000 - val_FN: 44.0400\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0507 - Accuracy: 0.9881 - Precision: 0.9686 - Recall: 0.9661 - TP: 3257.8000 - TN: 5571.6201 - FP: 75.3800 - FN: 114.2000 - val_loss: 0.1299 - val_Accuracy: 0.9738 - val_Precision: 0.9594 - val_Recall: 0.9521 - val_TP: 765.4700 - val_TN: 1080.9301 - val_FP: 25.0700 - val_FN: 38.5300\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0775 - Accuracy: 0.9870 - Precision: 0.9655 - Recall: 0.9647 - TP: 3253.0300 - TN: 5560.6401 - FP: 86.3600 - FN: 118.9700 - val_loss: 0.1559 - val_Accuracy: 0.9712 - val_Precision: 0.9609 - val_Recall: 0.9418 - val_TP: 757.1900 - val_TN: 1082.5800 - val_FP: 23.4200 - val_FN: 46.8100\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0500 - Accuracy: 0.9870 - Precision: 0.9682 - Recall: 0.9655 - TP: 3255.6499 - TN: 5570.2598 - FP: 76.7400 - FN: 116.3500 - val_loss: 0.1548 - val_Accuracy: 0.9723 - val_Precision: 0.9546 - val_Recall: 0.9503 - val_TP: 764.0500 - val_TN: 1077.0000 - val_FP: 29.0000 - val_FN: 39.9500\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0856 - Accuracy: 0.9866 - Precision: 0.9667 - Recall: 0.9643 - TP: 3251.6799 - TN: 5565.1499 - FP: 81.8500 - FN: 120.3200 - val_loss: 0.1343 - val_Accuracy: 0.9743 - val_Precision: 0.9537 - val_Recall: 0.9551 - val_TP: 767.9000 - val_TN: 1075.9900 - val_FP: 30.0100 - val_FN: 36.1000\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0883 - Accuracy: 0.9877 - Precision: 0.9672 - Recall: 0.9656 - TP: 3256.1001 - TN: 5566.5898 - FP: 80.4100 - FN: 115.9000 - val_loss: 0.1341 - val_Accuracy: 0.9764 - val_Precision: 0.9649 - val_Recall: 0.9483 - val_TP: 762.4200 - val_TN: 1085.6801 - val_FP: 20.3200 - val_FN: 41.5800\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0513 - Accuracy: 0.9881 - Precision: 0.9682 - Recall: 0.9661 - TP: 3257.6699 - TN: 5569.9302 - FP: 77.0700 - FN: 114.3300 - val_loss: 0.1370 - val_Accuracy: 0.9723 - val_Precision: 0.9571 - val_Recall: 0.9523 - val_TP: 765.6600 - val_TN: 1079.0300 - val_FP: 26.9700 - val_FN: 38.3400\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0667 - Accuracy: 0.9871 - Precision: 0.9686 - Recall: 0.9661 - TP: 3257.7000 - TN: 5571.8198 - FP: 75.1800 - FN: 114.3000 - val_loss: 0.1360 - val_Accuracy: 0.9754 - val_Precision: 0.9626 - val_Recall: 0.9481 - val_TP: 762.2400 - val_TN: 1083.8000 - val_FP: 22.2000 - val_FN: 41.7600\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0424 - Accuracy: 0.9882 - Precision: 0.9686 - Recall: 0.9669 - TP: 3260.5200 - TN: 5571.6699 - FP: 75.3300 - FN: 111.4800 - val_loss: 0.1463 - val_Accuracy: 0.9723 - val_Precision: 0.9557 - val_Recall: 0.9527 - val_TP: 765.9500 - val_TN: 1077.9200 - val_FP: 28.0800 - val_FN: 38.0500\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0572 - Accuracy: 0.9871 - Precision: 0.9687 - Recall: 0.9662 - TP: 3258.0601 - TN: 5571.9302 - FP: 75.0700 - FN: 113.9400 - val_loss: 0.1350 - val_Accuracy: 0.9759 - val_Precision: 0.9621 - val_Recall: 0.9502 - val_TP: 763.9500 - val_TN: 1083.2800 - val_FP: 22.7200 - val_FN: 40.0500\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0533 - Accuracy: 0.9888 - Precision: 0.9686 - Recall: 0.9675 - TP: 3262.5300 - TN: 5571.2998 - FP: 75.7000 - FN: 109.4700 - val_loss: 0.1491 - val_Accuracy: 0.9743 - val_Precision: 0.9647 - val_Recall: 0.9467 - val_TP: 761.1400 - val_TN: 1085.6700 - val_FP: 20.3300 - val_FN: 42.8600\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0533 - Accuracy: 0.9881 - Precision: 0.9695 - Recall: 0.9667 - TP: 3259.6599 - TN: 5574.7700 - FP: 72.2300 - FN: 112.3400 - val_loss: 0.1380 - val_Accuracy: 0.9723 - val_Precision: 0.9544 - val_Recall: 0.9539 - val_TP: 766.9000 - val_TN: 1076.6801 - val_FP: 29.3200 - val_FN: 37.1000\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0639 - Accuracy: 0.9870 - Precision: 0.9680 - Recall: 0.9661 - TP: 3257.5601 - TN: 5569.4902 - FP: 77.5100 - FN: 114.4400 - val_loss: 0.1392 - val_Accuracy: 0.9728 - val_Precision: 0.9516 - val_Recall: 0.9548 - val_TP: 767.6400 - val_TN: 1074.2200 - val_FP: 31.7800 - val_FN: 36.3600\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0561 - Accuracy: 0.9880 - Precision: 0.9676 - Recall: 0.9664 - TP: 3258.7700 - TN: 5567.8901 - FP: 79.1100 - FN: 113.2300 - val_loss: 0.1446 - val_Accuracy: 0.9723 - val_Precision: 0.9599 - val_Recall: 0.9474 - val_TP: 761.6700 - val_TN: 1081.5300 - val_FP: 24.4700 - val_FN: 42.3300\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0630 - Accuracy: 0.9880 - Precision: 0.9684 - Recall: 0.9668 - TP: 3259.9199 - TN: 5570.8999 - FP: 76.1000 - FN: 112.0800 - val_loss: 0.1449 - val_Accuracy: 0.9749 - val_Precision: 0.9583 - val_Recall: 0.9517 - val_TP: 765.1900 - val_TN: 1080.1500 - val_FP: 25.8500 - val_FN: 38.8100\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 4ms/step - loss: 0.0529 - Accuracy: 0.9864 - Precision: 0.9669 - Recall: 0.9658 - TP: 3256.6399 - TN: 5565.6401 - FP: 81.3600 - FN: 115.3600 - val_loss: 0.1291 - val_Accuracy: 0.9764 - val_Precision: 0.9671 - val_Recall: 0.9461 - val_TP: 760.7000 - val_TN: 1087.5400 - val_FP: 18.4600 - val_FN: 43.3000\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0974 - Accuracy: 0.9865 - Precision: 0.9667 - Recall: 0.9641 - TP: 3251.1001 - TN: 5565.0098 - FP: 81.9900 - FN: 120.9000 - val_loss: 0.1321 - val_Accuracy: 0.9743 - val_Precision: 0.9606 - val_Recall: 0.9502 - val_TP: 764.0000 - val_TN: 1081.9700 - val_FP: 24.0300 - val_FN: 40.0000\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0823 - Accuracy: 0.9854 - Precision: 0.9658 - Recall: 0.9632 - TP: 3247.7700 - TN: 5561.9902 - FP: 85.0100 - FN: 124.2300 - val_loss: 0.1731 - val_Accuracy: 0.9675 - val_Precision: 0.9390 - val_Recall: 0.9575 - val_TP: 769.8000 - val_TN: 1063.1400 - val_FP: 42.8600 - val_FN: 34.2000\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0657 - Accuracy: 0.9867 - Precision: 0.9663 - Recall: 0.9652 - TP: 3254.6399 - TN: 5563.5601 - FP: 83.4400 - FN: 117.3600 - val_loss: 0.1453 - val_Accuracy: 0.9733 - val_Precision: 0.9634 - val_Recall: 0.9443 - val_TP: 759.2200 - val_TN: 1084.6100 - val_FP: 21.3900 - val_FN: 44.7800\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0498 - Accuracy: 0.9872 - Precision: 0.9681 - Recall: 0.9656 - TP: 3255.9600 - TN: 5569.9800 - FP: 77.0200 - FN: 116.0400 - val_loss: 0.1299 - val_Accuracy: 0.9764 - val_Precision: 0.9634 - val_Recall: 0.9509 - val_TP: 764.5500 - val_TN: 1084.3700 - val_FP: 21.6300 - val_FN: 39.4500\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0666 - Accuracy: 0.9867 - Precision: 0.9666 - Recall: 0.9649 - TP: 3253.6101 - TN: 5564.5698 - FP: 82.4300 - FN: 118.3900 - val_loss: 0.1310 - val_Accuracy: 0.9759 - val_Precision: 0.9624 - val_Recall: 0.9499 - val_TP: 763.7400 - val_TN: 1083.5699 - val_FP: 22.4300 - val_FN: 40.2600\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0523 - Accuracy: 0.9868 - Precision: 0.9679 - Recall: 0.9656 - TP: 3256.1201 - TN: 5569.1099 - FP: 77.8900 - FN: 115.8800 - val_loss: 0.1418 - val_Accuracy: 0.9717 - val_Precision: 0.9547 - val_Recall: 0.9529 - val_TP: 766.1200 - val_TN: 1076.9800 - val_FP: 29.0200 - val_FN: 37.8800\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0510 - Accuracy: 0.9874 - Precision: 0.9674 - Recall: 0.9658 - TP: 3256.6201 - TN: 5567.1201 - FP: 79.8800 - FN: 115.3800 - val_loss: 0.1351 - val_Accuracy: 0.9733 - val_Precision: 0.9580 - val_Recall: 0.9519 - val_TP: 765.3400 - val_TN: 1079.7200 - val_FP: 26.2800 - val_FN: 38.6600\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0565 - Accuracy: 0.9880 - Precision: 0.9681 - Recall: 0.9655 - TP: 3255.6399 - TN: 5569.5498 - FP: 77.4500 - FN: 116.3600 - val_loss: 0.1404 - val_Accuracy: 0.9743 - val_Precision: 0.9595 - val_Recall: 0.9501 - val_TP: 763.9100 - val_TN: 1081.1899 - val_FP: 24.8100 - val_FN: 40.0900\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0602 - Accuracy: 0.9867 - Precision: 0.9675 - Recall: 0.9651 - TP: 3254.3899 - TN: 5567.5601 - FP: 79.4400 - FN: 117.6100 - val_loss: 0.1393 - val_Accuracy: 0.9743 - val_Precision: 0.9534 - val_Recall: 0.9552 - val_TP: 767.9700 - val_TN: 1075.8400 - val_FP: 30.1600 - val_FN: 36.0300\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0911 - Accuracy: 0.9870 - Precision: 0.9664 - Recall: 0.9656 - TP: 3256.0500 - TN: 5564.2300 - FP: 82.7700 - FN: 115.9500 - val_loss: 0.1368 - val_Accuracy: 0.9743 - val_Precision: 0.9630 - val_Recall: 0.9496 - val_TP: 763.4600 - val_TN: 1084.1100 - val_FP: 21.8900 - val_FN: 40.5400\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0643 - Accuracy: 0.9870 - Precision: 0.9678 - Recall: 0.9647 - TP: 3253.0701 - TN: 5569.0400 - FP: 77.9600 - FN: 118.9300 - val_loss: 0.1358 - val_Accuracy: 0.9749 - val_Precision: 0.9496 - val_Recall: 0.9577 - val_TP: 770.0300 - val_TN: 1072.3199 - val_FP: 33.6800 - val_FN: 33.9700\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0897 - Accuracy: 0.9870 - Precision: 0.9656 - Recall: 0.9654 - TP: 3255.3101 - TN: 5561.0898 - FP: 85.9100 - FN: 116.6900 - val_loss: 0.1522 - val_Accuracy: 0.9723 - val_Precision: 0.9661 - val_Recall: 0.9409 - val_TP: 756.4600 - val_TN: 1087.0000 - val_FP: 19.0000 - val_FN: 47.5400\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0715 - Accuracy: 0.9860 - Precision: 0.9676 - Recall: 0.9644 - TP: 3251.9099 - TN: 5568.1299 - FP: 78.8700 - FN: 120.0900 - val_loss: 0.1376 - val_Accuracy: 0.9754 - val_Precision: 0.9627 - val_Recall: 0.9496 - val_TP: 763.4700 - val_TN: 1083.8199 - val_FP: 22.1800 - val_FN: 40.5300\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0502 - Accuracy: 0.9872 - Precision: 0.9674 - Recall: 0.9664 - TP: 3258.5701 - TN: 5567.4102 - FP: 79.5900 - FN: 113.4300 - val_loss: 0.1566 - val_Accuracy: 0.9738 - val_Precision: 0.9591 - val_Recall: 0.9493 - val_TP: 763.2700 - val_TN: 1080.8600 - val_FP: 25.1400 - val_FN: 40.7300\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0567 - Accuracy: 0.9872 - Precision: 0.9679 - Recall: 0.9652 - TP: 3254.5200 - TN: 5569.3301 - FP: 77.6700 - FN: 117.4800 - val_loss: 0.1336 - val_Accuracy: 0.9738 - val_Precision: 0.9557 - val_Recall: 0.9545 - val_TP: 767.4000 - val_TN: 1077.7100 - val_FP: 28.2900 - val_FN: 36.6000\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0470 - Accuracy: 0.9886 - Precision: 0.9680 - Recall: 0.9673 - TP: 3261.8701 - TN: 5569.3398 - FP: 77.6600 - FN: 110.1300 - val_loss: 0.1462 - val_Accuracy: 0.9738 - val_Precision: 0.9701 - val_Recall: 0.9416 - val_TP: 757.0600 - val_TN: 1090.1300 - val_FP: 15.8700 - val_FN: 46.9400\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0710 - Accuracy: 0.9866 - Precision: 0.9672 - Recall: 0.9645 - TP: 3252.2600 - TN: 5567.0298 - FP: 79.9700 - FN: 119.7400 - val_loss: 0.1347 - val_Accuracy: 0.9749 - val_Precision: 0.9581 - val_Recall: 0.9528 - val_TP: 766.0700 - val_TN: 1079.8600 - val_FP: 26.1400 - val_FN: 37.9300\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0574 - Accuracy: 0.9874 - Precision: 0.9676 - Recall: 0.9659 - TP: 3257.1799 - TN: 5568.1299 - FP: 78.8700 - FN: 114.8200 - val_loss: 0.1473 - val_Accuracy: 0.9728 - val_Precision: 0.9629 - val_Recall: 0.9459 - val_TP: 760.5200 - val_TN: 1084.1300 - val_FP: 21.8700 - val_FN: 43.4800\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0796 - Accuracy: 0.9866 - Precision: 0.9673 - Recall: 0.9644 - TP: 3252.1101 - TN: 5567.6699 - FP: 79.3300 - FN: 119.8900 - val_loss: 0.1520 - val_Accuracy: 0.9738 - val_Precision: 0.9526 - val_Recall: 0.9538 - val_TP: 766.8800 - val_TN: 1075.1899 - val_FP: 30.8100 - val_FN: 37.1200\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0652 - Accuracy: 0.9879 - Precision: 0.9669 - Recall: 0.9672 - TP: 3261.4199 - TN: 5565.8599 - FP: 81.1400 - FN: 110.5800 - val_loss: 0.1453 - val_Accuracy: 0.9728 - val_Precision: 0.9654 - val_Recall: 0.9434 - val_TP: 758.4800 - val_TN: 1086.3000 - val_FP: 19.7000 - val_FN: 45.5200\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 6ms/step - loss: 0.0858 - Accuracy: 0.9855 - Precision: 0.9666 - Recall: 0.9645 - TP: 3252.2300 - TN: 5564.8599 - FP: 82.1400 - FN: 119.7700 - val_loss: 0.1331 - val_Accuracy: 0.9759 - val_Precision: 0.9674 - val_Recall: 0.9463 - val_TP: 760.8500 - val_TN: 1087.8101 - val_FP: 18.1900 - val_FN: 43.1500\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0556 - Accuracy: 0.9866 - Precision: 0.9673 - Recall: 0.9663 - TP: 3258.3999 - TN: 5567.4199 - FP: 79.5800 - FN: 113.6000 - val_loss: 0.1361 - val_Accuracy: 0.9738 - val_Precision: 0.9686 - val_Recall: 0.9438 - val_TP: 758.8200 - val_TN: 1088.8900 - val_FP: 17.1100 - val_FN: 45.1800\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0890 - Accuracy: 0.9870 - Precision: 0.9677 - Recall: 0.9648 - TP: 3253.2400 - TN: 5568.7300 - FP: 78.2700 - FN: 118.7600 - val_loss: 0.1343 - val_Accuracy: 0.9749 - val_Precision: 0.9570 - val_Recall: 0.9529 - val_TP: 766.1100 - val_TN: 1078.9301 - val_FP: 27.0700 - val_FN: 37.8900\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1034 - Accuracy: 0.9878 - Precision: 0.9669 - Recall: 0.9663 - TP: 3258.2300 - TN: 5565.4800 - FP: 81.5200 - FN: 113.7700 - val_loss: 0.1426 - val_Accuracy: 0.9738 - val_Precision: 0.9723 - val_Recall: 0.9398 - val_TP: 755.6300 - val_TN: 1091.9399 - val_FP: 14.0600 - val_FN: 48.3700\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0626 - Accuracy: 0.9874 - Precision: 0.9685 - Recall: 0.9655 - TP: 3255.5000 - TN: 5571.0698 - FP: 75.9300 - FN: 116.5000 - val_loss: 0.1347 - val_Accuracy: 0.9743 - val_Precision: 0.9547 - val_Recall: 0.9552 - val_TP: 768.0200 - val_TN: 1076.9399 - val_FP: 29.0600 - val_FN: 35.9800\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0904 - Accuracy: 0.9870 - Precision: 0.9672 - Recall: 0.9655 - TP: 3255.6599 - TN: 5566.9199 - FP: 80.0800 - FN: 116.3400 - val_loss: 0.1452 - val_Accuracy: 0.9723 - val_Precision: 0.9590 - val_Recall: 0.9508 - val_TP: 764.4700 - val_TN: 1080.7200 - val_FP: 25.2800 - val_FN: 39.5300\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0664 - Accuracy: 0.9872 - Precision: 0.9671 - Recall: 0.9651 - TP: 3254.1599 - TN: 5566.7202 - FP: 80.2800 - FN: 117.8400 - val_loss: 0.1471 - val_Accuracy: 0.9754 - val_Precision: 0.9518 - val_Recall: 0.9560 - val_TP: 768.6500 - val_TN: 1074.3800 - val_FP: 31.6200 - val_FN: 35.3500\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0633 - Accuracy: 0.9864 - Precision: 0.9667 - Recall: 0.9650 - TP: 3253.8701 - TN: 5564.9800 - FP: 82.0200 - FN: 118.1300 - val_loss: 0.1367 - val_Accuracy: 0.9743 - val_Precision: 0.9585 - val_Recall: 0.9521 - val_TP: 765.5200 - val_TN: 1080.1899 - val_FP: 25.8100 - val_FN: 38.4800\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0590 - Accuracy: 0.9870 - Precision: 0.9687 - Recall: 0.9656 - TP: 3256.0400 - TN: 5571.8999 - FP: 75.1000 - FN: 115.9600 - val_loss: 0.1349 - val_Accuracy: 0.9749 - val_Precision: 0.9547 - val_Recall: 0.9555 - val_TP: 768.2300 - val_TN: 1076.7900 - val_FP: 29.2100 - val_FN: 35.7700\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0678 - Accuracy: 0.9878 - Precision: 0.9666 - Recall: 0.9660 - TP: 3257.4600 - TN: 5564.5498 - FP: 82.4500 - FN: 114.5400 - val_loss: 0.1511 - val_Accuracy: 0.9733 - val_Precision: 0.9630 - val_Recall: 0.9457 - val_TP: 760.3100 - val_TN: 1084.2300 - val_FP: 21.7700 - val_FN: 43.6900\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1073 - Accuracy: 0.9860 - Precision: 0.9659 - Recall: 0.9634 - TP: 3248.6599 - TN: 5561.9800 - FP: 85.0200 - FN: 123.3400 - val_loss: 0.1552 - val_Accuracy: 0.9738 - val_Precision: 0.9512 - val_Recall: 0.9565 - val_TP: 769.0200 - val_TN: 1073.9500 - val_FP: 32.0500 - val_FN: 34.9800\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0570 - Accuracy: 0.9878 - Precision: 0.9683 - Recall: 0.9667 - TP: 3259.7700 - TN: 5570.7202 - FP: 76.2800 - FN: 112.2300 - val_loss: 0.1378 - val_Accuracy: 0.9754 - val_Precision: 0.9654 - val_Recall: 0.9498 - val_TP: 763.6400 - val_TN: 1086.1400 - val_FP: 19.8600 - val_FN: 40.3600\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0475 - Accuracy: 0.9878 - Precision: 0.9681 - Recall: 0.9666 - TP: 3259.2700 - TN: 5569.8198 - FP: 77.1800 - FN: 112.7300 - val_loss: 0.1441 - val_Accuracy: 0.9743 - val_Precision: 0.9543 - val_Recall: 0.9535 - val_TP: 766.6100 - val_TN: 1076.6899 - val_FP: 29.3100 - val_FN: 37.3900\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0834 - Accuracy: 0.9872 - Precision: 0.9670 - Recall: 0.9653 - TP: 3255.1399 - TN: 5566.1299 - FP: 80.8700 - FN: 116.8600 - val_loss: 0.1359 - val_Accuracy: 0.9754 - val_Precision: 0.9666 - val_Recall: 0.9469 - val_TP: 761.2700 - val_TN: 1087.1600 - val_FP: 18.8400 - val_FN: 42.7300\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0686 - Accuracy: 0.9863 - Precision: 0.9671 - Recall: 0.9651 - TP: 3254.1799 - TN: 5566.4199 - FP: 80.5800 - FN: 117.8200 - val_loss: 0.1408 - val_Accuracy: 0.9749 - val_Precision: 0.9557 - val_Recall: 0.9543 - val_TP: 767.2200 - val_TN: 1077.8000 - val_FP: 28.2000 - val_FN: 36.7800\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0620 - Accuracy: 0.9861 - Precision: 0.9664 - Recall: 0.9649 - TP: 3253.4900 - TN: 5564.3799 - FP: 82.6200 - FN: 118.5100 - val_loss: 0.1405 - val_Accuracy: 0.9749 - val_Precision: 0.9550 - val_Recall: 0.9544 - val_TP: 767.3700 - val_TN: 1077.2200 - val_FP: 28.7800 - val_FN: 36.6300\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0585 - Accuracy: 0.9880 - Precision: 0.9686 - Recall: 0.9668 - TP: 3260.1599 - TN: 5571.8501 - FP: 75.1500 - FN: 111.8400 - val_loss: 0.1386 - val_Accuracy: 0.9785 - val_Precision: 0.9613 - val_Recall: 0.9522 - val_TP: 765.5600 - val_TN: 1082.6300 - val_FP: 23.3700 - val_FN: 38.4400\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0560 - Accuracy: 0.9870 - Precision: 0.9673 - Recall: 0.9655 - TP: 3255.7200 - TN: 5567.1201 - FP: 79.8800 - FN: 116.2800 - val_loss: 0.1590 - val_Accuracy: 0.9717 - val_Precision: 0.9627 - val_Recall: 0.9449 - val_TP: 759.7000 - val_TN: 1084.0601 - val_FP: 21.9400 - val_FN: 44.3000\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0574 - Accuracy: 0.9879 - Precision: 0.9684 - Recall: 0.9666 - TP: 3259.3601 - TN: 5571.0400 - FP: 75.9600 - FN: 112.6400 - val_loss: 0.1504 - val_Accuracy: 0.9754 - val_Precision: 0.9526 - val_Recall: 0.9555 - val_TP: 768.2600 - val_TN: 1075.1801 - val_FP: 30.8200 - val_FN: 35.7400\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0527 - Accuracy: 0.9871 - Precision: 0.9675 - Recall: 0.9660 - TP: 3257.3201 - TN: 5567.7100 - FP: 79.2900 - FN: 114.6800 - val_loss: 0.1739 - val_Accuracy: 0.9702 - val_Precision: 0.9463 - val_Recall: 0.9543 - val_TP: 767.2700 - val_TN: 1069.8000 - val_FP: 36.2000 - val_FN: 36.7300\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0561 - Accuracy: 0.9880 - Precision: 0.9687 - Recall: 0.9658 - TP: 3256.6799 - TN: 5572.3398 - FP: 74.6600 - FN: 115.3200 - val_loss: 0.1506 - val_Accuracy: 0.9712 - val_Precision: 0.9481 - val_Recall: 0.9564 - val_TP: 768.9800 - val_TN: 1071.2800 - val_FP: 34.7200 - val_FN: 35.0200\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0548 - Accuracy: 0.9868 - Precision: 0.9663 - Recall: 0.9647 - TP: 3252.8701 - TN: 5563.6299 - FP: 83.3700 - FN: 119.1300 - val_loss: 0.1422 - val_Accuracy: 0.9738 - val_Precision: 0.9633 - val_Recall: 0.9456 - val_TP: 760.3000 - val_TN: 1084.5100 - val_FP: 21.4900 - val_FN: 43.7000\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0825 - Accuracy: 0.9848 - Precision: 0.9656 - Recall: 0.9642 - TP: 3251.3401 - TN: 5561.4902 - FP: 85.5100 - FN: 120.6600 - val_loss: 0.1355 - val_Accuracy: 0.9738 - val_Precision: 0.9693 - val_Recall: 0.9449 - val_TP: 759.6800 - val_TN: 1089.4600 - val_FP: 16.5400 - val_FN: 44.3200\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0682 - Accuracy: 0.9865 - Precision: 0.9673 - Recall: 0.9651 - TP: 3254.3601 - TN: 5567.4800 - FP: 79.5200 - FN: 117.6400 - val_loss: 0.1344 - val_Accuracy: 0.9743 - val_Precision: 0.9606 - val_Recall: 0.9509 - val_TP: 764.5100 - val_TN: 1082.0100 - val_FP: 23.9900 - val_FN: 39.4900\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0504 - Accuracy: 0.9884 - Precision: 0.9683 - Recall: 0.9665 - TP: 3258.8799 - TN: 5570.3198 - FP: 76.6800 - FN: 113.1200 - val_loss: 0.1329 - val_Accuracy: 0.9743 - val_Precision: 0.9598 - val_Recall: 0.9522 - val_TP: 765.5600 - val_TN: 1081.3300 - val_FP: 24.6700 - val_FN: 38.4400\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0810 - Accuracy: 0.9872 - Precision: 0.9686 - Recall: 0.9654 - TP: 3255.2900 - TN: 5571.5498 - FP: 75.4500 - FN: 116.7100 - val_loss: 0.1311 - val_Accuracy: 0.9743 - val_Precision: 0.9522 - val_Recall: 0.9590 - val_TP: 771.0700 - val_TN: 1074.5900 - val_FP: 31.4100 - val_FN: 32.9300\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1424 - Accuracy: 0.9854 - Precision: 0.9638 - Recall: 0.9632 - TP: 3248.0701 - TN: 5555.1699 - FP: 91.8300 - FN: 123.9300 - val_loss: 0.1386 - val_Accuracy: 0.9754 - val_Precision: 0.9654 - val_Recall: 0.9475 - val_TP: 761.8100 - val_TN: 1086.1400 - val_FP: 19.8600 - val_FN: 42.1900\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0712 - Accuracy: 0.9865 - Precision: 0.9678 - Recall: 0.9661 - TP: 3257.6299 - TN: 5569.1001 - FP: 77.9000 - FN: 114.3700 - val_loss: 0.1355 - val_Accuracy: 0.9749 - val_Precision: 0.9593 - val_Recall: 0.9526 - val_TP: 765.8800 - val_TN: 1080.9399 - val_FP: 25.0600 - val_FN: 38.1200\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0828 - Accuracy: 0.9874 - Precision: 0.9670 - Recall: 0.9654 - TP: 3255.2000 - TN: 5566.2900 - FP: 80.7100 - FN: 116.8000 - val_loss: 0.1447 - val_Accuracy: 0.9749 - val_Precision: 0.9599 - val_Recall: 0.9510 - val_TP: 764.5800 - val_TN: 1081.5400 - val_FP: 24.4600 - val_FN: 39.4200\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0616 - Accuracy: 0.9879 - Precision: 0.9681 - Recall: 0.9668 - TP: 3260.0801 - TN: 5569.8599 - FP: 77.1400 - FN: 111.9200 - val_loss: 0.1446 - val_Accuracy: 0.9733 - val_Precision: 0.9622 - val_Recall: 0.9486 - val_TP: 762.6400 - val_TN: 1083.5500 - val_FP: 22.4500 - val_FN: 41.3600\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0810 - Accuracy: 0.9864 - Precision: 0.9662 - Recall: 0.9642 - TP: 3251.3401 - TN: 5563.4800 - FP: 83.5200 - FN: 120.6600 - val_loss: 0.1505 - val_Accuracy: 0.9723 - val_Precision: 0.9652 - val_Recall: 0.9437 - val_TP: 758.7700 - val_TN: 1086.1400 - val_FP: 19.8600 - val_FN: 45.2300\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0573 - Accuracy: 0.9874 - Precision: 0.9677 - Recall: 0.9652 - TP: 3254.7800 - TN: 5568.6099 - FP: 78.3900 - FN: 117.2200 - val_loss: 0.1445 - val_Accuracy: 0.9728 - val_Precision: 0.9551 - val_Recall: 0.9543 - val_TP: 767.2200 - val_TN: 1077.3400 - val_FP: 28.6600 - val_FN: 36.7800\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0605 - Accuracy: 0.9874 - Precision: 0.9690 - Recall: 0.9662 - TP: 3258.0000 - TN: 5573.3799 - FP: 73.6200 - FN: 114.0000 - val_loss: 0.1432 - val_Accuracy: 0.9754 - val_Precision: 0.9453 - val_Recall: 0.9591 - val_TP: 771.1000 - val_TN: 1068.3700 - val_FP: 37.6300 - val_FN: 32.9000\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0708 - Accuracy: 0.9867 - Precision: 0.9665 - Recall: 0.9651 - TP: 3254.2400 - TN: 5564.2500 - FP: 82.7500 - FN: 117.7600 - val_loss: 0.1449 - val_Accuracy: 0.9717 - val_Precision: 0.9560 - val_Recall: 0.9516 - val_TP: 765.1100 - val_TN: 1078.1400 - val_FP: 27.8600 - val_FN: 38.8900\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1096 - Accuracy: 0.9867 - Precision: 0.9664 - Recall: 0.9651 - TP: 3254.2300 - TN: 5564.3198 - FP: 82.6800 - FN: 117.7700 - val_loss: 0.1383 - val_Accuracy: 0.9764 - val_Precision: 0.9591 - val_Recall: 0.9536 - val_TP: 766.7300 - val_TN: 1080.7500 - val_FP: 25.2500 - val_FN: 37.2700\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0519 - Accuracy: 0.9878 - Precision: 0.9684 - Recall: 0.9670 - TP: 3260.8899 - TN: 5571.2202 - FP: 75.7800 - FN: 111.1100 - val_loss: 0.1400 - val_Accuracy: 0.9749 - val_Precision: 0.9634 - val_Recall: 0.9481 - val_TP: 762.2700 - val_TN: 1084.4900 - val_FP: 21.5100 - val_FN: 41.7300\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0689 - Accuracy: 0.9864 - Precision: 0.9678 - Recall: 0.9656 - TP: 3256.0000 - TN: 5569.2202 - FP: 77.7800 - FN: 116.0000 - val_loss: 0.1542 - val_Accuracy: 0.9728 - val_Precision: 0.9500 - val_Recall: 0.9553 - val_TP: 768.0400 - val_TN: 1072.8400 - val_FP: 33.1600 - val_FN: 35.9600\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0912 - Accuracy: 0.9857 - Precision: 0.9663 - Recall: 0.9642 - TP: 3251.3201 - TN: 5563.8901 - FP: 83.1100 - FN: 120.6800 - val_loss: 0.1481 - val_Accuracy: 0.9733 - val_Precision: 0.9517 - val_Recall: 0.9533 - val_TP: 766.4700 - val_TN: 1074.3101 - val_FP: 31.6900 - val_FN: 37.5300\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0684 - Accuracy: 0.9861 - Precision: 0.9662 - Recall: 0.9645 - TP: 3252.3000 - TN: 5563.6001 - FP: 83.4000 - FN: 119.7000 - val_loss: 0.1407 - val_Accuracy: 0.9749 - val_Precision: 0.9648 - val_Recall: 0.9479 - val_TP: 762.1400 - val_TN: 1085.7100 - val_FP: 20.2900 - val_FN: 41.8600\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0617 - Accuracy: 0.9879 - Precision: 0.9682 - Recall: 0.9671 - TP: 3261.1799 - TN: 5570.3901 - FP: 76.6100 - FN: 110.8200 - val_loss: 0.1787 - val_Accuracy: 0.9691 - val_Precision: 0.9483 - val_Recall: 0.9529 - val_TP: 766.1600 - val_TN: 1071.6200 - val_FP: 34.3800 - val_FN: 37.8400\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0584 - Accuracy: 0.9884 - Precision: 0.9686 - Recall: 0.9665 - TP: 3258.9500 - TN: 5571.5000 - FP: 75.5000 - FN: 113.0500 - val_loss: 0.1468 - val_Accuracy: 0.9728 - val_Precision: 0.9586 - val_Recall: 0.9515 - val_TP: 765.0300 - val_TN: 1080.4100 - val_FP: 25.5900 - val_FN: 38.9700\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0784 - Accuracy: 0.9860 - Precision: 0.9669 - Recall: 0.9651 - TP: 3254.4500 - TN: 5565.9800 - FP: 81.0200 - FN: 117.5500 - val_loss: 0.1647 - val_Accuracy: 0.9733 - val_Precision: 0.9589 - val_Recall: 0.9483 - val_TP: 762.4000 - val_TN: 1080.8400 - val_FP: 25.1600 - val_FN: 41.6000\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0858 - Accuracy: 0.9871 - Precision: 0.9673 - Recall: 0.9661 - TP: 3257.6499 - TN: 5566.9902 - FP: 80.0100 - FN: 114.3500 - val_loss: 0.1452 - val_Accuracy: 0.9764 - val_Precision: 0.9639 - val_Recall: 0.9501 - val_TP: 763.8900 - val_TN: 1084.8500 - val_FP: 21.1500 - val_FN: 40.1100\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0482 - Accuracy: 0.9876 - Precision: 0.9694 - Recall: 0.9671 - TP: 3260.9099 - TN: 5574.8901 - FP: 72.1100 - FN: 111.0900 - val_loss: 0.1585 - val_Accuracy: 0.9738 - val_Precision: 0.9593 - val_Recall: 0.9503 - val_TP: 764.0100 - val_TN: 1081.0500 - val_FP: 24.9500 - val_FN: 39.9900\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0509 - Accuracy: 0.9875 - Precision: 0.9681 - Recall: 0.9665 - TP: 3259.1499 - TN: 5570.2100 - FP: 76.7900 - FN: 112.8500 - val_loss: 0.1392 - val_Accuracy: 0.9759 - val_Precision: 0.9631 - val_Recall: 0.9499 - val_TP: 763.7100 - val_TN: 1084.2300 - val_FP: 21.7700 - val_FN: 40.2900\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0528 - Accuracy: 0.9878 - Precision: 0.9689 - Recall: 0.9667 - TP: 3259.7400 - TN: 5572.7100 - FP: 74.2900 - FN: 112.2600 - val_loss: 0.1564 - val_Accuracy: 0.9717 - val_Precision: 0.9571 - val_Recall: 0.9516 - val_TP: 765.0700 - val_TN: 1079.1300 - val_FP: 26.8700 - val_FN: 38.9300\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.0861 - Accuracy: 0.9859 - Precision: 0.9652 - Recall: 0.9643 - TP: 3251.7700 - TN: 5560.2598 - FP: 86.7400 - FN: 120.2300 - val_loss: 0.1452 - val_Accuracy: 0.9733 - val_Precision: 0.9683 - val_Recall: 0.9420 - val_TP: 757.3500 - val_TN: 1088.6600 - val_FP: 17.3400 - val_FN: 46.6500\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0573 - Accuracy: 0.9865 - Precision: 0.9678 - Recall: 0.9655 - TP: 3255.6599 - TN: 5568.9102 - FP: 78.0900 - FN: 116.3400 - val_loss: 0.1475 - val_Accuracy: 0.9712 - val_Precision: 0.9733 - val_Recall: 0.9364 - val_TP: 752.9000 - val_TN: 1092.8199 - val_FP: 13.1800 - val_FN: 51.1000\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0645 - Accuracy: 0.9875 - Precision: 0.9681 - Recall: 0.9665 - TP: 3259.0500 - TN: 5569.8901 - FP: 77.1100 - FN: 112.9500 - val_loss: 0.1510 - val_Accuracy: 0.9743 - val_Precision: 0.9552 - val_Recall: 0.9538 - val_TP: 766.8200 - val_TN: 1077.4800 - val_FP: 28.5200 - val_FN: 37.1800\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0847 - Accuracy: 0.9863 - Precision: 0.9663 - Recall: 0.9645 - TP: 3252.3401 - TN: 5563.7202 - FP: 83.2800 - FN: 119.6600 - val_loss: 0.1551 - val_Accuracy: 0.9723 - val_Precision: 0.9617 - val_Recall: 0.9451 - val_TP: 759.8800 - val_TN: 1083.1600 - val_FP: 22.8400 - val_FN: 44.1200\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0757 - Accuracy: 0.9870 - Precision: 0.9682 - Recall: 0.9654 - TP: 3255.2800 - TN: 5570.7002 - FP: 76.3000 - FN: 116.7200 - val_loss: 0.1381 - val_Accuracy: 0.9743 - val_Precision: 0.9592 - val_Recall: 0.9533 - val_TP: 766.4700 - val_TN: 1080.7900 - val_FP: 25.2100 - val_FN: 37.5300\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0514 - Accuracy: 0.9860 - Precision: 0.9670 - Recall: 0.9659 - TP: 3256.9700 - TN: 5566.0000 - FP: 81.0000 - FN: 115.0300 - val_loss: 0.1446 - val_Accuracy: 0.9733 - val_Precision: 0.9680 - val_Recall: 0.9435 - val_TP: 758.5700 - val_TN: 1088.3900 - val_FP: 17.6100 - val_FN: 45.4300\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0590 - Accuracy: 0.9871 - Precision: 0.9681 - Recall: 0.9660 - TP: 3257.2700 - TN: 5570.1602 - FP: 76.8400 - FN: 114.7300 - val_loss: 0.1498 - val_Accuracy: 0.9743 - val_Precision: 0.9637 - val_Recall: 0.9468 - val_TP: 761.2000 - val_TN: 1084.8101 - val_FP: 21.1900 - val_FN: 42.8000\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0431 - Accuracy: 0.9878 - Precision: 0.9692 - Recall: 0.9671 - TP: 3260.9299 - TN: 5573.7700 - FP: 73.2300 - FN: 111.0700 - val_loss: 0.1484 - val_Accuracy: 0.9733 - val_Precision: 0.9516 - val_Recall: 0.9553 - val_TP: 768.0900 - val_TN: 1074.2800 - val_FP: 31.7200 - val_FN: 35.9100\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0888 - Accuracy: 0.9868 - Precision: 0.9661 - Recall: 0.9650 - TP: 3254.0601 - TN: 5562.8101 - FP: 84.1900 - FN: 117.9400 - val_loss: 0.1668 - val_Accuracy: 0.9691 - val_Precision: 0.9581 - val_Recall: 0.9445 - val_TP: 759.3700 - val_TN: 1080.2300 - val_FP: 25.7700 - val_FN: 44.6300\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0643 - Accuracy: 0.9875 - Precision: 0.9685 - Recall: 0.9663 - TP: 3258.3899 - TN: 5571.4199 - FP: 75.5800 - FN: 113.6100 - val_loss: 0.1455 - val_Accuracy: 0.9738 - val_Precision: 0.9699 - val_Recall: 0.9434 - val_TP: 758.4900 - val_TN: 1089.9600 - val_FP: 16.0400 - val_FN: 45.5100\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0692 - Accuracy: 0.9874 - Precision: 0.9672 - Recall: 0.9654 - TP: 3255.3899 - TN: 5566.8398 - FP: 80.1600 - FN: 116.6100 - val_loss: 0.1446 - val_Accuracy: 0.9733 - val_Precision: 0.9532 - val_Recall: 0.9545 - val_TP: 767.3900 - val_TN: 1075.6600 - val_FP: 30.3400 - val_FN: 36.6100\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1329 - Accuracy: 0.9857 - Precision: 0.9665 - Recall: 0.9642 - TP: 3251.2600 - TN: 5564.7300 - FP: 82.2700 - FN: 120.7400 - val_loss: 0.1434 - val_Accuracy: 0.9743 - val_Precision: 0.9519 - val_Recall: 0.9576 - val_TP: 769.8800 - val_TN: 1074.4800 - val_FP: 31.5200 - val_FN: 34.1200\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0952 - Accuracy: 0.9863 - Precision: 0.9657 - Recall: 0.9651 - TP: 3254.1899 - TN: 5561.5898 - FP: 85.4100 - FN: 117.8100 - val_loss: 0.1574 - val_Accuracy: 0.9728 - val_Precision: 0.9629 - val_Recall: 0.9452 - val_TP: 759.9800 - val_TN: 1084.1801 - val_FP: 21.8200 - val_FN: 44.0200\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0580 - Accuracy: 0.9868 - Precision: 0.9679 - Recall: 0.9650 - TP: 3253.9600 - TN: 5569.6499 - FP: 77.3500 - FN: 118.0400 - val_loss: 0.1603 - val_Accuracy: 0.9717 - val_Precision: 0.9535 - val_Recall: 0.9531 - val_TP: 766.2700 - val_TN: 1076.0400 - val_FP: 29.9600 - val_FN: 37.7300\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0470 - Accuracy: 0.9878 - Precision: 0.9686 - Recall: 0.9670 - TP: 3260.5801 - TN: 5571.6401 - FP: 75.3600 - FN: 111.4200 - val_loss: 0.1417 - val_Accuracy: 0.9749 - val_Precision: 0.9569 - val_Recall: 0.9550 - val_TP: 767.8500 - val_TN: 1078.8500 - val_FP: 27.1500 - val_FN: 36.1500\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0502 - Accuracy: 0.9877 - Precision: 0.9686 - Recall: 0.9667 - TP: 3259.8701 - TN: 5571.8901 - FP: 75.1100 - FN: 112.1300 - val_loss: 0.1512 - val_Accuracy: 0.9733 - val_Precision: 0.9577 - val_Recall: 0.9511 - val_TP: 764.6700 - val_TN: 1079.7300 - val_FP: 26.2700 - val_FN: 39.3300\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0693 - Accuracy: 0.9871 - Precision: 0.9675 - Recall: 0.9661 - TP: 3257.8501 - TN: 5568.1201 - FP: 78.8800 - FN: 114.1500 - val_loss: 0.1433 - val_Accuracy: 0.9759 - val_Precision: 0.9561 - val_Recall: 0.9539 - val_TP: 766.9700 - val_TN: 1078.1600 - val_FP: 27.8400 - val_FN: 37.0300\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0580 - Accuracy: 0.9876 - Precision: 0.9685 - Recall: 0.9667 - TP: 3259.5701 - TN: 5571.5200 - FP: 75.4800 - FN: 112.4300 - val_loss: 0.1440 - val_Accuracy: 0.9759 - val_Precision: 0.9637 - val_Recall: 0.9496 - val_TP: 763.4800 - val_TN: 1084.6700 - val_FP: 21.3300 - val_FN: 40.5200\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0789 - Accuracy: 0.9866 - Precision: 0.9671 - Recall: 0.9649 - TP: 3253.6201 - TN: 5566.9102 - FP: 80.0900 - FN: 118.3800 - val_loss: 0.1656 - val_Accuracy: 0.9702 - val_Precision: 0.9435 - val_Recall: 0.9593 - val_TP: 771.2400 - val_TN: 1067.1000 - val_FP: 38.9000 - val_FN: 32.7600\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0924 - Accuracy: 0.9860 - Precision: 0.9661 - Recall: 0.9646 - TP: 3252.5801 - TN: 5563.3501 - FP: 83.6500 - FN: 119.4200 - val_loss: 0.1432 - val_Accuracy: 0.9754 - val_Precision: 0.9527 - val_Recall: 0.9589 - val_TP: 770.9400 - val_TN: 1075.1300 - val_FP: 30.8700 - val_FN: 33.0600\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0711 - Accuracy: 0.9872 - Precision: 0.9687 - Recall: 0.9669 - TP: 3260.2600 - TN: 5572.4199 - FP: 74.5800 - FN: 111.7400 - val_loss: 0.1445 - val_Accuracy: 0.9733 - val_Precision: 0.9537 - val_Recall: 0.9564 - val_TP: 768.9700 - val_TN: 1076.1300 - val_FP: 29.8700 - val_FN: 35.0300\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0711 - Accuracy: 0.9853 - Precision: 0.9661 - Recall: 0.9656 - TP: 3256.0200 - TN: 5563.3198 - FP: 83.6800 - FN: 115.9800 - val_loss: 0.1552 - val_Accuracy: 0.9707 - val_Precision: 0.9591 - val_Recall: 0.9474 - val_TP: 761.7000 - val_TN: 1081.0500 - val_FP: 24.9500 - val_FN: 42.3000\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0543 - Accuracy: 0.9878 - Precision: 0.9689 - Recall: 0.9663 - TP: 3258.3601 - TN: 5572.9600 - FP: 74.0400 - FN: 113.6400 - val_loss: 0.1489 - val_Accuracy: 0.9728 - val_Precision: 0.9582 - val_Recall: 0.9504 - val_TP: 764.1300 - val_TN: 1080.1200 - val_FP: 25.8800 - val_FN: 39.8700\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0774 - Accuracy: 0.9868 - Precision: 0.9671 - Recall: 0.9652 - TP: 3254.7400 - TN: 5566.7202 - FP: 80.2800 - FN: 117.2600 - val_loss: 0.1533 - val_Accuracy: 0.9733 - val_Precision: 0.9653 - val_Recall: 0.9444 - val_TP: 759.2900 - val_TN: 1086.2100 - val_FP: 19.7900 - val_FN: 44.7100\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0616 - Accuracy: 0.9886 - Precision: 0.9678 - Recall: 0.9666 - TP: 3259.3101 - TN: 5568.9102 - FP: 78.0900 - FN: 112.6900 - val_loss: 0.1504 - val_Accuracy: 0.9712 - val_Precision: 0.9561 - val_Recall: 0.9534 - val_TP: 766.5200 - val_TN: 1078.2600 - val_FP: 27.7400 - val_FN: 37.4800\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 2s 5ms/step - loss: 0.1018 - Accuracy: 0.9861 - Precision: 0.9664 - Recall: 0.9649 - TP: 3253.5801 - TN: 5564.2002 - FP: 82.8000 - FN: 118.4200 - val_loss: 0.1546 - val_Accuracy: 0.9702 - val_Precision: 0.9572 - val_Recall: 0.9484 - val_TP: 762.5500 - val_TN: 1079.3900 - val_FP: 26.6100 - val_FN: 41.4500\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0430 - Accuracy: 0.9870 - Precision: 0.9694 - Recall: 0.9669 - TP: 3260.3799 - TN: 5574.5601 - FP: 72.4400 - FN: 111.6200 - val_loss: 0.1371 - val_Accuracy: 0.9738 - val_Precision: 0.9604 - val_Recall: 0.9511 - val_TP: 764.6900 - val_TN: 1081.9399 - val_FP: 24.0600 - val_FN: 39.3100\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0769 - Accuracy: 0.9860 - Precision: 0.9666 - Recall: 0.9649 - TP: 3253.7000 - TN: 5565.0400 - FP: 81.9600 - FN: 118.3000 - val_loss: 0.1405 - val_Accuracy: 0.9728 - val_Precision: 0.9658 - val_Recall: 0.9459 - val_TP: 760.5300 - val_TN: 1086.5500 - val_FP: 19.4500 - val_FN: 43.4700\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0679 - Accuracy: 0.9869 - Precision: 0.9666 - Recall: 0.9650 - TP: 3253.9600 - TN: 5564.7500 - FP: 82.2500 - FN: 118.0400 - val_loss: 0.1604 - val_Accuracy: 0.9717 - val_Precision: 0.9610 - val_Recall: 0.9460 - val_TP: 760.6000 - val_TN: 1082.6400 - val_FP: 23.3600 - val_FN: 43.4000\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0676 - Accuracy: 0.9849 - Precision: 0.9667 - Recall: 0.9647 - TP: 3253.0200 - TN: 5565.5000 - FP: 81.5000 - FN: 118.9800 - val_loss: 0.1382 - val_Accuracy: 0.9733 - val_Precision: 0.9584 - val_Recall: 0.9534 - val_TP: 766.5000 - val_TN: 1080.1899 - val_FP: 25.8100 - val_FN: 37.5000\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0579 - Accuracy: 0.9880 - Precision: 0.9693 - Recall: 0.9676 - TP: 3262.6001 - TN: 5574.3999 - FP: 72.6000 - FN: 109.4000 - val_loss: 0.1368 - val_Accuracy: 0.9754 - val_Precision: 0.9554 - val_Recall: 0.9558 - val_TP: 768.4700 - val_TN: 1077.4700 - val_FP: 28.5300 - val_FN: 35.5300\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0451 - Accuracy: 0.9880 - Precision: 0.9684 - Recall: 0.9667 - TP: 3259.8701 - TN: 5570.7798 - FP: 76.2200 - FN: 112.1300 - val_loss: 0.1405 - val_Accuracy: 0.9754 - val_Precision: 0.9631 - val_Recall: 0.9487 - val_TP: 762.7900 - val_TN: 1084.2500 - val_FP: 21.7500 - val_FN: 41.2100\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0625 - Accuracy: 0.9876 - Precision: 0.9678 - Recall: 0.9661 - TP: 3257.6599 - TN: 5569.0498 - FP: 77.9500 - FN: 114.3400 - val_loss: 0.1562 - val_Accuracy: 0.9723 - val_Precision: 0.9578 - val_Recall: 0.9497 - val_TP: 763.5700 - val_TN: 1079.8800 - val_FP: 26.1200 - val_FN: 40.4300\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1438 - Accuracy: 0.9872 - Precision: 0.9666 - Recall: 0.9650 - TP: 3254.0000 - TN: 5565.2300 - FP: 81.7700 - FN: 118.0000 - val_loss: 0.1524 - val_Accuracy: 0.9733 - val_Precision: 0.9580 - val_Recall: 0.9513 - val_TP: 764.8200 - val_TN: 1079.9600 - val_FP: 26.0400 - val_FN: 39.1800\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0551 - Accuracy: 0.9871 - Precision: 0.9686 - Recall: 0.9668 - TP: 3260.1499 - TN: 5572.1001 - FP: 74.9000 - FN: 111.8500 - val_loss: 0.1648 - val_Accuracy: 0.9717 - val_Precision: 0.9539 - val_Recall: 0.9524 - val_TP: 765.7500 - val_TN: 1076.4600 - val_FP: 29.5400 - val_FN: 38.2500\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0690 - Accuracy: 0.9874 - Precision: 0.9679 - Recall: 0.9659 - TP: 3257.1001 - TN: 5569.7100 - FP: 77.2900 - FN: 114.9000 - val_loss: 0.1408 - val_Accuracy: 0.9759 - val_Precision: 0.9668 - val_Recall: 0.9468 - val_TP: 761.2000 - val_TN: 1087.3700 - val_FP: 18.6300 - val_FN: 42.8000\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1049 - Accuracy: 0.9860 - Precision: 0.9663 - Recall: 0.9649 - TP: 3253.5901 - TN: 5563.8599 - FP: 83.1400 - FN: 118.4100 - val_loss: 0.1648 - val_Accuracy: 0.9728 - val_Precision: 0.9580 - val_Recall: 0.9500 - val_TP: 763.7900 - val_TN: 1079.9700 - val_FP: 26.0300 - val_FN: 40.2100\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1070 - Accuracy: 0.9849 - Precision: 0.9667 - Recall: 0.9645 - TP: 3252.3000 - TN: 5565.7202 - FP: 81.2800 - FN: 119.7000 - val_loss: 0.1445 - val_Accuracy: 0.9723 - val_Precision: 0.9570 - val_Recall: 0.9525 - val_TP: 765.7900 - val_TN: 1079.0000 - val_FP: 27.0000 - val_FN: 38.2100\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0414 - Accuracy: 0.9878 - Precision: 0.9691 - Recall: 0.9679 - TP: 3263.8601 - TN: 5573.6699 - FP: 73.3300 - FN: 108.1400 - val_loss: 0.1461 - val_Accuracy: 0.9764 - val_Precision: 0.9663 - val_Recall: 0.9472 - val_TP: 761.5100 - val_TN: 1086.9100 - val_FP: 19.0900 - val_FN: 42.4900\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0685 - Accuracy: 0.9869 - Precision: 0.9672 - Recall: 0.9658 - TP: 3256.6101 - TN: 5567.2300 - FP: 79.7700 - FN: 115.3900 - val_loss: 0.1583 - val_Accuracy: 0.9728 - val_Precision: 0.9600 - val_Recall: 0.9503 - val_TP: 764.0800 - val_TN: 1081.6899 - val_FP: 24.3100 - val_FN: 39.9200\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1030 - Accuracy: 0.9856 - Precision: 0.9663 - Recall: 0.9646 - TP: 3252.4900 - TN: 5564.2500 - FP: 82.7500 - FN: 119.5100 - val_loss: 0.1442 - val_Accuracy: 0.9749 - val_Precision: 0.9571 - val_Recall: 0.9557 - val_TP: 768.3700 - val_TN: 1079.0800 - val_FP: 26.9200 - val_FN: 35.6300\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0570 - Accuracy: 0.9866 - Precision: 0.9682 - Recall: 0.9666 - TP: 3259.2100 - TN: 5570.5498 - FP: 76.4500 - FN: 112.7900 - val_loss: 0.1804 - val_Accuracy: 0.9691 - val_Precision: 0.9472 - val_Recall: 0.9541 - val_TP: 767.1100 - val_TN: 1070.6801 - val_FP: 35.3200 - val_FN: 36.8900\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0500 - Accuracy: 0.9882 - Precision: 0.9694 - Recall: 0.9673 - TP: 3261.6001 - TN: 5574.7300 - FP: 72.2700 - FN: 110.4000 - val_loss: 0.1545 - val_Accuracy: 0.9733 - val_Precision: 0.9576 - val_Recall: 0.9516 - val_TP: 765.0800 - val_TN: 1079.6100 - val_FP: 26.3900 - val_FN: 38.9200\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0535 - Accuracy: 0.9885 - Precision: 0.9683 - Recall: 0.9672 - TP: 3261.4900 - TN: 5571.0898 - FP: 75.9100 - FN: 110.5100 - val_loss: 0.1409 - val_Accuracy: 0.9749 - val_Precision: 0.9608 - val_Recall: 0.9528 - val_TP: 766.0900 - val_TN: 1082.2500 - val_FP: 23.7500 - val_FN: 37.9100\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0983 - Accuracy: 0.9867 - Precision: 0.9672 - Recall: 0.9661 - TP: 3257.6599 - TN: 5567.2900 - FP: 79.7100 - FN: 114.3400 - val_loss: 0.1931 - val_Accuracy: 0.9702 - val_Precision: 0.9564 - val_Recall: 0.9445 - val_TP: 759.3700 - val_TN: 1078.8900 - val_FP: 27.1100 - val_FN: 44.6300\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.1007 - Accuracy: 0.9874 - Precision: 0.9681 - Recall: 0.9658 - TP: 3256.8000 - TN: 5570.6299 - FP: 76.3700 - FN: 115.2000 - val_loss: 0.1484 - val_Accuracy: 0.9738 - val_Precision: 0.9577 - val_Recall: 0.9521 - val_TP: 765.5200 - val_TN: 1079.6899 - val_FP: 26.3100 - val_FN: 38.4800\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0908 - Accuracy: 0.9869 - Precision: 0.9676 - Recall: 0.9659 - TP: 3257.0300 - TN: 5568.6401 - FP: 78.3600 - FN: 114.9700 - val_loss: 0.1618 - val_Accuracy: 0.9728 - val_Precision: 0.9613 - val_Recall: 0.9463 - val_TP: 760.8000 - val_TN: 1082.8300 - val_FP: 23.1700 - val_FN: 43.2000\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0575 - Accuracy: 0.9878 - Precision: 0.9686 - Recall: 0.9673 - TP: 3261.8899 - TN: 5572.0400 - FP: 74.9600 - FN: 110.1100 - val_loss: 0.1478 - val_Accuracy: 0.9764 - val_Precision: 0.9642 - val_Recall: 0.9492 - val_TP: 763.1900 - val_TN: 1085.2000 - val_FP: 20.8000 - val_FN: 40.8100\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0650 - Accuracy: 0.9876 - Precision: 0.9680 - Recall: 0.9662 - TP: 3258.1299 - TN: 5569.7500 - FP: 77.2500 - FN: 113.8700 - val_loss: 0.1503 - val_Accuracy: 0.9754 - val_Precision: 0.9625 - val_Recall: 0.9492 - val_TP: 763.1400 - val_TN: 1083.8000 - val_FP: 22.2000 - val_FN: 40.8600\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.1024 - Accuracy: 0.9861 - Precision: 0.9670 - Recall: 0.9656 - TP: 3256.0000 - TN: 5566.6802 - FP: 80.3200 - FN: 116.0000 - val_loss: 0.1632 - val_Accuracy: 0.9702 - val_Precision: 0.9474 - val_Recall: 0.9574 - val_TP: 769.7700 - val_TN: 1070.6899 - val_FP: 35.3100 - val_FN: 34.2300\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0713 - Accuracy: 0.9867 - Precision: 0.9684 - Recall: 0.9664 - TP: 3258.5701 - TN: 5571.5000 - FP: 75.5000 - FN: 113.4300 - val_loss: 0.1504 - val_Accuracy: 0.9743 - val_Precision: 0.9598 - val_Recall: 0.9513 - val_TP: 764.8800 - val_TN: 1081.4500 - val_FP: 24.5500 - val_FN: 39.1200\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 6ms/step - loss: 0.0815 - Accuracy: 0.9871 - Precision: 0.9672 - Recall: 0.9659 - TP: 3257.0901 - TN: 5567.1001 - FP: 79.9000 - FN: 114.9100 - val_loss: 0.1466 - val_Accuracy: 0.9733 - val_Precision: 0.9693 - val_Recall: 0.9425 - val_TP: 757.8100 - val_TN: 1089.4900 - val_FP: 16.5100 - val_FN: 46.1900\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0711 - Accuracy: 0.9860 - Precision: 0.9671 - Recall: 0.9650 - TP: 3253.9900 - TN: 5566.6699 - FP: 80.3300 - FN: 118.0100 - val_loss: 0.1460 - val_Accuracy: 0.9723 - val_Precision: 0.9611 - val_Recall: 0.9486 - val_TP: 762.6700 - val_TN: 1082.6600 - val_FP: 23.3400 - val_FN: 41.3300\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0598 - Accuracy: 0.9868 - Precision: 0.9674 - Recall: 0.9659 - TP: 3256.9700 - TN: 5567.7002 - FP: 79.3000 - FN: 115.0300 - val_loss: 0.1441 - val_Accuracy: 0.9733 - val_Precision: 0.9594 - val_Recall: 0.9500 - val_TP: 763.8000 - val_TN: 1081.1300 - val_FP: 24.8700 - val_FN: 40.2000\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1102 - Accuracy: 0.9849 - Precision: 0.9654 - Recall: 0.9631 - TP: 3247.7200 - TN: 5560.7300 - FP: 86.2700 - FN: 124.2800 - val_loss: 0.1477 - val_Accuracy: 0.9728 - val_Precision: 0.9578 - val_Recall: 0.9516 - val_TP: 765.0500 - val_TN: 1079.7900 - val_FP: 26.2100 - val_FN: 38.9500\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0609 - Accuracy: 0.9877 - Precision: 0.9687 - Recall: 0.9662 - TP: 3258.0200 - TN: 5572.2202 - FP: 74.7800 - FN: 113.9800 - val_loss: 0.1417 - val_Accuracy: 0.9754 - val_Precision: 0.9552 - val_Recall: 0.9557 - val_TP: 768.4000 - val_TN: 1077.3101 - val_FP: 28.6900 - val_FN: 35.6000\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1151 - Accuracy: 0.9861 - Precision: 0.9671 - Recall: 0.9653 - TP: 3255.0601 - TN: 5566.9199 - FP: 80.0800 - FN: 116.9400 - val_loss: 0.1431 - val_Accuracy: 0.9749 - val_Precision: 0.9568 - val_Recall: 0.9535 - val_TP: 766.5900 - val_TN: 1078.7600 - val_FP: 27.2400 - val_FN: 37.4100\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0725 - Accuracy: 0.9870 - Precision: 0.9669 - Recall: 0.9660 - TP: 3257.2600 - TN: 5565.7900 - FP: 81.2100 - FN: 114.7400 - val_loss: 0.1458 - val_Accuracy: 0.9728 - val_Precision: 0.9488 - val_Recall: 0.9596 - val_TP: 771.5100 - val_TN: 1071.6700 - val_FP: 34.3300 - val_FN: 32.4900\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0897 - Accuracy: 0.9868 - Precision: 0.9676 - Recall: 0.9658 - TP: 3256.6399 - TN: 5568.9800 - FP: 78.0200 - FN: 115.3600 - val_loss: 0.1463 - val_Accuracy: 0.9728 - val_Precision: 0.9525 - val_Recall: 0.9540 - val_TP: 767.0200 - val_TN: 1075.0200 - val_FP: 30.9800 - val_FN: 36.9800\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0862 - Accuracy: 0.9855 - Precision: 0.9660 - Recall: 0.9643 - TP: 3251.6899 - TN: 5563.0898 - FP: 83.9100 - FN: 120.3100 - val_loss: 0.1431 - val_Accuracy: 0.9759 - val_Precision: 0.9547 - val_Recall: 0.9556 - val_TP: 768.3200 - val_TN: 1076.9700 - val_FP: 29.0300 - val_FN: 35.6800\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0743 - Accuracy: 0.9870 - Precision: 0.9671 - Recall: 0.9667 - TP: 3259.7600 - TN: 5566.6099 - FP: 80.3900 - FN: 112.2400 - val_loss: 0.1494 - val_Accuracy: 0.9749 - val_Precision: 0.9621 - val_Recall: 0.9504 - val_TP: 764.1000 - val_TN: 1083.4100 - val_FP: 22.5900 - val_FN: 39.9000\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0700 - Accuracy: 0.9875 - Precision: 0.9687 - Recall: 0.9668 - TP: 3259.9199 - TN: 5572.3501 - FP: 74.6500 - FN: 112.0800 - val_loss: 0.1598 - val_Accuracy: 0.9728 - val_Precision: 0.9618 - val_Recall: 0.9466 - val_TP: 761.0600 - val_TN: 1083.2900 - val_FP: 22.7100 - val_FN: 42.9400\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0664 - Accuracy: 0.9865 - Precision: 0.9680 - Recall: 0.9657 - TP: 3256.2000 - TN: 5570.2700 - FP: 76.7300 - FN: 115.8000 - val_loss: 0.1544 - val_Accuracy: 0.9754 - val_Precision: 0.9619 - val_Recall: 0.9489 - val_TP: 762.9400 - val_TN: 1083.3199 - val_FP: 22.6800 - val_FN: 41.0600\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0865 - Accuracy: 0.9869 - Precision: 0.9661 - Recall: 0.9651 - TP: 3254.2100 - TN: 5563.1899 - FP: 83.8100 - FN: 117.7900 - val_loss: 0.1527 - val_Accuracy: 0.9712 - val_Precision: 0.9577 - val_Recall: 0.9509 - val_TP: 764.5000 - val_TN: 1079.7400 - val_FP: 26.2600 - val_FN: 39.5000\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0797 - Accuracy: 0.9880 - Precision: 0.9685 - Recall: 0.9670 - TP: 3260.8201 - TN: 5571.6899 - FP: 75.3100 - FN: 111.1800 - val_loss: 0.1541 - val_Accuracy: 0.9738 - val_Precision: 0.9648 - val_Recall: 0.9452 - val_TP: 759.9400 - val_TN: 1085.7800 - val_FP: 20.2200 - val_FN: 44.0600\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0610 - Accuracy: 0.9877 - Precision: 0.9686 - Recall: 0.9662 - TP: 3258.1201 - TN: 5572.2500 - FP: 74.7500 - FN: 113.8800 - val_loss: 0.1438 - val_Accuracy: 0.9733 - val_Precision: 0.9570 - val_Recall: 0.9554 - val_TP: 768.1200 - val_TN: 1078.9600 - val_FP: 27.0400 - val_FN: 35.8800\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0909 - Accuracy: 0.9866 - Precision: 0.9666 - Recall: 0.9661 - TP: 3257.5400 - TN: 5564.7300 - FP: 82.2700 - FN: 114.4600 - val_loss: 0.1582 - val_Accuracy: 0.9717 - val_Precision: 0.9675 - val_Recall: 0.9409 - val_TP: 756.4900 - val_TN: 1088.1100 - val_FP: 17.8900 - val_FN: 47.5100\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0623 - Accuracy: 0.9871 - Precision: 0.9685 - Recall: 0.9652 - TP: 3254.6101 - TN: 5571.4199 - FP: 75.5800 - FN: 117.3900 - val_loss: 0.1751 - val_Accuracy: 0.9696 - val_Precision: 0.9442 - val_Recall: 0.9584 - val_TP: 770.5800 - val_TN: 1067.7900 - val_FP: 38.2100 - val_FN: 33.4200\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0734 - Accuracy: 0.9877 - Precision: 0.9672 - Recall: 0.9661 - TP: 3257.7300 - TN: 5566.9800 - FP: 80.0200 - FN: 114.2700 - val_loss: 0.1618 - val_Accuracy: 0.9717 - val_Precision: 0.9725 - val_Recall: 0.9395 - val_TP: 755.3600 - val_TN: 1092.1600 - val_FP: 13.8400 - val_FN: 48.6400\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0628 - Accuracy: 0.9878 - Precision: 0.9690 - Recall: 0.9672 - TP: 3261.4299 - TN: 5573.2900 - FP: 73.7100 - FN: 110.5700 - val_loss: 0.1642 - val_Accuracy: 0.9712 - val_Precision: 0.9560 - val_Recall: 0.9509 - val_TP: 764.5300 - val_TN: 1078.3199 - val_FP: 27.6800 - val_FN: 39.4700\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0646 - Accuracy: 0.9869 - Precision: 0.9679 - Recall: 0.9661 - TP: 3257.7900 - TN: 5569.9399 - FP: 77.0600 - FN: 114.2100 - val_loss: 0.1556 - val_Accuracy: 0.9738 - val_Precision: 0.9683 - val_Recall: 0.9438 - val_TP: 758.8300 - val_TN: 1088.7000 - val_FP: 17.3000 - val_FN: 45.1700\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0606 - Accuracy: 0.9889 - Precision: 0.9695 - Recall: 0.9673 - TP: 3261.8000 - TN: 5574.8999 - FP: 72.1000 - FN: 110.2000 - val_loss: 0.1839 - val_Accuracy: 0.9707 - val_Precision: 0.9496 - val_Recall: 0.9523 - val_TP: 765.6200 - val_TN: 1072.7200 - val_FP: 33.2800 - val_FN: 38.3800\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0735 - Accuracy: 0.9879 - Precision: 0.9681 - Recall: 0.9673 - TP: 3261.7100 - TN: 5569.8501 - FP: 77.1500 - FN: 110.2900 - val_loss: 0.1594 - val_Accuracy: 0.9717 - val_Precision: 0.9605 - val_Recall: 0.9472 - val_TP: 761.5700 - val_TN: 1082.2300 - val_FP: 23.7700 - val_FN: 42.4300\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0475 - Accuracy: 0.9882 - Precision: 0.9695 - Recall: 0.9673 - TP: 3261.7500 - TN: 5575.3501 - FP: 71.6500 - FN: 110.2500 - val_loss: 0.1493 - val_Accuracy: 0.9743 - val_Precision: 0.9600 - val_Recall: 0.9509 - val_TP: 764.5400 - val_TN: 1081.6400 - val_FP: 24.3600 - val_FN: 39.4600\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1315 - Accuracy: 0.9869 - Precision: 0.9680 - Recall: 0.9657 - TP: 3256.3601 - TN: 5570.2900 - FP: 76.7100 - FN: 115.6400 - val_loss: 0.1562 - val_Accuracy: 0.9728 - val_Precision: 0.9493 - val_Recall: 0.9586 - val_TP: 770.6900 - val_TN: 1072.2300 - val_FP: 33.7700 - val_FN: 33.3100\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0736 - Accuracy: 0.9874 - Precision: 0.9677 - Recall: 0.9672 - TP: 3261.3701 - TN: 5568.9800 - FP: 78.0200 - FN: 110.6300 - val_loss: 0.1524 - val_Accuracy: 0.9764 - val_Precision: 0.9624 - val_Recall: 0.9507 - val_TP: 764.3800 - val_TN: 1083.6700 - val_FP: 22.3300 - val_FN: 39.6200\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 7ms/step - loss: 0.0788 - Accuracy: 0.9854 - Precision: 0.9662 - Recall: 0.9649 - TP: 3253.6499 - TN: 5563.6401 - FP: 83.3600 - FN: 118.3500 - val_loss: 0.1509 - val_Accuracy: 0.9717 - val_Precision: 0.9582 - val_Recall: 0.9509 - val_TP: 764.5100 - val_TN: 1080.2000 - val_FP: 25.8000 - val_FN: 39.4900\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0652 - Accuracy: 0.9872 - Precision: 0.9684 - Recall: 0.9662 - TP: 3258.1499 - TN: 5571.5200 - FP: 75.4800 - FN: 113.8500 - val_loss: 0.1412 - val_Accuracy: 0.9775 - val_Precision: 0.9647 - val_Recall: 0.9506 - val_TP: 764.3100 - val_TN: 1085.5400 - val_FP: 20.4600 - val_FN: 39.6900\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1039 - Accuracy: 0.9855 - Precision: 0.9654 - Recall: 0.9638 - TP: 3249.9800 - TN: 5560.6299 - FP: 86.3700 - FN: 122.0200 - val_loss: 0.1528 - val_Accuracy: 0.9749 - val_Precision: 0.9657 - val_Recall: 0.9450 - val_TP: 759.7400 - val_TN: 1086.5200 - val_FP: 19.4800 - val_FN: 44.2600\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.1444 - Accuracy: 0.9849 - Precision: 0.9657 - Recall: 0.9641 - TP: 3250.9500 - TN: 5561.8398 - FP: 85.1600 - FN: 121.0500 - val_loss: 0.1598 - val_Accuracy: 0.9723 - val_Precision: 0.9707 - val_Recall: 0.9398 - val_TP: 755.6000 - val_TN: 1090.7000 - val_FP: 15.3000 - val_FN: 48.4000\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0916 - Accuracy: 0.9857 - Precision: 0.9677 - Recall: 0.9655 - TP: 3255.7600 - TN: 5569.5400 - FP: 77.4600 - FN: 116.2400 - val_loss: 0.1434 - val_Accuracy: 0.9749 - val_Precision: 0.9567 - val_Recall: 0.9553 - val_TP: 768.0500 - val_TN: 1078.6600 - val_FP: 27.3400 - val_FN: 35.9500\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0715 - Accuracy: 0.9874 - Precision: 0.9687 - Recall: 0.9668 - TP: 3260.0400 - TN: 5572.7100 - FP: 74.2900 - FN: 111.9600 - val_loss: 0.1495 - val_Accuracy: 0.9717 - val_Precision: 0.9567 - val_Recall: 0.9522 - val_TP: 765.5700 - val_TN: 1078.8101 - val_FP: 27.1900 - val_FN: 38.4300\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0838 - Accuracy: 0.9872 - Precision: 0.9679 - Recall: 0.9667 - TP: 3259.8601 - TN: 5569.5498 - FP: 77.4500 - FN: 112.1400 - val_loss: 0.1452 - val_Accuracy: 0.9738 - val_Precision: 0.9563 - val_Recall: 0.9535 - val_TP: 766.6000 - val_TN: 1078.4000 - val_FP: 27.6000 - val_FN: 37.4000\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0861 - Accuracy: 0.9865 - Precision: 0.9667 - Recall: 0.9651 - TP: 3254.3401 - TN: 5565.2700 - FP: 81.7300 - FN: 117.6600 - val_loss: 0.1644 - val_Accuracy: 0.9723 - val_Precision: 0.9614 - val_Recall: 0.9481 - val_TP: 762.3100 - val_TN: 1082.9399 - val_FP: 23.0600 - val_FN: 41.6900\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0819 - Accuracy: 0.9860 - Precision: 0.9673 - Recall: 0.9647 - TP: 3252.9099 - TN: 5567.8799 - FP: 79.1200 - FN: 119.0900 - val_loss: 0.1546 - val_Accuracy: 0.9675 - val_Precision: 0.9484 - val_Recall: 0.9556 - val_TP: 768.3200 - val_TN: 1071.5400 - val_FP: 34.4600 - val_FN: 35.6800\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1231 - Accuracy: 0.9859 - Precision: 0.9657 - Recall: 0.9644 - TP: 3251.8201 - TN: 5562.0898 - FP: 84.9100 - FN: 120.1800 - val_loss: 0.1561 - val_Accuracy: 0.9717 - val_Precision: 0.9536 - val_Recall: 0.9532 - val_TP: 766.3400 - val_TN: 1076.1801 - val_FP: 29.8200 - val_FN: 37.6600\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0933 - Accuracy: 0.9855 - Precision: 0.9655 - Recall: 0.9642 - TP: 3251.4199 - TN: 5561.4800 - FP: 85.5200 - FN: 120.5800 - val_loss: 0.1506 - val_Accuracy: 0.9759 - val_Precision: 0.9631 - val_Recall: 0.9511 - val_TP: 764.6800 - val_TN: 1084.2300 - val_FP: 21.7700 - val_FN: 39.3200\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.1140 - Accuracy: 0.9867 - Precision: 0.9656 - Recall: 0.9642 - TP: 3251.4199 - TN: 5561.7300 - FP: 85.2700 - FN: 120.5800 - val_loss: 0.1570 - val_Accuracy: 0.9712 - val_Precision: 0.9561 - val_Recall: 0.9502 - val_TP: 763.9800 - val_TN: 1078.4200 - val_FP: 27.5800 - val_FN: 40.0200\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 2s 7ms/step - loss: 0.0549 - Accuracy: 0.9869 - Precision: 0.9673 - Recall: 0.9660 - TP: 3257.2000 - TN: 5567.7300 - FP: 79.2700 - FN: 114.8000 - val_loss: 0.1763 - val_Accuracy: 0.9712 - val_Precision: 0.9577 - val_Recall: 0.9500 - val_TP: 763.7900 - val_TN: 1079.8000 - val_FP: 26.2000 - val_FN: 40.2100\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.0676 - Accuracy: 0.9869 - Precision: 0.9679 - Recall: 0.9659 - TP: 3257.0601 - TN: 5569.5698 - FP: 77.4300 - FN: 114.9400 - val_loss: 0.1730 - val_Accuracy: 0.9723 - val_Precision: 0.9554 - val_Recall: 0.9515 - val_TP: 765.0300 - val_TN: 1077.7700 - val_FP: 28.2300 - val_FN: 38.9700\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0663 - Accuracy: 0.9872 - Precision: 0.9683 - Recall: 0.9669 - TP: 3260.4800 - TN: 5571.1401 - FP: 75.8600 - FN: 111.5200 - val_loss: 0.1524 - val_Accuracy: 0.9749 - val_Precision: 0.9646 - val_Recall: 0.9485 - val_TP: 762.6200 - val_TN: 1085.5900 - val_FP: 20.4100 - val_FN: 41.3800\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0749 - Accuracy: 0.9855 - Precision: 0.9665 - Recall: 0.9645 - TP: 3252.1299 - TN: 5564.8999 - FP: 82.1000 - FN: 119.8700 - val_loss: 0.1709 - val_Accuracy: 0.9723 - val_Precision: 0.9622 - val_Recall: 0.9449 - val_TP: 759.7100 - val_TN: 1083.7200 - val_FP: 22.2800 - val_FN: 44.2900\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0556 - Accuracy: 0.9876 - Precision: 0.9687 - Recall: 0.9667 - TP: 3259.7000 - TN: 5572.4302 - FP: 74.5700 - FN: 112.3000 - val_loss: 0.1709 - val_Accuracy: 0.9717 - val_Precision: 0.9586 - val_Recall: 0.9501 - val_TP: 763.8900 - val_TN: 1080.5800 - val_FP: 25.4200 - val_FN: 40.1100\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0541 - Accuracy: 0.9887 - Precision: 0.9691 - Recall: 0.9679 - TP: 3263.6101 - TN: 5573.7998 - FP: 73.2000 - FN: 108.3900 - val_loss: 0.2057 - val_Accuracy: 0.9675 - val_Precision: 0.9470 - val_Recall: 0.9520 - val_TP: 765.4300 - val_TN: 1070.6899 - val_FP: 35.3100 - val_FN: 38.5700\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0726 - Accuracy: 0.9868 - Precision: 0.9682 - Recall: 0.9655 - TP: 3255.7400 - TN: 5570.5898 - FP: 76.4100 - FN: 116.2600 - val_loss: 0.1554 - val_Accuracy: 0.9723 - val_Precision: 0.9535 - val_Recall: 0.9551 - val_TP: 767.9100 - val_TN: 1075.9700 - val_FP: 30.0300 - val_FN: 36.0900\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0921 - Accuracy: 0.9870 - Precision: 0.9660 - Recall: 0.9655 - TP: 3255.7400 - TN: 5563.0400 - FP: 83.9600 - FN: 116.2600 - val_loss: 0.2172 - val_Accuracy: 0.9686 - val_Precision: 0.9393 - val_Recall: 0.9566 - val_TP: 769.1300 - val_TN: 1063.7000 - val_FP: 42.3000 - val_FN: 34.8700\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0644 - Accuracy: 0.9868 - Precision: 0.9678 - Recall: 0.9660 - TP: 3257.3701 - TN: 5569.2202 - FP: 77.7800 - FN: 114.6300 - val_loss: 0.1582 - val_Accuracy: 0.9743 - val_Precision: 0.9662 - val_Recall: 0.9464 - val_TP: 760.8700 - val_TN: 1086.9000 - val_FP: 19.1000 - val_FN: 43.1300\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0600 - Accuracy: 0.9870 - Precision: 0.9689 - Recall: 0.9664 - TP: 3258.5701 - TN: 5573.1499 - FP: 73.8500 - FN: 113.4300 - val_loss: 0.1748 - val_Accuracy: 0.9728 - val_Precision: 0.9553 - val_Recall: 0.9530 - val_TP: 766.2100 - val_TN: 1077.7000 - val_FP: 28.3000 - val_FN: 37.7900\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 8ms/step - loss: 0.0933 - Accuracy: 0.9855 - Precision: 0.9666 - Recall: 0.9646 - TP: 3252.6399 - TN: 5564.9199 - FP: 82.0800 - FN: 119.3600 - val_loss: 0.2125 - val_Accuracy: 0.9660 - val_Precision: 0.9347 - val_Recall: 0.9558 - val_TP: 768.4500 - val_TN: 1059.6700 - val_FP: 46.3300 - val_FN: 35.5500\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0818 - Accuracy: 0.9861 - Precision: 0.9674 - Recall: 0.9657 - TP: 3256.3899 - TN: 5568.1499 - FP: 78.8500 - FN: 115.6100 - val_loss: 0.1622 - val_Accuracy: 0.9717 - val_Precision: 0.9567 - val_Recall: 0.9508 - val_TP: 764.4500 - val_TN: 1078.9200 - val_FP: 27.0800 - val_FN: 39.5500\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.1191 - Accuracy: 0.9866 - Precision: 0.9664 - Recall: 0.9654 - TP: 3255.3000 - TN: 5564.7002 - FP: 82.3000 - FN: 116.7000 - val_loss: 0.1465 - val_Accuracy: 0.9754 - val_Precision: 0.9638 - val_Recall: 0.9502 - val_TP: 763.9900 - val_TN: 1084.8199 - val_FP: 21.1800 - val_FN: 40.0100\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.1208 - Accuracy: 0.9864 - Precision: 0.9675 - Recall: 0.9647 - TP: 3252.8201 - TN: 5568.2002 - FP: 78.8000 - FN: 119.1800 - val_loss: 0.1529 - val_Accuracy: 0.9723 - val_Precision: 0.9517 - val_Recall: 0.9562 - val_TP: 768.8100 - val_TN: 1074.4500 - val_FP: 31.5500 - val_FN: 35.1900\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0682 - Accuracy: 0.9853 - Precision: 0.9657 - Recall: 0.9650 - TP: 3253.9700 - TN: 5562.2002 - FP: 84.8000 - FN: 118.0300 - val_loss: 0.1513 - val_Accuracy: 0.9759 - val_Precision: 0.9668 - val_Recall: 0.9463 - val_TP: 760.8400 - val_TN: 1087.3900 - val_FP: 18.6100 - val_FN: 43.1600\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0724 - Accuracy: 0.9871 - Precision: 0.9677 - Recall: 0.9665 - TP: 3259.1899 - TN: 5568.9502 - FP: 78.0500 - FN: 112.8100 - val_loss: 0.1478 - val_Accuracy: 0.9754 - val_Precision: 0.9634 - val_Recall: 0.9487 - val_TP: 762.7900 - val_TN: 1084.5699 - val_FP: 21.4300 - val_FN: 41.2100\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1254 - Accuracy: 0.9850 - Precision: 0.9659 - Recall: 0.9640 - TP: 3250.5901 - TN: 5562.8501 - FP: 84.1500 - FN: 121.4100 - val_loss: 0.1464 - val_Accuracy: 0.9743 - val_Precision: 0.9605 - val_Recall: 0.9509 - val_TP: 764.5300 - val_TN: 1082.0500 - val_FP: 23.9500 - val_FN: 39.4700\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0663 - Accuracy: 0.9874 - Precision: 0.9690 - Recall: 0.9667 - TP: 3259.8401 - TN: 5573.4902 - FP: 73.5100 - FN: 112.1600 - val_loss: 0.1584 - val_Accuracy: 0.9738 - val_Precision: 0.9653 - val_Recall: 0.9454 - val_TP: 760.0900 - val_TN: 1086.2100 - val_FP: 19.7900 - val_FN: 43.9100\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0822 - Accuracy: 0.9865 - Precision: 0.9674 - Recall: 0.9654 - TP: 3255.2100 - TN: 5568.1899 - FP: 78.8100 - FN: 116.7900 - val_loss: 0.2265 - val_Accuracy: 0.9670 - val_Precision: 0.9362 - val_Recall: 0.9575 - val_TP: 769.8200 - val_TN: 1060.9700 - val_FP: 45.0300 - val_FN: 34.1800\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1011 - Accuracy: 0.9876 - Precision: 0.9671 - Recall: 0.9668 - TP: 3259.9299 - TN: 5566.9800 - FP: 80.0200 - FN: 112.0700 - val_loss: 0.1795 - val_Accuracy: 0.9717 - val_Precision: 0.9513 - val_Recall: 0.9542 - val_TP: 767.1400 - val_TN: 1074.2600 - val_FP: 31.7400 - val_FN: 36.8600\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0816 - Accuracy: 0.9863 - Precision: 0.9666 - Recall: 0.9649 - TP: 3253.5601 - TN: 5565.6401 - FP: 81.3600 - FN: 118.4400 - val_loss: 0.2485 - val_Accuracy: 0.9654 - val_Precision: 0.9289 - val_Recall: 0.9563 - val_TP: 768.8800 - val_TN: 1053.7700 - val_FP: 52.2300 - val_FN: 35.1200\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0624 - Accuracy: 0.9877 - Precision: 0.9684 - Recall: 0.9667 - TP: 3259.7100 - TN: 5571.5200 - FP: 75.4800 - FN: 112.2900 - val_loss: 0.1529 - val_Accuracy: 0.9754 - val_Precision: 0.9622 - val_Recall: 0.9511 - val_TP: 764.7200 - val_TN: 1083.4399 - val_FP: 22.5600 - val_FN: 39.2800\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0800 - Accuracy: 0.9871 - Precision: 0.9673 - Recall: 0.9669 - TP: 3260.3000 - TN: 5567.5000 - FP: 79.5000 - FN: 111.7000 - val_loss: 0.1582 - val_Accuracy: 0.9743 - val_Precision: 0.9675 - val_Recall: 0.9464 - val_TP: 760.9000 - val_TN: 1087.9600 - val_FP: 18.0400 - val_FN: 43.1000\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0768 - Accuracy: 0.9859 - Precision: 0.9678 - Recall: 0.9649 - TP: 3253.6799 - TN: 5569.8799 - FP: 77.1200 - FN: 118.3200 - val_loss: 0.1559 - val_Accuracy: 0.9738 - val_Precision: 0.9571 - val_Recall: 0.9521 - val_TP: 765.5100 - val_TN: 1079.1300 - val_FP: 26.8700 - val_FN: 38.4900\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0812 - Accuracy: 0.9869 - Precision: 0.9678 - Recall: 0.9664 - TP: 3258.6201 - TN: 5569.2798 - FP: 77.7200 - FN: 113.3800 - val_loss: 0.1563 - val_Accuracy: 0.9717 - val_Precision: 0.9547 - val_Recall: 0.9546 - val_TP: 767.4600 - val_TN: 1077.0699 - val_FP: 28.9300 - val_FN: 36.5400\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0497 - Accuracy: 0.9879 - Precision: 0.9688 - Recall: 0.9676 - TP: 3262.8701 - TN: 5572.5898 - FP: 74.4100 - FN: 109.1300 - val_loss: 0.1583 - val_Accuracy: 0.9728 - val_Precision: 0.9649 - val_Recall: 0.9463 - val_TP: 760.8200 - val_TN: 1085.8800 - val_FP: 20.1200 - val_FN: 43.1800\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1647 - Accuracy: 0.9848 - Precision: 0.9648 - Recall: 0.9632 - TP: 3247.8601 - TN: 5559.3901 - FP: 87.6100 - FN: 124.1400 - val_loss: 0.3692 - val_Accuracy: 0.9340 - val_Precision: 0.8774 - val_Recall: 0.9534 - val_TP: 766.5000 - val_TN: 1006.1000 - val_FP: 99.9000 - val_FN: 37.5000\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0873 - Accuracy: 0.9867 - Precision: 0.9674 - Recall: 0.9654 - TP: 3255.4199 - TN: 5567.9399 - FP: 79.0600 - FN: 116.5800 - val_loss: 0.1872 - val_Accuracy: 0.9707 - val_Precision: 0.9540 - val_Recall: 0.9503 - val_TP: 764.0100 - val_TN: 1076.6801 - val_FP: 29.3200 - val_FN: 39.9900\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1063 - Accuracy: 0.9864 - Precision: 0.9673 - Recall: 0.9653 - TP: 3254.9399 - TN: 5567.7998 - FP: 79.2000 - FN: 117.0600 - val_loss: 0.1616 - val_Accuracy: 0.9743 - val_Precision: 0.9684 - val_Recall: 0.9442 - val_TP: 759.1700 - val_TN: 1088.7700 - val_FP: 17.2300 - val_FN: 44.8300\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0663 - Accuracy: 0.9872 - Precision: 0.9680 - Recall: 0.9669 - TP: 3260.5300 - TN: 5569.9902 - FP: 77.0100 - FN: 111.4700 - val_loss: 0.2613 - val_Accuracy: 0.9670 - val_Precision: 0.9264 - val_Recall: 0.9494 - val_TP: 763.3000 - val_TN: 1051.6200 - val_FP: 54.3800 - val_FN: 40.7000\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1438 - Accuracy: 0.9848 - Precision: 0.9656 - Recall: 0.9648 - TP: 3253.2800 - TN: 5561.9600 - FP: 85.0400 - FN: 118.7200 - val_loss: 0.2321 - val_Accuracy: 0.9670 - val_Precision: 0.9507 - val_Recall: 0.9438 - val_TP: 758.8400 - val_TN: 1074.2700 - val_FP: 31.7300 - val_FN: 45.1600\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0691 - Accuracy: 0.9863 - Precision: 0.9685 - Recall: 0.9652 - TP: 3254.6299 - TN: 5571.9302 - FP: 75.0700 - FN: 117.3700 - val_loss: 0.1781 - val_Accuracy: 0.9712 - val_Precision: 0.9453 - val_Recall: 0.9589 - val_TP: 770.9600 - val_TN: 1068.8300 - val_FP: 37.1700 - val_FN: 33.0400\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0699 - Accuracy: 0.9866 - Precision: 0.9666 - Recall: 0.9672 - TP: 3261.5601 - TN: 5565.4702 - FP: 81.5300 - FN: 110.4400 - val_loss: 0.1633 - val_Accuracy: 0.9733 - val_Precision: 0.9629 - val_Recall: 0.9474 - val_TP: 761.7100 - val_TN: 1084.1700 - val_FP: 21.8300 - val_FN: 42.2900\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1133 - Accuracy: 0.9870 - Precision: 0.9686 - Recall: 0.9652 - TP: 3254.7100 - TN: 5572.4902 - FP: 74.5100 - FN: 117.2900 - val_loss: 0.1612 - val_Accuracy: 0.9759 - val_Precision: 0.9633 - val_Recall: 0.9492 - val_TP: 763.1500 - val_TN: 1084.4399 - val_FP: 21.5600 - val_FN: 40.8500\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0638 - Accuracy: 0.9885 - Precision: 0.9686 - Recall: 0.9680 - TP: 3264.0000 - TN: 5572.2500 - FP: 74.7500 - FN: 108.0000 - val_loss: 0.1710 - val_Accuracy: 0.9754 - val_Precision: 0.9619 - val_Recall: 0.9496 - val_TP: 763.4400 - val_TN: 1083.3000 - val_FP: 22.7000 - val_FN: 40.5600\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0590 - Accuracy: 0.9884 - Precision: 0.9694 - Recall: 0.9677 - TP: 3262.9399 - TN: 5575.2598 - FP: 71.7400 - FN: 109.0600 - val_loss: 0.1694 - val_Accuracy: 0.9712 - val_Precision: 0.9563 - val_Recall: 0.9523 - val_TP: 765.6500 - val_TN: 1078.6200 - val_FP: 27.3800 - val_FN: 38.3500\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0759 - Accuracy: 0.9875 - Precision: 0.9682 - Recall: 0.9668 - TP: 3260.1399 - TN: 5570.6802 - FP: 76.3200 - FN: 111.8600 - val_loss: 0.1633 - val_Accuracy: 0.9738 - val_Precision: 0.9600 - val_Recall: 0.9515 - val_TP: 765.0000 - val_TN: 1081.6400 - val_FP: 24.3600 - val_FN: 39.0000\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 8ms/step - loss: 0.0828 - Accuracy: 0.9869 - Precision: 0.9669 - Recall: 0.9660 - TP: 3257.2500 - TN: 5566.1499 - FP: 80.8500 - FN: 114.7500 - val_loss: 0.1553 - val_Accuracy: 0.9733 - val_Precision: 0.9594 - val_Recall: 0.9495 - val_TP: 763.3900 - val_TN: 1081.2200 - val_FP: 24.7800 - val_FN: 40.6100\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0643 - Accuracy: 0.9867 - Precision: 0.9673 - Recall: 0.9661 - TP: 3257.7800 - TN: 5567.6201 - FP: 79.3800 - FN: 114.2200 - val_loss: 0.1794 - val_Accuracy: 0.9723 - val_Precision: 0.9556 - val_Recall: 0.9495 - val_TP: 763.3600 - val_TN: 1078.0500 - val_FP: 27.9500 - val_FN: 40.6400\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0841 - Accuracy: 0.9868 - Precision: 0.9669 - Recall: 0.9649 - TP: 3253.5601 - TN: 5566.2598 - FP: 80.7400 - FN: 118.4400 - val_loss: 0.1518 - val_Accuracy: 0.9743 - val_Precision: 0.9578 - val_Recall: 0.9537 - val_TP: 766.8000 - val_TN: 1079.7500 - val_FP: 26.2500 - val_FN: 37.2000\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0815 - Accuracy: 0.9849 - Precision: 0.9669 - Recall: 0.9646 - TP: 3252.6799 - TN: 5566.2300 - FP: 80.7700 - FN: 119.3200 - val_loss: 0.1562 - val_Accuracy: 0.9723 - val_Precision: 0.9556 - val_Recall: 0.9527 - val_TP: 765.9400 - val_TN: 1077.9399 - val_FP: 28.0600 - val_FN: 38.0600\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0756 - Accuracy: 0.9861 - Precision: 0.9666 - Recall: 0.9662 - TP: 3258.0601 - TN: 5564.9302 - FP: 82.0700 - FN: 113.9400 - val_loss: 0.1559 - val_Accuracy: 0.9743 - val_Precision: 0.9673 - val_Recall: 0.9442 - val_TP: 759.1700 - val_TN: 1087.8101 - val_FP: 18.1900 - val_FN: 44.8300\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1582 - Accuracy: 0.9858 - Precision: 0.9668 - Recall: 0.9639 - TP: 3250.2600 - TN: 5566.0698 - FP: 80.9300 - FN: 121.7400 - val_loss: 0.2360 - val_Accuracy: 0.9602 - val_Precision: 0.9176 - val_Recall: 0.9579 - val_TP: 770.1300 - val_TN: 1043.5200 - val_FP: 62.4800 - val_FN: 33.8700\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0786 - Accuracy: 0.9860 - Precision: 0.9670 - Recall: 0.9651 - TP: 3254.4099 - TN: 5566.7900 - FP: 80.2100 - FN: 117.5900 - val_loss: 0.1578 - val_Accuracy: 0.9717 - val_Precision: 0.9563 - val_Recall: 0.9521 - val_TP: 765.5200 - val_TN: 1078.5200 - val_FP: 27.4800 - val_FN: 38.4800\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1430 - Accuracy: 0.9849 - Precision: 0.9660 - Recall: 0.9638 - TP: 3249.9099 - TN: 5563.4902 - FP: 83.5100 - FN: 122.0900 - val_loss: 0.1803 - val_Accuracy: 0.9681 - val_Precision: 0.9296 - val_Recall: 0.9632 - val_TP: 774.4200 - val_TN: 1054.4600 - val_FP: 51.5400 - val_FN: 29.5800\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0839 - Accuracy: 0.9854 - Precision: 0.9657 - Recall: 0.9653 - TP: 3255.0400 - TN: 5562.2402 - FP: 84.7600 - FN: 116.9600 - val_loss: 0.1716 - val_Accuracy: 0.9733 - val_Precision: 0.9584 - val_Recall: 0.9509 - val_TP: 764.5600 - val_TN: 1080.3800 - val_FP: 25.6200 - val_FN: 39.4400\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0534 - Accuracy: 0.9887 - Precision: 0.9698 - Recall: 0.9678 - TP: 3263.3401 - TN: 5576.5601 - FP: 70.4400 - FN: 108.6600 - val_loss: 0.1817 - val_Accuracy: 0.9707 - val_Precision: 0.9478 - val_Recall: 0.9572 - val_TP: 769.6200 - val_TN: 1071.2000 - val_FP: 34.8000 - val_FN: 34.3800\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0552 - Accuracy: 0.9879 - Precision: 0.9686 - Recall: 0.9678 - TP: 3263.4099 - TN: 5572.1201 - FP: 74.8800 - FN: 108.5900 - val_loss: 0.1839 - val_Accuracy: 0.9691 - val_Precision: 0.9489 - val_Recall: 0.9553 - val_TP: 768.0300 - val_TN: 1072.1100 - val_FP: 33.8900 - val_FN: 35.9700\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0672 - Accuracy: 0.9886 - Precision: 0.9704 - Recall: 0.9687 - TP: 3266.5100 - TN: 5578.3701 - FP: 68.6300 - FN: 105.4900 - val_loss: 0.1806 - val_Accuracy: 0.9707 - val_Precision: 0.9474 - val_Recall: 0.9572 - val_TP: 769.5800 - val_TN: 1070.7500 - val_FP: 35.2500 - val_FN: 34.4200\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1081 - Accuracy: 0.9861 - Precision: 0.9667 - Recall: 0.9653 - TP: 3255.0901 - TN: 5565.7598 - FP: 81.2400 - FN: 116.9100 - val_loss: 0.1661 - val_Accuracy: 0.9733 - val_Precision: 0.9650 - val_Recall: 0.9440 - val_TP: 759.0000 - val_TN: 1085.9600 - val_FP: 20.0400 - val_FN: 45.0000\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0641 - Accuracy: 0.9866 - Precision: 0.9678 - Recall: 0.9662 - TP: 3258.1899 - TN: 5569.6401 - FP: 77.3600 - FN: 113.8100 - val_loss: 0.1615 - val_Accuracy: 0.9743 - val_Precision: 0.9608 - val_Recall: 0.9495 - val_TP: 763.3700 - val_TN: 1082.4200 - val_FP: 23.5800 - val_FN: 40.6300\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0570 - Accuracy: 0.9875 - Precision: 0.9685 - Recall: 0.9677 - TP: 3263.1499 - TN: 5571.8301 - FP: 75.1700 - FN: 108.8500 - val_loss: 0.1701 - val_Accuracy: 0.9733 - val_Precision: 0.9589 - val_Recall: 0.9502 - val_TP: 763.9600 - val_TN: 1080.8600 - val_FP: 25.1400 - val_FN: 40.0400\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0759 - Accuracy: 0.9878 - Precision: 0.9692 - Recall: 0.9675 - TP: 3262.3999 - TN: 5574.2002 - FP: 72.8000 - FN: 109.6000 - val_loss: 0.1734 - val_Accuracy: 0.9707 - val_Precision: 0.9621 - val_Recall: 0.9461 - val_TP: 760.6800 - val_TN: 1083.6500 - val_FP: 22.3500 - val_FN: 43.3200\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1594 - Accuracy: 0.9858 - Precision: 0.9672 - Recall: 0.9654 - TP: 3255.3000 - TN: 5567.7002 - FP: 79.3000 - FN: 116.7000 - val_loss: 0.1786 - val_Accuracy: 0.9707 - val_Precision: 0.9536 - val_Recall: 0.9491 - val_TP: 763.0400 - val_TN: 1076.3400 - val_FP: 29.6600 - val_FN: 40.9600\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0733 - Accuracy: 0.9868 - Precision: 0.9684 - Recall: 0.9669 - TP: 3260.4800 - TN: 5571.7500 - FP: 75.2500 - FN: 111.5200 - val_loss: 0.1766 - val_Accuracy: 0.9723 - val_Precision: 0.9484 - val_Recall: 0.9570 - val_TP: 769.4100 - val_TN: 1071.6000 - val_FP: 34.4000 - val_FN: 34.5900\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0986 - Accuracy: 0.9857 - Precision: 0.9674 - Recall: 0.9657 - TP: 3256.2600 - TN: 5568.2002 - FP: 78.8000 - FN: 115.7400 - val_loss: 0.1632 - val_Accuracy: 0.9749 - val_Precision: 0.9670 - val_Recall: 0.9468 - val_TP: 761.2500 - val_TN: 1087.6000 - val_FP: 18.4000 - val_FN: 42.7500\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0617 - Accuracy: 0.9876 - Precision: 0.9688 - Recall: 0.9674 - TP: 3261.9399 - TN: 5573.0200 - FP: 73.9800 - FN: 110.0600 - val_loss: 0.1582 - val_Accuracy: 0.9728 - val_Precision: 0.9548 - val_Recall: 0.9570 - val_TP: 769.4200 - val_TN: 1077.1000 - val_FP: 28.9000 - val_FN: 34.5800\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0904 - Accuracy: 0.9872 - Precision: 0.9684 - Recall: 0.9666 - TP: 3259.2600 - TN: 5571.7402 - FP: 75.2600 - FN: 112.7400 - val_loss: 0.1914 - val_Accuracy: 0.9712 - val_Precision: 0.9476 - val_Recall: 0.9571 - val_TP: 769.5000 - val_TN: 1071.0000 - val_FP: 35.0000 - val_FN: 34.5000\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0961 - Accuracy: 0.9872 - Precision: 0.9683 - Recall: 0.9671 - TP: 3260.8999 - TN: 5571.5400 - FP: 75.4600 - FN: 111.1000 - val_loss: 0.1900 - val_Accuracy: 0.9723 - val_Precision: 0.9564 - val_Recall: 0.9499 - val_TP: 763.7400 - val_TN: 1078.7800 - val_FP: 27.2200 - val_FN: 40.2600\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0561 - Accuracy: 0.9880 - Precision: 0.9683 - Recall: 0.9676 - TP: 3262.6399 - TN: 5571.3101 - FP: 75.6900 - FN: 109.3600 - val_loss: 0.1828 - val_Accuracy: 0.9712 - val_Precision: 0.9639 - val_Recall: 0.9414 - val_TP: 756.9000 - val_TN: 1085.2200 - val_FP: 20.7800 - val_FN: 47.1000\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 7ms/step - loss: 0.0892 - Accuracy: 0.9868 - Precision: 0.9678 - Recall: 0.9658 - TP: 3256.7100 - TN: 5569.6099 - FP: 77.3900 - FN: 115.2900 - val_loss: 0.1595 - val_Accuracy: 0.9728 - val_Precision: 0.9513 - val_Recall: 0.9539 - val_TP: 766.9100 - val_TN: 1074.1100 - val_FP: 31.8900 - val_FN: 37.0900\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0542 - Accuracy: 0.9859 - Precision: 0.9668 - Recall: 0.9649 - TP: 3253.5200 - TN: 5565.6099 - FP: 81.3900 - FN: 118.4800 - val_loss: 0.1511 - val_Accuracy: 0.9743 - val_Precision: 0.9524 - val_Recall: 0.9567 - val_TP: 769.1800 - val_TN: 1074.9500 - val_FP: 31.0500 - val_FN: 34.8200\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1602 - Accuracy: 0.9861 - Precision: 0.9660 - Recall: 0.9644 - TP: 3252.0500 - TN: 5563.1899 - FP: 83.8100 - FN: 119.9500 - val_loss: 0.1659 - val_Accuracy: 0.9728 - val_Precision: 0.9491 - val_Recall: 0.9583 - val_TP: 770.5100 - val_TN: 1072.2100 - val_FP: 33.7900 - val_FN: 33.4900\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0899 - Accuracy: 0.9858 - Precision: 0.9666 - Recall: 0.9653 - TP: 3254.9500 - TN: 5565.2500 - FP: 81.7500 - FN: 117.0500 - val_loss: 0.1538 - val_Accuracy: 0.9754 - val_Precision: 0.9570 - val_Recall: 0.9557 - val_TP: 768.4000 - val_TN: 1079.0400 - val_FP: 26.9600 - val_FN: 35.6000\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0726 - Accuracy: 0.9866 - Precision: 0.9678 - Recall: 0.9670 - TP: 3260.7400 - TN: 5569.7300 - FP: 77.2700 - FN: 111.2600 - val_loss: 0.1657 - val_Accuracy: 0.9728 - val_Precision: 0.9538 - val_Recall: 0.9546 - val_TP: 767.4700 - val_TN: 1076.3800 - val_FP: 29.6200 - val_FN: 36.5300\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0694 - Accuracy: 0.9869 - Precision: 0.9684 - Recall: 0.9666 - TP: 3259.3301 - TN: 5571.5601 - FP: 75.4400 - FN: 112.6700 - val_loss: 0.1723 - val_Accuracy: 0.9743 - val_Precision: 0.9648 - val_Recall: 0.9453 - val_TP: 760.0000 - val_TN: 1085.8300 - val_FP: 20.1700 - val_FN: 44.0000\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1276 - Accuracy: 0.9848 - Precision: 0.9656 - Recall: 0.9642 - TP: 3251.3999 - TN: 5561.8901 - FP: 85.1100 - FN: 120.6000 - val_loss: 0.1794 - val_Accuracy: 0.9707 - val_Precision: 0.9557 - val_Recall: 0.9511 - val_TP: 764.6500 - val_TN: 1078.1600 - val_FP: 27.8400 - val_FN: 39.3500\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0753 - Accuracy: 0.9866 - Precision: 0.9687 - Recall: 0.9669 - TP: 3260.3301 - TN: 5572.5801 - FP: 74.4200 - FN: 111.6700 - val_loss: 0.1904 - val_Accuracy: 0.9696 - val_Precision: 0.9548 - val_Recall: 0.9491 - val_TP: 763.1100 - val_TN: 1077.4100 - val_FP: 28.5900 - val_FN: 40.8900\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0929 - Accuracy: 0.9871 - Precision: 0.9679 - Recall: 0.9663 - TP: 3258.3899 - TN: 5569.8799 - FP: 77.1200 - FN: 113.6100 - val_loss: 0.1630 - val_Accuracy: 0.9733 - val_Precision: 0.9685 - val_Recall: 0.9419 - val_TP: 757.3000 - val_TN: 1088.8900 - val_FP: 17.1100 - val_FN: 46.7000\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1163 - Accuracy: 0.9858 - Precision: 0.9670 - Recall: 0.9660 - TP: 3257.2000 - TN: 5567.0601 - FP: 79.9400 - FN: 114.8000 - val_loss: 0.1632 - val_Accuracy: 0.9738 - val_Precision: 0.9629 - val_Recall: 0.9462 - val_TP: 760.7300 - val_TN: 1084.1500 - val_FP: 21.8500 - val_FN: 43.2700\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0680 - Accuracy: 0.9885 - Precision: 0.9687 - Recall: 0.9666 - TP: 3259.2100 - TN: 5572.8501 - FP: 74.1500 - FN: 112.7900 - val_loss: 0.1615 - val_Accuracy: 0.9717 - val_Precision: 0.9629 - val_Recall: 0.9457 - val_TP: 760.3600 - val_TN: 1084.2300 - val_FP: 21.7700 - val_FN: 43.6400\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1033 - Accuracy: 0.9872 - Precision: 0.9687 - Recall: 0.9672 - TP: 3261.2800 - TN: 5572.6001 - FP: 74.4000 - FN: 110.7200 - val_loss: 0.1567 - val_Accuracy: 0.9723 - val_Precision: 0.9608 - val_Recall: 0.9514 - val_TP: 764.9600 - val_TN: 1082.2900 - val_FP: 23.7100 - val_FN: 39.0400\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0630 - Accuracy: 0.9878 - Precision: 0.9682 - Recall: 0.9670 - TP: 3260.8501 - TN: 5570.8398 - FP: 76.1600 - FN: 111.1500 - val_loss: 0.1633 - val_Accuracy: 0.9723 - val_Precision: 0.9560 - val_Recall: 0.9532 - val_TP: 766.3600 - val_TN: 1078.2800 - val_FP: 27.7200 - val_FN: 37.6400\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0791 - Accuracy: 0.9878 - Precision: 0.9683 - Recall: 0.9667 - TP: 3259.7500 - TN: 5571.3501 - FP: 75.6500 - FN: 112.2500 - val_loss: 0.1609 - val_Accuracy: 0.9723 - val_Precision: 0.9556 - val_Recall: 0.9538 - val_TP: 766.8400 - val_TN: 1077.8400 - val_FP: 28.1600 - val_FN: 37.1600\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0585 - Accuracy: 0.9874 - Precision: 0.9673 - Recall: 0.9667 - TP: 3259.7500 - TN: 5567.8999 - FP: 79.1000 - FN: 112.2500 - val_loss: 0.1737 - val_Accuracy: 0.9723 - val_Precision: 0.9696 - val_Recall: 0.9387 - val_TP: 754.7400 - val_TN: 1089.8900 - val_FP: 16.1100 - val_FN: 49.2600\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0550 - Accuracy: 0.9879 - Precision: 0.9688 - Recall: 0.9670 - TP: 3260.5901 - TN: 5573.1299 - FP: 73.8700 - FN: 111.4100 - val_loss: 0.1723 - val_Accuracy: 0.9723 - val_Precision: 0.9636 - val_Recall: 0.9455 - val_TP: 760.1800 - val_TN: 1084.8400 - val_FP: 21.1600 - val_FN: 43.8200\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0703 - Accuracy: 0.9878 - Precision: 0.9678 - Recall: 0.9667 - TP: 3259.8601 - TN: 5569.5801 - FP: 77.4200 - FN: 112.1400 - val_loss: 0.1632 - val_Accuracy: 0.9738 - val_Precision: 0.9635 - val_Recall: 0.9470 - val_TP: 761.3500 - val_TN: 1084.7300 - val_FP: 21.2700 - val_FN: 42.6500\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0938 - Accuracy: 0.9868 - Precision: 0.9685 - Recall: 0.9666 - TP: 3259.3799 - TN: 5572.2998 - FP: 74.7000 - FN: 112.6200 - val_loss: 0.1950 - val_Accuracy: 0.9691 - val_Precision: 0.9454 - val_Recall: 0.9575 - val_TP: 769.8000 - val_TN: 1068.9900 - val_FP: 37.0100 - val_FN: 34.2000\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0654 - Accuracy: 0.9882 - Precision: 0.9685 - Recall: 0.9679 - TP: 3263.6299 - TN: 5571.7402 - FP: 75.2600 - FN: 108.3700 - val_loss: 0.1693 - val_Accuracy: 0.9733 - val_Precision: 0.9620 - val_Recall: 0.9479 - val_TP: 762.1200 - val_TN: 1083.4700 - val_FP: 22.5300 - val_FN: 41.8800\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0612 - Accuracy: 0.9879 - Precision: 0.9687 - Recall: 0.9672 - TP: 3261.5100 - TN: 5572.6802 - FP: 74.3200 - FN: 110.4900 - val_loss: 0.2018 - val_Accuracy: 0.9696 - val_Precision: 0.9523 - val_Recall: 0.9487 - val_TP: 762.7400 - val_TN: 1075.3199 - val_FP: 30.6800 - val_FN: 41.2600\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0637 - Accuracy: 0.9874 - Precision: 0.9682 - Recall: 0.9662 - TP: 3257.9099 - TN: 5570.7202 - FP: 76.2800 - FN: 114.0900 - val_loss: 0.2161 - val_Accuracy: 0.9649 - val_Precision: 0.9325 - val_Recall: 0.9598 - val_TP: 771.6600 - val_TN: 1057.3500 - val_FP: 48.6500 - val_FN: 32.3400\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0791 - Accuracy: 0.9864 - Precision: 0.9675 - Recall: 0.9668 - TP: 3259.8899 - TN: 5568.4702 - FP: 78.5300 - FN: 112.1100 - val_loss: 0.1965 - val_Accuracy: 0.9686 - val_Precision: 0.9455 - val_Recall: 0.9575 - val_TP: 769.8600 - val_TN: 1069.2200 - val_FP: 36.7800 - val_FN: 34.1400\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 8ms/step - loss: 0.1129 - Accuracy: 0.9855 - Precision: 0.9664 - Recall: 0.9646 - TP: 3252.5100 - TN: 5564.5098 - FP: 82.4900 - FN: 119.4900 - val_loss: 0.1566 - val_Accuracy: 0.9749 - val_Precision: 0.9638 - val_Recall: 0.9479 - val_TP: 762.1200 - val_TN: 1084.8600 - val_FP: 21.1400 - val_FN: 41.8800\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0858 - Accuracy: 0.9865 - Precision: 0.9669 - Recall: 0.9651 - TP: 3254.1799 - TN: 5566.2300 - FP: 80.7700 - FN: 117.8200 - val_loss: 0.2481 - val_Accuracy: 0.9654 - val_Precision: 0.9348 - val_Recall: 0.9552 - val_TP: 767.9600 - val_TN: 1059.9200 - val_FP: 46.0800 - val_FN: 36.0400\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0594 - Accuracy: 0.9863 - Precision: 0.9674 - Recall: 0.9661 - TP: 3257.5500 - TN: 5568.3101 - FP: 78.6900 - FN: 114.4500 - val_loss: 0.1587 - val_Accuracy: 0.9728 - val_Precision: 0.9591 - val_Recall: 0.9498 - val_TP: 763.6300 - val_TN: 1080.9200 - val_FP: 25.0800 - val_FN: 40.3700\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0789 - Accuracy: 0.9860 - Precision: 0.9667 - Recall: 0.9654 - TP: 3255.3301 - TN: 5565.6099 - FP: 81.3900 - FN: 116.6700 - val_loss: 0.1760 - val_Accuracy: 0.9723 - val_Precision: 0.9565 - val_Recall: 0.9516 - val_TP: 765.0500 - val_TN: 1078.7700 - val_FP: 27.2300 - val_FN: 38.9500\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0949 - Accuracy: 0.9866 - Precision: 0.9680 - Recall: 0.9659 - TP: 3256.9800 - TN: 5570.2900 - FP: 76.7100 - FN: 115.0200 - val_loss: 0.1587 - val_Accuracy: 0.9749 - val_Precision: 0.9635 - val_Recall: 0.9482 - val_TP: 762.3600 - val_TN: 1084.7100 - val_FP: 21.2900 - val_FN: 41.6400\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0686 - Accuracy: 0.9874 - Precision: 0.9685 - Recall: 0.9670 - TP: 3260.6399 - TN: 5571.9600 - FP: 75.0400 - FN: 111.3600 - val_loss: 0.2144 - val_Accuracy: 0.9675 - val_Precision: 0.9443 - val_Recall: 0.9541 - val_TP: 767.0800 - val_TN: 1068.3101 - val_FP: 37.6900 - val_FN: 36.9200\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0699 - Accuracy: 0.9864 - Precision: 0.9669 - Recall: 0.9664 - TP: 3258.7400 - TN: 5566.4600 - FP: 80.5400 - FN: 113.2600 - val_loss: 0.2182 - val_Accuracy: 0.9702 - val_Precision: 0.9556 - val_Recall: 0.9450 - val_TP: 759.7900 - val_TN: 1078.2900 - val_FP: 27.7100 - val_FN: 44.2100\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0971 - Accuracy: 0.9858 - Precision: 0.9664 - Recall: 0.9653 - TP: 3255.1299 - TN: 5564.9502 - FP: 82.0500 - FN: 116.8700 - val_loss: 0.2044 - val_Accuracy: 0.9660 - val_Precision: 0.9772 - val_Recall: 0.9216 - val_TP: 740.9900 - val_TN: 1096.2000 - val_FP: 9.8000 - val_FN: 63.0100\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1256 - Accuracy: 0.9857 - Precision: 0.9665 - Recall: 0.9643 - TP: 3251.4700 - TN: 5565.1201 - FP: 81.8800 - FN: 120.5300 - val_loss: 0.1900 - val_Accuracy: 0.9717 - val_Precision: 0.9623 - val_Recall: 0.9456 - val_TP: 760.3000 - val_TN: 1083.8199 - val_FP: 22.1800 - val_FN: 43.7000\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0906 - Accuracy: 0.9869 - Precision: 0.9686 - Recall: 0.9661 - TP: 3257.6799 - TN: 5572.6899 - FP: 74.3100 - FN: 114.3200 - val_loss: 0.1653 - val_Accuracy: 0.9717 - val_Precision: 0.9513 - val_Recall: 0.9571 - val_TP: 769.4700 - val_TN: 1074.0500 - val_FP: 31.9500 - val_FN: 34.5300\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0906 - Accuracy: 0.9863 - Precision: 0.9670 - Recall: 0.9663 - TP: 3258.2600 - TN: 5566.9702 - FP: 80.0300 - FN: 113.7400 - val_loss: 0.1749 - val_Accuracy: 0.9723 - val_Precision: 0.9728 - val_Recall: 0.9351 - val_TP: 751.8200 - val_TN: 1092.4900 - val_FP: 13.5100 - val_FN: 52.1800\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0916 - Accuracy: 0.9860 - Precision: 0.9673 - Recall: 0.9656 - TP: 3256.1001 - TN: 5567.6401 - FP: 79.3600 - FN: 115.9000 - val_loss: 0.1684 - val_Accuracy: 0.9702 - val_Precision: 0.9514 - val_Recall: 0.9554 - val_TP: 768.1100 - val_TN: 1074.3199 - val_FP: 31.6800 - val_FN: 35.8900\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0867 - Accuracy: 0.9864 - Precision: 0.9681 - Recall: 0.9663 - TP: 3258.4900 - TN: 5571.1299 - FP: 75.8700 - FN: 113.5100 - val_loss: 0.1665 - val_Accuracy: 0.9723 - val_Precision: 0.9527 - val_Recall: 0.9553 - val_TP: 768.0400 - val_TN: 1075.4100 - val_FP: 30.5900 - val_FN: 35.9600\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0979 - Accuracy: 0.9867 - Precision: 0.9671 - Recall: 0.9667 - TP: 3259.8201 - TN: 5567.2202 - FP: 79.7800 - FN: 112.1800 - val_loss: 0.2199 - val_Accuracy: 0.9681 - val_Precision: 0.9645 - val_Recall: 0.9372 - val_TP: 753.4900 - val_TN: 1085.8500 - val_FP: 20.1500 - val_FN: 50.5100\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1028 - Accuracy: 0.9881 - Precision: 0.9686 - Recall: 0.9676 - TP: 3262.6299 - TN: 5572.4902 - FP: 74.5100 - FN: 109.3700 - val_loss: 0.1909 - val_Accuracy: 0.9717 - val_Precision: 0.9633 - val_Recall: 0.9423 - val_TP: 757.5700 - val_TN: 1084.7200 - val_FP: 21.2800 - val_FN: 46.4300\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1189 - Accuracy: 0.9874 - Precision: 0.9680 - Recall: 0.9653 - TP: 3254.9199 - TN: 5570.5000 - FP: 76.5000 - FN: 117.0800 - val_loss: 0.1828 - val_Accuracy: 0.9717 - val_Precision: 0.9475 - val_Recall: 0.9574 - val_TP: 769.7300 - val_TN: 1070.9200 - val_FP: 35.0800 - val_FN: 34.2700\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1164 - Accuracy: 0.9853 - Precision: 0.9658 - Recall: 0.9655 - TP: 3255.6699 - TN: 5562.9399 - FP: 84.0600 - FN: 116.3300 - val_loss: 0.1794 - val_Accuracy: 0.9723 - val_Precision: 0.9571 - val_Recall: 0.9524 - val_TP: 765.7600 - val_TN: 1079.2700 - val_FP: 26.7300 - val_FN: 38.2400\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0556 - Accuracy: 0.9875 - Precision: 0.9691 - Recall: 0.9679 - TP: 3263.6599 - TN: 5574.4502 - FP: 72.5500 - FN: 108.3400 - val_loss: 0.1716 - val_Accuracy: 0.9738 - val_Precision: 0.9640 - val_Recall: 0.9468 - val_TP: 761.2000 - val_TN: 1085.2000 - val_FP: 20.8000 - val_FN: 42.8000\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0874 - Accuracy: 0.9868 - Precision: 0.9689 - Recall: 0.9679 - TP: 3263.8701 - TN: 5573.3101 - FP: 73.6900 - FN: 108.1300 - val_loss: 0.1680 - val_Accuracy: 0.9738 - val_Precision: 0.9634 - val_Recall: 0.9477 - val_TP: 761.9300 - val_TN: 1084.6100 - val_FP: 21.3900 - val_FN: 42.0700\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1301 - Accuracy: 0.9868 - Precision: 0.9677 - Recall: 0.9656 - TP: 3255.8601 - TN: 5569.2402 - FP: 77.7600 - FN: 116.1400 - val_loss: 0.2226 - val_Accuracy: 0.9670 - val_Precision: 0.9387 - val_Recall: 0.9547 - val_TP: 767.5600 - val_TN: 1063.2000 - val_FP: 42.8000 - val_FN: 36.4400\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0924 - Accuracy: 0.9871 - Precision: 0.9690 - Recall: 0.9686 - TP: 3265.9700 - TN: 5573.9302 - FP: 73.0700 - FN: 106.0300 - val_loss: 0.1940 - val_Accuracy: 0.9712 - val_Precision: 0.9644 - val_Recall: 0.9432 - val_TP: 758.3000 - val_TN: 1085.6300 - val_FP: 20.3700 - val_FN: 45.7000\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 7ms/step - loss: 0.1067 - Accuracy: 0.9858 - Precision: 0.9661 - Recall: 0.9653 - TP: 3255.0400 - TN: 5563.7402 - FP: 83.2600 - FN: 116.9600 - val_loss: 0.1890 - val_Accuracy: 0.9681 - val_Precision: 0.9706 - val_Recall: 0.9320 - val_TP: 749.3400 - val_TN: 1090.8300 - val_FP: 15.1700 - val_FN: 54.6600\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0646 - Accuracy: 0.9851 - Precision: 0.9669 - Recall: 0.9652 - TP: 3254.7100 - TN: 5566.5098 - FP: 80.4900 - FN: 117.2900 - val_loss: 0.1770 - val_Accuracy: 0.9728 - val_Precision: 0.9625 - val_Recall: 0.9459 - val_TP: 760.4700 - val_TN: 1083.9301 - val_FP: 22.0700 - val_FN: 43.5300\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0932 - Accuracy: 0.9859 - Precision: 0.9673 - Recall: 0.9648 - TP: 3253.3501 - TN: 5567.7598 - FP: 79.2400 - FN: 118.6500 - val_loss: 0.1619 - val_Accuracy: 0.9723 - val_Precision: 0.9562 - val_Recall: 0.9526 - val_TP: 765.8700 - val_TN: 1078.4800 - val_FP: 27.5200 - val_FN: 38.1300\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0833 - Accuracy: 0.9881 - Precision: 0.9686 - Recall: 0.9669 - TP: 3260.4800 - TN: 5572.2700 - FP: 74.7300 - FN: 111.5200 - val_loss: 0.1593 - val_Accuracy: 0.9728 - val_Precision: 0.9546 - val_Recall: 0.9548 - val_TP: 767.6600 - val_TN: 1076.9200 - val_FP: 29.0800 - val_FN: 36.3400\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0906 - Accuracy: 0.9847 - Precision: 0.9657 - Recall: 0.9649 - TP: 3253.4800 - TN: 5562.6299 - FP: 84.3700 - FN: 118.5200 - val_loss: 0.1652 - val_Accuracy: 0.9738 - val_Precision: 0.9537 - val_Recall: 0.9548 - val_TP: 767.6400 - val_TN: 1076.1899 - val_FP: 29.8100 - val_FN: 36.3600\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1124 - Accuracy: 0.9857 - Precision: 0.9663 - Recall: 0.9653 - TP: 3255.0200 - TN: 5564.4902 - FP: 82.5100 - FN: 116.9800 - val_loss: 0.1718 - val_Accuracy: 0.9738 - val_Precision: 0.9701 - val_Recall: 0.9406 - val_TP: 756.2700 - val_TN: 1090.2300 - val_FP: 15.7700 - val_FN: 47.7300\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0623 - Accuracy: 0.9877 - Precision: 0.9687 - Recall: 0.9664 - TP: 3258.6299 - TN: 5572.9502 - FP: 74.0500 - FN: 113.3700 - val_loss: 0.1620 - val_Accuracy: 0.9723 - val_Precision: 0.9538 - val_Recall: 0.9575 - val_TP: 769.8600 - val_TN: 1076.2900 - val_FP: 29.7100 - val_FN: 34.1400\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0793 - Accuracy: 0.9855 - Precision: 0.9670 - Recall: 0.9653 - TP: 3254.8701 - TN: 5566.7798 - FP: 80.2200 - FN: 117.1300 - val_loss: 0.1648 - val_Accuracy: 0.9749 - val_Precision: 0.9619 - val_Recall: 0.9500 - val_TP: 763.8300 - val_TN: 1083.2600 - val_FP: 22.7400 - val_FN: 40.1700\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1062 - Accuracy: 0.9856 - Precision: 0.9668 - Recall: 0.9661 - TP: 3257.5701 - TN: 5566.4102 - FP: 80.5900 - FN: 114.4300 - val_loss: 0.2618 - val_Accuracy: 0.9639 - val_Precision: 0.9320 - val_Recall: 0.9537 - val_TP: 766.7400 - val_TN: 1057.3900 - val_FP: 48.6100 - val_FN: 37.2600\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0728 - Accuracy: 0.9865 - Precision: 0.9684 - Recall: 0.9667 - TP: 3259.7500 - TN: 5571.7100 - FP: 75.2900 - FN: 112.2500 - val_loss: 0.1771 - val_Accuracy: 0.9728 - val_Precision: 0.9593 - val_Recall: 0.9500 - val_TP: 763.7700 - val_TN: 1081.1600 - val_FP: 24.8400 - val_FN: 40.2300\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1060 - Accuracy: 0.9849 - Precision: 0.9654 - Recall: 0.9652 - TP: 3254.8101 - TN: 5561.1602 - FP: 85.8400 - FN: 117.1900 - val_loss: 0.1732 - val_Accuracy: 0.9733 - val_Precision: 0.9700 - val_Recall: 0.9416 - val_TP: 757.0300 - val_TN: 1090.1200 - val_FP: 15.8800 - val_FN: 46.9700\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0873 - Accuracy: 0.9860 - Precision: 0.9672 - Recall: 0.9648 - TP: 3253.4700 - TN: 5567.7100 - FP: 79.2900 - FN: 118.5300 - val_loss: 0.1649 - val_Accuracy: 0.9738 - val_Precision: 0.9687 - val_Recall: 0.9453 - val_TP: 760.0500 - val_TN: 1089.0400 - val_FP: 16.9600 - val_FN: 43.9500\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0928 - Accuracy: 0.9866 - Precision: 0.9679 - Recall: 0.9662 - TP: 3258.0000 - TN: 5570.0498 - FP: 76.9500 - FN: 114.0000 - val_loss: 0.1697 - val_Accuracy: 0.9723 - val_Precision: 0.9590 - val_Recall: 0.9508 - val_TP: 764.4100 - val_TN: 1080.9100 - val_FP: 25.0900 - val_FN: 39.5900\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0853 - Accuracy: 0.9876 - Precision: 0.9679 - Recall: 0.9671 - TP: 3261.1399 - TN: 5570.0000 - FP: 77.0000 - FN: 110.8600 - val_loss: 0.1808 - val_Accuracy: 0.9717 - val_Precision: 0.9699 - val_Recall: 0.9378 - val_TP: 754.0100 - val_TN: 1090.1400 - val_FP: 15.8600 - val_FN: 49.9900\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1310 - Accuracy: 0.9854 - Precision: 0.9665 - Recall: 0.9651 - TP: 3254.2100 - TN: 5565.3901 - FP: 81.6100 - FN: 117.7900 - val_loss: 0.1662 - val_Accuracy: 0.9738 - val_Precision: 0.9626 - val_Recall: 0.9487 - val_TP: 762.7400 - val_TN: 1083.9301 - val_FP: 22.0700 - val_FN: 41.2600\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1349 - Accuracy: 0.9867 - Precision: 0.9672 - Recall: 0.9651 - TP: 3254.4199 - TN: 5567.7402 - FP: 79.2600 - FN: 117.5800 - val_loss: 0.1897 - val_Accuracy: 0.9696 - val_Precision: 0.9526 - val_Recall: 0.9516 - val_TP: 765.0900 - val_TN: 1075.4800 - val_FP: 30.5200 - val_FN: 38.9100\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0969 - Accuracy: 0.9876 - Precision: 0.9683 - Recall: 0.9671 - TP: 3261.0400 - TN: 5571.2500 - FP: 75.7500 - FN: 110.9600 - val_loss: 0.1765 - val_Accuracy: 0.9723 - val_Precision: 0.9620 - val_Recall: 0.9477 - val_TP: 761.9300 - val_TN: 1083.4800 - val_FP: 22.5200 - val_FN: 42.0700\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0755 - Accuracy: 0.9864 - Precision: 0.9681 - Recall: 0.9675 - TP: 3262.5000 - TN: 5570.8701 - FP: 76.1300 - FN: 109.5000 - val_loss: 0.1795 - val_Accuracy: 0.9723 - val_Precision: 0.9591 - val_Recall: 0.9483 - val_TP: 762.4400 - val_TN: 1081.0300 - val_FP: 24.9700 - val_FN: 41.5600\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1105 - Accuracy: 0.9859 - Precision: 0.9667 - Recall: 0.9647 - TP: 3252.9900 - TN: 5566.0298 - FP: 80.9700 - FN: 119.0100 - val_loss: 0.1728 - val_Accuracy: 0.9733 - val_Precision: 0.9580 - val_Recall: 0.9529 - val_TP: 766.1200 - val_TN: 1079.9900 - val_FP: 26.0100 - val_FN: 37.8800\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0678 - Accuracy: 0.9868 - Precision: 0.9679 - Recall: 0.9669 - TP: 3260.5000 - TN: 5570.2500 - FP: 76.7500 - FN: 111.5000 - val_loss: 0.1893 - val_Accuracy: 0.9702 - val_Precision: 0.9586 - val_Recall: 0.9477 - val_TP: 761.9500 - val_TN: 1080.7300 - val_FP: 25.2700 - val_FN: 42.0500\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1134 - Accuracy: 0.9860 - Precision: 0.9668 - Recall: 0.9653 - TP: 3254.8401 - TN: 5566.5400 - FP: 80.4600 - FN: 117.1600 - val_loss: 0.1749 - val_Accuracy: 0.9723 - val_Precision: 0.9603 - val_Recall: 0.9488 - val_TP: 762.8200 - val_TN: 1082.1000 - val_FP: 23.9000 - val_FN: 41.1800\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0732 - Accuracy: 0.9860 - Precision: 0.9680 - Recall: 0.9667 - TP: 3259.6599 - TN: 5570.4399 - FP: 76.5600 - FN: 112.3400 - val_loss: 0.1699 - val_Accuracy: 0.9717 - val_Precision: 0.9583 - val_Recall: 0.9496 - val_TP: 763.4800 - val_TN: 1080.3600 - val_FP: 25.6400 - val_FN: 40.5200\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0714 - Accuracy: 0.9876 - Precision: 0.9694 - Recall: 0.9674 - TP: 3262.1001 - TN: 5575.3398 - FP: 71.6600 - FN: 109.9000 - val_loss: 0.1687 - val_Accuracy: 0.9723 - val_Precision: 0.9535 - val_Recall: 0.9553 - val_TP: 768.0800 - val_TN: 1076.0601 - val_FP: 29.9400 - val_FN: 35.9200\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1103 - Accuracy: 0.9858 - Precision: 0.9664 - Recall: 0.9659 - TP: 3257.0701 - TN: 5564.8101 - FP: 82.1900 - FN: 114.9300 - val_loss: 0.2316 - val_Accuracy: 0.9670 - val_Precision: 0.9568 - val_Recall: 0.9402 - val_TP: 755.9100 - val_TN: 1079.4399 - val_FP: 26.5600 - val_FN: 48.0900\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 7ms/step - loss: 0.0720 - Accuracy: 0.9867 - Precision: 0.9669 - Recall: 0.9664 - TP: 3258.6899 - TN: 5566.3101 - FP: 80.6900 - FN: 113.3100 - val_loss: 0.1661 - val_Accuracy: 0.9717 - val_Precision: 0.9633 - val_Recall: 0.9456 - val_TP: 760.3000 - val_TN: 1084.5800 - val_FP: 21.4200 - val_FN: 43.7000\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0869 - Accuracy: 0.9867 - Precision: 0.9675 - Recall: 0.9651 - TP: 3254.4399 - TN: 5568.8501 - FP: 78.1500 - FN: 117.5600 - val_loss: 0.1597 - val_Accuracy: 0.9733 - val_Precision: 0.9592 - val_Recall: 0.9523 - val_TP: 765.6300 - val_TN: 1081.0000 - val_FP: 25.0000 - val_FN: 38.3700\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0915 - Accuracy: 0.9868 - Precision: 0.9676 - Recall: 0.9665 - TP: 3258.9900 - TN: 5568.6802 - FP: 78.3200 - FN: 113.0100 - val_loss: 0.1856 - val_Accuracy: 0.9702 - val_Precision: 0.9575 - val_Recall: 0.9498 - val_TP: 763.6100 - val_TN: 1079.6600 - val_FP: 26.3400 - val_FN: 40.3900\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0964 - Accuracy: 0.9871 - Precision: 0.9678 - Recall: 0.9660 - TP: 3257.5100 - TN: 5569.4102 - FP: 77.5900 - FN: 114.4900 - val_loss: 0.1937 - val_Accuracy: 0.9696 - val_Precision: 0.9492 - val_Recall: 0.9534 - val_TP: 766.5700 - val_TN: 1072.5699 - val_FP: 33.4300 - val_FN: 37.4300\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1181 - Accuracy: 0.9861 - Precision: 0.9665 - Recall: 0.9653 - TP: 3255.0000 - TN: 5565.2500 - FP: 81.7500 - FN: 117.0000 - val_loss: 0.1724 - val_Accuracy: 0.9728 - val_Precision: 0.9704 - val_Recall: 0.9395 - val_TP: 755.3700 - val_TN: 1090.4900 - val_FP: 15.5100 - val_FN: 48.6300\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1045 - Accuracy: 0.9863 - Precision: 0.9669 - Recall: 0.9654 - TP: 3255.2700 - TN: 5566.6401 - FP: 80.3600 - FN: 116.7300 - val_loss: 0.1628 - val_Accuracy: 0.9749 - val_Precision: 0.9619 - val_Recall: 0.9506 - val_TP: 764.2500 - val_TN: 1083.2700 - val_FP: 22.7300 - val_FN: 39.7500\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1015 - Accuracy: 0.9863 - Precision: 0.9676 - Recall: 0.9664 - TP: 3258.8201 - TN: 5569.3301 - FP: 77.6700 - FN: 113.1800 - val_loss: 0.1641 - val_Accuracy: 0.9749 - val_Precision: 0.9620 - val_Recall: 0.9500 - val_TP: 763.8000 - val_TN: 1083.3700 - val_FP: 22.6300 - val_FN: 40.2000\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1964 - Accuracy: 0.9840 - Precision: 0.9654 - Recall: 0.9643 - TP: 3251.7500 - TN: 5561.5601 - FP: 85.4400 - FN: 120.2500 - val_loss: 0.2689 - val_Accuracy: 0.9618 - val_Precision: 0.9457 - val_Recall: 0.9396 - val_TP: 755.4100 - val_TN: 1070.1801 - val_FP: 35.8200 - val_FN: 48.5900\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0675 - Accuracy: 0.9868 - Precision: 0.9685 - Recall: 0.9665 - TP: 3258.9500 - TN: 5572.5098 - FP: 74.4900 - FN: 113.0500 - val_loss: 0.1909 - val_Accuracy: 0.9712 - val_Precision: 0.9502 - val_Recall: 0.9547 - val_TP: 767.6100 - val_TN: 1073.3199 - val_FP: 32.6800 - val_FN: 36.3900\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0619 - Accuracy: 0.9872 - Precision: 0.9688 - Recall: 0.9676 - TP: 3262.5801 - TN: 5573.3398 - FP: 73.6600 - FN: 109.4200 - val_loss: 0.1731 - val_Accuracy: 0.9717 - val_Precision: 0.9652 - val_Recall: 0.9436 - val_TP: 758.6800 - val_TN: 1086.1600 - val_FP: 19.8400 - val_FN: 45.3200\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1094 - Accuracy: 0.9857 - Precision: 0.9669 - Recall: 0.9654 - TP: 3255.2800 - TN: 5566.6602 - FP: 80.3400 - FN: 116.7200 - val_loss: 0.1852 - val_Accuracy: 0.9717 - val_Precision: 0.9637 - val_Recall: 0.9425 - val_TP: 757.7700 - val_TN: 1085.0500 - val_FP: 20.9500 - val_FN: 46.2300\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1766 - Accuracy: 0.9853 - Precision: 0.9664 - Recall: 0.9652 - TP: 3254.8201 - TN: 5565.0601 - FP: 81.9400 - FN: 117.1800 - val_loss: 0.1787 - val_Accuracy: 0.9696 - val_Precision: 0.9458 - val_Recall: 0.9586 - val_TP: 770.7300 - val_TN: 1069.4800 - val_FP: 36.5200 - val_FN: 33.2700\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0597 - Accuracy: 0.9880 - Precision: 0.9702 - Recall: 0.9684 - TP: 3265.3999 - TN: 5578.0498 - FP: 68.9500 - FN: 106.6000 - val_loss: 0.2216 - val_Accuracy: 0.9670 - val_Precision: 0.9444 - val_Recall: 0.9561 - val_TP: 768.7400 - val_TN: 1068.4500 - val_FP: 37.5500 - val_FN: 35.2600\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0934 - Accuracy: 0.9860 - Precision: 0.9685 - Recall: 0.9663 - TP: 3258.4600 - TN: 5572.2002 - FP: 74.8000 - FN: 113.5400 - val_loss: 0.1762 - val_Accuracy: 0.9691 - val_Precision: 0.9502 - val_Recall: 0.9550 - val_TP: 767.8300 - val_TN: 1073.3400 - val_FP: 32.6600 - val_FN: 36.1700\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1089 - Accuracy: 0.9878 - Precision: 0.9669 - Recall: 0.9671 - TP: 3261.2200 - TN: 5566.6201 - FP: 80.3800 - FN: 110.7800 - val_loss: 0.2065 - val_Accuracy: 0.9712 - val_Precision: 0.9592 - val_Recall: 0.9472 - val_TP: 761.5200 - val_TN: 1081.2300 - val_FP: 24.7700 - val_FN: 42.4800\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0678 - Accuracy: 0.9866 - Precision: 0.9687 - Recall: 0.9672 - TP: 3261.4199 - TN: 5572.8599 - FP: 74.1400 - FN: 110.5800 - val_loss: 0.1933 - val_Accuracy: 0.9702 - val_Precision: 0.9611 - val_Recall: 0.9452 - val_TP: 759.9600 - val_TN: 1082.7900 - val_FP: 23.2100 - val_FN: 44.0400\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0628 - Accuracy: 0.9882 - Precision: 0.9698 - Recall: 0.9685 - TP: 3265.7700 - TN: 5576.5200 - FP: 70.4800 - FN: 106.2300 - val_loss: 0.2087 - val_Accuracy: 0.9707 - val_Precision: 0.9555 - val_Recall: 0.9502 - val_TP: 763.9400 - val_TN: 1078.0500 - val_FP: 27.9500 - val_FN: 40.0600\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0890 - Accuracy: 0.9885 - Precision: 0.9696 - Recall: 0.9674 - TP: 3261.9600 - TN: 5576.2402 - FP: 70.7600 - FN: 110.0400 - val_loss: 0.2062 - val_Accuracy: 0.9670 - val_Precision: 0.9360 - val_Recall: 0.9616 - val_TP: 773.0900 - val_TN: 1060.5100 - val_FP: 45.4900 - val_FN: 30.9100\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0976 - Accuracy: 0.9867 - Precision: 0.9677 - Recall: 0.9670 - TP: 3260.7200 - TN: 5569.4302 - FP: 77.5700 - FN: 111.2800 - val_loss: 0.1789 - val_Accuracy: 0.9702 - val_Precision: 0.9663 - val_Recall: 0.9415 - val_TP: 756.9400 - val_TN: 1087.2000 - val_FP: 18.8000 - val_FN: 47.0600\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0946 - Accuracy: 0.9874 - Precision: 0.9685 - Recall: 0.9669 - TP: 3260.4700 - TN: 5572.3398 - FP: 74.6600 - FN: 111.5300 - val_loss: 0.1767 - val_Accuracy: 0.9723 - val_Precision: 0.9564 - val_Recall: 0.9526 - val_TP: 765.9000 - val_TN: 1078.6801 - val_FP: 27.3200 - val_FN: 38.1000\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0820 - Accuracy: 0.9868 - Precision: 0.9677 - Recall: 0.9668 - TP: 3260.0100 - TN: 5569.3398 - FP: 77.6600 - FN: 111.9900 - val_loss: 0.2472 - val_Accuracy: 0.9660 - val_Precision: 0.9430 - val_Recall: 0.9501 - val_TP: 763.8700 - val_TN: 1067.4000 - val_FP: 38.6000 - val_FN: 40.1300\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1178 - Accuracy: 0.9864 - Precision: 0.9683 - Recall: 0.9656 - TP: 3255.8601 - TN: 5571.7900 - FP: 75.2100 - FN: 116.1400 - val_loss: 0.1906 - val_Accuracy: 0.9707 - val_Precision: 0.9487 - val_Recall: 0.9574 - val_TP: 769.7200 - val_TN: 1071.9399 - val_FP: 34.0600 - val_FN: 34.2800\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 7ms/step - loss: 0.0875 - Accuracy: 0.9866 - Precision: 0.9670 - Recall: 0.9656 - TP: 3255.9399 - TN: 5566.6802 - FP: 80.3200 - FN: 116.0600 - val_loss: 0.1579 - val_Accuracy: 0.9738 - val_Precision: 0.9642 - val_Recall: 0.9487 - val_TP: 762.7600 - val_TN: 1085.2300 - val_FP: 20.7700 - val_FN: 41.2400\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1009 - Accuracy: 0.9859 - Precision: 0.9681 - Recall: 0.9665 - TP: 3259.1799 - TN: 5570.8301 - FP: 76.1700 - FN: 112.8200 - val_loss: 0.1774 - val_Accuracy: 0.9712 - val_Precision: 0.9541 - val_Recall: 0.9543 - val_TP: 767.2900 - val_TN: 1076.7000 - val_FP: 29.3000 - val_FN: 36.7100\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1221 - Accuracy: 0.9857 - Precision: 0.9669 - Recall: 0.9658 - TP: 3256.7000 - TN: 5566.7002 - FP: 80.3000 - FN: 115.3000 - val_loss: 0.1626 - val_Accuracy: 0.9743 - val_Precision: 0.9638 - val_Recall: 0.9469 - val_TP: 761.2800 - val_TN: 1084.9399 - val_FP: 21.0600 - val_FN: 42.7200\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0709 - Accuracy: 0.9874 - Precision: 0.9691 - Recall: 0.9667 - TP: 3259.7400 - TN: 5574.2402 - FP: 72.7600 - FN: 112.2600 - val_loss: 0.1754 - val_Accuracy: 0.9702 - val_Precision: 0.9583 - val_Recall: 0.9494 - val_TP: 763.3400 - val_TN: 1080.3400 - val_FP: 25.6600 - val_FN: 40.6600\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1210 - Accuracy: 0.9867 - Precision: 0.9670 - Recall: 0.9662 - TP: 3258.0200 - TN: 5566.8101 - FP: 80.1900 - FN: 113.9800 - val_loss: 0.1754 - val_Accuracy: 0.9717 - val_Precision: 0.9551 - val_Recall: 0.9505 - val_TP: 764.2100 - val_TN: 1077.6200 - val_FP: 28.3800 - val_FN: 39.7900\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1212 - Accuracy: 0.9857 - Precision: 0.9666 - Recall: 0.9649 - TP: 3253.7300 - TN: 5565.7002 - FP: 81.3000 - FN: 118.2700 - val_loss: 0.1635 - val_Accuracy: 0.9723 - val_Precision: 0.9598 - val_Recall: 0.9522 - val_TP: 765.5800 - val_TN: 1081.5000 - val_FP: 24.5000 - val_FN: 38.4200\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0983 - Accuracy: 0.9855 - Precision: 0.9661 - Recall: 0.9652 - TP: 3254.6399 - TN: 5563.8599 - FP: 83.1400 - FN: 117.3600 - val_loss: 0.1683 - val_Accuracy: 0.9749 - val_Precision: 0.9653 - val_Recall: 0.9490 - val_TP: 762.9700 - val_TN: 1086.1500 - val_FP: 19.8500 - val_FN: 41.0300\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1166 - Accuracy: 0.9865 - Precision: 0.9671 - Recall: 0.9656 - TP: 3255.8501 - TN: 5567.2002 - FP: 79.8000 - FN: 116.1500 - val_loss: 0.1653 - val_Accuracy: 0.9738 - val_Precision: 0.9639 - val_Recall: 0.9488 - val_TP: 762.8200 - val_TN: 1085.0200 - val_FP: 20.9800 - val_FN: 41.1800\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0964 - Accuracy: 0.9858 - Precision: 0.9676 - Recall: 0.9660 - TP: 3257.2200 - TN: 5569.3301 - FP: 77.6700 - FN: 114.7800 - val_loss: 0.1676 - val_Accuracy: 0.9733 - val_Precision: 0.9616 - val_Recall: 0.9494 - val_TP: 763.2800 - val_TN: 1083.0699 - val_FP: 22.9300 - val_FN: 40.7200\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1322 - Accuracy: 0.9864 - Precision: 0.9671 - Recall: 0.9652 - TP: 3254.6299 - TN: 5567.5698 - FP: 79.4300 - FN: 117.3700 - val_loss: 0.1709 - val_Accuracy: 0.9723 - val_Precision: 0.9639 - val_Recall: 0.9464 - val_TP: 760.9300 - val_TN: 1085.0800 - val_FP: 20.9200 - val_FN: 43.0700\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.1228 - Accuracy: 0.9879 - Precision: 0.9683 - Recall: 0.9672 - TP: 3261.5000 - TN: 5571.2798 - FP: 75.7200 - FN: 110.5000 - val_loss: 0.2073 - val_Accuracy: 0.9696 - val_Precision: 0.9498 - val_Recall: 0.9538 - val_TP: 766.8700 - val_TN: 1073.0601 - val_FP: 32.9400 - val_FN: 37.1300\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0706 - Accuracy: 0.9871 - Precision: 0.9676 - Recall: 0.9675 - TP: 3262.3301 - TN: 5568.9800 - FP: 78.0200 - FN: 109.6700 - val_loss: 0.1921 - val_Accuracy: 0.9712 - val_Precision: 0.9746 - val_Recall: 0.9331 - val_TP: 750.2200 - val_TN: 1093.9600 - val_FP: 12.0400 - val_FN: 53.7800\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0756 - Accuracy: 0.9858 - Precision: 0.9672 - Recall: 0.9655 - TP: 3255.5100 - TN: 5567.7100 - FP: 79.2900 - FN: 116.4900 - val_loss: 0.2289 - val_Accuracy: 0.9696 - val_Precision: 0.9511 - val_Recall: 0.9475 - val_TP: 761.7500 - val_TN: 1074.4100 - val_FP: 31.5900 - val_FN: 42.2500\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2332 - Accuracy: 0.9849 - Precision: 0.9657 - Recall: 0.9637 - TP: 3249.5601 - TN: 5562.9600 - FP: 84.0400 - FN: 122.4400 - val_loss: 0.2431 - val_Accuracy: 0.9691 - val_Precision: 0.9530 - val_Recall: 0.9475 - val_TP: 761.7900 - val_TN: 1076.1200 - val_FP: 29.8800 - val_FN: 42.2100\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0709 - Accuracy: 0.9869 - Precision: 0.9687 - Recall: 0.9677 - TP: 3263.1799 - TN: 5573.0200 - FP: 73.9800 - FN: 108.8200 - val_loss: 0.1899 - val_Accuracy: 0.9728 - val_Precision: 0.9649 - val_Recall: 0.9437 - val_TP: 758.7000 - val_TN: 1086.0200 - val_FP: 19.9800 - val_FN: 45.3000\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.1091 - Accuracy: 0.9850 - Precision: 0.9670 - Recall: 0.9654 - TP: 3255.1799 - TN: 5567.2402 - FP: 79.7600 - FN: 116.8200 - val_loss: 0.1760 - val_Accuracy: 0.9723 - val_Precision: 0.9601 - val_Recall: 0.9500 - val_TP: 763.7800 - val_TN: 1081.7900 - val_FP: 24.2100 - val_FN: 40.2200\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0936 - Accuracy: 0.9863 - Precision: 0.9678 - Recall: 0.9662 - TP: 3257.9900 - TN: 5569.6899 - FP: 77.3100 - FN: 114.0100 - val_loss: 0.1705 - val_Accuracy: 0.9738 - val_Precision: 0.9581 - val_Recall: 0.9541 - val_TP: 767.1200 - val_TN: 1080.1300 - val_FP: 25.8700 - val_FN: 36.8800\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0783 - Accuracy: 0.9865 - Precision: 0.9678 - Recall: 0.9676 - TP: 3262.6599 - TN: 5569.8398 - FP: 77.1600 - FN: 109.3400 - val_loss: 0.1805 - val_Accuracy: 0.9707 - val_Precision: 0.9585 - val_Recall: 0.9494 - val_TP: 763.3100 - val_TN: 1080.5601 - val_FP: 25.4400 - val_FN: 40.6900\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1706 - Accuracy: 0.9865 - Precision: 0.9674 - Recall: 0.9657 - TP: 3256.3999 - TN: 5568.5498 - FP: 78.4500 - FN: 115.6000 - val_loss: 0.2078 - val_Accuracy: 0.9712 - val_Precision: 0.9603 - val_Recall: 0.9464 - val_TP: 760.9000 - val_TN: 1082.1600 - val_FP: 23.8400 - val_FN: 43.1000\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1177 - Accuracy: 0.9844 - Precision: 0.9668 - Recall: 0.9649 - TP: 3253.6399 - TN: 5566.5898 - FP: 80.4100 - FN: 118.3600 - val_loss: 0.1759 - val_Accuracy: 0.9743 - val_Precision: 0.9675 - val_Recall: 0.9457 - val_TP: 760.3700 - val_TN: 1088.1000 - val_FP: 17.9000 - val_FN: 43.6300\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0763 - Accuracy: 0.9860 - Precision: 0.9681 - Recall: 0.9663 - TP: 3258.4399 - TN: 5571.1401 - FP: 75.8600 - FN: 113.5600 - val_loss: 0.1706 - val_Accuracy: 0.9728 - val_Precision: 0.9554 - val_Recall: 0.9566 - val_TP: 769.0900 - val_TN: 1077.7300 - val_FP: 28.2700 - val_FN: 34.9100\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 7ms/step - loss: 0.0983 - Accuracy: 0.9843 - Precision: 0.9656 - Recall: 0.9643 - TP: 3251.4600 - TN: 5562.0000 - FP: 85.0000 - FN: 120.5400 - val_loss: 0.1706 - val_Accuracy: 0.9733 - val_Precision: 0.9664 - val_Recall: 0.9450 - val_TP: 759.7600 - val_TN: 1087.2200 - val_FP: 18.7800 - val_FN: 44.2400\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1520 - Accuracy: 0.9847 - Precision: 0.9649 - Recall: 0.9642 - TP: 3251.1799 - TN: 5559.8101 - FP: 87.1900 - FN: 120.8200 - val_loss: 0.2224 - val_Accuracy: 0.9675 - val_Precision: 0.9526 - val_Recall: 0.9453 - val_TP: 760.0000 - val_TN: 1075.7300 - val_FP: 30.2700 - val_FN: 44.0000\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0727 - Accuracy: 0.9875 - Precision: 0.9692 - Recall: 0.9671 - TP: 3261.1201 - TN: 5574.6699 - FP: 72.3300 - FN: 110.8800 - val_loss: 0.1644 - val_Accuracy: 0.9712 - val_Precision: 0.9597 - val_Recall: 0.9493 - val_TP: 763.2200 - val_TN: 1081.5601 - val_FP: 24.4400 - val_FN: 40.7800\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0612 - Accuracy: 0.9881 - Precision: 0.9694 - Recall: 0.9682 - TP: 3264.6899 - TN: 5575.1699 - FP: 71.8300 - FN: 107.3100 - val_loss: 0.1996 - val_Accuracy: 0.9712 - val_Precision: 0.9534 - val_Recall: 0.9525 - val_TP: 765.8200 - val_TN: 1076.2000 - val_FP: 29.8000 - val_FN: 38.1800\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1641 - Accuracy: 0.9864 - Precision: 0.9669 - Recall: 0.9646 - TP: 3252.7200 - TN: 5566.7300 - FP: 80.2700 - FN: 119.2800 - val_loss: 0.1683 - val_Accuracy: 0.9728 - val_Precision: 0.9429 - val_Recall: 0.9612 - val_TP: 772.8100 - val_TN: 1066.6200 - val_FP: 39.3800 - val_FN: 31.1900\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1567 - Accuracy: 0.9843 - Precision: 0.9652 - Recall: 0.9644 - TP: 3251.8101 - TN: 5561.0298 - FP: 85.9700 - FN: 120.1900 - val_loss: 0.1679 - val_Accuracy: 0.9733 - val_Precision: 0.9622 - val_Recall: 0.9500 - val_TP: 763.8400 - val_TN: 1083.5000 - val_FP: 22.5000 - val_FN: 40.1600\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0858 - Accuracy: 0.9864 - Precision: 0.9674 - Recall: 0.9667 - TP: 3259.6001 - TN: 5568.4102 - FP: 78.5900 - FN: 112.4000 - val_loss: 0.1960 - val_Accuracy: 0.9702 - val_Precision: 0.9502 - val_Recall: 0.9558 - val_TP: 768.4900 - val_TN: 1073.2800 - val_FP: 32.7200 - val_FN: 35.5100\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1266 - Accuracy: 0.9847 - Precision: 0.9662 - Recall: 0.9642 - TP: 3251.3799 - TN: 5564.2900 - FP: 82.7100 - FN: 120.6200 - val_loss: 0.1908 - val_Accuracy: 0.9728 - val_Precision: 0.9617 - val_Recall: 0.9481 - val_TP: 762.2900 - val_TN: 1083.2900 - val_FP: 22.7100 - val_FN: 41.7100\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1202 - Accuracy: 0.9843 - Precision: 0.9657 - Recall: 0.9641 - TP: 3250.7800 - TN: 5562.9502 - FP: 84.0500 - FN: 121.2200 - val_loss: 0.1589 - val_Accuracy: 0.9754 - val_Precision: 0.9592 - val_Recall: 0.9559 - val_TP: 768.5500 - val_TN: 1080.9600 - val_FP: 25.0400 - val_FN: 35.4500\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1132 - Accuracy: 0.9867 - Precision: 0.9674 - Recall: 0.9661 - TP: 3257.8501 - TN: 5568.4302 - FP: 78.5700 - FN: 114.1500 - val_loss: 0.1695 - val_Accuracy: 0.9738 - val_Precision: 0.9643 - val_Recall: 0.9481 - val_TP: 762.2800 - val_TN: 1085.3500 - val_FP: 20.6500 - val_FN: 41.7200\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1113 - Accuracy: 0.9860 - Precision: 0.9673 - Recall: 0.9663 - TP: 3258.4600 - TN: 5568.2998 - FP: 78.7000 - FN: 113.5400 - val_loss: 0.2098 - val_Accuracy: 0.9686 - val_Precision: 0.9529 - val_Recall: 0.9505 - val_TP: 764.1700 - val_TN: 1075.8199 - val_FP: 30.1800 - val_FN: 39.8300\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0865 - Accuracy: 0.9857 - Precision: 0.9677 - Recall: 0.9659 - TP: 3256.9800 - TN: 5569.6401 - FP: 77.3600 - FN: 115.0200 - val_loss: 0.1703 - val_Accuracy: 0.9712 - val_Precision: 0.9580 - val_Recall: 0.9538 - val_TP: 766.8700 - val_TN: 1080.0200 - val_FP: 25.9800 - val_FN: 37.1300\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1282 - Accuracy: 0.9857 - Precision: 0.9669 - Recall: 0.9662 - TP: 3257.9399 - TN: 5567.0200 - FP: 79.9800 - FN: 114.0600 - val_loss: 0.1834 - val_Accuracy: 0.9717 - val_Precision: 0.9610 - val_Recall: 0.9484 - val_TP: 762.5300 - val_TN: 1082.6600 - val_FP: 23.3400 - val_FN: 41.4700\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1191 - Accuracy: 0.9845 - Precision: 0.9659 - Recall: 0.9644 - TP: 3251.9399 - TN: 5563.3799 - FP: 83.6200 - FN: 120.0600 - val_loss: 0.1736 - val_Accuracy: 0.9733 - val_Precision: 0.9547 - val_Recall: 0.9555 - val_TP: 768.2500 - val_TN: 1077.0699 - val_FP: 28.9300 - val_FN: 35.7500\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0937 - Accuracy: 0.9855 - Precision: 0.9669 - Recall: 0.9663 - TP: 3258.2000 - TN: 5566.8398 - FP: 80.1600 - FN: 113.8000 - val_loss: 0.1744 - val_Accuracy: 0.9770 - val_Precision: 0.9683 - val_Recall: 0.9476 - val_TP: 761.8700 - val_TN: 1088.6300 - val_FP: 17.3700 - val_FN: 42.1300\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1018 - Accuracy: 0.9866 - Precision: 0.9677 - Recall: 0.9660 - TP: 3257.2400 - TN: 5569.5801 - FP: 77.4200 - FN: 114.7600 - val_loss: 0.1891 - val_Accuracy: 0.9717 - val_Precision: 0.9608 - val_Recall: 0.9485 - val_TP: 762.6200 - val_TN: 1082.4800 - val_FP: 23.5200 - val_FN: 41.3800\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0663 - Accuracy: 0.9870 - Precision: 0.9690 - Recall: 0.9675 - TP: 3262.3301 - TN: 5574.2002 - FP: 72.8000 - FN: 109.6700 - val_loss: 0.2191 - val_Accuracy: 0.9665 - val_Precision: 0.9387 - val_Recall: 0.9588 - val_TP: 770.8800 - val_TN: 1063.1899 - val_FP: 42.8100 - val_FN: 33.1200\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1297 - Accuracy: 0.9853 - Precision: 0.9665 - Recall: 0.9659 - TP: 3256.9700 - TN: 5565.7300 - FP: 81.2700 - FN: 115.0300 - val_loss: 0.2021 - val_Accuracy: 0.9728 - val_Precision: 0.9629 - val_Recall: 0.9471 - val_TP: 761.4600 - val_TN: 1084.2900 - val_FP: 21.7100 - val_FN: 42.5400\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0795 - Accuracy: 0.9874 - Precision: 0.9680 - Recall: 0.9663 - TP: 3258.2600 - TN: 5570.7002 - FP: 76.3000 - FN: 113.7400 - val_loss: 0.1799 - val_Accuracy: 0.9712 - val_Precision: 0.9566 - val_Recall: 0.9517 - val_TP: 765.1800 - val_TN: 1078.8600 - val_FP: 27.1400 - val_FN: 38.8200\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1499 - Accuracy: 0.9863 - Precision: 0.9672 - Recall: 0.9659 - TP: 3256.9399 - TN: 5567.8999 - FP: 79.1000 - FN: 115.0600 - val_loss: 0.2031 - val_Accuracy: 0.9702 - val_Precision: 0.9512 - val_Recall: 0.9547 - val_TP: 767.5700 - val_TN: 1074.3300 - val_FP: 31.6700 - val_FN: 36.4300\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1589 - Accuracy: 0.9866 - Precision: 0.9674 - Recall: 0.9653 - TP: 3255.1399 - TN: 5568.7402 - FP: 78.2600 - FN: 116.8600 - val_loss: 0.2160 - val_Accuracy: 0.9712 - val_Precision: 0.9512 - val_Recall: 0.9530 - val_TP: 766.2500 - val_TN: 1074.2300 - val_FP: 31.7700 - val_FN: 37.7500\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1056 - Accuracy: 0.9876 - Precision: 0.9678 - Recall: 0.9683 - TP: 3265.1001 - TN: 5570.0898 - FP: 76.9100 - FN: 106.9000 - val_loss: 0.1892 - val_Accuracy: 0.9717 - val_Precision: 0.9648 - val_Recall: 0.9445 - val_TP: 759.3700 - val_TN: 1085.9100 - val_FP: 20.0900 - val_FN: 44.6300\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1128 - Accuracy: 0.9850 - Precision: 0.9663 - Recall: 0.9653 - TP: 3254.8899 - TN: 5564.9902 - FP: 82.0100 - FN: 117.1100 - val_loss: 0.2294 - val_Accuracy: 0.9686 - val_Precision: 0.9584 - val_Recall: 0.9432 - val_TP: 758.3300 - val_TN: 1080.7200 - val_FP: 25.2800 - val_FN: 45.6700\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1963 - Accuracy: 0.9835 - Precision: 0.9650 - Recall: 0.9627 - TP: 3246.3000 - TN: 5560.7700 - FP: 86.2300 - FN: 125.7000 - val_loss: 0.2157 - val_Accuracy: 0.9707 - val_Precision: 0.9503 - val_Recall: 0.9536 - val_TP: 766.7000 - val_TN: 1073.5500 - val_FP: 32.4500 - val_FN: 37.3000\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0749 - Accuracy: 0.9872 - Precision: 0.9685 - Recall: 0.9682 - TP: 3264.8101 - TN: 5572.5000 - FP: 74.5000 - FN: 107.1900 - val_loss: 0.2053 - val_Accuracy: 0.9712 - val_Precision: 0.9620 - val_Recall: 0.9460 - val_TP: 760.5900 - val_TN: 1083.6100 - val_FP: 22.3900 - val_FN: 43.4100\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0828 - Accuracy: 0.9866 - Precision: 0.9693 - Recall: 0.9676 - TP: 3262.7300 - TN: 5575.2002 - FP: 71.8000 - FN: 109.2700 - val_loss: 0.1891 - val_Accuracy: 0.9707 - val_Precision: 0.9424 - val_Recall: 0.9599 - val_TP: 771.7400 - val_TN: 1066.3000 - val_FP: 39.7000 - val_FN: 32.2600\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0903 - Accuracy: 0.9867 - Precision: 0.9677 - Recall: 0.9670 - TP: 3260.6799 - TN: 5569.6299 - FP: 77.3700 - FN: 111.3200 - val_loss: 0.1937 - val_Accuracy: 0.9712 - val_Precision: 0.9542 - val_Recall: 0.9527 - val_TP: 765.9400 - val_TN: 1076.9301 - val_FP: 29.0700 - val_FN: 38.0600\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0750 - Accuracy: 0.9864 - Precision: 0.9683 - Recall: 0.9664 - TP: 3258.5701 - TN: 5571.6602 - FP: 75.3400 - FN: 113.4300 - val_loss: 0.1847 - val_Accuracy: 0.9728 - val_Precision: 0.9515 - val_Recall: 0.9574 - val_TP: 769.7500 - val_TN: 1074.4100 - val_FP: 31.5900 - val_FN: 34.2500\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1176 - Accuracy: 0.9864 - Precision: 0.9685 - Recall: 0.9673 - TP: 3261.7700 - TN: 5572.7402 - FP: 74.2600 - FN: 110.2300 - val_loss: 0.2307 - val_Accuracy: 0.9681 - val_Precision: 0.9490 - val_Recall: 0.9529 - val_TP: 766.1200 - val_TN: 1072.5200 - val_FP: 33.4800 - val_FN: 37.8800\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 8ms/step - loss: 0.1278 - Accuracy: 0.9869 - Precision: 0.9671 - Recall: 0.9666 - TP: 3259.2700 - TN: 5567.4302 - FP: 79.5700 - FN: 112.7300 - val_loss: 0.1969 - val_Accuracy: 0.9712 - val_Precision: 0.9668 - val_Recall: 0.9397 - val_TP: 755.5000 - val_TN: 1087.6300 - val_FP: 18.3700 - val_FN: 48.5000\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1158 - Accuracy: 0.9857 - Precision: 0.9662 - Recall: 0.9643 - TP: 3251.6899 - TN: 5564.6602 - FP: 82.3400 - FN: 120.3100 - val_loss: 0.2281 - val_Accuracy: 0.9707 - val_Precision: 0.9572 - val_Recall: 0.9467 - val_TP: 761.1400 - val_TN: 1079.5601 - val_FP: 26.4400 - val_FN: 42.8600\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1784 - Accuracy: 0.9853 - Precision: 0.9671 - Recall: 0.9652 - TP: 3254.5500 - TN: 5567.7900 - FP: 79.2100 - FN: 117.4500 - val_loss: 0.1838 - val_Accuracy: 0.9723 - val_Precision: 0.9554 - val_Recall: 0.9545 - val_TP: 767.4100 - val_TN: 1077.7400 - val_FP: 28.2600 - val_FN: 36.5900\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1009 - Accuracy: 0.9864 - Precision: 0.9686 - Recall: 0.9674 - TP: 3262.1201 - TN: 5572.6802 - FP: 74.3200 - FN: 109.8800 - val_loss: 0.2124 - val_Accuracy: 0.9686 - val_Precision: 0.9380 - val_Recall: 0.9618 - val_TP: 773.3100 - val_TN: 1062.4500 - val_FP: 43.5500 - val_FN: 30.6900\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1024 - Accuracy: 0.9856 - Precision: 0.9669 - Recall: 0.9661 - TP: 3257.5400 - TN: 5566.8198 - FP: 80.1800 - FN: 114.4600 - val_loss: 0.1736 - val_Accuracy: 0.9733 - val_Precision: 0.9635 - val_Recall: 0.9484 - val_TP: 762.5100 - val_TN: 1084.7100 - val_FP: 21.2900 - val_FN: 41.4900\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1053 - Accuracy: 0.9853 - Precision: 0.9674 - Recall: 0.9656 - TP: 3255.8701 - TN: 5568.7402 - FP: 78.2600 - FN: 116.1300 - val_loss: 0.1782 - val_Accuracy: 0.9712 - val_Precision: 0.9519 - val_Recall: 0.9555 - val_TP: 768.2400 - val_TN: 1074.7200 - val_FP: 31.2800 - val_FN: 35.7600\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1603 - Accuracy: 0.9838 - Precision: 0.9649 - Recall: 0.9635 - TP: 3248.8301 - TN: 5559.8398 - FP: 87.1600 - FN: 123.1700 - val_loss: 0.1843 - val_Accuracy: 0.9717 - val_Precision: 0.9593 - val_Recall: 0.9497 - val_TP: 763.5300 - val_TN: 1081.2800 - val_FP: 24.7200 - val_FN: 40.4700\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0796 - Accuracy: 0.9865 - Precision: 0.9676 - Recall: 0.9673 - TP: 3261.7100 - TN: 5569.4399 - FP: 77.5600 - FN: 110.2900 - val_loss: 0.1794 - val_Accuracy: 0.9738 - val_Precision: 0.9688 - val_Recall: 0.9442 - val_TP: 759.1100 - val_TN: 1089.1801 - val_FP: 16.8200 - val_FN: 44.8900\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1094 - Accuracy: 0.9867 - Precision: 0.9673 - Recall: 0.9662 - TP: 3258.1399 - TN: 5568.0698 - FP: 78.9300 - FN: 113.8600 - val_loss: 0.1955 - val_Accuracy: 0.9702 - val_Precision: 0.9720 - val_Recall: 0.9368 - val_TP: 753.1900 - val_TN: 1091.8700 - val_FP: 14.1300 - val_FN: 50.8100\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0614 - Accuracy: 0.9880 - Precision: 0.9697 - Recall: 0.9677 - TP: 3262.9800 - TN: 5576.2998 - FP: 70.7000 - FN: 109.0200 - val_loss: 0.2400 - val_Accuracy: 0.9660 - val_Precision: 0.9459 - val_Recall: 0.9534 - val_TP: 766.5500 - val_TN: 1069.8800 - val_FP: 36.1200 - val_FN: 37.4500\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1567 - Accuracy: 0.9849 - Precision: 0.9664 - Recall: 0.9646 - TP: 3252.5901 - TN: 5565.2002 - FP: 81.8000 - FN: 119.4100 - val_loss: 0.1813 - val_Accuracy: 0.9712 - val_Precision: 0.9490 - val_Recall: 0.9588 - val_TP: 770.8400 - val_TN: 1072.1700 - val_FP: 33.8300 - val_FN: 33.1600\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1724 - Accuracy: 0.9855 - Precision: 0.9661 - Recall: 0.9659 - TP: 3256.9500 - TN: 5564.3198 - FP: 82.6800 - FN: 115.0500 - val_loss: 0.1851 - val_Accuracy: 0.9712 - val_Precision: 0.9488 - val_Recall: 0.9576 - val_TP: 769.9400 - val_TN: 1071.9900 - val_FP: 34.0100 - val_FN: 34.0600\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1358 - Accuracy: 0.9840 - Precision: 0.9657 - Recall: 0.9639 - TP: 3250.4299 - TN: 5562.9102 - FP: 84.0900 - FN: 121.5700 - val_loss: 0.1888 - val_Accuracy: 0.9712 - val_Precision: 0.9565 - val_Recall: 0.9507 - val_TP: 764.3600 - val_TN: 1078.8101 - val_FP: 27.1900 - val_FN: 39.6400\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0729 - Accuracy: 0.9858 - Precision: 0.9678 - Recall: 0.9674 - TP: 3261.9199 - TN: 5569.7202 - FP: 77.2800 - FN: 110.0800 - val_loss: 0.1821 - val_Accuracy: 0.9728 - val_Precision: 0.9589 - val_Recall: 0.9527 - val_TP: 765.9500 - val_TN: 1080.8101 - val_FP: 25.1900 - val_FN: 38.0500\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1473 - Accuracy: 0.9859 - Precision: 0.9677 - Recall: 0.9660 - TP: 3257.3601 - TN: 5569.9399 - FP: 77.0600 - FN: 114.6400 - val_loss: 0.1983 - val_Accuracy: 0.9691 - val_Precision: 0.9403 - val_Recall: 0.9588 - val_TP: 770.8900 - val_TN: 1064.4100 - val_FP: 41.5900 - val_FN: 33.1100\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.1119 - Accuracy: 0.9850 - Precision: 0.9661 - Recall: 0.9659 - TP: 3256.8999 - TN: 5564.3301 - FP: 82.6700 - FN: 115.1000 - val_loss: 0.1909 - val_Accuracy: 0.9749 - val_Precision: 0.9643 - val_Recall: 0.9473 - val_TP: 761.6000 - val_TN: 1085.4100 - val_FP: 20.5900 - val_FN: 42.4000\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1267 - Accuracy: 0.9850 - Precision: 0.9664 - Recall: 0.9652 - TP: 3254.7000 - TN: 5565.2998 - FP: 81.7000 - FN: 117.3000 - val_loss: 0.2478 - val_Accuracy: 0.9654 - val_Precision: 0.9429 - val_Recall: 0.9551 - val_TP: 767.8900 - val_TN: 1067.2200 - val_FP: 38.7800 - val_FN: 36.1100\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1512 - Accuracy: 0.9858 - Precision: 0.9676 - Recall: 0.9657 - TP: 3256.3999 - TN: 5569.8501 - FP: 77.1500 - FN: 115.6000 - val_loss: 0.1952 - val_Accuracy: 0.9728 - val_Precision: 0.9589 - val_Recall: 0.9502 - val_TP: 763.9900 - val_TN: 1080.8800 - val_FP: 25.1200 - val_FN: 40.0100\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1064 - Accuracy: 0.9848 - Precision: 0.9663 - Recall: 0.9665 - TP: 3259.1399 - TN: 5564.9399 - FP: 82.0600 - FN: 112.8600 - val_loss: 0.1965 - val_Accuracy: 0.9738 - val_Precision: 0.9720 - val_Recall: 0.9405 - val_TP: 756.1700 - val_TN: 1091.7700 - val_FP: 14.2300 - val_FN: 47.8300\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0721 - Accuracy: 0.9863 - Precision: 0.9682 - Recall: 0.9661 - TP: 3257.8501 - TN: 5571.5898 - FP: 75.4100 - FN: 114.1500 - val_loss: 0.1918 - val_Accuracy: 0.9738 - val_Precision: 0.9600 - val_Recall: 0.9517 - val_TP: 765.1400 - val_TN: 1081.7900 - val_FP: 24.2100 - val_FN: 38.8600\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1318 - Accuracy: 0.9859 - Precision: 0.9670 - Recall: 0.9663 - TP: 3258.5300 - TN: 5567.5200 - FP: 79.4800 - FN: 113.4700 - val_loss: 0.1853 - val_Accuracy: 0.9733 - val_Precision: 0.9601 - val_Recall: 0.9524 - val_TP: 765.7100 - val_TN: 1081.8600 - val_FP: 24.1400 - val_FN: 38.2900\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0922 - Accuracy: 0.9866 - Precision: 0.9683 - Recall: 0.9661 - TP: 3257.8401 - TN: 5571.8198 - FP: 75.1800 - FN: 114.1600 - val_loss: 0.1890 - val_Accuracy: 0.9702 - val_Precision: 0.9478 - val_Recall: 0.9599 - val_TP: 771.7300 - val_TN: 1071.1500 - val_FP: 34.8500 - val_FN: 32.2700\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.1471 - Accuracy: 0.9876 - Precision: 0.9681 - Recall: 0.9674 - TP: 3262.0100 - TN: 5571.1499 - FP: 75.8500 - FN: 109.9900 - val_loss: 0.2075 - val_Accuracy: 0.9717 - val_Precision: 0.9485 - val_Recall: 0.9564 - val_TP: 768.9600 - val_TN: 1071.9399 - val_FP: 34.0600 - val_FN: 35.0400\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2170 - Accuracy: 0.9843 - Precision: 0.9656 - Recall: 0.9642 - TP: 3251.4199 - TN: 5563.0000 - FP: 84.0000 - FN: 120.5800 - val_loss: 0.2077 - val_Accuracy: 0.9686 - val_Precision: 0.9477 - val_Recall: 0.9538 - val_TP: 766.8500 - val_TN: 1071.1801 - val_FP: 34.8200 - val_FN: 37.1500\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0830 - Accuracy: 0.9859 - Precision: 0.9664 - Recall: 0.9672 - TP: 3261.4800 - TN: 5565.5000 - FP: 81.5000 - FN: 110.5200 - val_loss: 0.2745 - val_Accuracy: 0.9649 - val_Precision: 0.9496 - val_Recall: 0.9452 - val_TP: 759.9500 - val_TN: 1073.3900 - val_FP: 32.6100 - val_FN: 44.0500\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 8ms/step - loss: 0.1432 - Accuracy: 0.9849 - Precision: 0.9662 - Recall: 0.9646 - TP: 3252.6101 - TN: 5564.3901 - FP: 82.6100 - FN: 119.3900 - val_loss: 0.1799 - val_Accuracy: 0.9743 - val_Precision: 0.9619 - val_Recall: 0.9516 - val_TP: 765.1100 - val_TN: 1083.3900 - val_FP: 22.6100 - val_FN: 38.8900\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1615 - Accuracy: 0.9848 - Precision: 0.9661 - Recall: 0.9651 - TP: 3254.3501 - TN: 5564.3101 - FP: 82.6900 - FN: 117.6500 - val_loss: 0.1836 - val_Accuracy: 0.9749 - val_Precision: 0.9665 - val_Recall: 0.9449 - val_TP: 759.7100 - val_TN: 1087.2700 - val_FP: 18.7300 - val_FN: 44.2900\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1178 - Accuracy: 0.9851 - Precision: 0.9662 - Recall: 0.9650 - TP: 3254.0901 - TN: 5564.5498 - FP: 82.4500 - FN: 117.9100 - val_loss: 0.1900 - val_Accuracy: 0.9743 - val_Precision: 0.9724 - val_Recall: 0.9416 - val_TP: 757.0800 - val_TN: 1092.1300 - val_FP: 13.8700 - val_FN: 46.9200\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1026 - Accuracy: 0.9861 - Precision: 0.9678 - Recall: 0.9669 - TP: 3260.5200 - TN: 5570.0000 - FP: 77.0000 - FN: 111.4800 - val_loss: 0.2417 - val_Accuracy: 0.9686 - val_Precision: 0.9454 - val_Recall: 0.9518 - val_TP: 765.2600 - val_TN: 1069.3900 - val_FP: 36.6100 - val_FN: 38.7400\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0792 - Accuracy: 0.9859 - Precision: 0.9670 - Recall: 0.9656 - TP: 3255.8799 - TN: 5567.5098 - FP: 79.4900 - FN: 116.1200 - val_loss: 0.1760 - val_Accuracy: 0.9728 - val_Precision: 0.9585 - val_Recall: 0.9524 - val_TP: 765.7600 - val_TN: 1080.5000 - val_FP: 25.5000 - val_FN: 38.2400\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1350 - Accuracy: 0.9870 - Precision: 0.9688 - Recall: 0.9677 - TP: 3262.9600 - TN: 5573.6499 - FP: 73.3500 - FN: 109.0400 - val_loss: 0.1923 - val_Accuracy: 0.9723 - val_Precision: 0.9594 - val_Recall: 0.9492 - val_TP: 763.1200 - val_TN: 1081.3800 - val_FP: 24.6200 - val_FN: 40.8800\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2205 - Accuracy: 0.9851 - Precision: 0.9664 - Recall: 0.9657 - TP: 3256.3899 - TN: 5565.3901 - FP: 81.6100 - FN: 115.6100 - val_loss: 0.2127 - val_Accuracy: 0.9712 - val_Precision: 0.9606 - val_Recall: 0.9470 - val_TP: 761.3600 - val_TN: 1082.4000 - val_FP: 23.6000 - val_FN: 42.6400\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0986 - Accuracy: 0.9859 - Precision: 0.9683 - Recall: 0.9663 - TP: 3258.3601 - TN: 5571.8901 - FP: 75.1100 - FN: 113.6400 - val_loss: 0.1953 - val_Accuracy: 0.9712 - val_Precision: 0.9539 - val_Recall: 0.9522 - val_TP: 765.5400 - val_TN: 1076.5400 - val_FP: 29.4600 - val_FN: 38.4600\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2171 - Accuracy: 0.9863 - Precision: 0.9674 - Recall: 0.9669 - TP: 3260.2200 - TN: 5568.5400 - FP: 78.4600 - FN: 111.7800 - val_loss: 0.2005 - val_Accuracy: 0.9717 - val_Precision: 0.9601 - val_Recall: 0.9486 - val_TP: 762.7100 - val_TN: 1081.9500 - val_FP: 24.0500 - val_FN: 41.2900\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1232 - Accuracy: 0.9851 - Precision: 0.9668 - Recall: 0.9649 - TP: 3253.7100 - TN: 5566.8398 - FP: 80.1600 - FN: 118.2900 - val_loss: 0.2004 - val_Accuracy: 0.9707 - val_Precision: 0.9482 - val_Recall: 0.9552 - val_TP: 768.0000 - val_TN: 1071.6300 - val_FP: 34.3700 - val_FN: 36.0000\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1031 - Accuracy: 0.9840 - Precision: 0.9657 - Recall: 0.9659 - TP: 3256.9500 - TN: 5563.0601 - FP: 83.9400 - FN: 115.0500 - val_loss: 0.1920 - val_Accuracy: 0.9712 - val_Precision: 0.9668 - val_Recall: 0.9421 - val_TP: 757.4600 - val_TN: 1087.5699 - val_FP: 18.4300 - val_FN: 46.5400\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1993 - Accuracy: 0.9845 - Precision: 0.9668 - Recall: 0.9652 - TP: 3254.5500 - TN: 5566.6899 - FP: 80.3100 - FN: 117.4500 - val_loss: 0.1897 - val_Accuracy: 0.9749 - val_Precision: 0.9680 - val_Recall: 0.9468 - val_TP: 761.1900 - val_TN: 1088.5000 - val_FP: 17.5000 - val_FN: 42.8100\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1388 - Accuracy: 0.9857 - Precision: 0.9673 - Recall: 0.9665 - TP: 3259.0801 - TN: 5568.3901 - FP: 78.6100 - FN: 112.9200 - val_loss: 0.2207 - val_Accuracy: 0.9723 - val_Precision: 0.9590 - val_Recall: 0.9502 - val_TP: 763.9400 - val_TN: 1081.0601 - val_FP: 24.9400 - val_FN: 40.0600\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1576 - Accuracy: 0.9854 - Precision: 0.9667 - Recall: 0.9656 - TP: 3256.1499 - TN: 5566.7202 - FP: 80.2800 - FN: 115.8500 - val_loss: 0.1897 - val_Accuracy: 0.9728 - val_Precision: 0.9624 - val_Recall: 0.9506 - val_TP: 764.3200 - val_TN: 1083.7700 - val_FP: 22.2300 - val_FN: 39.6800\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1161 - Accuracy: 0.9857 - Precision: 0.9677 - Recall: 0.9657 - TP: 3256.4800 - TN: 5570.0000 - FP: 77.0000 - FN: 115.5200 - val_loss: 0.1943 - val_Accuracy: 0.9712 - val_Precision: 0.9470 - val_Recall: 0.9591 - val_TP: 771.1000 - val_TN: 1070.5200 - val_FP: 35.4800 - val_FN: 32.9000\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1106 - Accuracy: 0.9866 - Precision: 0.9686 - Recall: 0.9673 - TP: 3261.8999 - TN: 5573.1001 - FP: 73.9000 - FN: 110.1000 - val_loss: 0.1878 - val_Accuracy: 0.9712 - val_Precision: 0.9509 - val_Recall: 0.9597 - val_TP: 771.6300 - val_TN: 1073.8500 - val_FP: 32.1500 - val_FN: 32.3700\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1064 - Accuracy: 0.9861 - Precision: 0.9681 - Recall: 0.9675 - TP: 3262.2500 - TN: 5571.4102 - FP: 75.5900 - FN: 109.7500 - val_loss: 0.1856 - val_Accuracy: 0.9733 - val_Precision: 0.9636 - val_Recall: 0.9492 - val_TP: 763.1500 - val_TN: 1084.7700 - val_FP: 21.2300 - val_FN: 40.8500\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1172 - Accuracy: 0.9864 - Precision: 0.9675 - Recall: 0.9664 - TP: 3258.5601 - TN: 5569.2202 - FP: 77.7800 - FN: 113.4400 - val_loss: 0.1863 - val_Accuracy: 0.9717 - val_Precision: 0.9552 - val_Recall: 0.9552 - val_TP: 767.9800 - val_TN: 1077.6200 - val_FP: 28.3800 - val_FN: 36.0200\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1105 - Accuracy: 0.9863 - Precision: 0.9690 - Recall: 0.9673 - TP: 3261.7300 - TN: 5574.4702 - FP: 72.5300 - FN: 110.2700 - val_loss: 0.1993 - val_Accuracy: 0.9733 - val_Precision: 0.9641 - val_Recall: 0.9460 - val_TP: 760.5500 - val_TN: 1085.3700 - val_FP: 20.6300 - val_FN: 43.4500\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0694 - Accuracy: 0.9864 - Precision: 0.9688 - Recall: 0.9681 - TP: 3264.2800 - TN: 5573.4902 - FP: 73.5100 - FN: 107.7200 - val_loss: 0.2853 - val_Accuracy: 0.9660 - val_Precision: 0.9466 - val_Recall: 0.9495 - val_TP: 763.4100 - val_TN: 1070.6300 - val_FP: 35.3700 - val_FN: 40.5900\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1042 - Accuracy: 0.9860 - Precision: 0.9671 - Recall: 0.9670 - TP: 3260.7600 - TN: 5567.8198 - FP: 79.1800 - FN: 111.2400 - val_loss: 0.2430 - val_Accuracy: 0.9696 - val_Precision: 0.9683 - val_Recall: 0.9379 - val_TP: 754.0700 - val_TN: 1088.9700 - val_FP: 17.0300 - val_FN: 49.9300\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1334 - Accuracy: 0.9864 - Precision: 0.9686 - Recall: 0.9663 - TP: 3258.4700 - TN: 5573.1602 - FP: 73.8400 - FN: 113.5300 - val_loss: 0.2292 - val_Accuracy: 0.9675 - val_Precision: 0.9356 - val_Recall: 0.9629 - val_TP: 774.1400 - val_TN: 1060.3400 - val_FP: 45.6600 - val_FN: 29.8600\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1022 - Accuracy: 0.9858 - Precision: 0.9675 - Recall: 0.9669 - TP: 3260.5400 - TN: 5569.0698 - FP: 77.9300 - FN: 111.4600 - val_loss: 0.2180 - val_Accuracy: 0.9717 - val_Precision: 0.9566 - val_Recall: 0.9526 - val_TP: 765.8900 - val_TN: 1078.9100 - val_FP: 27.0900 - val_FN: 38.1100\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1099 - Accuracy: 0.9871 - Precision: 0.9683 - Recall: 0.9671 - TP: 3261.0801 - TN: 5571.8599 - FP: 75.1400 - FN: 110.9200 - val_loss: 0.2323 - val_Accuracy: 0.9691 - val_Precision: 0.9496 - val_Recall: 0.9521 - val_TP: 765.4700 - val_TN: 1073.0400 - val_FP: 32.9600 - val_FN: 38.5300\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0945 - Accuracy: 0.9861 - Precision: 0.9679 - Recall: 0.9669 - TP: 3260.3701 - TN: 5570.8101 - FP: 76.1900 - FN: 111.6300 - val_loss: 0.1900 - val_Accuracy: 0.9723 - val_Precision: 0.9571 - val_Recall: 0.9552 - val_TP: 768.0100 - val_TN: 1079.2700 - val_FP: 26.7300 - val_FN: 35.9900\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 7ms/step - loss: 0.1021 - Accuracy: 0.9854 - Precision: 0.9680 - Recall: 0.9663 - TP: 3258.4600 - TN: 5570.9702 - FP: 76.0300 - FN: 113.5400 - val_loss: 0.1841 - val_Accuracy: 0.9728 - val_Precision: 0.9594 - val_Recall: 0.9516 - val_TP: 765.1100 - val_TN: 1081.2800 - val_FP: 24.7200 - val_FN: 38.8900\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0804 - Accuracy: 0.9865 - Precision: 0.9678 - Recall: 0.9671 - TP: 3261.1001 - TN: 5570.2500 - FP: 76.7500 - FN: 110.9000 - val_loss: 0.2029 - val_Accuracy: 0.9686 - val_Precision: 0.9442 - val_Recall: 0.9578 - val_TP: 770.0500 - val_TN: 1068.0200 - val_FP: 37.9800 - val_FN: 33.9500\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1092 - Accuracy: 0.9856 - Precision: 0.9668 - Recall: 0.9665 - TP: 3258.9900 - TN: 5566.6802 - FP: 80.3200 - FN: 113.0100 - val_loss: 0.2085 - val_Accuracy: 0.9691 - val_Precision: 0.9721 - val_Recall: 0.9319 - val_TP: 749.2600 - val_TN: 1092.0200 - val_FP: 13.9800 - val_FN: 54.7400\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0976 - Accuracy: 0.9860 - Precision: 0.9688 - Recall: 0.9672 - TP: 3261.5200 - TN: 5573.4600 - FP: 73.5400 - FN: 110.4800 - val_loss: 0.1825 - val_Accuracy: 0.9733 - val_Precision: 0.9619 - val_Recall: 0.9499 - val_TP: 763.7300 - val_TN: 1083.3900 - val_FP: 22.6100 - val_FN: 40.2700\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2723 - Accuracy: 0.9833 - Precision: 0.9653 - Recall: 0.9634 - TP: 3248.7400 - TN: 5561.7300 - FP: 85.2700 - FN: 123.2600 - val_loss: 0.2002 - val_Accuracy: 0.9686 - val_Precision: 0.9390 - val_Recall: 0.9616 - val_TP: 773.1600 - val_TN: 1063.3500 - val_FP: 42.6500 - val_FN: 30.8400\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1077 - Accuracy: 0.9863 - Precision: 0.9675 - Recall: 0.9667 - TP: 3259.7800 - TN: 5568.9502 - FP: 78.0500 - FN: 112.2200 - val_loss: 0.1877 - val_Accuracy: 0.9712 - val_Precision: 0.9571 - val_Recall: 0.9526 - val_TP: 765.8800 - val_TN: 1079.3101 - val_FP: 26.6900 - val_FN: 38.1200\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1297 - Accuracy: 0.9860 - Precision: 0.9677 - Recall: 0.9668 - TP: 3260.2100 - TN: 5569.9702 - FP: 77.0300 - FN: 111.7900 - val_loss: 0.1871 - val_Accuracy: 0.9728 - val_Precision: 0.9614 - val_Recall: 0.9521 - val_TP: 765.5200 - val_TN: 1082.9399 - val_FP: 23.0600 - val_FN: 38.4800\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1544 - Accuracy: 0.9844 - Precision: 0.9660 - Recall: 0.9654 - TP: 3255.4600 - TN: 5564.1401 - FP: 82.8600 - FN: 116.5400 - val_loss: 0.1960 - val_Accuracy: 0.9733 - val_Precision: 0.9628 - val_Recall: 0.9487 - val_TP: 762.7700 - val_TN: 1084.1700 - val_FP: 21.8300 - val_FN: 41.2300\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0921 - Accuracy: 0.9863 - Precision: 0.9683 - Recall: 0.9665 - TP: 3259.1499 - TN: 5571.6802 - FP: 75.3200 - FN: 112.8500 - val_loss: 0.2323 - val_Accuracy: 0.9712 - val_Precision: 0.9557 - val_Recall: 0.9519 - val_TP: 765.3400 - val_TN: 1078.2400 - val_FP: 27.7600 - val_FN: 38.6600\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0881 - Accuracy: 0.9865 - Precision: 0.9678 - Recall: 0.9673 - TP: 3261.8000 - TN: 5570.2598 - FP: 76.7400 - FN: 110.2000 - val_loss: 0.1845 - val_Accuracy: 0.9717 - val_Precision: 0.9553 - val_Recall: 0.9553 - val_TP: 768.0900 - val_TN: 1077.7000 - val_FP: 28.3000 - val_FN: 35.9100\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1223 - Accuracy: 0.9868 - Precision: 0.9682 - Recall: 0.9665 - TP: 3258.9399 - TN: 5571.6001 - FP: 75.4000 - FN: 113.0600 - val_loss: 0.2462 - val_Accuracy: 0.9691 - val_Precision: 0.9498 - val_Recall: 0.9537 - val_TP: 766.8100 - val_TN: 1073.1801 - val_FP: 32.8200 - val_FN: 37.1900\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0610 - Accuracy: 0.9886 - Precision: 0.9705 - Recall: 0.9694 - TP: 3268.7800 - TN: 5579.2402 - FP: 67.7600 - FN: 103.2200 - val_loss: 0.2185 - val_Accuracy: 0.9707 - val_Precision: 0.9558 - val_Recall: 0.9511 - val_TP: 764.7200 - val_TN: 1078.2800 - val_FP: 27.7200 - val_FN: 39.2800\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0905 - Accuracy: 0.9853 - Precision: 0.9671 - Recall: 0.9658 - TP: 3256.5300 - TN: 5568.1001 - FP: 78.9000 - FN: 115.4700 - val_loss: 0.7094 - val_Accuracy: 0.9335 - val_Precision: 0.8747 - val_Recall: 0.9563 - val_TP: 768.8300 - val_TN: 1004.1700 - val_FP: 101.8300 - val_FN: 35.1700\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1260 - Accuracy: 0.9856 - Precision: 0.9672 - Recall: 0.9660 - TP: 3257.4299 - TN: 5568.1802 - FP: 78.8200 - FN: 114.5700 - val_loss: 0.2036 - val_Accuracy: 0.9723 - val_Precision: 0.9665 - val_Recall: 0.9426 - val_TP: 757.8200 - val_TN: 1087.3400 - val_FP: 18.6600 - val_FN: 46.1800\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0562 - Accuracy: 0.9874 - Precision: 0.9696 - Recall: 0.9686 - TP: 3266.2600 - TN: 5576.3301 - FP: 70.6700 - FN: 105.7400 - val_loss: 0.2155 - val_Accuracy: 0.9702 - val_Precision: 0.9556 - val_Recall: 0.9513 - val_TP: 764.8800 - val_TN: 1078.2000 - val_FP: 27.8000 - val_FN: 39.1200\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2176 - Accuracy: 0.9850 - Precision: 0.9664 - Recall: 0.9654 - TP: 3255.4800 - TN: 5565.7598 - FP: 81.2400 - FN: 116.5200 - val_loss: 0.1915 - val_Accuracy: 0.9728 - val_Precision: 0.9580 - val_Recall: 0.9505 - val_TP: 764.1800 - val_TN: 1080.1000 - val_FP: 25.9000 - val_FN: 39.8200\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1163 - Accuracy: 0.9861 - Precision: 0.9686 - Recall: 0.9670 - TP: 3260.6699 - TN: 5573.2002 - FP: 73.8000 - FN: 111.3300 - val_loss: 0.1890 - val_Accuracy: 0.9717 - val_Precision: 0.9656 - val_Recall: 0.9444 - val_TP: 759.3100 - val_TN: 1086.5800 - val_FP: 19.4200 - val_FN: 44.6900\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1789 - Accuracy: 0.9850 - Precision: 0.9672 - Recall: 0.9670 - TP: 3260.8401 - TN: 5568.4399 - FP: 78.5600 - FN: 111.1600 - val_loss: 0.2226 - val_Accuracy: 0.9723 - val_Precision: 0.9508 - val_Recall: 0.9558 - val_TP: 768.5000 - val_TN: 1073.8800 - val_FP: 32.1200 - val_FN: 35.5000\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1826 - Accuracy: 0.9869 - Precision: 0.9695 - Recall: 0.9677 - TP: 3263.1001 - TN: 5576.2300 - FP: 70.7700 - FN: 108.9000 - val_loss: 0.2537 - val_Accuracy: 0.9686 - val_Precision: 0.9495 - val_Recall: 0.9523 - val_TP: 765.6300 - val_TN: 1072.9500 - val_FP: 33.0500 - val_FN: 38.3700\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1078 - Accuracy: 0.9868 - Precision: 0.9684 - Recall: 0.9684 - TP: 3265.4399 - TN: 5572.0698 - FP: 74.9300 - FN: 106.5600 - val_loss: 0.4954 - val_Accuracy: 0.9366 - val_Precision: 0.8845 - val_Recall: 0.9489 - val_TP: 762.9500 - val_TN: 1014.6100 - val_FP: 91.3900 - val_FN: 41.0500\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1311 - Accuracy: 0.9866 - Precision: 0.9683 - Recall: 0.9666 - TP: 3259.2300 - TN: 5572.0601 - FP: 74.9400 - FN: 112.7700 - val_loss: 0.2301 - val_Accuracy: 0.9707 - val_Precision: 0.9529 - val_Recall: 0.9550 - val_TP: 767.8400 - val_TN: 1075.7300 - val_FP: 30.2700 - val_FN: 36.1600\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.0953 - Accuracy: 0.9875 - Precision: 0.9698 - Recall: 0.9686 - TP: 3266.2100 - TN: 5577.3701 - FP: 69.6300 - FN: 105.7900 - val_loss: 0.2035 - val_Accuracy: 0.9702 - val_Precision: 0.9689 - val_Recall: 0.9394 - val_TP: 755.2500 - val_TN: 1089.3000 - val_FP: 16.7000 - val_FN: 48.7500\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1489 - Accuracy: 0.9859 - Precision: 0.9676 - Recall: 0.9671 - TP: 3261.2200 - TN: 5569.5400 - FP: 77.4600 - FN: 110.7800 - val_loss: 0.2364 - val_Accuracy: 0.9712 - val_Precision: 0.9560 - val_Recall: 0.9497 - val_TP: 763.5900 - val_TN: 1078.5400 - val_FP: 27.4600 - val_FN: 40.4100\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1087 - Accuracy: 0.9875 - Precision: 0.9698 - Recall: 0.9682 - TP: 3264.9099 - TN: 5577.2700 - FP: 69.7300 - FN: 107.0900 - val_loss: 0.2065 - val_Accuracy: 0.9728 - val_Precision: 0.9696 - val_Recall: 0.9408 - val_TP: 756.4100 - val_TN: 1089.9000 - val_FP: 16.1000 - val_FN: 47.5900\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 18s 7ms/step - loss: 0.1069 - Accuracy: 0.9850 - Precision: 0.9672 - Recall: 0.9648 - TP: 3253.1499 - TN: 5568.2402 - FP: 78.7600 - FN: 118.8500 - val_loss: 0.1919 - val_Accuracy: 0.9743 - val_Precision: 0.9681 - val_Recall: 0.9448 - val_TP: 759.6200 - val_TN: 1088.6000 - val_FP: 17.4000 - val_FN: 44.3800\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1595 - Accuracy: 0.9845 - Precision: 0.9659 - Recall: 0.9653 - TP: 3255.1101 - TN: 5563.8701 - FP: 83.1300 - FN: 116.8900 - val_loss: 0.1805 - val_Accuracy: 0.9749 - val_Precision: 0.9607 - val_Recall: 0.9535 - val_TP: 766.5900 - val_TN: 1082.2500 - val_FP: 23.7500 - val_FN: 37.4100\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0975 - Accuracy: 0.9858 - Precision: 0.9671 - Recall: 0.9659 - TP: 3256.8899 - TN: 5567.9199 - FP: 79.0800 - FN: 115.1100 - val_loss: 0.1969 - val_Accuracy: 0.9717 - val_Precision: 0.9688 - val_Recall: 0.9425 - val_TP: 757.7400 - val_TN: 1089.2300 - val_FP: 16.7700 - val_FN: 46.2600\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1370 - Accuracy: 0.9870 - Precision: 0.9682 - Recall: 0.9677 - TP: 3262.9600 - TN: 5571.3101 - FP: 75.6900 - FN: 109.0400 - val_loss: 0.1926 - val_Accuracy: 0.9712 - val_Precision: 0.9570 - val_Recall: 0.9527 - val_TP: 765.9500 - val_TN: 1079.2100 - val_FP: 26.7900 - val_FN: 38.0500\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0724 - Accuracy: 0.9859 - Precision: 0.9686 - Recall: 0.9675 - TP: 3262.5701 - TN: 5573.0601 - FP: 73.9400 - FN: 109.4300 - val_loss: 0.2126 - val_Accuracy: 0.9728 - val_Precision: 0.9641 - val_Recall: 0.9435 - val_TP: 758.6100 - val_TN: 1085.3700 - val_FP: 20.6300 - val_FN: 45.3900\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2191 - Accuracy: 0.9856 - Precision: 0.9658 - Recall: 0.9647 - TP: 3253.0000 - TN: 5562.9302 - FP: 84.0700 - FN: 119.0000 - val_loss: 0.1990 - val_Accuracy: 0.9728 - val_Precision: 0.9695 - val_Recall: 0.9422 - val_TP: 757.5000 - val_TN: 1089.7600 - val_FP: 16.2400 - val_FN: 46.5000\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0854 - Accuracy: 0.9875 - Precision: 0.9690 - Recall: 0.9682 - TP: 3264.8799 - TN: 5574.3101 - FP: 72.6900 - FN: 107.1200 - val_loss: 0.1890 - val_Accuracy: 0.9749 - val_Precision: 0.9679 - val_Recall: 0.9445 - val_TP: 759.4100 - val_TN: 1088.4100 - val_FP: 17.5900 - val_FN: 44.5900\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0896 - Accuracy: 0.9865 - Precision: 0.9683 - Recall: 0.9670 - TP: 3260.8000 - TN: 5571.9399 - FP: 75.0600 - FN: 111.2000 - val_loss: 0.1853 - val_Accuracy: 0.9743 - val_Precision: 0.9672 - val_Recall: 0.9477 - val_TP: 761.9900 - val_TN: 1087.8300 - val_FP: 18.1700 - val_FN: 42.0100\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1280 - Accuracy: 0.9867 - Precision: 0.9673 - Recall: 0.9673 - TP: 3261.6899 - TN: 5568.5098 - FP: 78.4900 - FN: 110.3100 - val_loss: 0.1940 - val_Accuracy: 0.9712 - val_Precision: 0.9689 - val_Recall: 0.9410 - val_TP: 756.6000 - val_TN: 1089.2900 - val_FP: 16.7100 - val_FN: 47.4000\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1168 - Accuracy: 0.9858 - Precision: 0.9683 - Recall: 0.9662 - TP: 3257.8601 - TN: 5572.1499 - FP: 74.8500 - FN: 114.1400 - val_loss: 0.1930 - val_Accuracy: 0.9723 - val_Precision: 0.9605 - val_Recall: 0.9509 - val_TP: 764.5100 - val_TN: 1082.2400 - val_FP: 23.7600 - val_FN: 39.4900\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1627 - Accuracy: 0.9858 - Precision: 0.9673 - Recall: 0.9663 - TP: 3258.2800 - TN: 5568.7500 - FP: 78.2500 - FN: 113.7200 - val_loss: 0.2275 - val_Accuracy: 0.9712 - val_Precision: 0.9576 - val_Recall: 0.9501 - val_TP: 763.8700 - val_TN: 1079.8900 - val_FP: 26.1100 - val_FN: 40.1300\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1030 - Accuracy: 0.9872 - Precision: 0.9694 - Recall: 0.9681 - TP: 3264.3201 - TN: 5575.7300 - FP: 71.2700 - FN: 107.6800 - val_loss: 0.2288 - val_Accuracy: 0.9686 - val_Precision: 0.9410 - val_Recall: 0.9604 - val_TP: 772.1300 - val_TN: 1065.3700 - val_FP: 40.6300 - val_FN: 31.8700\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0963 - Accuracy: 0.9860 - Precision: 0.9694 - Recall: 0.9688 - TP: 3266.7600 - TN: 5575.7002 - FP: 71.3000 - FN: 105.2400 - val_loss: 0.2135 - val_Accuracy: 0.9717 - val_Precision: 0.9522 - val_Recall: 0.9548 - val_TP: 767.6700 - val_TN: 1075.1600 - val_FP: 30.8400 - val_FN: 36.3300\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1069 - Accuracy: 0.9861 - Precision: 0.9692 - Recall: 0.9679 - TP: 3263.7100 - TN: 5575.1099 - FP: 71.8900 - FN: 108.2900 - val_loss: 0.2529 - val_Accuracy: 0.9675 - val_Precision: 0.9395 - val_Recall: 0.9569 - val_TP: 769.3700 - val_TN: 1064.0500 - val_FP: 41.9500 - val_FN: 34.6300\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1022 - Accuracy: 0.9871 - Precision: 0.9682 - Recall: 0.9680 - TP: 3263.9299 - TN: 5571.4399 - FP: 75.5600 - FN: 108.0700 - val_loss: 0.2058 - val_Accuracy: 0.9696 - val_Precision: 0.9594 - val_Recall: 0.9479 - val_TP: 762.0900 - val_TN: 1081.4399 - val_FP: 24.5600 - val_FN: 41.9100\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1813 - Accuracy: 0.9846 - Precision: 0.9668 - Recall: 0.9660 - TP: 3257.2500 - TN: 5567.1401 - FP: 79.8600 - FN: 114.7500 - val_loss: 0.2543 - val_Accuracy: 0.9660 - val_Precision: 0.9535 - val_Recall: 0.9455 - val_TP: 760.1900 - val_TN: 1076.6200 - val_FP: 29.3800 - val_FN: 43.8100\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1652 - Accuracy: 0.9851 - Precision: 0.9667 - Recall: 0.9644 - TP: 3252.0300 - TN: 5566.7598 - FP: 80.2400 - FN: 119.9700 - val_loss: 0.1987 - val_Accuracy: 0.9723 - val_Precision: 0.9667 - val_Recall: 0.9445 - val_TP: 759.3900 - val_TN: 1087.4399 - val_FP: 18.5600 - val_FN: 44.6100\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1236 - Accuracy: 0.9856 - Precision: 0.9669 - Recall: 0.9660 - TP: 3257.3301 - TN: 5567.1299 - FP: 79.8700 - FN: 114.6700 - val_loss: 0.1997 - val_Accuracy: 0.9728 - val_Precision: 0.9651 - val_Recall: 0.9462 - val_TP: 760.7600 - val_TN: 1086.1500 - val_FP: 19.8500 - val_FN: 43.2400\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1058 - Accuracy: 0.9861 - Precision: 0.9679 - Recall: 0.9662 - TP: 3258.1899 - TN: 5570.5801 - FP: 76.4200 - FN: 113.8100 - val_loss: 0.1917 - val_Accuracy: 0.9723 - val_Precision: 0.9565 - val_Recall: 0.9541 - val_TP: 767.1000 - val_TN: 1078.8101 - val_FP: 27.1900 - val_FN: 36.9000\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0704 - Accuracy: 0.9878 - Precision: 0.9693 - Recall: 0.9689 - TP: 3267.0901 - TN: 5575.5298 - FP: 71.4700 - FN: 104.9100 - val_loss: 0.1938 - val_Accuracy: 0.9717 - val_Precision: 0.9600 - val_Recall: 0.9494 - val_TP: 763.3400 - val_TN: 1081.8101 - val_FP: 24.1900 - val_FN: 40.6600\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1087 - Accuracy: 0.9872 - Precision: 0.9685 - Recall: 0.9677 - TP: 3263.1899 - TN: 5572.6001 - FP: 74.4000 - FN: 108.8100 - val_loss: 0.2220 - val_Accuracy: 0.9712 - val_Precision: 0.9616 - val_Recall: 0.9459 - val_TP: 760.5000 - val_TN: 1083.2700 - val_FP: 22.7300 - val_FN: 43.5000\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1014 - Accuracy: 0.9864 - Precision: 0.9690 - Recall: 0.9668 - TP: 3260.1101 - TN: 5574.3901 - FP: 72.6100 - FN: 111.8900 - val_loss: 0.1904 - val_Accuracy: 0.9743 - val_Precision: 0.9639 - val_Recall: 0.9493 - val_TP: 763.2300 - val_TN: 1085.1200 - val_FP: 20.8800 - val_FN: 40.7700\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 7s 7ms/step - loss: 0.1198 - Accuracy: 0.9857 - Precision: 0.9673 - Recall: 0.9664 - TP: 3258.5701 - TN: 5568.6899 - FP: 78.3100 - FN: 113.4300 - val_loss: 0.2095 - val_Accuracy: 0.9702 - val_Precision: 0.9498 - val_Recall: 0.9565 - val_TP: 769.0600 - val_TN: 1073.1100 - val_FP: 32.8900 - val_FN: 34.9400\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0749 - Accuracy: 0.9868 - Precision: 0.9689 - Recall: 0.9675 - TP: 3262.4299 - TN: 5573.9302 - FP: 73.0700 - FN: 109.5700 - val_loss: 0.2310 - val_Accuracy: 0.9686 - val_Precision: 0.9459 - val_Recall: 0.9543 - val_TP: 767.2400 - val_TN: 1069.8800 - val_FP: 36.1200 - val_FN: 36.7600\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2111 - Accuracy: 0.9829 - Precision: 0.9651 - Recall: 0.9640 - TP: 3250.6201 - TN: 5561.0801 - FP: 85.9200 - FN: 121.3800 - val_loss: 0.2301 - val_Accuracy: 0.9733 - val_Precision: 0.9594 - val_Recall: 0.9488 - val_TP: 762.8700 - val_TN: 1081.4301 - val_FP: 24.5700 - val_FN: 41.1300\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1024 - Accuracy: 0.9847 - Precision: 0.9680 - Recall: 0.9669 - TP: 3260.4900 - TN: 5570.7900 - FP: 76.2100 - FN: 111.5100 - val_loss: 0.1956 - val_Accuracy: 0.9712 - val_Precision: 0.9560 - val_Recall: 0.9519 - val_TP: 765.3200 - val_TN: 1078.4500 - val_FP: 27.5500 - val_FN: 38.6800\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0769 - Accuracy: 0.9869 - Precision: 0.9692 - Recall: 0.9681 - TP: 3264.3301 - TN: 5574.8101 - FP: 72.1900 - FN: 107.6700 - val_loss: 0.2424 - val_Accuracy: 0.9681 - val_Precision: 0.9447 - val_Recall: 0.9534 - val_TP: 766.5100 - val_TN: 1068.7600 - val_FP: 37.2400 - val_FN: 37.4900\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0879 - Accuracy: 0.9872 - Precision: 0.9693 - Recall: 0.9682 - TP: 3264.7100 - TN: 5575.3901 - FP: 71.6100 - FN: 107.2900 - val_loss: 0.2186 - val_Accuracy: 0.9712 - val_Precision: 0.9482 - val_Recall: 0.9560 - val_TP: 768.5900 - val_TN: 1071.6200 - val_FP: 34.3800 - val_FN: 35.4100\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0844 - Accuracy: 0.9870 - Precision: 0.9683 - Recall: 0.9672 - TP: 3261.2600 - TN: 5571.9502 - FP: 75.0500 - FN: 110.7400 - val_loss: 0.1821 - val_Accuracy: 0.9764 - val_Precision: 0.9670 - val_Recall: 0.9495 - val_TP: 763.4300 - val_TN: 1087.6200 - val_FP: 18.3800 - val_FN: 40.5700\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0789 - Accuracy: 0.9889 - Precision: 0.9695 - Recall: 0.9689 - TP: 3267.2700 - TN: 5575.7300 - FP: 71.2700 - FN: 104.7300 - val_loss: 0.1863 - val_Accuracy: 0.9723 - val_Precision: 0.9586 - val_Recall: 0.9544 - val_TP: 767.3200 - val_TN: 1080.5300 - val_FP: 25.4700 - val_FN: 36.6800\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3058 - Accuracy: 0.9844 - Precision: 0.9657 - Recall: 0.9647 - TP: 3252.9700 - TN: 5563.0000 - FP: 84.0000 - FN: 119.0300 - val_loss: 0.2029 - val_Accuracy: 0.9728 - val_Precision: 0.9690 - val_Recall: 0.9414 - val_TP: 756.8500 - val_TN: 1089.3800 - val_FP: 16.6200 - val_FN: 47.1500\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1024 - Accuracy: 0.9836 - Precision: 0.9663 - Recall: 0.9648 - TP: 3253.3401 - TN: 5565.6602 - FP: 81.3400 - FN: 118.6600 - val_loss: 0.1919 - val_Accuracy: 0.9728 - val_Precision: 0.9529 - val_Recall: 0.9581 - val_TP: 770.3300 - val_TN: 1075.6000 - val_FP: 30.4000 - val_FN: 33.6700\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1206 - Accuracy: 0.9863 - Precision: 0.9678 - Recall: 0.9671 - TP: 3261.0200 - TN: 5570.4102 - FP: 76.5900 - FN: 110.9800 - val_loss: 0.1961 - val_Accuracy: 0.9717 - val_Precision: 0.9636 - val_Recall: 0.9443 - val_TP: 759.1800 - val_TN: 1084.9500 - val_FP: 21.0500 - val_FN: 44.8200\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2572 - Accuracy: 0.9848 - Precision: 0.9663 - Recall: 0.9649 - TP: 3253.7200 - TN: 5565.2798 - FP: 81.7200 - FN: 118.2800 - val_loss: 0.1962 - val_Accuracy: 0.9707 - val_Precision: 0.9541 - val_Recall: 0.9552 - val_TP: 767.9600 - val_TN: 1076.7800 - val_FP: 29.2200 - val_FN: 36.0400\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1076 - Accuracy: 0.9847 - Precision: 0.9674 - Recall: 0.9669 - TP: 3260.2300 - TN: 5569.3301 - FP: 77.6700 - FN: 111.7700 - val_loss: 0.1910 - val_Accuracy: 0.9754 - val_Precision: 0.9662 - val_Recall: 0.9485 - val_TP: 762.6300 - val_TN: 1086.9900 - val_FP: 19.0100 - val_FN: 41.3700\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.2107 - Accuracy: 0.9840 - Precision: 0.9647 - Recall: 0.9644 - TP: 3252.0801 - TN: 5559.7202 - FP: 87.2800 - FN: 119.9200 - val_loss: 0.2053 - val_Accuracy: 0.9686 - val_Precision: 0.9524 - val_Recall: 0.9525 - val_TP: 765.7700 - val_TN: 1075.4600 - val_FP: 30.5400 - val_FN: 38.2300\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1810 - Accuracy: 0.9837 - Precision: 0.9663 - Recall: 0.9651 - TP: 3254.1499 - TN: 5565.6001 - FP: 81.4000 - FN: 117.8500 - val_loss: 0.1945 - val_Accuracy: 0.9743 - val_Precision: 0.9651 - val_Recall: 0.9471 - val_TP: 761.5000 - val_TN: 1086.1600 - val_FP: 19.8400 - val_FN: 42.5000\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1600 - Accuracy: 0.9845 - Precision: 0.9672 - Recall: 0.9659 - TP: 3256.9399 - TN: 5568.5698 - FP: 78.4300 - FN: 115.0600 - val_loss: 0.1992 - val_Accuracy: 0.9733 - val_Precision: 0.9574 - val_Recall: 0.9518 - val_TP: 765.2100 - val_TN: 1079.6899 - val_FP: 26.3100 - val_FN: 38.7900\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0825 - Accuracy: 0.9876 - Precision: 0.9687 - Recall: 0.9676 - TP: 3262.8101 - TN: 5573.3301 - FP: 73.6700 - FN: 109.1900 - val_loss: 0.1959 - val_Accuracy: 0.9723 - val_Precision: 0.9502 - val_Recall: 0.9575 - val_TP: 769.7900 - val_TN: 1073.3900 - val_FP: 32.6100 - val_FN: 34.2100\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1353 - Accuracy: 0.9860 - Precision: 0.9682 - Recall: 0.9663 - TP: 3258.4900 - TN: 5571.7900 - FP: 75.2100 - FN: 113.5100 - val_loss: 0.2042 - val_Accuracy: 0.9712 - val_Precision: 0.9535 - val_Recall: 0.9532 - val_TP: 766.3400 - val_TN: 1076.3400 - val_FP: 29.6600 - val_FN: 37.6600\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1206 - Accuracy: 0.9845 - Precision: 0.9654 - Recall: 0.9655 - TP: 3255.5500 - TN: 5561.7900 - FP: 85.2100 - FN: 116.4500 - val_loss: 0.2076 - val_Accuracy: 0.9712 - val_Precision: 0.9625 - val_Recall: 0.9482 - val_TP: 762.3400 - val_TN: 1083.9600 - val_FP: 22.0400 - val_FN: 41.6600\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1191 - Accuracy: 0.9865 - Precision: 0.9686 - Recall: 0.9680 - TP: 3264.0901 - TN: 5573.0298 - FP: 73.9700 - FN: 107.9100 - val_loss: 0.2345 - val_Accuracy: 0.9723 - val_Precision: 0.9591 - val_Recall: 0.9496 - val_TP: 763.4800 - val_TN: 1081.2000 - val_FP: 24.8000 - val_FN: 40.5200\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0943 - Accuracy: 0.9858 - Precision: 0.9681 - Recall: 0.9672 - TP: 3261.3201 - TN: 5571.6899 - FP: 75.3100 - FN: 110.6800 - val_loss: 0.2158 - val_Accuracy: 0.9707 - val_Precision: 0.9719 - val_Recall: 0.9358 - val_TP: 752.4100 - val_TN: 1091.8700 - val_FP: 14.1300 - val_FN: 51.5900\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2278 - Accuracy: 0.9825 - Precision: 0.9645 - Recall: 0.9626 - TP: 3245.9399 - TN: 5559.2202 - FP: 87.7800 - FN: 126.0600 - val_loss: 0.2068 - val_Accuracy: 0.9702 - val_Precision: 0.9565 - val_Recall: 0.9517 - val_TP: 765.1500 - val_TN: 1078.9500 - val_FP: 27.0500 - val_FN: 38.8500\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1671 - Accuracy: 0.9848 - Precision: 0.9675 - Recall: 0.9665 - TP: 3259.0601 - TN: 5569.6401 - FP: 77.3600 - FN: 112.9400 - val_loss: 0.1986 - val_Accuracy: 0.9712 - val_Precision: 0.9557 - val_Recall: 0.9544 - val_TP: 767.3400 - val_TN: 1078.1600 - val_FP: 27.8400 - val_FN: 36.6600\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1446 - Accuracy: 0.9874 - Precision: 0.9690 - Recall: 0.9683 - TP: 3265.0200 - TN: 5574.3599 - FP: 72.6400 - FN: 106.9800 - val_loss: 0.2142 - val_Accuracy: 0.9702 - val_Precision: 0.9592 - val_Recall: 0.9493 - val_TP: 763.2400 - val_TN: 1081.2200 - val_FP: 24.7800 - val_FN: 40.7600\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1463 - Accuracy: 0.9863 - Precision: 0.9685 - Recall: 0.9677 - TP: 3263.2000 - TN: 5572.7700 - FP: 74.2300 - FN: 108.8000 - val_loss: 0.2575 - val_Accuracy: 0.9686 - val_Precision: 0.9568 - val_Recall: 0.9470 - val_TP: 761.4100 - val_TN: 1079.3400 - val_FP: 26.6600 - val_FN: 42.5900\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1096 - Accuracy: 0.9859 - Precision: 0.9680 - Recall: 0.9671 - TP: 3260.9500 - TN: 5571.3701 - FP: 75.6300 - FN: 111.0500 - val_loss: 0.2424 - val_Accuracy: 0.9733 - val_Precision: 0.9590 - val_Recall: 0.9513 - val_TP: 764.8700 - val_TN: 1081.0300 - val_FP: 24.9700 - val_FN: 39.1300\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1504 - Accuracy: 0.9848 - Precision: 0.9672 - Recall: 0.9655 - TP: 3255.5500 - TN: 5568.6299 - FP: 78.3700 - FN: 116.4500 - val_loss: 0.2520 - val_Accuracy: 0.9675 - val_Precision: 0.9508 - val_Recall: 0.9522 - val_TP: 765.5600 - val_TN: 1074.0800 - val_FP: 31.9200 - val_FN: 38.4400\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 8ms/step - loss: 0.1298 - Accuracy: 0.9847 - Precision: 0.9661 - Recall: 0.9660 - TP: 3257.3899 - TN: 5564.5298 - FP: 82.4700 - FN: 114.6100 - val_loss: 0.1933 - val_Accuracy: 0.9728 - val_Precision: 0.9656 - val_Recall: 0.9465 - val_TP: 760.9500 - val_TN: 1086.5200 - val_FP: 19.4800 - val_FN: 43.0500\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0766 - Accuracy: 0.9859 - Precision: 0.9676 - Recall: 0.9663 - TP: 3258.2800 - TN: 5569.7700 - FP: 77.2300 - FN: 113.7200 - val_loss: 0.1931 - val_Accuracy: 0.9717 - val_Precision: 0.9584 - val_Recall: 0.9488 - val_TP: 762.8400 - val_TN: 1080.5699 - val_FP: 25.4300 - val_FN: 41.1600\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0969 - Accuracy: 0.9859 - Precision: 0.9684 - Recall: 0.9674 - TP: 3262.0701 - TN: 5572.1899 - FP: 74.8100 - FN: 109.9300 - val_loss: 0.2291 - val_Accuracy: 0.9707 - val_Precision: 0.9556 - val_Recall: 0.9510 - val_TP: 764.6300 - val_TN: 1078.1801 - val_FP: 27.8200 - val_FN: 39.3700\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1243 - Accuracy: 0.9844 - Precision: 0.9677 - Recall: 0.9664 - TP: 3258.7200 - TN: 5570.0200 - FP: 76.9800 - FN: 113.2800 - val_loss: 0.2052 - val_Accuracy: 0.9728 - val_Precision: 0.9507 - val_Recall: 0.9578 - val_TP: 770.0900 - val_TN: 1073.7400 - val_FP: 32.2600 - val_FN: 33.9100\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1724 - Accuracy: 0.9845 - Precision: 0.9660 - Recall: 0.9645 - TP: 3252.2000 - TN: 5564.5698 - FP: 82.4300 - FN: 119.8000 - val_loss: 0.2494 - val_Accuracy: 0.9660 - val_Precision: 0.9399 - val_Recall: 0.9582 - val_TP: 770.4200 - val_TN: 1064.3600 - val_FP: 41.6400 - val_FN: 33.5800\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1331 - Accuracy: 0.9865 - Precision: 0.9680 - Recall: 0.9680 - TP: 3264.1699 - TN: 5571.2002 - FP: 75.8000 - FN: 107.8300 - val_loss: 0.2002 - val_Accuracy: 0.9723 - val_Precision: 0.9637 - val_Recall: 0.9453 - val_TP: 760.0200 - val_TN: 1084.9900 - val_FP: 21.0100 - val_FN: 43.9800\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1816 - Accuracy: 0.9850 - Precision: 0.9674 - Recall: 0.9658 - TP: 3256.7500 - TN: 5569.0898 - FP: 77.9100 - FN: 115.2500 - val_loss: 0.2198 - val_Accuracy: 0.9712 - val_Precision: 0.9534 - val_Recall: 0.9538 - val_TP: 766.8900 - val_TN: 1076.2300 - val_FP: 29.7700 - val_FN: 37.1100\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1738 - Accuracy: 0.9837 - Precision: 0.9642 - Recall: 0.9643 - TP: 3251.5100 - TN: 5557.8901 - FP: 89.1100 - FN: 120.4900 - val_loss: 0.2318 - val_Accuracy: 0.9686 - val_Precision: 0.9718 - val_Recall: 0.9320 - val_TP: 749.2900 - val_TN: 1091.8300 - val_FP: 14.1700 - val_FN: 54.7100\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2424 - Accuracy: 0.9830 - Precision: 0.9649 - Recall: 0.9633 - TP: 3248.3101 - TN: 5560.4502 - FP: 86.5500 - FN: 123.6900 - val_loss: 0.2099 - val_Accuracy: 0.9723 - val_Precision: 0.9626 - val_Recall: 0.9464 - val_TP: 760.8900 - val_TN: 1084.1000 - val_FP: 21.9000 - val_FN: 43.1100\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1328 - Accuracy: 0.9854 - Precision: 0.9684 - Recall: 0.9658 - TP: 3256.6001 - TN: 5572.5098 - FP: 74.4900 - FN: 115.4000 - val_loss: 0.2113 - val_Accuracy: 0.9738 - val_Precision: 0.9601 - val_Recall: 0.9521 - val_TP: 765.4700 - val_TN: 1081.8700 - val_FP: 24.1300 - val_FN: 38.5300\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0910 - Accuracy: 0.9854 - Precision: 0.9681 - Recall: 0.9680 - TP: 3263.9399 - TN: 5571.2998 - FP: 75.7000 - FN: 108.0600 - val_loss: 0.2129 - val_Accuracy: 0.9728 - val_Precision: 0.9717 - val_Recall: 0.9371 - val_TP: 753.4500 - val_TN: 1091.6700 - val_FP: 14.3300 - val_FN: 50.5500\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1431 - Accuracy: 0.9854 - Precision: 0.9669 - Recall: 0.9652 - TP: 3254.5100 - TN: 5567.2202 - FP: 79.7800 - FN: 117.4900 - val_loss: 0.2761 - val_Accuracy: 0.9660 - val_Precision: 0.9446 - val_Recall: 0.9556 - val_TP: 768.2800 - val_TN: 1068.8000 - val_FP: 37.2000 - val_FN: 35.7200\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0776 - Accuracy: 0.9870 - Precision: 0.9698 - Recall: 0.9698 - TP: 3270.2200 - TN: 5577.3101 - FP: 69.6900 - FN: 101.7800 - val_loss: 0.2046 - val_Accuracy: 0.9754 - val_Precision: 0.9683 - val_Recall: 0.9449 - val_TP: 759.6800 - val_TN: 1088.7900 - val_FP: 17.2100 - val_FN: 44.3200\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1411 - Accuracy: 0.9859 - Precision: 0.9674 - Recall: 0.9668 - TP: 3260.1699 - TN: 5569.0000 - FP: 78.0000 - FN: 111.8300 - val_loss: 0.2069 - val_Accuracy: 0.9717 - val_Precision: 0.9605 - val_Recall: 0.9504 - val_TP: 764.1600 - val_TN: 1082.3300 - val_FP: 23.6700 - val_FN: 39.8400\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0864 - Accuracy: 0.9864 - Precision: 0.9685 - Recall: 0.9674 - TP: 3262.0500 - TN: 5572.4102 - FP: 74.5900 - FN: 109.9500 - val_loss: 0.2014 - val_Accuracy: 0.9723 - val_Precision: 0.9625 - val_Recall: 0.9492 - val_TP: 763.1900 - val_TN: 1083.9500 - val_FP: 22.0500 - val_FN: 40.8100\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2390 - Accuracy: 0.9859 - Precision: 0.9675 - Recall: 0.9659 - TP: 3257.0200 - TN: 5569.5498 - FP: 77.4500 - FN: 114.9800 - val_loss: 0.2633 - val_Accuracy: 0.9686 - val_Precision: 0.9544 - val_Recall: 0.9486 - val_TP: 762.6600 - val_TN: 1077.3000 - val_FP: 28.7000 - val_FN: 41.3400\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1268 - Accuracy: 0.9853 - Precision: 0.9683 - Recall: 0.9672 - TP: 3261.3799 - TN: 5572.2202 - FP: 74.7800 - FN: 110.6200 - val_loss: 0.2108 - val_Accuracy: 0.9696 - val_Precision: 0.9538 - val_Recall: 0.9540 - val_TP: 767.0100 - val_TN: 1076.5900 - val_FP: 29.4100 - val_FN: 36.9900\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0635 - Accuracy: 0.9877 - Precision: 0.9708 - Recall: 0.9693 - TP: 3268.4099 - TN: 5580.7500 - FP: 66.2500 - FN: 103.5900 - val_loss: 0.2186 - val_Accuracy: 0.9702 - val_Precision: 0.9448 - val_Recall: 0.9600 - val_TP: 771.8200 - val_TN: 1068.6801 - val_FP: 37.3200 - val_FN: 32.1800\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1409 - Accuracy: 0.9863 - Precision: 0.9665 - Recall: 0.9672 - TP: 3261.3501 - TN: 5565.6299 - FP: 81.3700 - FN: 110.6500 - val_loss: 0.2393 - val_Accuracy: 0.9728 - val_Precision: 0.9586 - val_Recall: 0.9510 - val_TP: 764.6000 - val_TN: 1080.7300 - val_FP: 25.2700 - val_FN: 39.4000\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1855 - Accuracy: 0.9855 - Precision: 0.9686 - Recall: 0.9663 - TP: 3258.3401 - TN: 5573.3999 - FP: 73.6000 - FN: 113.6600 - val_loss: 0.2108 - val_Accuracy: 0.9712 - val_Precision: 0.9546 - val_Recall: 0.9511 - val_TP: 764.6500 - val_TN: 1077.3700 - val_FP: 28.6300 - val_FN: 39.3500\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1145 - Accuracy: 0.9875 - Precision: 0.9691 - Recall: 0.9686 - TP: 3265.9900 - TN: 5574.6401 - FP: 72.3600 - FN: 106.0100 - val_loss: 0.2623 - val_Accuracy: 0.9681 - val_Precision: 0.9519 - val_Recall: 0.9514 - val_TP: 764.8900 - val_TN: 1075.0500 - val_FP: 30.9500 - val_FN: 39.1100\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1914 - Accuracy: 0.9844 - Precision: 0.9651 - Recall: 0.9644 - TP: 3252.0100 - TN: 5561.2598 - FP: 85.7400 - FN: 119.9900 - val_loss: 0.2136 - val_Accuracy: 0.9738 - val_Precision: 0.9585 - val_Recall: 0.9535 - val_TP: 766.6500 - val_TN: 1080.5300 - val_FP: 25.4700 - val_FN: 37.3500\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 8ms/step - loss: 0.1410 - Accuracy: 0.9844 - Precision: 0.9663 - Recall: 0.9654 - TP: 3255.2800 - TN: 5565.3701 - FP: 81.6300 - FN: 116.7200 - val_loss: 0.2139 - val_Accuracy: 0.9691 - val_Precision: 0.9707 - val_Recall: 0.9335 - val_TP: 750.5000 - val_TN: 1090.9301 - val_FP: 15.0700 - val_FN: 53.5000\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1351 - Accuracy: 0.9855 - Precision: 0.9668 - Recall: 0.9664 - TP: 3258.8401 - TN: 5566.8901 - FP: 80.1100 - FN: 113.1600 - val_loss: 0.2081 - val_Accuracy: 0.9717 - val_Precision: 0.9709 - val_Recall: 0.9395 - val_TP: 755.3300 - val_TN: 1091.0200 - val_FP: 14.9800 - val_FN: 48.6700\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0687 - Accuracy: 0.9856 - Precision: 0.9685 - Recall: 0.9662 - TP: 3258.0100 - TN: 5572.8999 - FP: 74.1000 - FN: 113.9900 - val_loss: 0.1963 - val_Accuracy: 0.9733 - val_Precision: 0.9504 - val_Recall: 0.9569 - val_TP: 769.3600 - val_TN: 1073.5300 - val_FP: 32.4700 - val_FN: 34.6400\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2136 - Accuracy: 0.9840 - Precision: 0.9649 - Recall: 0.9655 - TP: 3255.7000 - TN: 5560.0098 - FP: 86.9900 - FN: 116.3000 - val_loss: 0.2071 - val_Accuracy: 0.9717 - val_Precision: 0.9678 - val_Recall: 0.9408 - val_TP: 756.4400 - val_TN: 1088.4700 - val_FP: 17.5300 - val_FN: 47.5600\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1229 - Accuracy: 0.9859 - Precision: 0.9688 - Recall: 0.9662 - TP: 3258.1799 - TN: 5573.9302 - FP: 73.0700 - FN: 113.8200 - val_loss: 0.1932 - val_Accuracy: 0.9717 - val_Precision: 0.9630 - val_Recall: 0.9469 - val_TP: 761.2900 - val_TN: 1084.4000 - val_FP: 21.6000 - val_FN: 42.7100\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1548 - Accuracy: 0.9859 - Precision: 0.9675 - Recall: 0.9662 - TP: 3258.1201 - TN: 5569.3999 - FP: 77.6000 - FN: 113.8800 - val_loss: 0.2170 - val_Accuracy: 0.9707 - val_Precision: 0.9517 - val_Recall: 0.9540 - val_TP: 767.0400 - val_TN: 1074.8300 - val_FP: 31.1700 - val_FN: 36.9600\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1120 - Accuracy: 0.9867 - Precision: 0.9684 - Recall: 0.9674 - TP: 3262.1299 - TN: 5572.6201 - FP: 74.3800 - FN: 109.8700 - val_loss: 0.2071 - val_Accuracy: 0.9728 - val_Precision: 0.9615 - val_Recall: 0.9463 - val_TP: 760.8500 - val_TN: 1083.2300 - val_FP: 22.7700 - val_FN: 43.1500\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1157 - Accuracy: 0.9850 - Precision: 0.9672 - Recall: 0.9668 - TP: 3259.9399 - TN: 5568.3599 - FP: 78.6400 - FN: 112.0600 - val_loss: 0.2325 - val_Accuracy: 0.9691 - val_Precision: 0.9741 - val_Recall: 0.9306 - val_TP: 748.2400 - val_TN: 1093.6700 - val_FP: 12.3300 - val_FN: 55.7600\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2052 - Accuracy: 0.9845 - Precision: 0.9665 - Recall: 0.9654 - TP: 3255.4800 - TN: 5566.2998 - FP: 80.7000 - FN: 116.5200 - val_loss: 0.2218 - val_Accuracy: 0.9707 - val_Precision: 0.9521 - val_Recall: 0.9551 - val_TP: 767.9300 - val_TN: 1075.2000 - val_FP: 30.8000 - val_FN: 36.0700\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1190 - Accuracy: 0.9849 - Precision: 0.9672 - Recall: 0.9661 - TP: 3257.6299 - TN: 5568.6499 - FP: 78.3500 - FN: 114.3700 - val_loss: 0.2576 - val_Accuracy: 0.9681 - val_Precision: 0.9415 - val_Recall: 0.9564 - val_TP: 768.9300 - val_TN: 1065.9399 - val_FP: 40.0600 - val_FN: 35.0700\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2746 - Accuracy: 0.9839 - Precision: 0.9652 - Recall: 0.9650 - TP: 3253.8899 - TN: 5561.6899 - FP: 85.3100 - FN: 118.1100 - val_loss: 0.2704 - val_Accuracy: 0.9649 - val_Precision: 0.9402 - val_Recall: 0.9571 - val_TP: 769.5400 - val_TN: 1064.8700 - val_FP: 41.1300 - val_FN: 34.4600\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0770 - Accuracy: 0.9863 - Precision: 0.9693 - Recall: 0.9682 - TP: 3264.6299 - TN: 5575.6602 - FP: 71.3400 - FN: 107.3700 - val_loss: 0.1999 - val_Accuracy: 0.9733 - val_Precision: 0.9604 - val_Recall: 0.9529 - val_TP: 766.1500 - val_TN: 1082.0900 - val_FP: 23.9100 - val_FN: 37.8500\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1493 - Accuracy: 0.9853 - Precision: 0.9669 - Recall: 0.9665 - TP: 3259.1201 - TN: 5567.0801 - FP: 79.9200 - FN: 112.8800 - val_loss: 0.2121 - val_Accuracy: 0.9702 - val_Precision: 0.9579 - val_Recall: 0.9485 - val_TP: 762.5800 - val_TN: 1080.2500 - val_FP: 25.7500 - val_FN: 41.4200\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1535 - Accuracy: 0.9861 - Precision: 0.9687 - Recall: 0.9675 - TP: 3262.4199 - TN: 5573.7202 - FP: 73.2800 - FN: 109.5800 - val_loss: 0.2121 - val_Accuracy: 0.9712 - val_Precision: 0.9566 - val_Recall: 0.9487 - val_TP: 762.7300 - val_TN: 1079.1000 - val_FP: 26.9000 - val_FN: 41.2700\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1421 - Accuracy: 0.9851 - Precision: 0.9673 - Recall: 0.9664 - TP: 3258.5901 - TN: 5568.7300 - FP: 78.2700 - FN: 113.4100 - val_loss: 0.2268 - val_Accuracy: 0.9712 - val_Precision: 0.9698 - val_Recall: 0.9362 - val_TP: 752.7200 - val_TN: 1090.1300 - val_FP: 15.8700 - val_FN: 51.2800\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1037 - Accuracy: 0.9853 - Precision: 0.9676 - Recall: 0.9667 - TP: 3259.5701 - TN: 5569.5898 - FP: 77.4100 - FN: 112.4300 - val_loss: 0.3409 - val_Accuracy: 0.9618 - val_Precision: 0.9382 - val_Recall: 0.9466 - val_TP: 761.0900 - val_TN: 1063.5200 - val_FP: 42.4800 - val_FN: 42.9100\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1558 - Accuracy: 0.9849 - Precision: 0.9675 - Recall: 0.9651 - TP: 3254.4099 - TN: 5569.3599 - FP: 77.6400 - FN: 117.5900 - val_loss: 0.2150 - val_Accuracy: 0.9717 - val_Precision: 0.9571 - val_Recall: 0.9517 - val_TP: 765.1800 - val_TN: 1079.3900 - val_FP: 26.6100 - val_FN: 38.8200\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0961 - Accuracy: 0.9871 - Precision: 0.9690 - Recall: 0.9691 - TP: 3267.9299 - TN: 5574.5498 - FP: 72.4500 - FN: 104.0700 - val_loss: 0.2097 - val_Accuracy: 0.9712 - val_Precision: 0.9526 - val_Recall: 0.9550 - val_TP: 767.8500 - val_TN: 1075.5500 - val_FP: 30.4500 - val_FN: 36.1500\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1286 - Accuracy: 0.9858 - Precision: 0.9680 - Recall: 0.9665 - TP: 3258.9600 - TN: 5571.3101 - FP: 75.6900 - FN: 113.0400 - val_loss: 0.2072 - val_Accuracy: 0.9707 - val_Precision: 0.9521 - val_Recall: 0.9562 - val_TP: 768.7500 - val_TN: 1075.0300 - val_FP: 30.9700 - val_FN: 35.2500\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1141 - Accuracy: 0.9861 - Precision: 0.9682 - Recall: 0.9679 - TP: 3263.8701 - TN: 5571.8701 - FP: 75.1300 - FN: 108.1300 - val_loss: 0.2455 - val_Accuracy: 0.9675 - val_Precision: 0.9551 - val_Recall: 0.9460 - val_TP: 760.5900 - val_TN: 1077.9301 - val_FP: 28.0700 - val_FN: 43.4100\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1943 - Accuracy: 0.9843 - Precision: 0.9672 - Recall: 0.9655 - TP: 3255.7100 - TN: 5568.3101 - FP: 78.6900 - FN: 116.2900 - val_loss: 0.2159 - val_Accuracy: 0.9691 - val_Precision: 0.9530 - val_Recall: 0.9529 - val_TP: 766.1500 - val_TN: 1075.9600 - val_FP: 30.0400 - val_FN: 37.8500\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1195 - Accuracy: 0.9850 - Precision: 0.9669 - Recall: 0.9665 - TP: 3259.1101 - TN: 5567.4702 - FP: 79.5300 - FN: 112.8900 - val_loss: 0.2622 - val_Accuracy: 0.9670 - val_Precision: 0.9531 - val_Recall: 0.9473 - val_TP: 761.6000 - val_TN: 1076.2100 - val_FP: 29.7900 - val_FN: 42.4000\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2151 - Accuracy: 0.9853 - Precision: 0.9666 - Recall: 0.9664 - TP: 3258.7700 - TN: 5566.3799 - FP: 80.6200 - FN: 113.2300 - val_loss: 0.2204 - val_Accuracy: 0.9723 - val_Precision: 0.9668 - val_Recall: 0.9434 - val_TP: 758.5000 - val_TN: 1087.6300 - val_FP: 18.3700 - val_FN: 45.5000\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1571 - Accuracy: 0.9860 - Precision: 0.9694 - Recall: 0.9676 - TP: 3262.7400 - TN: 5576.0400 - FP: 70.9600 - FN: 109.2600 - val_loss: 0.2611 - val_Accuracy: 0.9686 - val_Precision: 0.9456 - val_Recall: 0.9564 - val_TP: 768.9200 - val_TN: 1069.4900 - val_FP: 36.5100 - val_FN: 35.0800\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.1918 - Accuracy: 0.9849 - Precision: 0.9674 - Recall: 0.9674 - TP: 3262.1499 - TN: 5569.2998 - FP: 77.7000 - FN: 109.8500 - val_loss: 0.2437 - val_Accuracy: 0.9707 - val_Precision: 0.9705 - val_Recall: 0.9361 - val_TP: 752.6300 - val_TN: 1090.7400 - val_FP: 15.2600 - val_FN: 51.3700\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 7ms/step - loss: 0.1040 - Accuracy: 0.9853 - Precision: 0.9671 - Recall: 0.9653 - TP: 3255.0901 - TN: 5568.1201 - FP: 78.8800 - FN: 116.9100 - val_loss: 0.1975 - val_Accuracy: 0.9733 - val_Precision: 0.9680 - val_Recall: 0.9433 - val_TP: 758.4400 - val_TN: 1088.5300 - val_FP: 17.4700 - val_FN: 45.5600\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1573 - Accuracy: 0.9855 - Precision: 0.9678 - Recall: 0.9668 - TP: 3259.9500 - TN: 5570.1201 - FP: 76.8800 - FN: 112.0500 - val_loss: 0.1924 - val_Accuracy: 0.9702 - val_Precision: 0.9576 - val_Recall: 0.9508 - val_TP: 764.4800 - val_TN: 1079.7700 - val_FP: 26.2300 - val_FN: 39.5200\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1000 - Accuracy: 0.9867 - Precision: 0.9691 - Recall: 0.9677 - TP: 3263.0801 - TN: 5574.6899 - FP: 72.3100 - FN: 108.9200 - val_loss: 0.2204 - val_Accuracy: 0.9686 - val_Precision: 0.9439 - val_Recall: 0.9574 - val_TP: 769.7400 - val_TN: 1067.9301 - val_FP: 38.0700 - val_FN: 34.2600\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1080 - Accuracy: 0.9866 - Precision: 0.9689 - Recall: 0.9690 - TP: 3267.4099 - TN: 5574.2798 - FP: 72.7200 - FN: 104.5900 - val_loss: 0.2129 - val_Accuracy: 0.9717 - val_Precision: 0.9707 - val_Recall: 0.9381 - val_TP: 754.2500 - val_TN: 1090.8300 - val_FP: 15.1700 - val_FN: 49.7500\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1503 - Accuracy: 0.9857 - Precision: 0.9681 - Recall: 0.9667 - TP: 3259.5601 - TN: 5571.6299 - FP: 75.3700 - FN: 112.4400 - val_loss: 0.2680 - val_Accuracy: 0.9613 - val_Precision: 0.9308 - val_Recall: 0.9617 - val_TP: 773.1900 - val_TN: 1056.3600 - val_FP: 49.6400 - val_FN: 30.8100\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1329 - Accuracy: 0.9868 - Precision: 0.9686 - Recall: 0.9674 - TP: 3262.0300 - TN: 5573.1201 - FP: 73.8800 - FN: 109.9700 - val_loss: 0.1918 - val_Accuracy: 0.9717 - val_Precision: 0.9570 - val_Recall: 0.9536 - val_TP: 766.7000 - val_TN: 1079.2500 - val_FP: 26.7500 - val_FN: 37.3000\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1022 - Accuracy: 0.9865 - Precision: 0.9686 - Recall: 0.9681 - TP: 3264.5601 - TN: 5573.2402 - FP: 73.7600 - FN: 107.4400 - val_loss: 0.2091 - val_Accuracy: 0.9712 - val_Precision: 0.9593 - val_Recall: 0.9461 - val_TP: 760.6800 - val_TN: 1081.3900 - val_FP: 24.6100 - val_FN: 43.3200\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1298 - Accuracy: 0.9857 - Precision: 0.9671 - Recall: 0.9667 - TP: 3259.7200 - TN: 5568.0601 - FP: 78.9400 - FN: 112.2800 - val_loss: 0.2259 - val_Accuracy: 0.9717 - val_Precision: 0.9538 - val_Recall: 0.9538 - val_TP: 766.8400 - val_TN: 1076.5100 - val_FP: 29.4900 - val_FN: 37.1600\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2867 - Accuracy: 0.9825 - Precision: 0.9646 - Recall: 0.9630 - TP: 3247.2600 - TN: 5560.0298 - FP: 86.9700 - FN: 124.7400 - val_loss: 0.6424 - val_Accuracy: 0.9340 - val_Precision: 0.8741 - val_Recall: 0.9579 - val_TP: 770.1700 - val_TN: 1003.4000 - val_FP: 102.6000 - val_FN: 33.8300\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1241 - Accuracy: 0.9855 - Precision: 0.9674 - Recall: 0.9669 - TP: 3260.2200 - TN: 5568.9702 - FP: 78.0300 - FN: 111.7800 - val_loss: 0.2482 - val_Accuracy: 0.9696 - val_Precision: 0.9617 - val_Recall: 0.9395 - val_TP: 755.3700 - val_TN: 1083.5900 - val_FP: 22.4100 - val_FN: 48.6300\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1692 - Accuracy: 0.9857 - Precision: 0.9682 - Recall: 0.9659 - TP: 3257.0601 - TN: 5572.1299 - FP: 74.8700 - FN: 114.9400 - val_loss: 0.2020 - val_Accuracy: 0.9723 - val_Precision: 0.9530 - val_Recall: 0.9586 - val_TP: 770.7300 - val_TN: 1075.7200 - val_FP: 30.2800 - val_FN: 33.2700\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0900 - Accuracy: 0.9858 - Precision: 0.9679 - Recall: 0.9678 - TP: 3263.3000 - TN: 5570.5698 - FP: 76.4300 - FN: 108.7000 - val_loss: 0.2148 - val_Accuracy: 0.9743 - val_Precision: 0.9738 - val_Recall: 0.9393 - val_TP: 755.2200 - val_TN: 1093.3199 - val_FP: 12.6800 - val_FN: 48.7800\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1517 - Accuracy: 0.9854 - Precision: 0.9690 - Recall: 0.9675 - TP: 3262.5000 - TN: 5574.8198 - FP: 72.1800 - FN: 109.5000 - val_loss: 0.2119 - val_Accuracy: 0.9702 - val_Precision: 0.9541 - val_Recall: 0.9517 - val_TP: 765.2000 - val_TN: 1076.9200 - val_FP: 29.0800 - val_FN: 38.8000\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.1093 - Accuracy: 0.9843 - Precision: 0.9666 - Recall: 0.9667 - TP: 3259.7100 - TN: 5566.3599 - FP: 80.6400 - FN: 112.2900 - val_loss: 0.2045 - val_Accuracy: 0.9743 - val_Precision: 0.9633 - val_Recall: 0.9509 - val_TP: 764.5200 - val_TN: 1084.5900 - val_FP: 21.4100 - val_FN: 39.4800\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1610 - Accuracy: 0.9856 - Precision: 0.9682 - Recall: 0.9669 - TP: 3260.3701 - TN: 5571.9800 - FP: 75.0200 - FN: 111.6300 - val_loss: 0.2214 - val_Accuracy: 0.9707 - val_Precision: 0.9510 - val_Recall: 0.9567 - val_TP: 769.2000 - val_TN: 1074.1300 - val_FP: 31.8700 - val_FN: 34.8000\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1167 - Accuracy: 0.9864 - Precision: 0.9686 - Recall: 0.9672 - TP: 3261.2500 - TN: 5573.4399 - FP: 73.5600 - FN: 110.7500 - val_loss: 0.2099 - val_Accuracy: 0.9707 - val_Precision: 0.9517 - val_Recall: 0.9587 - val_TP: 770.7800 - val_TN: 1074.6400 - val_FP: 31.3600 - val_FN: 33.2200\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1721 - Accuracy: 0.9860 - Precision: 0.9680 - Recall: 0.9673 - TP: 3261.7500 - TN: 5571.2998 - FP: 75.7000 - FN: 110.2500 - val_loss: 0.2109 - val_Accuracy: 0.9738 - val_Precision: 0.9592 - val_Recall: 0.9535 - val_TP: 766.6200 - val_TN: 1081.1000 - val_FP: 24.9000 - val_FN: 37.3800\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1543 - Accuracy: 0.9865 - Precision: 0.9678 - Recall: 0.9675 - TP: 3262.3999 - TN: 5570.5000 - FP: 76.5000 - FN: 109.6000 - val_loss: 0.2326 - val_Accuracy: 0.9702 - val_Precision: 0.9540 - val_Recall: 0.9539 - val_TP: 766.9200 - val_TN: 1076.7800 - val_FP: 29.2200 - val_FN: 37.0800\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1266 - Accuracy: 0.9857 - Precision: 0.9683 - Recall: 0.9673 - TP: 3261.7600 - TN: 5571.9800 - FP: 75.0200 - FN: 110.2400 - val_loss: 0.2898 - val_Accuracy: 0.9665 - val_Precision: 0.9496 - val_Recall: 0.9480 - val_TP: 762.2200 - val_TN: 1073.3199 - val_FP: 32.6800 - val_FN: 41.7800\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2386 - Accuracy: 0.9839 - Precision: 0.9645 - Recall: 0.9633 - TP: 3248.1299 - TN: 5559.3901 - FP: 87.6100 - FN: 123.8700 - val_loss: 0.2621 - val_Accuracy: 0.9686 - val_Precision: 0.9457 - val_Recall: 0.9587 - val_TP: 770.7900 - val_TN: 1069.6000 - val_FP: 36.4000 - val_FN: 33.2100\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1004 - Accuracy: 0.9867 - Precision: 0.9698 - Recall: 0.9682 - TP: 3264.8000 - TN: 5577.4902 - FP: 69.5100 - FN: 107.2000 - val_loss: 0.2161 - val_Accuracy: 0.9738 - val_Precision: 0.9505 - val_Recall: 0.9595 - val_TP: 771.4400 - val_TN: 1073.6200 - val_FP: 32.3800 - val_FN: 32.5600\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0928 - Accuracy: 0.9860 - Precision: 0.9685 - Recall: 0.9684 - TP: 3265.4199 - TN: 5572.8701 - FP: 74.1300 - FN: 106.5800 - val_loss: 0.2244 - val_Accuracy: 0.9712 - val_Precision: 0.9536 - val_Recall: 0.9546 - val_TP: 767.4700 - val_TN: 1076.4200 - val_FP: 29.5800 - val_FN: 36.5300\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1522 - Accuracy: 0.9860 - Precision: 0.9684 - Recall: 0.9673 - TP: 3261.6399 - TN: 5572.4902 - FP: 74.5100 - FN: 110.3600 - val_loss: 0.2264 - val_Accuracy: 0.9675 - val_Precision: 0.9478 - val_Recall: 0.9566 - val_TP: 769.1100 - val_TN: 1071.4000 - val_FP: 34.6000 - val_FN: 34.8900\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1612 - Accuracy: 0.9859 - Precision: 0.9685 - Recall: 0.9679 - TP: 3263.8799 - TN: 5572.9399 - FP: 74.0600 - FN: 108.1200 - val_loss: 1.0066 - val_Accuracy: 0.9319 - val_Precision: 0.8689 - val_Recall: 0.9583 - val_TP: 770.4700 - val_TN: 998.2100 - val_FP: 107.7900 - val_FN: 33.5300\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1007 - Accuracy: 0.9855 - Precision: 0.9676 - Recall: 0.9673 - TP: 3261.7600 - TN: 5569.9702 - FP: 77.0300 - FN: 110.2400 - val_loss: 0.2276 - val_Accuracy: 0.9733 - val_Precision: 0.9733 - val_Recall: 0.9375 - val_TP: 753.7200 - val_TN: 1092.8900 - val_FP: 13.1100 - val_FN: 50.2800\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0875 - Accuracy: 0.9869 - Precision: 0.9704 - Recall: 0.9687 - TP: 3266.5901 - TN: 5579.4800 - FP: 67.5200 - FN: 105.4100 - val_loss: 0.2200 - val_Accuracy: 0.9702 - val_Precision: 0.9491 - val_Recall: 0.9563 - val_TP: 768.9000 - val_TN: 1072.5800 - val_FP: 33.4200 - val_FN: 35.1000\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 7ms/step - loss: 0.1291 - Accuracy: 0.9835 - Precision: 0.9668 - Recall: 0.9645 - TP: 3252.4299 - TN: 5567.3101 - FP: 79.6900 - FN: 119.5700 - val_loss: 0.2162 - val_Accuracy: 0.9670 - val_Precision: 0.9378 - val_Recall: 0.9608 - val_TP: 772.5000 - val_TN: 1062.4800 - val_FP: 43.5200 - val_FN: 31.5000\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1552 - Accuracy: 0.9838 - Precision: 0.9653 - Recall: 0.9657 - TP: 3256.3201 - TN: 5562.1299 - FP: 84.8700 - FN: 115.6800 - val_loss: 0.2160 - val_Accuracy: 0.9712 - val_Precision: 0.9606 - val_Recall: 0.9475 - val_TP: 761.7700 - val_TN: 1082.4000 - val_FP: 23.6000 - val_FN: 42.2300\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1089 - Accuracy: 0.9872 - Precision: 0.9697 - Recall: 0.9687 - TP: 3266.5500 - TN: 5577.0601 - FP: 69.9400 - FN: 105.4500 - val_loss: 0.2087 - val_Accuracy: 0.9712 - val_Precision: 0.9583 - val_Recall: 0.9512 - val_TP: 764.7500 - val_TN: 1080.4200 - val_FP: 25.5800 - val_FN: 39.2500\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3643 - Accuracy: 0.9808 - Precision: 0.9631 - Recall: 0.9612 - TP: 3241.1499 - TN: 5554.7798 - FP: 92.2200 - FN: 130.8500 - val_loss: 0.2206 - val_Accuracy: 0.9670 - val_Precision: 0.9540 - val_Recall: 0.9486 - val_TP: 762.6400 - val_TN: 1076.9800 - val_FP: 29.0200 - val_FN: 41.3600\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3600 - Accuracy: 0.9807 - Precision: 0.9620 - Recall: 0.9614 - TP: 3241.8601 - TN: 5550.7598 - FP: 96.2400 - FN: 130.1400 - val_loss: 0.2656 - val_Accuracy: 0.9686 - val_Precision: 0.9671 - val_Recall: 0.9374 - val_TP: 753.6600 - val_TN: 1088.0100 - val_FP: 17.9900 - val_FN: 50.3400\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0979 - Accuracy: 0.9851 - Precision: 0.9674 - Recall: 0.9669 - TP: 3260.3301 - TN: 5569.5000 - FP: 77.5000 - FN: 111.6700 - val_loss: 0.2710 - val_Accuracy: 0.9717 - val_Precision: 0.9585 - val_Recall: 0.9488 - val_TP: 762.8100 - val_TN: 1080.7500 - val_FP: 25.2500 - val_FN: 41.1900\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1522 - Accuracy: 0.9843 - Precision: 0.9668 - Recall: 0.9664 - TP: 3258.7600 - TN: 5567.2798 - FP: 79.7200 - FN: 113.2400 - val_loss: 0.2618 - val_Accuracy: 0.9670 - val_Precision: 0.9790 - val_Recall: 0.9222 - val_TP: 741.4800 - val_TN: 1097.5699 - val_FP: 8.4300 - val_FN: 62.5200\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2939 - Accuracy: 0.9812 - Precision: 0.9651 - Recall: 0.9626 - TP: 3246.0400 - TN: 5561.7598 - FP: 85.2400 - FN: 125.9600 - val_loss: 0.2682 - val_Accuracy: 0.9607 - val_Precision: 0.9184 - val_Recall: 0.9644 - val_TP: 775.3700 - val_TN: 1044.7700 - val_FP: 61.2300 - val_FN: 28.6300\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1363 - Accuracy: 0.9823 - Precision: 0.9645 - Recall: 0.9653 - TP: 3254.9399 - TN: 5559.3901 - FP: 87.6100 - FN: 117.0600 - val_loss: 0.2245 - val_Accuracy: 0.9712 - val_Precision: 0.9682 - val_Recall: 0.9394 - val_TP: 755.2500 - val_TN: 1088.7900 - val_FP: 17.2100 - val_FN: 48.7500\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1637 - Accuracy: 0.9854 - Precision: 0.9682 - Recall: 0.9666 - TP: 3259.3799 - TN: 5571.6401 - FP: 75.3600 - FN: 112.6200 - val_loss: 0.3992 - val_Accuracy: 0.9602 - val_Precision: 0.9302 - val_Recall: 0.9519 - val_TP: 765.3500 - val_TN: 1056.1000 - val_FP: 49.9000 - val_FN: 38.6500\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1381 - Accuracy: 0.9860 - Precision: 0.9687 - Recall: 0.9678 - TP: 3263.4500 - TN: 5573.5698 - FP: 73.4300 - FN: 108.5500 - val_loss: 0.2640 - val_Accuracy: 0.9696 - val_Precision: 0.9504 - val_Recall: 0.9534 - val_TP: 766.5100 - val_TN: 1073.7800 - val_FP: 32.2200 - val_FN: 37.4900\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2828 - Accuracy: 0.9825 - Precision: 0.9636 - Recall: 0.9631 - TP: 3247.7400 - TN: 5556.5200 - FP: 90.4800 - FN: 124.2600 - val_loss: 0.2449 - val_Accuracy: 0.9665 - val_Precision: 0.9473 - val_Recall: 0.9546 - val_TP: 767.4800 - val_TN: 1071.1200 - val_FP: 34.8800 - val_FN: 36.5200\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1324 - Accuracy: 0.9840 - Precision: 0.9666 - Recall: 0.9654 - TP: 3255.4600 - TN: 5566.7202 - FP: 80.2800 - FN: 116.5400 - val_loss: 0.2479 - val_Accuracy: 0.9707 - val_Precision: 0.9545 - val_Recall: 0.9540 - val_TP: 767.0500 - val_TN: 1077.3000 - val_FP: 28.7000 - val_FN: 36.9500\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1619 - Accuracy: 0.9846 - Precision: 0.9668 - Recall: 0.9661 - TP: 3257.6799 - TN: 5567.2002 - FP: 79.8000 - FN: 114.3200 - val_loss: 0.2109 - val_Accuracy: 0.9707 - val_Precision: 0.9542 - val_Recall: 0.9556 - val_TP: 768.3200 - val_TN: 1076.9100 - val_FP: 29.0900 - val_FN: 35.6800\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1593 - Accuracy: 0.9864 - Precision: 0.9690 - Recall: 0.9691 - TP: 3267.7100 - TN: 5574.5098 - FP: 72.4900 - FN: 104.2900 - val_loss: 0.2287 - val_Accuracy: 0.9717 - val_Precision: 0.9577 - val_Recall: 0.9520 - val_TP: 765.3800 - val_TN: 1079.9500 - val_FP: 26.0500 - val_FN: 38.6200\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1365 - Accuracy: 0.9854 - Precision: 0.9679 - Recall: 0.9665 - TP: 3259.1799 - TN: 5570.9600 - FP: 76.0400 - FN: 112.8200 - val_loss: 0.2265 - val_Accuracy: 0.9723 - val_Precision: 0.9637 - val_Recall: 0.9475 - val_TP: 761.7600 - val_TN: 1085.0100 - val_FP: 20.9900 - val_FN: 42.2400\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1083 - Accuracy: 0.9863 - Precision: 0.9686 - Recall: 0.9673 - TP: 3261.8799 - TN: 5573.4102 - FP: 73.5900 - FN: 110.1200 - val_loss: 0.2707 - val_Accuracy: 0.9686 - val_Precision: 0.9448 - val_Recall: 0.9580 - val_TP: 770.2700 - val_TN: 1068.8400 - val_FP: 37.1600 - val_FN: 33.7300\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1001 - Accuracy: 0.9854 - Precision: 0.9681 - Recall: 0.9681 - TP: 3264.5200 - TN: 5571.6401 - FP: 75.3600 - FN: 107.4800 - val_loss: 0.2253 - val_Accuracy: 0.9733 - val_Precision: 0.9612 - val_Recall: 0.9494 - val_TP: 763.2800 - val_TN: 1082.8900 - val_FP: 23.1100 - val_FN: 40.7200\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1722 - Accuracy: 0.9853 - Precision: 0.9678 - Recall: 0.9664 - TP: 3258.7900 - TN: 5570.6499 - FP: 76.3500 - FN: 113.2100 - val_loss: 0.2881 - val_Accuracy: 0.9670 - val_Precision: 0.9452 - val_Recall: 0.9542 - val_TP: 767.2100 - val_TN: 1069.2300 - val_FP: 36.7700 - val_FN: 36.7900\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1541 - Accuracy: 0.9859 - Precision: 0.9678 - Recall: 0.9677 - TP: 3262.9800 - TN: 5570.7402 - FP: 76.2600 - FN: 109.0200 - val_loss: 0.2373 - val_Accuracy: 0.9707 - val_Precision: 0.9601 - val_Recall: 0.9471 - val_TP: 761.4800 - val_TN: 1082.0699 - val_FP: 23.9300 - val_FN: 42.5200\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1448 - Accuracy: 0.9867 - Precision: 0.9690 - Recall: 0.9679 - TP: 3263.6201 - TN: 5574.8901 - FP: 72.1100 - FN: 108.3800 - val_loss: 0.2531 - val_Accuracy: 0.9712 - val_Precision: 0.9565 - val_Recall: 0.9535 - val_TP: 766.6400 - val_TN: 1078.9301 - val_FP: 27.0700 - val_FN: 37.3600\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1496 - Accuracy: 0.9851 - Precision: 0.9671 - Recall: 0.9667 - TP: 3259.8201 - TN: 5568.2598 - FP: 78.7400 - FN: 112.1800 - val_loss: 0.2500 - val_Accuracy: 0.9702 - val_Precision: 0.9539 - val_Recall: 0.9543 - val_TP: 767.2600 - val_TN: 1076.7200 - val_FP: 29.2800 - val_FN: 36.7400\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0949 - Accuracy: 0.9863 - Precision: 0.9690 - Recall: 0.9678 - TP: 3263.4800 - TN: 5574.7402 - FP: 72.2600 - FN: 108.5200 - val_loss: 0.2395 - val_Accuracy: 0.9665 - val_Precision: 0.9475 - val_Recall: 0.9553 - val_TP: 768.0300 - val_TN: 1071.2200 - val_FP: 34.7800 - val_FN: 35.9700\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 6ms/step - loss: 0.1908 - Accuracy: 0.9847 - Precision: 0.9657 - Recall: 0.9663 - TP: 3258.2800 - TN: 5563.3198 - FP: 83.6800 - FN: 113.7200 - val_loss: 0.2264 - val_Accuracy: 0.9702 - val_Precision: 0.9617 - val_Recall: 0.9446 - val_TP: 759.4600 - val_TN: 1083.4500 - val_FP: 22.5500 - val_FN: 44.5400\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1269 - Accuracy: 0.9855 - Precision: 0.9680 - Recall: 0.9659 - TP: 3257.1201 - TN: 5571.1699 - FP: 75.8300 - FN: 114.8800 - val_loss: 0.2526 - val_Accuracy: 0.9696 - val_Precision: 0.9508 - val_Recall: 0.9540 - val_TP: 767.0200 - val_TN: 1074.0800 - val_FP: 31.9200 - val_FN: 36.9800\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1649 - Accuracy: 0.9846 - Precision: 0.9668 - Recall: 0.9654 - TP: 3255.3799 - TN: 5567.0400 - FP: 79.9600 - FN: 116.6200 - val_loss: 0.2323 - val_Accuracy: 0.9707 - val_Precision: 0.9578 - val_Recall: 0.9491 - val_TP: 763.0600 - val_TN: 1080.1400 - val_FP: 25.8600 - val_FN: 40.9400\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1366 - Accuracy: 0.9839 - Precision: 0.9664 - Recall: 0.9651 - TP: 3254.3799 - TN: 5565.8701 - FP: 81.1300 - FN: 117.6200 - val_loss: 0.2136 - val_Accuracy: 0.9723 - val_Precision: 0.9649 - val_Recall: 0.9428 - val_TP: 757.9900 - val_TN: 1086.0800 - val_FP: 19.9200 - val_FN: 46.0100\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1840 - Accuracy: 0.9836 - Precision: 0.9663 - Recall: 0.9645 - TP: 3252.3000 - TN: 5565.6001 - FP: 81.4000 - FN: 119.7000 - val_loss: 0.2216 - val_Accuracy: 0.9733 - val_Precision: 0.9625 - val_Recall: 0.9471 - val_TP: 761.5000 - val_TN: 1084.0601 - val_FP: 21.9400 - val_FN: 42.5000\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2086 - Accuracy: 0.9839 - Precision: 0.9639 - Recall: 0.9653 - TP: 3254.9700 - TN: 5557.2700 - FP: 89.7300 - FN: 117.0300 - val_loss: 0.2534 - val_Accuracy: 0.9675 - val_Precision: 0.9639 - val_Recall: 0.9365 - val_TP: 752.9300 - val_TN: 1085.4600 - val_FP: 20.5400 - val_FN: 51.0700\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3506 - Accuracy: 0.9838 - Precision: 0.9658 - Recall: 0.9644 - TP: 3251.8501 - TN: 5563.7002 - FP: 83.3000 - FN: 120.1500 - val_loss: 0.2763 - val_Accuracy: 0.9717 - val_Precision: 0.9668 - val_Recall: 0.9401 - val_TP: 755.8600 - val_TN: 1087.7200 - val_FP: 18.2800 - val_FN: 48.1400\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1612 - Accuracy: 0.9857 - Precision: 0.9676 - Recall: 0.9663 - TP: 3258.3101 - TN: 5570.1499 - FP: 76.8500 - FN: 113.6900 - val_loss: 0.2518 - val_Accuracy: 0.9691 - val_Precision: 0.9572 - val_Recall: 0.9499 - val_TP: 763.7100 - val_TN: 1079.6000 - val_FP: 26.4000 - val_FN: 40.2900\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1664 - Accuracy: 0.9843 - Precision: 0.9672 - Recall: 0.9660 - TP: 3257.5000 - TN: 5569.0898 - FP: 77.9100 - FN: 114.5000 - val_loss: 0.2197 - val_Accuracy: 0.9702 - val_Precision: 0.9521 - val_Recall: 0.9547 - val_TP: 767.6000 - val_TN: 1075.1300 - val_FP: 30.8700 - val_FN: 36.4000\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1008 - Accuracy: 0.9850 - Precision: 0.9675 - Recall: 0.9672 - TP: 3261.2700 - TN: 5569.7900 - FP: 77.2100 - FN: 110.7300 - val_loss: 0.2296 - val_Accuracy: 0.9702 - val_Precision: 0.9640 - val_Recall: 0.9423 - val_TP: 757.6100 - val_TN: 1085.3400 - val_FP: 20.6600 - val_FN: 46.3900\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1171 - Accuracy: 0.9850 - Precision: 0.9675 - Recall: 0.9661 - TP: 3257.7000 - TN: 5569.6499 - FP: 77.3500 - FN: 114.3000 - val_loss: 0.2293 - val_Accuracy: 0.9696 - val_Precision: 0.9434 - val_Recall: 0.9612 - val_TP: 772.8300 - val_TN: 1067.4700 - val_FP: 38.5300 - val_FN: 31.1700\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2215 - Accuracy: 0.9846 - Precision: 0.9678 - Recall: 0.9666 - TP: 3259.3601 - TN: 5570.9399 - FP: 76.0600 - FN: 112.6400 - val_loss: 0.2317 - val_Accuracy: 0.9691 - val_Precision: 0.9599 - val_Recall: 0.9461 - val_TP: 760.6300 - val_TN: 1081.9000 - val_FP: 24.1000 - val_FN: 43.3700\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1625 - Accuracy: 0.9863 - Precision: 0.9690 - Recall: 0.9686 - TP: 3266.0500 - TN: 5575.0200 - FP: 71.9800 - FN: 105.9500 - val_loss: 0.2441 - val_Accuracy: 0.9712 - val_Precision: 0.9569 - val_Recall: 0.9519 - val_TP: 765.3200 - val_TN: 1079.3000 - val_FP: 26.7000 - val_FN: 38.6800\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2556 - Accuracy: 0.9849 - Precision: 0.9669 - Recall: 0.9660 - TP: 3257.2800 - TN: 5567.7100 - FP: 79.2900 - FN: 114.7200 - val_loss: 0.2835 - val_Accuracy: 0.9702 - val_Precision: 0.9558 - val_Recall: 0.9521 - val_TP: 765.5100 - val_TN: 1078.3700 - val_FP: 27.6300 - val_FN: 38.4900\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1495 - Accuracy: 0.9851 - Precision: 0.9672 - Recall: 0.9678 - TP: 3263.4900 - TN: 5568.6602 - FP: 78.3400 - FN: 108.5100 - val_loss: 0.2609 - val_Accuracy: 0.9686 - val_Precision: 0.9749 - val_Recall: 0.9304 - val_TP: 748.0300 - val_TN: 1094.2800 - val_FP: 11.7200 - val_FN: 55.9700\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1318 - Accuracy: 0.9856 - Precision: 0.9682 - Recall: 0.9670 - TP: 3260.7000 - TN: 5572.3101 - FP: 74.6900 - FN: 111.3000 - val_loss: 0.2931 - val_Accuracy: 0.9675 - val_Precision: 0.9522 - val_Recall: 0.9509 - val_TP: 764.5200 - val_TN: 1075.4399 - val_FP: 30.5600 - val_FN: 39.4800\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1782 - Accuracy: 0.9837 - Precision: 0.9669 - Recall: 0.9657 - TP: 3256.3899 - TN: 5567.7300 - FP: 79.2700 - FN: 115.6100 - val_loss: 0.2949 - val_Accuracy: 0.9681 - val_Precision: 0.9464 - val_Recall: 0.9547 - val_TP: 767.5400 - val_TN: 1070.3199 - val_FP: 35.6800 - val_FN: 36.4600\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1754 - Accuracy: 0.9871 - Precision: 0.9695 - Recall: 0.9689 - TP: 3267.0701 - TN: 5576.4800 - FP: 70.5200 - FN: 104.9300 - val_loss: 0.2461 - val_Accuracy: 0.9681 - val_Precision: 0.9666 - val_Recall: 0.9365 - val_TP: 752.9100 - val_TN: 1087.5699 - val_FP: 18.4300 - val_FN: 51.0900\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1049 - Accuracy: 0.9859 - Precision: 0.9685 - Recall: 0.9677 - TP: 3263.1899 - TN: 5573.0898 - FP: 73.9100 - FN: 108.8100 - val_loss: 0.2356 - val_Accuracy: 0.9723 - val_Precision: 0.9713 - val_Recall: 0.9393 - val_TP: 755.2100 - val_TN: 1091.3500 - val_FP: 14.6500 - val_FN: 48.7900\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1367 - Accuracy: 0.9853 - Precision: 0.9679 - Recall: 0.9676 - TP: 3262.6899 - TN: 5571.3599 - FP: 75.6400 - FN: 109.3100 - val_loss: 0.2720 - val_Accuracy: 0.9686 - val_Precision: 0.9772 - val_Recall: 0.9273 - val_TP: 745.5100 - val_TN: 1096.1600 - val_FP: 9.8400 - val_FN: 58.4900\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2326 - Accuracy: 0.9864 - Precision: 0.9696 - Recall: 0.9677 - TP: 3262.9199 - TN: 5577.1001 - FP: 69.9000 - FN: 109.0800 - val_loss: 0.2956 - val_Accuracy: 0.9696 - val_Precision: 0.9481 - val_Recall: 0.9561 - val_TP: 768.7200 - val_TN: 1071.7800 - val_FP: 34.2200 - val_FN: 35.2800\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1120 - Accuracy: 0.9839 - Precision: 0.9672 - Recall: 0.9669 - TP: 3260.3301 - TN: 5568.5698 - FP: 78.4300 - FN: 111.6700 - val_loss: 0.2233 - val_Accuracy: 0.9728 - val_Precision: 0.9657 - val_Recall: 0.9474 - val_TP: 761.7000 - val_TN: 1086.6801 - val_FP: 19.3200 - val_FN: 42.3000\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2425 - Accuracy: 0.9846 - Precision: 0.9674 - Recall: 0.9663 - TP: 3258.2900 - TN: 5569.6201 - FP: 77.3800 - FN: 113.7100 - val_loss: 0.2485 - val_Accuracy: 0.9702 - val_Precision: 0.9635 - val_Recall: 0.9451 - val_TP: 759.9000 - val_TN: 1084.9100 - val_FP: 21.0900 - val_FN: 44.1000\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2557 - Accuracy: 0.9846 - Precision: 0.9663 - Recall: 0.9647 - TP: 3253.1001 - TN: 5565.8999 - FP: 81.1000 - FN: 118.9000 - val_loss: 0.2380 - val_Accuracy: 0.9712 - val_Precision: 0.9480 - val_Recall: 0.9591 - val_TP: 771.1100 - val_TN: 1071.5200 - val_FP: 34.4800 - val_FN: 32.8900\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 6ms/step - loss: 0.1679 - Accuracy: 0.9838 - Precision: 0.9664 - Recall: 0.9658 - TP: 3256.7800 - TN: 5566.1201 - FP: 80.8800 - FN: 115.2200 - val_loss: 0.2231 - val_Accuracy: 0.9712 - val_Precision: 0.9537 - val_Recall: 0.9560 - val_TP: 768.6500 - val_TN: 1076.4900 - val_FP: 29.5100 - val_FN: 35.3500\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1275 - Accuracy: 0.9857 - Precision: 0.9685 - Recall: 0.9670 - TP: 3260.6001 - TN: 5573.2998 - FP: 73.7000 - FN: 111.4000 - val_loss: 0.2195 - val_Accuracy: 0.9733 - val_Precision: 0.9550 - val_Recall: 0.9566 - val_TP: 769.1200 - val_TN: 1077.5800 - val_FP: 28.4200 - val_FN: 34.8800\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1992 - Accuracy: 0.9834 - Precision: 0.9659 - Recall: 0.9656 - TP: 3256.0000 - TN: 5564.2002 - FP: 82.8000 - FN: 116.0000 - val_loss: 0.2659 - val_Accuracy: 0.9681 - val_Precision: 0.9458 - val_Recall: 0.9571 - val_TP: 769.5200 - val_TN: 1069.7300 - val_FP: 36.2700 - val_FN: 34.4800\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1026 - Accuracy: 0.9858 - Precision: 0.9679 - Recall: 0.9680 - TP: 3264.0200 - TN: 5571.0698 - FP: 75.9300 - FN: 107.9800 - val_loss: 0.2276 - val_Accuracy: 0.9743 - val_Precision: 0.9683 - val_Recall: 0.9451 - val_TP: 759.8800 - val_TN: 1088.7900 - val_FP: 17.2100 - val_FN: 44.1200\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0904 - Accuracy: 0.9870 - Precision: 0.9702 - Recall: 0.9693 - TP: 3268.4900 - TN: 5578.8198 - FP: 68.1800 - FN: 103.5100 - val_loss: 0.2234 - val_Accuracy: 0.9728 - val_Precision: 0.9648 - val_Recall: 0.9434 - val_TP: 758.5100 - val_TN: 1085.9399 - val_FP: 20.0600 - val_FN: 45.4900\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1679 - Accuracy: 0.9844 - Precision: 0.9672 - Recall: 0.9665 - TP: 3258.9600 - TN: 5568.5801 - FP: 78.4200 - FN: 113.0400 - val_loss: 0.2266 - val_Accuracy: 0.9733 - val_Precision: 0.9694 - val_Recall: 0.9436 - val_TP: 758.6800 - val_TN: 1089.7400 - val_FP: 16.2600 - val_FN: 45.3200\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1476 - Accuracy: 0.9850 - Precision: 0.9669 - Recall: 0.9660 - TP: 3257.4800 - TN: 5567.7202 - FP: 79.2800 - FN: 114.5200 - val_loss: 0.2243 - val_Accuracy: 0.9712 - val_Precision: 0.9592 - val_Recall: 0.9471 - val_TP: 761.4600 - val_TN: 1081.3000 - val_FP: 24.7000 - val_FN: 42.5400\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1463 - Accuracy: 0.9859 - Precision: 0.9690 - Recall: 0.9677 - TP: 3263.2400 - TN: 5574.7500 - FP: 72.2500 - FN: 108.7600 - val_loss: 0.2397 - val_Accuracy: 0.9696 - val_Precision: 0.9647 - val_Recall: 0.9405 - val_TP: 756.2000 - val_TN: 1086.0000 - val_FP: 20.0000 - val_FN: 47.8000\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0733 - Accuracy: 0.9858 - Precision: 0.9687 - Recall: 0.9683 - TP: 3265.1299 - TN: 5573.8301 - FP: 73.1700 - FN: 106.8700 - val_loss: 0.2385 - val_Accuracy: 0.9707 - val_Precision: 0.9702 - val_Recall: 0.9380 - val_TP: 754.1300 - val_TN: 1090.4200 - val_FP: 15.5800 - val_FN: 49.8700\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0883 - Accuracy: 0.9856 - Precision: 0.9686 - Recall: 0.9669 - TP: 3260.5300 - TN: 5573.5400 - FP: 73.4600 - FN: 111.4700 - val_loss: 0.2082 - val_Accuracy: 0.9749 - val_Precision: 0.9608 - val_Recall: 0.9552 - val_TP: 768.0200 - val_TN: 1082.4500 - val_FP: 23.5500 - val_FN: 35.9800\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2195 - Accuracy: 0.9830 - Precision: 0.9659 - Recall: 0.9644 - TP: 3252.0100 - TN: 5564.5298 - FP: 82.4700 - FN: 119.9900 - val_loss: 0.2331 - val_Accuracy: 0.9702 - val_Precision: 0.9437 - val_Recall: 0.9617 - val_TP: 773.1700 - val_TN: 1067.7600 - val_FP: 38.2400 - val_FN: 30.8300\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1850 - Accuracy: 0.9853 - Precision: 0.9676 - Recall: 0.9674 - TP: 3261.9600 - TN: 5570.3501 - FP: 76.6500 - FN: 110.0400 - val_loss: 0.2740 - val_Accuracy: 0.9691 - val_Precision: 0.9564 - val_Recall: 0.9490 - val_TP: 763.0200 - val_TN: 1079.0000 - val_FP: 27.0000 - val_FN: 40.9800\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1886 - Accuracy: 0.9849 - Precision: 0.9664 - Recall: 0.9663 - TP: 3258.4199 - TN: 5565.9399 - FP: 81.0600 - FN: 113.5800 - val_loss: 0.3630 - val_Accuracy: 0.9654 - val_Precision: 0.9445 - val_Recall: 0.9531 - val_TP: 766.2800 - val_TN: 1068.8600 - val_FP: 37.1400 - val_FN: 37.7200\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1433 - Accuracy: 0.9851 - Precision: 0.9681 - Recall: 0.9676 - TP: 3262.7800 - TN: 5571.9102 - FP: 75.0900 - FN: 109.2200 - val_loss: 0.2752 - val_Accuracy: 0.9681 - val_Precision: 0.9743 - val_Recall: 0.9279 - val_TP: 746.0000 - val_TN: 1093.9200 - val_FP: 12.0800 - val_FN: 58.0000\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2474 - Accuracy: 0.9823 - Precision: 0.9651 - Recall: 0.9630 - TP: 3247.2000 - TN: 5562.0898 - FP: 84.9100 - FN: 124.8000 - val_loss: 0.2689 - val_Accuracy: 0.9728 - val_Precision: 0.9611 - val_Recall: 0.9501 - val_TP: 763.8900 - val_TN: 1082.8700 - val_FP: 23.1300 - val_FN: 40.1100\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1336 - Accuracy: 0.9854 - Precision: 0.9676 - Recall: 0.9677 - TP: 3262.9900 - TN: 5569.9702 - FP: 77.0300 - FN: 109.0100 - val_loss: 0.2719 - val_Accuracy: 0.9686 - val_Precision: 0.9493 - val_Recall: 0.9541 - val_TP: 767.0600 - val_TN: 1072.8500 - val_FP: 33.1500 - val_FN: 36.9400\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1619 - Accuracy: 0.9863 - Precision: 0.9683 - Recall: 0.9677 - TP: 3262.9299 - TN: 5572.5801 - FP: 74.4200 - FN: 109.0700 - val_loss: 0.2266 - val_Accuracy: 0.9733 - val_Precision: 0.9609 - val_Recall: 0.9519 - val_TP: 765.3300 - val_TN: 1082.6200 - val_FP: 23.3800 - val_FN: 38.6700\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1336 - Accuracy: 0.9860 - Precision: 0.9689 - Recall: 0.9678 - TP: 3263.3401 - TN: 5574.3301 - FP: 72.6700 - FN: 108.6600 - val_loss: 0.5776 - val_Accuracy: 0.9346 - val_Precision: 0.8728 - val_Recall: 0.9594 - val_TP: 771.3400 - val_TN: 1001.9600 - val_FP: 104.0400 - val_FN: 32.6600\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2114 - Accuracy: 0.9836 - Precision: 0.9666 - Recall: 0.9658 - TP: 3256.5300 - TN: 5566.7700 - FP: 80.2300 - FN: 115.4700 - val_loss: 0.2250 - val_Accuracy: 0.9733 - val_Precision: 0.9562 - val_Recall: 0.9580 - val_TP: 770.2000 - val_TN: 1078.5100 - val_FP: 27.4900 - val_FN: 33.8000\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1826 - Accuracy: 0.9841 - Precision: 0.9672 - Recall: 0.9666 - TP: 3259.3701 - TN: 5569.0698 - FP: 77.9300 - FN: 112.6300 - val_loss: 0.2318 - val_Accuracy: 0.9717 - val_Precision: 0.9601 - val_Recall: 0.9529 - val_TP: 766.1200 - val_TN: 1081.9900 - val_FP: 24.0100 - val_FN: 37.8800\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1832 - Accuracy: 0.9848 - Precision: 0.9663 - Recall: 0.9663 - TP: 3258.5100 - TN: 5565.7700 - FP: 81.2300 - FN: 113.4900 - val_loss: 0.2852 - val_Accuracy: 0.9733 - val_Precision: 0.9571 - val_Recall: 0.9522 - val_TP: 765.5700 - val_TN: 1079.4500 - val_FP: 26.5500 - val_FN: 38.4300\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2391 - Accuracy: 0.9860 - Precision: 0.9688 - Recall: 0.9661 - TP: 3257.7900 - TN: 5574.6299 - FP: 72.3700 - FN: 114.2100 - val_loss: 0.2330 - val_Accuracy: 0.9723 - val_Precision: 0.9486 - val_Recall: 0.9634 - val_TP: 774.6000 - val_TN: 1071.8900 - val_FP: 34.1100 - val_FN: 29.4000\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3074 - Accuracy: 0.9835 - Precision: 0.9644 - Recall: 0.9656 - TP: 3256.1101 - TN: 5558.8501 - FP: 88.1500 - FN: 115.8900 - val_loss: 0.2786 - val_Accuracy: 0.9670 - val_Precision: 0.9496 - val_Recall: 0.9527 - val_TP: 765.9500 - val_TN: 1073.1600 - val_FP: 32.8400 - val_FN: 38.0500\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0930 - Accuracy: 0.9875 - Precision: 0.9702 - Recall: 0.9696 - TP: 3269.5400 - TN: 5579.1699 - FP: 67.8300 - FN: 102.4600 - val_loss: 0.2656 - val_Accuracy: 0.9691 - val_Precision: 0.9577 - val_Recall: 0.9486 - val_TP: 762.6400 - val_TN: 1080.1200 - val_FP: 25.8800 - val_FN: 41.3600\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1107 - Accuracy: 0.9860 - Precision: 0.9690 - Recall: 0.9681 - TP: 3264.5200 - TN: 5575.1802 - FP: 71.8200 - FN: 107.4800 - val_loss: 0.3415 - val_Accuracy: 0.9675 - val_Precision: 0.9436 - val_Recall: 0.9575 - val_TP: 769.8100 - val_TN: 1067.9399 - val_FP: 38.0600 - val_FN: 34.1900\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1472 - Accuracy: 0.9830 - Precision: 0.9655 - Recall: 0.9654 - TP: 3255.2600 - TN: 5563.0400 - FP: 83.9600 - FN: 116.7400 - val_loss: 0.2339 - val_Accuracy: 0.9743 - val_Precision: 0.9605 - val_Recall: 0.9530 - val_TP: 766.2300 - val_TN: 1082.2900 - val_FP: 23.7100 - val_FN: 37.7700\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1743 - Accuracy: 0.9874 - Precision: 0.9706 - Recall: 0.9690 - TP: 3267.5000 - TN: 5580.2798 - FP: 66.7200 - FN: 104.5000 - val_loss: 0.2660 - val_Accuracy: 0.9691 - val_Precision: 0.9514 - val_Recall: 0.9528 - val_TP: 766.0300 - val_TN: 1074.6899 - val_FP: 31.3100 - val_FN: 37.9700\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1102 - Accuracy: 0.9876 - Precision: 0.9704 - Recall: 0.9701 - TP: 3271.2700 - TN: 5579.7798 - FP: 67.2200 - FN: 100.7300 - val_loss: 0.2902 - val_Accuracy: 0.9707 - val_Precision: 0.9643 - val_Recall: 0.9434 - val_TP: 758.4900 - val_TN: 1085.6400 - val_FP: 20.3600 - val_FN: 45.5100\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1262 - Accuracy: 0.9870 - Precision: 0.9704 - Recall: 0.9693 - TP: 3268.5300 - TN: 5579.8198 - FP: 67.1800 - FN: 103.4700 - val_loss: 0.3015 - val_Accuracy: 0.9681 - val_Precision: 0.9496 - val_Recall: 0.9522 - val_TP: 765.6000 - val_TN: 1073.1899 - val_FP: 32.8100 - val_FN: 38.4000\n",
      "Epoch 30/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1200 - Accuracy: 0.9855 - Precision: 0.9679 - Recall: 0.9675 - TP: 3262.4199 - TN: 5571.0601 - FP: 75.9400 - FN: 109.5800 - val_loss: 0.2586 - val_Accuracy: 0.9670 - val_Precision: 0.9478 - val_Recall: 0.9525 - val_TP: 765.8400 - val_TN: 1071.6400 - val_FP: 34.3600 - val_FN: 38.1600\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 7ms/step - loss: 0.1396 - Accuracy: 0.9863 - Precision: 0.9689 - Recall: 0.9678 - TP: 3263.3999 - TN: 5574.4302 - FP: 72.5700 - FN: 108.6000 - val_loss: 0.2450 - val_Accuracy: 0.9691 - val_Precision: 0.9546 - val_Recall: 0.9461 - val_TP: 760.6800 - val_TN: 1077.5200 - val_FP: 28.4800 - val_FN: 43.3200\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1812 - Accuracy: 0.9837 - Precision: 0.9663 - Recall: 0.9661 - TP: 3257.8101 - TN: 5565.6602 - FP: 81.3400 - FN: 114.1900 - val_loss: 0.2285 - val_Accuracy: 0.9717 - val_Precision: 0.9671 - val_Recall: 0.9423 - val_TP: 757.6000 - val_TN: 1087.9301 - val_FP: 18.0700 - val_FN: 46.4000\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2462 - Accuracy: 0.9840 - Precision: 0.9657 - Recall: 0.9648 - TP: 3253.2000 - TN: 5563.4199 - FP: 83.5800 - FN: 118.8000 - val_loss: 0.2923 - val_Accuracy: 0.9675 - val_Precision: 0.9501 - val_Recall: 0.9530 - val_TP: 766.1800 - val_TN: 1073.5300 - val_FP: 32.4700 - val_FN: 37.8200\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0932 - Accuracy: 0.9864 - Precision: 0.9688 - Recall: 0.9678 - TP: 3263.5601 - TN: 5574.1699 - FP: 72.8300 - FN: 108.4400 - val_loss: 0.2310 - val_Accuracy: 0.9733 - val_Precision: 0.9671 - val_Recall: 0.9451 - val_TP: 759.8800 - val_TN: 1087.8500 - val_FP: 18.1500 - val_FN: 44.1200\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0897 - Accuracy: 0.9866 - Precision: 0.9695 - Recall: 0.9684 - TP: 3265.3899 - TN: 5576.6001 - FP: 70.4000 - FN: 106.6100 - val_loss: 0.2337 - val_Accuracy: 0.9686 - val_Precision: 0.9560 - val_Recall: 0.9507 - val_TP: 764.3900 - val_TN: 1078.6100 - val_FP: 27.3900 - val_FN: 39.6100\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1813 - Accuracy: 0.9836 - Precision: 0.9666 - Recall: 0.9654 - TP: 3255.3799 - TN: 5566.8701 - FP: 80.1300 - FN: 116.6200 - val_loss: 0.2262 - val_Accuracy: 0.9717 - val_Precision: 0.9563 - val_Recall: 0.9551 - val_TP: 767.9300 - val_TN: 1078.7100 - val_FP: 27.2900 - val_FN: 36.0700\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3041 - Accuracy: 0.9848 - Precision: 0.9673 - Recall: 0.9655 - TP: 3255.7800 - TN: 5568.9800 - FP: 78.0200 - FN: 116.2200 - val_loss: 0.2483 - val_Accuracy: 0.9686 - val_Precision: 0.9459 - val_Recall: 0.9557 - val_TP: 768.3800 - val_TN: 1069.8600 - val_FP: 36.1400 - val_FN: 35.6200\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0912 - Accuracy: 0.9860 - Precision: 0.9675 - Recall: 0.9683 - TP: 3265.2400 - TN: 5569.7998 - FP: 77.2000 - FN: 106.7600 - val_loss: 0.2731 - val_Accuracy: 0.9670 - val_Precision: 0.9546 - val_Recall: 0.9468 - val_TP: 761.2600 - val_TN: 1077.5900 - val_FP: 28.4100 - val_FN: 42.7400\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0876 - Accuracy: 0.9859 - Precision: 0.9694 - Recall: 0.9678 - TP: 3263.3201 - TN: 5576.0400 - FP: 70.9600 - FN: 108.6800 - val_loss: 0.2362 - val_Accuracy: 0.9712 - val_Precision: 0.9580 - val_Recall: 0.9500 - val_TP: 763.7700 - val_TN: 1080.3000 - val_FP: 25.7000 - val_FN: 40.2300\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1587 - Accuracy: 0.9857 - Precision: 0.9675 - Recall: 0.9668 - TP: 3260.0300 - TN: 5569.8599 - FP: 77.1400 - FN: 111.9700 - val_loss: 0.2491 - val_Accuracy: 0.9691 - val_Precision: 0.9517 - val_Recall: 0.9520 - val_TP: 765.3900 - val_TN: 1074.9500 - val_FP: 31.0500 - val_FN: 38.6100\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0902 - Accuracy: 0.9868 - Precision: 0.9697 - Recall: 0.9689 - TP: 3267.2800 - TN: 5577.3101 - FP: 69.6900 - FN: 104.7200 - val_loss: 0.2267 - val_Accuracy: 0.9749 - val_Precision: 0.9644 - val_Recall: 0.9500 - val_TP: 763.8300 - val_TN: 1085.4800 - val_FP: 20.5200 - val_FN: 40.1700\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1437 - Accuracy: 0.9856 - Precision: 0.9680 - Recall: 0.9673 - TP: 3261.7800 - TN: 5571.5498 - FP: 75.4500 - FN: 110.2200 - val_loss: 0.2445 - val_Accuracy: 0.9686 - val_Precision: 0.9513 - val_Recall: 0.9525 - val_TP: 765.8000 - val_TN: 1074.5500 - val_FP: 31.4500 - val_FN: 38.2000\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1499 - Accuracy: 0.9849 - Precision: 0.9675 - Recall: 0.9671 - TP: 3261.0901 - TN: 5569.8701 - FP: 77.1300 - FN: 110.9100 - val_loss: 0.2814 - val_Accuracy: 0.9691 - val_Precision: 0.9501 - val_Recall: 0.9554 - val_TP: 768.1300 - val_TN: 1073.5100 - val_FP: 32.4900 - val_FN: 35.8700\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1322 - Accuracy: 0.9869 - Precision: 0.9696 - Recall: 0.9685 - TP: 3265.8899 - TN: 5576.9702 - FP: 70.0300 - FN: 106.1100 - val_loss: 0.2452 - val_Accuracy: 0.9675 - val_Precision: 0.9410 - val_Recall: 0.9585 - val_TP: 770.6300 - val_TN: 1065.4800 - val_FP: 40.5200 - val_FN: 33.3700\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1452 - Accuracy: 0.9855 - Precision: 0.9682 - Recall: 0.9676 - TP: 3262.7500 - TN: 5572.0898 - FP: 74.9100 - FN: 109.2500 - val_loss: 0.2361 - val_Accuracy: 0.9743 - val_Precision: 0.9682 - val_Recall: 0.9464 - val_TP: 760.9400 - val_TN: 1088.7400 - val_FP: 17.2600 - val_FN: 43.0600\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1193 - Accuracy: 0.9860 - Precision: 0.9691 - Recall: 0.9678 - TP: 3263.4399 - TN: 5575.2998 - FP: 71.7000 - FN: 108.5600 - val_loss: 0.2649 - val_Accuracy: 0.9717 - val_Precision: 0.9585 - val_Recall: 0.9522 - val_TP: 765.6000 - val_TN: 1080.6500 - val_FP: 25.3500 - val_FN: 38.4000\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1766 - Accuracy: 0.9850 - Precision: 0.9687 - Recall: 0.9683 - TP: 3265.1899 - TN: 5574.0801 - FP: 72.9200 - FN: 106.8100 - val_loss: 0.2892 - val_Accuracy: 0.9707 - val_Precision: 0.9498 - val_Recall: 0.9571 - val_TP: 769.4700 - val_TN: 1073.2000 - val_FP: 32.8000 - val_FN: 34.5300\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1785 - Accuracy: 0.9854 - Precision: 0.9683 - Recall: 0.9675 - TP: 3262.3501 - TN: 5572.3999 - FP: 74.6000 - FN: 109.6500 - val_loss: 0.2657 - val_Accuracy: 0.9702 - val_Precision: 0.9471 - val_Recall: 0.9594 - val_TP: 771.3600 - val_TN: 1070.7900 - val_FP: 35.2100 - val_FN: 32.6400\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0811 - Accuracy: 0.9884 - Precision: 0.9718 - Recall: 0.9710 - TP: 3274.3301 - TN: 5584.6699 - FP: 62.3300 - FN: 97.6700 - val_loss: 0.2449 - val_Accuracy: 0.9696 - val_Precision: 0.9504 - val_Recall: 0.9543 - val_TP: 767.2400 - val_TN: 1073.8300 - val_FP: 32.1700 - val_FN: 36.7600\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3100 - Accuracy: 0.9824 - Precision: 0.9649 - Recall: 0.9649 - TP: 3253.7000 - TN: 5561.0098 - FP: 85.9900 - FN: 118.3000 - val_loss: 0.3913 - val_Accuracy: 0.9644 - val_Precision: 0.9480 - val_Recall: 0.9436 - val_TP: 758.6700 - val_TN: 1072.1300 - val_FP: 33.8700 - val_FN: 45.3300\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2274 - Accuracy: 0.9838 - Precision: 0.9674 - Recall: 0.9651 - TP: 3254.3899 - TN: 5569.8901 - FP: 77.1100 - FN: 117.6100 - val_loss: 0.2361 - val_Accuracy: 0.9733 - val_Precision: 0.9619 - val_Recall: 0.9530 - val_TP: 766.1900 - val_TN: 1083.4900 - val_FP: 22.5100 - val_FN: 37.8100\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1253 - Accuracy: 0.9863 - Precision: 0.9683 - Recall: 0.9684 - TP: 3265.4199 - TN: 5572.4302 - FP: 74.5700 - FN: 106.5800 - val_loss: 0.2861 - val_Accuracy: 0.9691 - val_Precision: 0.9555 - val_Recall: 0.9528 - val_TP: 766.0900 - val_TN: 1078.1600 - val_FP: 27.8400 - val_FN: 37.9100\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2340 - Accuracy: 0.9850 - Precision: 0.9675 - Recall: 0.9676 - TP: 3262.8101 - TN: 5569.9800 - FP: 77.0200 - FN: 109.1900 - val_loss: 0.2553 - val_Accuracy: 0.9717 - val_Precision: 0.9616 - val_Recall: 0.9480 - val_TP: 762.1700 - val_TN: 1083.3400 - val_FP: 22.6600 - val_FN: 41.8300\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1692 - Accuracy: 0.9855 - Precision: 0.9688 - Recall: 0.9677 - TP: 3263.0500 - TN: 5574.4600 - FP: 72.5400 - FN: 108.9500 - val_loss: 0.2853 - val_Accuracy: 0.9712 - val_Precision: 0.9587 - val_Recall: 0.9522 - val_TP: 765.5400 - val_TN: 1080.8500 - val_FP: 25.1500 - val_FN: 38.4600\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2329 - Accuracy: 0.9841 - Precision: 0.9659 - Recall: 0.9651 - TP: 3254.4500 - TN: 5564.3999 - FP: 82.6000 - FN: 117.5500 - val_loss: 0.2471 - val_Accuracy: 0.9717 - val_Precision: 0.9620 - val_Recall: 0.9517 - val_TP: 765.1700 - val_TN: 1083.6100 - val_FP: 22.3900 - val_FN: 38.8300\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2414 - Accuracy: 0.9826 - Precision: 0.9662 - Recall: 0.9655 - TP: 3255.7200 - TN: 5565.8398 - FP: 81.1600 - FN: 116.2800 - val_loss: 0.3150 - val_Accuracy: 0.9717 - val_Precision: 0.9533 - val_Recall: 0.9542 - val_TP: 767.2100 - val_TN: 1076.3000 - val_FP: 29.7000 - val_FN: 36.7900\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 6ms/step - loss: 0.1823 - Accuracy: 0.9835 - Precision: 0.9670 - Recall: 0.9652 - TP: 3254.7900 - TN: 5568.3101 - FP: 78.6900 - FN: 117.2100 - val_loss: 0.2274 - val_Accuracy: 0.9696 - val_Precision: 0.9475 - val_Recall: 0.9592 - val_TP: 771.1900 - val_TN: 1071.1100 - val_FP: 34.8900 - val_FN: 32.8100\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1392 - Accuracy: 0.9843 - Precision: 0.9673 - Recall: 0.9672 - TP: 3261.2800 - TN: 5569.0698 - FP: 77.9300 - FN: 110.7200 - val_loss: 0.2655 - val_Accuracy: 0.9691 - val_Precision: 0.9408 - val_Recall: 0.9622 - val_TP: 773.6200 - val_TN: 1065.3000 - val_FP: 40.7000 - val_FN: 30.3800\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1369 - Accuracy: 0.9855 - Precision: 0.9685 - Recall: 0.9677 - TP: 3263.2200 - TN: 5573.3799 - FP: 73.6200 - FN: 108.7800 - val_loss: 0.2344 - val_Accuracy: 0.9712 - val_Precision: 0.9578 - val_Recall: 0.9513 - val_TP: 764.8600 - val_TN: 1080.0100 - val_FP: 25.9900 - val_FN: 39.1400\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1740 - Accuracy: 0.9854 - Precision: 0.9674 - Recall: 0.9676 - TP: 3262.7100 - TN: 5569.5801 - FP: 77.4200 - FN: 109.2900 - val_loss: 0.3202 - val_Accuracy: 0.9696 - val_Precision: 0.9625 - val_Recall: 0.9392 - val_TP: 755.0900 - val_TN: 1084.2800 - val_FP: 21.7200 - val_FN: 48.9100\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.4389 - Accuracy: 0.9815 - Precision: 0.9634 - Recall: 0.9621 - TP: 3244.1299 - TN: 5555.9302 - FP: 91.0700 - FN: 127.8700 - val_loss: 0.2474 - val_Accuracy: 0.9728 - val_Precision: 0.9659 - val_Recall: 0.9445 - val_TP: 759.3400 - val_TN: 1086.9200 - val_FP: 19.0800 - val_FN: 44.6600\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1343 - Accuracy: 0.9845 - Precision: 0.9671 - Recall: 0.9664 - TP: 3258.7300 - TN: 5568.6299 - FP: 78.3700 - FN: 113.2700 - val_loss: 0.2641 - val_Accuracy: 0.9686 - val_Precision: 0.9540 - val_Recall: 0.9515 - val_TP: 765.0400 - val_TN: 1076.9600 - val_FP: 29.0400 - val_FN: 38.9600\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1476 - Accuracy: 0.9864 - Precision: 0.9687 - Recall: 0.9687 - TP: 3266.2900 - TN: 5573.7002 - FP: 73.3000 - FN: 105.7100 - val_loss: 0.2318 - val_Accuracy: 0.9733 - val_Precision: 0.9622 - val_Recall: 0.9507 - val_TP: 764.3300 - val_TN: 1083.6801 - val_FP: 22.3200 - val_FN: 39.6700\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1523 - Accuracy: 0.9853 - Precision: 0.9683 - Recall: 0.9678 - TP: 3263.3201 - TN: 5572.3901 - FP: 74.6100 - FN: 108.6800 - val_loss: 0.2475 - val_Accuracy: 0.9723 - val_Precision: 0.9669 - val_Recall: 0.9427 - val_TP: 757.9300 - val_TN: 1087.7400 - val_FP: 18.2600 - val_FN: 46.0700\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0778 - Accuracy: 0.9859 - Precision: 0.9696 - Recall: 0.9684 - TP: 3265.5100 - TN: 5576.9702 - FP: 70.0300 - FN: 106.4900 - val_loss: 0.3949 - val_Accuracy: 0.9654 - val_Precision: 0.9498 - val_Recall: 0.9449 - val_TP: 759.7000 - val_TN: 1073.6801 - val_FP: 32.3200 - val_FN: 44.3000\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2022 - Accuracy: 0.9840 - Precision: 0.9664 - Recall: 0.9653 - TP: 3254.9800 - TN: 5566.2100 - FP: 80.7900 - FN: 117.0200 - val_loss: 0.2755 - val_Accuracy: 0.9712 - val_Precision: 0.9579 - val_Recall: 0.9489 - val_TP: 762.8900 - val_TN: 1080.2400 - val_FP: 25.7600 - val_FN: 41.1100\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2662 - Accuracy: 0.9837 - Precision: 0.9667 - Recall: 0.9661 - TP: 3257.5601 - TN: 5567.2300 - FP: 79.7700 - FN: 114.4400 - val_loss: 0.2980 - val_Accuracy: 0.9686 - val_Precision: 0.9542 - val_Recall: 0.9513 - val_TP: 764.8500 - val_TN: 1077.1500 - val_FP: 28.8500 - val_FN: 39.1500\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1815 - Accuracy: 0.9834 - Precision: 0.9664 - Recall: 0.9657 - TP: 3256.3601 - TN: 5566.4302 - FP: 80.5700 - FN: 115.6400 - val_loss: 0.2552 - val_Accuracy: 0.9702 - val_Precision: 0.9617 - val_Recall: 0.9473 - val_TP: 761.5900 - val_TN: 1083.4500 - val_FP: 22.5500 - val_FN: 42.4100\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1820 - Accuracy: 0.9841 - Precision: 0.9676 - Recall: 0.9661 - TP: 3257.7300 - TN: 5570.6099 - FP: 76.3900 - FN: 114.2700 - val_loss: 0.3150 - val_Accuracy: 0.9639 - val_Precision: 0.9307 - val_Recall: 0.9637 - val_TP: 774.8000 - val_TN: 1056.2600 - val_FP: 49.7400 - val_FN: 29.2000\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1614 - Accuracy: 0.9872 - Precision: 0.9691 - Recall: 0.9689 - TP: 3267.2600 - TN: 5575.3398 - FP: 71.6600 - FN: 104.7400 - val_loss: 0.2650 - val_Accuracy: 0.9707 - val_Precision: 0.9606 - val_Recall: 0.9463 - val_TP: 760.8300 - val_TN: 1082.5699 - val_FP: 23.4300 - val_FN: 43.1700\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2937 - Accuracy: 0.9814 - Precision: 0.9644 - Recall: 0.9639 - TP: 3250.4099 - TN: 5559.2402 - FP: 87.7600 - FN: 121.5900 - val_loss: 0.2559 - val_Accuracy: 0.9723 - val_Precision: 0.9566 - val_Recall: 0.9525 - val_TP: 765.8100 - val_TN: 1079.1200 - val_FP: 26.8800 - val_FN: 38.1900\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1206 - Accuracy: 0.9866 - Precision: 0.9687 - Recall: 0.9683 - TP: 3264.9900 - TN: 5574.1602 - FP: 72.8400 - FN: 107.0100 - val_loss: 0.2686 - val_Accuracy: 0.9681 - val_Precision: 0.9524 - val_Recall: 0.9518 - val_TP: 765.2300 - val_TN: 1075.6000 - val_FP: 30.4000 - val_FN: 38.7700\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1620 - Accuracy: 0.9848 - Precision: 0.9677 - Recall: 0.9672 - TP: 3261.4399 - TN: 5570.7402 - FP: 76.2600 - FN: 110.5600 - val_loss: 0.3257 - val_Accuracy: 0.9702 - val_Precision: 0.9582 - val_Recall: 0.9464 - val_TP: 760.8700 - val_TN: 1080.6200 - val_FP: 25.3800 - val_FN: 43.1300\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1748 - Accuracy: 0.9857 - Precision: 0.9689 - Recall: 0.9677 - TP: 3263.0400 - TN: 5574.8301 - FP: 72.1700 - FN: 108.9600 - val_loss: 0.3196 - val_Accuracy: 0.9691 - val_Precision: 0.9478 - val_Recall: 0.9574 - val_TP: 769.7200 - val_TN: 1071.5300 - val_FP: 34.4700 - val_FN: 34.2800\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0886 - Accuracy: 0.9870 - Precision: 0.9696 - Recall: 0.9703 - TP: 3271.9800 - TN: 5576.7998 - FP: 70.2000 - FN: 100.0200 - val_loss: 0.2816 - val_Accuracy: 0.9681 - val_Precision: 0.9572 - val_Recall: 0.9477 - val_TP: 761.9300 - val_TN: 1079.7600 - val_FP: 26.2400 - val_FN: 42.0700\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2580 - Accuracy: 0.9844 - Precision: 0.9671 - Recall: 0.9655 - TP: 3255.5901 - TN: 5568.7402 - FP: 78.2600 - FN: 116.4100 - val_loss: 0.7222 - val_Accuracy: 0.9346 - val_Precision: 0.8752 - val_Recall: 0.9605 - val_TP: 772.2700 - val_TN: 1004.4000 - val_FP: 101.6000 - val_FN: 31.7300\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2123 - Accuracy: 0.9845 - Precision: 0.9676 - Recall: 0.9669 - TP: 3260.4199 - TN: 5570.3701 - FP: 76.6300 - FN: 111.5800 - val_loss: 0.2707 - val_Accuracy: 0.9712 - val_Precision: 0.9649 - val_Recall: 0.9437 - val_TP: 758.7400 - val_TN: 1086.1400 - val_FP: 19.8600 - val_FN: 45.2600\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 6ms/step - loss: 0.2237 - Accuracy: 0.9838 - Precision: 0.9640 - Recall: 0.9658 - TP: 3256.7700 - TN: 5557.6401 - FP: 89.3600 - FN: 115.2300 - val_loss: 0.2660 - val_Accuracy: 0.9712 - val_Precision: 0.9604 - val_Recall: 0.9448 - val_TP: 759.5900 - val_TN: 1082.4800 - val_FP: 23.5200 - val_FN: 44.4100\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1961 - Accuracy: 0.9845 - Precision: 0.9695 - Recall: 0.9657 - TP: 3256.3701 - TN: 5577.2500 - FP: 69.7500 - FN: 115.6300 - val_loss: 0.2449 - val_Accuracy: 0.9712 - val_Precision: 0.9647 - val_Recall: 0.9466 - val_TP: 761.0800 - val_TN: 1085.8800 - val_FP: 20.1200 - val_FN: 42.9200\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.5740 - Accuracy: 0.9824 - Precision: 0.9642 - Recall: 0.9642 - TP: 3251.1899 - TN: 5558.9399 - FP: 88.0600 - FN: 120.8100 - val_loss: 0.2442 - val_Accuracy: 0.9691 - val_Precision: 0.9532 - val_Recall: 0.9540 - val_TP: 767.0200 - val_TN: 1076.2000 - val_FP: 29.8000 - val_FN: 36.9800\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1240 - Accuracy: 0.9850 - Precision: 0.9672 - Recall: 0.9670 - TP: 3260.7800 - TN: 5568.7998 - FP: 78.2000 - FN: 111.2200 - val_loss: 0.3148 - val_Accuracy: 0.9681 - val_Precision: 0.9504 - val_Recall: 0.9496 - val_TP: 763.5000 - val_TN: 1073.9600 - val_FP: 32.0400 - val_FN: 40.5000\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2159 - Accuracy: 0.9841 - Precision: 0.9667 - Recall: 0.9656 - TP: 3256.1699 - TN: 5567.3398 - FP: 79.6600 - FN: 115.8300 - val_loss: 0.2465 - val_Accuracy: 0.9733 - val_Precision: 0.9635 - val_Recall: 0.9468 - val_TP: 761.2500 - val_TN: 1084.9000 - val_FP: 21.1000 - val_FN: 42.7500\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1562 - Accuracy: 0.9851 - Precision: 0.9682 - Recall: 0.9669 - TP: 3260.5400 - TN: 5572.5498 - FP: 74.4500 - FN: 111.4600 - val_loss: 0.2508 - val_Accuracy: 0.9681 - val_Precision: 0.9547 - val_Recall: 0.9475 - val_TP: 761.7900 - val_TN: 1077.5900 - val_FP: 28.4100 - val_FN: 42.2100\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1302 - Accuracy: 0.9850 - Precision: 0.9672 - Recall: 0.9669 - TP: 3260.3799 - TN: 5568.8198 - FP: 78.1800 - FN: 111.6200 - val_loss: 0.2562 - val_Accuracy: 0.9686 - val_Precision: 0.9508 - val_Recall: 0.9523 - val_TP: 765.6600 - val_TN: 1074.2500 - val_FP: 31.7500 - val_FN: 38.3400\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2124 - Accuracy: 0.9853 - Precision: 0.9674 - Recall: 0.9667 - TP: 3259.6499 - TN: 5569.3101 - FP: 77.6900 - FN: 112.3500 - val_loss: 0.2886 - val_Accuracy: 0.9702 - val_Precision: 0.9646 - val_Recall: 0.9417 - val_TP: 757.1000 - val_TN: 1085.9100 - val_FP: 20.0900 - val_FN: 46.9000\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1270 - Accuracy: 0.9858 - Precision: 0.9685 - Recall: 0.9676 - TP: 3262.7700 - TN: 5573.2500 - FP: 73.7500 - FN: 109.2300 - val_loss: 0.2447 - val_Accuracy: 0.9702 - val_Precision: 0.9609 - val_Recall: 0.9475 - val_TP: 761.7600 - val_TN: 1082.7100 - val_FP: 23.2900 - val_FN: 42.2400\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1827 - Accuracy: 0.9844 - Precision: 0.9669 - Recall: 0.9656 - TP: 3256.0801 - TN: 5568.0098 - FP: 78.9900 - FN: 115.9200 - val_loss: 0.2532 - val_Accuracy: 0.9665 - val_Precision: 0.9425 - val_Recall: 0.9567 - val_TP: 769.2200 - val_TN: 1066.8400 - val_FP: 39.1600 - val_FN: 34.7800\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1917 - Accuracy: 0.9848 - Precision: 0.9670 - Recall: 0.9666 - TP: 3259.2500 - TN: 5568.1602 - FP: 78.8400 - FN: 112.7500 - val_loss: 0.2733 - val_Accuracy: 0.9675 - val_Precision: 0.9488 - val_Recall: 0.9521 - val_TP: 765.4600 - val_TN: 1072.5900 - val_FP: 33.4100 - val_FN: 38.5400\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1051 - Accuracy: 0.9846 - Precision: 0.9680 - Recall: 0.9676 - TP: 3262.5901 - TN: 5571.5498 - FP: 75.4500 - FN: 109.4100 - val_loss: 0.2997 - val_Accuracy: 0.9681 - val_Precision: 0.9528 - val_Recall: 0.9518 - val_TP: 765.2800 - val_TN: 1075.9100 - val_FP: 30.0900 - val_FN: 38.7200\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2061 - Accuracy: 0.9845 - Precision: 0.9677 - Recall: 0.9671 - TP: 3260.9299 - TN: 5570.6001 - FP: 76.4000 - FN: 111.0700 - val_loss: 0.2611 - val_Accuracy: 0.9717 - val_Precision: 0.9673 - val_Recall: 0.9413 - val_TP: 756.7800 - val_TN: 1088.0699 - val_FP: 17.9300 - val_FN: 47.2200\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2345 - Accuracy: 0.9860 - Precision: 0.9683 - Recall: 0.9687 - TP: 3266.4800 - TN: 5572.5098 - FP: 74.4900 - FN: 105.5200 - val_loss: 0.2814 - val_Accuracy: 0.9670 - val_Precision: 0.9727 - val_Recall: 0.9307 - val_TP: 748.3000 - val_TN: 1092.6000 - val_FP: 13.4000 - val_FN: 55.7000\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0960 - Accuracy: 0.9871 - Precision: 0.9707 - Recall: 0.9690 - TP: 3267.3501 - TN: 5580.8501 - FP: 66.1500 - FN: 104.6500 - val_loss: 0.2457 - val_Accuracy: 0.9723 - val_Precision: 0.9625 - val_Recall: 0.9486 - val_TP: 762.7000 - val_TN: 1084.0500 - val_FP: 21.9500 - val_FN: 41.3000\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2165 - Accuracy: 0.9839 - Precision: 0.9666 - Recall: 0.9667 - TP: 3259.6599 - TN: 5566.7900 - FP: 80.2100 - FN: 112.3400 - val_loss: 0.3028 - val_Accuracy: 0.9696 - val_Precision: 0.9552 - val_Recall: 0.9498 - val_TP: 763.6600 - val_TN: 1078.0500 - val_FP: 27.9500 - val_FN: 40.3400\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2057 - Accuracy: 0.9847 - Precision: 0.9685 - Recall: 0.9664 - TP: 3258.6899 - TN: 5573.6099 - FP: 73.3900 - FN: 113.3100 - val_loss: 0.2857 - val_Accuracy: 0.9686 - val_Precision: 0.9424 - val_Recall: 0.9621 - val_TP: 773.5600 - val_TN: 1066.6801 - val_FP: 39.3200 - val_FN: 30.4400\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2447 - Accuracy: 0.9838 - Precision: 0.9657 - Recall: 0.9666 - TP: 3259.5200 - TN: 5563.9199 - FP: 83.0800 - FN: 112.4800 - val_loss: 0.2975 - val_Accuracy: 0.9691 - val_Precision: 0.9592 - val_Recall: 0.9465 - val_TP: 760.9500 - val_TN: 1081.4700 - val_FP: 24.5300 - val_FN: 43.0500\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1931 - Accuracy: 0.9857 - Precision: 0.9686 - Recall: 0.9676 - TP: 3262.7600 - TN: 5573.7798 - FP: 73.2200 - FN: 109.2400 - val_loss: 0.2984 - val_Accuracy: 0.9723 - val_Precision: 0.9668 - val_Recall: 0.9412 - val_TP: 756.7400 - val_TN: 1087.7200 - val_FP: 18.2800 - val_FN: 47.2600\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1258 - Accuracy: 0.9860 - Precision: 0.9697 - Recall: 0.9689 - TP: 3267.0100 - TN: 5577.7402 - FP: 69.2600 - FN: 104.9900 - val_loss: 0.3265 - val_Accuracy: 0.9702 - val_Precision: 0.9569 - val_Recall: 0.9504 - val_TP: 764.0900 - val_TN: 1079.4301 - val_FP: 26.5700 - val_FN: 39.9100\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1105 - Accuracy: 0.9856 - Precision: 0.9685 - Recall: 0.9684 - TP: 3265.5400 - TN: 5573.2900 - FP: 73.7100 - FN: 106.4600 - val_loss: 0.2980 - val_Accuracy: 0.9660 - val_Precision: 0.9723 - val_Recall: 0.9273 - val_TP: 745.5700 - val_TN: 1092.3900 - val_FP: 13.6100 - val_FN: 58.4300\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2054 - Accuracy: 0.9843 - Precision: 0.9675 - Recall: 0.9660 - TP: 3257.4500 - TN: 5570.3999 - FP: 76.6000 - FN: 114.5500 - val_loss: 0.2649 - val_Accuracy: 0.9717 - val_Precision: 0.9669 - val_Recall: 0.9429 - val_TP: 758.0600 - val_TN: 1087.8000 - val_FP: 18.2000 - val_FN: 45.9400\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2985 - Accuracy: 0.9830 - Precision: 0.9650 - Recall: 0.9647 - TP: 3252.9199 - TN: 5561.5400 - FP: 85.4600 - FN: 119.0800 - val_loss: 0.2706 - val_Accuracy: 0.9717 - val_Precision: 0.9612 - val_Recall: 0.9489 - val_TP: 762.9500 - val_TN: 1082.9500 - val_FP: 23.0500 - val_FN: 41.0500\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 7ms/step - loss: 0.2320 - Accuracy: 0.9833 - Precision: 0.9664 - Recall: 0.9650 - TP: 3254.1001 - TN: 5566.3101 - FP: 80.6900 - FN: 117.9000 - val_loss: 0.2379 - val_Accuracy: 0.9723 - val_Precision: 0.9606 - val_Recall: 0.9491 - val_TP: 763.0700 - val_TN: 1082.4399 - val_FP: 23.5600 - val_FN: 40.9300\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1972 - Accuracy: 0.9845 - Precision: 0.9679 - Recall: 0.9669 - TP: 3260.2900 - TN: 5571.2300 - FP: 75.7700 - FN: 111.7100 - val_loss: 0.2439 - val_Accuracy: 0.9686 - val_Precision: 0.9554 - val_Recall: 0.9499 - val_TP: 763.7000 - val_TN: 1078.0900 - val_FP: 27.9100 - val_FN: 40.3000\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0937 - Accuracy: 0.9875 - Precision: 0.9695 - Recall: 0.9699 - TP: 3270.5300 - TN: 5576.5898 - FP: 70.4100 - FN: 101.4700 - val_loss: 0.2424 - val_Accuracy: 0.9702 - val_Precision: 0.9637 - val_Recall: 0.9438 - val_TP: 758.8300 - val_TN: 1085.1200 - val_FP: 20.8800 - val_FN: 45.1700\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1692 - Accuracy: 0.9843 - Precision: 0.9671 - Recall: 0.9659 - TP: 3257.0300 - TN: 5568.5698 - FP: 78.4300 - FN: 114.9700 - val_loss: 0.2437 - val_Accuracy: 0.9702 - val_Precision: 0.9571 - val_Recall: 0.9500 - val_TP: 763.7800 - val_TN: 1079.5601 - val_FP: 26.4400 - val_FN: 40.2200\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.4103 - Accuracy: 0.9800 - Precision: 0.9611 - Recall: 0.9611 - TP: 3240.8000 - TN: 5548.1299 - FP: 98.8700 - FN: 131.2000 - val_loss: 0.2662 - val_Accuracy: 0.9728 - val_Precision: 0.9623 - val_Recall: 0.9493 - val_TP: 763.2300 - val_TN: 1083.9000 - val_FP: 22.1000 - val_FN: 40.7700\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2657 - Accuracy: 0.9845 - Precision: 0.9684 - Recall: 0.9684 - TP: 3265.4800 - TN: 5573.2598 - FP: 73.7400 - FN: 106.5200 - val_loss: 0.2630 - val_Accuracy: 0.9728 - val_Precision: 0.9695 - val_Recall: 0.9426 - val_TP: 757.8400 - val_TN: 1089.9100 - val_FP: 16.0900 - val_FN: 46.1600\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1413 - Accuracy: 0.9868 - Precision: 0.9700 - Recall: 0.9681 - TP: 3264.2800 - TN: 5578.5801 - FP: 68.4200 - FN: 107.7200 - val_loss: 0.5435 - val_Accuracy: 0.9382 - val_Precision: 0.8797 - val_Recall: 0.9610 - val_TP: 772.6400 - val_TN: 1008.8000 - val_FP: 97.2000 - val_FN: 31.3600\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.2395 - Accuracy: 0.9848 - Precision: 0.9681 - Recall: 0.9677 - TP: 3263.2100 - TN: 5572.1499 - FP: 74.8500 - FN: 108.7900 - val_loss: 0.2904 - val_Accuracy: 0.9691 - val_Precision: 0.9705 - val_Recall: 0.9336 - val_TP: 750.5800 - val_TN: 1090.8000 - val_FP: 15.2000 - val_FN: 53.4200\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1891 - Accuracy: 0.9830 - Precision: 0.9666 - Recall: 0.9653 - TP: 3254.8601 - TN: 5566.9502 - FP: 80.0500 - FN: 117.1400 - val_loss: 0.2555 - val_Accuracy: 0.9707 - val_Precision: 0.9482 - val_Recall: 0.9601 - val_TP: 771.8900 - val_TN: 1071.7600 - val_FP: 34.2400 - val_FN: 32.1100\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1500 - Accuracy: 0.9855 - Precision: 0.9676 - Recall: 0.9676 - TP: 3262.5901 - TN: 5570.0298 - FP: 76.9700 - FN: 109.4100 - val_loss: 0.2635 - val_Accuracy: 0.9733 - val_Precision: 0.9668 - val_Recall: 0.9439 - val_TP: 758.9100 - val_TN: 1087.6300 - val_FP: 18.3700 - val_FN: 45.0900\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1972 - Accuracy: 0.9857 - Precision: 0.9685 - Recall: 0.9677 - TP: 3262.9500 - TN: 5573.5200 - FP: 73.4800 - FN: 109.0500 - val_loss: 0.3110 - val_Accuracy: 0.9670 - val_Precision: 0.9551 - val_Recall: 0.9462 - val_TP: 760.7700 - val_TN: 1078.0200 - val_FP: 27.9800 - val_FN: 43.2300\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2692 - Accuracy: 0.9840 - Precision: 0.9661 - Recall: 0.9664 - TP: 3258.7000 - TN: 5565.1899 - FP: 81.8100 - FN: 113.3000 - val_loss: 0.3162 - val_Accuracy: 0.9686 - val_Precision: 0.9747 - val_Recall: 0.9294 - val_TP: 747.2000 - val_TN: 1094.2500 - val_FP: 11.7500 - val_FN: 56.8000\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2232 - Accuracy: 0.9846 - Precision: 0.9676 - Recall: 0.9664 - TP: 3258.8301 - TN: 5570.4800 - FP: 76.5200 - FN: 113.1700 - val_loss: 0.3070 - val_Accuracy: 0.9696 - val_Precision: 0.9678 - val_Recall: 0.9391 - val_TP: 755.0300 - val_TN: 1088.5699 - val_FP: 17.4300 - val_FN: 48.9700\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2460 - Accuracy: 0.9849 - Precision: 0.9671 - Recall: 0.9664 - TP: 3258.7700 - TN: 5568.8301 - FP: 78.1700 - FN: 113.2300 - val_loss: 0.2596 - val_Accuracy: 0.9691 - val_Precision: 0.9540 - val_Recall: 0.9553 - val_TP: 768.0800 - val_TN: 1076.8700 - val_FP: 29.1300 - val_FN: 35.9200\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1661 - Accuracy: 0.9835 - Precision: 0.9662 - Recall: 0.9656 - TP: 3255.9800 - TN: 5565.9102 - FP: 81.0900 - FN: 116.0200 - val_loss: 0.2982 - val_Accuracy: 0.9696 - val_Precision: 0.9482 - val_Recall: 0.9573 - val_TP: 769.6300 - val_TN: 1071.8800 - val_FP: 34.1200 - val_FN: 34.3700\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1549 - Accuracy: 0.9849 - Precision: 0.9676 - Recall: 0.9668 - TP: 3260.0500 - TN: 5570.3101 - FP: 76.6900 - FN: 111.9500 - val_loss: 0.3467 - val_Accuracy: 0.9675 - val_Precision: 0.9495 - val_Recall: 0.9535 - val_TP: 766.6100 - val_TN: 1073.1000 - val_FP: 32.9000 - val_FN: 37.3900\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1544 - Accuracy: 0.9863 - Precision: 0.9695 - Recall: 0.9687 - TP: 3266.2900 - TN: 5577.0298 - FP: 69.9700 - FN: 105.7100 - val_loss: 0.2801 - val_Accuracy: 0.9696 - val_Precision: 0.9573 - val_Recall: 0.9483 - val_TP: 762.4700 - val_TN: 1079.7600 - val_FP: 26.2400 - val_FN: 41.5300\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1513 - Accuracy: 0.9868 - Precision: 0.9702 - Recall: 0.9695 - TP: 3269.1599 - TN: 5579.4399 - FP: 67.5600 - FN: 102.8400 - val_loss: 0.2728 - val_Accuracy: 0.9686 - val_Precision: 0.9515 - val_Recall: 0.9528 - val_TP: 766.0300 - val_TN: 1074.7800 - val_FP: 31.2200 - val_FN: 37.9700\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1836 - Accuracy: 0.9844 - Precision: 0.9673 - Recall: 0.9674 - TP: 3261.9700 - TN: 5569.2598 - FP: 77.7400 - FN: 110.0300 - val_loss: 0.2741 - val_Accuracy: 0.9681 - val_Precision: 0.9512 - val_Recall: 0.9520 - val_TP: 765.3800 - val_TN: 1074.5500 - val_FP: 31.4500 - val_FN: 38.6200\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1632 - Accuracy: 0.9848 - Precision: 0.9683 - Recall: 0.9679 - TP: 3263.6399 - TN: 5572.7100 - FP: 74.2900 - FN: 108.3600 - val_loss: 0.3173 - val_Accuracy: 0.9691 - val_Precision: 0.9564 - val_Recall: 0.9485 - val_TP: 762.5600 - val_TN: 1079.0000 - val_FP: 27.0000 - val_FN: 41.4400\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.0856 - Accuracy: 0.9865 - Precision: 0.9701 - Recall: 0.9690 - TP: 3267.4800 - TN: 5578.7998 - FP: 68.2000 - FN: 104.5200 - val_loss: 0.2762 - val_Accuracy: 0.9702 - val_Precision: 0.9611 - val_Recall: 0.9472 - val_TP: 761.5600 - val_TN: 1082.8800 - val_FP: 23.1200 - val_FN: 42.4400\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 7ms/step - loss: 0.3484 - Accuracy: 0.9835 - Precision: 0.9657 - Recall: 0.9660 - TP: 3257.2700 - TN: 5563.7100 - FP: 83.2900 - FN: 114.7300 - val_loss: 0.3312 - val_Accuracy: 0.9686 - val_Precision: 0.9631 - val_Recall: 0.9387 - val_TP: 754.7100 - val_TN: 1084.7300 - val_FP: 21.2700 - val_FN: 49.2900\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1435 - Accuracy: 0.9839 - Precision: 0.9672 - Recall: 0.9653 - TP: 3255.0200 - TN: 5569.0498 - FP: 77.9500 - FN: 116.9800 - val_loss: 0.2489 - val_Accuracy: 0.9712 - val_Precision: 0.9712 - val_Recall: 0.9407 - val_TP: 756.3400 - val_TN: 1091.2300 - val_FP: 14.7700 - val_FN: 47.6600\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1125 - Accuracy: 0.9869 - Precision: 0.9687 - Recall: 0.9693 - TP: 3268.4600 - TN: 5574.0400 - FP: 72.9600 - FN: 103.5400 - val_loss: 0.2744 - val_Accuracy: 0.9696 - val_Precision: 0.9577 - val_Recall: 0.9485 - val_TP: 762.5900 - val_TN: 1080.1200 - val_FP: 25.8800 - val_FN: 41.4100\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2786 - Accuracy: 0.9856 - Precision: 0.9689 - Recall: 0.9682 - TP: 3264.6101 - TN: 5574.7500 - FP: 72.2500 - FN: 107.3900 - val_loss: 0.2533 - val_Accuracy: 0.9712 - val_Precision: 0.9615 - val_Recall: 0.9467 - val_TP: 761.1100 - val_TN: 1083.2300 - val_FP: 22.7700 - val_FN: 42.8900\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3137 - Accuracy: 0.9836 - Precision: 0.9659 - Recall: 0.9650 - TP: 3254.1201 - TN: 5564.5898 - FP: 82.4100 - FN: 117.8800 - val_loss: 0.6642 - val_Accuracy: 0.9387 - val_Precision: 0.8876 - val_Recall: 0.9530 - val_TP: 766.1900 - val_TN: 1017.4400 - val_FP: 88.5600 - val_FN: 37.8100\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2771 - Accuracy: 0.9851 - Precision: 0.9674 - Recall: 0.9669 - TP: 3260.5000 - TN: 5569.7798 - FP: 77.2200 - FN: 111.5000 - val_loss: 0.3714 - val_Accuracy: 0.9696 - val_Precision: 0.9582 - val_Recall: 0.9453 - val_TP: 760.0600 - val_TN: 1080.6200 - val_FP: 25.3800 - val_FN: 43.9400\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1419 - Accuracy: 0.9866 - Precision: 0.9701 - Recall: 0.9694 - TP: 3268.9800 - TN: 5578.9399 - FP: 68.0600 - FN: 103.0200 - val_loss: 0.3268 - val_Accuracy: 0.9660 - val_Precision: 0.9500 - val_Recall: 0.9514 - val_TP: 764.9100 - val_TN: 1073.6200 - val_FP: 32.3800 - val_FN: 39.0900\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1436 - Accuracy: 0.9866 - Precision: 0.9697 - Recall: 0.9687 - TP: 3266.3899 - TN: 5577.5498 - FP: 69.4500 - FN: 105.6100 - val_loss: 0.2524 - val_Accuracy: 0.9712 - val_Precision: 0.9572 - val_Recall: 0.9533 - val_TP: 766.4500 - val_TN: 1079.5500 - val_FP: 26.4500 - val_FN: 37.5500\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1024 - Accuracy: 0.9856 - Precision: 0.9697 - Recall: 0.9697 - TP: 3269.8301 - TN: 5577.3999 - FP: 69.6000 - FN: 102.1700 - val_loss: 0.2801 - val_Accuracy: 0.9707 - val_Precision: 0.9545 - val_Recall: 0.9523 - val_TP: 765.6700 - val_TN: 1077.3101 - val_FP: 28.6900 - val_FN: 38.3300\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2856 - Accuracy: 0.9815 - Precision: 0.9655 - Recall: 0.9635 - TP: 3248.7800 - TN: 5563.3999 - FP: 83.6000 - FN: 123.2200 - val_loss: 0.3085 - val_Accuracy: 0.9702 - val_Precision: 0.9548 - val_Recall: 0.9512 - val_TP: 764.7600 - val_TN: 1077.6200 - val_FP: 28.3800 - val_FN: 39.2400\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2698 - Accuracy: 0.9834 - Precision: 0.9659 - Recall: 0.9661 - TP: 3257.5500 - TN: 5564.7700 - FP: 82.2300 - FN: 114.4500 - val_loss: 0.3606 - val_Accuracy: 0.9654 - val_Precision: 0.9424 - val_Recall: 0.9560 - val_TP: 768.6500 - val_TN: 1066.9700 - val_FP: 39.0300 - val_FN: 35.3500\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1593 - Accuracy: 0.9838 - Precision: 0.9666 - Recall: 0.9669 - TP: 3260.3401 - TN: 5567.0801 - FP: 79.9200 - FN: 111.6600 - val_loss: 0.2699 - val_Accuracy: 0.9728 - val_Precision: 0.9674 - val_Recall: 0.9427 - val_TP: 757.9000 - val_TN: 1088.1300 - val_FP: 17.8700 - val_FN: 46.1000\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1920 - Accuracy: 0.9860 - Precision: 0.9685 - Recall: 0.9675 - TP: 3262.4700 - TN: 5573.2598 - FP: 73.7400 - FN: 109.5300 - val_loss: 0.3038 - val_Accuracy: 0.9702 - val_Precision: 0.9640 - val_Recall: 0.9403 - val_TP: 756.0400 - val_TN: 1085.4900 - val_FP: 20.5100 - val_FN: 47.9600\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1301 - Accuracy: 0.9843 - Precision: 0.9680 - Recall: 0.9676 - TP: 3262.8301 - TN: 5572.0000 - FP: 75.0000 - FN: 109.1700 - val_loss: 0.3312 - val_Accuracy: 0.9702 - val_Precision: 0.9608 - val_Recall: 0.9462 - val_TP: 760.7600 - val_TN: 1082.7300 - val_FP: 23.2700 - val_FN: 43.2400\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3100 - Accuracy: 0.9838 - Precision: 0.9664 - Recall: 0.9661 - TP: 3257.5601 - TN: 5566.2598 - FP: 80.7400 - FN: 114.4400 - val_loss: 0.3416 - val_Accuracy: 0.9707 - val_Precision: 0.9675 - val_Recall: 0.9412 - val_TP: 756.7200 - val_TN: 1088.2800 - val_FP: 17.7200 - val_FN: 47.2800\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1444 - Accuracy: 0.9839 - Precision: 0.9676 - Recall: 0.9662 - TP: 3258.0000 - TN: 5570.6299 - FP: 76.3700 - FN: 114.0000 - val_loss: 0.3299 - val_Accuracy: 0.9723 - val_Precision: 0.9637 - val_Recall: 0.9464 - val_TP: 760.8800 - val_TN: 1085.0800 - val_FP: 20.9200 - val_FN: 43.1200\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2770 - Accuracy: 0.9841 - Precision: 0.9676 - Recall: 0.9667 - TP: 3259.7000 - TN: 5570.7202 - FP: 76.2800 - FN: 112.3000 - val_loss: 0.2786 - val_Accuracy: 0.9707 - val_Precision: 0.9586 - val_Recall: 0.9507 - val_TP: 764.3800 - val_TN: 1080.7600 - val_FP: 25.2400 - val_FN: 39.6200\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2977 - Accuracy: 0.9840 - Precision: 0.9659 - Recall: 0.9665 - TP: 3258.9600 - TN: 5564.4902 - FP: 82.5100 - FN: 113.0400 - val_loss: 0.3297 - val_Accuracy: 0.9712 - val_Precision: 0.9719 - val_Recall: 0.9381 - val_TP: 754.2600 - val_TN: 1091.8700 - val_FP: 14.1300 - val_FN: 49.7400\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3141 - Accuracy: 0.9840 - Precision: 0.9668 - Recall: 0.9650 - TP: 3253.8601 - TN: 5567.8799 - FP: 79.1200 - FN: 118.1400 - val_loss: 0.3004 - val_Accuracy: 0.9696 - val_Precision: 0.9598 - val_Recall: 0.9476 - val_TP: 761.8400 - val_TN: 1081.9399 - val_FP: 24.0600 - val_FN: 42.1600\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2614 - Accuracy: 0.9860 - Precision: 0.9688 - Recall: 0.9685 - TP: 3265.6599 - TN: 5574.6699 - FP: 72.3300 - FN: 106.3400 - val_loss: 0.2977 - val_Accuracy: 0.9665 - val_Precision: 0.9500 - val_Recall: 0.9536 - val_TP: 766.6800 - val_TN: 1073.5699 - val_FP: 32.4300 - val_FN: 37.3200\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1098 - Accuracy: 0.9853 - Precision: 0.9691 - Recall: 0.9676 - TP: 3262.8201 - TN: 5575.6602 - FP: 71.3400 - FN: 109.1800 - val_loss: 0.2726 - val_Accuracy: 0.9733 - val_Precision: 0.9609 - val_Recall: 0.9528 - val_TP: 766.0200 - val_TN: 1082.6801 - val_FP: 23.3200 - val_FN: 37.9800\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.4731 - Accuracy: 0.9808 - Precision: 0.9626 - Recall: 0.9618 - TP: 3243.0901 - TN: 5553.4502 - FP: 93.5500 - FN: 128.9100 - val_loss: 0.2747 - val_Accuracy: 0.9717 - val_Precision: 0.9545 - val_Recall: 0.9573 - val_TP: 769.7000 - val_TN: 1077.2100 - val_FP: 28.7900 - val_FN: 34.3000\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 7ms/step - loss: 0.3222 - Accuracy: 0.9836 - Precision: 0.9661 - Recall: 0.9652 - TP: 3254.8101 - TN: 5565.2402 - FP: 81.7600 - FN: 117.1900 - val_loss: 0.2430 - val_Accuracy: 0.9717 - val_Precision: 0.9547 - val_Recall: 0.9548 - val_TP: 767.6800 - val_TN: 1077.4100 - val_FP: 28.5900 - val_FN: 36.3200\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2589 - Accuracy: 0.9847 - Precision: 0.9670 - Recall: 0.9677 - TP: 3263.2500 - TN: 5568.1201 - FP: 78.8800 - FN: 108.7500 - val_loss: 0.3115 - val_Accuracy: 0.9696 - val_Precision: 0.9675 - val_Recall: 0.9363 - val_TP: 752.8100 - val_TN: 1088.3900 - val_FP: 17.6100 - val_FN: 51.1900\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1307 - Accuracy: 0.9850 - Precision: 0.9689 - Recall: 0.9673 - TP: 3261.5901 - TN: 5575.0200 - FP: 71.9800 - FN: 110.4100 - val_loss: 0.2718 - val_Accuracy: 0.9707 - val_Precision: 0.9588 - val_Recall: 0.9505 - val_TP: 764.2300 - val_TN: 1080.9600 - val_FP: 25.0400 - val_FN: 39.7700\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2967 - Accuracy: 0.9830 - Precision: 0.9656 - Recall: 0.9649 - TP: 3253.5200 - TN: 5563.5298 - FP: 83.4700 - FN: 118.4800 - val_loss: 0.2475 - val_Accuracy: 0.9733 - val_Precision: 0.9559 - val_Recall: 0.9578 - val_TP: 770.1100 - val_TN: 1078.3700 - val_FP: 27.6300 - val_FN: 33.8900\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2997 - Accuracy: 0.9823 - Precision: 0.9649 - Recall: 0.9638 - TP: 3249.8701 - TN: 5561.3701 - FP: 85.6300 - FN: 122.1300 - val_loss: 0.2673 - val_Accuracy: 0.9723 - val_Precision: 0.9590 - val_Recall: 0.9513 - val_TP: 764.8200 - val_TN: 1081.1000 - val_FP: 24.9000 - val_FN: 39.1800\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1702 - Accuracy: 0.9837 - Precision: 0.9670 - Recall: 0.9668 - TP: 3260.0801 - TN: 5568.4302 - FP: 78.5700 - FN: 111.9200 - val_loss: 0.2599 - val_Accuracy: 0.9712 - val_Precision: 0.9672 - val_Recall: 0.9438 - val_TP: 758.8100 - val_TN: 1087.9900 - val_FP: 18.0100 - val_FN: 45.1900\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1483 - Accuracy: 0.9864 - Precision: 0.9687 - Recall: 0.9679 - TP: 3263.9099 - TN: 5573.9502 - FP: 73.0500 - FN: 108.0900 - val_loss: 0.2685 - val_Accuracy: 0.9712 - val_Precision: 0.9617 - val_Recall: 0.9478 - val_TP: 762.0100 - val_TN: 1083.4100 - val_FP: 22.5900 - val_FN: 41.9900\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1112 - Accuracy: 0.9857 - Precision: 0.9688 - Recall: 0.9672 - TP: 3261.2900 - TN: 5574.4800 - FP: 72.5200 - FN: 110.7100 - val_loss: 0.2798 - val_Accuracy: 0.9696 - val_Precision: 0.9435 - val_Recall: 0.9607 - val_TP: 772.4200 - val_TN: 1067.6500 - val_FP: 38.3500 - val_FN: 31.5800\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3411 - Accuracy: 0.9825 - Precision: 0.9645 - Recall: 0.9646 - TP: 3252.7000 - TN: 5559.7500 - FP: 87.2500 - FN: 119.3000 - val_loss: 0.3327 - val_Accuracy: 0.9681 - val_Precision: 0.9525 - val_Recall: 0.9542 - val_TP: 767.1800 - val_TN: 1075.5500 - val_FP: 30.4500 - val_FN: 36.8200\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1604 - Accuracy: 0.9858 - Precision: 0.9683 - Recall: 0.9677 - TP: 3263.2100 - TN: 5572.9199 - FP: 74.0800 - FN: 108.7900 - val_loss: 0.3130 - val_Accuracy: 0.9691 - val_Precision: 0.9517 - val_Recall: 0.9539 - val_TP: 766.9600 - val_TN: 1074.9000 - val_FP: 31.1000 - val_FN: 37.0400\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2517 - Accuracy: 0.9828 - Precision: 0.9656 - Recall: 0.9660 - TP: 3257.2100 - TN: 5563.5898 - FP: 83.4100 - FN: 114.7900 - val_loss: 0.3411 - val_Accuracy: 0.9686 - val_Precision: 0.9576 - val_Recall: 0.9447 - val_TP: 759.5100 - val_TN: 1080.1700 - val_FP: 25.8300 - val_FN: 44.4900\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1856 - Accuracy: 0.9850 - Precision: 0.9680 - Recall: 0.9667 - TP: 3259.8501 - TN: 5571.9199 - FP: 75.0800 - FN: 112.1500 - val_loss: 0.3045 - val_Accuracy: 0.9723 - val_Precision: 0.9592 - val_Recall: 0.9524 - val_TP: 765.7400 - val_TN: 1081.2900 - val_FP: 24.7100 - val_FN: 38.2600\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1589 - Accuracy: 0.9858 - Precision: 0.9686 - Recall: 0.9676 - TP: 3262.8000 - TN: 5573.7700 - FP: 73.2300 - FN: 109.2000 - val_loss: 0.3293 - val_Accuracy: 0.9712 - val_Precision: 0.9580 - val_Recall: 0.9492 - val_TP: 763.1200 - val_TN: 1080.3199 - val_FP: 25.6800 - val_FN: 40.8800\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2689 - Accuracy: 0.9826 - Precision: 0.9645 - Recall: 0.9647 - TP: 3253.0200 - TN: 5559.9102 - FP: 87.0900 - FN: 118.9800 - val_loss: 0.3005 - val_Accuracy: 0.9733 - val_Precision: 0.9618 - val_Recall: 0.9477 - val_TP: 761.9900 - val_TN: 1083.5100 - val_FP: 22.4900 - val_FN: 42.0100\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2326 - Accuracy: 0.9835 - Precision: 0.9669 - Recall: 0.9659 - TP: 3256.8799 - TN: 5568.0698 - FP: 78.9300 - FN: 115.1200 - val_loss: 0.2635 - val_Accuracy: 0.9723 - val_Precision: 0.9585 - val_Recall: 0.9535 - val_TP: 766.6300 - val_TN: 1080.6899 - val_FP: 25.3100 - val_FN: 37.3700\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2081 - Accuracy: 0.9856 - Precision: 0.9687 - Recall: 0.9683 - TP: 3265.0300 - TN: 5574.3501 - FP: 72.6500 - FN: 106.9700 - val_loss: 0.3012 - val_Accuracy: 0.9707 - val_Precision: 0.9647 - val_Recall: 0.9414 - val_TP: 756.8600 - val_TN: 1086.0601 - val_FP: 19.9400 - val_FN: 47.1400\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1323 - Accuracy: 0.9840 - Precision: 0.9676 - Recall: 0.9673 - TP: 3261.7500 - TN: 5570.2998 - FP: 76.7000 - FN: 110.2500 - val_loss: 0.3075 - val_Accuracy: 0.9717 - val_Precision: 0.9732 - val_Recall: 0.9355 - val_TP: 752.1800 - val_TN: 1092.9100 - val_FP: 13.0900 - val_FN: 51.8200\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2342 - Accuracy: 0.9835 - Precision: 0.9658 - Recall: 0.9653 - TP: 3254.8799 - TN: 5564.1899 - FP: 82.8100 - FN: 117.1200 - val_loss: 0.3401 - val_Accuracy: 0.9675 - val_Precision: 0.9484 - val_Recall: 0.9525 - val_TP: 765.7700 - val_TN: 1072.1700 - val_FP: 33.8300 - val_FN: 38.2300\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.4190 - Accuracy: 0.9827 - Precision: 0.9651 - Recall: 0.9646 - TP: 3252.6899 - TN: 5562.1699 - FP: 84.8300 - FN: 119.3100 - val_loss: 0.3049 - val_Accuracy: 0.9696 - val_Precision: 0.9642 - val_Recall: 0.9430 - val_TP: 758.1900 - val_TN: 1085.6200 - val_FP: 20.3800 - val_FN: 45.8100\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1668 - Accuracy: 0.9858 - Precision: 0.9705 - Recall: 0.9691 - TP: 3267.9500 - TN: 5580.6602 - FP: 66.3400 - FN: 104.0500 - val_loss: 0.2908 - val_Accuracy: 0.9728 - val_Precision: 0.9679 - val_Recall: 0.9435 - val_TP: 758.5500 - val_TN: 1088.5800 - val_FP: 17.4200 - val_FN: 45.4500\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3122 - Accuracy: 0.9821 - Precision: 0.9660 - Recall: 0.9647 - TP: 3252.9399 - TN: 5565.2798 - FP: 81.7200 - FN: 119.0600 - val_loss: 0.3955 - val_Accuracy: 0.9649 - val_Precision: 0.9395 - val_Recall: 0.9592 - val_TP: 771.2000 - val_TN: 1064.3400 - val_FP: 41.6600 - val_FN: 32.8000\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 7ms/step - loss: 0.3705 - Accuracy: 0.9814 - Precision: 0.9636 - Recall: 0.9621 - TP: 3244.3000 - TN: 5556.7402 - FP: 90.2600 - FN: 127.7000 - val_loss: 0.2609 - val_Accuracy: 0.9707 - val_Precision: 0.9518 - val_Recall: 0.9571 - val_TP: 769.5400 - val_TN: 1074.9100 - val_FP: 31.0900 - val_FN: 34.4600\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2872 - Accuracy: 0.9839 - Precision: 0.9662 - Recall: 0.9666 - TP: 3259.3799 - TN: 5565.5000 - FP: 81.5000 - FN: 112.6200 - val_loss: 0.2607 - val_Accuracy: 0.9702 - val_Precision: 0.9482 - val_Recall: 0.9591 - val_TP: 771.1400 - val_TN: 1071.7900 - val_FP: 34.2100 - val_FN: 32.8600\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1369 - Accuracy: 0.9847 - Precision: 0.9675 - Recall: 0.9677 - TP: 3262.9700 - TN: 5569.8799 - FP: 77.1200 - FN: 109.0300 - val_loss: 0.2794 - val_Accuracy: 0.9728 - val_Precision: 0.9657 - val_Recall: 0.9437 - val_TP: 758.7000 - val_TN: 1086.7700 - val_FP: 19.2300 - val_FN: 45.3000\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1829 - Accuracy: 0.9855 - Precision: 0.9686 - Recall: 0.9674 - TP: 3261.9199 - TN: 5573.8701 - FP: 73.1300 - FN: 110.0800 - val_loss: 0.2811 - val_Accuracy: 0.9681 - val_Precision: 0.9468 - val_Recall: 0.9588 - val_TP: 770.8500 - val_TN: 1070.6500 - val_FP: 35.3500 - val_FN: 33.1500\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3007 - Accuracy: 0.9855 - Precision: 0.9676 - Recall: 0.9681 - TP: 3264.3101 - TN: 5570.4502 - FP: 76.5500 - FN: 107.6900 - val_loss: 0.3084 - val_Accuracy: 0.9723 - val_Precision: 0.9625 - val_Recall: 0.9464 - val_TP: 760.9000 - val_TN: 1084.1200 - val_FP: 21.8800 - val_FN: 43.1000\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1795 - Accuracy: 0.9838 - Precision: 0.9671 - Recall: 0.9648 - TP: 3253.3401 - TN: 5568.7402 - FP: 78.2600 - FN: 118.6600 - val_loss: 0.2921 - val_Accuracy: 0.9691 - val_Precision: 0.9516 - val_Recall: 0.9542 - val_TP: 767.1800 - val_TN: 1074.8900 - val_FP: 31.1100 - val_FN: 36.8200\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3203 - Accuracy: 0.9820 - Precision: 0.9635 - Recall: 0.9636 - TP: 3249.3701 - TN: 5556.1899 - FP: 90.8100 - FN: 122.6300 - val_loss: 0.3473 - val_Accuracy: 0.9660 - val_Precision: 0.9412 - val_Recall: 0.9580 - val_TP: 770.2000 - val_TN: 1065.8800 - val_FP: 40.1200 - val_FN: 33.8000\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3423 - Accuracy: 0.9826 - Precision: 0.9654 - Recall: 0.9638 - TP: 3249.8201 - TN: 5563.3599 - FP: 83.6400 - FN: 122.1800 - val_loss: 0.2792 - val_Accuracy: 0.9717 - val_Precision: 0.9500 - val_Recall: 0.9590 - val_TP: 771.0000 - val_TN: 1073.3400 - val_FP: 32.6600 - val_FN: 33.0000\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2736 - Accuracy: 0.9818 - Precision: 0.9645 - Recall: 0.9646 - TP: 3252.6699 - TN: 5560.2402 - FP: 86.7600 - FN: 119.3300 - val_loss: 0.2763 - val_Accuracy: 0.9743 - val_Precision: 0.9610 - val_Recall: 0.9558 - val_TP: 768.4600 - val_TN: 1082.6801 - val_FP: 23.3200 - val_FN: 35.5400\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1330 - Accuracy: 0.9835 - Precision: 0.9668 - Recall: 0.9664 - TP: 3258.6399 - TN: 5567.7598 - FP: 79.2400 - FN: 113.3600 - val_loss: 0.2736 - val_Accuracy: 0.9707 - val_Precision: 0.9544 - val_Recall: 0.9535 - val_TP: 766.6200 - val_TN: 1077.2700 - val_FP: 28.7300 - val_FN: 37.3800\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1960 - Accuracy: 0.9853 - Precision: 0.9678 - Recall: 0.9674 - TP: 3261.9800 - TN: 5571.2002 - FP: 75.8000 - FN: 110.0200 - val_loss: 0.3130 - val_Accuracy: 0.9696 - val_Precision: 0.9718 - val_Recall: 0.9332 - val_TP: 750.3300 - val_TN: 1091.8400 - val_FP: 14.1600 - val_FN: 53.6700\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1942 - Accuracy: 0.9855 - Precision: 0.9686 - Recall: 0.9678 - TP: 3263.5000 - TN: 5573.9902 - FP: 73.0100 - FN: 108.5000 - val_loss: 0.3379 - val_Accuracy: 0.9670 - val_Precision: 0.9447 - val_Recall: 0.9555 - val_TP: 768.2500 - val_TN: 1069.0000 - val_FP: 37.0000 - val_FN: 35.7500\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2026 - Accuracy: 0.9854 - Precision: 0.9674 - Recall: 0.9670 - TP: 3260.5801 - TN: 5569.8599 - FP: 77.1400 - FN: 111.4200 - val_loss: 0.2680 - val_Accuracy: 0.9707 - val_Precision: 0.9499 - val_Recall: 0.9591 - val_TP: 771.1500 - val_TN: 1073.2200 - val_FP: 32.7800 - val_FN: 32.8500\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2301 - Accuracy: 0.9830 - Precision: 0.9661 - Recall: 0.9656 - TP: 3255.9299 - TN: 5565.4399 - FP: 81.5600 - FN: 116.0700 - val_loss: 0.2814 - val_Accuracy: 0.9702 - val_Precision: 0.9546 - val_Recall: 0.9544 - val_TP: 767.3000 - val_TN: 1077.3700 - val_FP: 28.6300 - val_FN: 36.7000\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1478 - Accuracy: 0.9853 - Precision: 0.9686 - Recall: 0.9685 - TP: 3265.6201 - TN: 5573.6699 - FP: 73.3300 - FN: 106.3800 - val_loss: 0.3269 - val_Accuracy: 0.9691 - val_Precision: 0.9656 - val_Recall: 0.9407 - val_TP: 756.3500 - val_TN: 1086.8101 - val_FP: 19.1900 - val_FN: 47.6500\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1811 - Accuracy: 0.9846 - Precision: 0.9682 - Recall: 0.9666 - TP: 3259.4199 - TN: 5572.8501 - FP: 74.1500 - FN: 112.5800 - val_loss: 0.3153 - val_Accuracy: 0.9691 - val_Precision: 0.9511 - val_Recall: 0.9527 - val_TP: 765.9700 - val_TN: 1074.4700 - val_FP: 31.5300 - val_FN: 38.0300\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2537 - Accuracy: 0.9829 - Precision: 0.9664 - Recall: 0.9659 - TP: 3257.0801 - TN: 5566.3901 - FP: 80.6100 - FN: 114.9200 - val_loss: 0.2911 - val_Accuracy: 0.9681 - val_Precision: 0.9441 - val_Recall: 0.9599 - val_TP: 771.7700 - val_TN: 1068.2700 - val_FP: 37.7300 - val_FN: 32.2300\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2764 - Accuracy: 0.9837 - Precision: 0.9657 - Recall: 0.9648 - TP: 3253.2400 - TN: 5564.1802 - FP: 82.8200 - FN: 118.7600 - val_loss: 0.3311 - val_Accuracy: 0.9733 - val_Precision: 0.9602 - val_Recall: 0.9515 - val_TP: 764.9800 - val_TN: 1082.1500 - val_FP: 23.8500 - val_FN: 39.0200\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2014 - Accuracy: 0.9840 - Precision: 0.9660 - Recall: 0.9665 - TP: 3258.9500 - TN: 5564.9199 - FP: 82.0800 - FN: 113.0500 - val_loss: 0.2785 - val_Accuracy: 0.9717 - val_Precision: 0.9616 - val_Recall: 0.9497 - val_TP: 763.5500 - val_TN: 1083.3500 - val_FP: 22.6500 - val_FN: 40.4500\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2090 - Accuracy: 0.9837 - Precision: 0.9679 - Recall: 0.9657 - TP: 3256.2200 - TN: 5571.5898 - FP: 75.4100 - FN: 115.7800 - val_loss: 0.2912 - val_Accuracy: 0.9707 - val_Precision: 0.9606 - val_Recall: 0.9478 - val_TP: 762.0700 - val_TN: 1082.4900 - val_FP: 23.5100 - val_FN: 41.9300\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1358 - Accuracy: 0.9848 - Precision: 0.9683 - Recall: 0.9683 - TP: 3265.0601 - TN: 5572.7598 - FP: 74.2400 - FN: 106.9400 - val_loss: 0.3242 - val_Accuracy: 0.9707 - val_Precision: 0.9584 - val_Recall: 0.9488 - val_TP: 762.8500 - val_TN: 1080.7100 - val_FP: 25.2900 - val_FN: 41.1500\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1178 - Accuracy: 0.9854 - Precision: 0.9694 - Recall: 0.9688 - TP: 3266.8301 - TN: 5576.6802 - FP: 70.3200 - FN: 105.1700 - val_loss: 0.3240 - val_Accuracy: 0.9686 - val_Precision: 0.9746 - val_Recall: 0.9307 - val_TP: 748.2500 - val_TN: 1094.0900 - val_FP: 11.9100 - val_FN: 55.7500\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 7ms/step - loss: 0.2644 - Accuracy: 0.9819 - Precision: 0.9642 - Recall: 0.9637 - TP: 3249.7000 - TN: 5558.9902 - FP: 88.0100 - FN: 122.3000 - val_loss: 0.2757 - val_Accuracy: 0.9691 - val_Precision: 0.9477 - val_Recall: 0.9569 - val_TP: 769.3200 - val_TN: 1071.4000 - val_FP: 34.6000 - val_FN: 34.6800\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2040 - Accuracy: 0.9837 - Precision: 0.9665 - Recall: 0.9663 - TP: 3258.3701 - TN: 5566.6001 - FP: 80.4000 - FN: 113.6300 - val_loss: 0.5198 - val_Accuracy: 0.9586 - val_Precision: 0.9235 - val_Recall: 0.9595 - val_TP: 771.4200 - val_TN: 1050.2500 - val_FP: 55.7500 - val_FN: 32.5800\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1928 - Accuracy: 0.9841 - Precision: 0.9681 - Recall: 0.9664 - TP: 3258.5801 - TN: 5572.3599 - FP: 74.6400 - FN: 113.4200 - val_loss: 0.5283 - val_Accuracy: 0.9571 - val_Precision: 0.9001 - val_Recall: 0.9619 - val_TP: 773.3700 - val_TN: 1026.9500 - val_FP: 79.0500 - val_FN: 30.6300\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1746 - Accuracy: 0.9838 - Precision: 0.9666 - Recall: 0.9676 - TP: 3262.5801 - TN: 5567.1899 - FP: 79.8100 - FN: 109.4200 - val_loss: 0.3508 - val_Accuracy: 0.9686 - val_Precision: 0.9648 - val_Recall: 0.9369 - val_TP: 753.2400 - val_TN: 1086.2500 - val_FP: 19.7500 - val_FN: 50.7600\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2857 - Accuracy: 0.9828 - Precision: 0.9662 - Recall: 0.9649 - TP: 3253.5801 - TN: 5566.0200 - FP: 80.9800 - FN: 118.4200 - val_loss: 0.2614 - val_Accuracy: 0.9691 - val_Precision: 0.9517 - val_Recall: 0.9559 - val_TP: 768.5400 - val_TN: 1074.9500 - val_FP: 31.0500 - val_FN: 35.4600\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1288 - Accuracy: 0.9845 - Precision: 0.9684 - Recall: 0.9681 - TP: 3264.4099 - TN: 5573.4199 - FP: 73.5800 - FN: 107.5900 - val_loss: 0.3457 - val_Accuracy: 0.9691 - val_Precision: 0.9618 - val_Recall: 0.9447 - val_TP: 759.5200 - val_TN: 1083.5900 - val_FP: 22.4100 - val_FN: 44.4800\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3010 - Accuracy: 0.9839 - Precision: 0.9663 - Recall: 0.9648 - TP: 3253.3301 - TN: 5565.9199 - FP: 81.0800 - FN: 118.6700 - val_loss: 0.2736 - val_Accuracy: 0.9696 - val_Precision: 0.9576 - val_Recall: 0.9494 - val_TP: 763.3400 - val_TN: 1080.0200 - val_FP: 25.9800 - val_FN: 40.6600\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2949 - Accuracy: 0.9820 - Precision: 0.9640 - Recall: 0.9633 - TP: 3248.3101 - TN: 5558.3398 - FP: 88.6600 - FN: 123.6900 - val_loss: 0.4519 - val_Accuracy: 0.9607 - val_Precision: 0.9281 - val_Recall: 0.9605 - val_TP: 772.2400 - val_TN: 1054.3300 - val_FP: 51.6700 - val_FN: 31.7600\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.4663 - Accuracy: 0.9792 - Precision: 0.9617 - Recall: 0.9619 - TP: 3243.3799 - TN: 5550.6499 - FP: 96.3500 - FN: 128.6200 - val_loss: 0.3125 - val_Accuracy: 0.9702 - val_Precision: 0.9657 - val_Recall: 0.9420 - val_TP: 757.3400 - val_TN: 1086.8800 - val_FP: 19.1200 - val_FN: 46.6600\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1642 - Accuracy: 0.9859 - Precision: 0.9696 - Recall: 0.9688 - TP: 3266.6899 - TN: 5577.2998 - FP: 69.7000 - FN: 105.3100 - val_loss: 0.2949 - val_Accuracy: 0.9707 - val_Precision: 0.9560 - val_Recall: 0.9541 - val_TP: 767.1100 - val_TN: 1078.6400 - val_FP: 27.3600 - val_FN: 36.8900\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.4678 - Accuracy: 0.9810 - Precision: 0.9641 - Recall: 0.9640 - TP: 3250.5701 - TN: 5558.9302 - FP: 88.0700 - FN: 121.4300 - val_loss: 0.3394 - val_Accuracy: 0.9707 - val_Precision: 0.9653 - val_Recall: 0.9442 - val_TP: 759.1600 - val_TN: 1086.5100 - val_FP: 19.4900 - val_FN: 44.8400\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1559 - Accuracy: 0.9837 - Precision: 0.9667 - Recall: 0.9669 - TP: 3260.4700 - TN: 5567.4302 - FP: 79.5700 - FN: 111.5300 - val_loss: 0.3141 - val_Accuracy: 0.9717 - val_Precision: 0.9622 - val_Recall: 0.9478 - val_TP: 762.0200 - val_TN: 1083.8900 - val_FP: 22.1100 - val_FN: 41.9800\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.4007 - Accuracy: 0.9826 - Precision: 0.9657 - Recall: 0.9643 - TP: 3251.6201 - TN: 5564.3198 - FP: 82.6800 - FN: 120.3800 - val_loss: 0.3191 - val_Accuracy: 0.9702 - val_Precision: 0.9574 - val_Recall: 0.9522 - val_TP: 765.5400 - val_TN: 1079.8300 - val_FP: 26.1700 - val_FN: 38.4600\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1599 - Accuracy: 0.9858 - Precision: 0.9692 - Recall: 0.9685 - TP: 3265.8799 - TN: 5576.1499 - FP: 70.8500 - FN: 106.1200 - val_loss: 0.3513 - val_Accuracy: 0.9691 - val_Precision: 0.9520 - val_Recall: 0.9539 - val_TP: 766.9500 - val_TN: 1075.2800 - val_FP: 30.7200 - val_FN: 37.0500\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2877 - Accuracy: 0.9841 - Precision: 0.9675 - Recall: 0.9669 - TP: 3260.5000 - TN: 5570.2002 - FP: 76.8000 - FN: 111.5000 - val_loss: 0.3389 - val_Accuracy: 0.9681 - val_Precision: 0.9477 - val_Recall: 0.9579 - val_TP: 770.1900 - val_TN: 1071.4700 - val_FP: 34.5300 - val_FN: 33.8100\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3575 - Accuracy: 0.9814 - Precision: 0.9643 - Recall: 0.9641 - TP: 3251.0100 - TN: 5559.3101 - FP: 87.6900 - FN: 120.9900 - val_loss: 0.3058 - val_Accuracy: 0.9686 - val_Precision: 0.9624 - val_Recall: 0.9428 - val_TP: 758.0500 - val_TN: 1084.1700 - val_FP: 21.8300 - val_FN: 45.9500\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2314 - Accuracy: 0.9844 - Precision: 0.9683 - Recall: 0.9678 - TP: 3263.5400 - TN: 5573.0601 - FP: 73.9400 - FN: 108.4600 - val_loss: 0.3243 - val_Accuracy: 0.9702 - val_Precision: 0.9503 - val_Recall: 0.9543 - val_TP: 767.2700 - val_TN: 1073.8101 - val_FP: 32.1900 - val_FN: 36.7300\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2496 - Accuracy: 0.9827 - Precision: 0.9659 - Recall: 0.9649 - TP: 3253.7300 - TN: 5564.9800 - FP: 82.0200 - FN: 118.2700 - val_loss: 0.2967 - val_Accuracy: 0.9738 - val_Precision: 0.9665 - val_Recall: 0.9478 - val_TP: 762.0700 - val_TN: 1087.3800 - val_FP: 18.6200 - val_FN: 41.9300\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1550 - Accuracy: 0.9830 - Precision: 0.9673 - Recall: 0.9657 - TP: 3256.2800 - TN: 5569.8301 - FP: 77.1700 - FN: 115.7200 - val_loss: 0.3056 - val_Accuracy: 0.9670 - val_Precision: 0.9426 - val_Recall: 0.9606 - val_TP: 772.3500 - val_TN: 1067.0200 - val_FP: 38.9800 - val_FN: 31.6500\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1476 - Accuracy: 0.9843 - Precision: 0.9676 - Recall: 0.9681 - TP: 3264.4600 - TN: 5570.6699 - FP: 76.3300 - FN: 107.5400 - val_loss: 0.3372 - val_Accuracy: 0.9691 - val_Precision: 0.9521 - val_Recall: 0.9551 - val_TP: 767.9300 - val_TN: 1075.3101 - val_FP: 30.6900 - val_FN: 36.0700\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2337 - Accuracy: 0.9824 - Precision: 0.9654 - Recall: 0.9648 - TP: 3253.1699 - TN: 5563.2300 - FP: 83.7700 - FN: 118.8300 - val_loss: 0.3405 - val_Accuracy: 0.9738 - val_Precision: 0.9712 - val_Recall: 0.9419 - val_TP: 757.2800 - val_TN: 1091.2800 - val_FP: 14.7200 - val_FN: 46.7200\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1942 - Accuracy: 0.9863 - Precision: 0.9696 - Recall: 0.9683 - TP: 3265.1899 - TN: 5577.3398 - FP: 69.6600 - FN: 106.8100 - val_loss: 0.3083 - val_Accuracy: 0.9707 - val_Precision: 0.9583 - val_Recall: 0.9487 - val_TP: 762.7700 - val_TN: 1080.6400 - val_FP: 25.3600 - val_FN: 41.2300\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1641 - Accuracy: 0.9864 - Precision: 0.9689 - Recall: 0.9690 - TP: 3267.4800 - TN: 5575.0898 - FP: 71.9100 - FN: 104.5200 - val_loss: 0.3162 - val_Accuracy: 0.9696 - val_Precision: 0.9614 - val_Recall: 0.9465 - val_TP: 761.0100 - val_TN: 1083.2100 - val_FP: 22.7900 - val_FN: 42.9900\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2237 - Accuracy: 0.9844 - Precision: 0.9673 - Recall: 0.9667 - TP: 3259.6899 - TN: 5569.6201 - FP: 77.3800 - FN: 112.3100 - val_loss: 0.3818 - val_Accuracy: 0.9691 - val_Precision: 0.9525 - val_Recall: 0.9513 - val_TP: 764.8200 - val_TN: 1075.7000 - val_FP: 30.3000 - val_FN: 39.1800\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2027 - Accuracy: 0.9865 - Precision: 0.9684 - Recall: 0.9695 - TP: 3269.1299 - TN: 5573.2402 - FP: 73.7600 - FN: 102.8700 - val_loss: 0.3704 - val_Accuracy: 0.9639 - val_Precision: 0.9674 - val_Recall: 0.9278 - val_TP: 745.9900 - val_TN: 1088.5000 - val_FP: 17.5000 - val_FN: 58.0100\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 3s 6ms/step - loss: 0.2719 - Accuracy: 0.9824 - Precision: 0.9645 - Recall: 0.9637 - TP: 3249.5300 - TN: 5560.2998 - FP: 86.7000 - FN: 122.4700 - val_loss: 0.2904 - val_Accuracy: 0.9681 - val_Precision: 0.9478 - val_Recall: 0.9570 - val_TP: 769.4300 - val_TN: 1071.5699 - val_FP: 34.4300 - val_FN: 34.5700\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2729 - Accuracy: 0.9838 - Precision: 0.9660 - Recall: 0.9664 - TP: 3258.7800 - TN: 5565.0698 - FP: 81.9300 - FN: 113.2200 - val_loss: 0.3431 - val_Accuracy: 0.9702 - val_Precision: 0.9436 - val_Recall: 0.9613 - val_TP: 772.8800 - val_TN: 1067.8500 - val_FP: 38.1500 - val_FN: 31.1200\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3674 - Accuracy: 0.9800 - Precision: 0.9634 - Recall: 0.9616 - TP: 3242.4500 - TN: 5556.5898 - FP: 90.4100 - FN: 129.5500 - val_loss: 0.3139 - val_Accuracy: 0.9670 - val_Precision: 0.9487 - val_Recall: 0.9525 - val_TP: 765.8000 - val_TN: 1072.5000 - val_FP: 33.5000 - val_FN: 38.2000\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1465 - Accuracy: 0.9854 - Precision: 0.9694 - Recall: 0.9686 - TP: 3266.1299 - TN: 5576.7900 - FP: 70.2100 - FN: 105.8700 - val_loss: 0.2970 - val_Accuracy: 0.9696 - val_Precision: 0.9497 - val_Recall: 0.9586 - val_TP: 770.7400 - val_TN: 1073.1300 - val_FP: 32.8700 - val_FN: 33.2600\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2760 - Accuracy: 0.9828 - Precision: 0.9662 - Recall: 0.9656 - TP: 3255.9900 - TN: 5565.7998 - FP: 81.2000 - FN: 116.0100 - val_loss: 0.2889 - val_Accuracy: 0.9702 - val_Precision: 0.9615 - val_Recall: 0.9466 - val_TP: 761.0900 - val_TN: 1083.2600 - val_FP: 22.7400 - val_FN: 42.9100\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2684 - Accuracy: 0.9823 - Precision: 0.9656 - Recall: 0.9661 - TP: 3257.6299 - TN: 5563.8599 - FP: 83.1400 - FN: 114.3700 - val_loss: 0.3429 - val_Accuracy: 0.9707 - val_Precision: 0.9607 - val_Recall: 0.9466 - val_TP: 761.0500 - val_TN: 1082.6700 - val_FP: 23.3300 - val_FN: 42.9500\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2087 - Accuracy: 0.9837 - Precision: 0.9672 - Recall: 0.9662 - TP: 3257.9700 - TN: 5569.3301 - FP: 77.6700 - FN: 114.0300 - val_loss: 0.2958 - val_Accuracy: 0.9670 - val_Precision: 0.9553 - val_Recall: 0.9485 - val_TP: 762.5800 - val_TN: 1078.1500 - val_FP: 27.8500 - val_FN: 41.4200\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1830 - Accuracy: 0.9851 - Precision: 0.9681 - Recall: 0.9673 - TP: 3261.7000 - TN: 5572.5000 - FP: 74.5000 - FN: 110.3000 - val_loss: 0.3070 - val_Accuracy: 0.9696 - val_Precision: 0.9599 - val_Recall: 0.9484 - val_TP: 762.5300 - val_TN: 1081.9200 - val_FP: 24.0800 - val_FN: 41.4700\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2901 - Accuracy: 0.9814 - Precision: 0.9650 - Recall: 0.9645 - TP: 3252.3501 - TN: 5561.6299 - FP: 85.3700 - FN: 119.6500 - val_loss: 0.2937 - val_Accuracy: 0.9702 - val_Precision: 0.9495 - val_Recall: 0.9588 - val_TP: 770.9000 - val_TN: 1073.0000 - val_FP: 33.0000 - val_FN: 33.1000\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2141 - Accuracy: 0.9825 - Precision: 0.9661 - Recall: 0.9659 - TP: 3256.8999 - TN: 5565.5000 - FP: 81.5000 - FN: 115.1000 - val_loss: 0.3121 - val_Accuracy: 0.9702 - val_Precision: 0.9516 - val_Recall: 0.9539 - val_TP: 766.9400 - val_TN: 1074.8600 - val_FP: 31.1400 - val_FN: 37.0600\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1376 - Accuracy: 0.9844 - Precision: 0.9682 - Recall: 0.9671 - TP: 3261.0701 - TN: 5572.8198 - FP: 74.1800 - FN: 110.9300 - val_loss: 0.2939 - val_Accuracy: 0.9717 - val_Precision: 0.9631 - val_Recall: 0.9477 - val_TP: 761.9300 - val_TN: 1084.6000 - val_FP: 21.4000 - val_FN: 42.0700\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2997 - Accuracy: 0.9843 - Precision: 0.9670 - Recall: 0.9658 - TP: 3256.5500 - TN: 5568.5200 - FP: 78.4800 - FN: 115.4500 - val_loss: 0.2938 - val_Accuracy: 0.9696 - val_Precision: 0.9520 - val_Recall: 0.9568 - val_TP: 769.2300 - val_TN: 1075.1400 - val_FP: 30.8600 - val_FN: 34.7700\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2717 - Accuracy: 0.9833 - Precision: 0.9651 - Recall: 0.9657 - TP: 3256.2500 - TN: 5562.1401 - FP: 84.8600 - FN: 115.7500 - val_loss: 0.5928 - val_Accuracy: 0.9592 - val_Precision: 0.9297 - val_Recall: 0.9497 - val_TP: 763.5800 - val_TN: 1056.2900 - val_FP: 49.7100 - val_FN: 40.4200\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2093 - Accuracy: 0.9856 - Precision: 0.9695 - Recall: 0.9687 - TP: 3266.5100 - TN: 5577.1201 - FP: 69.8800 - FN: 105.4900 - val_loss: 0.2992 - val_Accuracy: 0.9702 - val_Precision: 0.9535 - val_Recall: 0.9566 - val_TP: 769.0800 - val_TN: 1076.4301 - val_FP: 29.5700 - val_FN: 34.9200\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1978 - Accuracy: 0.9837 - Precision: 0.9672 - Recall: 0.9661 - TP: 3257.8401 - TN: 5569.2100 - FP: 77.7900 - FN: 114.1600 - val_loss: 0.4380 - val_Accuracy: 0.9665 - val_Precision: 0.9411 - val_Recall: 0.9573 - val_TP: 769.6500 - val_TN: 1065.7900 - val_FP: 40.2100 - val_FN: 34.3500\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3319 - Accuracy: 0.9828 - Precision: 0.9655 - Recall: 0.9646 - TP: 3252.5701 - TN: 5563.7002 - FP: 83.3000 - FN: 119.4300 - val_loss: 0.3098 - val_Accuracy: 0.9712 - val_Precision: 0.9543 - val_Recall: 0.9545 - val_TP: 767.4100 - val_TN: 1077.0900 - val_FP: 28.9100 - val_FN: 36.5900\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2831 - Accuracy: 0.9843 - Precision: 0.9669 - Recall: 0.9659 - TP: 3257.0400 - TN: 5567.9302 - FP: 79.0700 - FN: 114.9600 - val_loss: 0.3085 - val_Accuracy: 0.9707 - val_Precision: 0.9586 - val_Recall: 0.9495 - val_TP: 763.4100 - val_TN: 1080.8500 - val_FP: 25.1500 - val_FN: 40.5900\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2187 - Accuracy: 0.9816 - Precision: 0.9656 - Recall: 0.9651 - TP: 3254.2300 - TN: 5564.0801 - FP: 82.9200 - FN: 117.7700 - val_loss: 0.2998 - val_Accuracy: 0.9686 - val_Precision: 0.9572 - val_Recall: 0.9498 - val_TP: 763.6100 - val_TN: 1079.6300 - val_FP: 26.3700 - val_FN: 40.3900\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2084 - Accuracy: 0.9833 - Precision: 0.9658 - Recall: 0.9667 - TP: 3259.6201 - TN: 5564.2598 - FP: 82.7400 - FN: 112.3800 - val_loss: 0.3083 - val_Accuracy: 0.9723 - val_Precision: 0.9664 - val_Recall: 0.9420 - val_TP: 757.3700 - val_TN: 1087.4301 - val_FP: 18.5700 - val_FN: 46.6300\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2028 - Accuracy: 0.9838 - Precision: 0.9676 - Recall: 0.9669 - TP: 3260.3799 - TN: 5570.5601 - FP: 76.4400 - FN: 111.6200 - val_loss: 0.3000 - val_Accuracy: 0.9723 - val_Precision: 0.9672 - val_Recall: 0.9465 - val_TP: 761.0100 - val_TN: 1087.9399 - val_FP: 18.0600 - val_FN: 42.9900\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2528 - Accuracy: 0.9840 - Precision: 0.9679 - Recall: 0.9669 - TP: 3260.3401 - TN: 5571.6699 - FP: 75.3300 - FN: 111.6600 - val_loss: 0.3431 - val_Accuracy: 0.9702 - val_Precision: 0.9558 - val_Recall: 0.9527 - val_TP: 765.9900 - val_TN: 1078.4700 - val_FP: 27.5300 - val_FN: 38.0100\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2354 - Accuracy: 0.9845 - Precision: 0.9682 - Recall: 0.9680 - TP: 3264.0400 - TN: 5572.4302 - FP: 74.5700 - FN: 107.9600 - val_loss: 0.3833 - val_Accuracy: 0.9686 - val_Precision: 0.9701 - val_Recall: 0.9348 - val_TP: 751.5500 - val_TN: 1090.5400 - val_FP: 15.4600 - val_FN: 52.4500\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1580 - Accuracy: 0.9846 - Precision: 0.9682 - Recall: 0.9673 - TP: 3261.7700 - TN: 5572.6802 - FP: 74.3200 - FN: 110.2300 - val_loss: 0.3682 - val_Accuracy: 0.9670 - val_Precision: 0.9442 - val_Recall: 0.9585 - val_TP: 770.6100 - val_TN: 1068.5000 - val_FP: 37.5000 - val_FN: 33.3900\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3496 - Accuracy: 0.9856 - Precision: 0.9682 - Recall: 0.9681 - TP: 3264.4800 - TN: 5572.7100 - FP: 74.2900 - FN: 107.5200 - val_loss: 0.4338 - val_Accuracy: 0.9654 - val_Precision: 0.9491 - val_Recall: 0.9500 - val_TP: 763.8400 - val_TN: 1072.9800 - val_FP: 33.0200 - val_FN: 40.1600\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1848 - Accuracy: 0.9851 - Precision: 0.9686 - Recall: 0.9683 - TP: 3264.9700 - TN: 5574.1099 - FP: 72.8900 - FN: 107.0300 - val_loss: 0.6002 - val_Accuracy: 0.9628 - val_Precision: 0.9347 - val_Recall: 0.9552 - val_TP: 768.0000 - val_TN: 1060.4301 - val_FP: 45.5700 - val_FN: 36.0000\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 7ms/step - loss: 0.2473 - Accuracy: 0.9817 - Precision: 0.9658 - Recall: 0.9645 - TP: 3252.1299 - TN: 5564.5298 - FP: 82.4700 - FN: 119.8700 - val_loss: 0.2750 - val_Accuracy: 0.9691 - val_Precision: 0.9563 - val_Recall: 0.9503 - val_TP: 764.0300 - val_TN: 1078.8700 - val_FP: 27.1300 - val_FN: 39.9700\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2340 - Accuracy: 0.9824 - Precision: 0.9655 - Recall: 0.9653 - TP: 3255.0100 - TN: 5563.3701 - FP: 83.6300 - FN: 116.9900 - val_loss: 0.3088 - val_Accuracy: 0.9707 - val_Precision: 0.9628 - val_Recall: 0.9440 - val_TP: 758.9500 - val_TN: 1084.4800 - val_FP: 21.5200 - val_FN: 45.0500\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1886 - Accuracy: 0.9848 - Precision: 0.9667 - Recall: 0.9662 - TP: 3257.8899 - TN: 5567.7300 - FP: 79.2700 - FN: 114.1100 - val_loss: 0.3074 - val_Accuracy: 0.9696 - val_Precision: 0.9601 - val_Recall: 0.9453 - val_TP: 760.0000 - val_TN: 1082.2100 - val_FP: 23.7900 - val_FN: 44.0000\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2816 - Accuracy: 0.9835 - Precision: 0.9666 - Recall: 0.9675 - TP: 3262.3999 - TN: 5567.1201 - FP: 79.8800 - FN: 109.6000 - val_loss: 0.3364 - val_Accuracy: 0.9681 - val_Precision: 0.9689 - val_Recall: 0.9322 - val_TP: 749.4700 - val_TN: 1089.5900 - val_FP: 16.4100 - val_FN: 54.5300\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2136 - Accuracy: 0.9831 - Precision: 0.9666 - Recall: 0.9655 - TP: 3255.8000 - TN: 5567.3999 - FP: 79.6000 - FN: 116.2000 - val_loss: 0.3339 - val_Accuracy: 0.9712 - val_Precision: 0.9571 - val_Recall: 0.9521 - val_TP: 765.4600 - val_TN: 1079.5400 - val_FP: 26.4600 - val_FN: 38.5400\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.4355 - Accuracy: 0.9825 - Precision: 0.9663 - Recall: 0.9647 - TP: 3252.8601 - TN: 5566.3101 - FP: 80.6900 - FN: 119.1400 - val_loss: 0.3153 - val_Accuracy: 0.9691 - val_Precision: 0.9573 - val_Recall: 0.9518 - val_TP: 765.2200 - val_TN: 1079.7800 - val_FP: 26.2200 - val_FN: 38.7800\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3014 - Accuracy: 0.9818 - Precision: 0.9650 - Recall: 0.9651 - TP: 3254.2200 - TN: 5561.8999 - FP: 85.1000 - FN: 117.7800 - val_loss: 0.3129 - val_Accuracy: 0.9696 - val_Precision: 0.9625 - val_Recall: 0.9468 - val_TP: 761.2300 - val_TN: 1084.1200 - val_FP: 21.8800 - val_FN: 42.7700\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1291 - Accuracy: 0.9849 - Precision: 0.9689 - Recall: 0.9687 - TP: 3266.5400 - TN: 5575.0298 - FP: 71.9700 - FN: 105.4600 - val_loss: 0.3160 - val_Accuracy: 0.9723 - val_Precision: 0.9650 - val_Recall: 0.9450 - val_TP: 759.8200 - val_TN: 1086.1899 - val_FP: 19.8100 - val_FN: 44.1800\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3322 - Accuracy: 0.9841 - Precision: 0.9663 - Recall: 0.9660 - TP: 3257.4099 - TN: 5566.3799 - FP: 80.6200 - FN: 114.5900 - val_loss: 0.3689 - val_Accuracy: 0.9712 - val_Precision: 0.9593 - val_Recall: 0.9490 - val_TP: 763.0000 - val_TN: 1081.4700 - val_FP: 24.5300 - val_FN: 41.0000\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2600 - Accuracy: 0.9823 - Precision: 0.9657 - Recall: 0.9649 - TP: 3253.5701 - TN: 5564.3301 - FP: 82.6700 - FN: 118.4300 - val_loss: 0.3159 - val_Accuracy: 0.9686 - val_Precision: 0.9473 - val_Recall: 0.9590 - val_TP: 771.0400 - val_TN: 1071.0900 - val_FP: 34.9100 - val_FN: 32.9600\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.4184 - Accuracy: 0.9833 - Precision: 0.9652 - Recall: 0.9650 - TP: 3253.8401 - TN: 5562.6499 - FP: 84.3500 - FN: 118.1600 - val_loss: 0.3374 - val_Accuracy: 0.9681 - val_Precision: 0.9566 - val_Recall: 0.9456 - val_TP: 760.2300 - val_TN: 1079.3400 - val_FP: 26.6600 - val_FN: 43.7700\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2227 - Accuracy: 0.9825 - Precision: 0.9665 - Recall: 0.9654 - TP: 3255.4199 - TN: 5566.9399 - FP: 80.0600 - FN: 116.5800 - val_loss: 0.3786 - val_Accuracy: 0.9686 - val_Precision: 0.9415 - val_Recall: 0.9614 - val_TP: 772.9700 - val_TN: 1066.0000 - val_FP: 40.0000 - val_FN: 31.0300\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2143 - Accuracy: 0.9825 - Precision: 0.9650 - Recall: 0.9661 - TP: 3257.7400 - TN: 5561.7598 - FP: 85.2400 - FN: 114.2600 - val_loss: 0.3820 - val_Accuracy: 0.9712 - val_Precision: 0.9614 - val_Recall: 0.9479 - val_TP: 762.1000 - val_TN: 1083.2000 - val_FP: 22.8000 - val_FN: 41.9000\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2045 - Accuracy: 0.9856 - Precision: 0.9708 - Recall: 0.9681 - TP: 3264.3701 - TN: 5581.5801 - FP: 65.4200 - FN: 107.6300 - val_loss: 0.3236 - val_Accuracy: 0.9681 - val_Precision: 0.9463 - val_Recall: 0.9559 - val_TP: 768.5500 - val_TN: 1070.3199 - val_FP: 35.6800 - val_FN: 35.4500\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2533 - Accuracy: 0.9814 - Precision: 0.9635 - Recall: 0.9651 - TP: 3254.2900 - TN: 5556.6401 - FP: 90.3600 - FN: 117.7100 - val_loss: 0.3374 - val_Accuracy: 0.9675 - val_Precision: 0.9666 - val_Recall: 0.9381 - val_TP: 754.2200 - val_TN: 1087.6400 - val_FP: 18.3600 - val_FN: 49.7800\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3235 - Accuracy: 0.9834 - Precision: 0.9674 - Recall: 0.9652 - TP: 3254.5500 - TN: 5569.9702 - FP: 77.0300 - FN: 117.4500 - val_loss: 0.3744 - val_Accuracy: 0.9681 - val_Precision: 0.9621 - val_Recall: 0.9410 - val_TP: 756.6000 - val_TN: 1083.9900 - val_FP: 22.0100 - val_FN: 47.4000\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3082 - Accuracy: 0.9813 - Precision: 0.9636 - Recall: 0.9656 - TP: 3256.0701 - TN: 5556.8701 - FP: 90.1300 - FN: 115.9300 - val_loss: 0.4286 - val_Accuracy: 0.9675 - val_Precision: 0.9675 - val_Recall: 0.9356 - val_TP: 752.2200 - val_TN: 1088.4301 - val_FP: 17.5700 - val_FN: 51.7800\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2693 - Accuracy: 0.9837 - Precision: 0.9691 - Recall: 0.9661 - TP: 3257.6001 - TN: 5575.9902 - FP: 71.0100 - FN: 114.4000 - val_loss: 0.3737 - val_Accuracy: 0.9670 - val_Precision: 0.9471 - val_Recall: 0.9569 - val_TP: 769.3700 - val_TN: 1071.0900 - val_FP: 34.9100 - val_FN: 34.6300\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3480 - Accuracy: 0.9837 - Precision: 0.9663 - Recall: 0.9658 - TP: 3256.7000 - TN: 5566.3101 - FP: 80.6900 - FN: 115.3000 - val_loss: 0.3522 - val_Accuracy: 0.9712 - val_Precision: 0.9668 - val_Recall: 0.9426 - val_TP: 757.8800 - val_TN: 1087.8000 - val_FP: 18.2000 - val_FN: 46.1200\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3568 - Accuracy: 0.9831 - Precision: 0.9663 - Recall: 0.9662 - TP: 3258.1299 - TN: 5566.2300 - FP: 80.7700 - FN: 113.8700 - val_loss: 0.3603 - val_Accuracy: 0.9691 - val_Precision: 0.9581 - val_Recall: 0.9451 - val_TP: 759.9000 - val_TN: 1080.6200 - val_FP: 25.3800 - val_FN: 44.1000\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2453 - Accuracy: 0.9854 - Precision: 0.9695 - Recall: 0.9686 - TP: 3266.0400 - TN: 5577.0200 - FP: 69.9800 - FN: 105.9600 - val_loss: 0.3298 - val_Accuracy: 0.9717 - val_Precision: 0.9654 - val_Recall: 0.9441 - val_TP: 759.0400 - val_TN: 1086.5900 - val_FP: 19.4100 - val_FN: 44.9600\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 7ms/step - loss: 0.2741 - Accuracy: 0.9838 - Precision: 0.9668 - Recall: 0.9661 - TP: 3257.5901 - TN: 5567.8198 - FP: 79.1800 - FN: 114.4100 - val_loss: 0.2880 - val_Accuracy: 0.9702 - val_Precision: 0.9519 - val_Recall: 0.9559 - val_TP: 768.5300 - val_TN: 1075.1200 - val_FP: 30.8800 - val_FN: 35.4700\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.4029 - Accuracy: 0.9804 - Precision: 0.9626 - Recall: 0.9631 - TP: 3247.5601 - TN: 5553.6001 - FP: 93.4000 - FN: 124.4400 - val_loss: 0.3898 - val_Accuracy: 0.9681 - val_Precision: 0.9590 - val_Recall: 0.9447 - val_TP: 759.5000 - val_TN: 1081.3400 - val_FP: 24.6600 - val_FN: 44.5000\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3919 - Accuracy: 0.9818 - Precision: 0.9644 - Recall: 0.9646 - TP: 3252.5601 - TN: 5559.7798 - FP: 87.2200 - FN: 119.4400 - val_loss: 0.3000 - val_Accuracy: 0.9728 - val_Precision: 0.9704 - val_Recall: 0.9398 - val_TP: 755.6000 - val_TN: 1090.6801 - val_FP: 15.3200 - val_FN: 48.4000\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.4979 - Accuracy: 0.9820 - Precision: 0.9647 - Recall: 0.9632 - TP: 3247.8601 - TN: 5560.7900 - FP: 86.2100 - FN: 124.1400 - val_loss: 0.3869 - val_Accuracy: 0.9686 - val_Precision: 0.9520 - val_Recall: 0.9538 - val_TP: 766.8500 - val_TN: 1075.2500 - val_FP: 30.7500 - val_FN: 37.1500\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2071 - Accuracy: 0.9848 - Precision: 0.9687 - Recall: 0.9678 - TP: 3263.4199 - TN: 5574.6299 - FP: 72.3700 - FN: 108.5800 - val_loss: 0.3974 - val_Accuracy: 0.9707 - val_Precision: 0.9581 - val_Recall: 0.9492 - val_TP: 763.1200 - val_TN: 1080.5100 - val_FP: 25.4900 - val_FN: 40.8800\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1858 - Accuracy: 0.9849 - Precision: 0.9688 - Recall: 0.9686 - TP: 3266.1799 - TN: 5574.8599 - FP: 72.1400 - FN: 105.8200 - val_loss: 0.3376 - val_Accuracy: 0.9712 - val_Precision: 0.9636 - val_Recall: 0.9459 - val_TP: 760.4700 - val_TN: 1085.0300 - val_FP: 20.9700 - val_FN: 43.5300\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.4894 - Accuracy: 0.9850 - Precision: 0.9684 - Recall: 0.9669 - TP: 3260.2200 - TN: 5573.4199 - FP: 73.5800 - FN: 111.7800 - val_loss: 0.3402 - val_Accuracy: 0.9660 - val_Precision: 0.9507 - val_Recall: 0.9486 - val_TP: 762.6600 - val_TN: 1074.3000 - val_FP: 31.7000 - val_FN: 41.3400\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2962 - Accuracy: 0.9841 - Precision: 0.9668 - Recall: 0.9660 - TP: 3257.4800 - TN: 5568.2402 - FP: 78.7600 - FN: 114.5200 - val_loss: 0.5777 - val_Accuracy: 0.9581 - val_Precision: 0.9214 - val_Recall: 0.9618 - val_TP: 773.2500 - val_TN: 1048.1700 - val_FP: 57.8300 - val_FN: 30.7500\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1435 - Accuracy: 0.9850 - Precision: 0.9683 - Recall: 0.9677 - TP: 3263.1899 - TN: 5572.8799 - FP: 74.1200 - FN: 108.8100 - val_loss: 0.3201 - val_Accuracy: 0.9665 - val_Precision: 0.9453 - val_Recall: 0.9585 - val_TP: 770.6300 - val_TN: 1069.3900 - val_FP: 36.6100 - val_FN: 33.3700\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.5360 - Accuracy: 0.9828 - Precision: 0.9651 - Recall: 0.9653 - TP: 3255.1001 - TN: 5562.2500 - FP: 84.7500 - FN: 116.9000 - val_loss: 0.3414 - val_Accuracy: 0.9634 - val_Precision: 0.9355 - val_Recall: 0.9619 - val_TP: 773.3300 - val_TN: 1060.7100 - val_FP: 45.2900 - val_FN: 30.6700\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2663 - Accuracy: 0.9807 - Precision: 0.9631 - Recall: 0.9636 - TP: 3249.1201 - TN: 5555.3701 - FP: 91.6300 - FN: 122.8800 - val_loss: 0.3274 - val_Accuracy: 0.9717 - val_Precision: 0.9700 - val_Recall: 0.9394 - val_TP: 755.3000 - val_TN: 1090.3500 - val_FP: 15.6500 - val_FN: 48.7000\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1766 - Accuracy: 0.9865 - Precision: 0.9703 - Recall: 0.9695 - TP: 3269.2100 - TN: 5579.8799 - FP: 67.1200 - FN: 102.7900 - val_loss: 0.3407 - val_Accuracy: 0.9707 - val_Precision: 0.9557 - val_Recall: 0.9529 - val_TP: 766.1300 - val_TN: 1078.3700 - val_FP: 27.6300 - val_FN: 37.8700\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2462 - Accuracy: 0.9833 - Precision: 0.9658 - Recall: 0.9648 - TP: 3253.4600 - TN: 5564.6201 - FP: 82.3800 - FN: 118.5400 - val_loss: 0.3109 - val_Accuracy: 0.9702 - val_Precision: 0.9598 - val_Recall: 0.9489 - val_TP: 762.9500 - val_TN: 1081.9301 - val_FP: 24.0700 - val_FN: 41.0500\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1506 - Accuracy: 0.9869 - Precision: 0.9701 - Recall: 0.9707 - TP: 3273.1399 - TN: 5579.1099 - FP: 67.8900 - FN: 98.8600 - val_loss: 0.3100 - val_Accuracy: 0.9723 - val_Precision: 0.9650 - val_Recall: 0.9467 - val_TP: 761.1700 - val_TN: 1086.1899 - val_FP: 19.8100 - val_FN: 42.8300\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2394 - Accuracy: 0.9838 - Precision: 0.9674 - Recall: 0.9662 - TP: 3257.8999 - TN: 5570.3301 - FP: 76.6700 - FN: 114.1000 - val_loss: 0.3113 - val_Accuracy: 0.9686 - val_Precision: 0.9533 - val_Recall: 0.9546 - val_TP: 767.5300 - val_TN: 1076.3400 - val_FP: 29.6600 - val_FN: 36.4700\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1501 - Accuracy: 0.9858 - Precision: 0.9688 - Recall: 0.9696 - TP: 3269.6399 - TN: 5574.6499 - FP: 72.3500 - FN: 102.3600 - val_loss: 0.4123 - val_Accuracy: 0.9670 - val_Precision: 0.9673 - val_Recall: 0.9340 - val_TP: 750.9400 - val_TN: 1088.2800 - val_FP: 17.7200 - val_FN: 53.0600\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2622 - Accuracy: 0.9825 - Precision: 0.9665 - Recall: 0.9651 - TP: 3254.3701 - TN: 5567.0400 - FP: 79.9600 - FN: 117.6300 - val_loss: 0.3600 - val_Accuracy: 0.9717 - val_Precision: 0.9585 - val_Recall: 0.9492 - val_TP: 763.1900 - val_TN: 1080.8400 - val_FP: 25.1600 - val_FN: 40.8100\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2465 - Accuracy: 0.9845 - Precision: 0.9682 - Recall: 0.9680 - TP: 3264.0400 - TN: 5572.7202 - FP: 74.2800 - FN: 107.9600 - val_loss: 0.3811 - val_Accuracy: 0.9691 - val_Precision: 0.9754 - val_Recall: 0.9267 - val_TP: 745.0400 - val_TN: 1094.8199 - val_FP: 11.1800 - val_FN: 58.9600\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2430 - Accuracy: 0.9837 - Precision: 0.9679 - Recall: 0.9665 - TP: 3259.0100 - TN: 5571.8198 - FP: 75.1800 - FN: 112.9900 - val_loss: 0.3180 - val_Accuracy: 0.9738 - val_Precision: 0.9610 - val_Recall: 0.9538 - val_TP: 766.8700 - val_TN: 1082.7800 - val_FP: 23.2200 - val_FN: 37.1300\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2226 - Accuracy: 0.9840 - Precision: 0.9669 - Recall: 0.9668 - TP: 3259.9800 - TN: 5568.3301 - FP: 78.6700 - FN: 112.0200 - val_loss: 0.3359 - val_Accuracy: 0.9707 - val_Precision: 0.9696 - val_Recall: 0.9389 - val_TP: 754.8400 - val_TN: 1090.0500 - val_FP: 15.9500 - val_FN: 49.1600\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3989 - Accuracy: 0.9821 - Precision: 0.9651 - Recall: 0.9645 - TP: 3252.3899 - TN: 5562.2598 - FP: 84.7400 - FN: 119.6100 - val_loss: 0.3850 - val_Accuracy: 0.9728 - val_Precision: 0.9576 - val_Recall: 0.9528 - val_TP: 766.0800 - val_TN: 1079.9600 - val_FP: 26.0400 - val_FN: 37.9200\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 7ms/step - loss: 0.3359 - Accuracy: 0.9815 - Precision: 0.9643 - Recall: 0.9643 - TP: 3251.5601 - TN: 5559.2500 - FP: 87.7500 - FN: 120.4400 - val_loss: 0.3235 - val_Accuracy: 0.9670 - val_Precision: 0.9428 - val_Recall: 0.9602 - val_TP: 772.0100 - val_TN: 1067.2200 - val_FP: 38.7800 - val_FN: 31.9900\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3863 - Accuracy: 0.9815 - Precision: 0.9637 - Recall: 0.9635 - TP: 3248.9299 - TN: 5557.5601 - FP: 89.4400 - FN: 123.0700 - val_loss: 0.5794 - val_Accuracy: 0.9476 - val_Precision: 0.9028 - val_Recall: 0.9576 - val_TP: 769.8900 - val_TN: 1031.2200 - val_FP: 74.7800 - val_FN: 34.1100\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3272 - Accuracy: 0.9814 - Precision: 0.9645 - Recall: 0.9631 - TP: 3247.7300 - TN: 5560.3599 - FP: 86.6400 - FN: 124.2700 - val_loss: 0.2886 - val_Accuracy: 0.9723 - val_Precision: 0.9518 - val_Recall: 0.9590 - val_TP: 771.0500 - val_TN: 1074.9100 - val_FP: 31.0900 - val_FN: 32.9500\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1654 - Accuracy: 0.9848 - Precision: 0.9682 - Recall: 0.9679 - TP: 3263.7900 - TN: 5572.4800 - FP: 74.5200 - FN: 108.2100 - val_loss: 0.4135 - val_Accuracy: 0.9660 - val_Precision: 0.9511 - val_Recall: 0.9482 - val_TP: 762.3500 - val_TN: 1074.6600 - val_FP: 31.3400 - val_FN: 41.6500\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2974 - Accuracy: 0.9843 - Precision: 0.9679 - Recall: 0.9672 - TP: 3261.2700 - TN: 5571.6299 - FP: 75.3700 - FN: 110.7300 - val_loss: 0.4250 - val_Accuracy: 0.9628 - val_Precision: 0.9347 - val_Recall: 0.9580 - val_TP: 770.2000 - val_TN: 1060.2100 - val_FP: 45.7900 - val_FN: 33.8000\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.5926 - Accuracy: 0.9815 - Precision: 0.9633 - Recall: 0.9632 - TP: 3247.7800 - TN: 5556.0400 - FP: 90.9600 - FN: 124.2200 - val_loss: 0.3214 - val_Accuracy: 0.9717 - val_Precision: 0.9695 - val_Recall: 0.9436 - val_TP: 758.6300 - val_TN: 1089.9000 - val_FP: 16.1000 - val_FN: 45.3700\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2143 - Accuracy: 0.9840 - Precision: 0.9684 - Recall: 0.9668 - TP: 3260.1201 - TN: 5573.6401 - FP: 73.3600 - FN: 111.8800 - val_loss: 0.3097 - val_Accuracy: 0.9681 - val_Precision: 0.9494 - val_Recall: 0.9559 - val_TP: 768.5800 - val_TN: 1072.9800 - val_FP: 33.0200 - val_FN: 35.4200\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2682 - Accuracy: 0.9841 - Precision: 0.9677 - Recall: 0.9675 - TP: 3262.3701 - TN: 5571.0000 - FP: 76.0000 - FN: 109.6300 - val_loss: 0.3056 - val_Accuracy: 0.9702 - val_Precision: 0.9523 - val_Recall: 0.9579 - val_TP: 770.1900 - val_TN: 1075.3700 - val_FP: 30.6300 - val_FN: 33.8100\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2522 - Accuracy: 0.9831 - Precision: 0.9662 - Recall: 0.9664 - TP: 3258.7600 - TN: 5565.9702 - FP: 81.0300 - FN: 113.2400 - val_loss: 0.3292 - val_Accuracy: 0.9707 - val_Precision: 0.9607 - val_Recall: 0.9517 - val_TP: 765.1500 - val_TN: 1082.5900 - val_FP: 23.4100 - val_FN: 38.8500\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2106 - Accuracy: 0.9839 - Precision: 0.9670 - Recall: 0.9671 - TP: 3261.0400 - TN: 5568.7002 - FP: 78.3000 - FN: 110.9600 - val_loss: 0.4430 - val_Accuracy: 0.9675 - val_Precision: 0.9576 - val_Recall: 0.9426 - val_TP: 757.8400 - val_TN: 1080.2500 - val_FP: 25.7500 - val_FN: 46.1600\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1555 - Accuracy: 0.9853 - Precision: 0.9690 - Recall: 0.9682 - TP: 3264.6799 - TN: 5575.6099 - FP: 71.3900 - FN: 107.3200 - val_loss: 0.2905 - val_Accuracy: 0.9728 - val_Precision: 0.9602 - val_Recall: 0.9540 - val_TP: 766.9800 - val_TN: 1082.1100 - val_FP: 23.8900 - val_FN: 37.0200\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1783 - Accuracy: 0.9848 - Precision: 0.9689 - Recall: 0.9670 - TP: 3260.6201 - TN: 5575.4199 - FP: 71.5800 - FN: 111.3800 - val_loss: 0.3435 - val_Accuracy: 0.9665 - val_Precision: 0.9426 - val_Recall: 0.9568 - val_TP: 769.2700 - val_TN: 1067.1200 - val_FP: 38.8800 - val_FN: 34.7300\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.4129 - Accuracy: 0.9833 - Precision: 0.9656 - Recall: 0.9662 - TP: 3257.8799 - TN: 5563.8599 - FP: 83.1400 - FN: 114.1200 - val_loss: 0.3261 - val_Accuracy: 0.9728 - val_Precision: 0.9591 - val_Recall: 0.9530 - val_TP: 766.2200 - val_TN: 1081.1801 - val_FP: 24.8200 - val_FN: 37.7800\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.4334 - Accuracy: 0.9823 - Precision: 0.9650 - Recall: 0.9652 - TP: 3254.7500 - TN: 5561.8599 - FP: 85.1400 - FN: 117.2500 - val_loss: 0.4158 - val_Accuracy: 0.9691 - val_Precision: 0.9570 - val_Recall: 0.9510 - val_TP: 764.6000 - val_TN: 1079.5900 - val_FP: 26.4100 - val_FN: 39.4000\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1977 - Accuracy: 0.9855 - Precision: 0.9693 - Recall: 0.9680 - TP: 3264.0801 - TN: 5576.7998 - FP: 70.2000 - FN: 107.9200 - val_loss: 0.3445 - val_Accuracy: 0.9686 - val_Precision: 0.9558 - val_Recall: 0.9480 - val_TP: 762.2100 - val_TN: 1078.5800 - val_FP: 27.4200 - val_FN: 41.7900\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2423 - Accuracy: 0.9828 - Precision: 0.9661 - Recall: 0.9658 - TP: 3256.7300 - TN: 5565.4399 - FP: 81.5600 - FN: 115.2700 - val_loss: 0.3317 - val_Accuracy: 0.9665 - val_Precision: 0.9468 - val_Recall: 0.9545 - val_TP: 767.3800 - val_TN: 1070.8700 - val_FP: 35.1300 - val_FN: 36.6200\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1469 - Accuracy: 0.9850 - Precision: 0.9682 - Recall: 0.9677 - TP: 3263.0100 - TN: 5572.5898 - FP: 74.4100 - FN: 108.9900 - val_loss: 0.3646 - val_Accuracy: 0.9675 - val_Precision: 0.9477 - val_Recall: 0.9569 - val_TP: 769.3800 - val_TN: 1071.6000 - val_FP: 34.4000 - val_FN: 34.6200\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3144 - Accuracy: 0.9814 - Precision: 0.9646 - Recall: 0.9639 - TP: 3250.4199 - TN: 5560.5498 - FP: 86.4500 - FN: 121.5800 - val_loss: 0.3306 - val_Accuracy: 0.9712 - val_Precision: 0.9544 - val_Recall: 0.9546 - val_TP: 767.4600 - val_TN: 1077.2800 - val_FP: 28.7200 - val_FN: 36.5400\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.4266 - Accuracy: 0.9804 - Precision: 0.9640 - Recall: 0.9634 - TP: 3248.4399 - TN: 5558.5698 - FP: 88.4300 - FN: 123.5600 - val_loss: 0.4137 - val_Accuracy: 0.9717 - val_Precision: 0.9566 - val_Recall: 0.9524 - val_TP: 765.7300 - val_TN: 1079.1400 - val_FP: 26.8600 - val_FN: 38.2700\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2780 - Accuracy: 0.9838 - Precision: 0.9667 - Recall: 0.9665 - TP: 3259.1201 - TN: 5567.7798 - FP: 79.2200 - FN: 112.8800 - val_loss: 0.3338 - val_Accuracy: 0.9717 - val_Precision: 0.9693 - val_Recall: 0.9419 - val_TP: 757.2900 - val_TN: 1089.7100 - val_FP: 16.2900 - val_FN: 46.7100\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1690 - Accuracy: 0.9857 - Precision: 0.9694 - Recall: 0.9695 - TP: 3269.2300 - TN: 5576.8799 - FP: 70.1200 - FN: 102.7700 - val_loss: 0.3788 - val_Accuracy: 0.9717 - val_Precision: 0.9566 - val_Recall: 0.9541 - val_TP: 767.0800 - val_TN: 1079.0699 - val_FP: 26.9300 - val_FN: 36.9200\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1954 - Accuracy: 0.9849 - Precision: 0.9687 - Recall: 0.9684 - TP: 3265.4700 - TN: 5574.7202 - FP: 72.2800 - FN: 106.5300 - val_loss: 0.4123 - val_Accuracy: 0.9707 - val_Precision: 0.9609 - val_Recall: 0.9464 - val_TP: 760.8800 - val_TN: 1082.8500 - val_FP: 23.1500 - val_FN: 43.1200\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3602 - Accuracy: 0.9843 - Precision: 0.9674 - Recall: 0.9667 - TP: 3259.7500 - TN: 5569.8999 - FP: 77.1000 - FN: 112.2500 - val_loss: 0.3412 - val_Accuracy: 0.9717 - val_Precision: 0.9556 - val_Recall: 0.9530 - val_TP: 766.2000 - val_TN: 1078.2800 - val_FP: 27.7200 - val_FN: 37.8000\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 7ms/step - loss: 0.2880 - Accuracy: 0.9826 - Precision: 0.9656 - Recall: 0.9657 - TP: 3256.2800 - TN: 5563.8398 - FP: 83.1600 - FN: 115.7200 - val_loss: 0.4266 - val_Accuracy: 0.9660 - val_Precision: 0.9705 - val_Recall: 0.9295 - val_TP: 747.3500 - val_TN: 1090.9100 - val_FP: 15.0900 - val_FN: 56.6500\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2787 - Accuracy: 0.9840 - Precision: 0.9679 - Recall: 0.9664 - TP: 3258.8201 - TN: 5571.6699 - FP: 75.3300 - FN: 113.1800 - val_loss: 0.3278 - val_Accuracy: 0.9691 - val_Precision: 0.9471 - val_Recall: 0.9582 - val_TP: 770.3700 - val_TN: 1070.9000 - val_FP: 35.1000 - val_FN: 33.6300\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2170 - Accuracy: 0.9825 - Precision: 0.9657 - Recall: 0.9673 - TP: 3261.7500 - TN: 5564.1299 - FP: 82.8700 - FN: 110.2500 - val_loss: 0.3528 - val_Accuracy: 0.9696 - val_Precision: 0.9644 - val_Recall: 0.9447 - val_TP: 759.5600 - val_TN: 1085.7100 - val_FP: 20.2900 - val_FN: 44.4400\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3704 - Accuracy: 0.9823 - Precision: 0.9649 - Recall: 0.9637 - TP: 3249.7500 - TN: 5561.7202 - FP: 85.2800 - FN: 122.2500 - val_loss: 0.3845 - val_Accuracy: 0.9681 - val_Precision: 0.9753 - val_Recall: 0.9278 - val_TP: 745.9600 - val_TN: 1094.7000 - val_FP: 11.3000 - val_FN: 58.0400\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2168 - Accuracy: 0.9827 - Precision: 0.9666 - Recall: 0.9648 - TP: 3253.2800 - TN: 5567.4600 - FP: 79.5400 - FN: 118.7200 - val_loss: 0.3097 - val_Accuracy: 0.9707 - val_Precision: 0.9639 - val_Recall: 0.9464 - val_TP: 760.9100 - val_TN: 1085.2800 - val_FP: 20.7200 - val_FN: 43.0900\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3131 - Accuracy: 0.9814 - Precision: 0.9644 - Recall: 0.9638 - TP: 3249.9199 - TN: 5560.1201 - FP: 86.8800 - FN: 122.0800 - val_loss: 0.3007 - val_Accuracy: 0.9723 - val_Precision: 0.9664 - val_Recall: 0.9463 - val_TP: 760.8600 - val_TN: 1087.3500 - val_FP: 18.6500 - val_FN: 43.1400\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3803 - Accuracy: 0.9831 - Precision: 0.9669 - Recall: 0.9663 - TP: 3258.3201 - TN: 5568.2900 - FP: 78.7100 - FN: 113.6800 - val_loss: 0.3014 - val_Accuracy: 0.9728 - val_Precision: 0.9553 - val_Recall: 0.9580 - val_TP: 770.2000 - val_TN: 1077.9301 - val_FP: 28.0700 - val_FN: 33.8000\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.4560 - Accuracy: 0.9817 - Precision: 0.9631 - Recall: 0.9657 - TP: 3256.3999 - TN: 5555.1099 - FP: 91.8900 - FN: 115.6000 - val_loss: 0.5633 - val_Accuracy: 0.9634 - val_Precision: 0.9479 - val_Recall: 0.9429 - val_TP: 758.1000 - val_TN: 1072.2400 - val_FP: 33.7600 - val_FN: 45.9000\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2307 - Accuracy: 0.9854 - Precision: 0.9704 - Recall: 0.9667 - TP: 3259.8701 - TN: 5580.4902 - FP: 66.5100 - FN: 112.1300 - val_loss: 0.3070 - val_Accuracy: 0.9691 - val_Precision: 0.9499 - val_Recall: 0.9568 - val_TP: 769.2700 - val_TN: 1073.4399 - val_FP: 32.5600 - val_FN: 34.7300\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3518 - Accuracy: 0.9833 - Precision: 0.9658 - Recall: 0.9653 - TP: 3255.0300 - TN: 5564.8198 - FP: 82.1800 - FN: 116.9700 - val_loss: 0.3415 - val_Accuracy: 0.9691 - val_Precision: 0.9591 - val_Recall: 0.9474 - val_TP: 761.6700 - val_TN: 1081.3500 - val_FP: 24.6500 - val_FN: 42.3300\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.4809 - Accuracy: 0.9820 - Precision: 0.9655 - Recall: 0.9651 - TP: 3254.1899 - TN: 5563.6001 - FP: 83.4000 - FN: 117.8100 - val_loss: 0.4835 - val_Accuracy: 0.9665 - val_Precision: 0.9496 - val_Recall: 0.9494 - val_TP: 763.2900 - val_TN: 1073.4399 - val_FP: 32.5600 - val_FN: 40.7100\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2055 - Accuracy: 0.9829 - Precision: 0.9666 - Recall: 0.9664 - TP: 3258.6299 - TN: 5567.5000 - FP: 79.5000 - FN: 113.3700 - val_loss: 0.3788 - val_Accuracy: 0.9702 - val_Precision: 0.9722 - val_Recall: 0.9343 - val_TP: 751.1700 - val_TN: 1092.1700 - val_FP: 13.8300 - val_FN: 52.8300\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2597 - Accuracy: 0.9838 - Precision: 0.9679 - Recall: 0.9667 - TP: 3259.8401 - TN: 5571.7798 - FP: 75.2200 - FN: 112.1600 - val_loss: 0.3392 - val_Accuracy: 0.9717 - val_Precision: 0.9650 - val_Recall: 0.9463 - val_TP: 760.8400 - val_TN: 1086.2100 - val_FP: 19.7900 - val_FN: 43.1600\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1764 - Accuracy: 0.9849 - Precision: 0.9684 - Recall: 0.9684 - TP: 3265.4700 - TN: 5573.2202 - FP: 73.7800 - FN: 106.5300 - val_loss: 0.5665 - val_Accuracy: 0.9623 - val_Precision: 0.9376 - val_Recall: 0.9558 - val_TP: 768.4600 - val_TN: 1062.9301 - val_FP: 43.0700 - val_FN: 35.5400\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2283 - Accuracy: 0.9829 - Precision: 0.9653 - Recall: 0.9653 - TP: 3254.9600 - TN: 5562.8701 - FP: 84.1300 - FN: 117.0400 - val_loss: 0.3989 - val_Accuracy: 0.9644 - val_Precision: 0.9770 - val_Recall: 0.9218 - val_TP: 741.1500 - val_TN: 1096.0900 - val_FP: 9.9100 - val_FN: 62.8500\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.4780 - Accuracy: 0.9826 - Precision: 0.9652 - Recall: 0.9641 - TP: 3250.8799 - TN: 5562.6899 - FP: 84.3100 - FN: 121.1200 - val_loss: 0.4582 - val_Accuracy: 0.9686 - val_Precision: 0.9572 - val_Recall: 0.9466 - val_TP: 761.0600 - val_TN: 1079.8199 - val_FP: 26.1800 - val_FN: 42.9400\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3802 - Accuracy: 0.9828 - Precision: 0.9653 - Recall: 0.9646 - TP: 3252.5200 - TN: 5563.1099 - FP: 83.8900 - FN: 119.4800 - val_loss: 1.0217 - val_Accuracy: 0.9267 - val_Precision: 0.8549 - val_Recall: 0.9674 - val_TP: 777.8100 - val_TN: 982.8300 - val_FP: 123.1700 - val_FN: 26.1900\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2690 - Accuracy: 0.9846 - Precision: 0.9677 - Recall: 0.9679 - TP: 3263.8899 - TN: 5571.0698 - FP: 75.9300 - FN: 108.1100 - val_loss: 0.4080 - val_Accuracy: 0.9681 - val_Precision: 0.9590 - val_Recall: 0.9450 - val_TP: 759.8200 - val_TN: 1081.3199 - val_FP: 24.6800 - val_FN: 44.1800\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1992 - Accuracy: 0.9838 - Precision: 0.9678 - Recall: 0.9668 - TP: 3259.9299 - TN: 5571.5601 - FP: 75.4400 - FN: 112.0700 - val_loss: 0.3484 - val_Accuracy: 0.9707 - val_Precision: 0.9609 - val_Recall: 0.9459 - val_TP: 760.5400 - val_TN: 1082.8600 - val_FP: 23.1400 - val_FN: 43.4600\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2085 - Accuracy: 0.9857 - Precision: 0.9691 - Recall: 0.9697 - TP: 3269.8701 - TN: 5575.8301 - FP: 71.1700 - FN: 102.1300 - val_loss: 0.3524 - val_Accuracy: 0.9723 - val_Precision: 0.9668 - val_Recall: 0.9444 - val_TP: 759.3000 - val_TN: 1087.6700 - val_FP: 18.3300 - val_FN: 44.7000\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2549 - Accuracy: 0.9817 - Precision: 0.9651 - Recall: 0.9644 - TP: 3252.0000 - TN: 5562.2300 - FP: 84.7700 - FN: 120.0000 - val_loss: 0.4034 - val_Accuracy: 0.9723 - val_Precision: 0.9786 - val_Recall: 0.9336 - val_TP: 750.6100 - val_TN: 1097.2500 - val_FP: 8.7500 - val_FN: 53.3900\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3027 - Accuracy: 0.9826 - Precision: 0.9660 - Recall: 0.9655 - TP: 3255.5300 - TN: 5565.4102 - FP: 81.5900 - FN: 116.4700 - val_loss: 0.4025 - val_Accuracy: 0.9691 - val_Precision: 0.9500 - val_Recall: 0.9558 - val_TP: 768.4700 - val_TN: 1073.6100 - val_FP: 32.3900 - val_FN: 35.5300\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2524 - Accuracy: 0.9848 - Precision: 0.9685 - Recall: 0.9675 - TP: 3262.4199 - TN: 5574.0298 - FP: 72.9700 - FN: 109.5800 - val_loss: 1.3215 - val_Accuracy: 0.9288 - val_Precision: 0.8708 - val_Recall: 0.9487 - val_TP: 762.7700 - val_TN: 1001.4600 - val_FP: 104.5400 - val_FN: 41.2300\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.6690 - Accuracy: 0.9816 - Precision: 0.9651 - Recall: 0.9645 - TP: 3252.3601 - TN: 5562.5298 - FP: 84.4700 - FN: 119.6400 - val_loss: 0.4998 - val_Accuracy: 0.9644 - val_Precision: 0.9477 - val_Recall: 0.9515 - val_TP: 764.9900 - val_TN: 1071.7700 - val_FP: 34.2300 - val_FN: 39.0100\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2508 - Accuracy: 0.9844 - Precision: 0.9676 - Recall: 0.9689 - TP: 3267.0601 - TN: 5570.8901 - FP: 76.1100 - FN: 104.9400 - val_loss: 0.6661 - val_Accuracy: 0.9634 - val_Precision: 0.9443 - val_Recall: 0.9493 - val_TP: 763.2100 - val_TN: 1068.9600 - val_FP: 37.0400 - val_FN: 40.7900\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2269 - Accuracy: 0.9824 - Precision: 0.9655 - Recall: 0.9651 - TP: 3254.2500 - TN: 5563.8398 - FP: 83.1600 - FN: 117.7500 - val_loss: 0.4604 - val_Accuracy: 0.9670 - val_Precision: 0.9590 - val_Recall: 0.9408 - val_TP: 756.4000 - val_TN: 1081.4700 - val_FP: 24.5300 - val_FN: 47.6000\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 7ms/step - loss: 0.2315 - Accuracy: 0.9840 - Precision: 0.9660 - Recall: 0.9665 - TP: 3259.1699 - TN: 5565.2998 - FP: 81.7000 - FN: 112.8300 - val_loss: 0.3917 - val_Accuracy: 0.9691 - val_Precision: 0.9592 - val_Recall: 0.9448 - val_TP: 759.5800 - val_TN: 1081.5200 - val_FP: 24.4800 - val_FN: 44.4200\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.5475 - Accuracy: 0.9814 - Precision: 0.9634 - Recall: 0.9634 - TP: 3248.7200 - TN: 5556.4502 - FP: 90.5500 - FN: 123.2800 - val_loss: 0.4138 - val_Accuracy: 0.9654 - val_Precision: 0.9709 - val_Recall: 0.9276 - val_TP: 745.8300 - val_TN: 1091.2600 - val_FP: 14.7400 - val_FN: 58.1700\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3458 - Accuracy: 0.9820 - Precision: 0.9659 - Recall: 0.9643 - TP: 3251.7300 - TN: 5565.0000 - FP: 82.0000 - FN: 120.2700 - val_loss: 0.3296 - val_Accuracy: 0.9707 - val_Precision: 0.9600 - val_Recall: 0.9485 - val_TP: 762.6300 - val_TN: 1082.1000 - val_FP: 23.9000 - val_FN: 41.3700\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3760 - Accuracy: 0.9821 - Precision: 0.9651 - Recall: 0.9638 - TP: 3249.8799 - TN: 5562.6299 - FP: 84.3700 - FN: 122.1200 - val_loss: 0.3211 - val_Accuracy: 0.9696 - val_Precision: 0.9531 - val_Recall: 0.9556 - val_TP: 768.3000 - val_TN: 1076.2000 - val_FP: 29.8000 - val_FN: 35.7000\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2874 - Accuracy: 0.9814 - Precision: 0.9650 - Recall: 0.9654 - TP: 3255.4700 - TN: 5562.0698 - FP: 84.9300 - FN: 116.5300 - val_loss: 0.3499 - val_Accuracy: 0.9675 - val_Precision: 0.9563 - val_Recall: 0.9486 - val_TP: 762.6400 - val_TN: 1079.0200 - val_FP: 26.9800 - val_FN: 41.3600\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3836 - Accuracy: 0.9802 - Precision: 0.9642 - Recall: 0.9629 - TP: 3246.7700 - TN: 5559.5000 - FP: 87.5000 - FN: 125.2300 - val_loss: 0.3349 - val_Accuracy: 0.9691 - val_Precision: 0.9572 - val_Recall: 0.9490 - val_TP: 763.0300 - val_TN: 1079.7400 - val_FP: 26.2600 - val_FN: 40.9700\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1903 - Accuracy: 0.9829 - Precision: 0.9663 - Recall: 0.9663 - TP: 3258.3501 - TN: 5566.5298 - FP: 80.4700 - FN: 113.6500 - val_loss: 0.3685 - val_Accuracy: 0.9696 - val_Precision: 0.9556 - val_Recall: 0.9531 - val_TP: 766.2800 - val_TN: 1078.3500 - val_FP: 27.6500 - val_FN: 37.7200\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2185 - Accuracy: 0.9838 - Precision: 0.9677 - Recall: 0.9673 - TP: 3261.6201 - TN: 5571.1099 - FP: 75.8900 - FN: 110.3800 - val_loss: 0.3561 - val_Accuracy: 0.9723 - val_Precision: 0.9634 - val_Recall: 0.9477 - val_TP: 761.9800 - val_TN: 1084.8800 - val_FP: 21.1200 - val_FN: 42.0200\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3230 - Accuracy: 0.9841 - Precision: 0.9686 - Recall: 0.9666 - TP: 3259.5000 - TN: 5574.1802 - FP: 72.8200 - FN: 112.5000 - val_loss: 0.3514 - val_Accuracy: 0.9681 - val_Precision: 0.9465 - val_Recall: 0.9586 - val_TP: 770.7100 - val_TN: 1070.4600 - val_FP: 35.5400 - val_FN: 33.2900\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3044 - Accuracy: 0.9847 - Precision: 0.9663 - Recall: 0.9678 - TP: 3263.4199 - TN: 5566.1099 - FP: 80.8900 - FN: 108.5800 - val_loss: 0.4140 - val_Accuracy: 0.9681 - val_Precision: 0.9726 - val_Recall: 0.9324 - val_TP: 749.6100 - val_TN: 1092.5200 - val_FP: 13.4800 - val_FN: 54.3900\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2774 - Accuracy: 0.9827 - Precision: 0.9655 - Recall: 0.9645 - TP: 3252.1899 - TN: 5563.8599 - FP: 83.1400 - FN: 119.8100 - val_loss: 0.3585 - val_Accuracy: 0.9702 - val_Precision: 0.9716 - val_Recall: 0.9356 - val_TP: 752.2500 - val_TN: 1091.6200 - val_FP: 14.3800 - val_FN: 51.7500\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3154 - Accuracy: 0.9824 - Precision: 0.9658 - Recall: 0.9654 - TP: 3255.2400 - TN: 5564.7202 - FP: 82.2800 - FN: 116.7600 - val_loss: 0.5136 - val_Accuracy: 0.9628 - val_Precision: 0.9434 - val_Recall: 0.9516 - val_TP: 765.0900 - val_TN: 1068.1801 - val_FP: 37.8200 - val_FN: 38.9100\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2630 - Accuracy: 0.9833 - Precision: 0.9670 - Recall: 0.9660 - TP: 3257.3999 - TN: 5568.8398 - FP: 78.1600 - FN: 114.6000 - val_loss: 0.3791 - val_Accuracy: 0.9691 - val_Precision: 0.9495 - val_Recall: 0.9574 - val_TP: 769.7300 - val_TN: 1073.1200 - val_FP: 32.8800 - val_FN: 34.2700\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2973 - Accuracy: 0.9805 - Precision: 0.9637 - Recall: 0.9639 - TP: 3250.3701 - TN: 5557.5898 - FP: 89.4100 - FN: 121.6300 - val_loss: 0.3568 - val_Accuracy: 0.9702 - val_Precision: 0.9651 - val_Recall: 0.9442 - val_TP: 759.1200 - val_TN: 1086.3101 - val_FP: 19.6900 - val_FN: 44.8800\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1829 - Accuracy: 0.9850 - Precision: 0.9671 - Recall: 0.9680 - TP: 3264.1799 - TN: 5568.9702 - FP: 78.0300 - FN: 107.8200 - val_loss: 0.3702 - val_Accuracy: 0.9738 - val_Precision: 0.9686 - val_Recall: 0.9458 - val_TP: 760.4200 - val_TN: 1089.1300 - val_FP: 16.8700 - val_FN: 43.5800\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3262 - Accuracy: 0.9839 - Precision: 0.9691 - Recall: 0.9671 - TP: 3261.0801 - TN: 5576.1602 - FP: 70.8400 - FN: 110.9200 - val_loss: 0.4615 - val_Accuracy: 0.9686 - val_Precision: 0.9489 - val_Recall: 0.9574 - val_TP: 769.7500 - val_TN: 1072.6200 - val_FP: 33.3800 - val_FN: 34.2500\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2436 - Accuracy: 0.9825 - Precision: 0.9653 - Recall: 0.9658 - TP: 3256.8401 - TN: 5562.8198 - FP: 84.1800 - FN: 115.1600 - val_loss: 0.3824 - val_Accuracy: 0.9717 - val_Precision: 0.9724 - val_Recall: 0.9381 - val_TP: 754.2000 - val_TN: 1092.2800 - val_FP: 13.7200 - val_FN: 49.8000\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3274 - Accuracy: 0.9834 - Precision: 0.9681 - Recall: 0.9666 - TP: 3259.4099 - TN: 5572.4800 - FP: 74.5200 - FN: 112.5900 - val_loss: 0.6596 - val_Accuracy: 0.9628 - val_Precision: 0.9368 - val_Recall: 0.9532 - val_TP: 766.3700 - val_TN: 1062.0800 - val_FP: 43.9200 - val_FN: 37.6300\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.4530 - Accuracy: 0.9816 - Precision: 0.9647 - Recall: 0.9648 - TP: 3253.1599 - TN: 5561.2900 - FP: 85.7100 - FN: 118.8400 - val_loss: 0.5174 - val_Accuracy: 0.9660 - val_Precision: 0.9511 - val_Recall: 0.9495 - val_TP: 763.3700 - val_TN: 1074.7300 - val_FP: 31.2700 - val_FN: 40.6300\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1899 - Accuracy: 0.9847 - Precision: 0.9693 - Recall: 0.9690 - TP: 3267.3301 - TN: 5576.8198 - FP: 70.1800 - FN: 104.6700 - val_loss: 0.3699 - val_Accuracy: 0.9696 - val_Precision: 0.9585 - val_Recall: 0.9491 - val_TP: 763.0400 - val_TN: 1080.8199 - val_FP: 25.1800 - val_FN: 40.9600\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2620 - Accuracy: 0.9861 - Precision: 0.9711 - Recall: 0.9703 - TP: 3271.7200 - TN: 5582.8301 - FP: 64.1700 - FN: 100.2800 - val_loss: 0.4103 - val_Accuracy: 0.9675 - val_Precision: 0.9533 - val_Recall: 0.9504 - val_TP: 764.0900 - val_TN: 1076.4900 - val_FP: 29.5100 - val_FN: 39.9100\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.5294 - Accuracy: 0.9810 - Precision: 0.9653 - Recall: 0.9653 - TP: 3254.9199 - TN: 5562.8999 - FP: 84.1000 - FN: 117.0800 - val_loss: 0.3714 - val_Accuracy: 0.9717 - val_Precision: 0.9581 - val_Recall: 0.9511 - val_TP: 764.6900 - val_TN: 1080.4100 - val_FP: 25.5900 - val_FN: 39.3100\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2655 - Accuracy: 0.9846 - Precision: 0.9684 - Recall: 0.9678 - TP: 3263.4399 - TN: 5573.7998 - FP: 73.2000 - FN: 108.5600 - val_loss: 0.3589 - val_Accuracy: 0.9723 - val_Precision: 0.9550 - val_Recall: 0.9559 - val_TP: 768.5600 - val_TN: 1077.7500 - val_FP: 28.2500 - val_FN: 35.4400\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2853 - Accuracy: 0.9812 - Precision: 0.9644 - Recall: 0.9634 - TP: 3248.6101 - TN: 5560.0898 - FP: 86.9100 - FN: 123.3900 - val_loss: 0.3944 - val_Accuracy: 0.9670 - val_Precision: 0.9377 - val_Recall: 0.9648 - val_TP: 775.7000 - val_TN: 1062.6200 - val_FP: 43.3800 - val_FN: 28.3000\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 7ms/step - loss: 0.4811 - Accuracy: 0.9808 - Precision: 0.9630 - Recall: 0.9634 - TP: 3248.5901 - TN: 5555.1699 - FP: 91.8300 - FN: 123.4100 - val_loss: 0.4114 - val_Accuracy: 0.9686 - val_Precision: 0.9491 - val_Recall: 0.9562 - val_TP: 768.7800 - val_TN: 1072.7500 - val_FP: 33.2500 - val_FN: 35.2200\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1842 - Accuracy: 0.9831 - Precision: 0.9672 - Recall: 0.9677 - TP: 3263.2300 - TN: 5569.4800 - FP: 77.5200 - FN: 108.7700 - val_loss: 0.4001 - val_Accuracy: 0.9696 - val_Precision: 0.9551 - val_Recall: 0.9517 - val_TP: 765.1500 - val_TN: 1077.9399 - val_FP: 28.0600 - val_FN: 38.8500\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2866 - Accuracy: 0.9817 - Precision: 0.9655 - Recall: 0.9642 - TP: 3251.3301 - TN: 5564.0000 - FP: 83.0000 - FN: 120.6700 - val_loss: 0.4234 - val_Accuracy: 0.9634 - val_Precision: 0.9247 - val_Recall: 0.9680 - val_TP: 778.2700 - val_TN: 1050.7600 - val_FP: 55.2400 - val_FN: 25.7300\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2750 - Accuracy: 0.9826 - Precision: 0.9653 - Recall: 0.9657 - TP: 3256.4600 - TN: 5563.0898 - FP: 83.9100 - FN: 115.5400 - val_loss: 0.3420 - val_Accuracy: 0.9723 - val_Precision: 0.9657 - val_Recall: 0.9460 - val_TP: 760.5700 - val_TN: 1086.7400 - val_FP: 19.2600 - val_FN: 43.4300\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2015 - Accuracy: 0.9839 - Precision: 0.9677 - Recall: 0.9665 - TP: 3259.1001 - TN: 5571.2100 - FP: 75.7900 - FN: 112.9000 - val_loss: 0.4360 - val_Accuracy: 0.9675 - val_Precision: 0.9535 - val_Recall: 0.9484 - val_TP: 762.5500 - val_TN: 1076.7700 - val_FP: 29.2300 - val_FN: 41.4500\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2676 - Accuracy: 0.9841 - Precision: 0.9685 - Recall: 0.9680 - TP: 3264.0500 - TN: 5574.0400 - FP: 72.9600 - FN: 107.9500 - val_loss: 0.4523 - val_Accuracy: 0.9654 - val_Precision: 0.9457 - val_Recall: 0.9556 - val_TP: 768.3200 - val_TN: 1069.8700 - val_FP: 36.1300 - val_FN: 35.6800\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3491 - Accuracy: 0.9843 - Precision: 0.9670 - Recall: 0.9670 - TP: 3260.7000 - TN: 5568.5898 - FP: 78.4100 - FN: 111.3000 - val_loss: 0.4332 - val_Accuracy: 0.9707 - val_Precision: 0.9643 - val_Recall: 0.9441 - val_TP: 759.0800 - val_TN: 1085.6700 - val_FP: 20.3300 - val_FN: 44.9200\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2848 - Accuracy: 0.9827 - Precision: 0.9670 - Recall: 0.9658 - TP: 3256.7800 - TN: 5568.8599 - FP: 78.1400 - FN: 115.2200 - val_loss: 0.3266 - val_Accuracy: 0.9733 - val_Precision: 0.9660 - val_Recall: 0.9511 - val_TP: 764.7000 - val_TN: 1086.9100 - val_FP: 19.0900 - val_FN: 39.3000\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3160 - Accuracy: 0.9839 - Precision: 0.9686 - Recall: 0.9679 - TP: 3263.8201 - TN: 5574.4800 - FP: 72.5200 - FN: 108.1800 - val_loss: 0.3454 - val_Accuracy: 0.9665 - val_Precision: 0.9401 - val_Recall: 0.9592 - val_TP: 771.2200 - val_TN: 1064.9000 - val_FP: 41.1000 - val_FN: 32.7800\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.4703 - Accuracy: 0.9812 - Precision: 0.9652 - Recall: 0.9646 - TP: 3252.7300 - TN: 5562.8301 - FP: 84.1700 - FN: 119.2700 - val_loss: 0.3390 - val_Accuracy: 0.9733 - val_Precision: 0.9684 - val_Recall: 0.9454 - val_TP: 760.1400 - val_TN: 1088.9301 - val_FP: 17.0700 - val_FN: 43.8600\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.4527 - Accuracy: 0.9817 - Precision: 0.9653 - Recall: 0.9647 - TP: 3252.8899 - TN: 5563.1602 - FP: 83.8400 - FN: 119.1100 - val_loss: 0.3473 - val_Accuracy: 0.9717 - val_Precision: 0.9635 - val_Recall: 0.9484 - val_TP: 762.5100 - val_TN: 1084.9700 - val_FP: 21.0300 - val_FN: 41.4900\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2175 - Accuracy: 0.9841 - Precision: 0.9675 - Recall: 0.9678 - TP: 3263.4299 - TN: 5570.3301 - FP: 76.6700 - FN: 108.5700 - val_loss: 0.7669 - val_Accuracy: 0.9571 - val_Precision: 0.9165 - val_Recall: 0.9549 - val_TP: 767.7400 - val_TN: 1043.6300 - val_FP: 62.3700 - val_FN: 36.2600\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3054 - Accuracy: 0.9823 - Precision: 0.9654 - Recall: 0.9654 - TP: 3255.4800 - TN: 5563.4502 - FP: 83.5500 - FN: 116.5200 - val_loss: 0.5521 - val_Accuracy: 0.9654 - val_Precision: 0.9497 - val_Recall: 0.9467 - val_TP: 761.1600 - val_TN: 1073.5800 - val_FP: 32.4200 - val_FN: 42.8400\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2863 - Accuracy: 0.9833 - Precision: 0.9667 - Recall: 0.9651 - TP: 3254.2100 - TN: 5568.0098 - FP: 78.9900 - FN: 117.7900 - val_loss: 0.3765 - val_Accuracy: 0.9691 - val_Precision: 0.9650 - val_Recall: 0.9410 - val_TP: 756.5300 - val_TN: 1086.2900 - val_FP: 19.7100 - val_FN: 47.4700\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1904 - Accuracy: 0.9840 - Precision: 0.9675 - Recall: 0.9676 - TP: 3262.7100 - TN: 5570.4502 - FP: 76.5500 - FN: 109.2900 - val_loss: 0.4126 - val_Accuracy: 0.9696 - val_Precision: 0.9570 - val_Recall: 0.9475 - val_TP: 761.7500 - val_TN: 1079.6700 - val_FP: 26.3300 - val_FN: 42.2500\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.5640 - Accuracy: 0.9834 - Precision: 0.9655 - Recall: 0.9666 - TP: 3259.4800 - TN: 5563.5200 - FP: 83.4800 - FN: 112.5200 - val_loss: 2.9363 - val_Accuracy: 0.9105 - val_Precision: 0.8529 - val_Recall: 0.9296 - val_TP: 747.3700 - val_TN: 985.7100 - val_FP: 120.2900 - val_FN: 56.6300\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.4093 - Accuracy: 0.9826 - Precision: 0.9671 - Recall: 0.9646 - TP: 3252.5300 - TN: 5569.3301 - FP: 77.6700 - FN: 119.4700 - val_loss: 0.4277 - val_Accuracy: 0.9681 - val_Precision: 0.9654 - val_Recall: 0.9383 - val_TP: 754.4000 - val_TN: 1086.6400 - val_FP: 19.3600 - val_FN: 49.6000\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2777 - Accuracy: 0.9828 - Precision: 0.9666 - Recall: 0.9660 - TP: 3257.3101 - TN: 5567.5498 - FP: 79.4500 - FN: 114.6900 - val_loss: 0.4927 - val_Accuracy: 0.9675 - val_Precision: 0.9537 - val_Recall: 0.9466 - val_TP: 761.0500 - val_TN: 1076.9700 - val_FP: 29.0300 - val_FN: 42.9500\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2801 - Accuracy: 0.9829 - Precision: 0.9660 - Recall: 0.9662 - TP: 3257.9099 - TN: 5565.3398 - FP: 81.6600 - FN: 114.0900 - val_loss: 0.4670 - val_Accuracy: 0.9717 - val_Precision: 0.9660 - val_Recall: 0.9438 - val_TP: 758.8000 - val_TN: 1087.0400 - val_FP: 18.9600 - val_FN: 45.2000\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2806 - Accuracy: 0.9850 - Precision: 0.9691 - Recall: 0.9688 - TP: 3266.6499 - TN: 5576.0400 - FP: 70.9600 - FN: 105.3500 - val_loss: 0.6198 - val_Accuracy: 0.9607 - val_Precision: 0.9403 - val_Recall: 0.9479 - val_TP: 762.0900 - val_TN: 1065.5500 - val_FP: 40.4500 - val_FN: 41.9100\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2243 - Accuracy: 0.9850 - Precision: 0.9691 - Recall: 0.9678 - TP: 3263.3201 - TN: 5575.9302 - FP: 71.0700 - FN: 108.6800 - val_loss: 0.4189 - val_Accuracy: 0.9665 - val_Precision: 0.9616 - val_Recall: 0.9406 - val_TP: 756.2600 - val_TN: 1083.6200 - val_FP: 22.3800 - val_FN: 47.7400\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2238 - Accuracy: 0.9849 - Precision: 0.9689 - Recall: 0.9682 - TP: 3264.9299 - TN: 5575.4502 - FP: 71.5500 - FN: 107.0700 - val_loss: 0.4983 - val_Accuracy: 0.9686 - val_Precision: 0.9569 - val_Recall: 0.9489 - val_TP: 762.8900 - val_TN: 1079.5500 - val_FP: 26.4500 - val_FN: 41.1100\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2523 - Accuracy: 0.9844 - Precision: 0.9679 - Recall: 0.9680 - TP: 3263.9700 - TN: 5572.0200 - FP: 74.9800 - FN: 108.0300 - val_loss: 0.4119 - val_Accuracy: 0.9696 - val_Precision: 0.9615 - val_Recall: 0.9420 - val_TP: 757.3600 - val_TN: 1083.4500 - val_FP: 22.5500 - val_FN: 46.6400\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.4822 - Accuracy: 0.9827 - Precision: 0.9659 - Recall: 0.9656 - TP: 3256.0000 - TN: 5565.1099 - FP: 81.8900 - FN: 116.0000 - val_loss: 0.3900 - val_Accuracy: 0.9702 - val_Precision: 0.9669 - val_Recall: 0.9416 - val_TP: 757.0700 - val_TN: 1087.8199 - val_FP: 18.1800 - val_FN: 46.9300\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3832 - Accuracy: 0.9835 - Precision: 0.9674 - Recall: 0.9670 - TP: 3260.7700 - TN: 5570.1699 - FP: 76.8300 - FN: 111.2300 - val_loss: 0.3793 - val_Accuracy: 0.9691 - val_Precision: 0.9580 - val_Recall: 0.9481 - val_TP: 762.3000 - val_TN: 1080.5000 - val_FP: 25.5000 - val_FN: 41.7000\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.5044 - Accuracy: 0.9810 - Precision: 0.9653 - Recall: 0.9639 - TP: 3250.2800 - TN: 5563.3501 - FP: 83.6500 - FN: 121.7200 - val_loss: 0.4467 - val_Accuracy: 0.9738 - val_Precision: 0.9651 - val_Recall: 0.9510 - val_TP: 764.5900 - val_TN: 1086.1600 - val_FP: 19.8400 - val_FN: 39.4100\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3521 - Accuracy: 0.9836 - Precision: 0.9666 - Recall: 0.9673 - TP: 3261.7800 - TN: 5567.6099 - FP: 79.3900 - FN: 110.2200 - val_loss: 0.3808 - val_Accuracy: 0.9712 - val_Precision: 0.9639 - val_Recall: 0.9490 - val_TP: 762.9700 - val_TN: 1085.2900 - val_FP: 20.7100 - val_FN: 41.0300\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1705 - Accuracy: 0.9841 - Precision: 0.9680 - Recall: 0.9681 - TP: 3264.3000 - TN: 5572.1602 - FP: 74.8400 - FN: 107.7000 - val_loss: 0.6058 - val_Accuracy: 0.9654 - val_Precision: 0.9478 - val_Recall: 0.9495 - val_TP: 763.3800 - val_TN: 1071.9100 - val_FP: 34.0900 - val_FN: 40.6200\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 7ms/step - loss: 0.5246 - Accuracy: 0.9804 - Precision: 0.9632 - Recall: 0.9633 - TP: 3248.2500 - TN: 5555.8701 - FP: 91.1300 - FN: 123.7500 - val_loss: 0.3829 - val_Accuracy: 0.9712 - val_Precision: 0.9624 - val_Recall: 0.9478 - val_TP: 762.0200 - val_TN: 1084.0900 - val_FP: 21.9100 - val_FN: 41.9800\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.6591 - Accuracy: 0.9828 - Precision: 0.9659 - Recall: 0.9656 - TP: 3255.9299 - TN: 5565.3901 - FP: 81.6100 - FN: 116.0700 - val_loss: 0.3963 - val_Accuracy: 0.9707 - val_Precision: 0.9735 - val_Recall: 0.9344 - val_TP: 751.2900 - val_TN: 1093.2300 - val_FP: 12.7700 - val_FN: 52.7100\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2071 - Accuracy: 0.9834 - Precision: 0.9677 - Recall: 0.9660 - TP: 3257.2300 - TN: 5571.5200 - FP: 75.4800 - FN: 114.7700 - val_loss: 0.3578 - val_Accuracy: 0.9696 - val_Precision: 0.9557 - val_Recall: 0.9542 - val_TP: 767.2100 - val_TN: 1078.3400 - val_FP: 27.6600 - val_FN: 36.7900\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3911 - Accuracy: 0.9808 - Precision: 0.9634 - Recall: 0.9644 - TP: 3251.7900 - TN: 5556.5601 - FP: 90.4400 - FN: 120.2100 - val_loss: 0.3512 - val_Accuracy: 0.9712 - val_Precision: 0.9547 - val_Recall: 0.9576 - val_TP: 769.9200 - val_TN: 1077.4301 - val_FP: 28.5700 - val_FN: 34.0800\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2713 - Accuracy: 0.9840 - Precision: 0.9679 - Recall: 0.9661 - TP: 3257.7900 - TN: 5572.2798 - FP: 74.7200 - FN: 114.2100 - val_loss: 0.3726 - val_Accuracy: 0.9675 - val_Precision: 0.9411 - val_Recall: 0.9603 - val_TP: 772.0900 - val_TN: 1065.7000 - val_FP: 40.3000 - val_FN: 31.9100\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2865 - Accuracy: 0.9804 - Precision: 0.9627 - Recall: 0.9627 - TP: 3246.3000 - TN: 5554.2598 - FP: 92.7400 - FN: 125.7000 - val_loss: 0.3674 - val_Accuracy: 0.9691 - val_Precision: 0.9679 - val_Recall: 0.9393 - val_TP: 755.2200 - val_TN: 1088.7000 - val_FP: 17.3000 - val_FN: 48.7800\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.5197 - Accuracy: 0.9827 - Precision: 0.9652 - Recall: 0.9653 - TP: 3255.0300 - TN: 5562.6802 - FP: 84.3200 - FN: 116.9700 - val_loss: 0.3802 - val_Accuracy: 0.9717 - val_Precision: 0.9592 - val_Recall: 0.9518 - val_TP: 765.2800 - val_TN: 1081.3600 - val_FP: 24.6400 - val_FN: 38.7200\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3260 - Accuracy: 0.9823 - Precision: 0.9656 - Recall: 0.9648 - TP: 3253.3601 - TN: 5564.2202 - FP: 82.7800 - FN: 118.6400 - val_loss: 0.3764 - val_Accuracy: 0.9686 - val_Precision: 0.9566 - val_Recall: 0.9528 - val_TP: 766.0700 - val_TN: 1079.1500 - val_FP: 26.8500 - val_FN: 37.9300\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2209 - Accuracy: 0.9857 - Precision: 0.9694 - Recall: 0.9694 - TP: 3268.9199 - TN: 5577.2002 - FP: 69.8000 - FN: 103.0800 - val_loss: 0.3768 - val_Accuracy: 0.9681 - val_Precision: 0.9497 - val_Recall: 0.9557 - val_TP: 768.3500 - val_TN: 1073.3300 - val_FP: 32.6700 - val_FN: 35.6500\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3976 - Accuracy: 0.9850 - Precision: 0.9687 - Recall: 0.9695 - TP: 3269.1001 - TN: 5574.6401 - FP: 72.3600 - FN: 102.9000 - val_loss: 0.4679 - val_Accuracy: 0.9675 - val_Precision: 0.9571 - val_Recall: 0.9457 - val_TP: 760.3600 - val_TN: 1079.7900 - val_FP: 26.2100 - val_FN: 43.6400\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.5872 - Accuracy: 0.9807 - Precision: 0.9644 - Recall: 0.9623 - TP: 3245.0300 - TN: 5560.4302 - FP: 86.5700 - FN: 126.9700 - val_loss: 0.3699 - val_Accuracy: 0.9712 - val_Precision: 0.9555 - val_Recall: 0.9559 - val_TP: 768.5600 - val_TN: 1078.2000 - val_FP: 27.8000 - val_FN: 35.4400\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.4807 - Accuracy: 0.9820 - Precision: 0.9654 - Recall: 0.9653 - TP: 3254.8401 - TN: 5563.6299 - FP: 83.3700 - FN: 117.1600 - val_loss: 0.4656 - val_Accuracy: 0.9681 - val_Precision: 0.9782 - val_Recall: 0.9251 - val_TP: 743.8200 - val_TN: 1096.9500 - val_FP: 9.0500 - val_FN: 60.1800\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2318 - Accuracy: 0.9850 - Precision: 0.9691 - Recall: 0.9689 - TP: 3267.0100 - TN: 5576.1201 - FP: 70.8800 - FN: 104.9900 - val_loss: 0.3837 - val_Accuracy: 0.9717 - val_Precision: 0.9599 - val_Recall: 0.9519 - val_TP: 765.3100 - val_TN: 1081.9800 - val_FP: 24.0200 - val_FN: 38.6900\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3010 - Accuracy: 0.9821 - Precision: 0.9660 - Recall: 0.9655 - TP: 3255.7400 - TN: 5565.3301 - FP: 81.6700 - FN: 116.2600 - val_loss: 0.5620 - val_Accuracy: 0.9670 - val_Precision: 0.9549 - val_Recall: 0.9455 - val_TP: 760.2000 - val_TN: 1077.9900 - val_FP: 28.0100 - val_FN: 43.8000\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2066 - Accuracy: 0.9849 - Precision: 0.9694 - Recall: 0.9685 - TP: 3265.8301 - TN: 5577.2598 - FP: 69.7400 - FN: 106.1700 - val_loss: 0.4124 - val_Accuracy: 0.9660 - val_Precision: 0.9473 - val_Recall: 0.9550 - val_TP: 767.8100 - val_TN: 1071.3300 - val_FP: 34.6700 - val_FN: 36.1900\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3938 - Accuracy: 0.9830 - Precision: 0.9663 - Recall: 0.9659 - TP: 3257.1201 - TN: 5566.6201 - FP: 80.3800 - FN: 114.8800 - val_loss: 0.4703 - val_Accuracy: 0.9681 - val_Precision: 0.9515 - val_Recall: 0.9537 - val_TP: 766.7600 - val_TN: 1074.9399 - val_FP: 31.0600 - val_FN: 37.2400\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2534 - Accuracy: 0.9817 - Precision: 0.9650 - Recall: 0.9646 - TP: 3252.4800 - TN: 5562.0498 - FP: 84.9500 - FN: 119.5200 - val_loss: 0.3980 - val_Accuracy: 0.9712 - val_Precision: 0.9565 - val_Recall: 0.9526 - val_TP: 765.9300 - val_TN: 1079.0900 - val_FP: 26.9100 - val_FN: 38.0700\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2570 - Accuracy: 0.9855 - Precision: 0.9700 - Recall: 0.9687 - TP: 3266.4500 - TN: 5579.0698 - FP: 67.9300 - FN: 105.5500 - val_loss: 0.4615 - val_Accuracy: 0.9602 - val_Precision: 0.9254 - val_Recall: 0.9649 - val_TP: 775.7400 - val_TN: 1051.6899 - val_FP: 54.3100 - val_FN: 28.2600\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2696 - Accuracy: 0.9841 - Precision: 0.9674 - Recall: 0.9686 - TP: 3266.1499 - TN: 5570.2402 - FP: 76.7600 - FN: 105.8500 - val_loss: 0.3871 - val_Accuracy: 0.9717 - val_Precision: 0.9644 - val_Recall: 0.9477 - val_TP: 761.9500 - val_TN: 1085.7200 - val_FP: 20.2800 - val_FN: 42.0500\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2489 - Accuracy: 0.9840 - Precision: 0.9683 - Recall: 0.9686 - TP: 3266.1799 - TN: 5573.3799 - FP: 73.6200 - FN: 105.8200 - val_loss: 0.4171 - val_Accuracy: 0.9707 - val_Precision: 0.9605 - val_Recall: 0.9470 - val_TP: 761.3900 - val_TN: 1082.5100 - val_FP: 23.4900 - val_FN: 42.6100\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3092 - Accuracy: 0.9843 - Precision: 0.9676 - Recall: 0.9668 - TP: 3260.1399 - TN: 5571.0200 - FP: 75.9800 - FN: 111.8600 - val_loss: 0.4067 - val_Accuracy: 0.9733 - val_Precision: 0.9648 - val_Recall: 0.9467 - val_TP: 761.1600 - val_TN: 1086.0500 - val_FP: 19.9500 - val_FN: 42.8400\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2767 - Accuracy: 0.9828 - Precision: 0.9661 - Recall: 0.9666 - TP: 3259.2900 - TN: 5565.8501 - FP: 81.1500 - FN: 112.7100 - val_loss: 0.3846 - val_Accuracy: 0.9733 - val_Precision: 0.9604 - val_Recall: 0.9554 - val_TP: 768.1700 - val_TN: 1082.2300 - val_FP: 23.7700 - val_FN: 35.8300\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2460 - Accuracy: 0.9838 - Precision: 0.9686 - Recall: 0.9676 - TP: 3262.8899 - TN: 5574.3501 - FP: 72.6500 - FN: 109.1100 - val_loss: 0.6395 - val_Accuracy: 0.9644 - val_Precision: 0.9408 - val_Recall: 0.9541 - val_TP: 767.1300 - val_TN: 1065.8000 - val_FP: 40.2000 - val_FN: 36.8700\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2347 - Accuracy: 0.9869 - Precision: 0.9711 - Recall: 0.9705 - TP: 3272.4800 - TN: 5582.8398 - FP: 64.1600 - FN: 99.5200 - val_loss: 0.4022 - val_Accuracy: 0.9696 - val_Precision: 0.9517 - val_Recall: 0.9564 - val_TP: 768.9100 - val_TN: 1074.9900 - val_FP: 31.0100 - val_FN: 35.0900\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 7ms/step - loss: 0.4040 - Accuracy: 0.9817 - Precision: 0.9648 - Recall: 0.9645 - TP: 3252.3401 - TN: 5561.4702 - FP: 85.5300 - FN: 119.6600 - val_loss: 0.3784 - val_Accuracy: 0.9681 - val_Precision: 0.9504 - val_Recall: 0.9550 - val_TP: 767.8600 - val_TN: 1073.9399 - val_FP: 32.0600 - val_FN: 36.1400\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.4500 - Accuracy: 0.9837 - Precision: 0.9677 - Recall: 0.9676 - TP: 3262.6201 - TN: 5571.2500 - FP: 75.7500 - FN: 109.3800 - val_loss: 0.4657 - val_Accuracy: 0.9681 - val_Precision: 0.9569 - val_Recall: 0.9455 - val_TP: 760.2200 - val_TN: 1079.6000 - val_FP: 26.4000 - val_FN: 43.7800\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3714 - Accuracy: 0.9806 - Precision: 0.9644 - Recall: 0.9637 - TP: 3249.7600 - TN: 5560.0601 - FP: 86.9400 - FN: 122.2400 - val_loss: 0.3795 - val_Accuracy: 0.9707 - val_Precision: 0.9525 - val_Recall: 0.9541 - val_TP: 767.0800 - val_TN: 1075.7200 - val_FP: 30.2800 - val_FN: 36.9200\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2936 - Accuracy: 0.9829 - Precision: 0.9667 - Recall: 0.9664 - TP: 3258.8401 - TN: 5567.8301 - FP: 79.1700 - FN: 113.1600 - val_loss: 0.3698 - val_Accuracy: 0.9717 - val_Precision: 0.9576 - val_Recall: 0.9538 - val_TP: 766.8900 - val_TN: 1079.9000 - val_FP: 26.1000 - val_FN: 37.1100\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3596 - Accuracy: 0.9814 - Precision: 0.9638 - Recall: 0.9647 - TP: 3253.1201 - TN: 5558.0498 - FP: 88.9500 - FN: 118.8800 - val_loss: 0.3848 - val_Accuracy: 0.9743 - val_Precision: 0.9714 - val_Recall: 0.9444 - val_TP: 759.3100 - val_TN: 1091.3700 - val_FP: 14.6300 - val_FN: 44.6900\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3882 - Accuracy: 0.9831 - Precision: 0.9670 - Recall: 0.9661 - TP: 3257.7300 - TN: 5568.8301 - FP: 78.1700 - FN: 114.2700 - val_loss: 0.4621 - val_Accuracy: 0.9660 - val_Precision: 0.9641 - val_Recall: 0.9346 - val_TP: 751.4000 - val_TN: 1085.7800 - val_FP: 20.2200 - val_FN: 52.6000\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3427 - Accuracy: 0.9824 - Precision: 0.9660 - Recall: 0.9651 - TP: 3254.4399 - TN: 5565.4902 - FP: 81.5100 - FN: 117.5600 - val_loss: 0.5320 - val_Accuracy: 0.9649 - val_Precision: 0.9781 - val_Recall: 0.9168 - val_TP: 737.0800 - val_TN: 1097.0400 - val_FP: 8.9600 - val_FN: 66.9200\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3178 - Accuracy: 0.9835 - Precision: 0.9680 - Recall: 0.9669 - TP: 3260.3701 - TN: 5572.2798 - FP: 74.7200 - FN: 111.6300 - val_loss: 0.4230 - val_Accuracy: 0.9681 - val_Precision: 0.9474 - val_Recall: 0.9562 - val_TP: 768.7900 - val_TN: 1071.3400 - val_FP: 34.6600 - val_FN: 35.2100\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2221 - Accuracy: 0.9825 - Precision: 0.9664 - Recall: 0.9671 - TP: 3260.9199 - TN: 5566.8198 - FP: 80.1800 - FN: 111.0800 - val_loss: 0.4332 - val_Accuracy: 0.9675 - val_Precision: 0.9437 - val_Recall: 0.9620 - val_TP: 773.4500 - val_TN: 1067.9500 - val_FP: 38.0500 - val_FN: 30.5500\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2396 - Accuracy: 0.9828 - Precision: 0.9664 - Recall: 0.9656 - TP: 3255.8999 - TN: 5566.7998 - FP: 80.2000 - FN: 116.1000 - val_loss: 0.3845 - val_Accuracy: 0.9702 - val_Precision: 0.9527 - val_Recall: 0.9553 - val_TP: 768.1000 - val_TN: 1075.8101 - val_FP: 30.1900 - val_FN: 35.9000\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.4871 - Accuracy: 0.9834 - Precision: 0.9677 - Recall: 0.9663 - TP: 3258.4800 - TN: 5571.5498 - FP: 75.4500 - FN: 113.5200 - val_loss: 0.5137 - val_Accuracy: 0.9623 - val_Precision: 0.9305 - val_Recall: 0.9636 - val_TP: 774.7400 - val_TN: 1056.2600 - val_FP: 49.7400 - val_FN: 29.2600\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3505 - Accuracy: 0.9814 - Precision: 0.9633 - Recall: 0.9648 - TP: 3253.3000 - TN: 5556.1299 - FP: 90.8700 - FN: 118.7000 - val_loss: 0.4580 - val_Accuracy: 0.9670 - val_Precision: 0.9748 - val_Recall: 0.9292 - val_TP: 747.0600 - val_TN: 1094.2900 - val_FP: 11.7100 - val_FN: 56.9400\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3492 - Accuracy: 0.9809 - Precision: 0.9638 - Recall: 0.9636 - TP: 3249.1499 - TN: 5558.2598 - FP: 88.7400 - FN: 122.8500 - val_loss: 0.4093 - val_Accuracy: 0.9707 - val_Precision: 0.9659 - val_Recall: 0.9454 - val_TP: 760.0800 - val_TN: 1086.9600 - val_FP: 19.0400 - val_FN: 43.9200\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.5841 - Accuracy: 0.9838 - Precision: 0.9669 - Recall: 0.9658 - TP: 3256.8101 - TN: 5568.6099 - FP: 78.3900 - FN: 115.1900 - val_loss: 0.3902 - val_Accuracy: 0.9728 - val_Precision: 0.9535 - val_Recall: 0.9558 - val_TP: 768.4500 - val_TN: 1076.4900 - val_FP: 29.5100 - val_FN: 35.5500\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3937 - Accuracy: 0.9828 - Precision: 0.9666 - Recall: 0.9656 - TP: 3255.8799 - TN: 5567.5601 - FP: 79.4400 - FN: 116.1200 - val_loss: 0.4407 - val_Accuracy: 0.9686 - val_Precision: 0.9496 - val_Recall: 0.9560 - val_TP: 768.6100 - val_TN: 1073.1700 - val_FP: 32.8300 - val_FN: 35.3900\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.6208 - Accuracy: 0.9837 - Precision: 0.9657 - Recall: 0.9676 - TP: 3262.6001 - TN: 5564.5200 - FP: 82.4800 - FN: 109.4000 - val_loss: 0.4528 - val_Accuracy: 0.9686 - val_Precision: 0.9577 - val_Recall: 0.9456 - val_TP: 760.3000 - val_TN: 1080.2600 - val_FP: 25.7400 - val_FN: 43.7000\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2903 - Accuracy: 0.9831 - Precision: 0.9682 - Recall: 0.9665 - TP: 3258.9700 - TN: 5573.2402 - FP: 73.7600 - FN: 113.0300 - val_loss: 0.4147 - val_Accuracy: 0.9728 - val_Precision: 0.9638 - val_Recall: 0.9517 - val_TP: 765.1700 - val_TN: 1085.1600 - val_FP: 20.8400 - val_FN: 38.8300\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.6151 - Accuracy: 0.9808 - Precision: 0.9633 - Recall: 0.9624 - TP: 3245.3000 - TN: 5556.6299 - FP: 90.3700 - FN: 126.7000 - val_loss: 0.4251 - val_Accuracy: 0.9654 - val_Precision: 0.9467 - val_Recall: 0.9553 - val_TP: 768.0500 - val_TN: 1070.8199 - val_FP: 35.1800 - val_FN: 35.9500\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3017 - Accuracy: 0.9835 - Precision: 0.9663 - Recall: 0.9676 - TP: 3262.8701 - TN: 5566.6201 - FP: 80.3800 - FN: 109.1300 - val_loss: 0.4301 - val_Accuracy: 0.9723 - val_Precision: 0.9703 - val_Recall: 0.9412 - val_TP: 756.7500 - val_TN: 1090.6000 - val_FP: 15.4000 - val_FN: 47.2500\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3894 - Accuracy: 0.9834 - Precision: 0.9687 - Recall: 0.9664 - TP: 3258.7500 - TN: 5574.8301 - FP: 72.1700 - FN: 113.2500 - val_loss: 0.4200 - val_Accuracy: 0.9665 - val_Precision: 0.9477 - val_Recall: 0.9549 - val_TP: 767.7400 - val_TN: 1071.6200 - val_FP: 34.3800 - val_FN: 36.2600\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3414 - Accuracy: 0.9823 - Precision: 0.9655 - Recall: 0.9658 - TP: 3256.7500 - TN: 5563.7700 - FP: 83.2300 - FN: 115.2500 - val_loss: 0.3963 - val_Accuracy: 0.9723 - val_Precision: 0.9587 - val_Recall: 0.9524 - val_TP: 765.7400 - val_TN: 1080.8900 - val_FP: 25.1100 - val_FN: 38.2600\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2378 - Accuracy: 0.9856 - Precision: 0.9688 - Recall: 0.9705 - TP: 3272.4900 - TN: 5574.7700 - FP: 72.2300 - FN: 99.5100 - val_loss: 0.4720 - val_Accuracy: 0.9696 - val_Precision: 0.9751 - val_Recall: 0.9313 - val_TP: 748.7300 - val_TN: 1094.5601 - val_FP: 11.4400 - val_FN: 55.2700\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2874 - Accuracy: 0.9829 - Precision: 0.9677 - Recall: 0.9660 - TP: 3257.3701 - TN: 5571.4502 - FP: 75.5500 - FN: 114.6300 - val_loss: 0.4137 - val_Accuracy: 0.9712 - val_Precision: 0.9652 - val_Recall: 0.9455 - val_TP: 760.1800 - val_TN: 1086.3900 - val_FP: 19.6100 - val_FN: 43.8200\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3844 - Accuracy: 0.9821 - Precision: 0.9651 - Recall: 0.9649 - TP: 3253.6699 - TN: 5562.5698 - FP: 84.4300 - FN: 118.3300 - val_loss: 0.4796 - val_Accuracy: 0.9712 - val_Precision: 0.9655 - val_Recall: 0.9416 - val_TP: 757.0500 - val_TN: 1086.7900 - val_FP: 19.2100 - val_FN: 46.9500\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 7ms/step - loss: 0.3409 - Accuracy: 0.9807 - Precision: 0.9645 - Recall: 0.9647 - TP: 3252.8501 - TN: 5560.3198 - FP: 86.6800 - FN: 119.1500 - val_loss: 0.4042 - val_Accuracy: 0.9681 - val_Precision: 0.9629 - val_Recall: 0.9431 - val_TP: 758.2800 - val_TN: 1084.5601 - val_FP: 21.4400 - val_FN: 45.7200\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3946 - Accuracy: 0.9823 - Precision: 0.9661 - Recall: 0.9657 - TP: 3256.4399 - TN: 5565.6899 - FP: 81.3100 - FN: 115.5600 - val_loss: 0.3951 - val_Accuracy: 0.9686 - val_Precision: 0.9587 - val_Recall: 0.9480 - val_TP: 762.2200 - val_TN: 1080.9900 - val_FP: 25.0100 - val_FN: 41.7800\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.4528 - Accuracy: 0.9844 - Precision: 0.9678 - Recall: 0.9665 - TP: 3259.0000 - TN: 5571.7798 - FP: 75.2200 - FN: 113.0000 - val_loss: 0.3913 - val_Accuracy: 0.9702 - val_Precision: 0.9546 - val_Recall: 0.9515 - val_TP: 764.9700 - val_TN: 1077.5400 - val_FP: 28.4600 - val_FN: 39.0300\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.4009 - Accuracy: 0.9810 - Precision: 0.9639 - Recall: 0.9638 - TP: 3249.9099 - TN: 5558.4600 - FP: 88.5400 - FN: 122.0900 - val_loss: 0.4286 - val_Accuracy: 0.9670 - val_Precision: 0.9446 - val_Recall: 0.9580 - val_TP: 770.2400 - val_TN: 1068.8900 - val_FP: 37.1100 - val_FN: 33.7600\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.1729 - Accuracy: 0.9845 - Precision: 0.9673 - Recall: 0.9686 - TP: 3266.1899 - TN: 5569.8501 - FP: 77.1500 - FN: 105.8100 - val_loss: 0.4756 - val_Accuracy: 0.9675 - val_Precision: 0.9665 - val_Recall: 0.9353 - val_TP: 752.0200 - val_TN: 1087.6899 - val_FP: 18.3100 - val_FN: 51.9800\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3887 - Accuracy: 0.9820 - Precision: 0.9657 - Recall: 0.9644 - TP: 3251.8899 - TN: 5564.8301 - FP: 82.1700 - FN: 120.1100 - val_loss: 0.5896 - val_Accuracy: 0.9681 - val_Precision: 0.9566 - val_Recall: 0.9471 - val_TP: 761.4700 - val_TN: 1079.3600 - val_FP: 26.6400 - val_FN: 42.5300\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.4703 - Accuracy: 0.9814 - Precision: 0.9653 - Recall: 0.9632 - TP: 3247.8799 - TN: 5563.5801 - FP: 83.4200 - FN: 124.1200 - val_loss: 0.4235 - val_Accuracy: 0.9686 - val_Precision: 0.9496 - val_Recall: 0.9543 - val_TP: 767.2700 - val_TN: 1073.1801 - val_FP: 32.8200 - val_FN: 36.7300\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.4981 - Accuracy: 0.9838 - Precision: 0.9672 - Recall: 0.9669 - TP: 3260.4600 - TN: 5569.7598 - FP: 77.2400 - FN: 111.5400 - val_loss: 0.4610 - val_Accuracy: 0.9660 - val_Precision: 0.9589 - val_Recall: 0.9412 - val_TP: 756.7000 - val_TN: 1081.3600 - val_FP: 24.6400 - val_FN: 47.3000\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2648 - Accuracy: 0.9830 - Precision: 0.9667 - Recall: 0.9664 - TP: 3258.6499 - TN: 5568.0098 - FP: 78.9900 - FN: 113.3500 - val_loss: 0.5514 - val_Accuracy: 0.9586 - val_Precision: 0.9322 - val_Recall: 0.9496 - val_TP: 763.4500 - val_TN: 1058.4800 - val_FP: 47.5200 - val_FN: 40.5500\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3089 - Accuracy: 0.9816 - Precision: 0.9652 - Recall: 0.9651 - TP: 3254.2000 - TN: 5562.9302 - FP: 84.0700 - FN: 117.8000 - val_loss: 0.4495 - val_Accuracy: 0.9649 - val_Precision: 0.9357 - val_Recall: 0.9639 - val_TP: 775.0000 - val_TN: 1060.9000 - val_FP: 45.1000 - val_FN: 29.0000\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3859 - Accuracy: 0.9817 - Precision: 0.9644 - Recall: 0.9650 - TP: 3254.1201 - TN: 5560.0698 - FP: 86.9300 - FN: 117.8800 - val_loss: 0.4958 - val_Accuracy: 0.9691 - val_Precision: 0.9569 - val_Recall: 0.9503 - val_TP: 764.0200 - val_TN: 1079.5000 - val_FP: 26.5000 - val_FN: 39.9800\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2970 - Accuracy: 0.9829 - Precision: 0.9668 - Recall: 0.9666 - TP: 3259.3201 - TN: 5568.3398 - FP: 78.6600 - FN: 112.6800 - val_loss: 0.4662 - val_Accuracy: 0.9691 - val_Precision: 0.9712 - val_Recall: 0.9346 - val_TP: 751.4300 - val_TN: 1091.4200 - val_FP: 14.5800 - val_FN: 52.5700\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3731 - Accuracy: 0.9825 - Precision: 0.9660 - Recall: 0.9653 - TP: 3254.8999 - TN: 5565.7300 - FP: 81.2700 - FN: 117.1000 - val_loss: 0.4072 - val_Accuracy: 0.9707 - val_Precision: 0.9598 - val_Recall: 0.9515 - val_TP: 765.0200 - val_TN: 1081.8800 - val_FP: 24.1200 - val_FN: 38.9800\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.5712 - Accuracy: 0.9815 - Precision: 0.9645 - Recall: 0.9652 - TP: 3254.5901 - TN: 5560.6802 - FP: 86.3200 - FN: 117.4100 - val_loss: 0.4965 - val_Accuracy: 0.9686 - val_Precision: 0.9569 - val_Recall: 0.9501 - val_TP: 763.8700 - val_TN: 1079.4900 - val_FP: 26.5100 - val_FN: 40.1300\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2274 - Accuracy: 0.9840 - Precision: 0.9680 - Recall: 0.9666 - TP: 3259.3000 - TN: 5572.3901 - FP: 74.6100 - FN: 112.7000 - val_loss: 0.4153 - val_Accuracy: 0.9717 - val_Precision: 0.9654 - val_Recall: 0.9451 - val_TP: 759.9000 - val_TN: 1086.5699 - val_FP: 19.4300 - val_FN: 44.1000\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.4428 - Accuracy: 0.9843 - Precision: 0.9670 - Recall: 0.9680 - TP: 3263.9700 - TN: 5568.7500 - FP: 78.2500 - FN: 108.0300 - val_loss: 0.4631 - val_Accuracy: 0.9665 - val_Precision: 0.9578 - val_Recall: 0.9432 - val_TP: 758.3400 - val_TN: 1080.4399 - val_FP: 25.5600 - val_FN: 45.6600\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.5645 - Accuracy: 0.9813 - Precision: 0.9658 - Recall: 0.9644 - TP: 3251.8000 - TN: 5565.1602 - FP: 81.8400 - FN: 120.2000 - val_loss: 0.4816 - val_Accuracy: 0.9712 - val_Precision: 0.9698 - val_Recall: 0.9404 - val_TP: 756.1200 - val_TN: 1090.1801 - val_FP: 15.8200 - val_FN: 47.8800\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 0.2798 - Accuracy: 0.9841 - Precision: 0.9683 - Recall: 0.9681 - TP: 3264.4600 - TN: 5573.5498 - FP: 73.4500 - FN: 107.5400 - val_loss: 0.4289 - val_Accuracy: 0.9691 - val_Precision: 0.9575 - val_Recall: 0.9520 - val_TP: 765.4000 - val_TN: 1079.9600 - val_FP: 26.0400 - val_FN: 38.6000\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.3125 - Accuracy: 0.9841 - Precision: 0.9683 - Recall: 0.9674 - TP: 3262.1599 - TN: 5573.6299 - FP: 73.3700 - FN: 109.8400 - val_loss: 0.4242 - val_Accuracy: 0.9728 - val_Precision: 0.9654 - val_Recall: 0.9472 - val_TP: 761.5100 - val_TN: 1086.5699 - val_FP: 19.4300 - val_FN: 42.4900\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.3882 - Accuracy: 0.9843 - Precision: 0.9681 - Recall: 0.9686 - TP: 3265.9700 - TN: 5572.7002 - FP: 74.3000 - FN: 106.0300 - val_loss: 0.4536 - val_Accuracy: 0.9675 - val_Precision: 0.9543 - val_Recall: 0.9488 - val_TP: 762.8600 - val_TN: 1077.3700 - val_FP: 28.6300 - val_FN: 41.1400\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 34s 121ms/step - loss: 0.2945 - Accuracy: 0.9844 - Precision: 0.9684 - Recall: 0.9680 - TP: 3264.1599 - TN: 5573.8999 - FP: 73.1000 - FN: 107.8400 - val_loss: 0.4252 - val_Accuracy: 0.9728 - val_Precision: 0.9581 - val_Recall: 0.9524 - val_TP: 765.7200 - val_TN: 1080.4800 - val_FP: 25.5200 - val_FN: 38.2800\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 2s 8ms/step - loss: 0.6289 - Accuracy: 0.9831 - Precision: 0.9670 - Recall: 0.9664 - TP: 3258.5801 - TN: 5568.9800 - FP: 78.0200 - FN: 113.4200 - val_loss: 0.4059 - val_Accuracy: 0.9728 - val_Precision: 0.9651 - val_Recall: 0.9507 - val_TP: 764.4000 - val_TN: 1086.2500 - val_FP: 19.7500 - val_FN: 39.6000\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 3s 10ms/step - loss: 0.2385 - Accuracy: 0.9838 - Precision: 0.9678 - Recall: 0.9686 - TP: 3266.0601 - TN: 5571.7402 - FP: 75.2600 - FN: 105.9400 - val_loss: 0.4438 - val_Accuracy: 0.9691 - val_Precision: 0.9567 - val_Recall: 0.9510 - val_TP: 764.6100 - val_TN: 1079.3300 - val_FP: 26.6700 - val_FN: 39.3900\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 8s 13ms/step - loss: 0.4345 - Accuracy: 0.9787 - Precision: 0.9615 - Recall: 0.9624 - TP: 3245.3201 - TN: 5550.1099 - FP: 96.8900 - FN: 126.6800 - val_loss: 0.4206 - val_Accuracy: 0.9675 - val_Precision: 0.9551 - val_Recall: 0.9485 - val_TP: 762.5800 - val_TN: 1078.0200 - val_FP: 27.9800 - val_FN: 41.4200\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.4086 - Accuracy: 0.9857 - Precision: 0.9696 - Recall: 0.9683 - TP: 3265.0801 - TN: 5578.0801 - FP: 68.9200 - FN: 106.9200 - val_loss: 0.5067 - val_Accuracy: 0.9675 - val_Precision: 0.9505 - val_Recall: 0.9513 - val_TP: 764.8700 - val_TN: 1074.1000 - val_FP: 31.9000 - val_FN: 39.1300\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2328 - Accuracy: 0.9831 - Precision: 0.9671 - Recall: 0.9670 - TP: 3260.7000 - TN: 5569.2300 - FP: 77.7700 - FN: 111.3000 - val_loss: 0.4781 - val_Accuracy: 0.9681 - val_Precision: 0.9553 - val_Recall: 0.9508 - val_TP: 764.4500 - val_TN: 1078.1400 - val_FP: 27.8600 - val_FN: 39.5500\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3307 - Accuracy: 0.9834 - Precision: 0.9676 - Recall: 0.9663 - TP: 3258.3501 - TN: 5571.1802 - FP: 75.8200 - FN: 113.6500 - val_loss: 0.4490 - val_Accuracy: 0.9712 - val_Precision: 0.9680 - val_Recall: 0.9399 - val_TP: 755.7100 - val_TN: 1088.7400 - val_FP: 17.2600 - val_FN: 48.2900\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.6599 - Accuracy: 0.9798 - Precision: 0.9616 - Recall: 0.9619 - TP: 3243.4299 - TN: 5550.4502 - FP: 96.5500 - FN: 128.5700 - val_loss: 0.5494 - val_Accuracy: 0.9675 - val_Precision: 0.9489 - val_Recall: 0.9561 - val_TP: 768.7400 - val_TN: 1072.6600 - val_FP: 33.3400 - val_FN: 35.2600\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2476 - Accuracy: 0.9837 - Precision: 0.9677 - Recall: 0.9674 - TP: 3262.1699 - TN: 5571.3901 - FP: 75.6100 - FN: 109.8300 - val_loss: 0.4774 - val_Accuracy: 0.9686 - val_Precision: 0.9746 - val_Recall: 0.9311 - val_TP: 748.5700 - val_TN: 1094.1100 - val_FP: 11.8900 - val_FN: 55.4300\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.4264 - Accuracy: 0.9835 - Precision: 0.9675 - Recall: 0.9673 - TP: 3261.8000 - TN: 5570.8599 - FP: 76.1400 - FN: 110.2000 - val_loss: 0.7121 - val_Accuracy: 0.9618 - val_Precision: 0.9413 - val_Recall: 0.9491 - val_TP: 763.1100 - val_TN: 1066.4100 - val_FP: 39.5900 - val_FN: 40.8900\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.5900 - Accuracy: 0.9826 - Precision: 0.9655 - Recall: 0.9650 - TP: 3253.8701 - TN: 5563.8301 - FP: 83.1700 - FN: 118.1300 - val_loss: 0.4510 - val_Accuracy: 0.9654 - val_Precision: 0.9449 - val_Recall: 0.9562 - val_TP: 768.8200 - val_TN: 1069.2100 - val_FP: 36.7900 - val_FN: 35.1800\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2927 - Accuracy: 0.9847 - Precision: 0.9690 - Recall: 0.9681 - TP: 3264.6001 - TN: 5575.6099 - FP: 71.3900 - FN: 107.4000 - val_loss: 0.3784 - val_Accuracy: 0.9728 - val_Precision: 0.9607 - val_Recall: 0.9537 - val_TP: 766.8000 - val_TN: 1082.5400 - val_FP: 23.4600 - val_FN: 37.2000\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2623 - Accuracy: 0.9814 - Precision: 0.9649 - Recall: 0.9642 - TP: 3251.1699 - TN: 5561.7598 - FP: 85.2400 - FN: 120.8300 - val_loss: 0.4487 - val_Accuracy: 0.9686 - val_Precision: 0.9513 - val_Recall: 0.9541 - val_TP: 767.1300 - val_TN: 1074.7600 - val_FP: 31.2400 - val_FN: 36.8700\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.7288 - Accuracy: 0.9806 - Precision: 0.9629 - Recall: 0.9629 - TP: 3246.9299 - TN: 5555.0498 - FP: 91.9500 - FN: 125.0700 - val_loss: 0.4498 - val_Accuracy: 0.9702 - val_Precision: 0.9602 - val_Recall: 0.9488 - val_TP: 762.8500 - val_TN: 1082.2400 - val_FP: 23.7600 - val_FN: 41.1500\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2738 - Accuracy: 0.9839 - Precision: 0.9683 - Recall: 0.9674 - TP: 3261.9399 - TN: 5573.3799 - FP: 73.6200 - FN: 110.0600 - val_loss: 0.4411 - val_Accuracy: 0.9733 - val_Precision: 0.9696 - val_Recall: 0.9430 - val_TP: 758.1700 - val_TN: 1090.0300 - val_FP: 15.9700 - val_FN: 45.8300\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2626 - Accuracy: 0.9839 - Precision: 0.9672 - Recall: 0.9680 - TP: 3263.9800 - TN: 5569.6602 - FP: 77.3400 - FN: 108.0200 - val_loss: 0.4661 - val_Accuracy: 0.9707 - val_Precision: 0.9596 - val_Recall: 0.9476 - val_TP: 761.8700 - val_TN: 1081.7800 - val_FP: 24.2200 - val_FN: 42.1300\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3788 - Accuracy: 0.9824 - Precision: 0.9663 - Recall: 0.9656 - TP: 3256.1101 - TN: 5566.7998 - FP: 80.2000 - FN: 115.8900 - val_loss: 0.6340 - val_Accuracy: 0.9686 - val_Precision: 0.9566 - val_Recall: 0.9494 - val_TP: 763.3000 - val_TN: 1079.2800 - val_FP: 26.7200 - val_FN: 40.7000\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.4199 - Accuracy: 0.9807 - Precision: 0.9643 - Recall: 0.9630 - TP: 3247.0701 - TN: 5560.2598 - FP: 86.7400 - FN: 124.9300 - val_loss: 0.4354 - val_Accuracy: 0.9707 - val_Precision: 0.9648 - val_Recall: 0.9451 - val_TP: 759.8400 - val_TN: 1086.0800 - val_FP: 19.9200 - val_FN: 44.1600\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.4406 - Accuracy: 0.9847 - Precision: 0.9683 - Recall: 0.9687 - TP: 3266.6201 - TN: 5573.5200 - FP: 73.4800 - FN: 105.3800 - val_loss: 0.5613 - val_Accuracy: 0.9665 - val_Precision: 0.9585 - val_Recall: 0.9424 - val_TP: 757.6900 - val_TN: 1081.0601 - val_FP: 24.9400 - val_FN: 46.3100\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1825 - Accuracy: 0.9838 - Precision: 0.9670 - Recall: 0.9674 - TP: 3262.0300 - TN: 5568.8701 - FP: 78.1300 - FN: 109.9700 - val_loss: 0.6139 - val_Accuracy: 0.9681 - val_Precision: 0.9602 - val_Recall: 0.9426 - val_TP: 757.8800 - val_TN: 1082.4100 - val_FP: 23.5900 - val_FN: 46.1200\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.5083 - Accuracy: 0.9821 - Precision: 0.9663 - Recall: 0.9657 - TP: 3256.3201 - TN: 5566.7300 - FP: 80.2700 - FN: 115.6800 - val_loss: 0.4976 - val_Accuracy: 0.9696 - val_Precision: 0.9579 - val_Recall: 0.9494 - val_TP: 763.3100 - val_TN: 1080.4000 - val_FP: 25.6000 - val_FN: 40.6900\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2890 - Accuracy: 0.9833 - Precision: 0.9666 - Recall: 0.9657 - TP: 3256.3201 - TN: 5567.7998 - FP: 79.2000 - FN: 115.6800 - val_loss: 0.4329 - val_Accuracy: 0.9712 - val_Precision: 0.9543 - val_Recall: 0.9547 - val_TP: 767.5900 - val_TN: 1077.1700 - val_FP: 28.8300 - val_FN: 36.4100\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2617 - Accuracy: 0.9859 - Precision: 0.9693 - Recall: 0.9700 - TP: 3271.0000 - TN: 5576.8101 - FP: 70.1900 - FN: 101.0000 - val_loss: 0.6511 - val_Accuracy: 0.9675 - val_Precision: 0.9502 - val_Recall: 0.9507 - val_TP: 764.3900 - val_TN: 1073.9399 - val_FP: 32.0600 - val_FN: 39.6100\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.4711 - Accuracy: 0.9792 - Precision: 0.9627 - Recall: 0.9621 - TP: 3244.0500 - TN: 5554.5801 - FP: 92.4200 - FN: 127.9500 - val_loss: 0.4737 - val_Accuracy: 0.9717 - val_Precision: 0.9666 - val_Recall: 0.9424 - val_TP: 757.7200 - val_TN: 1087.6200 - val_FP: 18.3800 - val_FN: 46.2800\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.8129 - Accuracy: 0.9812 - Precision: 0.9651 - Recall: 0.9643 - TP: 3251.7300 - TN: 5562.6899 - FP: 84.3100 - FN: 120.2700 - val_loss: 0.5449 - val_Accuracy: 0.9675 - val_Precision: 0.9508 - val_Recall: 0.9518 - val_TP: 765.2400 - val_TN: 1074.3500 - val_FP: 31.6500 - val_FN: 38.7600\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.4080 - Accuracy: 0.9812 - Precision: 0.9655 - Recall: 0.9641 - TP: 3250.8601 - TN: 5564.1602 - FP: 82.8400 - FN: 121.1400 - val_loss: 0.4796 - val_Accuracy: 0.9712 - val_Precision: 0.9597 - val_Recall: 0.9512 - val_TP: 764.7700 - val_TN: 1081.8101 - val_FP: 24.1900 - val_FN: 39.2300\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3380 - Accuracy: 0.9821 - Precision: 0.9655 - Recall: 0.9661 - TP: 3257.8501 - TN: 5564.0698 - FP: 82.9300 - FN: 114.1500 - val_loss: 0.4945 - val_Accuracy: 0.9702 - val_Precision: 0.9694 - val_Recall: 0.9394 - val_TP: 755.2700 - val_TN: 1089.9100 - val_FP: 16.0900 - val_FN: 48.7300\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2776 - Accuracy: 0.9839 - Precision: 0.9681 - Recall: 0.9686 - TP: 3266.0200 - TN: 5572.6802 - FP: 74.3200 - FN: 105.9800 - val_loss: 0.6035 - val_Accuracy: 0.9691 - val_Precision: 0.9530 - val_Recall: 0.9545 - val_TP: 767.4300 - val_TN: 1076.1700 - val_FP: 29.8300 - val_FN: 36.5700\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2053 - Accuracy: 0.9834 - Precision: 0.9679 - Recall: 0.9671 - TP: 3261.1399 - TN: 5572.1499 - FP: 74.8500 - FN: 110.8600 - val_loss: 0.5505 - val_Accuracy: 0.9686 - val_Precision: 0.9474 - val_Recall: 0.9578 - val_TP: 770.1000 - val_TN: 1071.2600 - val_FP: 34.7400 - val_FN: 33.9000\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3240 - Accuracy: 0.9845 - Precision: 0.9680 - Recall: 0.9679 - TP: 3263.6699 - TN: 5572.5698 - FP: 74.4300 - FN: 108.3300 - val_loss: 0.4842 - val_Accuracy: 0.9696 - val_Precision: 0.9557 - val_Recall: 0.9526 - val_TP: 765.9100 - val_TN: 1078.4500 - val_FP: 27.5500 - val_FN: 38.0900\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.5600 - Accuracy: 0.9823 - Precision: 0.9659 - Recall: 0.9665 - TP: 3258.8799 - TN: 5565.2700 - FP: 81.7300 - FN: 113.1200 - val_loss: 0.6758 - val_Accuracy: 0.9696 - val_Precision: 0.9594 - val_Recall: 0.9463 - val_TP: 760.8200 - val_TN: 1081.6700 - val_FP: 24.3300 - val_FN: 43.1800\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3162 - Accuracy: 0.9840 - Precision: 0.9692 - Recall: 0.9686 - TP: 3266.1599 - TN: 5576.6201 - FP: 70.3800 - FN: 105.8400 - val_loss: 0.6149 - val_Accuracy: 0.9696 - val_Precision: 0.9580 - val_Recall: 0.9493 - val_TP: 763.2100 - val_TN: 1080.4600 - val_FP: 25.5400 - val_FN: 40.7900\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 8ms/step - loss: 0.5785 - Accuracy: 0.9813 - Precision: 0.9636 - Recall: 0.9639 - TP: 3250.2700 - TN: 5557.3599 - FP: 89.6400 - FN: 121.7300 - val_loss: 0.4372 - val_Accuracy: 0.9675 - val_Precision: 0.9517 - val_Recall: 0.9525 - val_TP: 765.8100 - val_TN: 1075.1100 - val_FP: 30.8900 - val_FN: 38.1900\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3332 - Accuracy: 0.9823 - Precision: 0.9652 - Recall: 0.9658 - TP: 3256.5500 - TN: 5562.9600 - FP: 84.0400 - FN: 115.4500 - val_loss: 0.5083 - val_Accuracy: 0.9723 - val_Precision: 0.9700 - val_Recall: 0.9382 - val_TP: 754.3200 - val_TN: 1090.4200 - val_FP: 15.5800 - val_FN: 49.6800\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1916 - Accuracy: 0.9853 - Precision: 0.9700 - Recall: 0.9689 - TP: 3267.1201 - TN: 5579.2100 - FP: 67.7900 - FN: 104.8800 - val_loss: 0.4695 - val_Accuracy: 0.9723 - val_Precision: 0.9654 - val_Recall: 0.9449 - val_TP: 759.7000 - val_TN: 1086.5699 - val_FP: 19.4300 - val_FN: 44.3000\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2544 - Accuracy: 0.9833 - Precision: 0.9670 - Recall: 0.9665 - TP: 3258.8799 - TN: 5569.1699 - FP: 77.8300 - FN: 113.1200 - val_loss: 0.4566 - val_Accuracy: 0.9707 - val_Precision: 0.9612 - val_Recall: 0.9479 - val_TP: 762.1100 - val_TN: 1083.0601 - val_FP: 22.9400 - val_FN: 41.8900\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.7399 - Accuracy: 0.9819 - Precision: 0.9653 - Recall: 0.9660 - TP: 3257.4299 - TN: 5563.2002 - FP: 83.8000 - FN: 114.5700 - val_loss: 0.4990 - val_Accuracy: 0.9702 - val_Precision: 0.9604 - val_Recall: 0.9453 - val_TP: 760.0100 - val_TN: 1082.5400 - val_FP: 23.4600 - val_FN: 43.9900\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.6098 - Accuracy: 0.9819 - Precision: 0.9664 - Recall: 0.9638 - TP: 3250.0500 - TN: 5567.2002 - FP: 79.8000 - FN: 121.9500 - val_loss: 0.4358 - val_Accuracy: 0.9696 - val_Precision: 0.9528 - val_Recall: 0.9556 - val_TP: 768.2700 - val_TN: 1075.9000 - val_FP: 30.1000 - val_FN: 35.7300\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2519 - Accuracy: 0.9851 - Precision: 0.9691 - Recall: 0.9701 - TP: 3271.0500 - TN: 5576.0698 - FP: 70.9300 - FN: 100.9500 - val_loss: 0.4712 - val_Accuracy: 0.9686 - val_Precision: 0.9516 - val_Recall: 0.9547 - val_TP: 767.5600 - val_TN: 1074.9800 - val_FP: 31.0200 - val_FN: 36.4400\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.1842 - Accuracy: 0.9839 - Precision: 0.9685 - Recall: 0.9685 - TP: 3265.8999 - TN: 5573.9302 - FP: 73.0700 - FN: 106.1000 - val_loss: 0.6310 - val_Accuracy: 0.9660 - val_Precision: 0.9507 - val_Recall: 0.9472 - val_TP: 761.5500 - val_TN: 1074.4301 - val_FP: 31.5700 - val_FN: 42.4500\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.4892 - Accuracy: 0.9821 - Precision: 0.9657 - Recall: 0.9651 - TP: 3254.2700 - TN: 5564.5498 - FP: 82.4500 - FN: 117.7300 - val_loss: 0.4777 - val_Accuracy: 0.9686 - val_Precision: 0.9518 - val_Recall: 0.9512 - val_TP: 764.7300 - val_TN: 1075.2700 - val_FP: 30.7300 - val_FN: 39.2700\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.5242 - Accuracy: 0.9838 - Precision: 0.9673 - Recall: 0.9670 - TP: 3260.6399 - TN: 5570.1699 - FP: 76.8300 - FN: 111.3600 - val_loss: 0.5722 - val_Accuracy: 0.9675 - val_Precision: 0.9504 - val_Recall: 0.9509 - val_TP: 764.5200 - val_TN: 1074.0601 - val_FP: 31.9400 - val_FN: 39.4800\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3966 - Accuracy: 0.9833 - Precision: 0.9683 - Recall: 0.9676 - TP: 3262.6299 - TN: 5573.4702 - FP: 73.5300 - FN: 109.3700 - val_loss: 0.4727 - val_Accuracy: 0.9707 - val_Precision: 0.9604 - val_Recall: 0.9492 - val_TP: 763.1300 - val_TN: 1082.4200 - val_FP: 23.5800 - val_FN: 40.8700\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3495 - Accuracy: 0.9816 - Precision: 0.9648 - Recall: 0.9645 - TP: 3252.4500 - TN: 5561.7500 - FP: 85.2500 - FN: 119.5500 - val_loss: 0.8216 - val_Accuracy: 0.9634 - val_Precision: 0.9409 - val_Recall: 0.9503 - val_TP: 764.0600 - val_TN: 1066.0601 - val_FP: 39.9400 - val_FN: 39.9400\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 1.2296 - Accuracy: 0.9797 - Precision: 0.9637 - Recall: 0.9627 - TP: 3246.2000 - TN: 5557.8901 - FP: 89.1100 - FN: 125.8000 - val_loss: 0.4761 - val_Accuracy: 0.9681 - val_Precision: 0.9459 - val_Recall: 0.9568 - val_TP: 769.2700 - val_TN: 1070.0601 - val_FP: 35.9400 - val_FN: 34.7300\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2134 - Accuracy: 0.9866 - Precision: 0.9707 - Recall: 0.9705 - TP: 3272.5300 - TN: 5581.5200 - FP: 65.4800 - FN: 99.4700 - val_loss: 0.4391 - val_Accuracy: 0.9707 - val_Precision: 0.9672 - val_Recall: 0.9440 - val_TP: 758.9500 - val_TN: 1088.0900 - val_FP: 17.9100 - val_FN: 45.0500\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3342 - Accuracy: 0.9848 - Precision: 0.9685 - Recall: 0.9688 - TP: 3266.8401 - TN: 5574.1099 - FP: 72.8900 - FN: 105.1600 - val_loss: 0.5454 - val_Accuracy: 0.9702 - val_Precision: 0.9663 - val_Recall: 0.9384 - val_TP: 754.4900 - val_TN: 1087.4700 - val_FP: 18.5300 - val_FN: 49.5100\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.7183 - Accuracy: 0.9808 - Precision: 0.9641 - Recall: 0.9627 - TP: 3246.2100 - TN: 5559.4199 - FP: 87.5800 - FN: 125.7900 - val_loss: 0.5169 - val_Accuracy: 0.9665 - val_Precision: 0.9377 - val_Recall: 0.9618 - val_TP: 773.2700 - val_TN: 1062.8199 - val_FP: 43.1800 - val_FN: 30.7300\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2912 - Accuracy: 0.9833 - Precision: 0.9661 - Recall: 0.9678 - TP: 3263.4800 - TN: 5565.9399 - FP: 81.0600 - FN: 108.5200 - val_loss: 0.5323 - val_Accuracy: 0.9707 - val_Precision: 0.9610 - val_Recall: 0.9478 - val_TP: 762.0700 - val_TN: 1082.9500 - val_FP: 23.0500 - val_FN: 41.9300\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.7002 - Accuracy: 0.9798 - Precision: 0.9633 - Recall: 0.9631 - TP: 3247.7300 - TN: 5556.4902 - FP: 90.5100 - FN: 124.2700 - val_loss: 0.6547 - val_Accuracy: 0.9644 - val_Precision: 0.9684 - val_Recall: 0.9296 - val_TP: 747.4200 - val_TN: 1089.3199 - val_FP: 16.6800 - val_FN: 56.5800\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2492 - Accuracy: 0.9841 - Precision: 0.9687 - Recall: 0.9676 - TP: 3262.7200 - TN: 5574.7402 - FP: 72.2600 - FN: 109.2800 - val_loss: 0.5066 - val_Accuracy: 0.9691 - val_Precision: 0.9627 - val_Recall: 0.9443 - val_TP: 759.2100 - val_TN: 1084.4399 - val_FP: 21.5600 - val_FN: 44.7900\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.4199 - Accuracy: 0.9844 - Precision: 0.9694 - Recall: 0.9679 - TP: 3263.6101 - TN: 5577.2998 - FP: 69.7000 - FN: 108.3900 - val_loss: 0.5308 - val_Accuracy: 0.9634 - val_Precision: 0.9337 - val_Recall: 0.9612 - val_TP: 772.7800 - val_TN: 1059.3199 - val_FP: 46.6800 - val_FN: 31.2200\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3062 - Accuracy: 0.9835 - Precision: 0.9673 - Recall: 0.9685 - TP: 3265.8000 - TN: 5570.1099 - FP: 76.8900 - FN: 106.2000 - val_loss: 0.6535 - val_Accuracy: 0.9712 - val_Precision: 0.9635 - val_Recall: 0.9445 - val_TP: 759.3600 - val_TN: 1085.0601 - val_FP: 20.9400 - val_FN: 44.6400\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2723 - Accuracy: 0.9848 - Precision: 0.9690 - Recall: 0.9695 - TP: 3269.2600 - TN: 5575.7202 - FP: 71.2800 - FN: 102.7400 - val_loss: 0.6604 - val_Accuracy: 0.9665 - val_Precision: 0.9612 - val_Recall: 0.9378 - val_TP: 754.0200 - val_TN: 1083.3600 - val_FP: 22.6400 - val_FN: 49.9800\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3804 - Accuracy: 0.9838 - Precision: 0.9676 - Recall: 0.9676 - TP: 3262.7600 - TN: 5571.1602 - FP: 75.8400 - FN: 109.2400 - val_loss: 0.5950 - val_Accuracy: 0.9670 - val_Precision: 0.9742 - val_Recall: 0.9295 - val_TP: 747.3400 - val_TN: 1093.8600 - val_FP: 12.1400 - val_FN: 56.6600\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3395 - Accuracy: 0.9834 - Precision: 0.9677 - Recall: 0.9676 - TP: 3262.7300 - TN: 5571.4399 - FP: 75.5600 - FN: 109.2700 - val_loss: 0.5316 - val_Accuracy: 0.9681 - val_Precision: 0.9622 - val_Recall: 0.9431 - val_TP: 758.2400 - val_TN: 1084.0300 - val_FP: 21.9700 - val_FN: 45.7600\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.4405 - Accuracy: 0.9815 - Precision: 0.9654 - Recall: 0.9642 - TP: 3251.2000 - TN: 5563.7002 - FP: 83.3000 - FN: 120.8000 - val_loss: 0.7097 - val_Accuracy: 0.9634 - val_Precision: 0.9481 - val_Recall: 0.9468 - val_TP: 761.1900 - val_TN: 1072.2900 - val_FP: 33.7100 - val_FN: 42.8100\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.5610 - Accuracy: 0.9825 - Precision: 0.9661 - Recall: 0.9653 - TP: 3255.0100 - TN: 5566.1401 - FP: 80.8600 - FN: 116.9900 - val_loss: 1.4542 - val_Accuracy: 0.9414 - val_Precision: 0.8964 - val_Recall: 0.9500 - val_TP: 763.8400 - val_TN: 1026.0800 - val_FP: 79.9200 - val_FN: 40.1600\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 4s 8ms/step - loss: 0.5792 - Accuracy: 0.9819 - Precision: 0.9656 - Recall: 0.9650 - TP: 3253.8601 - TN: 5564.4902 - FP: 82.5100 - FN: 118.1400 - val_loss: 0.5008 - val_Accuracy: 0.9702 - val_Precision: 0.9570 - val_Recall: 0.9521 - val_TP: 765.4800 - val_TN: 1079.5300 - val_FP: 26.4700 - val_FN: 38.5200\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3490 - Accuracy: 0.9843 - Precision: 0.9679 - Recall: 0.9688 - TP: 3266.6699 - TN: 5572.2100 - FP: 74.7900 - FN: 105.3300 - val_loss: 0.6193 - val_Accuracy: 0.9644 - val_Precision: 0.9425 - val_Recall: 0.9548 - val_TP: 767.6500 - val_TN: 1067.2900 - val_FP: 38.7100 - val_FN: 36.3500\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2993 - Accuracy: 0.9844 - Precision: 0.9675 - Recall: 0.9677 - TP: 3263.2200 - TN: 5570.5698 - FP: 76.4300 - FN: 108.7800 - val_loss: 0.6268 - val_Accuracy: 0.9639 - val_Precision: 0.9564 - val_Recall: 0.9386 - val_TP: 754.6300 - val_TN: 1079.4700 - val_FP: 26.5300 - val_FN: 49.3700\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.4485 - Accuracy: 0.9819 - Precision: 0.9659 - Recall: 0.9644 - TP: 3251.8000 - TN: 5565.5498 - FP: 81.4500 - FN: 120.2000 - val_loss: 0.4666 - val_Accuracy: 0.9691 - val_Precision: 0.9563 - val_Recall: 0.9512 - val_TP: 764.7800 - val_TN: 1079.0100 - val_FP: 26.9900 - val_FN: 39.2200\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2620 - Accuracy: 0.9838 - Precision: 0.9672 - Recall: 0.9678 - TP: 3263.5100 - TN: 5569.7798 - FP: 77.2200 - FN: 108.4900 - val_loss: 0.4945 - val_Accuracy: 0.9702 - val_Precision: 0.9710 - val_Recall: 0.9379 - val_TP: 754.1000 - val_TN: 1091.2400 - val_FP: 14.7600 - val_FN: 49.9000\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3001 - Accuracy: 0.9828 - Precision: 0.9673 - Recall: 0.9663 - TP: 3258.4800 - TN: 5570.1899 - FP: 76.8100 - FN: 113.5200 - val_loss: 0.5391 - val_Accuracy: 0.9675 - val_Precision: 0.9626 - val_Recall: 0.9410 - val_TP: 756.5600 - val_TN: 1084.4200 - val_FP: 21.5800 - val_FN: 47.4400\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.7809 - Accuracy: 0.9795 - Precision: 0.9627 - Recall: 0.9619 - TP: 3243.4600 - TN: 5554.7700 - FP: 92.2300 - FN: 128.5400 - val_loss: 0.5784 - val_Accuracy: 0.9681 - val_Precision: 0.9462 - val_Recall: 0.9579 - val_TP: 770.1900 - val_TN: 1070.2500 - val_FP: 35.7500 - val_FN: 33.8100\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3079 - Accuracy: 0.9835 - Precision: 0.9668 - Recall: 0.9685 - TP: 3265.8999 - TN: 5568.4302 - FP: 78.5700 - FN: 106.1000 - val_loss: 0.5079 - val_Accuracy: 0.9686 - val_Precision: 0.9642 - val_Recall: 0.9409 - val_TP: 756.5000 - val_TN: 1085.6700 - val_FP: 20.3300 - val_FN: 47.5000\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.6375 - Accuracy: 0.9823 - Precision: 0.9657 - Recall: 0.9654 - TP: 3255.1799 - TN: 5564.6499 - FP: 82.3500 - FN: 116.8200 - val_loss: 0.4857 - val_Accuracy: 0.9712 - val_Precision: 0.9685 - val_Recall: 0.9430 - val_TP: 758.1500 - val_TN: 1089.1600 - val_FP: 16.8400 - val_FN: 45.8500\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.2501 - Accuracy: 0.9846 - Precision: 0.9699 - Recall: 0.9678 - TP: 3263.4199 - TN: 5579.1602 - FP: 67.8400 - FN: 108.5800 - val_loss: 0.6058 - val_Accuracy: 0.9665 - val_Precision: 0.9491 - val_Recall: 0.9516 - val_TP: 765.0600 - val_TN: 1072.9399 - val_FP: 33.0600 - val_FN: 38.9400\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3904 - Accuracy: 0.9831 - Precision: 0.9672 - Recall: 0.9662 - TP: 3258.1201 - TN: 5569.7700 - FP: 77.2300 - FN: 113.8800 - val_loss: 0.5941 - val_Accuracy: 0.9707 - val_Precision: 0.9590 - val_Recall: 0.9497 - val_TP: 763.5500 - val_TN: 1081.3000 - val_FP: 24.7000 - val_FN: 40.4500\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.4683 - Accuracy: 0.9819 - Precision: 0.9647 - Recall: 0.9654 - TP: 3255.2100 - TN: 5561.3198 - FP: 85.6800 - FN: 116.7900 - val_loss: 0.4870 - val_Accuracy: 0.9712 - val_Precision: 0.9630 - val_Recall: 0.9477 - val_TP: 761.9500 - val_TN: 1084.6300 - val_FP: 21.3700 - val_FN: 42.0500\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.5008 - Accuracy: 0.9827 - Precision: 0.9667 - Recall: 0.9668 - TP: 3260.1599 - TN: 5568.0098 - FP: 78.9900 - FN: 111.8400 - val_loss: 0.4501 - val_Accuracy: 0.9696 - val_Precision: 0.9547 - val_Recall: 0.9541 - val_TP: 767.1100 - val_TN: 1077.5699 - val_FP: 28.4300 - val_FN: 36.8900\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.5219 - Accuracy: 0.9823 - Precision: 0.9650 - Recall: 0.9651 - TP: 3254.2200 - TN: 5562.4199 - FP: 84.5800 - FN: 117.7800 - val_loss: 0.5154 - val_Accuracy: 0.9681 - val_Precision: 0.9563 - val_Recall: 0.9471 - val_TP: 761.5000 - val_TN: 1079.1000 - val_FP: 26.9000 - val_FN: 42.5000\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.4049 - Accuracy: 0.9831 - Precision: 0.9669 - Recall: 0.9667 - TP: 3259.6499 - TN: 5568.5601 - FP: 78.4400 - FN: 112.3500 - val_loss: 0.5946 - val_Accuracy: 0.9702 - val_Precision: 0.9587 - val_Recall: 0.9487 - val_TP: 762.7500 - val_TN: 1081.0500 - val_FP: 24.9500 - val_FN: 41.2500\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.5320 - Accuracy: 0.9826 - Precision: 0.9673 - Recall: 0.9666 - TP: 3259.4800 - TN: 5570.0200 - FP: 76.9800 - FN: 112.5200 - val_loss: 0.5420 - val_Accuracy: 0.9675 - val_Precision: 0.9446 - val_Recall: 0.9592 - val_TP: 771.2200 - val_TN: 1068.9100 - val_FP: 37.0900 - val_FN: 32.7800\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.2084 - Accuracy: 0.9858 - Precision: 0.9697 - Recall: 0.9702 - TP: 3271.4199 - TN: 5578.1401 - FP: 68.8600 - FN: 100.5800 - val_loss: 0.5683 - val_Accuracy: 0.9675 - val_Precision: 0.9559 - val_Recall: 0.9480 - val_TP: 762.1800 - val_TN: 1078.7400 - val_FP: 27.2600 - val_FN: 41.8200\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.4372 - Accuracy: 0.9835 - Precision: 0.9680 - Recall: 0.9661 - TP: 3257.5901 - TN: 5572.5400 - FP: 74.4600 - FN: 114.4100 - val_loss: 0.5936 - val_Accuracy: 0.9644 - val_Precision: 0.9280 - val_Recall: 0.9672 - val_TP: 777.6200 - val_TN: 1053.9100 - val_FP: 52.0900 - val_FN: 26.3800\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2774 - Accuracy: 0.9848 - Precision: 0.9685 - Recall: 0.9695 - TP: 3269.1399 - TN: 5574.2700 - FP: 72.7300 - FN: 102.8600 - val_loss: 0.4700 - val_Accuracy: 0.9707 - val_Precision: 0.9617 - val_Recall: 0.9475 - val_TP: 761.7700 - val_TN: 1083.5100 - val_FP: 22.4900 - val_FN: 42.2300\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.3186 - Accuracy: 0.9819 - Precision: 0.9658 - Recall: 0.9660 - TP: 3257.3101 - TN: 5565.1299 - FP: 81.8700 - FN: 114.6900 - val_loss: 0.5780 - val_Accuracy: 0.9707 - val_Precision: 0.9575 - val_Recall: 0.9524 - val_TP: 765.7100 - val_TN: 1079.9500 - val_FP: 26.0500 - val_FN: 38.2900\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.8491 - Accuracy: 0.9823 - Precision: 0.9661 - Recall: 0.9652 - TP: 3254.7600 - TN: 5566.1001 - FP: 80.9000 - FN: 117.2400 - val_loss: 0.4912 - val_Accuracy: 0.9681 - val_Precision: 0.9578 - val_Recall: 0.9491 - val_TP: 763.0600 - val_TN: 1080.2600 - val_FP: 25.7400 - val_FN: 40.9400\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.5713 - Accuracy: 0.9825 - Precision: 0.9662 - Recall: 0.9661 - TP: 3257.6399 - TN: 5566.4502 - FP: 80.5500 - FN: 114.3600 - val_loss: 0.6018 - val_Accuracy: 0.9681 - val_Precision: 0.9570 - val_Recall: 0.9452 - val_TP: 759.9700 - val_TN: 1079.7600 - val_FP: 26.2400 - val_FN: 44.0300\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.5613 - Accuracy: 0.9812 - Precision: 0.9643 - Recall: 0.9644 - TP: 3252.0000 - TN: 5559.8101 - FP: 87.1900 - FN: 120.0000 - val_loss: 0.7562 - val_Accuracy: 0.9644 - val_Precision: 0.9426 - val_Recall: 0.9535 - val_TP: 766.5800 - val_TN: 1067.4200 - val_FP: 38.5800 - val_FN: 37.4200\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3150 - Accuracy: 0.9836 - Precision: 0.9681 - Recall: 0.9677 - TP: 3263.0100 - TN: 5573.0400 - FP: 73.9600 - FN: 108.9900 - val_loss: 0.5375 - val_Accuracy: 0.9665 - val_Precision: 0.9485 - val_Recall: 0.9546 - val_TP: 767.4800 - val_TN: 1072.4100 - val_FP: 33.5900 - val_FN: 36.5200\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2910 - Accuracy: 0.9861 - Precision: 0.9706 - Recall: 0.9703 - TP: 3271.9500 - TN: 5581.5200 - FP: 65.4800 - FN: 100.0500 - val_loss: 0.5158 - val_Accuracy: 0.9696 - val_Precision: 0.9551 - val_Recall: 0.9520 - val_TP: 765.4400 - val_TN: 1078.0000 - val_FP: 28.0000 - val_FN: 38.5600\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.4832 - Accuracy: 0.9833 - Precision: 0.9681 - Recall: 0.9673 - TP: 3261.7300 - TN: 5572.7500 - FP: 74.2500 - FN: 110.2700 - val_loss: 0.7462 - val_Accuracy: 0.9649 - val_Precision: 0.9452 - val_Recall: 0.9502 - val_TP: 763.9700 - val_TN: 1069.7600 - val_FP: 36.2400 - val_FN: 40.0300\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.5772 - Accuracy: 0.9843 - Precision: 0.9687 - Recall: 0.9676 - TP: 3262.8701 - TN: 5574.9502 - FP: 72.0500 - FN: 109.1300 - val_loss: 0.6829 - val_Accuracy: 0.9649 - val_Precision: 0.9452 - val_Recall: 0.9522 - val_TP: 765.5500 - val_TN: 1069.6801 - val_FP: 36.3200 - val_FN: 38.4500\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.7114 - Accuracy: 0.9819 - Precision: 0.9653 - Recall: 0.9657 - TP: 3256.3401 - TN: 5563.3101 - FP: 83.6900 - FN: 115.6600 - val_loss: 0.9915 - val_Accuracy: 0.9597 - val_Precision: 0.9387 - val_Recall: 0.9501 - val_TP: 763.8900 - val_TN: 1064.2100 - val_FP: 41.7900 - val_FN: 40.1100\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 1s 5ms/step - loss: 0.3843 - Accuracy: 0.9836 - Precision: 0.9676 - Recall: 0.9674 - TP: 3262.1001 - TN: 5571.2598 - FP: 75.7400 - FN: 109.9000 - val_loss: 0.5216 - val_Accuracy: 0.9696 - val_Precision: 0.9563 - val_Recall: 0.9517 - val_TP: 765.1600 - val_TN: 1079.0000 - val_FP: 27.0000 - val_FN: 38.8400\n",
      "Epoch 30/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.2475 - Accuracy: 0.9841 - Precision: 0.9683 - Recall: 0.9684 - TP: 3265.3101 - TN: 5573.5000 - FP: 73.5000 - FN: 106.6900 - val_loss: 0.9454 - val_Accuracy: 0.9602 - val_Precision: 0.9294 - val_Recall: 0.9569 - val_TP: 769.3200 - val_TN: 1055.7400 - val_FP: 50.2600 - val_FN: 34.6800\n",
      "Epoch 31/60\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 0.3976 - Accuracy: 0.9844 - Precision: 0.9679 - Recall: 0.9691 - TP: 3267.6499 - TN: 5572.1001 - FP: 74.9000 - FN: 104.3500 - val_loss: 0.6063 - val_Accuracy: 0.9712 - val_Precision: 0.9668 - val_Recall: 0.9423 - val_TP: 757.6100 - val_TN: 1087.8101 - val_FP: 18.1900 - val_FN: 46.3900\n",
      "Epoch 32/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.6912 - Accuracy: 0.9814 - Precision: 0.9657 - Recall: 0.9658 - TP: 3256.5100 - TN: 5564.7202 - FP: 82.2800 - FN: 115.4900 - val_loss: 0.8987 - val_Accuracy: 0.9613 - val_Precision: 0.9448 - val_Recall: 0.9421 - val_TP: 757.4600 - val_TN: 1069.6899 - val_FP: 36.3100 - val_FN: 46.5400\n",
      "Epoch 33/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.5477 - Accuracy: 0.9833 - Precision: 0.9679 - Recall: 0.9666 - TP: 3259.5200 - TN: 5572.3501 - FP: 74.6500 - FN: 112.4800 - val_loss: 0.5412 - val_Accuracy: 0.9728 - val_Precision: 0.9677 - val_Recall: 0.9457 - val_TP: 760.3400 - val_TN: 1088.4399 - val_FP: 17.5600 - val_FN: 43.6600\n"
     ]
    }
   ],
   "source": [
    "metadata_path = \"..\\\\metadata.csv\"\n",
    "audio_dir = \"..\\\\dataset\\\\audios\"\n",
    "\n",
    "audio_dataset = dataLoader.AudioDataset(metadata_path, audio_dir)\n",
    "train_ds, val_ds, test_ds = audio_dataset.preprocess_datasets()\n",
    "\n",
    "classifier = modelo.Clasificador()\n",
    "classifier.units = 100\n",
    "classifier.compilar()\n",
    "history = classifier.train(train_ds, val_ds)\n",
    "\n",
    "loss_func = []\n",
    "valloss_func = []\n",
    "lrs = []\n",
    "\n",
    "i = 10**(-5)\n",
    "for cicle in range(200):\n",
    "    classifier.alpha = i\n",
    "    classifier.compilar()\n",
    "    history = classifier.train(train_ds, val_ds)\n",
    "    \n",
    "    loss_func.append(history.history['loss'][-21])\n",
    "    valloss_func.append(history.history['val_loss'][-21])\n",
    "    lrs.append(i)\n",
    "\n",
    "    i *= 10**(np.log10(10**4)/200)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.063204</td>\n",
       "      <td>0.072708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.062265</td>\n",
       "      <td>0.072777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.061100</td>\n",
       "      <td>0.072938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.060126</td>\n",
       "      <td>0.073151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.059590</td>\n",
       "      <td>0.073328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.079433</td>\n",
       "      <td>0.293638</td>\n",
       "      <td>0.369796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.083176</td>\n",
       "      <td>0.452777</td>\n",
       "      <td>0.391335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.087096</td>\n",
       "      <td>0.292654</td>\n",
       "      <td>0.378420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.091201</td>\n",
       "      <td>0.609770</td>\n",
       "      <td>0.435797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.095499</td>\n",
       "      <td>0.500798</td>\n",
       "      <td>0.450092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Learning Rate      Loss  Validation Loss\n",
       "0         0.000010  0.063204         0.072708\n",
       "1         0.000010  0.062265         0.072777\n",
       "2         0.000011  0.061100         0.072938\n",
       "3         0.000011  0.060126         0.073151\n",
       "4         0.000012  0.059590         0.073328\n",
       "..             ...       ...              ...\n",
       "195       0.079433  0.293638         0.369796\n",
       "196       0.083176  0.452777         0.391335\n",
       "197       0.087096  0.292654         0.378420\n",
       "198       0.091201  0.609770         0.435797\n",
       "199       0.095499  0.500798         0.450092\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Tasa de aprendizaje')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABlsAAAHJCAYAAAACWo8mAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAADYzElEQVR4nOzdZ3hUZfrH8d/MJJPeaEkIgSiIiCJVWMQuLvayFmyAqLiusovL37K6q9jRtaG7rqwV29pXcUFxBcVVkCIKNorUhJIESC/T5//izEwypE0mk0Ly/VzXXJk585xznhR8MT/v+zZ5vV6vAAAAAAAAAAAAEBZze28AAAAAAAAAAADgYEbYAgAAAAAAAAAA0AKELQAAAAAAAAAAAC1A2AIAAAAAAAAAANAChC0AAAAAAAAAAAAtQNgCAAAAAAAAAADQAoQtAAAAAAAAAAAALRDV3hvoKDwej3bv3q2kpCSZTKb23g4AAAAAAAAAAGhHXq9X5eXl6t27t8zmxmtXCFt8du/erezs7PbeBgAAAAAAAAAA6EDy8vLUp0+fRtcQtvgkJSVJMn5oycnJ7bwbAAAAAAAAAADQnsrKypSdnR3IDxpD2OLjbx2WnJxM2AIAAAAAAAAAACQppNEjjTcZAwAAAAAAAAAAQKMIWwAAAAAAAAAAAFqAsAUAAAAAAAAAAKAFmNnSTG63W06ns723gU4kOjpaFoulvbcBAAAAAAAAAAgTYUuIvF6v8vPzVVJS0t5bQSeUmpqqjIyMkAYtAQAAAAAAAAA6FsKWEPmDll69eik+Pp4PxRERXq9XVVVVKiwslCRlZma2844AAAAAAAAAAM1F2BICt9sdCFq6d+/e3ttBJxMXFydJKiwsVK9evWgpBgAAAAAAAAAHGXN7b+Bg4J/REh8f3847QWfl/9tiHhAAAAAAAAAAHHwIW5qB1mFoLfxtAQAAAAAAAMDBi7AFAAAAAAAAAACgBQhbAAAAAAAAAAAAWoCwBQAAAAAAAAAAoAUIWxDkqquukslkqvM4/fTTJRmzRT744IP23SQAAAAAAAAAAB1IVHtvAB3P6aefrpdeeinoWExMTDvtBgAAAAAAAADQEl6vV59tKNTg3snKTIlr7+10SlS2oI6YmBhlZGQEPdLS0pSTkyNJuuCCC2QymQKvt2zZovPOO0/p6elKTEzUMccco8WLFwddMycnR/fdd58uu+wyJSQkKCsrS08//XTQmscff1xDhgxRQkKCsrOzdcMNN6iioqItvmUAAAAAAAAA6LS+zS3WNS9/o1vf/b69t9JpEbYgZKtXr5YkvfTSS9qzZ0/gdUVFhc4880wtWbJE3333nU4//XSdc845ys3NDTr/kUce0dChQ/Xdd9/pT3/6k2bMmKFPP/008L7ZbNZTTz2ln376SS+//LI+++wz3XrrrW33DQIAAAAAAABAJ5RfapckbSnkf25vLbQRQx0LFixQYmJi0LE77rhDd9xxhyQpNTVVGRkZgfeGDh2qoUOHBl7fd999ev/99/Xhhx9q+vTpgePjxo3Tn/70J0nSwIEDtWzZMj3xxBM67bTTJEk33XRTYG1OTo7uv/9+XX/99frHP/4R8e8RAAAAAAAAALqKaqdbklRYbpfH45XZbGrnHXU+Hbay5emnn1ZOTo5iY2M1ZswYrVq1qtH1JSUluvHGG5WZmamYmBgNHDhQH330URvttnM5+eSTtXbt2qDH9ddf3+D6iooK3XzzzTriiCOUmpqqxMRErV+/vk5ly9ixY+u8Xr9+feD14sWLdeqppyorK0tJSUmaNGmS9u/fr6qqqsh+gwAAAAAAAADQhdh8YYvL49W+Sns776Zz6pCVLW+99ZZmzpypuXPnasyYMZozZ44mTJigjRs3qlevXnXWOxwOnXbaaerVq5feffddZWVlaceOHUpNTW37zXcCCQkJGjBgQMjrb775Zn366ad69NFHNWDAAMXFxemiiy6Sw+EI+Rrbt2/X2Wefrd/97nd64IEH1K1bN3311Ve65ppr5HA4FB8fH863AgAAAAAAAABdnj9skaT8Upt6JcW24246pw4Ztjz++OOaNm2apk6dKkmaO3euFi5cqBdffDHQhqq2F198UUVFRVq+fLmio6MlKTC8HZEVHR0tt9sddGzZsmW66qqrdMEFF0gyKl22b99e59wVK1bUeX3EEUdIktasWSOPx6PHHntMZrNRcPX222+3wncAAAAAAAAAAF3LgWHL0X3acTOdVIdrI+ZwOLRmzRqNHz8+cMxsNmv8+PH6+uuv6z3nww8/1NixY3XjjTcqPT1dRx11lB588ME6oUBtdrtdZWVlQQ8Y7Ha78vPzgx779u2TZIRYS5YsUX5+voqLiyVJhx12mP79739r7dq1WrdunS6//HJ5PJ461122bJn++te/atOmTXr66af1zjvvaMaMGZKkAQMGyOl06m9/+5u2bt2qV199VXPnzm27bxoAAAAAAAAAOimbs+bz2oIyWzvupPPqcGHLvn375Ha7lZ6eHnQ8PT1d+fn59Z6zdetWvfvuu3K73froo49055136rHHHtP999/f4H1mz56tlJSUwCM7Ozui38fBbNGiRcrMzAx6HHfccZKkxx57TJ9++qmys7M1fPhwSUYlUlpamo499lidc845mjBhgkaMGFHnuv/3f/+nb775RsOHD9f999+vxx9/XBMmTJAkDR06VI8//rgefvhhHXXUUXr99dc1e/bstvumAQAAAAAAAKCTqq5d2ULY0ipMXq/X296bqG337t3KysrS8uXLgwaq33rrrfriiy+0cuXKOucMHDhQNptN27Ztk8VikWQEAI888oj27NlT733sdrvs9ppBQGVlZcrOzlZpaamSk5OD1vqvfcghhyg2ll524cjJydFNN92km266qb230iHxNwYAAAAAAACgtfz5/R/0+spcSdJvRmTp8UuGte+GDhJlZWVKSUmpNzc4UIeb2dKjRw9ZLBYVFBQEHS8oKFBGRka952RmZio6OjoQtEjSEUccofz8fDkcDlmt1jrnxMTEKCYmJrKbBwAAAAAAAACgg6GNWOvrcG3ErFarRo4cqSVLlgSOeTweLVmyJKjSpbZx48Zp8+bNQXNCNm3apMzMzHqDFgAAAAAAAAAAugpb7TZipYQtraHDhS2SNHPmTD333HN6+eWXtX79ev3ud79TZWWlpk6dKkmaPHmybr/99sD63/3udyoqKtKMGTO0adMmLVy4UA8++KBuvPHG9voWcIDt27fTQgwAAAAAAAAA2kHtsKWgzN7ISoSrw7URk6SJEydq7969uuuuu5Sfn69hw4Zp0aJFSk9PlyTl5ubKbK7JibKzs/XJJ5/oj3/8o44++mhlZWVpxowZuu2229rrWwAAAAAAAAAAoEOwuWrClgq7S+U2p5Jio9txR51PhwxbJGn69OmaPn16ve8tXbq0zrGxY8dqxYoVrbwrAAAAAAAAAAAOLtUOd9DrgjIbYUuEdcg2YgAAAAAAAAAAIDJsTk/Q6/xSWolFGmELAAAAAAAAAACdmH9mS1y0RZK0p7S6PbfTKRG2AAAAAAAAAADQifnDln7d4yUZbcQQWYQt6DJycnI0Z86c9t4GAAAAAAAAALQpm8toI5bTPUGSlE/YEnGELZ3cVVddJZPJVOdx+umnh3T+0qVLZTKZVFJS0robbQOrV6/WddddF9FrnnTSSbrpppsiek0AAAAAAAAAiKRqh6+ypYdR2cLMlsiLau8NoPWdfvrpeumll4KOxcTERPQeDodDVqs1oteMtJ49e7b3FgAAAAAAAACgTXm9XtlcRthySKCyhZktkUZlSxcQExOjjIyMoEdaWpokyWQy6fnnn9cFF1yg+Ph4HXbYYfrwww8lSdu3b9fJJ58sSUpLS5PJZNJVV10lyajomD59um666Sb16NFDEyZMkCT9+OOPOuOMM5SYmKj09HRNmjRJ+/btC+zlpJNO0h/+8Afdeuut6tatmzIyMnT33XcH7ffxxx/XkCFDlJCQoOzsbN1www2qqKgIvD9v3jylpqZqwYIFOvzwwxUfH6+LLrpIVVVVevnll5WTk6O0tDT94Q9/kNvtDpx3YBuxkpISXXvtterZs6eSk5N1yimnaN26dYH37777bg0bNkyvvvqqcnJylJKSoksvvVTl5eWSjKqhL774Qk8++WSgYmj79u2SpC+++EKjR49WTEyMMjMz9ac//Ukul6sFv0UAAAAAAAAAaD6H2yOv13ie08MXtlDZEnGELWHyer2qcrja5eH1/8uIkHvuuUeXXHKJvv/+e5155pm64oorVFRUpOzsbL333nuSpI0bN2rPnj168sknA+e9/PLLslqtWrZsmebOnauSkhKdcsopGj58uL755hstWrRIBQUFuuSSS4Lu9/LLLyshIUErV67UX//6V91777369NNPA++bzWY99dRT+umnn/Tyyy/rs88+06233hp0jaqqKj311FN68803tWjRIi1dulQXXHCBPvroI3300Ud69dVX9c9//lPvvvtug9/3xRdfrMLCQn388cdas2aNRowYoVNPPVVFRUWBNVu2bNEHH3ygBQsWaMGCBfriiy/00EMPSZKefPJJjR07VtOmTdOePXu0Z88eZWdna9euXTrzzDN1zDHHaN26dXrmmWf0wgsv6P777w//lwQAAAAAAAC0ok0F5Xr0k40qsznbeyuIMJvDE3h+iC9s2V9pl9PtaegUhIE2YmGqdro1+K5P2uXeP987QfHW0H91CxYsUGJiYtCxO+64Q3fccYcko0LjsssukyQ9+OCDeuqpp7Rq1Sqdfvrp6tatmySpV69eSk1NDbrGYYcdpr/+9a+B1/fff7+GDx+uBx98MHDsxRdfVHZ2tjZt2qSBAwdKko4++mjNmjUrcI2///3vWrJkiU477TRJCpqBkpOTo/vvv1/XX3+9/vGPfwSOO51OPfPMM+rfv78k6aKLLtKrr76qgoICJSYmavDgwTr55JP1+eefa+LEiXV+Jl999ZVWrVqlwsLCQEu1Rx99VB988IHefffdwGwXj8ejefPmKSkpSZI0adIkLVmyRA888IBSUlJktVoVHx+vjIyMwLX/8Y9/KDs7W3//+99lMpk0aNAg7d69W7fddpvuuusumc1knAAAAAAAAOhY/v7ZZn24brf6dovXJcdkt/d2EEH+FmIWs0k9E2MUbTHJ6faqsNyurNS4dt5d50HY0gWcfPLJeuaZZ4KO+UMUyQg//BISEpScnKzCwsImrzty5Mig1+vWrdPnn39eJ9iRjAqR2mFLbZmZmUH3W7x4sWbPnq0NGzaorKxMLpdLNptNVVVVio83BjjFx8cHghZJSk9PV05OTtC909PTG/w+1q1bp4qKCnXv3j3oeHV1tbZs2RJ4nZOTEwha6ttrfdavX6+xY8fKZDIFjo0bN04VFRXauXOn+vbt2+j5AAAAAAAAQFsr91W0lFZT2dLZVDuMsCUu2iKz2aT05FjtLK5Wfmk1YUsEEbaEKS7aop/vndBu926OhIQEDRgwoMH3o6Ojg16bTCZ5PE2XkCUkJAS9rqio0DnnnKOHH364ztrMzMyQ7rd9+3adffbZ+t3vfqcHHnhA3bp101dffaVrrrlGDocjELbUd43mfB8VFRXKzMzU0qVL67xXu4In3J8NAAAAAAAAcDCxuzy+r+4mVuJg469siY02Ou5kBMIW5rZEEmFLmEwmU7NaeR2srFarJAUNmm/IiBEj9N577yknJ0dRUeH9bNasWSOPx6PHHnss0G7r7bffDutajRkxYoTy8/MVFRWlnJycsK9jtVrr/GyOOOIIvffee/J6vYHqlmXLlikpKUl9+vRpybYBAAAAAACAVuHwhS02J/+jcWfj/53GRBn/E396SqwkKb/M1m576owYHtEF2O125efnBz327dsX0rn9+vWTyWTSggULtHfvXlVUVDS49sYbb1RRUZEuu+wyrV69Wlu2bNEnn3yiqVOnhhTWSNKAAQPkdDr1t7/9TVu3btWrr76quXPnhnRuc4wfP15jx47V+eefr//+97/avn27li9frj//+c/65ptvQr5OTk6OVq5cqe3bt2vfvn3yeDy64YYblJeXp9///vfasGGD5s+fr1mzZmnmzJnMawEAAAAAAECHZA+ELVS2dDaBNmJWI2zJTDbClgLClojik98uYNGiRcrMzAx6HHfccSGdm5WVpXvuuUd/+tOflJ6erunTpze4tnfv3lq2bJncbrd+/etfa8iQIbrpppuUmpoacsgwdOhQPf7443r44Yd11FFH6fXXX9fs2bNDOrc5TCaTPvroI51wwgmaOnWqBg4cqEsvvVQ7duxQenp6yNe5+eabZbFYNHjwYPXs2VO5ubnKysrSRx99pFWrVmno0KG6/vrrdc011+gvf/lLxL8PAAAAAAAAIBIcgTZiVLZ0NnXaiPkqW/aUErZEksnr9XrbexMdQVlZmVJSUlRaWqrk5OSg92w2m7Zt26ZDDjlEsbGx7bRDdGb8jQEAAAAAAKA9nfTI59q+v0oXj+yjRy4e2t7bQQQt+nGPrn/tWx2Tk6Z3rj9W/1m3W79/4zuNzummt68f297b69Aayw0ORGULAAAAAAAAAHRxgTZiVLZ0OtVOf2WL0UYsg5ktrYKwBQAAAAAAAAC6uEAbMWa2dDo2p/G7jYnyhS3JNWELja8ih7AFAAAAAAAAALo4Kls6L5svQIuzGmFLui9scbg8Kq5yttu+OhvCFgAAAAAAAADo4vyVLTYqWzqdQBuxKCMOsEaZ1T3BKknKL6WVWKQQtgAAAAAAAABAF+bxeOVw+9qIUdnS6fjbiPlntkg11S0FzG2JGMIWAAAAAAAAAOjC/EGLxMyWzujANmKSlJlihC17qGyJGMIWAAAAAAAAAOjCalez0Eas87Ed0EZMktJ9YUs+lS0RQ9gCAAAAAAAAAF2Y3eWu9Zw2Yp2NP2yJqdVGLMPfRozKloghbMFBbfPmzXrwwQdVXV3d3lsBAAAAAAAADkoOKls6tWrfzJa42mELlS0RR9iCRp100km66aabAq9zcnI0Z86cRs8xmUz64IMPIraHhu5ps9l00UUXqXfv3oqLi4vY/QAAAAAAAICuJLiNGJUtnU2gjVg9lS35VLZETFR7bwCt55xzzpHT6dSiRYvqvPfll1/qhBNO0Lp163T00UeHfM3Vq1crISEhktsM+56///3vdf755+uqq65q0/0AAAAAAAAAnUntyha7yy2v1yuTydSOO0Ik+cOWOGtN7QWVLZFH2NKJXXPNNbrwwgu1c+dO9enTJ+i9l156SaNGjWpW0CJJPXv2jOQWW3TP5557ro13AgAAAAAAAHQ+tStbPF7J6fbKGkXY0lkEKluiaipb0n2VLaXVTtmc7qCqF4SHNmKd2Nlnn62ePXtq3rx5QccrKir0zjvv6Pzzz9dll12mrKwsxcfHa8iQIXrjjTcaveaBLb1++eUXnXDCCYqNjdXgwYP16aef1jnntttu08CBAxUfH69DDz1Ud955p5xOZ9Ca//znPzrmmGMUGxurHj166IILLmjwnrm5uTrvvPOUmJio5ORkXXLJJSooKAi8f/fdd2vYsGF69dVXlZOTo5SUFF166aUqLy8P4acGAAAAAAAAdC32A+a02FzMbelM/K3hagcqybFRircar2klFhmELeHyeiVHZfs8vN6QthgVFaXJkydr3rx58tY655133pHb7daVV16pkSNHauHChfrxxx913XXXadKkSVq1alVI1/d4PPrNb34jq9WqlStXau7cubrtttvqrEtKStK8efP0888/68knn9Rzzz2nJ554IvD+woULdcEFF+jMM8/Ud999pyVLlmj06NEN3vO8885TUVGRvvjiC3366afaunWrJk6cGLRuy5Yt+uCDD7RgwQItWLBAX3zxhR566KGQvi8AAAAAAACgK3G4g+e02JyELZ1JdT0zW0wmU2Buyx7CloigjVi4nFXSg73b59537Jasoc1Nufrqq/XII4/oiy++0EknnSTJaCF24YUXql+/frr55psDa3//+9/rk08+0dtvv91g2FHb4sWLtWHDBn3yySfq3dv4WTz44IM644wzgtb95S9/CTzPycnRzTffrDfffFO33nqrJOmBBx7QpZdeqnvuuSewbujQofXec8mSJfrhhx+0bds2ZWdnS5JeeeUVHXnkkVq9erWOOeYYSUYoM2/ePCUlJUmSJk2apCVLluiBBx5o8vsCAAAAAAAAuhK709PoaxzcAm3EooNrL9KTY7V1X6UKmNsSEVS2dHKDBg3SscceqxdffFGStHnzZn355Ze65ppr5Ha7dd9992nIkCHq1q2bEhMT9cknnyg3Nzeka69fv17Z2dmBoEWSxo4dW2fdW2+9pXHjxikjI0OJiYn6y1/+EnSPtWvX6tRTT23WPf1BiyQNHjxYqampWr9+feBYTk5OIGiRpMzMTBUWFoZ0DwAAAAAAAKArObCyxU4bsU6lvjZikpSRYlS25BO2RASVLeGKjjcqTNrr3s1wzTXX6Pe//72efvppvfTSS+rfv79OPPFEPfzww3ryySc1Z84cDRkyRAkJCbrpppvkcDgittWvv/5aV1xxhe655x5NmDBBKSkpevPNN/XYY48F1sTFxUXsfn7R0dFBr00mkzweEnkAAAAAAADgQAeGKzYqWzoVf2VLXENhC23EIoKwJVwmU8itvNrbJZdcohkzZuhf//qXXnnlFf3ud7+TyWTSsmXLdN555+nKK6+UZLTe2rRpkwYPHhzSdY844gjl5eVpz549yszMlCStWLEiaM3y5cvVr18//fnPfw4c27FjR9Cao48+WkuWLNHUqVNDvmdeXl6guuXnn39WSUlJyPsGAAAAAAAAUKNOGzEqWzoVWz0zWyQFZrYQtkQGbcS6gMTERE2cOFG333679uzZo6uuukqSdNhhh+nTTz/V8uXLtX79ev32t79VQUFByNcdP368Bg4cqClTpmjdunX68ssvg0IV/z1yc3P15ptvasuWLXrqqaf0/vvvB62ZNWuW3njjDc2aNUvr16/XDz/8oIcffrjBew4ZMkRXXHGFvv32W61atUqTJ0/WiSeeqFGjRjXvBwMAAAAAAACgThsxKls6D6fbI5fHK6luZUt6Mm3EIomwpYu45pprVFxcrAkTJgRmrPzlL3/RiBEjNGHCBJ100knKyMjQ+eefH/I1zWaz3n//fVVXV2v06NG69tpr6wygP/fcc/XHP/5R06dP17Bhw7R8+XLdeeedQWtOOukkvfPOO/rwww81bNgwnXLKKVq1alW99zSZTJo/f77S0tJ0wgknaPz48Tr00EP11ltvNe8HAgAAAAAAAEBS3coWfyUEDn61f5cx0cFxgL+NWAFhS0SYvF6vt7030RGUlZUpJSVFpaWlSk5ODnrPZrNp27ZtOuSQQxQbG9tOO0Rnxt8YAAAAAAAA2svTn2/WI59sDLz+xxUjdOaQzHbcESJlb7ldxzywWCaTtPXBM2UymQLvFZTZNObBJbKYTdp0/xmymE2NXKlraiw3OBCVLQAAAAAAAADQhdkPqGShsqXzCMxribIEBS2S1CMxRhazSW6PV/sq7O2xvU6FsAUAAAAAAAAAujC7i5ktnVUgbImuGwVYzCb1TIyRJOWX0kqspQhbAAAAAAAAAKALOzBssbuobOks/MFZbLSl3vf9c1vymdvSYoQtAAAAAAAAANCFUdnSeVX7KlviGgpbkn1hC5UtLUbY0gxer7e9t4BOir8tAAAAAAAAtBdHnbCFypbOwv+7jKGypdURtoQgOjpaklRVVdXOO0Fn5f/b8v+tAQAAAAAAAG3F3zbMYjb5XlPZ0lk0NrNFktJ9lS0FVLa0WFR7b+BgYLFYlJqaqsLCQklSfHy8TCZTO+8KnYHX61VVVZUKCwuVmpoqi6X+hBkAAAAAAABoLf7KluTYKBVXOals6USaaiOWSWVLxBC2hCgjI0OSAoELEEmpqamBvzEAAAAAAACgLfkrWVLiolVc5QxUuuDgZ/fN34ltIGxJZ2ZLxBC2hMhkMikzM1O9evWS0+ls7+2gE4mOjqaiBQAAAAAAAO3GH64kxxkt7v0f0OPgZ3M1XtlSe2aL1+ulo1MLELY0k8Vi4YNxAAAAAAAAAJ1GTRsxI2yxUdnSaVQ7jN9lTAMzWzJ8lS1VDrfK7a7A3wCar/6fMAAAAAAAAACgS6jdRkySbFS2dBq2JtqIxVktgd87rcRahrAFAAAAAAAAALqwQGVLnNEIyeaksqWzqHY23kZMqqluIWxpGcIWAAAAAAAAAOjC7Ae0EfO/xsHPH5zFNtBGTJLSa81tQfgIWwAAAAAAAACgC7P7ZrQkB9qIUdnSWfh/t7FRDVe2ZPoqWwqobGmRDh22PP3008rJyVFsbKzGjBmjVatWNbh23rx5MplMQY/Y2Ng23C0AAAAAAAAAHHxq2ogRtnQ21Q5fGzFrw2GLv7JlD5UtLdJhw5a33npLM2fO1KxZs/Ttt99q6NChmjBhggoLCxs8Jzk5WXv27Ak8duzY0YY7BgAAAAAAAICDT00bsaig1zj42ZzG7zImhJktVLa0TIcNWx5//HFNmzZNU6dO1eDBgzV37lzFx8frxRdfbPAck8mkjIyMwCM9Pb0NdwwAAAAAAAAAB5+6lS2ELZ2FzddGLK6xsCUlRhIzW1qqQ4YtDodDa9as0fjx4wPHzGazxo8fr6+//rrB8yoqKtSvXz9lZ2frvPPO008//dTgWrvdrrKysqAHAAAAAAAAAHQlbo9XLo9XkpTiC1vstBHrNPxtxGKjG44CMpLjJEkFhC0t0iHDln379sntdtepTElPT1d+fn695xx++OF68cUXNX/+fL322mvyeDw69thjtXPnznrXz549WykpKYFHdnZ2xL8PAAAAAAAAAOjIHLVahiXH+sIW2oh1Gjbf7zI2quHKlkN7JmjhH47TJzed0Fbb6pQ6ZNgSjrFjx2ry5MkaNmyYTjzxRP373/9Wz5499c9//rPe9bfffrtKS0sDj7y8vDbeMQAAAAAAAAC0L7urpoolOc6Y2eJwe+T2Vbvg4GbzVbbEWRsOW2KjLTqyd4q6J8a01bY6paj23kB9evToIYvFooKCgqDjBQUFysjICOka0dHRGj58uDZv3lzv+zExMYqJ4Y8HAAAAAAAAQNflr2KxmE1KsEbVOu5WvLVDfnyMZvDPbGmsjRgio0P+hK1Wq0aOHKklS5YEjnk8Hi1ZskRjx44N6Rput1s//PCDMjMzW2ubAAAAAAAAAHBQ87cRi4kyKyaq5uNiu5NWYp2BzTd/J6aRNmKIjA4bTc6cOVNTpkzRqFGjNHr0aM2ZM0eVlZWaOnWqJGny5MnKysrS7NmzJUn33nuvfvWrX2nAgAEqKSnRI488oh07dujaa69tz28DAAAAAAAAADosfxsxa5RZURazoswmuTzeQEUEDm7VIbQRQ2R02LBl4sSJ2rt3r+666y7l5+dr2LBhWrRokdLT0yVJubm5Mptrktbi4mJNmzZN+fn5SktL08iRI7V8+XINHjy4vb4FAAAAAAAAAOjQ7LUqWyRjfkeF3SUblS2dgs33+42NJmxpbR02bJGk6dOna/r06fW+t3Tp0qDXTzzxhJ544ok22BUAAAAAAAAAdA41YYvxYXxstFkV9pqKFxy8PB5voE1cbFSHnCjSqfATBgAAAAAAAIAuyj+bxer7MN4fulDZcvCr3QqONmKtj7AFAAAAAAAAALoohzu4jVhMtPHVP1gdB6/agVlsFGFLayNsAQAAAAAAAIAuyu4LVfyVLf4P5f3txXDwqq71uzWbTe28m86PsAUAAAAAAAAAuigqWzov/++QeS1tg58yAAAAAAAAAHRRNTNbjIqW2MDMFsKWg10gbImmhVhbIGwBAAAAAAAAgC7K3y7MX9kS66tssTtpI3aw84ctcVbClrZA2AIAAAAAAAAAXZTDZXwgXxO2+Ge2UNlysLP5AjN/tRJaF2ELAAAAAAAAAHRR/soWq39mS5R/ZguVLQe7mjZixABtgZ8yAAAAAAAAAHRRjkAbMd/MlmhmtnQW1cxsaVOELQAAAAAAAADQRdWd2WIJOo6DV6CNGGFLmyBsAQAAAAAAAIAuyuEODltq2ohR2XKw8/8O4whb2kRUSy+wc+dOff7559q9e7fsdnud900mk+68886W3gYAAAAAAAAAEGF23wfygbDF30bMRdhysGNmS9tqUdhyyy236Mknn5TbXfMPz+v1ymQyBT0nbAEAAAAAAACAjsffLswaaCNmfLU7aSN2sLMxs6VNhR1pPffcc3rsscd08skn691335XX69WUKVP0xhtv6Prrr1dUVJQuvvhiffbZZ5HcLwAAAAAAAAAgQhyBmS2WoK82ZrYc9KoJW9pU2JUtzz77rHJycvTxxx/LbDYym5ycHE2cOFETJ07UJZdcotNOO00XX3xxxDYLAAAAAAAAAIichipbmNly8LP5qpMIW9pG2JUtGzZs0Omnnx4IWiTJ5XIFnp944ok666yz9Oijj7ZshwAAAAAAAACAVmEPVLb4whZfZYudypaDHjNb2laLfsqpqamB5wkJCdq/f3/Q+4cffrh++umnltwCAAAAAAAAANBK7C7jA3l/ZUsMlS2dhr+NWByVLW0i7LAlKytLO3fuDLzu37+/Vq5cGbTmxx9/VEJCQvi7AwAAAAAAAAC0GvsBM1sClS2ELQc9O23E2lTYYcu4ceO0YsWKwOvzzjtP3333nX77299q4cKFuv322/Xxxx/rhBNOiMhGAQAAAAAAAACR5TiwjVg0bcQ6C9qIta2ocE+cNGmSdu/erR07dqhfv3665ZZbtGDBAj333HN6/vnn5fV6lZOTo0ceeSSS+wUAAAAAAAAARIg/VLEGwhbaiHUW1YGwhcqWthB22HLSSSfppJNOCrxOTEzUihUrNH/+fG3ZskX9+vXTOeecQxsxAAAAAAAAAOigHL6ZLf7KFn87MZuTypaOaH+FXc/+b6suOSZb/XsmNrrWRtjSpsIOW+oTHR2tiy66KJKXBAAAAAAAAAC0koYqW+wuKls6on9/u0v//N9WFVc59NeLhja6ttoXmMWFErYUrpe6HyZZIhoZdCk0awMAAAAAAACALqpmZovxgby/CoLKlo6psNwmSdpbbm9yrT3UypZ9m6UXJkivXSBVl7R0i11WyDHV1VdfHdYNTCaTXnjhhbDOBQAAAAAAAAC0Hn9lS0y0v42Yb2aLyy2v1yuTydRue0NdJVVO42u1s8m1NW3EGqm5sJVJb14m2Usll12KjovIPruikMOWefPm1XvcZDLJ6/U2eJywBQAAAAAAAAA6Jn+7MKvFF7b4qiC8Xsnh9gQqXtAxFPvDlqqmw5ZqX9jSYBsxj0f69zRp3yYpqbd0yatSVEzE9trVhBy2bNu2Lei1x+PRjBkztGLFCs2YMUPHH3+80tPTVVBQoP/973966qmnNHbsWD3xxBMR3zQAAAAAAAAAoGW8Xm9NG7Ho4JktklH1QtjSsZRUOYK+NsbfCq7BNmKfPyBtWiRFxUqXvi4lpUdsn11RyGFLv379gl4/9NBDWrlypdatW6fMzMzA8cMPP1wnnHCCpk6dquHDh+vdd9/VrbfeGrkdAwAAAAAAAABazOXxyuNrWhRjMT6Qt1rMMpmMyhab063k2Oh23CEO5G8fVlrtlMfjldlcf5s3r9crm69qKaa+NmI//lv68lHj+TlPSVkjWmW/XUkjzdoa98ILL+iSSy4JClpqy8rK0iWXXKLnnnsu7M0BAAAAAAAAAFqHv6pFqvlA3mQyBea22J2ees9D+/FXtHi8UrnN1eA6u8sj//SPOm3E9nwvzb/ReH7s76WhE1tjq11O2GHLzp07FRsb2+ia2NhY7dy5M9xbAAAAAAAAAABaib1W2OKf2SLVtJ3yz3NBx+D1eoNmtRQ30kqsdlAW1Eascp/05hWSs0rqf4o0/p5W2WtXFHbY0qdPH73//vuy2Wz1vl9VVaX3339fffr0CXtzAAAAAAAAAIDW4Q9Toi2moHZU/soWG5UtHUqF3SWXv++balqK1afaafxuo8wmRfuDNLdTenuKVJordTtUuuhFycxMnkgJO2y59tprtXXrVo0bN07z58/X/v37JUn79+/XBx98oOOOO07bt2/XtGnTIrZZAAAAAAAAAEBk+NuIxUQFf+Dur4SwOals6UhqV7VIjVe2+H93QVUti26XdnwlWROlS9+Q4tJaZZ9dVVS4J95yyy3atGmTXnrpJf3mN7+RJJnNZnk8xj9Qr9erqVOn6pZbbonMTgEAAAAAAAAAEeNvI2aNCv5/8mOjLEHvo2M4MFwpaSxscfnDFt/vNneltNo3X/03z0m9BrXKHruysMMWs9msF154QZMnT9bLL7+s77//XqWlpUpJSdHQoUM1adIknXTSSRHcKgAAAAAAAAAgUmoqW4LDlphofxsxKls6kgMrWw58XVu144DKlh3LjK9HnCsNOrNV9tfVhR22+J144ok68cQTI7EXAAAAAAAAAEAb8c9saaiyhZktHcuBlS3FjYQt/t9dIGzZ/Z3xNXt0q+wNLZjZAgAAAAAAAAA4eNmbqGzxhzHoGA6sZCltThux3WuNr5nDWmFnkJpR2ZKbmytJysrKksViCbwORd++fZu/MwAAAAAAAABAq6kJWyxBx/3VEFS2dCwHhi2NVrb42ojFRVukyn1Sqe/z/Myhrba/ri7ksCUnJ0cmk0nr16/XwIEDA6+bYjKZ5HK5WrRJAAAAAAAAAEBk2X1hyoFtxPyVLsxs6Vj8bcTSk2NUUGZXSXUjYYur1swWf1VL98Ok2OTW3maXFXLYMnnyZJlMJqWkpAS9BgAAAAAAAAAcfBzu+tuI+Stb/JUv6BhKfGFLTvcEI2xprI2Ys1bV0h7fvJbew1t9j11ZyGHLvHnzGn0NAAAAAAAAADh42H2VKwdWtvjnfFDZ0rH424Yd0iNBK7cV1WkrVlu1v42YtVZlS+9hrbzDrs3c9BIAAAAAAAAAQGfTUGWLf4aLvxUVOgZ/27CcHgmSatqK1SfQRizKLO2msqUtELYAAAAAAAAAQBdUM7PFEnTcX9nifx8dg79t2CG+sKXc5pLLXf/vyOarbOlpKpHKdkkySRlHt8U2u6yQ24idcsopYd3AZDJpyZIlYZ0LAAAAAAAAAGgd/pksdWa2RPlntlDZ0pEUV9bMbPErrXaqe2JMnbU23++2n+MX40DPw6WYxNbfZBcWctiydOnSeo+bTCZ5vd4Gj5tMprA3BwAAAAAAAABoHY4GwpaYwMwWKls6CrfHqzKbS5LUPdGqpNgoldtcKq5qIGzxzdvJrt5oHMgc1lZb7bJCbiPm8XiCHtXV1Tr77LM1cOBAvfrqq9q+fbuqq6u1fft2vfLKKxo4cKDOOeccVVVVteb+AQAAAAAAAABh8FeuWA+sbIn2zWxxUtnSUZT65rVIUmpctNLirb7j9c9tqfa1Ecus2mAcYF5Lqwt7ZsusWbP0ww8/aPXq1briiivUt29fxcTEqG/fvrryyiu1cuVKrVu3TrNmzYrkfgEAAAAAAAAAEVBT2XLAzJZAGzEqWzqKYt+8lqSYKEVZzEqNjzaOVzrrXe9vI5Zevt44QNjS6sIOW/71r3/pwgsvVGJi/X3ekpOTdeGFF+qNN94Ie3MAAAAAAAAAgNbhD1MOrGypaSNGZUtHUVJlhCqpCUbIkuqrbCmpbiBscbrVS8WKd+yVTGYpY0jbbLQLCzts2bt3r5zO+n+Rfi6XS4WFheHeAgAAAAAAAADQSvxtxOrMbImijVhHU+KrbPG3D0uNiw46fiCb062jzVuNFz0HSdb41t9kFxd22NK/f3+988472r9/f73v7927V2+//bYGDBgQ9uYAAAAAAAAAAK2jpo3YgTNbjNe0Ees4in2VLSm+kCUt3h+2NFzZMsS8zXhBC7E2EXbYctNNNyk/P18jRozQk08+qTVr1igvL09r1qzRnDlzNHLkSBUWFuqPf/xjJPcLAAAAAAAAAIgAe4NhC5UtHc2BlS0pvq/FDVS2VDvdGmLyVbYQtrSJqHBPvPbaa7Vnzx7dd999mjlzZtB7Xq9XFotFd999t66++uoWbxIAAAAAAAAAEFk1lS2WoOP+8MXmpLKlo/BXsPgrWgKVLQ3NbHG4NcRM2NKWwq5skaQ777xT69ev16xZs3TBBRfolFNO0QUXXKB77rlHGzZs0J133tmizT399NPKyclRbGysxowZo1WrVoV03ptvvimTyaTzzz+/RfcHAAAAAAAAgM7KX9libaCyhTZiHYe/gsVf0ZIa3/jMlmRHoXqayuQ1WaT0I9tmk11c2JUtr7zyitLT0zVhwgTdddddkdyTJOmtt97SzJkzNXfuXI0ZM0Zz5szRhAkTtHHjRvXq1avB87Zv366bb75Zxx9/fMT3BAAAAAAAAACdRcMzW3xhC23EOgx/BYu/oiXV30assv7KlkOdmyRJ9m6HKzY6rg12iLArW6655hotWrQoknsJ8vjjj2vatGmaOnWqBg8erLlz5yo+Pl4vvvhig+e43W5dccUVuueee3TooYe22t4AAAAAAAAA4GBndxlhyoGVLYE2Yi7Clo7iwJkt/q+lDbQRO8y9RZLkTB/aBruD1IKwJTMzUy6XK5J7CXA4HFqzZo3Gjx8fOGY2mzV+/Hh9/fXXDZ537733qlevXrrmmmuavIfdbldZWVnQAwAAAAAAAAC6CnsDM1v8lS1Ot1duj7fN94W6/BUsKf7Kljjja3EDbcSO8G6WJHkymNfSVsIOW84991x9+umnstvtkdyPJGnfvn1yu91KT08POp6enq78/Px6z/nqq6/0wgsv6LnnngvpHrNnz1ZKSkrgkZ2d3eJ9AwAAAAAAAMDBItBGLPrANmI1r+1Ut3QIpYE2YsGVLVUOd53fkdPl1lGmrZIkSxZhS1sJO2x54IEHlJCQoN/85jf66aefIrmnZisvL9ekSZP03HPPqUePHiGdc/vtt6u0tDTwyMvLa+VdAgAAAAAAAEDH4a9ssVoObCNWU+lic3radE+oX3GgjZhR0ZIUGyWzyXivtCq4lZh933Z1M1XI4bUoqvdRbbrPriwq3BOHDx8uu92utWvXatGiRYqNjVWvXr1kMpmC1plMJm3ZsqVZ1+7Ro4csFosKCgqCjhcUFCgjI6PO+i1btmj79u0655xzAsc8HuM/AlFRUdq4caP69+8fdE5MTIxiYmKatS8AAAAAAAAA6CzsDVS2WMwmRVtMcrq9VLZ0AHaXW1UO4/eQGmdUtJjNJqXERau4yqmSaqd6JccG1rt3fStJ2ujN1lGxcW2/4S4q7MoWj8cjq9Wqvn37qm/fvurVq5ckyev1Bj38oUdzWK1WjRw5UkuWLAm635IlSzR27Ng66wcNGqQffvhBa9euDTzOPfdcnXzyyVq7di0twgAAAAAAAADgAP4g5cDKFkmK9VW3UNnS/vyVK2aTUdGiyv2S16tUXyux4srguS2m3WslST+rf53iCLSesCtbtm/fHsFt1DVz5kxNmTJFo0aN0ujRozVnzhxVVlZq6tSpkqTJkycrKytLs2fPVmxsrI46KrgcKjU1VZLqHAcAAAAAAAAA1K5ssdR5LybarHK7ZHNS2dIaPvhulx74aL3mXjlSI/ulNbq22Be2pMZbZf7hben966ThVyo17jJJUkl1cBuxqIJ1kqSNlgGtsHM0JOywpbVNnDhRe/fu1V133aX8/HwNGzZMixYtUnp6uiQpNzdXZnPYhTkAAAAAAAAA0GV5vV45/GFLVN3PWf1zW/yBDCLr4x/3aG+5XZ9tKAghbDEqV9JjPdKndxkHv3tN1ya7dKPOVUlVrcoWr1fWQiNs2RpF2NKWIhK2/Pzzz9qwYYMqKys1adKkSFxSkjR9+nRNnz693veWLl3a6Lnz5s2L2D4AAAAAAAAAoDNxuGtCFGs9YUusb44LlS2tI7/UJknaVVzd5NoSX2XLFVooVeRLsSmSrVRnlb2p1RariqsG1Swu3qYoR5ns3ijtth7SKntH/VpUGrJ69WoNGzZMQ4YM0cUXX6yrrroq8N7//vc/xcfH68MPP2zpHgEAAAAAAAAAEeSoVbFSX2VLbLR/ZgthS2vY4wtbdpfYmlxbUuVQqsr1m6p3jANnPiqdcqck6a6oV5WR93HN4t3fSZLWe/vKYo2N7KbRqJDClueff77OsZ9++kmnnHKKtm3bpj/+8Y8644wzgt4//vjj1aNHD73zzjuR2SkAAAAAAAAAICJqtwezWuprI+avbKGNWKQ53R7trbBLknaVNF3ZUlzl1I1R8xXvrZLSh0hHXSQd/39al3mxzCavzt5yt7Ttf8bi3WslST94DlVcNGM42lJIP+3rrrtO9913X9CxWbNmSZLWrFmjRx99VMccc0zQ+yaTSWPHjtXq1asjtFUAAAAAAAAAQCT4K1usUWaZTKY67/srW+wuKlsirbDcLq/XeJ5fZpPL3Xig5SnZocmW/xovxt8tmc2SyaQfhtyuj9yjFeV1Sm9eIeX/EKhs+cF7SOB3iLYRUtjy6KOP6r777tP1118vr++v4IsvvtCFF16oAQMaHrLTt29f7dmzJzI7BQAAAAAAAABEhL+yJaaeqhapVthCZUvE5ZfWVLO4PV4VlNsbXf+r7f9UjMmlnSmjpAGnBo4nJ8Tpj84b9JN1iGQvk167sCZs8RxK2NLGQgpbZs6cqc8++0wLFizQnDlzJEnl5eXq1atXo+dVV1fL7Sb5BAAAAAAAAICOxF+xEtNAq6lAGzEqWyLOP6/Fb3djrcTyf9Twkk8kSd8PninVqkJKi4+WXVbdFXuH1OtIqaJAclTIZY7RL94sxRG2tKmQm7Ydd9xx+u6773TkkUdKkrKzs/XDDz80es63336r/v37t2yHAAAAAAAAAICI8rcRi4mq/wN5KltaT/4BYcuu4kbCliX3yCyvFrjHyJM5POit1DirJGmnzSpd+a6Uki1J2p94mFyKajBIQ+to1k+7Z8+e+vWvfy1JOvvss/Xf//5Xixcvrnft22+/rRUrVuj8889v8SYBAAAAAAAAAJFjrzWzpT6xvg/qbU4qWxrzn3W7dcPra1Rhd4V8zoGVLbsaqmzZ9qX0y3/lllmPui5RWrw16O3U+GhJUkmVU0ruLV35b2ng6VqRNVWSaCPWxsKOtu644w717t1bZ555pqZNm6ZvvvlGkvSPf/xDkyZN0uWXX66cnBzNnDkzYpsFAAAAAAAAALRcTWVLQ23EjA/qaSPWuCc+3aSPfsjX0o2FIZ/jr2xJjo2S1EDY4vVKi2dJkt43n6bt3kylxEUHLfGHLXaXR9UOt9RzoHT5W1qffJwk0UasjUWFe2LPnj31xRdfaNKkSXrhhRcCx6dPny5JGjNmjN544w2lpKS0fJcAAAAAAAAAgIjxz2xpqLLF34KKNmINq3K4tG1/pSQpr6iRVmAH2FNqrB3RL01LN+6tf2bL+g+lXWvkjY7X41UXSJLSEoIrWxJjohRlNsnl8aq4yqE4a5ykmmqkWNqItamwwxZJOvTQQ7Vs2TKtXbtWK1asUFFRkZKTkzVmzBgdc8wxkdojAAAAAAAAACCC/CFKQ5UtsVS2NGlDfrm8XuP5zuKqkM/zV7aM7GuELXVmtrhd0pJ7JUnO0Tdo95JkSVJafHBli8lkUmp8tPZVOFRS5VTv1OCwhcqWttWisMVv2LBhGjZsWCQuBQAAAAAAAABoZQ63P2yp/wP5mMDMFipbGrJ+T1ngeV5jQ+5rcXu8Kii3S5JG5qRJknaXVMvr9cpkMhmLvp0n7d8sxXfX3iHXSUu+kdVirjc8SY23+sIWR+BYTWULYUtbikjYsn//fq1bt06lpaVKSUnR0KFD1b1790hcGgAAAAAAAAAQYf7KlobaiPkrW+wuwpaG/Ly7JmwJtbJlf4Vdbo9XFrNJQ/ukSpIqHW6VVjuVGm+VygsCVS068TYVu2MlGfNZAmFMLf5ql5JqZ+CYPyCLIWxpUy0KW7Zv364ZM2Zo4cKF8vrrpWSUL5199tmaM2eOcnJyWrpHAAAAAAAAAEAE2d1NtBHzfVDvr5JAXbUrW3YWV8vj8cpsrhuI1LbH10KsV1KMEmKi1CPRqEzZVVJthC2f3CHZSqXMYdIx16pkS7EkKS3eWu/1UuKM48W1KluqaSPWLsIOW7Zs2aJx48apsLBQhx12mMaNG6f09HQVFBRo+fLl+vDDD7VixQotX75chx56aCT3DAAAAAAAAABoAbvvA/mGKlv8IQxhS/08Hq825JcHXjtcHu2tsCs9ObbR8/xhS0aKsa53apwRthRX68iq1dKP70oms3TOHMlsCYQoKQfMa/ELVLZU1a5s8bcRq/93i9YRdthy2223ae/evZo7d66mTZsWVMLk9Xr17LPP6oYbbtBtt92md955JyKbBQAAAAAAAAC0nL89WFOVLbQRq19uUZWqHG7FRJmVFm9VfplNO4urmgxb8kuN2S6ZvrAlKzVO3+8sVcH+IunbmcaiMddLvYdLqmkPltZA2JIaCFvqmdnSwDwetI6wo60lS5bo3HPP1XXXXVenV5zJZNJvf/tbnX322Vq8eHGLNwkAAAAAAAAAiByHq4mZLb6qCDuVLfX62ddC7PCMJPXrHi9JyiuqbvK8PWVGZYs/lOmdGidJOnT9M1LJDik5Szr5jsD6kkojRGmojViq73hwZYvxu42zEra0pbDDFrfbrSOPPLLRNUcddZTcbv4xAgAAAAAAAEBHUlPZUv8H8jUzW6hsqY9/XssRGcnK7maELTuLq5o8L9/XRqx2Zcvhplz9as/rxoIzH5FikgLri30hSkNtxPyVLcW1wxYXbcTaQ9htxEaMGKGffvqp0TU//fSTRo0aFe4tAAAAAAAAAACtwNFEGzH/cbuL/5m+Pv6wZXDv5EBVSUiVLYGZLUZFS++UGD0Y/YIsckuDzpYGnRW03t8erKHKlrRAZUtNG7Fqhz9sobKlLYUdbT3wwAP6+OOP9fzzz9f7/rPPPqtPPvlE999/f9ibAwAAAAAAAABEnj9EabiNGJUtjfl5t6+yJTNZfdKM4CQvjMqWIQXva6T5F1UqVjrj4Trrm5zZEhcdtE6qNbOFsKVNhV3ZsmTJEp188sn67W9/q8cee0zjxo1Tenq6CgoKtGzZMm3atEkTJkzQ4sWLg+a2mEwm3XnnnRHZPAAAAAAAAACg+RxNthEzQhgblS11lFQ5tNsXmgzKrGn5tbO48coWr9cbCFsykmOl8gJlrn5IkvSo82LdFp+p2APOKfZVrKTENTWzpaayxeb73RK2tK2ww5a777478Hzjxo3auHFjnTWLFi3SokWLgo4RtgAAAAAAAABA+/LPbGmossUfwvirJFBj/Z5ySVJ2tzglx0YHKlt2l1TL7fHKYjbVe15RpUMOt/FzT0+OlT6YLrO9TD96D9XL7gmaUmpTTo+EoHP8LcoarGzxHS+pcsrr9crjrQnS4ghb2lTYYcvnn38eyX0AAAAAAAAAANqIv41YgzNbov0zWzzyer0ymeoPELqin33zWo7ISJZkBCfRFpOcbq/yy2zKSo2r9zz/vJYeiTGybv9M+vE9yWTW3+NvlMdu1q6S6nrCFt/MloTGZ7a4PF5V2F1BQY+/OgltI+yw5cQTT4zkPgAAAAAAAAAAbaSmjVjjM1u8Xsnh9jTYbqwrWr+nZl6LJFnMJvVOjdOO/VXKK6pqMGwJzGtJjpGW/Nk4OPq3qtpztFS0V7tKgtuQeTxelfpmsfhnsxwozmpRTJRZdpdHJVVOxVtrfk+x/M7aFNEWAAAAAAAAAHQxTbcRqzluc3raZE8HiwPDFknKTouXJOUVVTV43p4yI2w5xfqTtGedFB0vnXCLslKNSS27Dpj5UmZzyuM1nvtns9SndisxW63fq7mBdmZoHYQtAAAAAAAAANDF1FS21F/9YLWY5e8c5m85Bsnp9uiXggpJ0pG9a4Ut3Yxqlp0HBCa15Zca751X8ZZxYMQUKaF7oBJm9wGVLf55LQlWS4OhmFTTSqyk2hGYsRPbyHq0Dn7iAAAAAAAAANDF2JtoI2YymQJtqOxUtgRs2Vshh9ujpJgo9UmraRfWx1/ZUtxIZUupTcNMm3VoxbeSOUoae6MkqbcvbDmwjVixb15LY1UtkpTiazFWXOVUtcMXtkTTQqytEbYAAAAAAAAAQBfjr1ZpKGyRpBjfgHV/tQRqWogNykySyVTTpssfvDRW2VJQZtPvoj40Xhw9UUrNlqQmK1v8bcIaEqhsqXIEfq9xVsKWtkbYAgAAAAAAAABdjKOJmS1SzYB1fxUMpPV7yiUFz2uRaipbdjYys8VatEkTLN/IK5M0bkbgeO9A2GKTxz+kRUZbMKkmTGlI0MwWXxVSbAPt4dB6CFsAAAAAAAAAoIuxNzGzRZJiqWyp4+fdRmXL4APCFv/MlvwyWyDIqs3r9ercynclSVWHni71PDzwXkZKrMwmyeH2aF+lPXC8uNKobElporLF32asuMpR00aMypY2R9gCAAAAAAAAAF2MPxDwtwqrj3/uh42ZLZKMwMTfRuzAypaeiTGKiTLL45X2lNZtJVZeuF1n6ytJUtQJM4Pei7aYlZ4cK0naVasNWUmVv7KlqbDFeL+0yimbr41YbCMVS2gdLf6Jf/fdd7r11lt17rnnavz48YHjO3bs0Ntvv62ioqKW3gIAAAAAAAAAEEH+yharpZGZLb4P7P1zQLq6veV27a90yGySDs9ICnrPZDIF5rbkFdUNW9xfPqVok1srdZRickbXeT+rVisxv5Jqo7KlqTZi/jCmuMpR00YsmsqWthbVkpNvvfVWPfbYY/J6jT5ytQcCeb1eXX755Xrsscc0Y8aMhi4BAAAAAAAAAGhjoVS2xFDZEuQnX1XLoT0T6w0zsrvFa8veSu0sPmBuS+V+Ja//lyRpfuJEjann2r1T46QdxdpVUnNucZWvjVhc45UtKXFGGFNS7VS1r+VbHGFLmwu7suWll17So48+qrPPPlvff/+9br/99qD3c3JyNHr0aH344Yct3iQAAAAAAAAAIDI8Hq8c7qYrW2raiFHZIqnBFmJ+gcqWA8OWlXNlcdv0vecQ5Xf/Vb3nZqXVU9kSaCMWWmVLSZVTdt/vKraREA2tI+zKln/84x864ogj9N577ykqKkpWa91f+KBBg7R48eIWbRAAAAAAAAAAEDn+oEWqqV6pT00bMSpbJGn9nnJJ0hGZSfW+n50WL0naWWvuiuzl0qpnJUnPuM5Vhq9d2IF6+47vKqk9s8XXRiyh8cqWtARfZUuVQ9UOf9hCZUtbCzve+vnnn3XaaacpKqrhvCY9PV2FhYXh3gIAAAAAAAAAEGG1w5OYRgapU9kSrOnKFiNsySuqVdmyZp5kK9Fea7Y+8RyjjOTYes/NSjWO76oV1BT7Klv8bcIakuprM1Za7VSVk7ClvYQdtkRFRcnhcDS6Zvfu3UpMTAz3FgAAAAAAAACACPMPvDeZpCizqcF1sb4gxuYibLE53dq6t0KSdGQDYUt2N38bMV9g4rJLXz8tSZqfeLE8MisjpaGwxQhqdpfWU9kS38TMFt/7Hq+0t9wuibClPYQdtgwZMkSfffaZ3O76/6FVVVVp8eLFGjlyZNibAwAAAAAAAABElsNX2RITZZbJ1HDYEuOb+2F3dv42YjPe/E6nz/mfCsps9b6/Mb9cHq/UPcGqnkkx9a7xtxHbW26XzW6Xvpojle+RkjL1vmucJCmzgbClt6+ypaTKqUq7S063RxV2l6SmZ7bERFkUbzXClfxSY/9xhC1tLuyw5eqrr9amTZt0/fXXy263B71XVlamq666Svn5+Zo2bVqLNwkAAAAAAAAAiAx/GzGrpfGPh2OjfG3EOnllS3GlQ/PX7taG/HJd98o39bZNq91CrKGAKjU+WmlWt660fCrL06OkpQ8abxz7e+WWGddsKGxJio1WcqwxsmN3SXWgqsVkkpLjGq9skWoCmT2+ypjY6LA/+keYGh640oSrr75aixcv1gsvvKC33npLqampkqTRo0dr/fr1qqys1FVXXaWLLrooUnsFAAAAAAAAALSQv1IlponqB38rqs5e2bI2ryTwfN3OUt367vd68tJhQaHKz76wZXDv+luIyVYm0zcvaIlljrqZS6QySfHdpbE3qmLYtSqfv1iSlJES1+A+eqfGqSy/XDtLalqJJcdGy9JIqze/lLho7SqpDlS20Eas7bUo3vrXv/6lf/7znzrkkEO0a9cueb1effPNN+rbt6+eeeYZvfjii5HaJwAAAAAAAAAgAhzu0CpbYvwzW+qp9AjFlr0VGv/4F1r4/Z6wzm8r3+UWS5IGZyYrymzSh+t26x9LtwStqalsSQo+ubpYWnKv9MRR0uK71c1bop3eHlp1xJ+km36Ujv8/5ZcbVSpJMVFKjGm4/qFPmhHE7C6pVkl1aPNa/NISjHWVDuN3RRuxthd2ZYvftGnTNG3aNFVXV6u4uFjJyclKTEyMxN4AAAAAAAAAABFm94UnMU20mgpUtrjCq2z5708F2lxYocc/3agzh2Q0Oh+mPX3nq2y5fExfmUzSn9//UY98slH9eybq9KMy5PF4tX5PuSSjjViAxyO9dpG06xvjdY/D9X7Cxbpl40BdkzRQo63GDBf/HJiMBlqI+fVONcKWXcXV6plozIVJaWJei19qXPC6pn63iLyI/cTj4uLUu3dvghYAAAAAAAAA6MD8lS0xUU21EWtZZUuZzajO2LK3UpsKKsK6RmvzeLxam1siSRreN1VXjOmnKWP7SZJmvr1W6/eUaWdxtSrsLlktZvXvWevz7+/fNIIWa5I08TXphhXaP+BCuRSlncU1rcD2lIYWtmSl1qpsqWpeZUvqAetoI9b2iLcAAAAAAAAAoAvxz2CxRjXRRsz3gX24YUuprxWWJC38oWO2Etuyt0Lldpfioi06PN1oEXbn2YN13IAeqnK4de3L3+irzfskSYelJyra33rNXiEtvsd4fuIt0hHnSGazsrsZ1Sx5xVWBe+T7htZnhlrZUlKtkmqHpJrB9005cB1txNpeyGGL2WyWxWJp9iMqqsWdygAAAAAAAAAAEVJT2RLazJZw24jVDls+6qBhy3e+qpaj+6QoyhekRFnMevryETqkR4J2lVRr1oc/SjqghdiyJ6WKfCktRxpzfeBwdpoRttRf2RLX6F6yAjNbbCr2VbakxFHZcrAIOQk54YQT6vTUKy4u1vfffy+LxaLs7Gylp6eroKBAeXl5crvdOvroo5WWlhbxTQMAAAAAAAAAwmN3+Wa2NBG2xLawsqWsVtiyubBCmwrKNTA9qZEz2t53ecWSpOF9gz/HTomP1nOTR+mCfyxTuc0lqVbYUpInLX/KeH7afVJUTOC8Pt2MwKSo0qFKu0sJMVHK94UtTVW2+NuI5ZfZtK/cLin0ypbUA9bFMrOlzYUctixdujTo9c6dOzVu3DhdfvnlevDBB9W3b9/Ae7m5ubr99tu1bNkyLViwIGKbBQAAAAAAAAC0jL+NWOhhS3iVLf6wJcFqUaXDrYXf79HA0zpY2FJrXsuBBvRK1N8vH6GpL62Sxysd2dsXtiy+W3LZpH7HGe3DakmOjVZKXLRKq53KK67SoIzkkGe29EyMUbTFJKfbq00F5ZKktIQQK1sOqIChjVjbCzveuvnmm5WZmanXXnstKGiRpL59++r1119XRkaGbrnllhZvEgAAAAAAAAAQGTVtxBr/QL6mjVjLZracOyxLUsdrJVZhd2mjL9QYnp1a75oTB/bUPyeN0szTBmrMId2kvFXSj+9KMkkTHpAO6AYlSX187cB2FhmtxPLLQqtsMZtNyvS1Glufb+wr1DZiB4YytBFre2GHLYsXL9app57a6JpTTjlFixcvDvcWAAAAAAAAAIAI81e2WFu7ssXXfuvCEVmKtpj0S2GFfvGFGx3B93kl8nqN9l29khsOQk4bnK4/nHqYTF6vtOh24+DwK6Tew+pd75/bkldcJZvTraJKY9h9ZnLjM1ukmlZiDt+cnFDbiKXEHdhGjLClrYUdtthsNu3Z03gSuXv3blVXVze6BgAAAAAAAADQdmoqW5oKW8KvbPF6vYHKlqy0OB1/WE9J0sIOVN3yXV6JpPpbiNXrx/ekXd9I0QnSKXc2uCzbN7dlZ3G1CnxVLXHRFiXHNT3Vo3dqcCATatiSFn9gZQszW9pa2D/xkSNH6s0339TXX39d7/vLly/XW2+9pWOOOSbszQEAAAAAAAAAIsvuG3jfVGWLv82YPYzKliqHW26PV5LRCuvMIZmSOlYrse9yiyVJw/umNb3YUSUtnmU8P36mlJTR4NI+/sqWoqrAvJbMlFiZ6mk5dqCstOCwJTU+tDZiB7Ybo7Kl7YUdtjzwwANyu906/vjjdcEFF+ixxx7Tq6++qscee0znn3++TjjhBHm9Xt1///1hb+7pp59WTk6OYmNjNWbMGK1atarBtf/+9781atQopaamKiEhQcOGDdOrr74a9r0BAAAAAAAAoDOyu5pX2WILo7LFX9USZTYpLtqi0wanK9pi0qaCCm0ubP9WYl6vV9/llkgKsbJl+d+ksl1SSl9p7I2NLvVXtuQVVyvfF7ZkNDGvxS8rNXhdqGFLlMWspFijcibKbFK0hcqWttZ03VIDjjvuOH300Ue67rrrNH/+fM2fP18mk0ler5FWHnLIIXr22Wc1bty4sK7/1ltvaebMmZo7d67GjBmjOXPmaMKECdq4caN69epVZ323bt305z//WYMGDZLVatWCBQs0depU9erVSxMmTAj32wQAAAAAAACATsUftjQ5s8VX2eJ0e+X2eGUxN12Z4ecPW1LiomUymZQSF63jBvTQ5xv3auH3+ZoxPinM3UdGXlG19lc6ZLWYdWTv5MYXl+2Wls0xnp92txTd+OwVf2XLzuKaypbQw5b4wPMos0mJMaF/hJ8aH61ym4uqlnYSdtgiSaeeeqo2b96sr776SuvWrVNpaalSUlI0dOhQHXfccSGVRTXk8ccf17Rp0zR16lRJ0ty5c7Vw4UK9+OKL+tOf/lRn/UknnRT0esaMGXr55Zf11VdfEbYAAAAAAAAAgE9NZUvjH8rH1Jr7YXe5FW8N/ePkslphi9+ZQzL1+ca9+uiHPZox/rDmbDnivsszWogN7p3c+M/B65UW3S45q6TsMdKRv2ny2n18rcDKbS5tzC+TJGUkhxa29K5V2ZIaH92sz9jT4q3KK6pmXks7aVHYIkkmk0nHH3+8jj/++EjsR5LkcDi0Zs0a3X777YFjZrNZ48ePb3BGTG1er1efffaZNm7cqIcffrjeNXa7XXa7PfC6rKys5RsHAAAAAAAAgA7OEWobsVohhM3pUYiz2iXVVLYk1Qpbfj04Q3dYftDGgnJtLqzQgF6Jzdh1ZIXUQszrlRb9Sfr5A8lklk6fLYUQfsRbo9Q9war9lQ6t3m6EOpkhVrb0Tq2pmkltzg+81noqW9pHh4y49u3bJ7fbrfT09KDj6enpys/Pb/C80tJSJSYmymq16qyzztLf/vY3nXbaafWunT17tlJSUgKP7OzsiH4PAAAAAAAAANAR2X0zWJpqI2Y2m2T1zf6wOZs3t6W0nsqWlPhojRvQQ5L08Q97mnW9SPsu1whBhvdNa3jRknullXON5+c9LWWNDPn6fboZ7cB2lVRLkjJSGm895hcbbVGPRCM0SQtxXotfqu9nTdjSPjpk2BKupKQkrV27VqtXr9YDDzygmTNnaunSpfWuvf3221VaWhp45OXlte1mAQAAAAAAAKAdhNpGzFhjDjonVGU2l6TgsEUyWolJ0sJ2DFtsTrd+2m10OhqenVr/ov89In31uPH8rMekYZc36x7ZacHhSqiVLZKU5atuaW5liz+ciSNsaRctbiPWGnr06CGLxaKCgoKg4wUFBcrIyGjwPLPZrAEDBkiShg0bpvXr12v27Nl15rlIUkxMjGJiYiK6bwAAAAAAAADo6PxtxJqqbJGkmGiLyu2usCtbkmODP4L+9eB03WE2aUN+ubburdChPdu+ldhPu0vl8njVIzEmMF8lyPK/S5/dbzz/9QPSMdc2+x590uKDXmc0I2zpnRqndTtLA5UqoUoJtBHrVDUWB40O+VO3Wq0aOXKklixZEjjm8Xi0ZMkSjR07NuTreDyeoLksAAAAAAAAANDV+duINTWzRar54L65YUtZPW3EJKNaw99K7KN2qm6pPa+lzgD61S9I//2z8fzkP0vHTg/rHtndakIcq8Wsbs2oUjmkR4Kk5lXDSDWVLbQRax8dsrJFkmbOnKkpU6Zo1KhRGj16tObMmaPKykpNnTpVkjR58mRlZWVp9uzZkowZLKNGjVL//v1lt9v10Ucf6dVXX9UzzzzTnt8GAAAAAAAAAHQojkAbsVDCFuODe5uzmW3EGghbJOnMIRn6YtNeLfwhX9NPOaxZ142E2mFLkLX/khbONJ4f90fphFvCvkftypb0lBiZzaZGVge75rhD1C3BqguGZzXrnsOyU2UxmzS0T2qzzkNkdNiwZeLEidq7d6/uuusu5efna9iwYVq0aJHS09MlSbm5uTKba/5jUFlZqRtuuEE7d+5UXFycBg0apNdee00TJ05sr28BAAAAAAAAADoce3PaiAVmtoTZRqyesOXXgzN0x/s/av2eMm3bVxmo5AiJxy19+ZjUvb901IXN2pNcDql4m2zbV2msuUynqEL6/jvJUSGV7TKuK0ljrpdOnSUdWPXSDLVntmQm19OqrBHdE2N07fGHNvuew/um6ftZv1ZCTIf92L9T69A/9enTp2v69PrLtA4cfH///ffr/vvvb4NdAQAAAAAAAMDBq6aypel2U2FXttgarmxJS7Dq2P7d9eUv+/TgR+s1/ohe6pMWrz5pccpMiWs8BNqwQPr8AUkmKSpWGnRWaBsqyZXmnSWV5OoFSbJKWlrPuhFTpNMfalHQIhlzV/yaM6+lpQha2k+Lf/KrVq3S6tWrVVJSIre7brppMpl05513tvQ2AAAAAAAAAIAIaE5li39mS9iVLbH1D3k/Z2hvffnLPn36c4E+/bkgcNxkktKTYtUnLU4XjuyjS4/JDp6rsuo53xOv9N406ZpPpIwhjW+mqkh67UKpJFcuS5zyXQlyW+LVL7OnZE30PRKk3sOMqpYWBi2SEVKlJ8eooMze7NkrODiFHbYUFRXp/PPP17Jly+T1ehtcR9gCAAAAAAAAAB2HPzgJZWaLv/rF3szKltJGZrZI0m+GZ6na4damgnLtLK7WrpJq7Syuks3pUX6ZTfllNn2zo1jf7yzVvecdqWiLWSr4Wdr+pWSySH1GSXkrpX9dKl33uZTYq/6NOKulNy6T9m2SkrM099Bn9OiKCl0+pq8evKCJkKaFstPiVVBmb9PKFrSfsMOWmTNn6quvvtJJJ52kKVOmqE+fPoqKokQJAAAAAAAAADqymjZioVe22JpZ2VJW7ZLUcNgSZTFryrE5Qce8Xq/2Vzq0q7haX2zaqycWb9Ibq3K1bV+FnrlipNJW+6paBp0lnfuU9Px4af9m6c0rpCn/kaIPCDU8bunf06S8FVJMinTFu/rfB6WSpOHZqc36fsJx0cg+Kqpy6KTDGwiC0KmEnY4sWLBAo0eP1pIlS4LLuAAAAAAAAAAAHZa9OTNbovwzW0IPWxwuj6p965PjQv8I2mQyqUdijHokxmhodqqO7J2sP7zxnVZsLdKVT3+i/zjekFmSRl8nxaVJl70lPX+KtHOV9J8/SBf8s6YFmNcrLbpdWv8fyWKVLn1drh6D9P3OTyQZw+Rb26Wj++rS0X1b/T7oGJqOLhtQXV2tE044gaAFAAAAAAAAAA4igcqW6BDaiPlntjSjjViZzRl4ntTAzJZQnHpEuv59wzj1SYvT6NJPZHZVqzLlMCnnOGNBjwHSxS8bbcW+f0v66omak5c/Ja36p/H8grnSIcdrQ365bE6PkmOjdGiPhLD3BdQn7LBl2LBh2r59ewS3AgAAAAAAAABoTS63Ry6PMYPbagl9Zktz2oj557UkxUbJYm7Z/6x/eEaS5t8wVtNiP5Mkzd53vOYt314zR7z/ydIZDxvPl9xjVLJ8/4706V3GsV8/IB11oSTpu7wSSdKwvmkyt3BfwIHCbiM2a9YsnXvuuVqxYoV+9atfRXJPAAAAAAAAAIBW4HDXVKiEUtkSG+1vIxZ6ZYs/bEluQVVLbd0LlknuXao2J+jf7uNU9Z+fVVBu122nDzIWjJ4m7d0orX5O+vd1kttXWfOrG6Vjpweu811usaS2mdeCrifssCU/P19nnXWWTjzxRF1xxRUaMWKEkpOT6107efLksDcIAAAAAAAAAIgMfwsxKdTKFl8bsWZUtpT5wpaUuMiELVr5rCQp9phJmhE/TLM/3qBn/7dVU8bmKCMl1lhz+kPS/l+krUuN10deIP36/qDLrM0tkSQN75samX0BtYQdtlx11VUymUzyer2aN2+e5s2bV2d+i9frlclkImwBAAAAAAAAgA7A7gtbLGaTokIIW1pU2RIX9sfPNYq2Sr/8V5JkOmaaftujvxavL9Dq7cV6a3WeZow/zFhniZIunie9e40U310692+Sueb721xYoa37KmUyScOobEErCPuv/aWXXorkPgAAAAAAAAAArcxf2eKvWGlKrK/VmM3ZTpUtq1+Q5JX6nyr1GCBJumJMP1/YkqvppwyomQsTlyZN+ne9l5m3fJsk6dRB6UqNt7Z8X8ABwg5bpkyZEsl9AAAAAAAAAABamb8dmDXksMXiOy/0ypYym0tSBMIWR5X03avG89HXBQ6fflSG0v4Trd2lNi3dWKhTj0hv9DKlVU69t2aXJOnqcTkt2xPQgND+RQEAAAAAAAAADnr2Zla2+Nc1p7Il0EYstoVhyw/vSLZSKbWfdNhpgcOx0RZdOKKPJOn1lblNXuatb3JV7XTr8PQkje3fvWV7AhrQ4qZ527dv1+uvv661a9eqrKxMycnJGjZsmK644grl5OREYIsAAAAAAAAAgEjwhy3NrmxpxsyWiLQR83qlVc8Zz4+5VjJbgt6+bExfPf/VNi3dWKhdJdXKSo2r9zIut0cvL98hSZo6LqfO3HEgUloUtjz55JO69dZb5XK55PV6A8ffe+893XvvvfrrX/+qGTNmtHiTAAAAAAAAAICW84cmMVGWJlYa/DNb/O3HQuGvbEmJb0HYkrtCKvhBioqVhl9Z5+3+PRM19tDu+nrrfr21Klczf314vZdZvN4IY9Lio3X+8Kzw9wM0IaT48qqrrpLbHfyPacGCBfrjH/+olJQU3X///Vq+fLm2bdumr7/+Wg8++KBSUlI0c+ZMLVy4sFU2DgAAAAAAAABoHofbV9liCbWNmBHK2JpR2RKRNmKrnjW+DrlYiu9W75LLx/SVJL25Ok9Od/37e2nZNknSZaP7Bqp0gNYQUmXLW2+9pfz8fL377rtKTEyUJD3++OPq1q2bvv32W/Xp0yewtl+/fhozZoyuuOIKDR8+XI8//rjOOuus1tk9AAAAAAAAACBkdt/slZjoUNuI+Wa2NKOypcwWQhsxt1NaM08q2yXZyyVbmfHVXi7ZS6WCn411o6c1eIkJR2aoe4JVheV2LVlfqNOPygh6/6fdpVq5rUgWs0mTxvYLef9AOEL6F/Xll1/ql19+0fHHH689e/ZIkr799ltNnDgxKGipLTs7W5dcconWrFkTud0CAAAAAAAAAMLmr2yJCXFmS01lS/PbiCU3FrYsfUj66Gbpqyek1c9LP7wtbfpY2vGVlP+D5HVLh54kZQ5t8BLWKLMuHpUtSfrXqtw6789btl2SdMZRGcpMqX+mCxApIVW2jBo1SmvWrNGUKVP03HPP6a677pLD4VBCQkKj5yUmJsrhcERkowAAAAAAAACAlvHPbLE2e2ZLM9qIVfkrWxr4+HnPOiNkkaRhV0opWVJMkhSTXPM1NlnKGNLkvS4bna25X2zRl7/sVV5RlbK7xUuS9lfYNX/dbknS1HGHhLx3IFwhhS2SlJqaqvnz52v79u2SpIEDB+o///mPHnzwQUVF1b2My+XSggULNHDgwIhtFgAAAAAAAAAQPn9o0lqVLR6PV+V2l6QGKlvcTmn+jUblyuDzpPOfDum6DenXPUHHH9ZDX/6yT2+sytWtpw+SJP1rZa4cLo+G9knRiL6pLboHEIrQ/kXVkpOTI0maPHmyNm7cqAkTJtRpFfbNN9/ojDPO0MaNGzVlypSIbBQAAAAAAAAA0DIO3+wVa4hhi3+ovM3pkdfrbXJ9ud0l/7Lk2HrClmVzjDZhcWnSmY+GtIemXDGmryTp7W/y5HB55HB59OqKHZKMqhaTyRSR+wCNCbmy5UAzZszQ//73P3344YcaPXq04uPj1atXLxUWFqqqqkper1fnnXeeZsyYEcn9AgAAAAAAAADC1OzKluiadQ63J1Dp0pAy37yWmChzIKgJKNwgffFX4/npD0uJvULcdeNOPSJdPZNitLfcrk9/LpDL41FhuV29kmJ05pDMiNwDaEqzK1v8LBaLPvjgA82bN08nnXSSrFarcnNzZbVadfLJJ+vll1/W+++/L7M57FsAAAAAAAAAACLIEQhbQpzZUmudzdn03JbSav+8lgOqWjxuo32Y2yEdNkE6+pIQd9y0aItZE0dlS5L+tWqHXly2XZJ05a/6hVzBA7RU2JUtfpMnT9bkyZMjsRcAAAAAAAAAQCtqbmVLtMUks0nyeCW70y3VCVE80p61UvqRUlRMoLKlzryWlXOlXd9IMcnS2U9IEW7tdenobD29dLOWbd4vSbJazLpsdN+I3gNoDLEeAAAAAAAAAHQRdt/MllDDFpPJFGgH5g9qAlx26e1J0nMnS08Nl755UeVVlZIOqGzZv0Vacp/x/Nf3SSlZLfsm6tEnLV4nDewZeH3O0N7qmRQT8fsADSFsAQAAAAAAAIAuwt9GrDnttfzBjM3prnWhSulfE6UNC4zXZbukBX/UuI/P0MWWpUqL9V3f45E+/IPkqpYOOVEaMSUS30a9Lh/TL/B86ricVrsPUJ+Q24iZzWaZzWb9/PPPGjhwoMxms0whlHqZTCa5XK4WbRIAAAAAAAAA0HINthGzlUk7lkuHnihFxwW9ZVS2OGtmtthKjaAl92spOkG6eJ5UtFX68jElVu7SI9HPau/uhdK6WZK9TNrxlRQdL537VMTbh9V2yqBeumx0tronxOiorJRWuw9Qn5DDlhNOOEEmk0nx8fFBrwEAAAAAAAAAB4d6K1vcLum1C6Wdq6TkPtLJd0hDL5XMRvuwmjZibqlyv/Tab4w5LTEp0pXvStmjjeuMmKylr8/WkO0vqadzl/T+dTX3OHWWlJbTqt+bxWzS7N8c3ar3ABoSctiydOnSRl8DAAAAAAAAADq2msoWS83BZU8YQYskle2U5t8gLf+bNP5uaeCEQBWMuyxfWni1tHe9FN9dmvS+lDm05jrWeC1Jm6gbNw7V3IFrdHzhvyRbiZT9K2l0reAF6IRCDlsAAAAAAAAAAAe3Om3Edq+Vlj5kPD/nSaOd2JePGYHKGxOlfuM0RBeqXBYN+e+fpIpcKSlTmjxf6nl4neuXVjtVqThtPGyajr/8T9LmxVL/UyUz48PRuYUdtpSWlmrHjh0aMGBAoLVYbZWVldqyZYtycnKUnJzcok0CAAAAAAAAAFrO7jKG3FujzJLTJr3/W8njko441xhebzJJIyZJX82RVs6VdizTI1qmspg4xVdUS6n9jKCl2yH1Xr/M5pQkJcdFS7Ep0lEXttW3BrSrsOPEe++9V+PGjZPb7a73fbfbrXHjxumBBx4Ie3MAAAAAAAAAgMgJaiO25F5p7wYpoZd09pya4fVxadJp90i/XyMNv1IemZVsqlZZ4qHS1YsaDFoko7JFkpJjo1v7WwE6lLDDlkWLFum0005TUlJSve8nJydrwoQJ+uijj8LeHAAAAAAAAAAgchy+sCW9aJW04mnj4Hl/lxK6112c0kc672nd0+c53ee8Qv8d85KU3LvR65f5wpaUOMIWdC1hhy25ubk67LDDGl3Tv39/5ebmhnsLAAAAAAAAAEAE2V0eJalKR626zTgw8ipp4IRGzylO6K8X3GepzJTS5PVLq12SCFvQ9YQdtphMJtnt9kbX2O32BtuMAQAAAAAAAADalsPl1qzoVxRbtUdKy5F+3fQYiJgo42Nkm6vxz3q9Xm+gsiU5Luxx4cBBKeywZdCgQVq0aJG8Xm+973s8Hn388cc6/PDDw94cAAAAAAAAACByxtiX6yLL/+Q1maUL/inFJDZ5jr9KpajC0eg6u8sjh9sTdA7QVYQdtlx22WXatGmTrr76apWWlga9V1paqquvvlqbN2/WlVde2eJNAgAAAAAAAABawOuVSnJ1i+MZSdL+ob+T+v4qpFOzu8VLkvKKqxpdV+qrajGbpMQYKlvQtYT9Fz99+nS99957evnllzV//nwdc8wxysrK0q5du7R69WqVlJTohBNO0PTp0yO5XwAAAAAAAABAQyoKpZ/el8p2SWV7pPI9UtluqTxfclYqTdLPnn6yjrlZPUK8ZHa3OElSXlF1o+tKAy3EomUymVrwTQAHn7DDlujoaC1evFh/+ctf9Nxzz+nTTz8NvJecnKxbbrlF9957r6KjKRcDAAAAAAAAgFZnK5OePVkq29ngkq3e3prhvFEvxsSGfNm+/sqWoip5vd4GgxT/vBZaiKEralEtV2xsrB599FE9/PDD2rBhg0pLS5WamqrDDz9cFoslUnsEAAAAAAAAADRl8d1G0JKcJR1xrpScKSX19n3NlDcpQ+NnLZXHWzP0PhR90oywpdzuUkmVU2kJ1nrXBSpbYglb0PVEpHGexWLRkUceGYlLAQAAAAAAAACaa8dy6ZsXjOfnPyMdemKdJS63Rx6v8TwmKvT/WT422qJeSTEqLLcrr7iqwbClzEZlC7qu0ONLAAAAAAAAAEDH46yW5vtmZ4+YXG/QIkkOlyfwPCa6eR8N+1uJ5RZVNbimtIqwBV1Xi8KWxYsX68wzz1TPnj0VHR0ti8VS5xEVFZHiGQAAAAAAAABAfb54WCraIiVmSKfd1+Aye62wxWpp3kfD2YG5LdUNrimtdkmSkuP4TBhdT9h/9e+9954mTpwoj8ejfv36adCgQQQrAAAAAAAAANCW9qyTlj1lPD/rMSkutcGldpdbkhRtMclsrn/IfUOyQ6hs8bcRS6ayBV1Q2OnIvffeq7i4OM2fP1+nnHJKJPcEAAAAAAAAAGiK22W0D/O6pcHnS0ec3ehyfxux5la1SDVtxPIaayNWTRsxdF1hhy0bN27UpEmTCFoAAAAAAAAAIJIKfpK+fUXyuKVRV0vpg+tf9/XfpPzvpdhU6cxHmrysv41YTLSl2VvKTouTJOUVNx22JMcStqDrCTts6d69u+Lj4yO5FwAAAAAAAADomtwuaeNH0qpnpe1f1hxf/Zx02ATpuD9K/cbWHN+3Wfp8tvH89NlSYq8mb+GvbImJCqOypbvxWfCu4mq5PV5Z6mlDVkZlC7qwsMOWiy66SIsXL5bL5WJWCwAAAAAAAACEo3K/9O3L0uoXpLKdxjGTRRp0lmQyST9/KP3yifHIHiONmyENPF368PeS2y71P0UaellIt/LPbLGGEbakJ8XKajHL4fZoT2m1+qTV/R/xA5UthC3ogsJOSR588EF98803mjhxop544gn17ds3kvsCAAAAAAAAgM7L45E+vVNa9ZwRmkhSfHdpxBTpmGuklD7GsX2bpeVPSevekPJWSm9eLiVmSBX5UnSCdPYcI5QJgd0ZfmWL2WxSn7Q4bd1XqdyiqnrDlnKbSxKVLeiawg5bhgwZIqfTqRUrVuiDDz5QamqqUlJS6qwzmUzasmVLizYJAAAAAAAAAJ3K6uekr/9uPM8cKo3+rXTUhVJ0bPC6HgOkc5+STr5DWvGM9M2LRtAiSafeJaX1C/mWdrcRtoRT2SJJfbrFa+u+SuUVVUn9675fShsxdGFhhy0ej0dRUVFBFS1er7fOuvqOAQAAAAAAAECXte8X6dO7jOcTHpR+dUPT1SlJGdJp90jHz5S+e01y2aXR05p125rKFks4u1bfbnGSpLyi6jrvudweVdiNypbkWMZOoOsJ+69++/btEdxG/Z5++mk98sgjys/P19ChQ/W3v/1No0ePrnftc889p1deeUU//vijJGnkyJF68MEHG1wPAAAAAAAAAG3O7ZLe/63kskmHniyN+V3IbcAkSbEp0tgbw7q1w1/ZYgmvsqVvN6N1WG5RVZ33/C3EJGa2oGsK719VG3jrrbc0c+ZMzZo1S99++62GDh2qCRMmqLCwsN71S5cu1WWXXabPP/9cX3/9tbKzs/XrX/9au3btauOdAwAAAAAAAEADvnpC2rVGikmRzntaMrfdR7R2p1uSFBMd3j2zfXNa8orrhi3+FmIJVouiwwxzgINZh/2rf/zxxzVt2jRNnTpVgwcP1ty5cxUfH68XX3yx3vWvv/66brjhBg0bNkyDBg3S888/L4/HoyVLlrTxzgEAAAAAAACgHrvXSl88ZDw/8xEpJatNb293+duIhRm2+Cpb8uqpbPGHLVS1oKsKu43Y1VdfHdI6k8mkF154oVnXdjgcWrNmjW6//fbAMbPZrPHjx+vrr78O6RpVVVVyOp3q1q1bve/b7XbZ7fbA67KysmbtEQAAAAAAAABC5rRJ718veVzSEedKR1/S5ltw+MIWa5gzW/xhy74Kh6ocLsVbaz5eLrMZYUsKYQu6qLDDlnnz5jX6vslkktfrDSts2bdvn9xut9LT04OOp6ena8OGDSFd47bbblPv3r01fvz4et+fPXu27rnnnmbtCwAAAAAAAADC8vn90t71UkIv6ewnmjenJUJaWtmSEhetlLholVY7lVdUrcMzkgLvUdmCri7ssGXbtm31Hi8tLdW3336rBx54QMOHD9df//rXsDcXroceekhvvvmmli5dqtjY2HrX3H777Zo5c2bgdVlZmbKzs9tqiwAAAAAAAAC6iu3LpOV/N56f+5SU0KNdtlFT2RL+dInsbnEq3eVUblFVUNhSVu2SJCXHEragawo7bOnXr1+D7x199NE644wzNGTIEC1cuFA33nhjs67do0cPWSwWFRQUBB0vKChQRkZGo+c++uijeuihh7R48WIdffTRDa6LiYlRTExMs/YFAAAAAAAAoIsq3SmVF0jySl6P7+F7Lq8U101K6SPFJgefZy+XPvidsWb4ldLhZ7TD5n1bcbklhV/ZIkl9u8Xrx11ldea2+CtbaCOGrirssKUp6enpOuecc/T3v/+92WGL1WrVyJEjtWTJEp1//vmSFBh2P3369AbP++tf/6oHHnhAn3zyiUaNGtWS7QMAAAAAAACAYfnfpf/+RZK36bWxKVJKthG8pGRLxdukkh1SSl9pwuxW32pjHIE2YuHNbJFq5rbkNhC2JMe12kfOQIfWqn/5SUlJ2r59e1jnzpw5U1OmTNGoUaM0evRozZkzR5WVlZo6daokafLkycrKytLs2cZ/oB5++GHddddd+te//qWcnBzl5+dLkhITE5WYmBiR7wcAAAAAAABAF+L1Sksfkr54yHidnCWZLZLJLMlkfPXPXqncJ9lKJFup8Sj4sdaFTNIFz9Stemlj9ki0EUszwpadxcFhS5mNyhZ0ba0WtpSUlGj+/Pl1htyHauLEidq7d6/uuusu5efna9iwYVq0aFHgerm5uTKba/6j8Mwzz8jhcOiiiy4Kus6sWbN09913h/19AAAAAAAAAOiCvF7pkz9LK542Xp9yp3T8/zU+2N5eLpXukkrzfI+dxuuc44xHO4tUGzGp4coWwhZ0VWGHLffee2+9x10ul3bt2qUPP/xQRUVFLQo6pk+f3mDbsKVLlwa9DreCBgAAAAAAAACCeNzSgpukb18xXp/xV2nMb5s+LyZJ6jXIeHRANW3EWlDZ4gtb8oqq5fV6ZfKFT2X+NmKxhC3omsIOW5oKUZKSknT77bfrzjvvDPcWAAAAAAAAANC2XA7p/d9KP/3baBN27t+l4Ve0964iwh6BsCUrNU4mk1TtdGtfhUM9k2Ik1YQtVLagqwo7bPn888/rPW42m5WWlqbDDz9c0dH8wwIAAAAAAABwkHBWS29PkX75RDJHSxc+Lx15fnvvKmIcEZjZYo0yq3dKnHaVVCu3qCoQtgTaiMXzmTC6pmaFLWVlZYqNjZXVatWJJ57YWnsCAAAAAAAAgObzeKQf3pZ+el9KypDSj5LSj5R6DZbiUuuu93qlqiKpaItUtNVoG7ZjmRQVK018TTrstDb/FiLB5nRrf6VD+8rt2l9p174Kh/ZXOLSpsFySFBNladH1+6QZYcvO4iqN7JcmqSZsoY0YuqpmhS1paWm6++67g1qDrVy5UitXrtQf/vCHiG8OAAAAAAAAAEKy42vpk9ul3d/V/35yHyN46T5AqiyU9m8xQhZbafA6a5J0+VtSzrjW33MruH/Bz3r+q22NrumeaG3RPfp2i9fKbUXK3V8lSfJ6vSqzuSTRRgxdV7PCFq/XK6/XG3Rs0aJFuvfeewlbAAAAAAAAALS94u3Sp7Oknz8wXluTpF/9TvK6pYKfjEdpnlS203j88kndayRnSd0ONYKY0dOMUOYgNX/dbklStMWkHokx6p5oNb4mxKhHklUDeibq2P49WnSP7G7xkqTcIiNsqXS45fYYnxsnx4U9uQI4qPGXDwAAAAAAAODgYyuTvnxMWvEPye0whtmPmCyd/GcpsVfw2uoSqXC9VPCj0S4ssZfUrb/Uvb+UdohkjW+XbyHSbE639pbbJUkr7xivbgktq2BpSF9f2JJXbIQtZb4WYtEWk+KiW9aiDDhYEbYAAAAAAAAA6PhcDmnvemn3WmnPWmn9f6TKvcZ7h5woTXhQyjiq/nPjUqV+Y41HJ7arpFqSlGC1KK0VB9Vnd4uTJOUVGffzz2tJiYuWyWRqtfsCHRlhCwAAAAAAAICOx14u/fhvYwbLnrVGOzC3I3hN9wHSr++XBp4u8SG/dhYb4UeftPhWDT38bcT2lFbL4fIEwpbkWOa1oOsibAEAAAAAAADQsTiqpJfOkPJ/CD4emyJlDpN6D5OyRkoDz5CiWqdV1sFop6+tV5+0uFa9T8/EGMVGm2VzerS7pDrQRiw5jrAFXVezw5bXXntNK1asCLzevHmzJOnMM8+sd73JZNLChQvD3B4AAAAAAACALsXrlRb80Qha4rpJIybVBCxph1DB0oiaypbWDVtMJpOy0+L1S2GFcouqgtqIAV1Vs8OWzZs3BwKW2hYtWlTvenr0AQAAAAAAAAjZ6uel7980Bt5f8rJ0yAntvaODRu02Yq2tbzcjbMkrrlK1wy2JyhZ0bc0KW7Zt29Za+wAAAAAAAADQ1eWulBb9yXg+/h6ClmZqqzZiUs3cltyiKsVEWSRJKXFMrUDX1ay//n79+rXWPgAAAAAAAAB0ZeUF0tuTJY9LGny+dOzv23tHB522rGzxhy07i6rVMylGkpQcS2ULui6iRgAAAAAAAADty+2U3rlKqsiXeg6Szvs7s1mayeZ0a2+5XVIbVbb47mFUtpglMbMFXZu5vTcAAAAAAAAAoIv79C4pd7lkTZImvibFJLX3jg46u0qMqpYEq0Wp8a0fevTtXtNGrLTaKYmwBV0bYQsAAAAAAACA9vPDu9KKfxjPL5gr9TisffdzkKrdQszUBlVB2b5WZaXVzsC9kwlb0IXRRgwAAAAAAABAw+zl0s5vpLxVUvluyVktOaskR1XNc2e1FB0rdT9M6nm4EZj0OFzq3l+Kigm+nsshVe2XqvZJRdukD32zWY6bKR1xdqt+K0WVDs1ZvElTxx2iQ3oktOq92trO4ipJbdNCTJISYqLUPcGq/ZUObd5bIYnKFnRthC0AAAAAAAAAapTulHJXSHkrja8FP0peT2jn7lkX/NpkltJypPjuRsBSuV+yl9Y979CTpVP+0uKtN+WFr7bqla93qMLu0uOXDGv1+7WlXb7qkqw2ClskKbtbvPZXOuT2eCURtqBrI2wBAAAAAAAAujqXQ/r+TWn536R9m+q+n5ItZY+RegyUrPFSdJwUneD76nttLzPO3bvJ+Lpvk3GsaKvxqM1kNgKYhJ5S+lHSGQ9LZkurf5s/7iqTJG0urGj1e7W1mjZibRu2rM0rCbxOjiVsQddF2AIAAAAAAAB0VY5K6dtXjJClbJdxzGSRMo6Ssn8l9R1jfE3JCvGCZ9U89XqligJp70bJViol9JDiexhfY1Mlc9uPk/55jxG2bN1bKa/X2yazTdpKTRux+Da7Z99uwcEOlS3oyghbAAAAAAAAgM7G45ZkajjQqC6RVj9vDKav2m8cS8yQjv29NGKyFJvc8j2YTFJShvHoAArLbdpbbpckVdhdKiy3Kz05tp13FTntUdnSt1tNsGMySUmxfNyMrou/fgAAAAAAAKCzKN0pff20Ua3irJJiU4wqkrjUmq9RsdKGhUaLL0lK7Scdd5M09HJjyH0ntX5PedDrLXsrOk3YYnO6VegLktqysiW71r0SY6JkNneeSiGguQhbAAAAAAAAgIPd3k3Ssiel79+SPM6a49XFxqO4nnN6DpKO/z/pyN9Ils7/MeHPu8uCXm/ZW6lj+/dop91E1u4So6ol3mpRWnzbtfLKrlXZQgsxdHWd/7+iAAAAAAAAQGe1a4301RPS+gWSvMaxnOONSpX0o4x2YbaSA76WShlDpIGnt8vclPbin9cSE2WW3eXR1r0V7byjyKndQqwt59BkpsTKYjbJ7fEqOZawBV0bYQsAAAAAAABwMPF6pc1LpOVPSdu+qDl++FnScX+Uso+pOdZB5qV0BD/tLpUknXpEL330Q7627K1s5x1FTk3Y0nYtxCQpymJWVmqccouqqGxBl0fYAgAAAAAAABwMXHbp+7eNmSx71xvHzFHSkIulcTdJvQa16/Y6siqHS9v2GeHK2Uf3NsKWws5U2VIlyahsaWvZ3QhbAImwBQAAAAAAAOjYKvdL37worXpWqiw0jlkTpRFTpF9dL6X2bd/9HQQ25JfL65V6JsVozCHdJEm7S6tV7XArzmpp5921XO02Ym2tb7d4LdN+JcfxUTO6Nv4FAAAAAAAAAO2hPF9a87K06WNJJsmaIEXHS9Z4KTpBio6THJXST+9LLuPDdCVnSWOul0ZOkWJT2nX7B5OfdxvzWo7snaxuCValxkerpMqpbfsqNbh3cjvvruVqKlvato2YJI0b0ENvrs7TqH7d2vzeQEdC2AIAAAAAAAC0Fa9Xyv1aWvWctP5DyeMK7bzModLY30tHni9ZaNfUXD/vMcKWwZnJMplMOrRHgr7NLdHWfRWdJGxpv8qWs4/urZMP76WEGD5qRtfGvwAAAAAAAACgpTb9V9q0SIrvJiX3NipQkjKNr/HdjAqVH96WVj0vFf5Uc172GKMdWFya5KwyHo4qyVlpfPU4pQGnSTnHSSZT+31/Bzl/ZYs/WOnfM1Hf5pZoS2Fle24rImxOtwrL7ZLap7JFEkELIMIWAAAAAAAAIHxF26RFfzKCloZYYiSzxQhSJCkqTjr6YumYaVLm0W2zzy7M7fFqQ35NZYskHdozUZK0dV9Fu+2rKXO/2KIqu0t/PG2gTI0EbbtLjKqWeKtFafFUPQHthbAFAAAAAAAAaC5ntfTVHOmrJyS3XTJHScOuML6W7ZbKdxtfK/ca77sldTtUOuZaadjlRiUL2sS2fZWyOT2Kt1rUr3uCJKl/T+Prlr0dM2zZkF+mhz7eIEk6e2hvDUxPanBt7RZijYUyAFoXYQsAAAAAAAAgSaU7jWH0JblSj4FSr8FS+uDgYMTrlTZ+bFSzlOwwjh1yonTmI1LPw+te02WXyvONNmI9B0lmc9t8Lwjwz2sZlJEki9kIIwKVLXsr5fV6Wy2k8Hq9WrZ5vzJSYjSgV8OByYFe+XpH4PmqbUUhhi3t00IMgIGwBQAAAAAAAF1X5X7p5w+kH96VcpfXvyYpsyZ42btR+uW/xvHkLGnCA9Lg8xuepxIVI6X1a42dI0QHzmuRpH7d4xVlNqnK4VZ+mU2ZKZEfLO90e3TX/B/1xqo8JcdG6cvbTlFKXNNtvkqrnXr/212B16u2FenKXzX8N7SrxGhP1yct8t8DgNARtgAAAAAAAKDzqS6RyvwfWPuCkEAgYpL2rJN+eEfa+rnkcdWc1/dYKWuEtO8XqXC9VJorle8xHluWGGvM0dKx06Xjb5ZiEtvoG0K4/JUtgzNTAseiLWb17R6vrXsrtaWwMuJhS5nNqRtf/1Zf/rLP99qlV7/erumnHNbkue+t2alqp1vxVouqHG6t2lbUaPWNv7IlK5WwBWhPhC0AAAAAAADoHLxeafuX0pp50vr/SG5HaOdlHC0NuUg68jdSanbwe7YyI3Qp/Nl4uJ3S2BulHk1/aI6Oob7KFkk6tEeitu6t1NZ9FTrusB4Ru19eUZWunrdavxRWKN5q0fnDs/Svlbl64attmjruECXENPyRrMfj1WsrjBZiM08bqIcXbVB+mU07i6uV3a3+NmG0EQM6BsIWAAAAAAAAHNwq9kprX5e+fUUq2lJzPK6bZPLPSPH6vvi+JvYy2n8Nuajx4CQ2Weo7xnjgoFNYbtO+CrvMJunwA+ae9O+VoMXrpS2FFRG739q8El378mrtq3AoPTlGL0w5RkdkJuvrLfu1bV+lXl+5Q9ed0L/B87/avE9b91UqMSZKl47uq4U/7NF3uSVata2okbCFNmJAR0DYAgAAAAAAgIODyyFVF0lV+41HRaFRwbJhoeRxGmusidKQi6WRU6Tew9t3v61oV0m1rnvlG111bI4uHpXd9AldlL+q5dCeiYqzWoLe69/DaAG3dV9lRO718Q97dNNba2V3eTQ4M1kvXDUq0J7sdyf1163vfq9n/7dNk8fmKDbaUu81XvnaqGq5aGQfJcZEafQh3fRdbolWby/ShSP71Flvd7lVUGaXRNgCtDfCFgAAAAAAAHQsVUVS3iopb4WUt1oqzTOOOcobPidrpDTyKqMVWBeYozJ/7S79tLtMf/98M2FLI2rmtSTXea9/rwRJkalsefZ/W/TgRxskSacM6qW/XTY8qF3YBcOz9OTiX7SrpFpvrc7TlGNz6lwjr6hKn20okCRd+at+kqTROd30zy+2atW2onrvu7vEJkmKi7aoW4K1xd8HgPARtgAAAAAAAKD9eL1S0VYpb6WUu8J47NvY8HqTWYpLk+K7G4+MIdLwSVLm0W235w7gJ1/Fxo79Vdq+r1I5PRLaeUcd008NzGuRjJktkrS71KYqh0vx1vA+Kl2XVxIIWq46Nkd3nj1YFnPwMPtoi1m/O6m//vLBj5r7xRZdOjpbMVHB1S2vr8yVxysdN6CHBvQy9jaqXzeZTEb1zd5yu3omxQSdU7uFmMkUfE8AbYuwBQAAAAAAAG3H5ZDyvzdClbwVUu5KqbKw7rruA6TsXxmzUnoMlOJ7SPHdpNhUyWyuu76L8bfHkqQvNu09aMOWT38u0Je/7NWtpw9SYiOD48O1fnfDlS1pCVZ1S7CqqNKhrXsrdVRWSlj3+N+mvZKk8Uek6+5zj2xw3UUj++hvn/2iPaU2/fvbXbpsdN/AezanW2+tzpUkTRrbL3A8JT5ah6cnaUN+uVZvL9KZQzKDrrmzuFoSLcSAjoCwBQCA/2/vvuOkqO//gb9m++313rkCRz/6HVWaRERRiTG2BEsSTH62qFG/GvMV0zRRVCJoYvwmthjFiiCKCoiAgPSjHvXuuML1trd7W2d+f8zW273e4fV8PPaxszOzn/nM3jHAvPf9fhMRERERUc+yGOR+Kk0V8sNQATSWAqUHgNL9gL3Zd3+lRu6vkjoVGDJNfg6O6Z+5DwIGsw0FXn1Gvj1VFbAs1UBnc4h47KPDqDFaYRclPP3D7B4d32ixo6BG/pxGBQi2AEBmTLAcbKnuerBld0ENAGDO8LZ/Z3VqJe6aPRR//Ow4Xtl6Bj+enAKVUg4cfnb4AupMNiSF63D5yDif9+VmRCG/3IA9BYGCLa7MFn2X5k5EPYfBFiIiIiIiIiIi6p7688DB/wDH1gINJYCtnYbjQVHOwMpUOXslaSKg1vXJVC8GJy7IvWs0SgWsDhG7ztbAbHO02nR9oNpxpho1RisA4L/fn8ficYmYMbTngmz55QZIEhAXqvUrv+UyNDYE+4rquty3xWJ3YF9hHQBgWmZ0u/vfmjsEr3xzBsW1zViXV4brJ8lN79/eVQgA+Mm0NHcAxiU3Iwpv7SrC3kL/vi3MbCEaOBhsISIiIiIiIiKizrNbgVNfAPvfBM5uASD5blcHA6HxQIjXI2GsHFyJyQLYX6LLjpU1AABmD4/B4ZIGVBos2FdYh1lZgysb6NODpQCAUK0KBosdj310BBsfuKzLvVNaOn6h9X4tLkPj5PJrZ6u6FmzJK26AxS4iJkTj7rPSliCNEr+4LBN/3ZiP1d+cwXUTknGktAF5JQ3QKBW4OSfV7z256VEA5PNpNNsQplO7t3mCLcxsIepvDLYQEREREREREV3MJAkw1QJ1hUB9ofxcVySX+VKqAZVOzipR6QCV1vmsA7RhgDbU89CFyevsZiDvPSDvXcBY5TlOxmxg4m1A8iQ5sKJt/8YzdY2r6fuYpHBE6jX4YH8Jvj1V2SPBluJaE7RqBeJCezfTyGS146vjFQCAv/90Mh79MA/na01Y8eUpPHnN6B45xvE2+rW4ZMbIv6fnqtrJxmrF7nNyCbGpmdEdblD/02lD8I9vz+JclRFfHL2ALflyz6KrxyUiOsQ/AycuTIf0aD0Ka0zYX1SHeSM8ZcY8ZcSY2ULU3xhsISIiIiIiIiIarKxGoOas3GDeWC0HUIxV8qOpEjCUA/VFgLVr39pvV0g8MOEnwKSlQFRm7xyD/BwtlTNbxiSFISs+xBlsqcITV3dv3JomC65cuQ0Reg2+eXguNCpF+2/qoq+PV8BkdSAtWo+Zw6Lx9PXZuOP1vXh9ZwGuHpeAyWlR3T5GxzJbnMGW6iaIogSFonMZV65gS0dKiLmE6tS4c2Y6Vm46jRe+PuXOTrltelqr78lJj0JhjQl7CmrdwRaL3YGKRgsABluIBgIGW4iIiIiIiIiIBgNJAuoKgOK9QMkeoHgPUHEMkBwde39oEhCZBkSmAxFpQGgCINoBu0XOVrFb5Mb1dgtgMwGWJrnRvc+jUd4+dB4w6TYgayGg5O2lvmSxO3DG2V9kTHI4gjVKKATgVEUTyuqbkRTR9ZvuB87Xw2h1wGhtxqYTFX7N2HvSWmcJsesmJEMQBMwdEYcfTUrBRwdK8OiHh7Hh/su61YPG7hCRf6H9zJbUyCColQLMNhEXGs1I7sTnZ7E7sL9I7tcyPbNzwaE7Z2Tg/7YXuDNqspPDMSE1otX9czKi8MH+Euwt8PRtKas3AwCC1EpEBWs6dXwi6nn825CIiIiIiIiIqLdJktw43lQDKFReD6Vn2WEFmuvkh7nes9xcJ2evFO8BTNX+Y+tj5MBJcAwQHAeExHktx8sBlvBUNqC/SJwqb4JdlBCpVyMpXAdBEDA+NQIHz9dj26kq3Jw7pMtjuzJmAOC9vcW9FmypabJg22n5d/m6CUnu9f+7eBS2na7C2SojXtp8Go9eObLLxyisMcJiF6HXKJEWHdzqfiqlAmnRwThT2YSzlU2dCrYcOl/v7tcyNLZzZfPC9WrcNj0Nr2w9CwBYOj2tzTJkUzPkYM7hkgaYbQ7o1EqfEmIdLWFGRL2HwRYiIiIiIiIios6wGAAIgCa49SbvoghUHgfO7wLO75afG0u7f2ylBkgcD6TkAqk58nN4cvfHpUHjaJmrhFi4+wb7nOGxOHi+Ht/2YLBl++kqFNeakBrV843XNxy5AIcoITs53CdIEaHX4E9LxuKXb+/Hq9vOYdHYRGSnhHfpGK6+NiMTQqFspzRYZowcbDlX1YTZw2M7fIzd5+Qsk870a/H281kZeG9vMYLUSlw7PqnNfYdE6REXqkWlwYJDxfWYlhntLj/GEmJEAwODLURERERERERErXHY5FJdpfuAEuej5rS8TaUD9NGeR3AMEBQpN6A//z1gafAdS6GSs00khzyu6JDLeLkeChWgjwJ0EfI47kcEEJYEpOQACeOYoXKJO1bm6dfiMmd4LFZuOo0dp6thc4hQK7vWa8UVyIkJ0aC6yYoP9pfgoR8M7/6kW/CUEPMPMCwck4CrxyViw+ELeOTDPKy7d1aXesd0pF+Ly9C4EOB4Bc46S3p1lKtfy/RO9GvxFh2ixeaH5kChENotmSYIAnIyorDh8AXsLajFtMxolLqDLT0fECOizhuwwZaXX34Zzz33HMrLyzF+/HisWrUKubm5Afc9duwYnnzySezfvx9FRUV48cUX8cADD/TthImIiIiIiIhocHPY5UDKhcNA+WGgdD9QdkjuYxKI3Sxnq7SWsaIJkQMkQ6YDQ6YBKVPkbBiibnBlbHgHEcalRCBCr0a9yYZDxfXISe98c/lKgxkVjRYoBOCRhSPwPx8dwQf7ivHry7PazQzpjPM1Jhw4Xw+FgFazOX5/7RjsPFON/HID/vHtWdx/eVanj3Pc+TmNSWo/M8aVXXOuuqnD45ttDhw4L/drmdbFYAsARHai18pUZ7BlT6GcUeMqI5bMzBaiAWFABlvWrFmDhx56CP/4xz8wdepUrFy5EgsXLsTJkycRFxfnt7/JZEJmZiZ+/OMf48EHH+yHGRMRERERERFRt4gOwFAuZ3co1XK5LKVGXvYuzyNJchaIw+bJCJEkOftD0cFm2qIINFXIzeYrjsmBlfIjQMVxwGHx318bDqRMBpKnyMGT5MmASiv3XzFVA6ZawFjtfF0j90wZMg2Iz2bzeOpRDlHCCWfGxthkTxBBqRBwWVYs1ueV4duTVV0KtrhKiA2NDcF1E5LxzBf5uNBgxrbTVZg3wv9+XFd9ekgOTs4YGoO4sMBZWjEhWjx17Rj8+r1DWLXlNK7KTsCwuNAOH0OSJHewZXRi+5ktmbFyEPRsZcczW/KKXf1atBga2zdBVNfP9UBRHewOkWXEiAaYAfk3/gsvvIBly5bhzjvvBAD84x//wIYNG/Dvf/8bjz32mN/+OTk5yMnJAYCA24mIiIiIiIhogJEkoPIEULANKNwuP8wNgfd1NZB3BVda2yc0US63FZYEhCXLj+BYoKkcqCuSy3vVFwH15+WslEA0oUDCWCB+LJA8SQ6wRA8DFAHKGGlD5ObzRH3kXFUTzDa56XtGi6bvc4bLwZZtp6vw8MIRnR77aKkniKNTK/HDicl4/btCrNlT3GPBFkmSsPZQ6yXEvF07PgmfHirDlvxKvLjpNF6+dVKHj1NlsKDGaIVCAEYktB+kGRojZ7aUN5rRZLEjRNv+LVNXv5ZpmVF91px+RHwownQqNJrtOH6h0SvYwjJiRAPBgAu2WK1W7N+/H48//rh7nUKhwIIFC7Br164eO47FYoHF4vm2SmNjY4+NTUREREREREQB1J8HTn8tB1YKtstZId4EJSCJACTf9W0FWbz3aSiWHx0hKOXG8nGjgYRszyMiPXBghWgAcJUQG5UYBkWL0l6zs2IAAIdLGlDdZEFMiLZTYx9xZra4MmZuzhmC178rxKYTFagyWBAb2rnxAjlW1oizVUZoVQpcOTahzX0FQcCjV47AlvxKfH7kAk6WGzoUOAGAY87sn6GxIe32QgGAcL3a3aemoMqI7JT2S4/tOidfv7pTQqyzFAoBOelR2JxfiR1nqlFhkIPGzGwhGhgGXLCluroaDocD8fHxPuvj4+ORn5/fY8d55pln8Pvf/77HxiMiIiIiIiKiFiQJqMoHTqyXH+WHfbergoC06UD6ZUDGHCBxvFwKTHQADisg2uRyYQ6r/OwqMeZ+VsvPkgQYK4EGZ/+UxjJPLxVjtZzdEpkuZ6FEpsuPsGT5vUSDyDFnA/sxAZq+x4XpMDoxDMcvNGLH6WosmZjcubFdwRbn2CMSQjFxSAQOnq/HxwdK8Ms5Q7s5e2DtQTmrZcGoeITq2v/zNzIhDFdlJ+DzI+V4aUvHs1vyiusB+Pa1aU9mbAiqm2pxtqqp3WCL3K9FPsb0oX0XbAGAnAw52PLpwTJIEqBTKxDdib4vRNR7Blywpa88/vjjeOihh9yvGxsbkZqa2o8zIiIiIiIiIhrgmuvl4EnlcXlZFwboIgBduPzQhsnPjaXAiXXAic+A2rOe9wsKIHUakDkXyJjt7H0S4CahUtX5Xieu8mHI6fLpEQ107lJfrTR9nzMiFscvNOLbU1WdCrbUNFlQ1iBnSYzx6gVzc04qDp6vx5q9xbhrdma3ymU5RAnr8soAtF9CzNv9l2fh8yPl+PzIBZyqMGB4fNvZLZUGM/69owAAML0TWSdDY4Oxp6AW56qa2t33UHE9rHYRsaFaZMb0Tb8Wl9wMuW/LyQoDALmEWF+VMSOitg24YEtMTAyUSiUqKip81ldUVCAhoe30ws7QarXQaruf/khERERERER0UZAkwGqU+6aY6+VgSl0hUHVC7q1SeUIOonSWUgNkzgNGXQOMWAQEx/TwxIkuDZIkuTNbWsvYmDM8Fn/fehbbTlVBFCW/UmOtcZUQy4wJ9ulXsnhcEv6w/jjOVRuxp6AWU7tRMmv3uRpUGiwID1Jjbid6wIxMCMOisQn44mg5Xtp8GqvbyW7542cn0Gi2Izs5HDdMTunwcYbGyn1bzlYZ291397kaAHIJsb4OdIxNCodOrYDZJgJgCTGigWTABVs0Gg0mT56MzZs3Y8mSJQAAURSxefNm3Hvvvf07OSIiIiIiIqLeJIpyoMNYLfczMVY5l2sAU62cGaLWyeW31DpAHSQvq7RymS1rkxwwcT+cr+1muaeJw+ZVmsu5bGnyBFja64sCAOGpQNwouTSXuUF+WBo9y+ZGQK0Hhl8BjFwMZP0A0HaszwIRta6krhmNZjvUSqHV7I5JQyIRolWhxmjFsbLGDvUeATy9YMYm++4frFXhmvFJeG9vMdbsLe5WsMVVQuyq7ERoVJ3ri3T/5Vn44mg5Nhy5gPvbyG755mQl1ueVQSEAz1yfDZWy48fJjJUzVM52ILPFE2yJ6vD4PUWjUmDSkEjsPCvPgcEWooFjwAVbAOChhx7C7bffjilTpiA3NxcrV66E0WjEnXfeCQC47bbbkJycjGeeeQYAYLVacfz4cfdyaWkpDh06hJCQEAwbNqzfzoOIiIiIiIguEpIk9wEpPwyUHwEu5MnN3rWhnhJa7kcEoA0BIACQ5Pe6mr5LktyPpLnWK6BS7Vk21QKSo3/PVaGSzyEoAghNBOLHyMGVuNFA7Aj5HNsiOc+TTeaJepQrIJIVF9pqsEKjUmDG0Gh8dbwC356q7HCw5UiJs19Lsn/GzE05qXhvbzE2HLmA5deOQXhQ53sdmW0ObDxaDgBY0okSYi6jEtvPbjFZ7fjdJ0cBAD+bmeEXOGqPK7OloNoIhyhB2UpWkHe/lmndCD51R056lFewRd8vcyAifwMy2HLTTTehqqoKTz75JMrLyzFhwgRs3LgR8fHxAIDz589D4fWPtrKyMkycONH9esWKFVixYgXmzJmDrVu39vX0iYiIiIiIqK+JopyloVDJ2R8ty7qIDrkEVl2h/6O5Xg6OaMPk4In7OVQes/yI/DDV9N356MIBfYxccsv9HCUHMexmwNbseXYtKzWAJhjQhDifXct6OfNFqfE0lFeo5NdKtZyFEhThCbCo9f6fX2cIQvfeT0QBuUqIBQqIeJszItYZbKnCvfOzOjT2UffY/gGKCakRGBEfipMVBqw7VIql09M7N3EAW/IrYbDYkRSuQ05617JBvLNbfl1hQFaL7JaVm06jtL4ZyRFBePAHwzs9fkqkHhqlAha7iLL6ZqRGBQ5iHDwv92uJ64d+LS6uvi0AM1uIBpIBGWwBgHvvvbfVsmEtAyjp6emQJKkPZkVERERERESdYrfIwQxXmSpzg/N1PdBcJy8318kP1zpBGSBbxPlwWJyZIFVAU6Vn2VTtzB5xUqg8D0EJ2IwdK5HVFkEpZ3YkjAMSxwHRwwCbyat8VoPnXC0G53sEAILvs6AAgiLlMlzuYEq0/FofA+ijAzeNJ6JLmiuzZUxS2xkbs7NiAQAHztejodnWbiZKndGKkrrmVscWBAE356bi9+uP4729xQGDLWabA7vO1uBMZROaLHaYrHY0WRwwOpdPXJCviddMSOpwH5mWRiWG4coxCdh4rBwvbTmDVbd4vnh9tLQB/9pRAAD445IxCNZ2/panUiEgPUaPUxVNOFvV1GqwpT/7tbhMHBIBlUKAXZSY2UI0gAzYYAsRERERERH1MUmSgxd1hUB9EVBXADQ4G6K7siCUGs+yQuVsqF7fSkClAbA398+5iHb/4IpCDUSmAZHpvg99tNy3xNIoB0nczwb5M4kfLQdY4kbLfVKI6KL20f4SbDtdhcXjkjB/ZFyr5aT6miuzZUxS25ktqVF6DI0NxtkqI3aeqcai7MQ293dltaRF61sNzPxwYjKe+SIfx8oacaSkAdkp4WhotmHryUp8eawcW09WwWRtuwSiQgB+NKnjDesDuf/yLGw8Vo7PDpfh/vnDkBUfCoco4befHIFDlHD1uETMHxnf5fGHxoY4gy1GzB0ReB/vYEt/0WtUePTKEThV0YTsTpZLI6Lew2ALERERERHRQOXq9SE65GdJlAMIdoscxLBb5PJRdounnJR3wMP7YTV6ZVcoPBkWgNwovaEYqCuSM0B6nADowuQyVbpwr5JVkfJyUKTva0lsMf9Gz3kpNc6MkFhPZohrWR3k+Yx8HqIcJAlNBBTKXjg/IrpYmKx2/O+nR2GyOvDpoTIkRwThJ9OG4KYpqYgO0fbbvKoMFlQ0WiAIcoZHe+YMj8PZqgJsPVnVfrClVM6YaavHSYRegyvHJGBdXhn+tOE4NCoFdp+rgc3hqTST6CwRFqpTIUSrgl6jQrBWKS9rVRgaG9xqY/uOGp3kn93y5s5CHC5pQKhOheXXjO7W+JmxclmwHaer8NNpQ6BV+f6dYbY5cLC4HgAwLbNr5dB6yl2zh/br8YnIH4MtREREREREorN5eavb7XJAQrTJz97LgkIOALh6Yqi0gFIrNwcXHXKWhCtY4Fq2NMrlsoxVvs3RXctWg29JrD4lAGHJngyQ8BS5fJbD6nzYPMuiXe4L0jKI4l52NYsPY7N0IhoUvj5eAZPVgQi9nOFRWt+MZzeexMpNp7E4OxFLp6dhQmpEn5ePcmW1ZMQEd6hE1ryRsfj3dwX46ng5/mAf4xc08Ha01NmvpZ3yZDfnpGJdXhm+L6h1r8uKC8EVY+KxcEwCspPD++Rz8c5uuWFyClZ8dRIA8NiikYgL7V724axhsXj5m7P45mQVrlm1Ayt+PB7jUiLc2737tWT0U78WIhq4GGwhIiIiIqLukSQ5qCDavDIJHM6ARMsMA+fDYZeDCQqVV2kqtWdZUDqDGS1u7vstt9jH1SDdXeqqRckrYxXQWOZ8lDofZYChHJDaLn/SaYKy58f0ptLJgR33c5CcveHT4yTCs6xx3hSSRPlnBsmTOaNQykGVyAz5WdV/394mIuopDSYbRElCZHDHeyCtO1QGAFg6LQ33zBuG9XlleHt3EQ6XNODjg6X4+GApxqWE4xeXZeKqsQlQKfsmkNzRfi0u0zOjER+mRUWjBZuOV+Lqca1nt7jKiLVXjmpaZjSun5SMktpmzB8VhytGxyMzNqSDZ9BzRieFYeGYeHx5rAI/f2Mv7KKEKWmRuCVnSLfHnj40Gq8unYwnPjmCUxVN+OErO3H33KG4b34WNCoFdg2Afi1ENHAx2EJERERENJiJolxGytYsl5WymeUMAqW2RaaFRi4bJUlyHwp3jw2vZ1uzVwaH3TeAYjP7Nzd3LfdK2akBTuEKEKnkz9RukRu3e/MOtKiC5DJa2jDPc1CEpyF6cIynHJY+BtCGygEQQekp9yUoPOtUWmdJMCIiCqSh2YaFK7fBLorY/NBchOvbbhIPyI3ivz1VBQC4bkISdGolfjwlFT+ekopDxfV4a1chPjt8AYdLGnD/uwfxbGQQfjErAzfmpEKv6d1bbMfdwZb2S4gBgEqpwA2TU/DyN2exZl9xq8GWhmYbimpMHRpboRDwwo0TOj7pXnT/5Vn48lgF7KIEtVLA09dnQ9FDvXUWjklATnoUlq87hvV5ZVi15Qy+Pl6BFT8e7+7XMn1o//VrIaKBi8EWIiIiIiJvosPT+8LufLaZ5JvpglK+2e3KxlCoPDe//TIuLJ5luyVAVobzYbcGfp/d6hVEMQeYk/PR8gZ/W5QaZ++PXsy28CY4PyuFSg5KKLwfSjl44MqAcZ2/6Py8IHllqLRoyt7WskLlHNPi+3nbnVkv+mggLMn5SHE+JwNhiXKGSCCSJM/XO0MmUKBDkloc0yK/RxsKqDr+rWoiIuq+f247i/JGMwDg/X3FWDY7s933fH70AuyihDFJYRgW59tbZEJqBCakTsDvrh6N/+wuwps7C1FS14yn1h/Hys2ncdu0NNw2Ix0xvdTXxZV90tFgCwDcOCUVL39zFttPV6G0vhnJEUF++xxzlhBLiQzqVAZQfxuTFI6rshPw+ZFy/GrO0G73gmkpKliDVbdMxKKxCfjd2qPILzdgycvfuQuOTstksIWI/DHYQkRERDRYiaJ809zdONt7WQyw3uEpGeTD+6ax181iV4aDqzSTazzAU4LIe9lVGsq79JNrjJa9MKRAvTECrHPY5CwMa5Pc3NvS5Fxukm9ke5esEh2e15Lo1fxb8F0GfD8T13m5sjgc1s79HAYSpbOklOTMdhFtvtu9z02p9WpSHuEpM6XwCiK5A0oqOZOitb4cmtAAwZRWAhIdJUmDL3NDEOSgCgMrRET9qrLRjH/vKHS/fmt3IX42KwPKdjIfPnWWELtuQlKr+0QFa3D/5Vm4a3YmPtxfgv/bfg6FNSa8tOUMXt12DjdOScXjV43s0UyXRrN39knHyogBQFp0MKZnRmPXuRp8sK8YDywY7rdPR0uIDUTP3TAet+QOwcyhMb12jKuyE5GbEYX/XXsUXxwtBwDEh2mRHq3vtWMS0eDFYAv1Le+bQqLd/wZHqzc+urOv1w0Yye5pfuq3r6PFTStHKzeCAhAEzzddBaVcusPndSvr3aUgvJ69b3j53GBobX1b27r7Hr8THUBz68J72hyvlbE6PIeefo+T3++g1Mq2tm5itvaezozXkff01LF6eu5dGQ9tbBugc/e+ge5dhx+Sf21+n/1brHO9XxD8b5oqFM6bp0rf/QON4bMcYE5+67wIAtw3x93P8F12bZNET+keu8WTPeBa19Z1XKH07XPg3fdAkjxjusdzPos2z2fq+hxdD7R43XKfgNu9lgNtF21eWQwm3+fBHBQYLFw9MNR65++G6Awo2T3ltRzOf0+07A/iLt+lhl//EFXLfiLO97jKfbnf7zy2Wueci9fD77VO/r32JorOwJfFmUHjzM4JipDfM5ANtkALERENGC9tOY1mmwPjUsJRVGNCcW0ztuRX4gej41t9T1l9M/YU1EIQgGvGtx5scdGplfjptDTckjsEXx0rxz+2nUNecT3e3l0EuyjimevH9dj5nHCWEEsK1yGqk9knN+WkOoMtJbh/fpZfqa0jpfLYYwdhsCVYq8JlWbG9fpyYEC1e+ckkfHb4Al74+hRuyU1lvxYiCojBFmpb4Q7gq9/JN3RafkNWEj3BiUDfoPW+idSX5SqIiIjISfAE832C/c5tAAJEF317Ufgsq3y/GOAKermW3eWivMo5KdXyGEIbzWPb+s+qQiWXYNKEyFkX2hA5i0IT7AlkeJelci1DQMDAoiso6feFCOfnpFQ7Ays6Z/Cib5re9hqFAlDo5GANERHRAHam0oDYEF2Hequ0pbDaiPf2FAMAfnvVKHyTX4lXt53DmzsL2wy2rMuTs1py06OQGN7xLyQoFQIWZSfiyrEJ+Op4BX759n68u6cY14xLwoxhPZNxcdQZbBndiawWlyvHJiD0UxVK65vx3dlqv+CEq4zYYAy29CVBEHDN+KQOBeKI6NLFYAu1zdwAlB3so4MJAW58uG4OqQKs82oYKjrazy5xZY+otPI3OV3fzm4zG6UDN1jcpVNaZtu0yJJpud4vQ0f03AByj+t+0cr6trb15ns6MlZ/za0rWQKtjNXhOfTGe3ozi6er43XkPT11rP7IaOrtY/XyeK7rlV9WiCJwpoh3aSWf9zn3984WDFSmqeVN9tYyUNrcHuCGfbvZLy0yYQQhcBNw13PLb/l7Ex1ymSW7Wc5YsTU7s2PM8ufgM5bWN+vAu1m164GW69DOdsH3ubXtCpVX9oLe99mVyeCTLen1dxi/cUdERESDwM4z1fjpv75HeJAaL940AXNHxHV5rOe/PgW7KGHuiFhMy4xGckQQXtt+DjvOVON0hQFZrfT28JQQS+7ScQVBwMIxCVg6LQ1v7y7C/3x8GF8+MLtHyokd60K/FhedWoklE5Lx9u4irNlb7BNsMZhtOFdtBACM7cLYRETki8EWalvyZODmdztRHquNoEib+yp5Q4iIiIiIiIjoEiNJEp798iRECagz2XDH63txz7yheHDBcKiUncswPVragPXODJVHFo4AAKRG6bFgVDy+Ol6BN3cV4k9Lsv3ed6rCgBMXGqFWClg0NqFb5/M/i0Zi84kKFNc2Y8WXp/DkNaO7NR4AHC/rXqmvm3JS8fbuInx1rAJ1RisinaXIjnmVJ4sO0XZ7nkRElzoGW6htoQnAyKv6exZEREREREREdBH65mQlDhXXQ6dW4NrxSXh/Xwle/uYs9hXWYdUtExEX1vFSmM99eRIAcO34JJ9G8nfMTMdXxyvw8YFSPLJwJMKDfEuVrXNmtcwZHusORHRViFaFp6/Pxh2v78XrOwuweHwiJg2J7PJ4ZpsDpyubAHQtswWQgzRjksJwrKwRaw+V4s6ZGQDk4BQAjGEJMSKiHjHIi1ATEREREREREdFgJEkSXvj6FADg9unpePaG8Vh1y0QEa5T4vqAWV720Hd+dqe7QWLvO1uDbU1VQKQT85orhPtumZ0ZjRHwoTFYHPthX7DeHT/NKAQDXdrGEWEtzR8Th+knJkCTg0Q8Pw2Lveg/bk+UGOEQJkXo1EsO73oPtppxUAMCavcWQnGV5XcGWbAZbiIh6BIMtRERERERERETU5746XoGjpY0I1ijxyzlDAQDXjE/C+vtmYWRCKKqbrPjpv77Hyk2n4BBb9u70kCQJf92YDwC4JXcI0qKDfbYLgoDbZ6QDAN7aVeQz1sHiehTXNkOvUWLBqK73imnpycWjEROixZnKJqzecqbT769oNOPVb8/iofcPAQDGJIVD6Eb59evGJ0OjUiC/3IDDJXKQ5aizjBiDLUREPYNlxKhNR0sb8Jcv8hGhVyMmRIOYEC1iQrWID9UhNlSLhDAtooK1UCjYb4WIiIiIiIiIOkYUJbzozGq5c2YGorzKd2XGhmDtPTPx1LpjeG9vMVZuOo0t+ZX4+awMLBqbCI3K97vDXx2vwKHiegSplbjv8mEBj7dkYhL+8sUJnK81YevJSlw+Kh6Ap4TYwjEJPdLM3iVCr8EfrxuD//fOAfx961ksGpuI0e2UAWu2OvDV8XJ8dKAUO05XwRUT0igV+PGUlG7NJ1yvxlVjE7D2UBnW7CvGsLgQnK1ylidL7lp5MiIi8sVgC7XpfK0JO9pJ2RUEIFynRoRejegQLaJDNIgJ1iImRIPYMB2igzXQa5QI1qrkZ40Keq0Seo0KerWSgRoiIiIiIiKiS8znRy8gv9yAUJ0Kyy7L9NuuUyvxlx+NQ25GFJ745CgOlzTg1+8dwp9DT+Cn09JwS+4QxIZqYXeI7l4tP5+VgbjQwKW29BoVbspJxWvbC/DGzkJcPioedoeIzw7LwZZrJyT1+Dkuyk7EorEJ+OJoOR79KA9r754JldI3UFRvsmLX2Rpsya/E50cuwGj1lBybkhaJ6yel4OrsRITr1S2H77Qbc1Kx9lAZ1h8qw5VjEiBJQHyYttXPjIiIOofBFmpTdnI4nrpmNMobzag1WlFtsKLGaEGN0Yp6kw1NFjskCahvtqG+2YbCGlOnjxGkViLYFXxxBmXUSgFqpQJKhQCVQnA+K6BSCl7rFM5nwCECKoXg3q5WKqBWet7jetYo5WfvsVUKBZRK/+OoFAJ0aiXCdGqEB6mhUyu6lbJLREREREREfctid2Dj0XLMGxmHMF33b1ZTz3CIElZuOg0A+MWszDYDCddPSsGsrBj89/vz+M/u86g0WPDC16ewessZLB6fiKTwIJypbEKEXo275vgHbbzdNj0d/7ejANtPV+NMZRNK65tR3WRFVLAGs4bF9Og5uvz+ujHYebYGR0sb8c/t53DHjHTsLazDzjPV+O5sNY6VNULyqpCWGhWE6yem4IcTk5EeE9z6wF0wLSMaQ6L0OF9rwoqv5ADV2CSWECMi6ikMtlCbUqP0uGNmRqvbbQ4R1QYLKgxmVDZaUGmwoMpgQU2TBdVGKxpMNjhECUarHSarAyarHSaLA0ar3Z0O22xzoNnmAGDtm5PqIo1SgbAgFcKC1O4ATFiQGuFBKoRo1QhSK6HXKKHTKKFXKxGkcT7U8kOnVkKpkGvFKgQBCgFQCAIE57NrneC1TSEIEBRod//WSJIEUfI8qxQCM4mIiIiIiOiS8dS6Y3h3TzEmDonAe3dNg1al7O8pDWrna0zYnF+BIyUN+PllGRjTxRv16/JKcaayCeFBatw5K73d/eNCdXhgwXDcPXcYPj9yAW/sLMSh4np8fKDUvc89c4e1G1BLjdLj8pHx2HSiAm/tKkSTxQ4AuDo7EWpl77Q1jgvV4X8Xj8bDH+Thha9O4cWvT8Hm8O0/MywuBDOHRuPqcUnISY/stS96KhQCbpySghVfnXL3bRnLfi1ERD2GwRbqFrVSgcSIICRGBHXqfZIkwWIXYbTIQRij1Q6jRQ7GGC0O2BwiHKIEuyjBIYqwOSSf13ZRgt0hv7bZRZisDthF0ed9dud7fMeSIAhy6TO7z5ie/bzXmax2NJrtcIgSrA4R1U1WVDcNvKCQdyDGO7gSiE6t8ASAvIJBQRo5IBTotSjJ52+xibA6HM5n+ecQolEhRKdCsFaFUK28HKJ1PryXtSp31hIzhIiIiIiIqLftPFuNd/cUAwAOnq/H7z45imdvGMf/j3SC3SHiwPl6bM6vwJYTlThd2eTetuNMNT67bxbiwjpXgsruEPE3Z1bLXbMzO5VxpFEpsGRiMpZMTMbB83V4c2chNhy5gCFReiydntahMe6cmY5NJyrw4f4SuH4TruuFEmLefjQpGevzyvDtqSoAQFK4DjOGxWDmsGjMGBqD+E5+ht1xw+RUvPD1Kfc9AwZbiIh6DoMt1C8EQS7RpVMrEd3fk2mHJEkwWh1obLahodnmeTbb0eBcNlrscoaOVX6YbA40W+V1JqsDZqsDZrsIUZIgihIkCfKy89nzuvUgSVtc43SE2SbCbBNRB1vnD9RDXOXcVAoBGpXCr8ybSqGAWqWA2lkaTi4LJ5eN86xX+JSLU6sEqBUKr/1bjiOvCwtSIyJIjQi9BhFBaoTqVH41c4mIiIiIaHAz2xz47cdHAADTMqOwp6AWH+wvwajEMPxsVuvVG0hWXGvC81+dxDcnq9DQ7Pm/o1IhICc9EhWNFhRUG3H3Owfw32XT/BrWt+Xjg6UorDEhOliDO2akd3mOE4dEYuKQSPzph9lQOu8xdMSModHIigtxB46SI4IwaUhkl+fREYIg4JWfTMK3p6owKjEM6dH6fgv6JYTrMHdEHLbkVwKQy8cTEVHPYLCFqB2CILgzM5I6mcHTVZJXIMY3GOMMzoi+wRnv/ZUKOcNFgG85Mghy2bdmqwNmZ+m2Zqv87Hktel5b5UBRs80BpQLQKJXQqhXQqhTQqBTQqpRQCIDJ6kCTxY4msx1NFjsMZjuaLDYYLQ6f12ab6D4/q0OEV8+/ficIcAdqXD1/VK5nZ1BI7R0IUvr29lG16BHkHfTx3u49tt97Ao7tu817TL/5OMfTKNlbiIiIiIjoxU2nUFhjQkKYDq/dNgVr9hbjTxtO4M+fn8Dw+FDMyuqd/hz9QXJ+8a6n/h9gstpx5xt7ccYZjIjQqzFvRBzmj4zD7KxYhOvVKKg24trVO7CvqA5/2nAcf7hubIfGttpFvLRZzmr51ZyhCNZ2/7ZUSCfHEAQBt89Ix+/WHgUAXDshqU/KbQdrVbgqO7HXj9MRN05JxZb8SsSHaREfpu3v6RARXTQYbCEagARBgFIAlLh4bprbHSKMFgcsDodcAs4hOUuRiZ5lhwS7Q4TNWR7O7iwhZ3Nus4mic73ktd57f3mdZ3/fcSx2BwxmO+pNckaSqz6vJA28AFBXKRUC9BolgjUq6LVyHyG9Ri7fFnh/BcJ0ci+iUJ0KYTq5F1GIVgmFIAeIlILc60d+hv96hdBiHfzep3T2C1I591crFFB6BbK8+w9Jkqecn12U4HBIsIsiFIKcCSVnQ7EcHREREREFdrS0Af+3vQAA8KclYxGqU+PnszJw4oIBHx0owT3/PYBP75nZ483H2yNJErbkV0KrUnY62GO2OXCsrBEldSaU1jejpK4ZpXXN7tcRQRq8cNN4zBja/SDSH9Yfx5nKJsSFarHqlomYnBbpVw0gIyYYK2+agJ+/uQ9v7SpCdnI4fjwltd2xP9hfjJK6ZsSGavHTaR0r+9Ubrp+UjBVfnURjsw1LJiT32zz6y8Ix8Vh+zWiMSAjl/6uIiHqQIEkdrD10kWtsbER4eDgaGhoQFhbW39Mhoj5gc4hoMtthE0V3AMi1bHP2pHH1DPLe5grw2L2CQK4eQnaHJ+jT9nu8x275ngBjO/fx3s8VRLpYqJUCRAlwdKCWniDIPaO0Sjn4IgiujC55m0IQnMuCe3/vjC/BuR3u9zjXQ3C/P1SnQoRejYggDSL0aoTr1QgPkl+H6lTuwI/W+XBlf6mVCr/AlCBAXucMQBERERFR77A5RFy3+jscv9CIxeMSsfrWSe5tZpsDN/9zNw4V1yMrLgQf3z0DoZ3oF+JytqoJT607hrRoPX59+XDEhrafGVBW34zffnIEW0/KPTvuvzwLDy7I6tCN7uNljVj21j6U1je3uZ9GqcCqWydi4ZiEjp1IAOvyynD/uwchCMA7v5jabvBm5aZTWLnpNDQqBT781XSMS4lodd8mix0/eOFbXGgwY/k1o3HnzP4t53a6woBaoxVTMwd6cXMiIupPnYkbMNjixGALEQ1G3lkgVmeZOKPFDpOzDJzRaofRYm81gGFzSDCYbWhstqPRLPckajTbYLI64BDlsUXnMRwSIHqtc613BUi893W/x3u717pLnUKAMwjjzAASAIVXhpB3CUB3sMa53bXN/X6FZ1+/cRW+47Q9ru/7tSoFgjRK6NVKBGnkHlt6jRJBaiU0KoVXzykJDp/Shp7XLbcBcPdg0qgU0Hj1ZJLHlGC1i7DYRVhdD4dcglDOupKzr0Kd2VhhOnWn6oN3hCRJsNhFaJQKBsaIiIgGob9vPYu/bsxHhF6NTQ/NQUyIbyCkotGMa1btQKXBggWj4vHPpZM79Xf+Nycrcf9/D8LgzJIP0apwz7xhuHNmesCeIZIk4d09xXj68xNostihUgiwO/89/MOJyfjLj7KhVbXea+SLIxfw0Pt5aLY5EKlXIys+FCmRQUiJCEJKpB7JkUFICNfh2Y35+PJYBRQC8JcfjcONHcgyaamoxoirX9qBJosd988fhoeuGNHue0RRwl1v78OmE5VICtdh/X2zEN3iMzfbHHjn+/P4+9YzqG6yIjFch28entvhHitERET9icGWLmCwhYiob3gHiGwOEQ5nWTi7KLpLjqm8yoy5So+JEtw34C0Oh8/NeFEEJMj9jeRjeF6LkgTJuQ7Oda7XknOb6FzpWm8XRbnkXLMcgKo3WVFvsqG+2YYGkw0Gix1Wu8MTFHCI7iABg0l9S6P0ZBh5ZxvJwRyF3LPKyfsnI0ny76DJ6vDtZWVzQJLkoFNMiAZxoTrEhWoRF6ZFbIgWsWE6ROrVXv2yvAJKovz71GpfJWe/Jt/eTvI+GpUCwc7+YEoGeYiIiHyYbQ58eawc+eUGLBgVh8lpUQH3K6g24sqV22Cxi1jx4/G4YXJKwP0OFdfjxld3wWoXcd/8YfhNB4IKkiThn9vO4S8b8yFJwKQhEXCIEvJKGgAAqVFB+O2iUbhybII7W+V8jQmPfXwYO8/WAAAmDonAczeMw77COjyx9igcooTcjCj8c+lkROg1PscTRQkvbTmNlZvk/iaXZcVg9S2TEK4PnIljd4h44pOjWLOvGADwxFWjsGx2Zrvn5WK1i7jhHztxuKQBuelR+O+yqX6lw1rTaLZhyervcK7aiOmZ0Xj757lQKRWwOUS8v68YqzafQXmjGQCQFq3HczeMR25G4J8hERHRQMNgSxcw2EJERD1BdGbxyDff5ZvwDkmCJMJrvTPjx73syQCSnPuLXhkhrgwh13sdkhw08s4yEp3jt5Vp4n1cV9BLPqbv3BwiYHXI2VFmmxyMMFnlQITZJgeZXL2lXKXR/DJuAmwD5Gwqq0Puv+TqsWRxBqyUXn155ICJElqVApIkodFsR2OzDQbXs/PbpBejILUSIToVQrUqdwAmROd8brEcpFF6lc3zlMsDPOX2VAoBapXCL8CjcmYWuYJDrgCRQhBgd8g/E1d/LFdQUf65Se6fm+tnaHOIsDok6NVKudyeXn6EBcnl91r7xq7k/F0WhJ5r6ktERBcHSZJwtLQR7+8rxqeHStFo9vzdP3FIBJZdlomFYxLcX1IQRQm3vLYb3xfU4rKsGLz1s9w2/275+EAJHno/DwBw3/xhuCV3CJIiggLua7Y58NhHh7H2UBkA4JbcVPz+2rFQKQSsPVSKv27MR0WjBQCQmxGF3109CgeK6vDXjSfRbHNAp1bgkYUjcceMdPd8t5+uwt3/OQCDxY7M2GC8fkcO0qLlHjImqx2/eT8PXxwtBwD8bGYGfnvVyHaDH5Ik4S9f5OPVbecAAP9v7lA8unBEh/6O/fOG43htewEi9Gp8fv9lrX4WrTldYcCSl7+D0erAz2ZmYGxyGFZuOo3ztSYAQGK4DvdfnoUbJqdA3cEgDhER0UDAYEsXMNhCREQ0eDhECU1mO5qsdk+Wk12Exe5wZxlZ7CJ881k8QQhAzorROcukuUqk6dRK6NQKGC0OVBksqDSYUWmwoLLRgqomMyobLahvtrlLrrUs0wYIsLfo/WR3Bi3c693bPessdsdF1YOppSC1EgrBFdSDT9AQkH8WYUEqhOrUCPMqExcWpIJeo/LLWJJ7JSkDZjNp1UpolHIZvFCdCqE6VZvlWVwkSUKzzQGbXYJaJUCrUjLLiIhaZbTY8d2ZapypasLoxDBMTovsUu+PlvYX1WLTiUqMiA/FD0bHI1ir6oHZtq6w2oh/7ShAYY3RXYa22Wp3Z36anKWrJqdFIic9CrkZURidGNbhjIeuqDNa8cnBUry/rxj55Qb3+uSIIIxLCcfmE5XuMqOpUUH42cwM/HhKKtYdKsNvPzmCILUSXz04G6lR+naP5QowAPK/D2YNi8ENk1NwxegEBGnkvzsuNDTjl2/vx+GSBigVApZfMxpLp6X5BDBMVjte/fYcXt12Fmab6HOMqRlR+OuPxiE9Jtjv+PnljfjZ63tR1mBGVLAGr902BfFhWix7az9OXGiEWingz0uycWNO50qC/ePbs/jLF/kA5MDQn5Zkt/l32jf5lbjzjb0AgNdum4IfjI7v1PFcvjhyAf/vnQM+62JCNLh77jDcOnUIy4YREdGgxGBLFzDYQkRERP3JYnfAaHHIQSSL62FDk3udZ9no3G602r1K48n/pHOV0RNFuSSeT6DHGQCy2UXYnIEg7wCQq4a8UiFnwKiVcgDD1VfHvU6l8Gxz9t9RKgSYrA659F6zDQ3Ox0D4l6ZGqXAHXkJ0KqiVCnfGlsl1U9FZQs6bSiH4lakDXGUIPaUIW5Ys9Kz3rAvRqhAZrEZEkAbhejUinBlAoTo1msx21JqsqDdZUWe0oc5kRZ2zfGF0sAaZsSHIjA1GRkywvBwTjKSIIPeNM1evIbPNAbPN+Wz3Wnaut9jlZZ1aidQoPdKi9IgK1gzIrCKbQ0SzzYFQrWpAzm+gMFntqGi0oKLRjIpGOSAMAFeNS0RyJ7+VTu0rrjVhS34lNudXYve5GljtnpvqCgEYlRiG3Iwo5KZHIScjyq9XSGscooQvj5Xjte3ncPB8vXu9Tq3A5aPice34JMwdEduhwHFHFVYbsWrLGaw9VNrpEqh6jRKThkRiSnokhkTp5VKrJivqm22ocy7Xmayw2ET3NdQVINeq5KC4QpCzRUzepTyt8rWq0mB2fwFBo1LgyjEJuHFKKmYMjYZCIaDSYMbbu4rwn91FqDPZAAChOhVEUYLR6sDvrh6FX1zWsfJZoijh07xSrNlbjN3nat3rQ7UqLB6fiNyMKDz9eT6qDBZE6tV4+SeT2mwYX1bfjGc35mPtoTIEa5R47KpR+EnukDZ7wlQ0mvHzN/fiaGkjNCoFQrQq1BqtiAnR4B8/nYwp6V0rt/XenvP47SdHIErAFaPjcfuMdIxLCfcLCpY3mHHVS9tRa7TijhnpeOraMV06nsuzG/PxytazCA9S45dzMnHHjHToNb0bNCQiIupNDLZ0AYMtREREdKmTnJknPZXRIYqSXPrNbIMoSe7SckrBWV7OmR3UbHP4lIlrNNvcr/2zl1r2SnL4rHeVpWu2OtB0EZeb06gUCFIr3aX9uipEq3IHXoZE6xGmUzlvesrBDotXPyOrsy+VK7gkl0n0BPq8A3OuTCPXs1olQKNUyllDXgE7QQBqmqyoMlhQ1WSRnw0W1Jqs7iBVSmQQUqP0SI3UIzUqCKmReiSE69DYbJMzzwxykKHS+d46kxVhQWrEh+mQEKZFfJgOcWE6JITpEBuqhShJPsE271KJrhud7hJ+rtJ9GjlY15Em2o1mG85UNuFMRRPOVjXBYhcRrFVCr5HH02uU8rNWhYggNWJDtYgN1bZaVsfmEFFQbUR+uQEnyxtxsrwJhTVGVDSaYTAH/h1XCMD8kfH4ybQhmJMV26nm3xcLi92B/AsGHC6px+GSBhwpbUCN0epTojFYK/9cXT8fV684lVLhDjorFQpUGsz4Jr8SpyqafI4xJEqP7ORwHCltcJdK8pYZE4xxKeEYmxyO7ORwjE4K87nRbbTY8cG+YvzruwIU1zYDkP8cLRgdh+NljSis8YwZqlPhyjEJuGZ8ErKTwxGhV3cpEFlQbcSqLaex9mApXDGWeSNisXhcEoKdv596jSvrU4UgtRIldSbsLazD3sJa7Cus9Snn1Vuyk8Nx45QUXDs+udUeJc1WBz46UIJ/7ShAQbURADA+JRwf3z2zS3+PFdea8NGBEnx0oMT983AZmRCK126b0qFsGQA4V9WEsCB1hwNuRosdv37vIDadqAQAjE4Mw2u3T+l20PSLIxfw6/cOuTOBBAHIigvBhNQITEiNxITUCPzhs2PYfa4WY5LC8PHdM7od1JMkCYeK6zE0LgRhPZDtRURE1N8YbOkCBluIiIiILi4OUYLRaofBbIfBbEOTWV62OUT5JqJGKd9kVXuW1c6Gvu5ydM6MEE9pOvlGtuAMGAkQfPrlCM4eRfJrVy8aOehU32xDg/tb33LmT6PZhlCtChF6DaKCNYjQqxEVrEGkXoMwnRpVTWacqzLiXLUR56qaUFBtRGG1yX3jrCWlQoBOpXCWxFNCq1ZAp5JvnOqcywaLHcW1JlxoMPfdD+MioBCAqGANooO18nOIBtHBGkQFa1FnsuJMZRNOVxrcfRs6KypYgzhn4CUuVAe7KOJkuQFnq5raLDOo1yjdgaT4MB0qDWafb+inRgXh1tw03DglBdHt3Pi1O0SU1jejqMaEoloTiqqNKKo14UJDM2JDtO4sq8wY+TkuVNupG/6SJKHOZENRjRHna01oaLbJWXoWu5zZZ/Fk7gVrvAJtziBbcmSQ+xvyoiihzmRFjdGKaoMF1c7nM1VNOFxSj5Plhh4vz6hUCJiSFonLR8Vh/sh4DI0Ndp9/RaMZewpqsbewFnsKanGywuCXLScIQEZ0MMYmhyNSr8YnBz19SCL0aiydloal09MQF6qDJEk4UtqA9XllWJ93wd1c3EWjVCA2VIuYUC3i3A8dQnUqd7AkyKtUpiQB/91z3i/I8usFwzEhNaLDn4EoSjhVaZCDLwW1qDFaEKHXIFKvRqRegwi9BhFBakQGq6FTK30C5Ravkp8OUfLMUa2Ezrms1ygRqdd0OKjhmtPm/Ep8d6YaP5+V0an3tjbensJafLi/BF8eLcecEbH464/G9XpJN4co4R/fnkVDsw0PLMjqsWyQ/UW1eP27QhwqrkdJXXPAffQaJT67bxYyY0N65JhEREQXEwZbuoDBFiIiIiIaDByihLL6ZljsDmhVnl5DOrWyU02HzTYHSupMOF9rkm+u15jQbHXIN0AD3ARVKwWfXkUKZ2BJoYC7bJ3rZqrNIcFqd8Dq7FlksYvuIJbVa1mUJEQFuwIMWneWR2yoFnqNEmX1zSiubUZxnQnFtSb3ckWjBeFBKsSF6hAX5rnRHBemRaReg4Zmm7u0VrlXma0qgwVKheD89r7KfXPXdb42hwijxQGD103/Jovdp1xURySE6TAsLgTD4kIQolW5gwgmZ8aVyWpHk8WBepOc1WNvp4xTiFaF4fEhGJEQhpEJoRgWF4KEcB3iw3QICXAD+ExlE975vggf7S9x38zXKBWYPTwWWrUCFpucAWZxZkZZ7SKaLHaU1Te3O5eW80qP0SNSr0GwRgW91pm1o1Eh2Pm5VjVZcL5G/j07X2OCoZsZZzEhGgAC6kzWdstfRerVGJcSgXEpcmZJUkSQHNhxBmGNFgeMFjsMFjvMNgdsDjl7y+aQ4PAqr6hTKzArKxZzsmJbzbJoqcFkw4HiOhx1ZtUcLW1AWYAAZ0ZMMH42KwM3TEpx9whpSRQl7C2sxbq8Mnx9vAKVhq4F9Fzmj4zDry/PwvhOBFno4lBlsOBQcT0Onq/DoWI568tktePFmybgugnJ/T09IiKiAYnBli5gsIWIiIiIiAKx2kXUm6yobrKi1mhFjdGCmib5udZoRahO7Q6uDOtk6RxXhoZcEk0uhVZpkG/KD48LxYiEUKREBnWpZFSz1YH1eWX4z/dFOFzS0KH3aFUKDInSIy1aj7ToYKRF65EYHoSKRjnLqqC6CeeqjSiuNaGTrT7c4sO0SIsKRnSIxqdkm7ysRLBWhcZmG4rrmlFca0JJnRxkC1Q2LUIvl2qKDtYgJlSLlMggjEuWAyxd/dx6S02TBUdKG3CsrBEldSbMGxGHBaPiO13mzWJ3uEvuef/eVBnMaLLIDe6bbQ53k3tXP5RxKRG4b/4wBlnIzSFKaLLYER7Ecl9EREStYbClCxhsISIiIiKii9XhknrsKaiFSiFAq1ZCo1RAq1Y4n+UMn5TIIMSH6jp0899qF3G+Vi5r12i2wWiVs0RMFjlrx2S1w2h1IEqvxpDoYKQ5AzipUXro1F3rCdFgsqG4Tu5jEhsql3PrTDYXEREREVFnMdjSBQy2EBERERERERERERGRS2fiBvwaEBERERERERERERERUTcw2EJERERERERERERERNQNDLYQERERERERERERERF1A4MtRERERERERERERERE3cBgCxERERERERERERERUTcw2EJERERERERERERERNQNDLYQERERERERERERERF1A4MtRERERERERERERERE3cBgCxERERERERERERERUTcw2EJERERERERERERERNQNDLYQERERERERERERERF1A4MtRERERERERERERERE3cBgCxERERERERERERERUTcw2EJERERERERERERERNQNqv6ewEAhSRIAoLGxsZ9nQkRERERERERERERE/c0VL3DFD9rCYIuTwWAAAKSmpvbzTIiIiIiIiIiIiIiIaKAwGAwIDw9vcx9B6khI5hIgiiLKysoQGhoKQRC6NEZOTg727t3bY3PqyfG6M1ZjYyNSU1NRXFyMsLCwHpkP9Y6e/h0cTAbbuQ+U+fb1PHr7eLwOU38bKH+2+8NgO/eBMl9eh/tuTF6HLw0D5c92fxhs5z5Q5svrcN+NyevwpWGg/NnuD4Pt3AfKfHkd7rsxeR3uGkmSYDAYkJSUBIWi7a4szGxxUigUSElJ6dYYSqWyR3/ZenK8nhgrLCzskvvDNNj09O/gYDLYzn2gzLev59Hbx+N1mPrbQPmz3R8G27kPlPnyOtx3Y/I6fGkYKH+2+8NgO/eBMl9eh/tuTF6HLw0D5c92fxhs5z5Q5svrcN+Nyetw17WX0eLSdiiGOuWee+4ZsOP19NxoYLqUf86D7dwHynz7eh69fTxeh6m/Xco/58F27gNlvrwO992YA+VnTr3rUv45D7ZzHyjz5XW478YcKD9z6l2X8s95sJ37QJkvr8N9N+ZA+ZlfzFhGjNrV2NiI8PBwNDQ0XJKRSyKi/sbrMBFR/+J1mIiof/E6TETUv3gd7hhmtlC7tFotli9fDq1W299TISK6JPE6TETUv3gdJiLqX7wOExH1L16HO4aZLURERERERERERERERN3AzBYiIiIiIiIiIiIiIqJuYLCFiIiIiIiIiIiIiIioGxhsISIiIiIiIiIiIiIi6gYGW4iIiIiIiIiIiIiIiLqBwRYiIiIiIiIiIiIiIqJuYLCFelR6ejrGjRuHCRMmYN68ef09HSKiS5LJZEJaWhoefvjh/p4KEdElpb6+HlOmTMGECRMwduxYvPbaa/09JSKiS0pxcTHmzp2L0aNHY9y4cfjggw/6e0pERJecH/7wh4iMjMQNN9zQ31Ppc4IkSVJ/T4IuHunp6Th69ChCQkL6eypERJesJ554AmfOnEFqaipWrFjR39MhIrpkOBwOWCwW6PV6GI1GjB07Fvv27UN0dHR/T42I6JJw4cIFVFRUYMKECSgvL8fkyZNx6tQpBAcH9/fUiIguGVu3boXBYMCbb76JDz/8sL+n06eY2UJERHQROX36NPLz87Fo0aL+ngoR0SVHqVRCr9cDACwWCyRJAr/bRkTUdxITEzFhwgQAQEJCAmJiYlBbW9u/kyIiusTMnTsXoaGh/T2NfsFgyyVk27ZtuOaaa5CUlARBELB27Vq/fV5++WWkp6dDp9Nh6tSp2LNnT6eOIQgC5syZg5ycHLzzzjs9NHMiootDX1yHH374YTzzzDM9NGMiootLX1yH6+vrMX78eKSkpOCRRx5BTExMD82eiGjw64vrsMv+/fvhcDiQmprazVkTEV08+vI6fClisOUSYjQaMX78eLz88ssBt69ZswYPPfQQli9fjgMHDmD8+PFYuHAhKisr3fu46k+3fJSVlQEAduzYgf3792PdunV4+umncfjw4T45NyKiwaC3r8Offvophg8fjuHDh/fVKRERDSp98e/hiIgI5OXloaCgAP/9739RUVHRJ+dGRDQY9MV1GABqa2tx22234Z///GevnxMR0WDSV9fhSxV7tlyiBEHAJ598giVLlrjXTZ06FTk5OVi9ejUAQBRFpKam4r777sNjjz3W6WM88sgjGDNmDO64444emjUR0cWjN67Djz/+OP7zn/9AqVSiqakJNpsNv/nNb/Dkk0/21mkQEQ1affHv4bvvvhvz58+/JJuDEhG1p7euwxaLBT/4wQ+wbNkyLF26tDemTkR0UejNfw9v3boVq1evZs8WujRZrVbs378fCxYscK9TKBRYsGABdu3a1aExjEYjDAYDAKCpqQlbtmzBmDFjemW+REQXm564Dj/zzDMoLi5GYWEhVqxYgWXLljHQQkTUQT1xHa6oqHD/e7ihoQHbtm3DiBEjemW+REQXm564DkuShDvuuAPz589noIWIqJN64jp8qVP19wRoYKiurobD4UB8fLzP+vj4eOTn53dojIqKCvzwhz8EADgcDixbtgw5OTk9PlciootRT1yHiYio63riOlxUVIS77roLkiRBkiTcd999yM7O7o3pEhFddHriOvzdd99hzZo1GDdunLsPwdtvv81rMRFRB/TUfYkFCxYgLy8PRqMRKSkp+OCDDzB9+vSenu6AxGAL9ZjMzEzk5eX19zSIiAhgCUcion6Qm5uLQ4cO9fc0iIguWbNmzYIoiv09DSKiS9qmTZv6ewr9hmXECAAQExMDpVLp18CzoqICCQkJ/TQrIqJLB6/DRET9i9dhIqL+xeswEVH/4nW4+xhsIQCARqPB5MmTsXnzZvc6URSxefPmSybNi4ioP/E6TETUv3gdJiLqX7wOExH1L16Hu49lxC4hTU1NOHPmjPt1QUEBDh06hKioKAwZMgQPPfQQbr/9dkyZMgW5ublYuXIljEYj7rzzzn6cNRHRxYPXYSKi/sXrMBFR/+J1mIiof/E63LsESZKk/p4E9Y2tW7di3rx5futvv/12vPHGGwCA1atX47nnnkN5eTkmTJiAl156CVOnTu3jmRIRXZx4HSYi6l+8DhMR9S9eh4mI+hevw72LwRYiIiIiIiIiIiIiIqJuYM8WIiIiIiIiIiIiIiKibmCwhYiIiIiIiIiIiIiIqBsYbCEiIiIiIiIiIiIiIuoGBluIiIiIiIiIiIiIiIi6gcEWIiIiIiIiIiIiIiKibmCwhYiIiIiIiIiIiIiIqBsYbCEiIiIiIiIiIiIiIuoGBluIiIiIiIiIiIiIiIi6gcEWIiIiIiIiIiIiIiKibmCwhYiIiIiI+sXWrVshCAKeeuqp/p7KReeNN96AIAh44403fNYLgoC5c+f2yRz48yUiIiKiS4mqvydARERERET+BEHo1P6SJPXSTIiIiIiIiKg9DLYQEREREQ1Ay5cv91u3cuVKNDQ0BNxG1BEnTpyAXq/vk2Pl5ubixIkTiImJ6ZPjERERERH1JwZbiIiIiIgGoECll9544w00NDSwLBN12ciRI/vsWHq9vk+PR0RERETUn9izhYiIiIhoECsrK8Py5csxbdo0xMXFQavVIj09HXfffTcqKyv99m9oaMCTTz6J0aNHIyQkBGFhYRg2bBhuv/12FBUVdXnctjQ3N+Oxxx5DamoqdDodxo4di9dee63N9xQUFOAXv/gFhgwZAq1Wi8TERNxxxx0+c2zP/v37ce+992Ls2LEIDw9HUFAQsrOz8Ze//AU2m81v//T0dKSnp6O+vh6//OUvkZCQAJ1Oh4kTJ+Ldd9/12/+pp56CIAjYunUr3njjDUyaNAl6vd6nJ4rBYMDy5csxZswYBAUFISIiAgsXLsSOHTv8xps7dy4EQYDNZsNTTz2F9PR0aLVaDB8+HK+88krAc6ytrcWvfvUrxMfHQ6/XIycnB5988kmrn0nLni2uviptPQoLCwEAVqsVq1atwsKFC5GamgqtVou4uDhcf/31OHjwoN+x2urZUllZiQcffBDDhg2DVqtFTEwMfvSjH+Ho0aOtzp2IiIiIaCBjZgsRERER0SC2bds2PP/887j88ssxdepUqNVqHDx4EH//+9/x5Zdf4sCBAwgPDwcg93VZuHAhvv/+e8ycORNXXnklFAoFioqKsG7dOixduhRpaWmdHrctoiji2muvxaZNm5CdnY1bb70VNTU1ePDBBzFv3ryA7/n++++xcOFCGI1GLF68GFlZWSgsLMQ777yDL774Art27UJmZma7x37ttdewfv16zJ49G1dddRVMJhO2bt2Kxx9/HHv37sVHH33k9x6r1YoFCxagqakJS5cuhdFoxPvvv49bb70V1dXVuO+++/ze89xzz+Gbb77BddddhyuuuAJKpRKAHAiZPXs2jh07hpkzZ+JXv/oVGhsb8emnn2LevHn44IMPsGTJEr/xbrnlFuzZsweLFi2CUqnE+++/j3vuuQdqtRrLli1z72cymTB37lwcOXIE06dPx5w5c1BcXIybbroJV1xxRbufDyAHmAKVpWtqasKLL74IANDpdO7zeeCBB3DZZZfhqquuQmRkJM6dO4d169bhiy++wLZt25CTk9PuMc+ePYu5c+eipKQEV1xxBZYsWYLKykp89NFH+PLLL7F582ZMnTq1Q/MnIiIiIhowJCIiIiIiGhTS0tKklv+Er6iokAwGg9++b775pgRA+tOf/uRed/jwYQmAtGTJEr/9zWazzzidGbctr7/+ugRAuvLKKyW73e4zF41GIwGQli9f7l5vtVql9PR0KTQ0VDpw4IDPWNu3b5eUSqW0ePHiDh27qKjI55iSJEmiKEo/+9nPJADSjh07fLa5Pt/Zs2dLFovFvb64uFiKiYmRtFqtVFJS4l6/fPlyCYAUHBwsHT582O/4t956qwRAeu2113zWV1RUSKmpqVJsbKzU3NzsXj9nzhwJgDR16lSpoaHBvT4/P19SqVTSiBEjfMZxHX/ZsmU+6zdu3CgBkABIr7/+us82ANKcOXMCfFoeDodDWrx4sQRAev75593rzWazz/m7HD16VAoJCZEWLFjgs/6bb77x+/lKkiTNmDFDUiqV0saNG33Wnzx5UgoNDZWys7PbnB8RERER0UDEMmJERERERINYXFwcQkJC/NYvXboUYWFh2LRpk9+2oKAgv3VardZnnK6MG8hbb70FAPjzn//szvgAgOzsbCxdutRv/88++wyFhYV45JFHMHHiRJ9ts2bNwnXXXYfPP/8cjY2N7R57yJAhPscE5DJa99xzDwC0eg5PP/00NBqN+3VKSgp+/etfw2Kx4L333vPb/6677kJ2drbPuurqaqxZswbz58/HL37xC59tcXFxeOSRR1BVVRVwDs888wzCwsLcr0eMGIGZM2fi5MmTMBgM7vVvvfUWNBoN/vCHP/i8f+HChbj88ssDnltHPPjgg/jss8/wy1/+Eg899JB7vVarRXJyst/+Y8aMwbx587Bt27aA5dm8HTx4EDt37sTtt9+OhQsX+mwbPnw4li1bhiNHjrCcGBERERENOiwjRkREREQ0yH388cd49dVXceDAAdTV1cHhcLi3lZWVuZdHjRqFcePG4d1330VJSQmWLFmCuXPnYsKECVAo/L+H1dFx25KXl4fg4GBMmjTJb9tll12Gf/3rXz7rdu/eDQA4efJkwF4f5eXlEEURp06dwpQpU9o8ttVqxerVq/Hee+8hPz8fTU1NkCSpzXNQqVSYPn16wLkCCNibJDc312/d3r174XA4YLFYAp7H6dOnAQD5+flYvHixz7bJkyf77Z+SkgIAqK+vR2hoKBobG1FQUIDRo0cjISEh4Hw3b97st749r7zyCl566SX84Ac/wOrVq/22Hzp0CM8++yx27NiB8vJyv+BKdXU1EhMTWx3f9fOtqKgI+Lnk5+e7n8eOHdvp+RMRERER9RcGW4iIiIiIBrHnn38eDz/8MGJjY3HFFVcgJSXFnbmycuVKWCwW974qlQpbtmzBU089hY8++gi/+c1vAACxsbG499578cQTT7gzQTozblsaGhqQmpoacFt8fLzfutraWgDAO++80+a4RqOx3WPfcMMNWL9+PYYPH46bbroJcXFxUKvVqK+vx9/+9reA5xATExMw8OSaa0NDQ6fO47vvvsN3333XqfPwzmpxUank/7q5Al6uzJ64uLiA4waaU3s2btyI+++/H6NGjcIHH3zgPqbLzp07MX/+fADAFVdcgaysLISEhEAQBKxduxZ5eXnt/l64PpcNGzZgw4YNre7XkZ8vEREREdFAwmALEREREdEgZbfb8cc//hGJiYk4dOiQz413SZLw7LPP+r0nOjoaq1atwksvvYT8/Hxs2bIFq1atwvLly6FWq/H44493adzWhIeHo6qqKuC2iooKv3WuQMP69ev9Mj46Y+/evVi/fj0WLlyIDRs2+JQT2717N/72t78FfF91dTVEUfQLuLjmGh4e7vceQRBaPY/f/OY3WLFiRZfPozWu8SsrKwNuD/TZtuXo0aO46aabEBUVhQ0bNgQ8zz//+c+wWCzYvn07Zs2a5bNt9+7dyMvL6/C8V61ahXvvvbdTcyQiIiIiGsjYs4WIiIiIaJCqrq5GQ0MDpk+f7pfhsG/fPjQ3N7f6XkEQMGrUKNxzzz34+uuvAQDr1q3r9rgtjR8/HkajEQcOHPDbtn37dr91U6dOBQDs2rWrw8cI5OzZswCAq6++2q9vS6Djutjt9oDHdr2nZR+Z1uTk5EAQhG6fR2vCwsKQkZGBM2fOoLy83G97W+fYUkVFBRYvXgyLxYK1a9ciIyMj4H5nz55FVFSUX6DFZDIF/PkG0lM/XyIiIiKigYbBFiIiIiKiQSouLg5BQUE4cOAATCaTe31dXR3uu+8+v/0LCwtRWFjot96VBaHT6bo0bluWLl0KAHjiiSd8er4cOXIEb7/9tt/+1113HYYMGYIXXngB27Zt89tus9mwY8eOdo+blpYGAH77Hjt2DM8880yb7/3tb38Lq9Xqfl1SUoK//e1v0Gq1uPnmm9s9NgAkJCTgxhtvxM6dO/Hcc8/59Ipx+f77730+385aunQprFYrnnzySZ/1X331VYf7tTQ3N+Paa69FUVER/v3vf2PGjBmt7puWloa6ujocO3bMvc7hcODhhx9uNXuppdzcXEydOhXvvvsu1qxZ47ddFEV8++23HRqLiIiIiGggYRkxIiIiIqJBSqFQ4O6778bzzz+P8ePH45prrkFjYyO++OILpKWlISkpyWf/Q4cO4frrr0dubq67sXppaSnWrl0LhUKBBx98sEvjtuX222/Hf//7X2zcuBETJ07EokWLUFtbi3fffRdXXHEFPvvsM5/9tVotPvzwQyxatAhz5szB/PnzkZ2dDUEQUFRUhO3btyM6OtrdSL01ubm5yM3Nxfvvv48LFy5g2rRpOH/+PNatW4err74aH374YcD3JSYmwmg0Yty4cbjmmmtgNBrx/vvvo6amBi+99BKSk5M7fO6vvPIKTp48iUcffRRvv/02pk+fjoiICBQXF2Pfvn04ffo0Lly4AL1e3+ExvT366KP4+OOP8dprr+HYsWOYPXs2iouL8f777+Pqq69usyeKy6pVq7Bnzx4MGzYMp06dCti0/oEHHkBERATuu+8+fPXVV5g1axZuvPFG6HQ6bN26FaWlpZg7dy62bt3aoXm/++67mDdvHm6++WasXLkSkyZNQlBQEM6fP49du3ahqqoKZrO5k58GEREREVH/YrCFiIiIiGgQe+aZZxAVFYU33ngDr7zyCuLj43HLLbfgqaeewtixY332nTJlCv7nf/4HW7duxYYNG1BfX4+EhAQsWLAAjzzyCKZNm9alcduiUCjw6aef4ve//z3eeecd/O1vf8PQoUPx4osvIisryy/YAsgluPLy8vDcc8/h888/x3fffQetVovk5GQsWbIEt9xyS7vHVSqV+Oyzz/DYY49h48aN2Lt3L7KysrBixQosWrSo1WCLRqPB119/jcceewxvv/026uvrMXLkSKxatapDx/UWFRWFnTt3YvXq1VizZg3eeecdiKKIhIQEjB8/Hv/7v/+LmJiYTo3pLTg4GN9++y0ef/xxfPLJJzhw4ADGjBmDNWvWoKGhoUPBFldmzZkzZ/D73/8+4D533HEHIiIisHjxYnz44Yd4+umn8Z///Ad6vR7z58/HJ598gj/84Q8dnndGRgYOHjyIF154AWvXrsXrr78OpVKJxMREzJ49GzfccEOHxyIiIiIiGigEKVA+OxERERER0SUmPT0dAAKWWqPO27hxIxYtWoSnn34ajz/+eH9Ph4iIiIioV7FnCxEREREREfW4M2fOAABSUlL6eSZERERERL2PZcSIiIiIiIiox+zZswdr1qzBG2+8Ab1ej4ULF/b3lIiIiIiIeh0zW4iIiIiIiKjH7Ny5E6+++iqysrLw5ZdfIi4urr+nRERERETU69izhYiIiIiIiIiIiIiIqBuY2UJERERERERERERERNQNDLYQERERERERERERERF1A4MtRERERERERERERERE3cBgCxERERERERERERERUTcw2EJERERERERERERERNQNDLYQERERERERERERERF1A4MtRERERERERERERERE3cBgCxERERERERERERERUTf8fzAd7G4tu+obAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 2000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "d = pd.read_excel('..\\\\resultados.xlsx', sheet_name='learning rates', usecols='B:D')\n",
    "d.columns = ['Tasa de aprendizaje', 'Entrenamiento', 'Validacin']\n",
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "sns.lineplot(data=pd.melt(d, ['Tasa de aprendizaje'], var_name='Etapa'), x='Tasa de aprendizaje', y='value', hue='Etapa')\n",
    "plt.xscale('log')\n",
    "plt.ylabel('Funcin de prdida', fontsize=14)\n",
    "plt.xlabel('Tasa de aprendizaje', fontsize=14)\n",
    "#plt.legend(['asd', 'da'])\n",
    "#sns.lineplot(data=d, x='Learning Rate', y='Validation Loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "sns.lineplot(data=pd.melt(d, ['Learning Rate']), x='Learning Rate', y='value', hue='variable')\n",
    "plt.xscale('log')\n",
    "plt.ylim([0,0.2])\n",
    "#plt.axhline(0.075)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.063204</td>\n",
       "      <td>0.072708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.062265</td>\n",
       "      <td>0.072777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.061100</td>\n",
       "      <td>0.072938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.060126</td>\n",
       "      <td>0.073151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.059590</td>\n",
       "      <td>0.073328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.059379</td>\n",
       "      <td>0.073486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.059111</td>\n",
       "      <td>0.073596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.058949</td>\n",
       "      <td>0.073716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.058936</td>\n",
       "      <td>0.073739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.058671</td>\n",
       "      <td>0.073979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.057615</td>\n",
       "      <td>0.073970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.057043</td>\n",
       "      <td>0.073810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.056934</td>\n",
       "      <td>0.073627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.056855</td>\n",
       "      <td>0.073632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.056887</td>\n",
       "      <td>0.073544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.056669</td>\n",
       "      <td>0.073600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.056755</td>\n",
       "      <td>0.073575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.056232</td>\n",
       "      <td>0.073709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.055855</td>\n",
       "      <td>0.073539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.056173</td>\n",
       "      <td>0.073384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.055531</td>\n",
       "      <td>0.073554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.055088</td>\n",
       "      <td>0.073579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.054647</td>\n",
       "      <td>0.073519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.054453</td>\n",
       "      <td>0.073464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.054281</td>\n",
       "      <td>0.073499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.054003</td>\n",
       "      <td>0.073431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.053456</td>\n",
       "      <td>0.073518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.053175</td>\n",
       "      <td>0.073491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.052978</td>\n",
       "      <td>0.073336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.052729</td>\n",
       "      <td>0.073414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.052480</td>\n",
       "      <td>0.073423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.052441</td>\n",
       "      <td>0.073377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.051926</td>\n",
       "      <td>0.073383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.051852</td>\n",
       "      <td>0.073427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.051356</td>\n",
       "      <td>0.073285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.051363</td>\n",
       "      <td>0.073457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.050751</td>\n",
       "      <td>0.073463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.050651</td>\n",
       "      <td>0.073352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.050537</td>\n",
       "      <td>0.073408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.050335</td>\n",
       "      <td>0.073553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.050109</td>\n",
       "      <td>0.073358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.050302</td>\n",
       "      <td>0.073511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.050004</td>\n",
       "      <td>0.073363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.050005</td>\n",
       "      <td>0.073479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.049919</td>\n",
       "      <td>0.073579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.049852</td>\n",
       "      <td>0.073447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.048980</td>\n",
       "      <td>0.073592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.048645</td>\n",
       "      <td>0.073443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.048517</td>\n",
       "      <td>0.073465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.048365</td>\n",
       "      <td>0.073562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.048181</td>\n",
       "      <td>0.073385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.048052</td>\n",
       "      <td>0.073647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.048042</td>\n",
       "      <td>0.073759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.047744</td>\n",
       "      <td>0.073730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.047847</td>\n",
       "      <td>0.073798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.047354</td>\n",
       "      <td>0.073614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.047386</td>\n",
       "      <td>0.073704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.047570</td>\n",
       "      <td>0.073819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.047264</td>\n",
       "      <td>0.073719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.047556</td>\n",
       "      <td>0.073731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.046851</td>\n",
       "      <td>0.073653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.046488</td>\n",
       "      <td>0.074001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.046505</td>\n",
       "      <td>0.074007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.046955</td>\n",
       "      <td>0.073646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.045778</td>\n",
       "      <td>0.073979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.045888</td>\n",
       "      <td>0.074058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.045727</td>\n",
       "      <td>0.074219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.045442</td>\n",
       "      <td>0.074379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.044773</td>\n",
       "      <td>0.074291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.044214</td>\n",
       "      <td>0.074752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.044170</td>\n",
       "      <td>0.074893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.043862</td>\n",
       "      <td>0.074996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.043714</td>\n",
       "      <td>0.074984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.043970</td>\n",
       "      <td>0.075225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.044284</td>\n",
       "      <td>0.075259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.043501</td>\n",
       "      <td>0.075489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.043621</td>\n",
       "      <td>0.075433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.042885</td>\n",
       "      <td>0.075506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.042595</td>\n",
       "      <td>0.076066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.042235</td>\n",
       "      <td>0.076246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.041565</td>\n",
       "      <td>0.076179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.042086</td>\n",
       "      <td>0.076322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.041732</td>\n",
       "      <td>0.076770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.041777</td>\n",
       "      <td>0.076573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.041850</td>\n",
       "      <td>0.076839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.041043</td>\n",
       "      <td>0.077198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.041934</td>\n",
       "      <td>0.077434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.040168</td>\n",
       "      <td>0.077924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.040490</td>\n",
       "      <td>0.078280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.040985</td>\n",
       "      <td>0.077946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.039434</td>\n",
       "      <td>0.078705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.039889</td>\n",
       "      <td>0.078902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.039990</td>\n",
       "      <td>0.079651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.000724</td>\n",
       "      <td>0.039627</td>\n",
       "      <td>0.079855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.039386</td>\n",
       "      <td>0.080037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.040459</td>\n",
       "      <td>0.079788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.000832</td>\n",
       "      <td>0.038935</td>\n",
       "      <td>0.080110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.040066</td>\n",
       "      <td>0.080331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.038865</td>\n",
       "      <td>0.080047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.000955</td>\n",
       "      <td>0.039369</td>\n",
       "      <td>0.081322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.038762</td>\n",
       "      <td>0.081313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.001047</td>\n",
       "      <td>0.037786</td>\n",
       "      <td>0.081559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.039661</td>\n",
       "      <td>0.081251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.039087</td>\n",
       "      <td>0.081941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.037960</td>\n",
       "      <td>0.082909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.001259</td>\n",
       "      <td>0.040003</td>\n",
       "      <td>0.083011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.041177</td>\n",
       "      <td>0.083385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.001380</td>\n",
       "      <td>0.036425</td>\n",
       "      <td>0.084105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.001445</td>\n",
       "      <td>0.036774</td>\n",
       "      <td>0.084041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.001514</td>\n",
       "      <td>0.038401</td>\n",
       "      <td>0.085583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.001585</td>\n",
       "      <td>0.036655</td>\n",
       "      <td>0.085316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.001660</td>\n",
       "      <td>0.036095</td>\n",
       "      <td>0.086014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.001738</td>\n",
       "      <td>0.037666</td>\n",
       "      <td>0.086816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.001820</td>\n",
       "      <td>0.038262</td>\n",
       "      <td>0.087616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.036792</td>\n",
       "      <td>0.086902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.037814</td>\n",
       "      <td>0.087909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.002089</td>\n",
       "      <td>0.040191</td>\n",
       "      <td>0.087733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.002188</td>\n",
       "      <td>0.039575</td>\n",
       "      <td>0.089279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.002291</td>\n",
       "      <td>0.039373</td>\n",
       "      <td>0.088634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.002399</td>\n",
       "      <td>0.042817</td>\n",
       "      <td>0.090847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.002512</td>\n",
       "      <td>0.040045</td>\n",
       "      <td>0.090112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.002630</td>\n",
       "      <td>0.037743</td>\n",
       "      <td>0.090160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.002754</td>\n",
       "      <td>0.042960</td>\n",
       "      <td>0.091194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.002884</td>\n",
       "      <td>0.038924</td>\n",
       "      <td>0.092085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.003020</td>\n",
       "      <td>0.037798</td>\n",
       "      <td>0.091675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.003162</td>\n",
       "      <td>0.037325</td>\n",
       "      <td>0.092217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.003311</td>\n",
       "      <td>0.043108</td>\n",
       "      <td>0.092458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.003467</td>\n",
       "      <td>0.043607</td>\n",
       "      <td>0.093216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.003631</td>\n",
       "      <td>0.040856</td>\n",
       "      <td>0.095216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.041704</td>\n",
       "      <td>0.094507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.003981</td>\n",
       "      <td>0.041356</td>\n",
       "      <td>0.098188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.004169</td>\n",
       "      <td>0.041818</td>\n",
       "      <td>0.101162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.004365</td>\n",
       "      <td>0.046250</td>\n",
       "      <td>0.100898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.004571</td>\n",
       "      <td>0.041038</td>\n",
       "      <td>0.101119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.004786</td>\n",
       "      <td>0.059044</td>\n",
       "      <td>0.099843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.005012</td>\n",
       "      <td>0.044790</td>\n",
       "      <td>0.101365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.005248</td>\n",
       "      <td>0.040440</td>\n",
       "      <td>0.103539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.049903</td>\n",
       "      <td>0.106047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.005754</td>\n",
       "      <td>0.043300</td>\n",
       "      <td>0.105119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.006026</td>\n",
       "      <td>0.050938</td>\n",
       "      <td>0.107861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.006310</td>\n",
       "      <td>0.040919</td>\n",
       "      <td>0.107673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.006607</td>\n",
       "      <td>0.050435</td>\n",
       "      <td>0.108479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.006918</td>\n",
       "      <td>0.051862</td>\n",
       "      <td>0.111060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.007244</td>\n",
       "      <td>0.041141</td>\n",
       "      <td>0.112083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.007586</td>\n",
       "      <td>0.038625</td>\n",
       "      <td>0.113600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.007943</td>\n",
       "      <td>0.054391</td>\n",
       "      <td>0.113227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.008318</td>\n",
       "      <td>0.057847</td>\n",
       "      <td>0.112582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.008710</td>\n",
       "      <td>0.043227</td>\n",
       "      <td>0.117137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.009120</td>\n",
       "      <td>0.049243</td>\n",
       "      <td>0.118239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.009550</td>\n",
       "      <td>0.071971</td>\n",
       "      <td>0.120947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.063195</td>\n",
       "      <td>0.123606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.010471</td>\n",
       "      <td>0.058218</td>\n",
       "      <td>0.124504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.010965</td>\n",
       "      <td>0.080021</td>\n",
       "      <td>0.129121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.011482</td>\n",
       "      <td>0.052866</td>\n",
       "      <td>0.129096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.012023</td>\n",
       "      <td>0.085827</td>\n",
       "      <td>0.133141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.012589</td>\n",
       "      <td>0.080986</td>\n",
       "      <td>0.131113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.013183</td>\n",
       "      <td>0.075653</td>\n",
       "      <td>0.138060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.013804</td>\n",
       "      <td>0.057855</td>\n",
       "      <td>0.136803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.014454</td>\n",
       "      <td>0.060890</td>\n",
       "      <td>0.141659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.015136</td>\n",
       "      <td>0.065161</td>\n",
       "      <td>0.141169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.015849</td>\n",
       "      <td>0.125445</td>\n",
       "      <td>0.146375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.016596</td>\n",
       "      <td>0.084146</td>\n",
       "      <td>0.151844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.017378</td>\n",
       "      <td>0.054212</td>\n",
       "      <td>0.151069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.018197</td>\n",
       "      <td>0.112945</td>\n",
       "      <td>0.156612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.019055</td>\n",
       "      <td>0.083266</td>\n",
       "      <td>0.159281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.019953</td>\n",
       "      <td>0.086914</td>\n",
       "      <td>0.159739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.020893</td>\n",
       "      <td>0.087489</td>\n",
       "      <td>0.157903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.021878</td>\n",
       "      <td>0.120167</td>\n",
       "      <td>0.158864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.022909</td>\n",
       "      <td>0.102448</td>\n",
       "      <td>0.173635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.023988</td>\n",
       "      <td>0.079209</td>\n",
       "      <td>0.175950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.025119</td>\n",
       "      <td>0.097641</td>\n",
       "      <td>0.182534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.026303</td>\n",
       "      <td>0.159474</td>\n",
       "      <td>0.180455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.084404</td>\n",
       "      <td>0.182126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.028840</td>\n",
       "      <td>0.076607</td>\n",
       "      <td>0.193091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.030200</td>\n",
       "      <td>0.122915</td>\n",
       "      <td>0.193161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.132854</td>\n",
       "      <td>0.191785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.033113</td>\n",
       "      <td>0.108944</td>\n",
       "      <td>0.208692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.034674</td>\n",
       "      <td>0.136631</td>\n",
       "      <td>0.213631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.036308</td>\n",
       "      <td>0.088257</td>\n",
       "      <td>0.208233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.038019</td>\n",
       "      <td>0.181283</td>\n",
       "      <td>0.226176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.039811</td>\n",
       "      <td>0.182296</td>\n",
       "      <td>0.227399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.041687</td>\n",
       "      <td>0.574040</td>\n",
       "      <td>0.244194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.043652</td>\n",
       "      <td>0.231960</td>\n",
       "      <td>0.237932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.045709</td>\n",
       "      <td>0.143513</td>\n",
       "      <td>0.248941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.047863</td>\n",
       "      <td>0.322163</td>\n",
       "      <td>0.243014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.050119</td>\n",
       "      <td>0.287167</td>\n",
       "      <td>0.260746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.052481</td>\n",
       "      <td>0.285733</td>\n",
       "      <td>0.261391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.054954</td>\n",
       "      <td>0.276050</td>\n",
       "      <td>0.288891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.057544</td>\n",
       "      <td>0.247278</td>\n",
       "      <td>0.274972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.060256</td>\n",
       "      <td>0.274069</td>\n",
       "      <td>0.288042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.063096</td>\n",
       "      <td>0.327152</td>\n",
       "      <td>0.288598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.066069</td>\n",
       "      <td>0.313135</td>\n",
       "      <td>0.300685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.069183</td>\n",
       "      <td>0.375981</td>\n",
       "      <td>0.321085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.072444</td>\n",
       "      <td>0.284767</td>\n",
       "      <td>0.326560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.075858</td>\n",
       "      <td>0.391077</td>\n",
       "      <td>0.351230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.079433</td>\n",
       "      <td>0.293638</td>\n",
       "      <td>0.369796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.083176</td>\n",
       "      <td>0.452777</td>\n",
       "      <td>0.391335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.087096</td>\n",
       "      <td>0.292654</td>\n",
       "      <td>0.378420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.091201</td>\n",
       "      <td>0.609770</td>\n",
       "      <td>0.435797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.095499</td>\n",
       "      <td>0.500798</td>\n",
       "      <td>0.450092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Learning Rate      Loss  Validation Loss\n",
       "0         0.000010  0.063204         0.072708\n",
       "1         0.000010  0.062265         0.072777\n",
       "2         0.000011  0.061100         0.072938\n",
       "3         0.000011  0.060126         0.073151\n",
       "4         0.000012  0.059590         0.073328\n",
       "5         0.000013  0.059379         0.073486\n",
       "6         0.000013  0.059111         0.073596\n",
       "7         0.000014  0.058949         0.073716\n",
       "8         0.000014  0.058936         0.073739\n",
       "9         0.000015  0.058671         0.073979\n",
       "10        0.000016  0.057615         0.073970\n",
       "11        0.000017  0.057043         0.073810\n",
       "12        0.000017  0.056934         0.073627\n",
       "13        0.000018  0.056855         0.073632\n",
       "14        0.000019  0.056887         0.073544\n",
       "15        0.000020  0.056669         0.073600\n",
       "16        0.000021  0.056755         0.073575\n",
       "17        0.000022  0.056232         0.073709\n",
       "18        0.000023  0.055855         0.073539\n",
       "19        0.000024  0.056173         0.073384\n",
       "20        0.000025  0.055531         0.073554\n",
       "21        0.000026  0.055088         0.073579\n",
       "22        0.000028  0.054647         0.073519\n",
       "23        0.000029  0.054453         0.073464\n",
       "24        0.000030  0.054281         0.073499\n",
       "25        0.000032  0.054003         0.073431\n",
       "26        0.000033  0.053456         0.073518\n",
       "27        0.000035  0.053175         0.073491\n",
       "28        0.000036  0.052978         0.073336\n",
       "29        0.000038  0.052729         0.073414\n",
       "30        0.000040  0.052480         0.073423\n",
       "31        0.000042  0.052441         0.073377\n",
       "32        0.000044  0.051926         0.073383\n",
       "33        0.000046  0.051852         0.073427\n",
       "34        0.000048  0.051356         0.073285\n",
       "35        0.000050  0.051363         0.073457\n",
       "36        0.000052  0.050751         0.073463\n",
       "37        0.000055  0.050651         0.073352\n",
       "38        0.000058  0.050537         0.073408\n",
       "39        0.000060  0.050335         0.073553\n",
       "40        0.000063  0.050109         0.073358\n",
       "41        0.000066  0.050302         0.073511\n",
       "42        0.000069  0.050004         0.073363\n",
       "43        0.000072  0.050005         0.073479\n",
       "44        0.000076  0.049919         0.073579\n",
       "45        0.000079  0.049852         0.073447\n",
       "46        0.000083  0.048980         0.073592\n",
       "47        0.000087  0.048645         0.073443\n",
       "48        0.000091  0.048517         0.073465\n",
       "49        0.000095  0.048365         0.073562\n",
       "50        0.000100  0.048181         0.073385\n",
       "51        0.000105  0.048052         0.073647\n",
       "52        0.000110  0.048042         0.073759\n",
       "53        0.000115  0.047744         0.073730\n",
       "54        0.000120  0.047847         0.073798\n",
       "55        0.000126  0.047354         0.073614\n",
       "56        0.000132  0.047386         0.073704\n",
       "57        0.000138  0.047570         0.073819\n",
       "58        0.000145  0.047264         0.073719\n",
       "59        0.000151  0.047556         0.073731\n",
       "60        0.000158  0.046851         0.073653\n",
       "61        0.000166  0.046488         0.074001\n",
       "62        0.000174  0.046505         0.074007\n",
       "63        0.000182  0.046955         0.073646\n",
       "64        0.000191  0.045778         0.073979\n",
       "65        0.000200  0.045888         0.074058\n",
       "66        0.000209  0.045727         0.074219\n",
       "67        0.000219  0.045442         0.074379\n",
       "68        0.000229  0.044773         0.074291\n",
       "69        0.000240  0.044214         0.074752\n",
       "70        0.000251  0.044170         0.074893\n",
       "71        0.000263  0.043862         0.074996\n",
       "72        0.000275  0.043714         0.074984\n",
       "73        0.000288  0.043970         0.075225\n",
       "74        0.000302  0.044284         0.075259\n",
       "75        0.000316  0.043501         0.075489\n",
       "76        0.000331  0.043621         0.075433\n",
       "77        0.000347  0.042885         0.075506\n",
       "78        0.000363  0.042595         0.076066\n",
       "79        0.000380  0.042235         0.076246\n",
       "80        0.000398  0.041565         0.076179\n",
       "81        0.000417  0.042086         0.076322\n",
       "82        0.000437  0.041732         0.076770\n",
       "83        0.000457  0.041777         0.076573\n",
       "84        0.000479  0.041850         0.076839\n",
       "85        0.000501  0.041043         0.077198\n",
       "86        0.000525  0.041934         0.077434\n",
       "87        0.000550  0.040168         0.077924\n",
       "88        0.000575  0.040490         0.078280\n",
       "89        0.000603  0.040985         0.077946\n",
       "90        0.000631  0.039434         0.078705\n",
       "91        0.000661  0.039889         0.078902\n",
       "92        0.000692  0.039990         0.079651\n",
       "93        0.000724  0.039627         0.079855\n",
       "94        0.000759  0.039386         0.080037\n",
       "95        0.000794  0.040459         0.079788\n",
       "96        0.000832  0.038935         0.080110\n",
       "97        0.000871  0.040066         0.080331\n",
       "98        0.000912  0.038865         0.080047\n",
       "99        0.000955  0.039369         0.081322\n",
       "100       0.001000  0.038762         0.081313\n",
       "101       0.001047  0.037786         0.081559\n",
       "102       0.001096  0.039661         0.081251\n",
       "103       0.001148  0.039087         0.081941\n",
       "104       0.001202  0.037960         0.082909\n",
       "105       0.001259  0.040003         0.083011\n",
       "106       0.001318  0.041177         0.083385\n",
       "107       0.001380  0.036425         0.084105\n",
       "108       0.001445  0.036774         0.084041\n",
       "109       0.001514  0.038401         0.085583\n",
       "110       0.001585  0.036655         0.085316\n",
       "111       0.001660  0.036095         0.086014\n",
       "112       0.001738  0.037666         0.086816\n",
       "113       0.001820  0.038262         0.087616\n",
       "114       0.001905  0.036792         0.086902\n",
       "115       0.001995  0.037814         0.087909\n",
       "116       0.002089  0.040191         0.087733\n",
       "117       0.002188  0.039575         0.089279\n",
       "118       0.002291  0.039373         0.088634\n",
       "119       0.002399  0.042817         0.090847\n",
       "120       0.002512  0.040045         0.090112\n",
       "121       0.002630  0.037743         0.090160\n",
       "122       0.002754  0.042960         0.091194\n",
       "123       0.002884  0.038924         0.092085\n",
       "124       0.003020  0.037798         0.091675\n",
       "125       0.003162  0.037325         0.092217\n",
       "126       0.003311  0.043108         0.092458\n",
       "127       0.003467  0.043607         0.093216\n",
       "128       0.003631  0.040856         0.095216\n",
       "129       0.003802  0.041704         0.094507\n",
       "130       0.003981  0.041356         0.098188\n",
       "131       0.004169  0.041818         0.101162\n",
       "132       0.004365  0.046250         0.100898\n",
       "133       0.004571  0.041038         0.101119\n",
       "134       0.004786  0.059044         0.099843\n",
       "135       0.005012  0.044790         0.101365\n",
       "136       0.005248  0.040440         0.103539\n",
       "137       0.005495  0.049903         0.106047\n",
       "138       0.005754  0.043300         0.105119\n",
       "139       0.006026  0.050938         0.107861\n",
       "140       0.006310  0.040919         0.107673\n",
       "141       0.006607  0.050435         0.108479\n",
       "142       0.006918  0.051862         0.111060\n",
       "143       0.007244  0.041141         0.112083\n",
       "144       0.007586  0.038625         0.113600\n",
       "145       0.007943  0.054391         0.113227\n",
       "146       0.008318  0.057847         0.112582\n",
       "147       0.008710  0.043227         0.117137\n",
       "148       0.009120  0.049243         0.118239\n",
       "149       0.009550  0.071971         0.120947\n",
       "150       0.010000  0.063195         0.123606\n",
       "151       0.010471  0.058218         0.124504\n",
       "152       0.010965  0.080021         0.129121\n",
       "153       0.011482  0.052866         0.129096\n",
       "154       0.012023  0.085827         0.133141\n",
       "155       0.012589  0.080986         0.131113\n",
       "156       0.013183  0.075653         0.138060\n",
       "157       0.013804  0.057855         0.136803\n",
       "158       0.014454  0.060890         0.141659\n",
       "159       0.015136  0.065161         0.141169\n",
       "160       0.015849  0.125445         0.146375\n",
       "161       0.016596  0.084146         0.151844\n",
       "162       0.017378  0.054212         0.151069\n",
       "163       0.018197  0.112945         0.156612\n",
       "164       0.019055  0.083266         0.159281\n",
       "165       0.019953  0.086914         0.159739\n",
       "166       0.020893  0.087489         0.157903\n",
       "167       0.021878  0.120167         0.158864\n",
       "168       0.022909  0.102448         0.173635\n",
       "169       0.023988  0.079209         0.175950\n",
       "170       0.025119  0.097641         0.182534\n",
       "171       0.026303  0.159474         0.180455\n",
       "172       0.027542  0.084404         0.182126\n",
       "173       0.028840  0.076607         0.193091\n",
       "174       0.030200  0.122915         0.193161\n",
       "175       0.031623  0.132854         0.191785\n",
       "176       0.033113  0.108944         0.208692\n",
       "177       0.034674  0.136631         0.213631\n",
       "178       0.036308  0.088257         0.208233\n",
       "179       0.038019  0.181283         0.226176\n",
       "180       0.039811  0.182296         0.227399\n",
       "181       0.041687  0.574040         0.244194\n",
       "182       0.043652  0.231960         0.237932\n",
       "183       0.045709  0.143513         0.248941\n",
       "184       0.047863  0.322163         0.243014\n",
       "185       0.050119  0.287167         0.260746\n",
       "186       0.052481  0.285733         0.261391\n",
       "187       0.054954  0.276050         0.288891\n",
       "188       0.057544  0.247278         0.274972\n",
       "189       0.060256  0.274069         0.288042\n",
       "190       0.063096  0.327152         0.288598\n",
       "191       0.066069  0.313135         0.300685\n",
       "192       0.069183  0.375981         0.321085\n",
       "193       0.072444  0.284767         0.326560\n",
       "194       0.075858  0.391077         0.351230\n",
       "195       0.079433  0.293638         0.369796\n",
       "196       0.083176  0.452777         0.391335\n",
       "197       0.087096  0.292654         0.378420\n",
       "198       0.091201  0.609770         0.435797\n",
       "199       0.095499  0.500798         0.450092"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "\n",
    "# Display the entire DataFrame\n",
    "display(lrs)\n",
    "\n",
    "pd.reset_option('display.max_rows')\n",
    "pd.reset_option('display.max_columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "Epoch 1/60\n",
      "282/282 [==============================] - 123s 366ms/step - loss: 0.2287 - Accuracy: 0.9338 - Precision: 0.8589 - Recall: 0.7714 - TP: 2601.1299 - TN: 4913.7300 - FP: 733.2700 - FN: 770.8700 - val_loss: 0.1379 - val_Accuracy: 0.9644 - val_Precision: 0.9103 - val_Recall: 0.8631 - val_TP: 693.9100 - val_TN: 1016.5200 - val_FP: 89.4800 - val_FN: 110.0900\n",
      "Epoch 2/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1354 - Accuracy: 0.9658 - Precision: 0.9074 - Recall: 0.8703 - TP: 2934.5400 - TN: 5255.2998 - FP: 391.7000 - FN: 437.4600 - val_loss: 0.1113 - val_Accuracy: 0.9691 - val_Precision: 0.9319 - val_Recall: 0.8893 - val_TP: 715.0100 - val_TN: 1043.8400 - val_FP: 62.1600 - val_FN: 88.9900\n",
      "Epoch 3/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1152 - Accuracy: 0.9683 - Precision: 0.9213 - Recall: 0.8923 - TP: 3008.8101 - TN: 5341.9102 - FP: 305.0900 - FN: 363.1900 - val_loss: 0.0978 - val_Accuracy: 0.9717 - val_Precision: 0.9366 - val_Recall: 0.9080 - val_TP: 730.0500 - val_TN: 1051.0500 - val_FP: 54.9500 - val_FN: 73.9500\n",
      "Epoch 4/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1017 - Accuracy: 0.9696 - Precision: 0.9260 - Recall: 0.9051 - TP: 3051.8799 - TN: 5370.7202 - FP: 276.2800 - FN: 320.1200 - val_loss: 0.0898 - val_Accuracy: 0.9707 - val_Precision: 0.9481 - val_Recall: 0.9105 - val_TP: 732.0700 - val_TN: 1065.5500 - val_FP: 40.4500 - val_FN: 71.9300\n",
      "Epoch 5/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0994 - Accuracy: 0.9714 - Precision: 0.9316 - Recall: 0.9113 - TP: 3072.7600 - TN: 5402.0498 - FP: 244.9500 - FN: 299.2400 - val_loss: 0.0850 - val_Accuracy: 0.9743 - val_Precision: 0.9475 - val_Recall: 0.9199 - val_TP: 739.6200 - val_TN: 1065.3700 - val_FP: 40.6300 - val_FN: 64.3800\n",
      "Epoch 6/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0913 - Accuracy: 0.9726 - Precision: 0.9345 - Recall: 0.9172 - TP: 3092.8999 - TN: 5415.8301 - FP: 231.1700 - FN: 279.1000 - val_loss: 0.0840 - val_Accuracy: 0.9749 - val_Precision: 0.9484 - val_Recall: 0.9231 - val_TP: 742.1900 - val_TN: 1065.6600 - val_FP: 40.3400 - val_FN: 61.8100\n",
      "Epoch 7/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0874 - Accuracy: 0.9735 - Precision: 0.9373 - Recall: 0.9203 - TP: 3103.3899 - TN: 5430.8198 - FP: 216.1800 - FN: 268.6100 - val_loss: 0.0839 - val_Accuracy: 0.9754 - val_Precision: 0.9451 - val_Recall: 0.9276 - val_TP: 745.7800 - val_TN: 1061.3500 - val_FP: 44.6500 - val_FN: 58.2200\n",
      "Epoch 8/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0839 - Accuracy: 0.9742 - Precision: 0.9378 - Recall: 0.9248 - TP: 3118.3501 - TN: 5433.1401 - FP: 213.8600 - FN: 253.6500 - val_loss: 0.0869 - val_Accuracy: 0.9759 - val_Precision: 0.9449 - val_Recall: 0.9257 - val_TP: 744.2300 - val_TN: 1060.8800 - val_FP: 45.1200 - val_FN: 59.7700\n",
      "Epoch 9/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0821 - Accuracy: 0.9751 - Precision: 0.9407 - Recall: 0.9255 - TP: 3120.7500 - TN: 5447.5098 - FP: 199.4900 - FN: 251.2500 - val_loss: 0.0853 - val_Accuracy: 0.9764 - val_Precision: 0.9439 - val_Recall: 0.9299 - val_TP: 747.6400 - val_TN: 1059.8000 - val_FP: 46.2000 - val_FN: 56.3600\n",
      "Epoch 10/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0805 - Accuracy: 0.9751 - Precision: 0.9420 - Recall: 0.9273 - TP: 3126.7800 - TN: 5454.4600 - FP: 192.5400 - FN: 245.2200 - val_loss: 0.0801 - val_Accuracy: 0.9759 - val_Precision: 0.9485 - val_Recall: 0.9329 - val_TP: 750.0800 - val_TN: 1065.5800 - val_FP: 40.4200 - val_FN: 53.9200\n",
      "Epoch 11/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0807 - Accuracy: 0.9751 - Precision: 0.9421 - Recall: 0.9295 - TP: 3134.2200 - TN: 5456.2300 - FP: 190.7700 - FN: 237.7800 - val_loss: 0.0796 - val_Accuracy: 0.9754 - val_Precision: 0.9496 - val_Recall: 0.9336 - val_TP: 750.5900 - val_TN: 1066.6899 - val_FP: 39.3100 - val_FN: 53.4100\n",
      "Epoch 12/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0759 - Accuracy: 0.9765 - Precision: 0.9433 - Recall: 0.9310 - TP: 3139.2100 - TN: 5460.3999 - FP: 186.6000 - FN: 232.7900 - val_loss: 0.0763 - val_Accuracy: 0.9759 - val_Precision: 0.9534 - val_Recall: 0.9350 - val_TP: 751.7300 - val_TN: 1072.0800 - val_FP: 33.9200 - val_FN: 52.2700\n",
      "Epoch 13/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0747 - Accuracy: 0.9766 - Precision: 0.9451 - Recall: 0.9321 - TP: 3143.1001 - TN: 5468.5000 - FP: 178.5000 - FN: 228.9000 - val_loss: 0.0862 - val_Accuracy: 0.9764 - val_Precision: 0.9397 - val_Recall: 0.9352 - val_TP: 751.8900 - val_TN: 1056.3700 - val_FP: 49.6300 - val_FN: 52.1100\n",
      "Epoch 14/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0733 - Accuracy: 0.9773 - Precision: 0.9442 - Recall: 0.9337 - TP: 3148.5400 - TN: 5464.6001 - FP: 182.4000 - FN: 223.4600 - val_loss: 0.0765 - val_Accuracy: 0.9764 - val_Precision: 0.9586 - val_Recall: 0.9325 - val_TP: 749.6900 - val_TN: 1077.2900 - val_FP: 28.7100 - val_FN: 54.3100\n",
      "Epoch 15/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0717 - Accuracy: 0.9773 - Precision: 0.9460 - Recall: 0.9343 - TP: 3150.4600 - TN: 5472.9502 - FP: 174.0500 - FN: 221.5400 - val_loss: 0.0775 - val_Accuracy: 0.9754 - val_Precision: 0.9567 - val_Recall: 0.9338 - val_TP: 750.7400 - val_TN: 1074.8800 - val_FP: 31.1200 - val_FN: 53.2600\n",
      "Epoch 16/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0714 - Accuracy: 0.9775 - Precision: 0.9463 - Recall: 0.9349 - TP: 3152.5601 - TN: 5474.8999 - FP: 172.1000 - FN: 219.4400 - val_loss: 0.0749 - val_Accuracy: 0.9764 - val_Precision: 0.9605 - val_Recall: 0.9336 - val_TP: 750.6500 - val_TN: 1079.5601 - val_FP: 26.4400 - val_FN: 53.3500\n",
      "Epoch 17/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0713 - Accuracy: 0.9777 - Precision: 0.9469 - Recall: 0.9362 - TP: 3156.7100 - TN: 5479.2500 - FP: 167.7500 - FN: 215.2900 - val_loss: 0.0769 - val_Accuracy: 0.9775 - val_Precision: 0.9550 - val_Recall: 0.9364 - val_TP: 752.8900 - val_TN: 1073.2000 - val_FP: 32.8000 - val_FN: 51.1100\n",
      "Epoch 18/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0685 - Accuracy: 0.9782 - Precision: 0.9480 - Recall: 0.9362 - TP: 3156.7800 - TN: 5481.4199 - FP: 165.5800 - FN: 215.2200 - val_loss: 0.0738 - val_Accuracy: 0.9770 - val_Precision: 0.9596 - val_Recall: 0.9363 - val_TP: 752.8200 - val_TN: 1078.7800 - val_FP: 27.2200 - val_FN: 51.1800\n",
      "Epoch 19/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0673 - Accuracy: 0.9788 - Precision: 0.9482 - Recall: 0.9381 - TP: 3163.1799 - TN: 5483.7798 - FP: 163.2200 - FN: 208.8200 - val_loss: 0.0741 - val_Accuracy: 0.9770 - val_Precision: 0.9580 - val_Recall: 0.9381 - val_TP: 754.2100 - val_TN: 1077.0800 - val_FP: 28.9200 - val_FN: 49.7900\n",
      "Epoch 20/60\n",
      "282/282 [==============================] - 1s 4ms/step - loss: 0.0666 - Accuracy: 0.9789 - Precision: 0.9484 - Recall: 0.9382 - TP: 3163.4500 - TN: 5484.0098 - FP: 162.9900 - FN: 208.5500 - val_loss: 0.0755 - val_Accuracy: 0.9775 - val_Precision: 0.9584 - val_Recall: 0.9374 - val_TP: 753.6400 - val_TN: 1076.9900 - val_FP: 29.0100 - val_FN: 50.3600\n",
      "Epoch 21/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0660 - Accuracy: 0.9792 - Precision: 0.9489 - Recall: 0.9392 - TP: 3166.9099 - TN: 5486.7700 - FP: 160.2300 - FN: 205.0900 - val_loss: 0.0741 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9375 - val_TP: 753.7300 - val_TN: 1079.4399 - val_FP: 26.5600 - val_FN: 50.2700\n",
      "Epoch 22/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0660 - Accuracy: 0.9786 - Precision: 0.9502 - Recall: 0.9388 - TP: 3165.6599 - TN: 5492.8198 - FP: 154.1800 - FN: 206.3400 - val_loss: 0.0747 - val_Accuracy: 0.9775 - val_Precision: 0.9569 - val_Recall: 0.9396 - val_TP: 755.4100 - val_TN: 1075.5200 - val_FP: 30.4800 - val_FN: 48.5900\n",
      "Epoch 23/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0660 - Accuracy: 0.9794 - Precision: 0.9488 - Recall: 0.9404 - TP: 3171.0400 - TN: 5487.0698 - FP: 159.9300 - FN: 200.9600 - val_loss: 0.0744 - val_Accuracy: 0.9780 - val_Precision: 0.9600 - val_Recall: 0.9380 - val_TP: 754.1900 - val_TN: 1078.9399 - val_FP: 27.0600 - val_FN: 49.8100\n",
      "Epoch 24/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0627 - Accuracy: 0.9796 - Precision: 0.9504 - Recall: 0.9406 - TP: 3171.6499 - TN: 5492.7100 - FP: 154.2900 - FN: 200.3500 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9625 - val_Recall: 0.9371 - val_TP: 753.4600 - val_TN: 1081.6500 - val_FP: 24.3500 - val_FN: 50.5400\n",
      "Epoch 25/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0627 - Accuracy: 0.9793 - Precision: 0.9512 - Recall: 0.9407 - TP: 3172.0100 - TN: 5496.4199 - FP: 150.5800 - FN: 199.9900 - val_loss: 0.0766 - val_Accuracy: 0.9780 - val_Precision: 0.9563 - val_Recall: 0.9391 - val_TP: 755.0500 - val_TN: 1074.4700 - val_FP: 31.5300 - val_FN: 48.9500\n",
      "Epoch 26/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0632 - Accuracy: 0.9800 - Precision: 0.9509 - Recall: 0.9409 - TP: 3172.7400 - TN: 5494.7500 - FP: 152.2500 - FN: 199.2600 - val_loss: 0.0735 - val_Accuracy: 0.9775 - val_Precision: 0.9598 - val_Recall: 0.9399 - val_TP: 755.6500 - val_TN: 1078.9500 - val_FP: 27.0500 - val_FN: 48.3500\n",
      "Epoch 27/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0620 - Accuracy: 0.9798 - Precision: 0.9508 - Recall: 0.9418 - TP: 3175.8501 - TN: 5494.2002 - FP: 152.8000 - FN: 196.1500 - val_loss: 0.0738 - val_Accuracy: 0.9780 - val_Precision: 0.9612 - val_Recall: 0.9392 - val_TP: 755.1000 - val_TN: 1080.2200 - val_FP: 25.7800 - val_FN: 48.9000\n",
      "Epoch 28/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0618 - Accuracy: 0.9800 - Precision: 0.9518 - Recall: 0.9420 - TP: 3176.4700 - TN: 5499.8999 - FP: 147.1000 - FN: 195.5300 - val_loss: 0.0755 - val_Accuracy: 0.9780 - val_Precision: 0.9587 - val_Recall: 0.9395 - val_TP: 755.3300 - val_TN: 1077.3101 - val_FP: 28.6900 - val_FN: 48.6700\n",
      "Epoch 29/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0605 - Accuracy: 0.9804 - Precision: 0.9519 - Recall: 0.9420 - TP: 3176.5200 - TN: 5499.2100 - FP: 147.7900 - FN: 195.4800 - val_loss: 0.0742 - val_Accuracy: 0.9780 - val_Precision: 0.9603 - val_Recall: 0.9399 - val_TP: 755.6400 - val_TN: 1079.1300 - val_FP: 26.8700 - val_FN: 48.3600\n",
      "Epoch 30/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0627 - Accuracy: 0.9792 - Precision: 0.9520 - Recall: 0.9421 - TP: 3176.9099 - TN: 5501.7900 - FP: 145.2100 - FN: 195.0900 - val_loss: 0.0723 - val_Accuracy: 0.9775 - val_Precision: 0.9613 - val_Recall: 0.9408 - val_TP: 756.4300 - val_TN: 1080.6899 - val_FP: 25.3100 - val_FN: 47.5700\n",
      "Epoch 31/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0606 - Accuracy: 0.9802 - Precision: 0.9505 - Recall: 0.9434 - TP: 3181.0400 - TN: 5494.9199 - FP: 152.0800 - FN: 190.9600 - val_loss: 0.0758 - val_Accuracy: 0.9775 - val_Precision: 0.9604 - val_Recall: 0.9390 - val_TP: 754.9600 - val_TN: 1079.0300 - val_FP: 26.9700 - val_FN: 49.0400\n",
      "Epoch 32/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0607 - Accuracy: 0.9802 - Precision: 0.9526 - Recall: 0.9436 - TP: 3181.8101 - TN: 5502.5000 - FP: 144.5000 - FN: 190.1900 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9643 - val_Recall: 0.9380 - val_TP: 754.1300 - val_TN: 1083.4800 - val_FP: 22.5200 - val_FN: 49.8700\n",
      "Epoch 33/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0601 - Accuracy: 0.9803 - Precision: 0.9530 - Recall: 0.9433 - TP: 3180.8799 - TN: 5504.7002 - FP: 142.3000 - FN: 191.1200 - val_loss: 0.0734 - val_Accuracy: 0.9775 - val_Precision: 0.9628 - val_Recall: 0.9399 - val_TP: 755.6900 - val_TN: 1082.0900 - val_FP: 23.9100 - val_FN: 48.3100\n",
      "Epoch 34/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0580 - Accuracy: 0.9808 - Precision: 0.9534 - Recall: 0.9444 - TP: 3184.4900 - TN: 5506.3101 - FP: 140.6900 - FN: 187.5100 - val_loss: 0.0727 - val_Accuracy: 0.9775 - val_Precision: 0.9626 - val_Recall: 0.9406 - val_TP: 756.2800 - val_TN: 1081.9399 - val_FP: 24.0600 - val_FN: 47.7200\n",
      "Epoch 35/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0610 - Accuracy: 0.9809 - Precision: 0.9527 - Recall: 0.9439 - TP: 3182.9299 - TN: 5503.8301 - FP: 143.1700 - FN: 189.0700 - val_loss: 0.0727 - val_Accuracy: 0.9775 - val_Precision: 0.9619 - val_Recall: 0.9413 - val_TP: 756.8000 - val_TN: 1081.3000 - val_FP: 24.7000 - val_FN: 47.2000\n",
      "Epoch 36/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0574 - Accuracy: 0.9814 - Precision: 0.9527 - Recall: 0.9453 - TP: 3187.4299 - TN: 5503.7002 - FP: 143.3000 - FN: 184.5700 - val_loss: 0.0733 - val_Accuracy: 0.9770 - val_Precision: 0.9634 - val_Recall: 0.9404 - val_TP: 756.1100 - val_TN: 1082.6600 - val_FP: 23.3400 - val_FN: 47.8900\n",
      "Epoch 37/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0572 - Accuracy: 0.9803 - Precision: 0.9538 - Recall: 0.9442 - TP: 3183.9500 - TN: 5507.9302 - FP: 139.0700 - FN: 188.0500 - val_loss: 0.0735 - val_Accuracy: 0.9770 - val_Precision: 0.9632 - val_Recall: 0.9404 - val_TP: 756.1000 - val_TN: 1082.4600 - val_FP: 23.5400 - val_FN: 47.9000\n",
      "Epoch 38/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0573 - Accuracy: 0.9814 - Precision: 0.9538 - Recall: 0.9453 - TP: 3187.6699 - TN: 5508.2700 - FP: 138.7300 - FN: 184.3300 - val_loss: 0.0728 - val_Accuracy: 0.9775 - val_Precision: 0.9625 - val_Recall: 0.9415 - val_TP: 756.9400 - val_TN: 1081.9100 - val_FP: 24.0900 - val_FN: 47.0600\n",
      "Epoch 39/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0566 - Accuracy: 0.9815 - Precision: 0.9542 - Recall: 0.9455 - TP: 3188.1101 - TN: 5509.3599 - FP: 137.6400 - FN: 183.8900 - val_loss: 0.0734 - val_Accuracy: 0.9770 - val_Precision: 0.9613 - val_Recall: 0.9422 - val_TP: 757.5400 - val_TN: 1080.5699 - val_FP: 25.4300 - val_FN: 46.4600\n",
      "Epoch 40/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0556 - Accuracy: 0.9814 - Precision: 0.9538 - Recall: 0.9464 - TP: 3191.2000 - TN: 5507.5298 - FP: 139.4700 - FN: 180.8000 - val_loss: 0.0758 - val_Accuracy: 0.9775 - val_Precision: 0.9626 - val_Recall: 0.9397 - val_TP: 755.5200 - val_TN: 1081.5699 - val_FP: 24.4300 - val_FN: 48.4800\n",
      "Epoch 41/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0573 - Accuracy: 0.9812 - Precision: 0.9542 - Recall: 0.9454 - TP: 3187.9700 - TN: 5509.8501 - FP: 137.1500 - FN: 184.0300 - val_loss: 0.0739 - val_Accuracy: 0.9770 - val_Precision: 0.9644 - val_Recall: 0.9404 - val_TP: 756.0500 - val_TN: 1083.6801 - val_FP: 22.3200 - val_FN: 47.9500\n",
      "Epoch 42/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0560 - Accuracy: 0.9816 - Precision: 0.9542 - Recall: 0.9458 - TP: 3189.3601 - TN: 5509.9502 - FP: 137.0500 - FN: 182.6400 - val_loss: 0.0734 - val_Accuracy: 0.9770 - val_Precision: 0.9643 - val_Recall: 0.9408 - val_TP: 756.4100 - val_TN: 1083.6300 - val_FP: 22.3700 - val_FN: 47.5900\n",
      "Epoch 43/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0552 - Accuracy: 0.9815 - Precision: 0.9548 - Recall: 0.9461 - TP: 3190.3000 - TN: 5512.0498 - FP: 134.9500 - FN: 181.7000 - val_loss: 0.0740 - val_Accuracy: 0.9770 - val_Precision: 0.9628 - val_Recall: 0.9417 - val_TP: 757.1000 - val_TN: 1082.0800 - val_FP: 23.9200 - val_FN: 46.9000\n",
      "Epoch 44/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0562 - Accuracy: 0.9817 - Precision: 0.9551 - Recall: 0.9460 - TP: 3189.9700 - TN: 5513.7598 - FP: 133.2400 - FN: 182.0300 - val_loss: 0.0732 - val_Accuracy: 0.9770 - val_Precision: 0.9636 - val_Recall: 0.9417 - val_TP: 757.1000 - val_TN: 1083.0500 - val_FP: 22.9500 - val_FN: 46.9000\n",
      "Epoch 45/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0547 - Accuracy: 0.9815 - Precision: 0.9541 - Recall: 0.9471 - TP: 3193.7000 - TN: 5509.9902 - FP: 137.0100 - FN: 178.3000 - val_loss: 0.0737 - val_Accuracy: 0.9770 - val_Precision: 0.9644 - val_Recall: 0.9413 - val_TP: 756.7800 - val_TN: 1083.7300 - val_FP: 22.2700 - val_FN: 47.2200\n",
      "Epoch 46/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0542 - Accuracy: 0.9820 - Precision: 0.9556 - Recall: 0.9465 - TP: 3191.5701 - TN: 5515.4702 - FP: 131.5300 - FN: 180.4300 - val_loss: 0.0755 - val_Accuracy: 0.9764 - val_Precision: 0.9602 - val_Recall: 0.9424 - val_TP: 757.6600 - val_TN: 1079.3900 - val_FP: 26.6100 - val_FN: 46.3400\n",
      "Epoch 47/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0545 - Accuracy: 0.9817 - Precision: 0.9548 - Recall: 0.9470 - TP: 3193.1699 - TN: 5512.9702 - FP: 134.0300 - FN: 178.8300 - val_loss: 0.0734 - val_Accuracy: 0.9780 - val_Precision: 0.9616 - val_Recall: 0.9434 - val_TP: 758.5300 - val_TN: 1081.0699 - val_FP: 24.9300 - val_FN: 45.4700\n",
      "Epoch 48/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0528 - Accuracy: 0.9820 - Precision: 0.9556 - Recall: 0.9476 - TP: 3195.3501 - TN: 5515.7500 - FP: 131.2500 - FN: 176.6500 - val_loss: 0.0734 - val_Accuracy: 0.9780 - val_Precision: 0.9613 - val_Recall: 0.9438 - val_TP: 758.8500 - val_TN: 1080.7700 - val_FP: 25.2300 - val_FN: 45.1500\n",
      "Epoch 49/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0533 - Accuracy: 0.9823 - Precision: 0.9557 - Recall: 0.9476 - TP: 3195.2100 - TN: 5515.8398 - FP: 131.1600 - FN: 176.7900 - val_loss: 0.0866 - val_Accuracy: 0.9743 - val_Precision: 0.9440 - val_Recall: 0.9428 - val_TP: 758.0000 - val_TN: 1063.5200 - val_FP: 42.4800 - val_FN: 46.0000\n",
      "Epoch 50/60\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0529 - Accuracy: 0.9817 - Precision: 0.9548 - Recall: 0.9487 - TP: 3198.9299 - TN: 5512.2798 - FP: 134.7200 - FN: 173.0700 - val_loss: 0.0744 - val_Accuracy: 0.9770 - val_Precision: 0.9646 - val_Recall: 0.9415 - val_TP: 756.9700 - val_TN: 1084.0000 - val_FP: 22.0000 - val_FN: 47.0300\n"
     ]
    }
   ],
   "source": [
    "metadata_path = \"..\\\\metadata.csv\"\n",
    "audio_dir = \"..\\\\dataset\\\\audios\"\n",
    "\n",
    "audio_dataset = dataLoader.AudioDataset(metadata_path, audio_dir, BATCH_SIZE=32)\n",
    "train_ds, val_ds, test_ds = audio_dataset.preprocess_datasets()\n",
    "\n",
    "classifier = modelo.Clasificador()\n",
    "classifier.units = 100\n",
    "classifier.alpha = 0.001\n",
    "classifier.compilar()\n",
    "history = classifier.train(train_ds, val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4560\\1544320673.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexportar_entrenamiento\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'.\\\\entrenamiento\\\\historia_entrenamiento'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'classifier' is not defined"
     ]
    }
   ],
   "source": [
    "# classifier.exportar_entrenamiento(history, '.\\\\entrenamiento\\\\historia_entrenamiento')\n",
    "# import pickle\n",
    "# with open('training_history', 'rb') as file:\n",
    "#     historia = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier.plot_training_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataLoader.yamnet_params.Params.BN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.244764</td>\n",
       "      <td>0.924825</td>\n",
       "      <td>0.149314</td>\n",
       "      <td>0.963351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.139062</td>\n",
       "      <td>0.963300</td>\n",
       "      <td>0.109381</td>\n",
       "      <td>0.970157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.115214</td>\n",
       "      <td>0.967402</td>\n",
       "      <td>0.097550</td>\n",
       "      <td>0.971204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.105376</td>\n",
       "      <td>0.969065</td>\n",
       "      <td>0.089083</td>\n",
       "      <td>0.973822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.097436</td>\n",
       "      <td>0.971172</td>\n",
       "      <td>0.085564</td>\n",
       "      <td>0.974869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.091995</td>\n",
       "      <td>0.972281</td>\n",
       "      <td>0.083870</td>\n",
       "      <td>0.974346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.088043</td>\n",
       "      <td>0.973168</td>\n",
       "      <td>0.086005</td>\n",
       "      <td>0.975393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.085564</td>\n",
       "      <td>0.973944</td>\n",
       "      <td>0.080252</td>\n",
       "      <td>0.974869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.081394</td>\n",
       "      <td>0.974831</td>\n",
       "      <td>0.077308</td>\n",
       "      <td>0.975393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.081968</td>\n",
       "      <td>0.975053</td>\n",
       "      <td>0.078460</td>\n",
       "      <td>0.974869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.080269</td>\n",
       "      <td>0.974942</td>\n",
       "      <td>0.079804</td>\n",
       "      <td>0.974869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.077203</td>\n",
       "      <td>0.976161</td>\n",
       "      <td>0.075253</td>\n",
       "      <td>0.975393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.074922</td>\n",
       "      <td>0.976383</td>\n",
       "      <td>0.079139</td>\n",
       "      <td>0.975393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.073984</td>\n",
       "      <td>0.976938</td>\n",
       "      <td>0.075698</td>\n",
       "      <td>0.975916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.075405</td>\n",
       "      <td>0.976383</td>\n",
       "      <td>0.078569</td>\n",
       "      <td>0.975916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.072288</td>\n",
       "      <td>0.977270</td>\n",
       "      <td>0.074584</td>\n",
       "      <td>0.975916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.070800</td>\n",
       "      <td>0.977714</td>\n",
       "      <td>0.074208</td>\n",
       "      <td>0.975916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.068530</td>\n",
       "      <td>0.978046</td>\n",
       "      <td>0.075563</td>\n",
       "      <td>0.976440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.068712</td>\n",
       "      <td>0.977603</td>\n",
       "      <td>0.073088</td>\n",
       "      <td>0.976440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.071080</td>\n",
       "      <td>0.978046</td>\n",
       "      <td>0.073531</td>\n",
       "      <td>0.976963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.068276</td>\n",
       "      <td>0.978046</td>\n",
       "      <td>0.074157</td>\n",
       "      <td>0.977487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.065146</td>\n",
       "      <td>0.978822</td>\n",
       "      <td>0.076754</td>\n",
       "      <td>0.977487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.064967</td>\n",
       "      <td>0.978822</td>\n",
       "      <td>0.073743</td>\n",
       "      <td>0.977487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.065645</td>\n",
       "      <td>0.979266</td>\n",
       "      <td>0.073004</td>\n",
       "      <td>0.977487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.065444</td>\n",
       "      <td>0.978822</td>\n",
       "      <td>0.073634</td>\n",
       "      <td>0.977487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.062324</td>\n",
       "      <td>0.979710</td>\n",
       "      <td>0.075359</td>\n",
       "      <td>0.976963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.062482</td>\n",
       "      <td>0.978933</td>\n",
       "      <td>0.074490</td>\n",
       "      <td>0.976963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.061038</td>\n",
       "      <td>0.979377</td>\n",
       "      <td>0.073225</td>\n",
       "      <td>0.978010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.062025</td>\n",
       "      <td>0.979599</td>\n",
       "      <td>0.092740</td>\n",
       "      <td>0.973822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.061252</td>\n",
       "      <td>0.980264</td>\n",
       "      <td>0.072583</td>\n",
       "      <td>0.977487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.061057</td>\n",
       "      <td>0.980707</td>\n",
       "      <td>0.073566</td>\n",
       "      <td>0.977487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.059995</td>\n",
       "      <td>0.981040</td>\n",
       "      <td>0.073584</td>\n",
       "      <td>0.977487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.059626</td>\n",
       "      <td>0.980375</td>\n",
       "      <td>0.073877</td>\n",
       "      <td>0.976963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.059778</td>\n",
       "      <td>0.980375</td>\n",
       "      <td>0.075410</td>\n",
       "      <td>0.976963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.061967</td>\n",
       "      <td>0.980153</td>\n",
       "      <td>0.083764</td>\n",
       "      <td>0.974869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.059131</td>\n",
       "      <td>0.981373</td>\n",
       "      <td>0.075704</td>\n",
       "      <td>0.976963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.058444</td>\n",
       "      <td>0.980597</td>\n",
       "      <td>0.073444</td>\n",
       "      <td>0.977487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.057055</td>\n",
       "      <td>0.980929</td>\n",
       "      <td>0.076547</td>\n",
       "      <td>0.977487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.056323</td>\n",
       "      <td>0.981040</td>\n",
       "      <td>0.074982</td>\n",
       "      <td>0.976963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.056995</td>\n",
       "      <td>0.980818</td>\n",
       "      <td>0.072574</td>\n",
       "      <td>0.978010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.056323</td>\n",
       "      <td>0.981040</td>\n",
       "      <td>0.073203</td>\n",
       "      <td>0.976963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.054732</td>\n",
       "      <td>0.981594</td>\n",
       "      <td>0.075545</td>\n",
       "      <td>0.976440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.055362</td>\n",
       "      <td>0.981594</td>\n",
       "      <td>0.072367</td>\n",
       "      <td>0.978010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.054500</td>\n",
       "      <td>0.981484</td>\n",
       "      <td>0.072268</td>\n",
       "      <td>0.977487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.057637</td>\n",
       "      <td>0.980929</td>\n",
       "      <td>0.072780</td>\n",
       "      <td>0.976963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.055482</td>\n",
       "      <td>0.981705</td>\n",
       "      <td>0.072921</td>\n",
       "      <td>0.977487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.054056</td>\n",
       "      <td>0.981594</td>\n",
       "      <td>0.073584</td>\n",
       "      <td>0.976963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.054352</td>\n",
       "      <td>0.981705</td>\n",
       "      <td>0.073020</td>\n",
       "      <td>0.978010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.053733</td>\n",
       "      <td>0.981262</td>\n",
       "      <td>0.072822</td>\n",
       "      <td>0.977487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.054128</td>\n",
       "      <td>0.981373</td>\n",
       "      <td>0.073489</td>\n",
       "      <td>0.977487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.051983</td>\n",
       "      <td>0.982481</td>\n",
       "      <td>0.072902</td>\n",
       "      <td>0.977487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.052655</td>\n",
       "      <td>0.981816</td>\n",
       "      <td>0.073350</td>\n",
       "      <td>0.977487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.052238</td>\n",
       "      <td>0.981816</td>\n",
       "      <td>0.073180</td>\n",
       "      <td>0.977487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.053592</td>\n",
       "      <td>0.982149</td>\n",
       "      <td>0.073485</td>\n",
       "      <td>0.976963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.051713</td>\n",
       "      <td>0.982260</td>\n",
       "      <td>0.074451</td>\n",
       "      <td>0.976963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.052106</td>\n",
       "      <td>0.982481</td>\n",
       "      <td>0.074490</td>\n",
       "      <td>0.976963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.053024</td>\n",
       "      <td>0.982371</td>\n",
       "      <td>0.073067</td>\n",
       "      <td>0.977487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.050781</td>\n",
       "      <td>0.982703</td>\n",
       "      <td>0.074027</td>\n",
       "      <td>0.976963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.050381</td>\n",
       "      <td>0.982925</td>\n",
       "      <td>0.073754</td>\n",
       "      <td>0.976963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.050409</td>\n",
       "      <td>0.983258</td>\n",
       "      <td>0.073462</td>\n",
       "      <td>0.977487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  Accuracy  val_loss  val_Accuracy\n",
       "0   0.244764  0.924825  0.149314      0.963351\n",
       "1   0.139062  0.963300  0.109381      0.970157\n",
       "2   0.115214  0.967402  0.097550      0.971204\n",
       "3   0.105376  0.969065  0.089083      0.973822\n",
       "4   0.097436  0.971172  0.085564      0.974869\n",
       "5   0.091995  0.972281  0.083870      0.974346\n",
       "6   0.088043  0.973168  0.086005      0.975393\n",
       "7   0.085564  0.973944  0.080252      0.974869\n",
       "8   0.081394  0.974831  0.077308      0.975393\n",
       "9   0.081968  0.975053  0.078460      0.974869\n",
       "10  0.080269  0.974942  0.079804      0.974869\n",
       "11  0.077203  0.976161  0.075253      0.975393\n",
       "12  0.074922  0.976383  0.079139      0.975393\n",
       "13  0.073984  0.976938  0.075698      0.975916\n",
       "14  0.075405  0.976383  0.078569      0.975916\n",
       "15  0.072288  0.977270  0.074584      0.975916\n",
       "16  0.070800  0.977714  0.074208      0.975916\n",
       "17  0.068530  0.978046  0.075563      0.976440\n",
       "18  0.068712  0.977603  0.073088      0.976440\n",
       "19  0.071080  0.978046  0.073531      0.976963\n",
       "20  0.068276  0.978046  0.074157      0.977487\n",
       "21  0.065146  0.978822  0.076754      0.977487\n",
       "22  0.064967  0.978822  0.073743      0.977487\n",
       "23  0.065645  0.979266  0.073004      0.977487\n",
       "24  0.065444  0.978822  0.073634      0.977487\n",
       "25  0.062324  0.979710  0.075359      0.976963\n",
       "26  0.062482  0.978933  0.074490      0.976963\n",
       "27  0.061038  0.979377  0.073225      0.978010\n",
       "28  0.062025  0.979599  0.092740      0.973822\n",
       "29  0.061252  0.980264  0.072583      0.977487\n",
       "30  0.061057  0.980707  0.073566      0.977487\n",
       "31  0.059995  0.981040  0.073584      0.977487\n",
       "32  0.059626  0.980375  0.073877      0.976963\n",
       "33  0.059778  0.980375  0.075410      0.976963\n",
       "34  0.061967  0.980153  0.083764      0.974869\n",
       "35  0.059131  0.981373  0.075704      0.976963\n",
       "36  0.058444  0.980597  0.073444      0.977487\n",
       "37  0.057055  0.980929  0.076547      0.977487\n",
       "38  0.056323  0.981040  0.074982      0.976963\n",
       "39  0.056995  0.980818  0.072574      0.978010\n",
       "40  0.056323  0.981040  0.073203      0.976963\n",
       "41  0.054732  0.981594  0.075545      0.976440\n",
       "42  0.055362  0.981594  0.072367      0.978010\n",
       "43  0.054500  0.981484  0.072268      0.977487\n",
       "44  0.057637  0.980929  0.072780      0.976963\n",
       "45  0.055482  0.981705  0.072921      0.977487\n",
       "46  0.054056  0.981594  0.073584      0.976963\n",
       "47  0.054352  0.981705  0.073020      0.978010\n",
       "48  0.053733  0.981262  0.072822      0.977487\n",
       "49  0.054128  0.981373  0.073489      0.977487\n",
       "50  0.051983  0.982481  0.072902      0.977487\n",
       "51  0.052655  0.981816  0.073350      0.977487\n",
       "52  0.052238  0.981816  0.073180      0.977487\n",
       "53  0.053592  0.982149  0.073485      0.976963\n",
       "54  0.051713  0.982260  0.074451      0.976963\n",
       "55  0.052106  0.982481  0.074490      0.976963\n",
       "56  0.053024  0.982371  0.073067      0.977487\n",
       "57  0.050781  0.982703  0.074027      0.976963\n",
       "58  0.050381  0.982925  0.073754      0.976963\n",
       "59  0.050409  0.983258  0.073462      0.977487"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dic = {}\n",
    "for key in ('loss', 'Accuracy', 'val_loss', 'val_Accuracy'):\n",
    "    dic[key] = history.history[key]\n",
    "df = pd.DataFrame(dic)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluacion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 42s 655ms/step - loss: 0.0918 - Accuracy: 0.9725 - Precision: 0.9523 - Recall: 0.9299 - TP: 686.2900 - TN: 1195.7600 - FP: 30.2400 - FN: 51.7100\n",
      "Loss: 0.09\n",
      "Accuracy: 0.97\n",
      "Precision: 0.98\n",
      "Recall: 0.95\n",
      "F1: 0.96\n",
      "TP:  699.0\n",
      "TN:  1211.0\n",
      "FP:  15.0\n",
      "FN:  39.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Documents\\Tesis\\codigo\\evaluador.py:44: RuntimeWarning: invalid value encountered in true_divide\n",
      "  F1 = (2 * precision * recall) / (precision + recall)\n"
     ]
    }
   ],
   "source": [
    "eval = evaluador.ClassifierEvaluator(classifier.model)\n",
    "loss, bacc, precision, recall, F1, TP, TN, FP, FN = eval.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731.0</td>\n",
       "      <td>849.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>730.0</td>\n",
       "      <td>964.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>726.0</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>725.0</td>\n",
       "      <td>1059.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>722.0</td>\n",
       "      <td>1086.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>721.0</td>\n",
       "      <td>1103.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>721.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>720.0</td>\n",
       "      <td>1121.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>720.0</td>\n",
       "      <td>1126.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>720.0</td>\n",
       "      <td>1133.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>718.0</td>\n",
       "      <td>1144.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>716.0</td>\n",
       "      <td>1149.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>716.0</td>\n",
       "      <td>1151.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>711.0</td>\n",
       "      <td>1158.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>710.0</td>\n",
       "      <td>1161.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>710.0</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>710.0</td>\n",
       "      <td>1167.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>710.0</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>710.0</td>\n",
       "      <td>1176.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>708.0</td>\n",
       "      <td>1177.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>708.0</td>\n",
       "      <td>1178.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>708.0</td>\n",
       "      <td>1182.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>708.0</td>\n",
       "      <td>1183.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>708.0</td>\n",
       "      <td>1184.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>708.0</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>708.0</td>\n",
       "      <td>1187.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>708.0</td>\n",
       "      <td>1189.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>708.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>707.0</td>\n",
       "      <td>1194.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>707.0</td>\n",
       "      <td>1194.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>705.0</td>\n",
       "      <td>1196.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>705.0</td>\n",
       "      <td>1196.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>705.0</td>\n",
       "      <td>1197.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>705.0</td>\n",
       "      <td>1197.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>705.0</td>\n",
       "      <td>1199.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>705.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>705.0</td>\n",
       "      <td>1202.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>705.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>705.0</td>\n",
       "      <td>1204.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>704.0</td>\n",
       "      <td>1204.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>704.0</td>\n",
       "      <td>1206.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>704.0</td>\n",
       "      <td>1208.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>704.0</td>\n",
       "      <td>1209.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>704.0</td>\n",
       "      <td>1209.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>704.0</td>\n",
       "      <td>1209.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>702.0</td>\n",
       "      <td>1209.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>699.0</td>\n",
       "      <td>1210.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>697.0</td>\n",
       "      <td>1211.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>697.0</td>\n",
       "      <td>1211.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>695.0</td>\n",
       "      <td>1211.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>695.0</td>\n",
       "      <td>1211.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>695.0</td>\n",
       "      <td>1211.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>694.0</td>\n",
       "      <td>1211.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>693.0</td>\n",
       "      <td>1212.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>693.0</td>\n",
       "      <td>1212.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>693.0</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>692.0</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>692.0</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>692.0</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>692.0</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>692.0</td>\n",
       "      <td>1214.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>692.0</td>\n",
       "      <td>1214.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>692.0</td>\n",
       "      <td>1214.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>692.0</td>\n",
       "      <td>1215.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>691.0</td>\n",
       "      <td>1215.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>691.0</td>\n",
       "      <td>1216.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>691.0</td>\n",
       "      <td>1217.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>691.0</td>\n",
       "      <td>1217.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>690.0</td>\n",
       "      <td>1217.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>689.0</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>689.0</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>689.0</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>688.0</td>\n",
       "      <td>1221.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>685.0</td>\n",
       "      <td>1221.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>685.0</td>\n",
       "      <td>1221.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>684.0</td>\n",
       "      <td>1222.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>683.0</td>\n",
       "      <td>1222.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>682.0</td>\n",
       "      <td>1222.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>681.0</td>\n",
       "      <td>1222.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>679.0</td>\n",
       "      <td>1222.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>679.0</td>\n",
       "      <td>1222.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>677.0</td>\n",
       "      <td>1222.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>676.0</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>673.0</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>672.0</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>672.0</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>669.0</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>665.0</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>662.0</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>660.0</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>656.0</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>650.0</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>644.0</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>635.0</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>628.0</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>623.0</td>\n",
       "      <td>1225.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>617.0</td>\n",
       "      <td>1225.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>608.0</td>\n",
       "      <td>1225.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>588.0</td>\n",
       "      <td>1225.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1226.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>738.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TP      TN     FP     FN\n",
       "0   731.0   849.0  377.0    7.0\n",
       "1   730.0   964.0  262.0    8.0\n",
       "2   726.0  1036.0  190.0   12.0\n",
       "3   725.0  1059.0  167.0   13.0\n",
       "4   722.0  1086.0  140.0   16.0\n",
       "5   721.0  1103.0  123.0   17.0\n",
       "6   721.0  1110.0  116.0   17.0\n",
       "7   720.0  1121.0  105.0   18.0\n",
       "8   720.0  1126.0  100.0   18.0\n",
       "9   720.0  1133.0   93.0   18.0\n",
       "10  718.0  1144.0   82.0   20.0\n",
       "11  716.0  1149.0   77.0   22.0\n",
       "12  716.0  1151.0   75.0   22.0\n",
       "13  711.0  1158.0   68.0   27.0\n",
       "14  710.0  1161.0   65.0   28.0\n",
       "15  710.0  1165.0   61.0   28.0\n",
       "16  710.0  1167.0   59.0   28.0\n",
       "17  710.0  1174.0   52.0   28.0\n",
       "18  710.0  1176.0   50.0   28.0\n",
       "19  708.0  1177.0   49.0   30.0\n",
       "20  708.0  1178.0   48.0   30.0\n",
       "21  708.0  1182.0   44.0   30.0\n",
       "22  708.0  1183.0   43.0   30.0\n",
       "23  708.0  1184.0   42.0   30.0\n",
       "24  708.0  1185.0   41.0   30.0\n",
       "25  708.0  1187.0   39.0   30.0\n",
       "26  708.0  1189.0   37.0   30.0\n",
       "27  708.0  1193.0   33.0   30.0\n",
       "28  707.0  1194.0   32.0   31.0\n",
       "29  707.0  1194.0   32.0   31.0\n",
       "30  705.0  1196.0   30.0   33.0\n",
       "31  705.0  1196.0   30.0   33.0\n",
       "32  705.0  1197.0   29.0   33.0\n",
       "33  705.0  1197.0   29.0   33.0\n",
       "34  705.0  1199.0   27.0   33.0\n",
       "35  705.0  1200.0   26.0   33.0\n",
       "36  705.0  1202.0   24.0   33.0\n",
       "37  705.0  1203.0   23.0   33.0\n",
       "38  705.0  1204.0   22.0   33.0\n",
       "39  704.0  1204.0   22.0   34.0\n",
       "40  704.0  1206.0   20.0   34.0\n",
       "41  704.0  1208.0   18.0   34.0\n",
       "42  704.0  1209.0   17.0   34.0\n",
       "43  704.0  1209.0   17.0   34.0\n",
       "44  704.0  1209.0   17.0   34.0\n",
       "45  702.0  1209.0   17.0   36.0\n",
       "46  699.0  1210.0   16.0   39.0\n",
       "47  697.0  1211.0   15.0   41.0\n",
       "48  697.0  1211.0   15.0   41.0\n",
       "49  695.0  1211.0   15.0   43.0\n",
       "50  695.0  1211.0   15.0   43.0\n",
       "51  695.0  1211.0   15.0   43.0\n",
       "52  694.0  1211.0   15.0   44.0\n",
       "53  693.0  1212.0   14.0   45.0\n",
       "54  693.0  1212.0   14.0   45.0\n",
       "55  693.0  1213.0   13.0   45.0\n",
       "56  692.0  1213.0   13.0   46.0\n",
       "57  692.0  1213.0   13.0   46.0\n",
       "58  692.0  1213.0   13.0   46.0\n",
       "59  692.0  1213.0   13.0   46.0\n",
       "60  692.0  1214.0   12.0   46.0\n",
       "61  692.0  1214.0   12.0   46.0\n",
       "62  692.0  1214.0   12.0   46.0\n",
       "63  692.0  1215.0   11.0   46.0\n",
       "64  691.0  1215.0   11.0   47.0\n",
       "65  691.0  1216.0   10.0   47.0\n",
       "66  691.0  1217.0    9.0   47.0\n",
       "67  691.0  1217.0    9.0   47.0\n",
       "68  690.0  1217.0    9.0   48.0\n",
       "69  689.0  1218.0    8.0   49.0\n",
       "70  689.0  1218.0    8.0   49.0\n",
       "71  689.0  1220.0    6.0   49.0\n",
       "72  688.0  1221.0    5.0   50.0\n",
       "73  685.0  1221.0    5.0   53.0\n",
       "74  685.0  1221.0    5.0   53.0\n",
       "75  684.0  1222.0    4.0   54.0\n",
       "76  683.0  1222.0    4.0   55.0\n",
       "77  682.0  1222.0    4.0   56.0\n",
       "78  681.0  1222.0    4.0   57.0\n",
       "79  679.0  1222.0    4.0   59.0\n",
       "80  679.0  1222.0    4.0   59.0\n",
       "81  677.0  1222.0    4.0   61.0\n",
       "82  676.0  1223.0    3.0   62.0\n",
       "83  673.0  1223.0    3.0   65.0\n",
       "84  672.0  1223.0    3.0   66.0\n",
       "85  672.0  1223.0    3.0   66.0\n",
       "86  669.0  1223.0    3.0   69.0\n",
       "87  665.0  1223.0    3.0   73.0\n",
       "88  662.0  1223.0    3.0   76.0\n",
       "89  660.0  1223.0    3.0   78.0\n",
       "90  656.0  1223.0    3.0   82.0\n",
       "91  650.0  1223.0    3.0   88.0\n",
       "92  644.0  1223.0    3.0   94.0\n",
       "93  635.0  1224.0    2.0  103.0\n",
       "94  628.0  1224.0    2.0  110.0\n",
       "95  623.0  1225.0    1.0  115.0\n",
       "96  617.0  1225.0    1.0  121.0\n",
       "97  608.0  1225.0    1.0  130.0\n",
       "98  588.0  1225.0    1.0  150.0\n",
       "99    0.0  1226.0    0.0  738.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame({'TP':TP, 'TN':TN, 'FP':FP, 'FN':FN})\n",
    "\n",
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "\n",
    "# Display the entire DataFrame\n",
    "display(df)\n",
    "\n",
    "pd.reset_option('display.max_rows')\n",
    "pd.reset_option('display.max_columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval.plot_confusion_matrix(TP, TN, FP, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval.curva_det(TP, TN, FP, FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluacion en test set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "dir_metadata = \"..\\\\dataset\\\\sonidos_grabados\\\\mdgrabados.csv\"\n",
    "dir_audios =  \"..\\\\dataset\\\\sonidos_grabados\"\n",
    "\n",
    "recorded_dataset = dataLoader.AudioDataset(dir_metadata, dir_audios, split=False)\n",
    "test_ds2 = recorded_dataset.create_single_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 73s 397ms/step - loss: 0.1235 - Accuracy: 0.9630 - Precision: 0.9396 - Recall: 0.8386 - TP: 978.6900 - TN: 4312.7500 - FP: 60.2500 - FN: 188.3100\n",
      "Loss: 0.12\n",
      "Accuracy: 0.96\n",
      "Precision: 0.97\n",
      "Recall: 0.85\n",
      "F1: 0.91\n",
      "TP:  997.0\n",
      "TN:  4338.0\n",
      "FP:  35.0\n",
      "FN:  170.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Documents\\Tesis\\codigo\\evaluador.py:44: RuntimeWarning: invalid value encountered in true_divide\n",
      "  F1 = (2 * precision * recall) / (precision + recall)\n"
     ]
    }
   ],
   "source": [
    "eval = evaluador.ClassifierEvaluator(classifier.model)\n",
    "loss, bacc, precision, recall, F1, TP, TN, FP, FN = eval.evaluate(test_ds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1128.0</td>\n",
       "      <td>3877.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1117.0</td>\n",
       "      <td>4019.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1110.0</td>\n",
       "      <td>4084.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1108.0</td>\n",
       "      <td>4129.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1102.0</td>\n",
       "      <td>4155.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1095.0</td>\n",
       "      <td>4175.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1090.0</td>\n",
       "      <td>4191.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1088.0</td>\n",
       "      <td>4208.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1085.0</td>\n",
       "      <td>4215.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1080.0</td>\n",
       "      <td>4226.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1079.0</td>\n",
       "      <td>4237.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1078.0</td>\n",
       "      <td>4244.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1076.0</td>\n",
       "      <td>4249.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1074.0</td>\n",
       "      <td>4250.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1072.0</td>\n",
       "      <td>4255.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1070.0</td>\n",
       "      <td>4261.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1066.0</td>\n",
       "      <td>4264.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1062.0</td>\n",
       "      <td>4269.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1058.0</td>\n",
       "      <td>4277.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1056.0</td>\n",
       "      <td>4278.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1053.0</td>\n",
       "      <td>4282.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1051.0</td>\n",
       "      <td>4283.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1048.0</td>\n",
       "      <td>4286.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1046.0</td>\n",
       "      <td>4290.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1043.0</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1041.0</td>\n",
       "      <td>4301.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1038.0</td>\n",
       "      <td>4303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1037.0</td>\n",
       "      <td>4304.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1036.0</td>\n",
       "      <td>4308.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1034.0</td>\n",
       "      <td>4309.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1034.0</td>\n",
       "      <td>4312.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1034.0</td>\n",
       "      <td>4314.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1030.0</td>\n",
       "      <td>4316.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1030.0</td>\n",
       "      <td>4318.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1029.0</td>\n",
       "      <td>4319.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1029.0</td>\n",
       "      <td>4321.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1029.0</td>\n",
       "      <td>4323.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1027.0</td>\n",
       "      <td>4324.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1025.0</td>\n",
       "      <td>4325.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1025.0</td>\n",
       "      <td>4329.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1022.0</td>\n",
       "      <td>4329.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1021.0</td>\n",
       "      <td>4331.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>146.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1019.0</td>\n",
       "      <td>4333.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1018.0</td>\n",
       "      <td>4334.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1014.0</td>\n",
       "      <td>4334.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1007.0</td>\n",
       "      <td>4334.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1006.0</td>\n",
       "      <td>4334.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1001.0</td>\n",
       "      <td>4335.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>998.0</td>\n",
       "      <td>4338.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>997.0</td>\n",
       "      <td>4338.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>992.0</td>\n",
       "      <td>4338.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>991.0</td>\n",
       "      <td>4339.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>990.0</td>\n",
       "      <td>4340.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>987.0</td>\n",
       "      <td>4342.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>985.0</td>\n",
       "      <td>4342.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>984.0</td>\n",
       "      <td>4342.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>983.0</td>\n",
       "      <td>4342.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>980.0</td>\n",
       "      <td>4343.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>187.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>978.0</td>\n",
       "      <td>4346.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>189.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>975.0</td>\n",
       "      <td>4346.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>971.0</td>\n",
       "      <td>4347.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>969.0</td>\n",
       "      <td>4347.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>967.0</td>\n",
       "      <td>4347.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>966.0</td>\n",
       "      <td>4349.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>201.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>964.0</td>\n",
       "      <td>4349.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>203.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>962.0</td>\n",
       "      <td>4350.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>960.0</td>\n",
       "      <td>4351.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>207.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>956.0</td>\n",
       "      <td>4353.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>954.0</td>\n",
       "      <td>4354.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>213.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>952.0</td>\n",
       "      <td>4354.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>950.0</td>\n",
       "      <td>4358.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>946.0</td>\n",
       "      <td>4359.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>221.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>946.0</td>\n",
       "      <td>4359.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>221.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>945.0</td>\n",
       "      <td>4359.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>222.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>942.0</td>\n",
       "      <td>4359.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>941.0</td>\n",
       "      <td>4360.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>937.0</td>\n",
       "      <td>4361.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>931.0</td>\n",
       "      <td>4361.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>236.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>929.0</td>\n",
       "      <td>4361.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>927.0</td>\n",
       "      <td>4364.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>924.0</td>\n",
       "      <td>4364.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>243.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>920.0</td>\n",
       "      <td>4365.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>247.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>919.0</td>\n",
       "      <td>4365.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>248.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>919.0</td>\n",
       "      <td>4366.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>248.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>915.0</td>\n",
       "      <td>4367.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>252.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>912.0</td>\n",
       "      <td>4368.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>907.0</td>\n",
       "      <td>4369.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>904.0</td>\n",
       "      <td>4370.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>263.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>898.0</td>\n",
       "      <td>4370.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>269.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>886.0</td>\n",
       "      <td>4370.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>281.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>876.0</td>\n",
       "      <td>4370.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>291.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>869.0</td>\n",
       "      <td>4370.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>298.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>860.0</td>\n",
       "      <td>4370.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>307.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>852.0</td>\n",
       "      <td>4370.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>315.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>839.0</td>\n",
       "      <td>4371.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>328.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>822.0</td>\n",
       "      <td>4371.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>345.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>797.0</td>\n",
       "      <td>4371.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>370.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>766.0</td>\n",
       "      <td>4371.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>401.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>708.0</td>\n",
       "      <td>4372.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>459.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4373.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1167.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        TP      TN     FP      FN\n",
       "0   1128.0  3877.0  496.0    39.0\n",
       "1   1117.0  4019.0  354.0    50.0\n",
       "2   1110.0  4084.0  289.0    57.0\n",
       "3   1108.0  4129.0  244.0    59.0\n",
       "4   1102.0  4155.0  218.0    65.0\n",
       "5   1095.0  4175.0  198.0    72.0\n",
       "6   1090.0  4191.0  182.0    77.0\n",
       "7   1088.0  4208.0  165.0    79.0\n",
       "8   1085.0  4215.0  158.0    82.0\n",
       "9   1080.0  4226.0  147.0    87.0\n",
       "10  1079.0  4237.0  136.0    88.0\n",
       "11  1078.0  4244.0  129.0    89.0\n",
       "12  1076.0  4249.0  124.0    91.0\n",
       "13  1074.0  4250.0  123.0    93.0\n",
       "14  1072.0  4255.0  118.0    95.0\n",
       "15  1070.0  4261.0  112.0    97.0\n",
       "16  1066.0  4264.0  109.0   101.0\n",
       "17  1062.0  4269.0  104.0   105.0\n",
       "18  1058.0  4277.0   96.0   109.0\n",
       "19  1056.0  4278.0   95.0   111.0\n",
       "20  1053.0  4282.0   91.0   114.0\n",
       "21  1051.0  4283.0   90.0   116.0\n",
       "22  1048.0  4286.0   87.0   119.0\n",
       "23  1046.0  4290.0   83.0   121.0\n",
       "24  1043.0  4300.0   73.0   124.0\n",
       "25  1041.0  4301.0   72.0   126.0\n",
       "26  1038.0  4303.0   70.0   129.0\n",
       "27  1037.0  4304.0   69.0   130.0\n",
       "28  1036.0  4308.0   65.0   131.0\n",
       "29  1034.0  4309.0   64.0   133.0\n",
       "30  1034.0  4312.0   61.0   133.0\n",
       "31  1034.0  4314.0   59.0   133.0\n",
       "32  1030.0  4316.0   57.0   137.0\n",
       "33  1030.0  4318.0   55.0   137.0\n",
       "34  1029.0  4319.0   54.0   138.0\n",
       "35  1029.0  4321.0   52.0   138.0\n",
       "36  1029.0  4323.0   50.0   138.0\n",
       "37  1027.0  4324.0   49.0   140.0\n",
       "38  1025.0  4325.0   48.0   142.0\n",
       "39  1025.0  4329.0   44.0   142.0\n",
       "40  1022.0  4329.0   44.0   145.0\n",
       "41  1021.0  4331.0   42.0   146.0\n",
       "42  1019.0  4333.0   40.0   148.0\n",
       "43  1018.0  4334.0   39.0   149.0\n",
       "44  1014.0  4334.0   39.0   153.0\n",
       "45  1007.0  4334.0   39.0   160.0\n",
       "46  1006.0  4334.0   39.0   161.0\n",
       "47  1001.0  4335.0   38.0   166.0\n",
       "48   998.0  4338.0   35.0   169.0\n",
       "49   997.0  4338.0   35.0   170.0\n",
       "50   992.0  4338.0   35.0   175.0\n",
       "51   991.0  4339.0   34.0   176.0\n",
       "52   990.0  4340.0   33.0   177.0\n",
       "53   987.0  4342.0   31.0   180.0\n",
       "54   985.0  4342.0   31.0   182.0\n",
       "55   984.0  4342.0   31.0   183.0\n",
       "56   983.0  4342.0   31.0   184.0\n",
       "57   980.0  4343.0   30.0   187.0\n",
       "58   978.0  4346.0   27.0   189.0\n",
       "59   975.0  4346.0   27.0   192.0\n",
       "60   971.0  4347.0   26.0   196.0\n",
       "61   969.0  4347.0   26.0   198.0\n",
       "62   967.0  4347.0   26.0   200.0\n",
       "63   966.0  4349.0   24.0   201.0\n",
       "64   964.0  4349.0   24.0   203.0\n",
       "65   962.0  4350.0   23.0   205.0\n",
       "66   960.0  4351.0   22.0   207.0\n",
       "67   956.0  4353.0   20.0   211.0\n",
       "68   954.0  4354.0   19.0   213.0\n",
       "69   952.0  4354.0   19.0   215.0\n",
       "70   950.0  4358.0   15.0   217.0\n",
       "71   946.0  4359.0   14.0   221.0\n",
       "72   946.0  4359.0   14.0   221.0\n",
       "73   945.0  4359.0   14.0   222.0\n",
       "74   942.0  4359.0   14.0   225.0\n",
       "75   941.0  4360.0   13.0   226.0\n",
       "76   937.0  4361.0   12.0   230.0\n",
       "77   931.0  4361.0   12.0   236.0\n",
       "78   929.0  4361.0   12.0   238.0\n",
       "79   927.0  4364.0    9.0   240.0\n",
       "80   924.0  4364.0    9.0   243.0\n",
       "81   920.0  4365.0    8.0   247.0\n",
       "82   919.0  4365.0    8.0   248.0\n",
       "83   919.0  4366.0    7.0   248.0\n",
       "84   915.0  4367.0    6.0   252.0\n",
       "85   912.0  4368.0    5.0   255.0\n",
       "86   907.0  4369.0    4.0   260.0\n",
       "87   904.0  4370.0    3.0   263.0\n",
       "88   898.0  4370.0    3.0   269.0\n",
       "89   886.0  4370.0    3.0   281.0\n",
       "90   876.0  4370.0    3.0   291.0\n",
       "91   869.0  4370.0    3.0   298.0\n",
       "92   860.0  4370.0    3.0   307.0\n",
       "93   852.0  4370.0    3.0   315.0\n",
       "94   839.0  4371.0    2.0   328.0\n",
       "95   822.0  4371.0    2.0   345.0\n",
       "96   797.0  4371.0    2.0   370.0\n",
       "97   766.0  4371.0    2.0   401.0\n",
       "98   708.0  4372.0    1.0   459.0\n",
       "99     0.0  4373.0    0.0  1167.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'TP':TP, 'TN':TN, 'FP':FP, 'FN':FN})\n",
    "\n",
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "\n",
    "# Display the entire DataFrame\n",
    "display(df)\n",
    "\n",
    "pd.reset_option('display.max_rows')\n",
    "pd.reset_option('display.max_columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curvas nuevas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = \"..\\\\metadata.csv\"\n",
    "audio_dir = \"..\\\\dataset\\\\audios\"\n",
    "\n",
    "audio_dataset = dataLoader.AudioDataset(metadata_path, audio_dir, BATCH_SIZE=32)\n",
    "train_ds, val_ds, test_ds = audio_dataset.preprocess_datasets()\n",
    "\n",
    "for i in \n",
    "classifier = modelo.Clasificador()\n",
    "classifier.units = 100\n",
    "classifier.alpha = 0.001\n",
    "classifier.compilar()\n",
    "history = classifier.train(train_ds, val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distancia (m)</th>\n",
       "      <th>Total</th>\n",
       "      <th>Positivos</th>\n",
       "      <th>Negativos</th>\n",
       "      <th>Exhaustividad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>257</td>\n",
       "      <td>97.276265</td>\n",
       "      <td>2.723735</td>\n",
       "      <td>0.972763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>341</td>\n",
       "      <td>97.067449</td>\n",
       "      <td>2.932551</td>\n",
       "      <td>0.970674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>569</td>\n",
       "      <td>56.766257</td>\n",
       "      <td>43.233743</td>\n",
       "      <td>0.567663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Distancia (m)  Total  Positivos  Negativos  Exhaustividad\n",
       "0             10    257  97.276265   2.723735       0.972763\n",
       "1             20    341  97.067449   2.932551       0.970674\n",
       "2             50    569  56.766257  43.233743       0.567663"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m10 = load_wav_16k_mono('..\\\\dataset\\\\sonidos_grabados\\\\STE-002.wav')\n",
    "m20 = load_wav_16k_mono('..\\\\dataset\\\\sonidos_grabados\\\\STE-004.wav')\n",
    "m50 = load_wav_16k_mono('..\\\\dataset\\\\sonidos_grabados\\\\STE-005.wav')\n",
    "\n",
    "def round_th(arr, th):\n",
    "    return np.where(arr >= th, 1, 0)\n",
    "\n",
    "def func(audio):\n",
    "    preds = modelo_final(audio).numpy()\n",
    "    labels = round_th(preds, 0.88)\n",
    "    tot = labels.shape[0]\n",
    "    pos = np.count_nonzero(labels)\n",
    "    neg = tot-pos\n",
    "    rec = pos / tot\n",
    "    return tot, pos, neg, rec \n",
    "\n",
    "t10, p10, n10, r10 = func(m10)\n",
    "t20, p20, n20, r20 = func(m20)\n",
    "t50, p50, n50, r50 = func(m50)\n",
    "\n",
    "dic = {'Distancia (m)': [10, 20, 50],\n",
    "       'Total': [t10, t20, t50],\n",
    "       'Positivos (%)': [p10*100/t10, p20*100/t20, p50*100/t50],\n",
    "       'Negativos (%)': [n10*100/t10, n20*100/t20, n50*100/t50],\n",
    "       'Exhaustividad': [r10, r20, r50]}\n",
    "\n",
    "pd.DataFrame(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yamnet vs clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "from yamnet import params as yamnet_params\n",
    "from yamnet import yamnet as yamnet_model\n",
    "\n",
    "params = yamnet_params.Params(patch_hop_seconds=0.96)\n",
    "yamnet = yamnet_model.yamnet_frames_model(params)\n",
    "yamnet.load_weights('C:\\\\Users\\\\user\\\\Documents\\\\Tesis\\\\codigo\\\\yamnet\\\\yamnet.h5')\n",
    "yamnet.traineable = False\n",
    "\n",
    "clasificador = tf.keras.models.load_model('.\\\\modelo_final_bn')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "# Define the function to load and preprocess the audio\n",
    "def load_wav_16k_mono(filename):\n",
    "    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav\n",
    "\n",
    "# Load the metadata CSV file\n",
    "dir_metadata = \"..\\\\dataset\\\\sonidos_grabados\\\\mdgrabados.csv\"\n",
    "dir_audios =  \"..\\\\dataset\\\\sonidos_grabados\"\n",
    "dataset = pd.read_csv(dir_metadata)\n",
    "\n",
    "# Prepend directory path to filenames\n",
    "dataset['filename'] = dataset['filename'].apply(lambda fname: os.path.join(dir_audios, fname))\n",
    "\n",
    "# Extract filenames and categories\n",
    "filenames = dataset['filename'].to_numpy()\n",
    "categories = np.array(dataset['category'].to_list())\n",
    "\n",
    "# Create a TensorFlow dataset from filenames and categories\n",
    "ds = tf.data.Dataset.from_tensor_slices((filenames, categories))\n",
    "\n",
    "# Map the load_wav_16k_mono function to the filenames\n",
    "def process_path(filename, label):\n",
    "    audio = load_wav_16k_mono(filename)\n",
    "    return audio, label\n",
    "\n",
    "# Apply the processing to each element in the dataset\n",
    "ds = ds.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# (Optional) Prefetch to improve performance\n",
    "ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "# Define the function to load, preprocess, and split the audio into windows\n",
    "def load_wav_16k_mono(filename):\n",
    "    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    \n",
    "    # Split audio into 0.96-second windows\n",
    "    window_size = int(0.96 * 16000)  # 15360 samples\n",
    "    num_windows = tf.math.floordiv(tf.size(wav), window_size)\n",
    "    wav = tf.reshape(wav[:num_windows * window_size], (num_windows, window_size))\n",
    "    \n",
    "    return wav\n",
    "\n",
    "# Load the metadata CSV file\n",
    "dir_metadata = \"..\\\\dataset\\\\sonidos_grabados\\\\mdgrabados.csv\"\n",
    "dir_audios =  \"..\\\\dataset\\\\sonidos_grabados\"\n",
    "dataset = pd.read_csv(dir_metadata)\n",
    "\n",
    "# Prepend directory path to filenames\n",
    "dataset['filename'] = dataset['filename'].apply(lambda fname: os.path.join(dir_audios, fname))\n",
    "\n",
    "# Extract filenames and categories\n",
    "filenames = dataset['filename'].to_numpy()\n",
    "categories = np.array(dataset['category'].to_list())\n",
    "\n",
    "# Create a TensorFlow dataset from filenames and categories\n",
    "ds = tf.data.Dataset.from_tensor_slices((filenames, categories))\n",
    "\n",
    "# Map the load_wav_16k_mono function to the filenames\n",
    "def process_path(filename, label):\n",
    "    audio = load_wav_16k_mono(filename)\n",
    "    labels = tf.fill([tf.shape(audio)[0]], label)\n",
    "    return audio, labels\n",
    "\n",
    "# Apply the processing to each element in the dataset\n",
    "ds = ds.flat_map(lambda filename, label: tf.data.Dataset.from_tensor_slices(process_path(filename, label)))\n",
    "\n",
    "# (Optional) Prefetch to improve performance\n",
    "ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Batch the dataset\n",
    "#ds = ds.batch(32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 0\n",
      "Predicting 1\n",
      "Predicting 2\n",
      "Predicting 3\n",
      "Predicting 4\n",
      "Predicting 5\n",
      "Predicting 6\n",
      "Predicting 7\n",
      "Predicting 8\n",
      "Predicting 9\n",
      "Predicting 10\n",
      "Predicting 11\n",
      "Predicting 12\n",
      "Predicting 13\n",
      "Predicting 14\n",
      "Predicting 15\n",
      "Predicting 16\n",
      "Predicting 17\n",
      "Predicting 18\n",
      "Predicting 19\n",
      "Predicting 20\n",
      "Predicting 21\n",
      "Predicting 22\n",
      "Predicting 23\n",
      "Predicting 24\n",
      "Predicting 25\n",
      "Predicting 26\n",
      "Predicting 27\n",
      "Predicting 28\n",
      "Predicting 29\n",
      "Predicting 30\n",
      "Predicting 31\n",
      "Predicting 32\n",
      "Predicting 33\n",
      "Predicting 34\n",
      "Predicting 35\n",
      "Predicting 36\n",
      "Predicting 37\n",
      "Predicting 38\n",
      "Predicting 39\n",
      "Predicting 40\n",
      "Predicting 41\n",
      "Predicting 42\n",
      "Predicting 43\n",
      "Predicting 44\n",
      "Predicting 45\n",
      "Predicting 46\n",
      "Predicting 47\n",
      "Predicting 48\n",
      "Predicting 49\n",
      "Predicting 50\n",
      "Predicting 51\n",
      "Predicting 52\n",
      "Predicting 53\n",
      "Predicting 54\n",
      "Predicting 55\n",
      "Predicting 56\n",
      "Predicting 57\n",
      "Predicting 58\n",
      "Predicting 59\n",
      "Predicting 60\n",
      "Predicting 61\n",
      "Predicting 62\n",
      "Predicting 63\n",
      "Predicting 64\n",
      "Predicting 65\n",
      "Predicting 66\n",
      "Predicting 67\n",
      "Predicting 68\n",
      "Predicting 69\n",
      "Predicting 70\n",
      "Predicting 71\n",
      "Predicting 72\n",
      "Predicting 73\n",
      "Predicting 74\n",
      "Predicting 75\n",
      "Predicting 76\n",
      "Predicting 77\n",
      "Predicting 78\n",
      "Predicting 79\n",
      "Predicting 80\n",
      "Predicting 81\n",
      "Predicting 82\n",
      "Predicting 83\n",
      "Predicting 84\n",
      "Predicting 85\n",
      "Predicting 86\n",
      "Predicting 87\n",
      "Predicting 88\n",
      "Predicting 89\n",
      "Predicting 90\n",
      "Predicting 91\n",
      "Predicting 92\n",
      "Predicting 93\n",
      "Predicting 94\n",
      "Predicting 95\n",
      "Predicting 96\n",
      "Predicting 97\n",
      "Predicting 98\n",
      "Predicting 99\n",
      "Predicting 100\n",
      "Predicting 101\n",
      "Predicting 102\n",
      "Predicting 103\n",
      "Predicting 104\n",
      "Predicting 105\n",
      "Predicting 106\n",
      "Predicting 107\n",
      "Predicting 108\n",
      "Predicting 109\n",
      "Predicting 110\n",
      "Predicting 111\n",
      "Predicting 112\n",
      "Predicting 113\n",
      "Predicting 114\n",
      "Predicting 115\n",
      "Predicting 116\n",
      "Predicting 117\n",
      "Predicting 118\n",
      "Predicting 119\n",
      "Predicting 120\n",
      "Predicting 121\n",
      "Predicting 122\n",
      "Predicting 123\n",
      "Predicting 124\n",
      "Predicting 125\n",
      "Predicting 126\n",
      "Predicting 127\n",
      "Predicting 128\n",
      "Predicting 129\n",
      "Predicting 130\n",
      "Predicting 131\n",
      "Predicting 132\n",
      "Predicting 133\n",
      "Predicting 134\n",
      "Predicting 135\n",
      "Predicting 136\n",
      "Predicting 137\n",
      "Predicting 138\n",
      "Predicting 139\n",
      "Predicting 140\n",
      "Predicting 141\n",
      "Predicting 142\n",
      "Predicting 143\n",
      "Predicting 144\n",
      "Predicting 145\n",
      "Predicting 146\n",
      "Predicting 147\n",
      "Predicting 148\n",
      "Predicting 149\n",
      "Predicting 150\n",
      "Predicting 151\n",
      "Predicting 152\n",
      "Predicting 153\n",
      "Predicting 154\n",
      "Predicting 155\n",
      "Predicting 156\n",
      "Predicting 157\n",
      "Predicting 158\n",
      "Predicting 159\n",
      "Predicting 160\n",
      "Predicting 161\n",
      "Predicting 162\n",
      "Predicting 163\n",
      "Predicting 164\n",
      "Predicting 165\n",
      "Predicting 166\n",
      "Predicting 167\n",
      "Predicting 168\n",
      "Predicting 169\n",
      "Predicting 170\n",
      "Predicting 171\n",
      "Predicting 172\n",
      "Predicting 173\n",
      "Predicting 174\n",
      "Predicting 175\n",
      "Predicting 176\n",
      "Predicting 177\n",
      "Predicting 178\n",
      "Predicting 179\n",
      "Predicting 180\n",
      "Predicting 181\n",
      "Predicting 182\n",
      "Predicting 183\n",
      "Predicting 184\n",
      "Predicting 185\n",
      "Predicting 186\n",
      "Predicting 187\n",
      "Predicting 188\n",
      "Predicting 189\n",
      "Predicting 190\n",
      "Predicting 191\n",
      "Predicting 192\n",
      "Predicting 193\n",
      "Predicting 194\n",
      "Predicting 195\n",
      "Predicting 196\n",
      "Predicting 197\n",
      "Predicting 198\n",
      "Predicting 199\n",
      "Predicting 200\n",
      "Predicting 201\n",
      "Predicting 202\n",
      "Predicting 203\n",
      "Predicting 204\n",
      "Predicting 205\n",
      "Predicting 206\n",
      "Predicting 207\n",
      "Predicting 208\n",
      "Predicting 209\n",
      "Predicting 210\n",
      "Predicting 211\n",
      "Predicting 212\n",
      "Predicting 213\n",
      "Predicting 214\n",
      "Predicting 215\n",
      "Predicting 216\n",
      "Predicting 217\n",
      "Predicting 218\n",
      "Predicting 219\n",
      "Predicting 220\n",
      "Predicting 221\n",
      "Predicting 222\n",
      "Predicting 223\n",
      "Predicting 224\n",
      "Predicting 225\n",
      "Predicting 226\n",
      "Predicting 227\n",
      "Predicting 228\n",
      "Predicting 229\n",
      "Predicting 230\n",
      "Predicting 231\n",
      "Predicting 232\n",
      "Predicting 233\n",
      "Predicting 234\n",
      "Predicting 235\n",
      "Predicting 236\n",
      "Predicting 237\n",
      "Predicting 238\n",
      "Predicting 239\n",
      "Predicting 240\n",
      "Predicting 241\n",
      "Predicting 242\n",
      "Predicting 243\n",
      "Predicting 244\n",
      "Predicting 245\n",
      "Predicting 246\n",
      "Predicting 247\n",
      "Predicting 248\n",
      "Predicting 249\n",
      "Predicting 250\n",
      "Predicting 251\n",
      "Predicting 252\n",
      "Predicting 253\n",
      "Predicting 254\n",
      "Predicting 255\n",
      "Predicting 256\n",
      "Predicting 257\n",
      "Predicting 258\n",
      "Predicting 259\n",
      "Predicting 260\n",
      "Predicting 261\n",
      "Predicting 262\n",
      "Predicting 263\n",
      "Predicting 264\n",
      "Predicting 265\n",
      "Predicting 266\n",
      "Predicting 267\n",
      "Predicting 268\n",
      "Predicting 269\n",
      "Predicting 270\n",
      "Predicting 271\n",
      "Predicting 272\n",
      "Predicting 273\n",
      "Predicting 274\n",
      "Predicting 275\n",
      "Predicting 276\n",
      "Predicting 277\n",
      "Predicting 278\n",
      "Predicting 279\n",
      "Predicting 280\n",
      "Predicting 281\n",
      "Predicting 282\n",
      "Predicting 283\n",
      "Predicting 284\n",
      "Predicting 285\n",
      "Predicting 286\n",
      "Predicting 287\n",
      "Predicting 288\n",
      "Predicting 289\n",
      "Predicting 290\n",
      "Predicting 291\n",
      "Predicting 292\n",
      "Predicting 293\n",
      "Predicting 294\n",
      "Predicting 295\n",
      "Predicting 296\n",
      "Predicting 297\n",
      "Predicting 298\n",
      "Predicting 299\n",
      "Predicting 300\n",
      "Predicting 301\n",
      "Predicting 302\n",
      "Predicting 303\n",
      "Predicting 304\n",
      "Predicting 305\n",
      "Predicting 306\n",
      "Predicting 307\n",
      "Predicting 308\n",
      "Predicting 309\n",
      "Predicting 310\n",
      "Predicting 311\n",
      "Predicting 312\n",
      "Predicting 313\n",
      "Predicting 314\n",
      "Predicting 315\n",
      "Predicting 316\n",
      "Predicting 317\n",
      "Predicting 318\n",
      "Predicting 319\n",
      "Predicting 320\n",
      "Predicting 321\n",
      "Predicting 322\n",
      "Predicting 323\n",
      "Predicting 324\n",
      "Predicting 325\n",
      "Predicting 326\n",
      "Predicting 327\n",
      "Predicting 328\n",
      "Predicting 329\n",
      "Predicting 330\n",
      "Predicting 331\n",
      "Predicting 332\n",
      "Predicting 333\n",
      "Predicting 334\n",
      "Predicting 335\n",
      "Predicting 336\n",
      "Predicting 337\n",
      "Predicting 338\n",
      "Predicting 339\n",
      "Predicting 340\n",
      "Predicting 341\n",
      "Predicting 342\n",
      "Predicting 343\n",
      "Predicting 344\n",
      "Predicting 345\n",
      "Predicting 346\n",
      "Predicting 347\n",
      "Predicting 348\n",
      "Predicting 349\n",
      "Predicting 350\n",
      "Predicting 351\n",
      "Predicting 352\n",
      "Predicting 353\n",
      "Predicting 354\n",
      "Predicting 355\n",
      "Predicting 356\n",
      "Predicting 357\n",
      "Predicting 358\n",
      "Predicting 359\n",
      "Predicting 360\n",
      "Predicting 361\n",
      "Predicting 362\n",
      "Predicting 363\n",
      "Predicting 364\n",
      "Predicting 365\n",
      "Predicting 366\n",
      "Predicting 367\n",
      "Predicting 368\n",
      "Predicting 369\n",
      "Predicting 370\n",
      "Predicting 371\n",
      "Predicting 372\n",
      "Predicting 373\n",
      "Predicting 374\n",
      "Predicting 375\n",
      "Predicting 376\n",
      "Predicting 377\n",
      "Predicting 378\n",
      "Predicting 379\n",
      "Predicting 380\n",
      "Predicting 381\n",
      "Predicting 382\n",
      "Predicting 383\n",
      "Predicting 384\n",
      "Predicting 385\n",
      "Predicting 386\n",
      "Predicting 387\n",
      "Predicting 388\n",
      "Predicting 389\n",
      "Predicting 390\n",
      "Predicting 391\n",
      "Predicting 392\n",
      "Predicting 393\n",
      "Predicting 394\n",
      "Predicting 395\n",
      "Predicting 396\n",
      "Predicting 397\n",
      "Predicting 398\n",
      "Predicting 399\n",
      "Predicting 400\n",
      "Predicting 401\n",
      "Predicting 402\n",
      "Predicting 403\n",
      "Predicting 404\n",
      "Predicting 405\n",
      "Predicting 406\n",
      "Predicting 407\n",
      "Predicting 408\n",
      "Predicting 409\n",
      "Predicting 410\n",
      "Predicting 411\n",
      "Predicting 412\n",
      "Predicting 413\n",
      "Predicting 414\n",
      "Predicting 415\n",
      "Predicting 416\n",
      "Predicting 417\n",
      "Predicting 418\n",
      "Predicting 419\n",
      "Predicting 420\n",
      "Predicting 421\n",
      "Predicting 422\n",
      "Predicting 423\n",
      "Predicting 424\n",
      "Predicting 425\n",
      "Predicting 426\n",
      "Predicting 427\n",
      "Predicting 428\n",
      "Predicting 429\n",
      "Predicting 430\n",
      "Predicting 431\n",
      "Predicting 432\n",
      "Predicting 433\n",
      "Predicting 434\n",
      "Predicting 435\n",
      "Predicting 436\n",
      "Predicting 437\n",
      "Predicting 438\n",
      "Predicting 439\n",
      "Predicting 440\n",
      "Predicting 441\n",
      "Predicting 442\n",
      "Predicting 443\n",
      "Predicting 444\n",
      "Predicting 445\n",
      "Predicting 446\n",
      "Predicting 447\n",
      "Predicting 448\n",
      "Predicting 449\n",
      "Predicting 450\n",
      "Predicting 451\n",
      "Predicting 452\n",
      "Predicting 453\n",
      "Predicting 454\n",
      "Predicting 455\n",
      "Predicting 456\n",
      "Predicting 457\n",
      "Predicting 458\n",
      "Predicting 459\n",
      "Predicting 460\n",
      "Predicting 461\n",
      "Predicting 462\n",
      "Predicting 463\n",
      "Predicting 464\n",
      "Predicting 465\n",
      "Predicting 466\n",
      "Predicting 467\n",
      "Predicting 468\n",
      "Predicting 469\n",
      "Predicting 470\n",
      "Predicting 471\n",
      "Predicting 472\n",
      "Predicting 473\n",
      "Predicting 474\n",
      "Predicting 475\n",
      "Predicting 476\n",
      "Predicting 477\n",
      "Predicting 478\n",
      "Predicting 479\n",
      "Predicting 480\n",
      "Predicting 481\n",
      "Predicting 482\n",
      "Predicting 483\n",
      "Predicting 484\n",
      "Predicting 485\n",
      "Predicting 486\n",
      "Predicting 487\n",
      "Predicting 488\n",
      "Predicting 489\n",
      "Predicting 490\n",
      "Predicting 491\n",
      "Predicting 492\n",
      "Predicting 493\n",
      "Predicting 494\n",
      "Predicting 495\n",
      "Predicting 496\n",
      "Predicting 497\n",
      "Predicting 498\n",
      "Predicting 499\n",
      "Predicting 500\n",
      "Predicting 501\n",
      "Predicting 502\n",
      "Predicting 503\n",
      "Predicting 504\n",
      "Predicting 505\n",
      "Predicting 506\n",
      "Predicting 507\n",
      "Predicting 508\n",
      "Predicting 509\n",
      "Predicting 510\n",
      "Predicting 511\n",
      "Predicting 512\n",
      "Predicting 513\n",
      "Predicting 514\n",
      "Predicting 515\n",
      "Predicting 516\n",
      "Predicting 517\n",
      "Predicting 518\n",
      "Predicting 519\n",
      "Predicting 520\n",
      "Predicting 521\n",
      "Predicting 522\n",
      "Predicting 523\n",
      "Predicting 524\n",
      "Predicting 525\n",
      "Predicting 526\n",
      "Predicting 527\n",
      "Predicting 528\n",
      "Predicting 529\n",
      "Predicting 530\n",
      "Predicting 531\n",
      "Predicting 532\n",
      "Predicting 533\n",
      "Predicting 534\n",
      "Predicting 535\n",
      "Predicting 536\n",
      "Predicting 537\n",
      "Predicting 538\n",
      "Predicting 539\n",
      "Predicting 540\n",
      "Predicting 541\n",
      "Predicting 542\n",
      "Predicting 543\n",
      "Predicting 544\n",
      "Predicting 545\n",
      "Predicting 546\n",
      "Predicting 547\n",
      "Predicting 548\n",
      "Predicting 549\n",
      "Predicting 550\n",
      "Predicting 551\n",
      "Predicting 552\n",
      "Predicting 553\n",
      "Predicting 554\n",
      "Predicting 555\n",
      "Predicting 556\n",
      "Predicting 557\n",
      "Predicting 558\n",
      "Predicting 559\n",
      "Predicting 560\n",
      "Predicting 561\n",
      "Predicting 562\n",
      "Predicting 563\n",
      "Predicting 564\n",
      "Predicting 565\n",
      "Predicting 566\n",
      "Predicting 567\n",
      "Predicting 568\n",
      "Predicting 569\n",
      "Predicting 570\n",
      "Predicting 571\n",
      "Predicting 572\n",
      "Predicting 573\n",
      "Predicting 574\n",
      "Predicting 575\n",
      "Predicting 576\n",
      "Predicting 577\n",
      "Predicting 578\n",
      "Predicting 579\n",
      "Predicting 580\n",
      "Predicting 581\n",
      "Predicting 582\n",
      "Predicting 583\n",
      "Predicting 584\n",
      "Predicting 585\n",
      "Predicting 586\n",
      "Predicting 587\n",
      "Predicting 588\n",
      "Predicting 589\n",
      "Predicting 590\n",
      "Predicting 591\n",
      "Predicting 592\n",
      "Predicting 593\n",
      "Predicting 594\n",
      "Predicting 595\n",
      "Predicting 596\n",
      "Predicting 597\n",
      "Predicting 598\n",
      "Predicting 599\n",
      "Predicting 600\n",
      "Predicting 601\n",
      "Predicting 602\n",
      "Predicting 603\n",
      "Predicting 604\n",
      "Predicting 605\n",
      "Predicting 606\n",
      "Predicting 607\n",
      "Predicting 608\n",
      "Predicting 609\n",
      "Predicting 610\n",
      "Predicting 611\n",
      "Predicting 612\n",
      "Predicting 613\n",
      "Predicting 614\n",
      "Predicting 615\n",
      "Predicting 616\n",
      "Predicting 617\n",
      "Predicting 618\n",
      "Predicting 619\n",
      "Predicting 620\n",
      "Predicting 621\n",
      "Predicting 622\n",
      "Predicting 623\n",
      "Predicting 624\n",
      "Predicting 625\n",
      "Predicting 626\n",
      "Predicting 627\n",
      "Predicting 628\n",
      "Predicting 629\n",
      "Predicting 630\n",
      "Predicting 631\n",
      "Predicting 632\n",
      "Predicting 633\n",
      "Predicting 634\n",
      "Predicting 635\n",
      "Predicting 636\n",
      "Predicting 637\n",
      "Predicting 638\n",
      "Predicting 639\n",
      "Predicting 640\n",
      "Predicting 641\n",
      "Predicting 642\n",
      "Predicting 643\n",
      "Predicting 644\n",
      "Predicting 645\n",
      "Predicting 646\n",
      "Predicting 647\n",
      "Predicting 648\n",
      "Predicting 649\n",
      "Predicting 650\n",
      "Predicting 651\n",
      "Predicting 652\n",
      "Predicting 653\n",
      "Predicting 654\n",
      "Predicting 655\n",
      "Predicting 656\n",
      "Predicting 657\n",
      "Predicting 658\n",
      "Predicting 659\n",
      "Predicting 660\n",
      "Predicting 661\n",
      "Predicting 662\n",
      "Predicting 663\n",
      "Predicting 664\n",
      "Predicting 665\n",
      "Predicting 666\n",
      "Predicting 667\n",
      "Predicting 668\n",
      "Predicting 669\n",
      "Predicting 670\n",
      "Predicting 671\n",
      "Predicting 672\n",
      "Predicting 673\n",
      "Predicting 674\n",
      "Predicting 675\n",
      "Predicting 676\n",
      "Predicting 677\n",
      "Predicting 678\n",
      "Predicting 679\n",
      "Predicting 680\n",
      "Predicting 681\n",
      "Predicting 682\n",
      "Predicting 683\n",
      "Predicting 684\n",
      "Predicting 685\n",
      "Predicting 686\n",
      "Predicting 687\n",
      "Predicting 688\n",
      "Predicting 689\n",
      "Predicting 690\n",
      "Predicting 691\n",
      "Predicting 692\n",
      "Predicting 693\n",
      "Predicting 694\n",
      "Predicting 695\n",
      "Predicting 696\n",
      "Predicting 697\n",
      "Predicting 698\n",
      "Predicting 699\n",
      "Predicting 700\n",
      "Predicting 701\n",
      "Predicting 702\n",
      "Predicting 703\n",
      "Predicting 704\n",
      "Predicting 705\n",
      "Predicting 706\n",
      "Predicting 707\n",
      "Predicting 708\n",
      "Predicting 709\n",
      "Predicting 710\n",
      "Predicting 711\n",
      "Predicting 712\n",
      "Predicting 713\n",
      "Predicting 714\n",
      "Predicting 715\n",
      "Predicting 716\n",
      "Predicting 717\n",
      "Predicting 718\n",
      "Predicting 719\n",
      "Predicting 720\n",
      "Predicting 721\n",
      "Predicting 722\n",
      "Predicting 723\n",
      "Predicting 724\n",
      "Predicting 725\n",
      "Predicting 726\n",
      "Predicting 727\n",
      "Predicting 728\n",
      "Predicting 729\n",
      "Predicting 730\n",
      "Predicting 731\n",
      "Predicting 732\n",
      "Predicting 733\n",
      "Predicting 734\n",
      "Predicting 735\n",
      "Predicting 736\n",
      "Predicting 737\n",
      "Predicting 738\n",
      "Predicting 739\n",
      "Predicting 740\n",
      "Predicting 741\n",
      "Predicting 742\n",
      "Predicting 743\n",
      "Predicting 744\n",
      "Predicting 745\n",
      "Predicting 746\n",
      "Predicting 747\n",
      "Predicting 748\n",
      "Predicting 749\n",
      "Predicting 750\n",
      "Predicting 751\n",
      "Predicting 752\n",
      "Predicting 753\n",
      "Predicting 754\n",
      "Predicting 755\n",
      "Predicting 756\n",
      "Predicting 757\n",
      "Predicting 758\n",
      "Predicting 759\n",
      "Predicting 760\n",
      "Predicting 761\n",
      "Predicting 762\n",
      "Predicting 763\n",
      "Predicting 764\n",
      "Predicting 765\n",
      "Predicting 766\n",
      "Predicting 767\n",
      "Predicting 768\n",
      "Predicting 769\n",
      "Predicting 770\n",
      "Predicting 771\n",
      "Predicting 772\n",
      "Predicting 773\n",
      "Predicting 774\n",
      "Predicting 775\n",
      "Predicting 776\n",
      "Predicting 777\n",
      "Predicting 778\n",
      "Predicting 779\n",
      "Predicting 780\n",
      "Predicting 781\n",
      "Predicting 782\n",
      "Predicting 783\n",
      "Predicting 784\n",
      "Predicting 785\n",
      "Predicting 786\n",
      "Predicting 787\n",
      "Predicting 788\n",
      "Predicting 789\n",
      "Predicting 790\n",
      "Predicting 791\n",
      "Predicting 792\n",
      "Predicting 793\n",
      "Predicting 794\n",
      "Predicting 795\n",
      "Predicting 796\n",
      "Predicting 797\n",
      "Predicting 798\n",
      "Predicting 799\n",
      "Predicting 800\n",
      "Predicting 801\n",
      "Predicting 802\n",
      "Predicting 803\n",
      "Predicting 804\n",
      "Predicting 805\n",
      "Predicting 806\n",
      "Predicting 807\n",
      "Predicting 808\n",
      "Predicting 809\n",
      "Predicting 810\n",
      "Predicting 811\n",
      "Predicting 812\n",
      "Predicting 813\n",
      "Predicting 814\n",
      "Predicting 815\n",
      "Predicting 816\n",
      "Predicting 817\n",
      "Predicting 818\n",
      "Predicting 819\n",
      "Predicting 820\n",
      "Predicting 821\n",
      "Predicting 822\n",
      "Predicting 823\n",
      "Predicting 824\n",
      "Predicting 825\n",
      "Predicting 826\n",
      "Predicting 827\n",
      "Predicting 828\n",
      "Predicting 829\n",
      "Predicting 830\n",
      "Predicting 831\n",
      "Predicting 832\n",
      "Predicting 833\n",
      "Predicting 834\n",
      "Predicting 835\n",
      "Predicting 836\n",
      "Predicting 837\n",
      "Predicting 838\n",
      "Predicting 839\n",
      "Predicting 840\n",
      "Predicting 841\n",
      "Predicting 842\n",
      "Predicting 843\n",
      "Predicting 844\n",
      "Predicting 845\n",
      "Predicting 846\n",
      "Predicting 847\n",
      "Predicting 848\n",
      "Predicting 849\n",
      "Predicting 850\n",
      "Predicting 851\n",
      "Predicting 852\n",
      "Predicting 853\n",
      "Predicting 854\n",
      "Predicting 855\n",
      "Predicting 856\n",
      "Predicting 857\n",
      "Predicting 858\n",
      "Predicting 859\n",
      "Predicting 860\n",
      "Predicting 861\n",
      "Predicting 862\n",
      "Predicting 863\n",
      "Predicting 864\n",
      "Predicting 865\n",
      "Predicting 866\n",
      "Predicting 867\n",
      "Predicting 868\n",
      "Predicting 869\n",
      "Predicting 870\n",
      "Predicting 871\n",
      "Predicting 872\n",
      "Predicting 873\n",
      "Predicting 874\n",
      "Predicting 875\n",
      "Predicting 876\n",
      "Predicting 877\n",
      "Predicting 878\n",
      "Predicting 879\n",
      "Predicting 880\n",
      "Predicting 881\n",
      "Predicting 882\n",
      "Predicting 883\n",
      "Predicting 884\n",
      "Predicting 885\n",
      "Predicting 886\n",
      "Predicting 887\n",
      "Predicting 888\n",
      "Predicting 889\n",
      "Predicting 890\n",
      "Predicting 891\n",
      "Predicting 892\n",
      "Predicting 893\n",
      "Predicting 894\n",
      "Predicting 895\n",
      "Predicting 896\n",
      "Predicting 897\n",
      "Predicting 898\n",
      "Predicting 899\n",
      "Predicting 900\n",
      "Predicting 901\n",
      "Predicting 902\n",
      "Predicting 903\n",
      "Predicting 904\n",
      "Predicting 905\n",
      "Predicting 906\n",
      "Predicting 907\n",
      "Predicting 908\n",
      "Predicting 909\n",
      "Predicting 910\n",
      "Predicting 911\n",
      "Predicting 912\n",
      "Predicting 913\n",
      "Predicting 914\n",
      "Predicting 915\n",
      "Predicting 916\n",
      "Predicting 917\n",
      "Predicting 918\n",
      "Predicting 919\n",
      "Predicting 920\n",
      "Predicting 921\n",
      "Predicting 922\n",
      "Predicting 923\n",
      "Predicting 924\n",
      "Predicting 925\n",
      "Predicting 926\n",
      "Predicting 927\n",
      "Predicting 928\n",
      "Predicting 929\n",
      "Predicting 930\n",
      "Predicting 931\n",
      "Predicting 932\n",
      "Predicting 933\n",
      "Predicting 934\n",
      "Predicting 935\n",
      "Predicting 936\n",
      "Predicting 937\n",
      "Predicting 938\n",
      "Predicting 939\n",
      "Predicting 940\n",
      "Predicting 941\n",
      "Predicting 942\n",
      "Predicting 943\n",
      "Predicting 944\n",
      "Predicting 945\n",
      "Predicting 946\n",
      "Predicting 947\n",
      "Predicting 948\n",
      "Predicting 949\n",
      "Predicting 950\n",
      "Predicting 951\n",
      "Predicting 952\n",
      "Predicting 953\n",
      "Predicting 954\n",
      "Predicting 955\n",
      "Predicting 956\n",
      "Predicting 957\n",
      "Predicting 958\n",
      "Predicting 959\n",
      "Predicting 960\n",
      "Predicting 961\n",
      "Predicting 962\n",
      "Predicting 963\n",
      "Predicting 964\n",
      "Predicting 965\n",
      "Predicting 966\n",
      "Predicting 967\n",
      "Predicting 968\n",
      "Predicting 969\n",
      "Predicting 970\n",
      "Predicting 971\n",
      "Predicting 972\n",
      "Predicting 973\n",
      "Predicting 974\n",
      "Predicting 975\n",
      "Predicting 976\n",
      "Predicting 977\n",
      "Predicting 978\n",
      "Predicting 979\n",
      "Predicting 980\n",
      "Predicting 981\n",
      "Predicting 982\n",
      "Predicting 983\n",
      "Predicting 984\n",
      "Predicting 985\n",
      "Predicting 986\n",
      "Predicting 987\n",
      "Predicting 988\n",
      "Predicting 989\n",
      "Predicting 990\n",
      "Predicting 991\n",
      "Predicting 992\n",
      "Predicting 993\n",
      "Predicting 994\n",
      "Predicting 995\n",
      "Predicting 996\n",
      "Predicting 997\n",
      "Predicting 998\n",
      "Predicting 999\n",
      "Predicting 1000\n",
      "Predicting 1001\n",
      "Predicting 1002\n",
      "Predicting 1003\n",
      "Predicting 1004\n",
      "Predicting 1005\n",
      "Predicting 1006\n",
      "Predicting 1007\n",
      "Predicting 1008\n",
      "Predicting 1009\n",
      "Predicting 1010\n",
      "Predicting 1011\n",
      "Predicting 1012\n",
      "Predicting 1013\n",
      "Predicting 1014\n",
      "Predicting 1015\n",
      "Predicting 1016\n",
      "Predicting 1017\n",
      "Predicting 1018\n",
      "Predicting 1019\n",
      "Predicting 1020\n",
      "Predicting 1021\n",
      "Predicting 1022\n",
      "Predicting 1023\n",
      "Predicting 1024\n",
      "Predicting 1025\n",
      "Predicting 1026\n",
      "Predicting 1027\n",
      "Predicting 1028\n",
      "Predicting 1029\n",
      "Predicting 1030\n",
      "Predicting 1031\n",
      "Predicting 1032\n",
      "Predicting 1033\n",
      "Predicting 1034\n",
      "Predicting 1035\n",
      "Predicting 1036\n",
      "Predicting 1037\n",
      "Predicting 1038\n",
      "Predicting 1039\n",
      "Predicting 1040\n",
      "Predicting 1041\n",
      "Predicting 1042\n",
      "Predicting 1043\n",
      "Predicting 1044\n",
      "Predicting 1045\n",
      "Predicting 1046\n",
      "Predicting 1047\n",
      "Predicting 1048\n",
      "Predicting 1049\n",
      "Predicting 1050\n",
      "Predicting 1051\n",
      "Predicting 1052\n",
      "Predicting 1053\n",
      "Predicting 1054\n",
      "Predicting 1055\n",
      "Predicting 1056\n",
      "Predicting 1057\n",
      "Predicting 1058\n",
      "Predicting 1059\n",
      "Predicting 1060\n",
      "Predicting 1061\n",
      "Predicting 1062\n",
      "Predicting 1063\n",
      "Predicting 1064\n",
      "Predicting 1065\n",
      "Predicting 1066\n",
      "Predicting 1067\n",
      "Predicting 1068\n",
      "Predicting 1069\n",
      "Predicting 1070\n",
      "Predicting 1071\n",
      "Predicting 1072\n",
      "Predicting 1073\n",
      "Predicting 1074\n",
      "Predicting 1075\n",
      "Predicting 1076\n",
      "Predicting 1077\n",
      "Predicting 1078\n",
      "Predicting 1079\n",
      "Predicting 1080\n",
      "Predicting 1081\n",
      "Predicting 1082\n",
      "Predicting 1083\n",
      "Predicting 1084\n",
      "Predicting 1085\n",
      "Predicting 1086\n",
      "Predicting 1087\n",
      "Predicting 1088\n",
      "Predicting 1089\n",
      "Predicting 1090\n",
      "Predicting 1091\n",
      "Predicting 1092\n",
      "Predicting 1093\n",
      "Predicting 1094\n",
      "Predicting 1095\n",
      "Predicting 1096\n",
      "Predicting 1097\n",
      "Predicting 1098\n",
      "Predicting 1099\n",
      "Predicting 1100\n",
      "Predicting 1101\n",
      "Predicting 1102\n",
      "Predicting 1103\n",
      "Predicting 1104\n",
      "Predicting 1105\n",
      "Predicting 1106\n",
      "Predicting 1107\n",
      "Predicting 1108\n",
      "Predicting 1109\n",
      "Predicting 1110\n",
      "Predicting 1111\n",
      "Predicting 1112\n",
      "Predicting 1113\n",
      "Predicting 1114\n",
      "Predicting 1115\n",
      "Predicting 1116\n",
      "Predicting 1117\n",
      "Predicting 1118\n",
      "Predicting 1119\n",
      "Predicting 1120\n",
      "Predicting 1121\n",
      "Predicting 1122\n",
      "Predicting 1123\n",
      "Predicting 1124\n",
      "Predicting 1125\n",
      "Predicting 1126\n",
      "Predicting 1127\n",
      "Predicting 1128\n",
      "Predicting 1129\n",
      "Predicting 1130\n",
      "Predicting 1131\n",
      "Predicting 1132\n",
      "Predicting 1133\n",
      "Predicting 1134\n",
      "Predicting 1135\n",
      "Predicting 1136\n",
      "Predicting 1137\n",
      "Predicting 1138\n",
      "Predicting 1139\n",
      "Predicting 1140\n",
      "Predicting 1141\n",
      "Predicting 1142\n",
      "Predicting 1143\n",
      "Predicting 1144\n",
      "Predicting 1145\n",
      "Predicting 1146\n",
      "Predicting 1147\n",
      "Predicting 1148\n",
      "Predicting 1149\n",
      "Predicting 1150\n",
      "Predicting 1151\n",
      "Predicting 1152\n",
      "Predicting 1153\n",
      "Predicting 1154\n",
      "Predicting 1155\n",
      "Predicting 1156\n",
      "Predicting 1157\n",
      "Predicting 1158\n",
      "Predicting 1159\n",
      "Predicting 1160\n",
      "Predicting 1161\n",
      "Predicting 1162\n",
      "Predicting 1163\n",
      "Predicting 1164\n",
      "Predicting 1165\n",
      "Predicting 1166\n",
      "Predicting 1167\n",
      "Predicting 1168\n",
      "Predicting 1169\n",
      "Predicting 1170\n",
      "Predicting 1171\n",
      "Predicting 1172\n",
      "Predicting 1173\n",
      "Predicting 1174\n",
      "Predicting 1175\n",
      "Predicting 1176\n",
      "Predicting 1177\n",
      "Predicting 1178\n",
      "Predicting 1179\n",
      "Predicting 1180\n",
      "Predicting 1181\n",
      "Predicting 1182\n",
      "Predicting 1183\n",
      "Predicting 1184\n",
      "Predicting 1185\n",
      "Predicting 1186\n",
      "Predicting 1187\n",
      "Predicting 1188\n",
      "Predicting 1189\n",
      "Predicting 1190\n",
      "Predicting 1191\n",
      "Predicting 1192\n",
      "Predicting 1193\n",
      "Predicting 1194\n",
      "Predicting 1195\n",
      "Predicting 1196\n",
      "Predicting 1197\n",
      "Predicting 1198\n",
      "Predicting 1199\n",
      "Predicting 1200\n",
      "Predicting 1201\n",
      "Predicting 1202\n",
      "Predicting 1203\n",
      "Predicting 1204\n",
      "Predicting 1205\n",
      "Predicting 1206\n",
      "Predicting 1207\n",
      "Predicting 1208\n",
      "Predicting 1209\n",
      "Predicting 1210\n",
      "Predicting 1211\n",
      "Predicting 1212\n",
      "Predicting 1213\n",
      "Predicting 1214\n",
      "Predicting 1215\n",
      "Predicting 1216\n",
      "Predicting 1217\n",
      "Predicting 1218\n",
      "Predicting 1219\n",
      "Predicting 1220\n",
      "Predicting 1221\n",
      "Predicting 1222\n",
      "Predicting 1223\n",
      "Predicting 1224\n",
      "Predicting 1225\n",
      "Predicting 1226\n",
      "Predicting 1227\n",
      "Predicting 1228\n",
      "Predicting 1229\n",
      "Predicting 1230\n",
      "Predicting 1231\n",
      "Predicting 1232\n",
      "Predicting 1233\n",
      "Predicting 1234\n",
      "Predicting 1235\n",
      "Predicting 1236\n",
      "Predicting 1237\n",
      "Predicting 1238\n",
      "Predicting 1239\n",
      "Predicting 1240\n",
      "Predicting 1241\n",
      "Predicting 1242\n",
      "Predicting 1243\n",
      "Predicting 1244\n",
      "Predicting 1245\n",
      "Predicting 1246\n",
      "Predicting 1247\n",
      "Predicting 1248\n",
      "Predicting 1249\n",
      "Predicting 1250\n",
      "Predicting 1251\n",
      "Predicting 1252\n",
      "Predicting 1253\n",
      "Predicting 1254\n",
      "Predicting 1255\n",
      "Predicting 1256\n",
      "Predicting 1257\n",
      "Predicting 1258\n",
      "Predicting 1259\n",
      "Predicting 1260\n",
      "Predicting 1261\n",
      "Predicting 1262\n",
      "Predicting 1263\n",
      "Predicting 1264\n",
      "Predicting 1265\n",
      "Predicting 1266\n",
      "Predicting 1267\n",
      "Predicting 1268\n",
      "Predicting 1269\n",
      "Predicting 1270\n",
      "Predicting 1271\n",
      "Predicting 1272\n",
      "Predicting 1273\n",
      "Predicting 1274\n",
      "Predicting 1275\n",
      "Predicting 1276\n",
      "Predicting 1277\n",
      "Predicting 1278\n",
      "Predicting 1279\n",
      "Predicting 1280\n",
      "Predicting 1281\n",
      "Predicting 1282\n",
      "Predicting 1283\n",
      "Predicting 1284\n",
      "Predicting 1285\n",
      "Predicting 1286\n",
      "Predicting 1287\n",
      "Predicting 1288\n",
      "Predicting 1289\n",
      "Predicting 1290\n",
      "Predicting 1291\n",
      "Predicting 1292\n",
      "Predicting 1293\n",
      "Predicting 1294\n",
      "Predicting 1295\n",
      "Predicting 1296\n",
      "Predicting 1297\n",
      "Predicting 1298\n",
      "Predicting 1299\n",
      "Predicting 1300\n",
      "Predicting 1301\n",
      "Predicting 1302\n",
      "Predicting 1303\n",
      "Predicting 1304\n",
      "Predicting 1305\n",
      "Predicting 1306\n",
      "Predicting 1307\n",
      "Predicting 1308\n",
      "Predicting 1309\n",
      "Predicting 1310\n",
      "Predicting 1311\n",
      "Predicting 1312\n",
      "Predicting 1313\n",
      "Predicting 1314\n",
      "Predicting 1315\n",
      "Predicting 1316\n",
      "Predicting 1317\n",
      "Predicting 1318\n",
      "Predicting 1319\n",
      "Predicting 1320\n",
      "Predicting 1321\n",
      "Predicting 1322\n",
      "Predicting 1323\n",
      "Predicting 1324\n",
      "Predicting 1325\n",
      "Predicting 1326\n",
      "Predicting 1327\n",
      "Predicting 1328\n",
      "Predicting 1329\n",
      "Predicting 1330\n",
      "Predicting 1331\n",
      "Predicting 1332\n",
      "Predicting 1333\n",
      "Predicting 1334\n",
      "Predicting 1335\n",
      "Predicting 1336\n",
      "Predicting 1337\n",
      "Predicting 1338\n",
      "Predicting 1339\n",
      "Predicting 1340\n",
      "Predicting 1341\n",
      "Predicting 1342\n",
      "Predicting 1343\n",
      "Predicting 1344\n",
      "Predicting 1345\n",
      "Predicting 1346\n",
      "Predicting 1347\n",
      "Predicting 1348\n",
      "Predicting 1349\n",
      "Predicting 1350\n",
      "Predicting 1351\n",
      "Predicting 1352\n",
      "Predicting 1353\n",
      "Predicting 1354\n",
      "Predicting 1355\n",
      "Predicting 1356\n",
      "Predicting 1357\n",
      "Predicting 1358\n",
      "Predicting 1359\n",
      "Predicting 1360\n",
      "Predicting 1361\n",
      "Predicting 1362\n",
      "Predicting 1363\n",
      "Predicting 1364\n",
      "Predicting 1365\n",
      "Predicting 1366\n",
      "Predicting 1367\n",
      "Predicting 1368\n",
      "Predicting 1369\n",
      "Predicting 1370\n",
      "Predicting 1371\n",
      "Predicting 1372\n",
      "Predicting 1373\n",
      "Predicting 1374\n",
      "Predicting 1375\n",
      "Predicting 1376\n",
      "Predicting 1377\n",
      "Predicting 1378\n",
      "Predicting 1379\n",
      "Predicting 1380\n",
      "Predicting 1381\n",
      "Predicting 1382\n",
      "Predicting 1383\n",
      "Predicting 1384\n",
      "Predicting 1385\n",
      "Predicting 1386\n",
      "Predicting 1387\n",
      "Predicting 1388\n",
      "Predicting 1389\n",
      "Predicting 1390\n",
      "Predicting 1391\n",
      "Predicting 1392\n",
      "Predicting 1393\n",
      "Predicting 1394\n",
      "Predicting 1395\n",
      "Predicting 1396\n",
      "Predicting 1397\n",
      "Predicting 1398\n",
      "Predicting 1399\n",
      "Predicting 1400\n",
      "Predicting 1401\n",
      "Predicting 1402\n",
      "Predicting 1403\n",
      "Predicting 1404\n",
      "Predicting 1405\n",
      "Predicting 1406\n",
      "Predicting 1407\n",
      "Predicting 1408\n",
      "Predicting 1409\n",
      "Predicting 1410\n",
      "Predicting 1411\n",
      "Predicting 1412\n",
      "Predicting 1413\n",
      "Predicting 1414\n",
      "Predicting 1415\n",
      "Predicting 1416\n",
      "Predicting 1417\n",
      "Predicting 1418\n",
      "Predicting 1419\n",
      "Predicting 1420\n",
      "Predicting 1421\n",
      "Predicting 1422\n",
      "Predicting 1423\n",
      "Predicting 1424\n",
      "Predicting 1425\n",
      "Predicting 1426\n",
      "Predicting 1427\n",
      "Predicting 1428\n",
      "Predicting 1429\n",
      "Predicting 1430\n",
      "Predicting 1431\n",
      "Predicting 1432\n",
      "Predicting 1433\n",
      "Predicting 1434\n",
      "Predicting 1435\n",
      "Predicting 1436\n",
      "Predicting 1437\n",
      "Predicting 1438\n",
      "Predicting 1439\n",
      "Predicting 1440\n",
      "Predicting 1441\n",
      "Predicting 1442\n",
      "Predicting 1443\n",
      "Predicting 1444\n",
      "Predicting 1445\n",
      "Predicting 1446\n",
      "Predicting 1447\n",
      "Predicting 1448\n",
      "Predicting 1449\n",
      "Predicting 1450\n",
      "Predicting 1451\n",
      "Predicting 1452\n",
      "Predicting 1453\n",
      "Predicting 1454\n",
      "Predicting 1455\n",
      "Predicting 1456\n",
      "Predicting 1457\n",
      "Predicting 1458\n",
      "Predicting 1459\n",
      "Predicting 1460\n",
      "Predicting 1461\n",
      "Predicting 1462\n",
      "Predicting 1463\n",
      "Predicting 1464\n",
      "Predicting 1465\n",
      "Predicting 1466\n",
      "Predicting 1467\n",
      "Predicting 1468\n",
      "Predicting 1469\n",
      "Predicting 1470\n",
      "Predicting 1471\n",
      "Predicting 1472\n",
      "Predicting 1473\n",
      "Predicting 1474\n",
      "Predicting 1475\n",
      "Predicting 1476\n",
      "Predicting 1477\n",
      "Predicting 1478\n",
      "Predicting 1479\n",
      "Predicting 1480\n",
      "Predicting 1481\n",
      "Predicting 1482\n",
      "Predicting 1483\n",
      "Predicting 1484\n",
      "Predicting 1485\n",
      "Predicting 1486\n",
      "Predicting 1487\n",
      "Predicting 1488\n",
      "Predicting 1489\n",
      "Predicting 1490\n",
      "Predicting 1491\n",
      "Predicting 1492\n",
      "Predicting 1493\n",
      "Predicting 1494\n",
      "Predicting 1495\n",
      "Predicting 1496\n",
      "Predicting 1497\n",
      "Predicting 1498\n",
      "Predicting 1499\n",
      "Predicting 1500\n",
      "Predicting 1501\n",
      "Predicting 1502\n",
      "Predicting 1503\n",
      "Predicting 1504\n",
      "Predicting 1505\n",
      "Predicting 1506\n",
      "Predicting 1507\n",
      "Predicting 1508\n",
      "Predicting 1509\n",
      "Predicting 1510\n",
      "Predicting 1511\n",
      "Predicting 1512\n",
      "Predicting 1513\n",
      "Predicting 1514\n",
      "Predicting 1515\n",
      "Predicting 1516\n",
      "Predicting 1517\n",
      "Predicting 1518\n",
      "Predicting 1519\n",
      "Predicting 1520\n",
      "Predicting 1521\n",
      "Predicting 1522\n",
      "Predicting 1523\n",
      "Predicting 1524\n",
      "Predicting 1525\n",
      "Predicting 1526\n",
      "Predicting 1527\n",
      "Predicting 1528\n",
      "Predicting 1529\n",
      "Predicting 1530\n",
      "Predicting 1531\n",
      "Predicting 1532\n",
      "Predicting 1533\n",
      "Predicting 1534\n",
      "Predicting 1535\n",
      "Predicting 1536\n",
      "Predicting 1537\n",
      "Predicting 1538\n",
      "Predicting 1539\n",
      "Predicting 1540\n",
      "Predicting 1541\n",
      "Predicting 1542\n",
      "Predicting 1543\n",
      "Predicting 1544\n",
      "Predicting 1545\n",
      "Predicting 1546\n",
      "Predicting 1547\n",
      "Predicting 1548\n",
      "Predicting 1549\n",
      "Predicting 1550\n",
      "Predicting 1551\n",
      "Predicting 1552\n",
      "Predicting 1553\n",
      "Predicting 1554\n",
      "Predicting 1555\n",
      "Predicting 1556\n",
      "Predicting 1557\n",
      "Predicting 1558\n",
      "Predicting 1559\n",
      "Predicting 1560\n",
      "Predicting 1561\n",
      "Predicting 1562\n",
      "Predicting 1563\n",
      "Predicting 1564\n",
      "Predicting 1565\n",
      "Predicting 1566\n",
      "Predicting 1567\n",
      "Predicting 1568\n",
      "Predicting 1569\n",
      "Predicting 1570\n",
      "Predicting 1571\n",
      "Predicting 1572\n",
      "Predicting 1573\n",
      "Predicting 1574\n",
      "Predicting 1575\n",
      "Predicting 1576\n",
      "Predicting 1577\n",
      "Predicting 1578\n",
      "Predicting 1579\n",
      "Predicting 1580\n",
      "Predicting 1581\n",
      "Predicting 1582\n",
      "Predicting 1583\n",
      "Predicting 1584\n",
      "Predicting 1585\n",
      "Predicting 1586\n",
      "Predicting 1587\n",
      "Predicting 1588\n",
      "Predicting 1589\n",
      "Predicting 1590\n",
      "Predicting 1591\n",
      "Predicting 1592\n",
      "Predicting 1593\n",
      "Predicting 1594\n",
      "Predicting 1595\n",
      "Predicting 1596\n",
      "Predicting 1597\n",
      "Predicting 1598\n",
      "Predicting 1599\n",
      "Predicting 1600\n",
      "Predicting 1601\n",
      "Predicting 1602\n",
      "Predicting 1603\n",
      "Predicting 1604\n",
      "Predicting 1605\n",
      "Predicting 1606\n",
      "Predicting 1607\n",
      "Predicting 1608\n",
      "Predicting 1609\n",
      "Predicting 1610\n",
      "Predicting 1611\n",
      "Predicting 1612\n",
      "Predicting 1613\n",
      "Predicting 1614\n",
      "Predicting 1615\n",
      "Predicting 1616\n",
      "Predicting 1617\n",
      "Predicting 1618\n",
      "Predicting 1619\n",
      "Predicting 1620\n",
      "Predicting 1621\n",
      "Predicting 1622\n",
      "Predicting 1623\n",
      "Predicting 1624\n",
      "Predicting 1625\n",
      "Predicting 1626\n",
      "Predicting 1627\n",
      "Predicting 1628\n",
      "Predicting 1629\n",
      "Predicting 1630\n",
      "Predicting 1631\n",
      "Predicting 1632\n",
      "Predicting 1633\n",
      "Predicting 1634\n",
      "Predicting 1635\n",
      "Predicting 1636\n",
      "Predicting 1637\n",
      "Predicting 1638\n",
      "Predicting 1639\n",
      "Predicting 1640\n",
      "Predicting 1641\n",
      "Predicting 1642\n",
      "Predicting 1643\n",
      "Predicting 1644\n",
      "Predicting 1645\n",
      "Predicting 1646\n",
      "Predicting 1647\n",
      "Predicting 1648\n",
      "Predicting 1649\n",
      "Predicting 1650\n",
      "Predicting 1651\n",
      "Predicting 1652\n",
      "Predicting 1653\n",
      "Predicting 1654\n",
      "Predicting 1655\n",
      "Predicting 1656\n",
      "Predicting 1657\n",
      "Predicting 1658\n",
      "Predicting 1659\n",
      "Predicting 1660\n",
      "Predicting 1661\n",
      "Predicting 1662\n",
      "Predicting 1663\n",
      "Predicting 1664\n",
      "Predicting 1665\n",
      "Predicting 1666\n",
      "Predicting 1667\n",
      "Predicting 1668\n",
      "Predicting 1669\n",
      "Predicting 1670\n",
      "Predicting 1671\n",
      "Predicting 1672\n",
      "Predicting 1673\n",
      "Predicting 1674\n",
      "Predicting 1675\n",
      "Predicting 1676\n",
      "Predicting 1677\n",
      "Predicting 1678\n",
      "Predicting 1679\n",
      "Predicting 1680\n",
      "Predicting 1681\n",
      "Predicting 1682\n",
      "Predicting 1683\n",
      "Predicting 1684\n",
      "Predicting 1685\n",
      "Predicting 1686\n",
      "Predicting 1687\n",
      "Predicting 1688\n",
      "Predicting 1689\n",
      "Predicting 1690\n",
      "Predicting 1691\n",
      "Predicting 1692\n",
      "Predicting 1693\n",
      "Predicting 1694\n",
      "Predicting 1695\n",
      "Predicting 1696\n",
      "Predicting 1697\n",
      "Predicting 1698\n",
      "Predicting 1699\n",
      "Predicting 1700\n",
      "Predicting 1701\n",
      "Predicting 1702\n",
      "Predicting 1703\n",
      "Predicting 1704\n",
      "Predicting 1705\n",
      "Predicting 1706\n",
      "Predicting 1707\n",
      "Predicting 1708\n",
      "Predicting 1709\n",
      "Predicting 1710\n",
      "Predicting 1711\n",
      "Predicting 1712\n",
      "Predicting 1713\n",
      "Predicting 1714\n",
      "Predicting 1715\n",
      "Predicting 1716\n",
      "Predicting 1717\n",
      "Predicting 1718\n",
      "Predicting 1719\n",
      "Predicting 1720\n",
      "Predicting 1721\n",
      "Predicting 1722\n",
      "Predicting 1723\n",
      "Predicting 1724\n",
      "Predicting 1725\n",
      "Predicting 1726\n",
      "Predicting 1727\n",
      "Predicting 1728\n",
      "Predicting 1729\n",
      "Predicting 1730\n",
      "Predicting 1731\n",
      "Predicting 1732\n",
      "Predicting 1733\n",
      "Predicting 1734\n",
      "Predicting 1735\n",
      "Predicting 1736\n",
      "Predicting 1737\n",
      "Predicting 1738\n",
      "Predicting 1739\n",
      "Predicting 1740\n",
      "Predicting 1741\n",
      "Predicting 1742\n",
      "Predicting 1743\n",
      "Predicting 1744\n",
      "Predicting 1745\n",
      "Predicting 1746\n",
      "Predicting 1747\n",
      "Predicting 1748\n",
      "Predicting 1749\n",
      "Predicting 1750\n",
      "Predicting 1751\n",
      "Predicting 1752\n",
      "Predicting 1753\n",
      "Predicting 1754\n",
      "Predicting 1755\n",
      "Predicting 1756\n",
      "Predicting 1757\n",
      "Predicting 1758\n",
      "Predicting 1759\n",
      "Predicting 1760\n",
      "Predicting 1761\n",
      "Predicting 1762\n",
      "Predicting 1763\n",
      "Predicting 1764\n",
      "Predicting 1765\n",
      "Predicting 1766\n",
      "Predicting 1767\n",
      "Predicting 1768\n",
      "Predicting 1769\n",
      "Predicting 1770\n",
      "Predicting 1771\n",
      "Predicting 1772\n",
      "Predicting 1773\n",
      "Predicting 1774\n",
      "Predicting 1775\n",
      "Predicting 1776\n",
      "Predicting 1777\n",
      "Predicting 1778\n",
      "Predicting 1779\n",
      "Predicting 1780\n",
      "Predicting 1781\n",
      "Predicting 1782\n",
      "Predicting 1783\n",
      "Predicting 1784\n",
      "Predicting 1785\n",
      "Predicting 1786\n",
      "Predicting 1787\n",
      "Predicting 1788\n",
      "Predicting 1789\n",
      "Predicting 1790\n",
      "Predicting 1791\n",
      "Predicting 1792\n",
      "Predicting 1793\n",
      "Predicting 1794\n",
      "Predicting 1795\n",
      "Predicting 1796\n",
      "Predicting 1797\n",
      "Predicting 1798\n",
      "Predicting 1799\n",
      "Predicting 1800\n",
      "Predicting 1801\n",
      "Predicting 1802\n",
      "Predicting 1803\n",
      "Predicting 1804\n",
      "Predicting 1805\n",
      "Predicting 1806\n",
      "Predicting 1807\n",
      "Predicting 1808\n",
      "Predicting 1809\n",
      "Predicting 1810\n",
      "Predicting 1811\n",
      "Predicting 1812\n",
      "Predicting 1813\n",
      "Predicting 1814\n",
      "Predicting 1815\n",
      "Predicting 1816\n",
      "Predicting 1817\n",
      "Predicting 1818\n",
      "Predicting 1819\n",
      "Predicting 1820\n",
      "Predicting 1821\n",
      "Predicting 1822\n",
      "Predicting 1823\n",
      "Predicting 1824\n",
      "Predicting 1825\n",
      "Predicting 1826\n",
      "Predicting 1827\n",
      "Predicting 1828\n",
      "Predicting 1829\n",
      "Predicting 1830\n",
      "Predicting 1831\n",
      "Predicting 1832\n",
      "Predicting 1833\n",
      "Predicting 1834\n",
      "Predicting 1835\n",
      "Predicting 1836\n",
      "Predicting 1837\n",
      "Predicting 1838\n",
      "Predicting 1839\n",
      "Predicting 1840\n",
      "Predicting 1841\n",
      "Predicting 1842\n",
      "Predicting 1843\n",
      "Predicting 1844\n",
      "Predicting 1845\n",
      "Predicting 1846\n",
      "Predicting 1847\n",
      "Predicting 1848\n",
      "Predicting 1849\n",
      "Predicting 1850\n",
      "Predicting 1851\n",
      "Predicting 1852\n",
      "Predicting 1853\n",
      "Predicting 1854\n",
      "Predicting 1855\n",
      "Predicting 1856\n",
      "Predicting 1857\n",
      "Predicting 1858\n",
      "Predicting 1859\n",
      "Predicting 1860\n",
      "Predicting 1861\n",
      "Predicting 1862\n",
      "Predicting 1863\n",
      "Predicting 1864\n",
      "Predicting 1865\n",
      "Predicting 1866\n",
      "Predicting 1867\n",
      "Predicting 1868\n",
      "Predicting 1869\n",
      "Predicting 1870\n",
      "Predicting 1871\n",
      "Predicting 1872\n",
      "Predicting 1873\n",
      "Predicting 1874\n",
      "Predicting 1875\n",
      "Predicting 1876\n",
      "Predicting 1877\n",
      "Predicting 1878\n",
      "Predicting 1879\n",
      "Predicting 1880\n",
      "Predicting 1881\n",
      "Predicting 1882\n",
      "Predicting 1883\n",
      "Predicting 1884\n",
      "Predicting 1885\n",
      "Predicting 1886\n",
      "Predicting 1887\n",
      "Predicting 1888\n",
      "Predicting 1889\n",
      "Predicting 1890\n",
      "Predicting 1891\n",
      "Predicting 1892\n",
      "Predicting 1893\n",
      "Predicting 1894\n",
      "Predicting 1895\n",
      "Predicting 1896\n",
      "Predicting 1897\n",
      "Predicting 1898\n",
      "Predicting 1899\n",
      "Predicting 1900\n",
      "Predicting 1901\n",
      "Predicting 1902\n",
      "Predicting 1903\n",
      "Predicting 1904\n",
      "Predicting 1905\n",
      "Predicting 1906\n",
      "Predicting 1907\n",
      "Predicting 1908\n",
      "Predicting 1909\n",
      "Predicting 1910\n",
      "Predicting 1911\n",
      "Predicting 1912\n",
      "Predicting 1913\n",
      "Predicting 1914\n",
      "Predicting 1915\n",
      "Predicting 1916\n",
      "Predicting 1917\n",
      "Predicting 1918\n",
      "Predicting 1919\n",
      "Predicting 1920\n",
      "Predicting 1921\n",
      "Predicting 1922\n",
      "Predicting 1923\n",
      "Predicting 1924\n",
      "Predicting 1925\n",
      "Predicting 1926\n",
      "Predicting 1927\n",
      "Predicting 1928\n",
      "Predicting 1929\n",
      "Predicting 1930\n",
      "Predicting 1931\n",
      "Predicting 1932\n",
      "Predicting 1933\n",
      "Predicting 1934\n",
      "Predicting 1935\n",
      "Predicting 1936\n",
      "Predicting 1937\n",
      "Predicting 1938\n",
      "Predicting 1939\n",
      "Predicting 1940\n",
      "Predicting 1941\n",
      "Predicting 1942\n",
      "Predicting 1943\n",
      "Predicting 1944\n",
      "Predicting 1945\n",
      "Predicting 1946\n",
      "Predicting 1947\n",
      "Predicting 1948\n",
      "Predicting 1949\n",
      "Predicting 1950\n",
      "Predicting 1951\n",
      "Predicting 1952\n",
      "Predicting 1953\n",
      "Predicting 1954\n",
      "Predicting 1955\n",
      "Predicting 1956\n",
      "Predicting 1957\n",
      "Predicting 1958\n",
      "Predicting 1959\n",
      "Predicting 1960\n",
      "Predicting 1961\n",
      "Predicting 1962\n",
      "Predicting 1963\n",
      "Predicting 1964\n",
      "Predicting 1965\n",
      "Predicting 1966\n",
      "Predicting 1967\n",
      "Predicting 1968\n",
      "Predicting 1969\n",
      "Predicting 1970\n",
      "Predicting 1971\n",
      "Predicting 1972\n",
      "Predicting 1973\n",
      "Predicting 1974\n",
      "Predicting 1975\n",
      "Predicting 1976\n",
      "Predicting 1977\n",
      "Predicting 1978\n",
      "Predicting 1979\n",
      "Predicting 1980\n",
      "Predicting 1981\n",
      "Predicting 1982\n",
      "Predicting 1983\n",
      "Predicting 1984\n",
      "Predicting 1985\n",
      "Predicting 1986\n",
      "Predicting 1987\n",
      "Predicting 1988\n",
      "Predicting 1989\n",
      "Predicting 1990\n",
      "Predicting 1991\n",
      "Predicting 1992\n",
      "Predicting 1993\n",
      "Predicting 1994\n",
      "Predicting 1995\n",
      "Predicting 1996\n",
      "Predicting 1997\n",
      "Predicting 1998\n",
      "Predicting 1999\n",
      "Predicting 2000\n",
      "Predicting 2001\n",
      "Predicting 2002\n",
      "Predicting 2003\n",
      "Predicting 2004\n",
      "Predicting 2005\n",
      "Predicting 2006\n",
      "Predicting 2007\n",
      "Predicting 2008\n",
      "Predicting 2009\n",
      "Predicting 2010\n",
      "Predicting 2011\n",
      "Predicting 2012\n",
      "Predicting 2013\n",
      "Predicting 2014\n",
      "Predicting 2015\n",
      "Predicting 2016\n",
      "Predicting 2017\n",
      "Predicting 2018\n",
      "Predicting 2019\n",
      "Predicting 2020\n",
      "Predicting 2021\n",
      "Predicting 2022\n",
      "Predicting 2023\n",
      "Predicting 2024\n",
      "Predicting 2025\n",
      "Predicting 2026\n",
      "Predicting 2027\n",
      "Predicting 2028\n",
      "Predicting 2029\n",
      "Predicting 2030\n",
      "Predicting 2031\n",
      "Predicting 2032\n",
      "Predicting 2033\n",
      "Predicting 2034\n",
      "Predicting 2035\n",
      "Predicting 2036\n",
      "Predicting 2037\n",
      "Predicting 2038\n",
      "Predicting 2039\n",
      "Predicting 2040\n",
      "Predicting 2041\n",
      "Predicting 2042\n",
      "Predicting 2043\n",
      "Predicting 2044\n",
      "Predicting 2045\n",
      "Predicting 2046\n",
      "Predicting 2047\n",
      "Predicting 2048\n",
      "Predicting 2049\n",
      "Predicting 2050\n",
      "Predicting 2051\n",
      "Predicting 2052\n",
      "Predicting 2053\n",
      "Predicting 2054\n",
      "Predicting 2055\n",
      "Predicting 2056\n",
      "Predicting 2057\n",
      "Predicting 2058\n",
      "Predicting 2059\n",
      "Predicting 2060\n",
      "Predicting 2061\n",
      "Predicting 2062\n",
      "Predicting 2063\n",
      "Predicting 2064\n",
      "Predicting 2065\n",
      "Predicting 2066\n",
      "Predicting 2067\n",
      "Predicting 2068\n",
      "Predicting 2069\n",
      "Predicting 2070\n",
      "Predicting 2071\n",
      "Predicting 2072\n",
      "Predicting 2073\n",
      "Predicting 2074\n",
      "Predicting 2075\n",
      "Predicting 2076\n",
      "Predicting 2077\n",
      "Predicting 2078\n",
      "Predicting 2079\n",
      "Predicting 2080\n",
      "Predicting 2081\n",
      "Predicting 2082\n",
      "Predicting 2083\n",
      "Predicting 2084\n",
      "Predicting 2085\n",
      "Predicting 2086\n",
      "Predicting 2087\n",
      "Predicting 2088\n",
      "Predicting 2089\n",
      "Predicting 2090\n",
      "Predicting 2091\n",
      "Predicting 2092\n",
      "Predicting 2093\n",
      "Predicting 2094\n",
      "Predicting 2095\n",
      "Predicting 2096\n",
      "Predicting 2097\n",
      "Predicting 2098\n",
      "Predicting 2099\n",
      "Predicting 2100\n",
      "Predicting 2101\n",
      "Predicting 2102\n",
      "Predicting 2103\n",
      "Predicting 2104\n",
      "Predicting 2105\n",
      "Predicting 2106\n",
      "Predicting 2107\n",
      "Predicting 2108\n",
      "Predicting 2109\n",
      "Predicting 2110\n",
      "Predicting 2111\n",
      "Predicting 2112\n",
      "Predicting 2113\n",
      "Predicting 2114\n",
      "Predicting 2115\n",
      "Predicting 2116\n",
      "Predicting 2117\n",
      "Predicting 2118\n",
      "Predicting 2119\n",
      "Predicting 2120\n",
      "Predicting 2121\n",
      "Predicting 2122\n",
      "Predicting 2123\n",
      "Predicting 2124\n",
      "Predicting 2125\n",
      "Predicting 2126\n",
      "Predicting 2127\n",
      "Predicting 2128\n",
      "Predicting 2129\n",
      "Predicting 2130\n",
      "Predicting 2131\n",
      "Predicting 2132\n",
      "Predicting 2133\n",
      "Predicting 2134\n",
      "Predicting 2135\n",
      "Predicting 2136\n",
      "Predicting 2137\n",
      "Predicting 2138\n",
      "Predicting 2139\n",
      "Predicting 2140\n",
      "Predicting 2141\n",
      "Predicting 2142\n",
      "Predicting 2143\n",
      "Predicting 2144\n",
      "Predicting 2145\n",
      "Predicting 2146\n",
      "Predicting 2147\n",
      "Predicting 2148\n",
      "Predicting 2149\n",
      "Predicting 2150\n",
      "Predicting 2151\n",
      "Predicting 2152\n",
      "Predicting 2153\n",
      "Predicting 2154\n",
      "Predicting 2155\n",
      "Predicting 2156\n",
      "Predicting 2157\n",
      "Predicting 2158\n",
      "Predicting 2159\n",
      "Predicting 2160\n",
      "Predicting 2161\n",
      "Predicting 2162\n",
      "Predicting 2163\n",
      "Predicting 2164\n",
      "Predicting 2165\n",
      "Predicting 2166\n",
      "Predicting 2167\n",
      "Predicting 2168\n",
      "Predicting 2169\n",
      "Predicting 2170\n",
      "Predicting 2171\n",
      "Predicting 2172\n",
      "Predicting 2173\n",
      "Predicting 2174\n",
      "Predicting 2175\n",
      "Predicting 2176\n",
      "Predicting 2177\n",
      "Predicting 2178\n",
      "Predicting 2179\n",
      "Predicting 2180\n",
      "Predicting 2181\n",
      "Predicting 2182\n",
      "Predicting 2183\n",
      "Predicting 2184\n",
      "Predicting 2185\n",
      "Predicting 2186\n",
      "Predicting 2187\n",
      "Predicting 2188\n",
      "Predicting 2189\n",
      "Predicting 2190\n",
      "Predicting 2191\n",
      "Predicting 2192\n",
      "Predicting 2193\n",
      "Predicting 2194\n",
      "Predicting 2195\n",
      "Predicting 2196\n",
      "Predicting 2197\n",
      "Predicting 2198\n",
      "Predicting 2199\n",
      "Predicting 2200\n",
      "Predicting 2201\n",
      "Predicting 2202\n",
      "Predicting 2203\n",
      "Predicting 2204\n",
      "Predicting 2205\n",
      "Predicting 2206\n",
      "Predicting 2207\n",
      "Predicting 2208\n",
      "Predicting 2209\n",
      "Predicting 2210\n",
      "Predicting 2211\n",
      "Predicting 2212\n",
      "Predicting 2213\n",
      "Predicting 2214\n",
      "Predicting 2215\n",
      "Predicting 2216\n",
      "Predicting 2217\n",
      "Predicting 2218\n",
      "Predicting 2219\n",
      "Predicting 2220\n",
      "Predicting 2221\n",
      "Predicting 2222\n",
      "Predicting 2223\n",
      "Predicting 2224\n",
      "Predicting 2225\n",
      "Predicting 2226\n",
      "Predicting 2227\n",
      "Predicting 2228\n",
      "Predicting 2229\n",
      "Predicting 2230\n",
      "Predicting 2231\n",
      "Predicting 2232\n",
      "Predicting 2233\n",
      "Predicting 2234\n",
      "Predicting 2235\n",
      "Predicting 2236\n",
      "Predicting 2237\n",
      "Predicting 2238\n",
      "Predicting 2239\n",
      "Predicting 2240\n",
      "Predicting 2241\n",
      "Predicting 2242\n",
      "Predicting 2243\n",
      "Predicting 2244\n",
      "Predicting 2245\n",
      "Predicting 2246\n",
      "Predicting 2247\n",
      "Predicting 2248\n",
      "Predicting 2249\n",
      "Predicting 2250\n",
      "Predicting 2251\n",
      "Predicting 2252\n",
      "Predicting 2253\n",
      "Predicting 2254\n",
      "Predicting 2255\n",
      "Predicting 2256\n",
      "Predicting 2257\n",
      "Predicting 2258\n",
      "Predicting 2259\n",
      "Predicting 2260\n",
      "Predicting 2261\n",
      "Predicting 2262\n",
      "Predicting 2263\n",
      "Predicting 2264\n",
      "Predicting 2265\n",
      "Predicting 2266\n",
      "Predicting 2267\n",
      "Predicting 2268\n",
      "Predicting 2269\n",
      "Predicting 2270\n",
      "Predicting 2271\n",
      "Predicting 2272\n",
      "Predicting 2273\n",
      "Predicting 2274\n",
      "Predicting 2275\n",
      "Predicting 2276\n",
      "Predicting 2277\n",
      "Predicting 2278\n",
      "Predicting 2279\n",
      "Predicting 2280\n",
      "Predicting 2281\n",
      "Predicting 2282\n",
      "Predicting 2283\n",
      "Predicting 2284\n",
      "Predicting 2285\n",
      "Predicting 2286\n",
      "Predicting 2287\n",
      "Predicting 2288\n",
      "Predicting 2289\n",
      "Predicting 2290\n",
      "Predicting 2291\n",
      "Predicting 2292\n",
      "Predicting 2293\n",
      "Predicting 2294\n",
      "Predicting 2295\n",
      "Predicting 2296\n",
      "Predicting 2297\n",
      "Predicting 2298\n",
      "Predicting 2299\n",
      "Predicting 2300\n",
      "Predicting 2301\n",
      "Predicting 2302\n",
      "Predicting 2303\n",
      "Predicting 2304\n",
      "Predicting 2305\n",
      "Predicting 2306\n",
      "Predicting 2307\n",
      "Predicting 2308\n",
      "Predicting 2309\n",
      "Predicting 2310\n",
      "Predicting 2311\n",
      "Predicting 2312\n",
      "Predicting 2313\n",
      "Predicting 2314\n",
      "Predicting 2315\n",
      "Predicting 2316\n",
      "Predicting 2317\n",
      "Predicting 2318\n",
      "Predicting 2319\n",
      "Predicting 2320\n",
      "Predicting 2321\n",
      "Predicting 2322\n",
      "Predicting 2323\n",
      "Predicting 2324\n",
      "Predicting 2325\n",
      "Predicting 2326\n",
      "Predicting 2327\n",
      "Predicting 2328\n",
      "Predicting 2329\n",
      "Predicting 2330\n",
      "Predicting 2331\n",
      "Predicting 2332\n",
      "Predicting 2333\n",
      "Predicting 2334\n",
      "Predicting 2335\n",
      "Predicting 2336\n",
      "Predicting 2337\n",
      "Predicting 2338\n",
      "Predicting 2339\n",
      "Predicting 2340\n",
      "Predicting 2341\n",
      "Predicting 2342\n",
      "Predicting 2343\n",
      "Predicting 2344\n",
      "Predicting 2345\n",
      "Predicting 2346\n",
      "Predicting 2347\n",
      "Predicting 2348\n",
      "Predicting 2349\n",
      "Predicting 2350\n",
      "Predicting 2351\n",
      "Predicting 2352\n",
      "Predicting 2353\n",
      "Predicting 2354\n",
      "Predicting 2355\n",
      "Predicting 2356\n",
      "Predicting 2357\n",
      "Predicting 2358\n",
      "Predicting 2359\n",
      "Predicting 2360\n",
      "Predicting 2361\n",
      "Predicting 2362\n",
      "Predicting 2363\n",
      "Predicting 2364\n",
      "Predicting 2365\n",
      "Predicting 2366\n",
      "Predicting 2367\n",
      "Predicting 2368\n",
      "Predicting 2369\n",
      "Predicting 2370\n",
      "Predicting 2371\n",
      "Predicting 2372\n",
      "Predicting 2373\n",
      "Predicting 2374\n",
      "Predicting 2375\n",
      "Predicting 2376\n",
      "Predicting 2377\n",
      "Predicting 2378\n",
      "Predicting 2379\n",
      "Predicting 2380\n",
      "Predicting 2381\n",
      "Predicting 2382\n",
      "Predicting 2383\n",
      "Predicting 2384\n",
      "Predicting 2385\n",
      "Predicting 2386\n",
      "Predicting 2387\n",
      "Predicting 2388\n",
      "Predicting 2389\n",
      "Predicting 2390\n",
      "Predicting 2391\n",
      "Predicting 2392\n",
      "Predicting 2393\n",
      "Predicting 2394\n",
      "Predicting 2395\n",
      "Predicting 2396\n",
      "Predicting 2397\n",
      "Predicting 2398\n",
      "Predicting 2399\n",
      "Predicting 2400\n",
      "Predicting 2401\n",
      "Predicting 2402\n",
      "Predicting 2403\n",
      "Predicting 2404\n",
      "Predicting 2405\n",
      "Predicting 2406\n",
      "Predicting 2407\n",
      "Predicting 2408\n",
      "Predicting 2409\n",
      "Predicting 2410\n",
      "Predicting 2411\n",
      "Predicting 2412\n",
      "Predicting 2413\n",
      "Predicting 2414\n",
      "Predicting 2415\n",
      "Predicting 2416\n",
      "Predicting 2417\n",
      "Predicting 2418\n",
      "Predicting 2419\n",
      "Predicting 2420\n",
      "Predicting 2421\n",
      "Predicting 2422\n",
      "Predicting 2423\n",
      "Predicting 2424\n",
      "Predicting 2425\n",
      "Predicting 2426\n",
      "Predicting 2427\n",
      "Predicting 2428\n",
      "Predicting 2429\n",
      "Predicting 2430\n",
      "Predicting 2431\n",
      "Predicting 2432\n",
      "Predicting 2433\n",
      "Predicting 2434\n",
      "Predicting 2435\n",
      "Predicting 2436\n",
      "Predicting 2437\n",
      "Predicting 2438\n",
      "Predicting 2439\n",
      "Predicting 2440\n",
      "Predicting 2441\n",
      "Predicting 2442\n",
      "Predicting 2443\n",
      "Predicting 2444\n",
      "Predicting 2445\n",
      "Predicting 2446\n",
      "Predicting 2447\n",
      "Predicting 2448\n",
      "Predicting 2449\n",
      "Predicting 2450\n",
      "Predicting 2451\n",
      "Predicting 2452\n",
      "Predicting 2453\n",
      "Predicting 2454\n",
      "Predicting 2455\n",
      "Predicting 2456\n",
      "Predicting 2457\n",
      "Predicting 2458\n",
      "Predicting 2459\n",
      "Predicting 2460\n",
      "Predicting 2461\n",
      "Predicting 2462\n",
      "Predicting 2463\n",
      "Predicting 2464\n",
      "Predicting 2465\n",
      "Predicting 2466\n",
      "Predicting 2467\n",
      "Predicting 2468\n",
      "Predicting 2469\n",
      "Predicting 2470\n",
      "Predicting 2471\n",
      "Predicting 2472\n",
      "Predicting 2473\n",
      "Predicting 2474\n",
      "Predicting 2475\n",
      "Predicting 2476\n",
      "Predicting 2477\n",
      "Predicting 2478\n",
      "Predicting 2479\n",
      "Predicting 2480\n",
      "Predicting 2481\n",
      "Predicting 2482\n",
      "Predicting 2483\n",
      "Predicting 2484\n",
      "Predicting 2485\n",
      "Predicting 2486\n",
      "Predicting 2487\n",
      "Predicting 2488\n",
      "Predicting 2489\n",
      "Predicting 2490\n",
      "Predicting 2491\n",
      "Predicting 2492\n",
      "Predicting 2493\n",
      "Predicting 2494\n",
      "Predicting 2495\n",
      "Predicting 2496\n",
      "Predicting 2497\n",
      "Predicting 2498\n",
      "Predicting 2499\n",
      "Predicting 2500\n",
      "Predicting 2501\n",
      "Predicting 2502\n",
      "Predicting 2503\n",
      "Predicting 2504\n",
      "Predicting 2505\n",
      "Predicting 2506\n",
      "Predicting 2507\n",
      "Predicting 2508\n",
      "Predicting 2509\n",
      "Predicting 2510\n",
      "Predicting 2511\n",
      "Predicting 2512\n",
      "Predicting 2513\n",
      "Predicting 2514\n",
      "Predicting 2515\n",
      "Predicting 2516\n",
      "Predicting 2517\n",
      "Predicting 2518\n",
      "Predicting 2519\n",
      "Predicting 2520\n",
      "Predicting 2521\n",
      "Predicting 2522\n",
      "Predicting 2523\n",
      "Predicting 2524\n",
      "Predicting 2525\n",
      "Predicting 2526\n",
      "Predicting 2527\n",
      "Predicting 2528\n",
      "Predicting 2529\n",
      "Predicting 2530\n",
      "Predicting 2531\n",
      "Predicting 2532\n",
      "Predicting 2533\n",
      "Predicting 2534\n",
      "Predicting 2535\n",
      "Predicting 2536\n",
      "Predicting 2537\n",
      "Predicting 2538\n",
      "Predicting 2539\n",
      "Predicting 2540\n",
      "Predicting 2541\n",
      "Predicting 2542\n",
      "Predicting 2543\n",
      "Predicting 2544\n",
      "Predicting 2545\n",
      "Predicting 2546\n",
      "Predicting 2547\n",
      "Predicting 2548\n",
      "Predicting 2549\n",
      "Predicting 2550\n",
      "Predicting 2551\n",
      "Predicting 2552\n",
      "Predicting 2553\n",
      "Predicting 2554\n",
      "Predicting 2555\n",
      "Predicting 2556\n",
      "Predicting 2557\n",
      "Predicting 2558\n",
      "Predicting 2559\n",
      "Predicting 2560\n",
      "Predicting 2561\n",
      "Predicting 2562\n",
      "Predicting 2563\n",
      "Predicting 2564\n",
      "Predicting 2565\n",
      "Predicting 2566\n",
      "Predicting 2567\n",
      "Predicting 2568\n",
      "Predicting 2569\n",
      "Predicting 2570\n",
      "Predicting 2571\n",
      "Predicting 2572\n",
      "Predicting 2573\n",
      "Predicting 2574\n",
      "Predicting 2575\n",
      "Predicting 2576\n",
      "Predicting 2577\n",
      "Predicting 2578\n",
      "Predicting 2579\n",
      "Predicting 2580\n",
      "Predicting 2581\n",
      "Predicting 2582\n",
      "Predicting 2583\n",
      "Predicting 2584\n",
      "Predicting 2585\n",
      "Predicting 2586\n",
      "Predicting 2587\n",
      "Predicting 2588\n",
      "Predicting 2589\n",
      "Predicting 2590\n",
      "Predicting 2591\n",
      "Predicting 2592\n",
      "Predicting 2593\n",
      "Predicting 2594\n",
      "Predicting 2595\n",
      "Predicting 2596\n",
      "Predicting 2597\n",
      "Predicting 2598\n",
      "Predicting 2599\n",
      "Predicting 2600\n",
      "Predicting 2601\n",
      "Predicting 2602\n",
      "Predicting 2603\n",
      "Predicting 2604\n",
      "Predicting 2605\n",
      "Predicting 2606\n",
      "Predicting 2607\n",
      "Predicting 2608\n",
      "Predicting 2609\n",
      "Predicting 2610\n",
      "Predicting 2611\n",
      "Predicting 2612\n",
      "Predicting 2613\n",
      "Predicting 2614\n",
      "Predicting 2615\n",
      "Predicting 2616\n",
      "Predicting 2617\n",
      "Predicting 2618\n",
      "Predicting 2619\n",
      "Predicting 2620\n",
      "Predicting 2621\n",
      "Predicting 2622\n",
      "Predicting 2623\n",
      "Predicting 2624\n",
      "Predicting 2625\n",
      "Predicting 2626\n",
      "Predicting 2627\n",
      "Predicting 2628\n",
      "Predicting 2629\n",
      "Predicting 2630\n",
      "Predicting 2631\n",
      "Predicting 2632\n",
      "Predicting 2633\n",
      "Predicting 2634\n",
      "Predicting 2635\n",
      "Predicting 2636\n",
      "Predicting 2637\n",
      "Predicting 2638\n",
      "Predicting 2639\n",
      "Predicting 2640\n",
      "Predicting 2641\n",
      "Predicting 2642\n",
      "Predicting 2643\n",
      "Predicting 2644\n",
      "Predicting 2645\n",
      "Predicting 2646\n",
      "Predicting 2647\n",
      "Predicting 2648\n",
      "Predicting 2649\n",
      "Predicting 2650\n",
      "Predicting 2651\n",
      "Predicting 2652\n",
      "Predicting 2653\n",
      "Predicting 2654\n",
      "Predicting 2655\n",
      "Predicting 2656\n",
      "Predicting 2657\n",
      "Predicting 2658\n",
      "Predicting 2659\n",
      "Predicting 2660\n",
      "Predicting 2661\n",
      "Predicting 2662\n",
      "Predicting 2663\n",
      "Predicting 2664\n",
      "Predicting 2665\n",
      "Predicting 2666\n",
      "Predicting 2667\n",
      "Predicting 2668\n",
      "Predicting 2669\n",
      "Predicting 2670\n",
      "Predicting 2671\n",
      "Predicting 2672\n",
      "Predicting 2673\n",
      "Predicting 2674\n",
      "Predicting 2675\n",
      "Predicting 2676\n",
      "Predicting 2677\n",
      "Predicting 2678\n",
      "Predicting 2679\n",
      "Predicting 2680\n",
      "Predicting 2681\n",
      "Predicting 2682\n",
      "Predicting 2683\n",
      "Predicting 2684\n",
      "Predicting 2685\n",
      "Predicting 2686\n",
      "Predicting 2687\n",
      "Predicting 2688\n",
      "Predicting 2689\n",
      "Predicting 2690\n",
      "Predicting 2691\n",
      "Predicting 2692\n",
      "Predicting 2693\n",
      "Predicting 2694\n",
      "Predicting 2695\n",
      "Predicting 2696\n",
      "Predicting 2697\n",
      "Predicting 2698\n",
      "Predicting 2699\n",
      "Predicting 2700\n",
      "Predicting 2701\n",
      "Predicting 2702\n",
      "Predicting 2703\n",
      "Predicting 2704\n",
      "Predicting 2705\n",
      "Predicting 2706\n",
      "Predicting 2707\n",
      "Predicting 2708\n",
      "Predicting 2709\n",
      "Predicting 2710\n",
      "Predicting 2711\n",
      "Predicting 2712\n",
      "Predicting 2713\n",
      "Predicting 2714\n",
      "Predicting 2715\n",
      "Predicting 2716\n",
      "Predicting 2717\n",
      "Predicting 2718\n",
      "Predicting 2719\n",
      "Predicting 2720\n",
      "Predicting 2721\n",
      "Predicting 2722\n",
      "Predicting 2723\n",
      "Predicting 2724\n",
      "Predicting 2725\n",
      "Predicting 2726\n",
      "Predicting 2727\n",
      "Predicting 2728\n",
      "Predicting 2729\n",
      "Predicting 2730\n",
      "Predicting 2731\n",
      "Predicting 2732\n",
      "Predicting 2733\n",
      "Predicting 2734\n",
      "Predicting 2735\n",
      "Predicting 2736\n",
      "Predicting 2737\n",
      "Predicting 2738\n",
      "Predicting 2739\n",
      "Predicting 2740\n",
      "Predicting 2741\n",
      "Predicting 2742\n",
      "Predicting 2743\n",
      "Predicting 2744\n",
      "Predicting 2745\n",
      "Predicting 2746\n",
      "Predicting 2747\n",
      "Predicting 2748\n",
      "Predicting 2749\n",
      "Predicting 2750\n",
      "Predicting 2751\n",
      "Predicting 2752\n",
      "Predicting 2753\n",
      "Predicting 2754\n",
      "Predicting 2755\n",
      "Predicting 2756\n",
      "Predicting 2757\n",
      "Predicting 2758\n",
      "Predicting 2759\n",
      "Predicting 2760\n",
      "Predicting 2761\n",
      "Predicting 2762\n",
      "Predicting 2763\n",
      "Predicting 2764\n",
      "Predicting 2765\n",
      "Predicting 2766\n",
      "Predicting 2767\n",
      "Predicting 2768\n",
      "Predicting 2769\n",
      "Predicting 2770\n",
      "Predicting 2771\n",
      "Predicting 2772\n",
      "Predicting 2773\n",
      "Predicting 2774\n",
      "Predicting 2775\n",
      "Predicting 2776\n",
      "Predicting 2777\n",
      "Predicting 2778\n",
      "Predicting 2779\n",
      "Predicting 2780\n",
      "Predicting 2781\n",
      "Predicting 2782\n",
      "Predicting 2783\n",
      "Predicting 2784\n",
      "Predicting 2785\n",
      "Predicting 2786\n",
      "Predicting 2787\n",
      "Predicting 2788\n",
      "Predicting 2789\n",
      "Predicting 2790\n",
      "Predicting 2791\n",
      "Predicting 2792\n",
      "Predicting 2793\n",
      "Predicting 2794\n",
      "Predicting 2795\n",
      "Predicting 2796\n",
      "Predicting 2797\n",
      "Predicting 2798\n",
      "Predicting 2799\n",
      "Predicting 2800\n",
      "Predicting 2801\n",
      "Predicting 2802\n",
      "Predicting 2803\n",
      "Predicting 2804\n",
      "Predicting 2805\n",
      "Predicting 2806\n",
      "Predicting 2807\n",
      "Predicting 2808\n",
      "Predicting 2809\n",
      "Predicting 2810\n",
      "Predicting 2811\n",
      "Predicting 2812\n",
      "Predicting 2813\n",
      "Predicting 2814\n",
      "Predicting 2815\n",
      "Predicting 2816\n",
      "Predicting 2817\n",
      "Predicting 2818\n",
      "Predicting 2819\n",
      "Predicting 2820\n",
      "Predicting 2821\n",
      "Predicting 2822\n",
      "Predicting 2823\n",
      "Predicting 2824\n",
      "Predicting 2825\n",
      "Predicting 2826\n",
      "Predicting 2827\n",
      "Predicting 2828\n",
      "Predicting 2829\n",
      "Predicting 2830\n",
      "Predicting 2831\n",
      "Predicting 2832\n",
      "Predicting 2833\n",
      "Predicting 2834\n",
      "Predicting 2835\n",
      "Predicting 2836\n",
      "Predicting 2837\n",
      "Predicting 2838\n",
      "Predicting 2839\n",
      "Predicting 2840\n",
      "Predicting 2841\n",
      "Predicting 2842\n",
      "Predicting 2843\n",
      "Predicting 2844\n",
      "Predicting 2845\n",
      "Predicting 2846\n",
      "Predicting 2847\n",
      "Predicting 2848\n",
      "Predicting 2849\n",
      "Predicting 2850\n",
      "Predicting 2851\n",
      "Predicting 2852\n",
      "Predicting 2853\n",
      "Predicting 2854\n",
      "Predicting 2855\n",
      "Predicting 2856\n",
      "Predicting 2857\n",
      "Predicting 2858\n",
      "Predicting 2859\n",
      "Predicting 2860\n",
      "Predicting 2861\n",
      "Predicting 2862\n",
      "Predicting 2863\n",
      "Predicting 2864\n",
      "Predicting 2865\n",
      "Predicting 2866\n",
      "Predicting 2867\n",
      "Predicting 2868\n",
      "Predicting 2869\n",
      "Predicting 2870\n",
      "Predicting 2871\n",
      "Predicting 2872\n",
      "Predicting 2873\n",
      "Predicting 2874\n",
      "Predicting 2875\n",
      "Predicting 2876\n",
      "Predicting 2877\n",
      "Predicting 2878\n",
      "Predicting 2879\n",
      "Predicting 2880\n",
      "Predicting 2881\n",
      "Predicting 2882\n",
      "Predicting 2883\n",
      "Predicting 2884\n",
      "Predicting 2885\n",
      "Predicting 2886\n",
      "Predicting 2887\n",
      "Predicting 2888\n",
      "Predicting 2889\n",
      "Predicting 2890\n",
      "Predicting 2891\n",
      "Predicting 2892\n",
      "Predicting 2893\n",
      "Predicting 2894\n",
      "Predicting 2895\n",
      "Predicting 2896\n",
      "Predicting 2897\n",
      "Predicting 2898\n",
      "Predicting 2899\n",
      "Predicting 2900\n",
      "Predicting 2901\n",
      "Predicting 2902\n",
      "Predicting 2903\n",
      "Predicting 2904\n",
      "Predicting 2905\n",
      "Predicting 2906\n",
      "Predicting 2907\n",
      "Predicting 2908\n",
      "Predicting 2909\n",
      "Predicting 2910\n",
      "Predicting 2911\n",
      "Predicting 2912\n",
      "Predicting 2913\n",
      "Predicting 2914\n",
      "Predicting 2915\n",
      "Predicting 2916\n",
      "Predicting 2917\n",
      "Predicting 2918\n",
      "Predicting 2919\n",
      "Predicting 2920\n",
      "Predicting 2921\n",
      "Predicting 2922\n",
      "Predicting 2923\n",
      "Predicting 2924\n",
      "Predicting 2925\n",
      "Predicting 2926\n",
      "Predicting 2927\n",
      "Predicting 2928\n",
      "Predicting 2929\n",
      "Predicting 2930\n",
      "Predicting 2931\n",
      "Predicting 2932\n",
      "Predicting 2933\n",
      "Predicting 2934\n",
      "Predicting 2935\n",
      "Predicting 2936\n",
      "Predicting 2937\n",
      "Predicting 2938\n",
      "Predicting 2939\n",
      "Predicting 2940\n",
      "Predicting 2941\n",
      "Predicting 2942\n",
      "Predicting 2943\n",
      "Predicting 2944\n",
      "Predicting 2945\n",
      "Predicting 2946\n",
      "Predicting 2947\n",
      "Predicting 2948\n",
      "Predicting 2949\n",
      "Predicting 2950\n",
      "Predicting 2951\n",
      "Predicting 2952\n",
      "Predicting 2953\n",
      "Predicting 2954\n",
      "Predicting 2955\n",
      "Predicting 2956\n",
      "Predicting 2957\n",
      "Predicting 2958\n",
      "Predicting 2959\n",
      "Predicting 2960\n",
      "Predicting 2961\n",
      "Predicting 2962\n",
      "Predicting 2963\n",
      "Predicting 2964\n",
      "Predicting 2965\n",
      "Predicting 2966\n",
      "Predicting 2967\n",
      "Predicting 2968\n",
      "Predicting 2969\n",
      "Predicting 2970\n",
      "Predicting 2971\n",
      "Predicting 2972\n",
      "Predicting 2973\n",
      "Predicting 2974\n",
      "Predicting 2975\n",
      "Predicting 2976\n",
      "Predicting 2977\n",
      "Predicting 2978\n",
      "Predicting 2979\n",
      "Predicting 2980\n",
      "Predicting 2981\n",
      "Predicting 2982\n",
      "Predicting 2983\n",
      "Predicting 2984\n",
      "Predicting 2985\n",
      "Predicting 2986\n",
      "Predicting 2987\n",
      "Predicting 2988\n",
      "Predicting 2989\n",
      "Predicting 2990\n",
      "Predicting 2991\n",
      "Predicting 2992\n",
      "Predicting 2993\n",
      "Predicting 2994\n",
      "Predicting 2995\n",
      "Predicting 2996\n",
      "Predicting 2997\n",
      "Predicting 2998\n",
      "Predicting 2999\n",
      "Predicting 3000\n",
      "Predicting 3001\n",
      "Predicting 3002\n",
      "Predicting 3003\n",
      "Predicting 3004\n",
      "Predicting 3005\n",
      "Predicting 3006\n",
      "Predicting 3007\n",
      "Predicting 3008\n",
      "Predicting 3009\n",
      "Predicting 3010\n",
      "Predicting 3011\n",
      "Predicting 3012\n",
      "Predicting 3013\n",
      "Predicting 3014\n",
      "Predicting 3015\n",
      "Predicting 3016\n",
      "Predicting 3017\n",
      "Predicting 3018\n",
      "Predicting 3019\n",
      "Predicting 3020\n",
      "Predicting 3021\n",
      "Predicting 3022\n",
      "Predicting 3023\n",
      "Predicting 3024\n",
      "Predicting 3025\n",
      "Predicting 3026\n",
      "Predicting 3027\n",
      "Predicting 3028\n",
      "Predicting 3029\n",
      "Predicting 3030\n",
      "Predicting 3031\n",
      "Predicting 3032\n",
      "Predicting 3033\n",
      "Predicting 3034\n",
      "Predicting 3035\n",
      "Predicting 3036\n",
      "Predicting 3037\n",
      "Predicting 3038\n",
      "Predicting 3039\n",
      "Predicting 3040\n",
      "Predicting 3041\n",
      "Predicting 3042\n",
      "Predicting 3043\n",
      "Predicting 3044\n",
      "Predicting 3045\n",
      "Predicting 3046\n",
      "Predicting 3047\n",
      "Predicting 3048\n",
      "Predicting 3049\n",
      "Predicting 3050\n",
      "Predicting 3051\n",
      "Predicting 3052\n",
      "Predicting 3053\n",
      "Predicting 3054\n",
      "Predicting 3055\n",
      "Predicting 3056\n",
      "Predicting 3057\n",
      "Predicting 3058\n",
      "Predicting 3059\n",
      "Predicting 3060\n",
      "Predicting 3061\n",
      "Predicting 3062\n",
      "Predicting 3063\n",
      "Predicting 3064\n",
      "Predicting 3065\n",
      "Predicting 3066\n",
      "Predicting 3067\n",
      "Predicting 3068\n",
      "Predicting 3069\n",
      "Predicting 3070\n",
      "Predicting 3071\n",
      "Predicting 3072\n",
      "Predicting 3073\n",
      "Predicting 3074\n",
      "Predicting 3075\n",
      "Predicting 3076\n",
      "Predicting 3077\n",
      "Predicting 3078\n",
      "Predicting 3079\n",
      "Predicting 3080\n",
      "Predicting 3081\n",
      "Predicting 3082\n",
      "Predicting 3083\n",
      "Predicting 3084\n",
      "Predicting 3085\n",
      "Predicting 3086\n",
      "Predicting 3087\n",
      "Predicting 3088\n",
      "Predicting 3089\n",
      "Predicting 3090\n",
      "Predicting 3091\n",
      "Predicting 3092\n",
      "Predicting 3093\n",
      "Predicting 3094\n",
      "Predicting 3095\n",
      "Predicting 3096\n",
      "Predicting 3097\n",
      "Predicting 3098\n",
      "Predicting 3099\n",
      "Predicting 3100\n",
      "Predicting 3101\n",
      "Predicting 3102\n",
      "Predicting 3103\n",
      "Predicting 3104\n",
      "Predicting 3105\n",
      "Predicting 3106\n",
      "Predicting 3107\n",
      "Predicting 3108\n",
      "Predicting 3109\n",
      "Predicting 3110\n",
      "Predicting 3111\n",
      "Predicting 3112\n",
      "Predicting 3113\n",
      "Predicting 3114\n",
      "Predicting 3115\n",
      "Predicting 3116\n",
      "Predicting 3117\n",
      "Predicting 3118\n",
      "Predicting 3119\n",
      "Predicting 3120\n",
      "Predicting 3121\n",
      "Predicting 3122\n",
      "Predicting 3123\n",
      "Predicting 3124\n",
      "Predicting 3125\n",
      "Predicting 3126\n",
      "Predicting 3127\n",
      "Predicting 3128\n",
      "Predicting 3129\n",
      "Predicting 3130\n",
      "Predicting 3131\n",
      "Predicting 3132\n",
      "Predicting 3133\n",
      "Predicting 3134\n",
      "Predicting 3135\n",
      "Predicting 3136\n",
      "Predicting 3137\n",
      "Predicting 3138\n",
      "Predicting 3139\n",
      "Predicting 3140\n",
      "Predicting 3141\n",
      "Predicting 3142\n",
      "Predicting 3143\n",
      "Predicting 3144\n",
      "Predicting 3145\n",
      "Predicting 3146\n",
      "Predicting 3147\n",
      "Predicting 3148\n",
      "Predicting 3149\n",
      "Predicting 3150\n",
      "Predicting 3151\n",
      "Predicting 3152\n",
      "Predicting 3153\n",
      "Predicting 3154\n",
      "Predicting 3155\n",
      "Predicting 3156\n",
      "Predicting 3157\n",
      "Predicting 3158\n",
      "Predicting 3159\n",
      "Predicting 3160\n",
      "Predicting 3161\n",
      "Predicting 3162\n",
      "Predicting 3163\n",
      "Predicting 3164\n",
      "Predicting 3165\n",
      "Predicting 3166\n",
      "Predicting 3167\n",
      "Predicting 3168\n",
      "Predicting 3169\n",
      "Predicting 3170\n",
      "Predicting 3171\n",
      "Predicting 3172\n",
      "Predicting 3173\n",
      "Predicting 3174\n",
      "Predicting 3175\n",
      "Predicting 3176\n",
      "Predicting 3177\n",
      "Predicting 3178\n",
      "Predicting 3179\n",
      "Predicting 3180\n",
      "Predicting 3181\n",
      "Predicting 3182\n",
      "Predicting 3183\n",
      "Predicting 3184\n",
      "Predicting 3185\n",
      "Predicting 3186\n",
      "Predicting 3187\n",
      "Predicting 3188\n",
      "Predicting 3189\n",
      "Predicting 3190\n",
      "Predicting 3191\n",
      "Predicting 3192\n",
      "Predicting 3193\n",
      "Predicting 3194\n",
      "Predicting 3195\n",
      "Predicting 3196\n",
      "Predicting 3197\n",
      "Predicting 3198\n",
      "Predicting 3199\n",
      "Predicting 3200\n",
      "Predicting 3201\n",
      "Predicting 3202\n",
      "Predicting 3203\n",
      "Predicting 3204\n",
      "Predicting 3205\n",
      "Predicting 3206\n",
      "Predicting 3207\n",
      "Predicting 3208\n",
      "Predicting 3209\n",
      "Predicting 3210\n",
      "Predicting 3211\n",
      "Predicting 3212\n",
      "Predicting 3213\n",
      "Predicting 3214\n",
      "Predicting 3215\n",
      "Predicting 3216\n",
      "Predicting 3217\n",
      "Predicting 3218\n",
      "Predicting 3219\n",
      "Predicting 3220\n",
      "Predicting 3221\n",
      "Predicting 3222\n",
      "Predicting 3223\n",
      "Predicting 3224\n",
      "Predicting 3225\n",
      "Predicting 3226\n",
      "Predicting 3227\n",
      "Predicting 3228\n",
      "Predicting 3229\n",
      "Predicting 3230\n",
      "Predicting 3231\n",
      "Predicting 3232\n",
      "Predicting 3233\n",
      "Predicting 3234\n",
      "Predicting 3235\n",
      "Predicting 3236\n",
      "Predicting 3237\n",
      "Predicting 3238\n",
      "Predicting 3239\n",
      "Predicting 3240\n",
      "Predicting 3241\n",
      "Predicting 3242\n",
      "Predicting 3243\n",
      "Predicting 3244\n",
      "Predicting 3245\n",
      "Predicting 3246\n",
      "Predicting 3247\n",
      "Predicting 3248\n",
      "Predicting 3249\n",
      "Predicting 3250\n",
      "Predicting 3251\n",
      "Predicting 3252\n",
      "Predicting 3253\n",
      "Predicting 3254\n",
      "Predicting 3255\n",
      "Predicting 3256\n",
      "Predicting 3257\n",
      "Predicting 3258\n",
      "Predicting 3259\n",
      "Predicting 3260\n",
      "Predicting 3261\n",
      "Predicting 3262\n",
      "Predicting 3263\n",
      "Predicting 3264\n",
      "Predicting 3265\n",
      "Predicting 3266\n",
      "Predicting 3267\n",
      "Predicting 3268\n",
      "Predicting 3269\n",
      "Predicting 3270\n",
      "Predicting 3271\n",
      "Predicting 3272\n",
      "Predicting 3273\n",
      "Predicting 3274\n",
      "Predicting 3275\n",
      "Predicting 3276\n",
      "Predicting 3277\n",
      "Predicting 3278\n",
      "Predicting 3279\n",
      "Predicting 3280\n",
      "Predicting 3281\n",
      "Predicting 3282\n",
      "Predicting 3283\n",
      "Predicting 3284\n",
      "Predicting 3285\n",
      "Predicting 3286\n",
      "Predicting 3287\n",
      "Predicting 3288\n",
      "Predicting 3289\n",
      "Predicting 3290\n",
      "Predicting 3291\n",
      "Predicting 3292\n",
      "Predicting 3293\n",
      "Predicting 3294\n",
      "Predicting 3295\n",
      "Predicting 3296\n",
      "Predicting 3297\n",
      "Predicting 3298\n",
      "Predicting 3299\n",
      "Predicting 3300\n",
      "Predicting 3301\n",
      "Predicting 3302\n",
      "Predicting 3303\n",
      "Predicting 3304\n",
      "Predicting 3305\n",
      "Predicting 3306\n",
      "Predicting 3307\n",
      "Predicting 3308\n",
      "Predicting 3309\n",
      "Predicting 3310\n",
      "Predicting 3311\n",
      "Predicting 3312\n",
      "Predicting 3313\n",
      "Predicting 3314\n",
      "Predicting 3315\n",
      "Predicting 3316\n",
      "Predicting 3317\n",
      "Predicting 3318\n",
      "Predicting 3319\n",
      "Predicting 3320\n",
      "Predicting 3321\n",
      "Predicting 3322\n",
      "Predicting 3323\n",
      "Predicting 3324\n",
      "Predicting 3325\n",
      "Predicting 3326\n",
      "Predicting 3327\n",
      "Predicting 3328\n",
      "Predicting 3329\n",
      "Predicting 3330\n",
      "Predicting 3331\n",
      "Predicting 3332\n",
      "Predicting 3333\n",
      "Predicting 3334\n",
      "Predicting 3335\n",
      "Predicting 3336\n",
      "Predicting 3337\n",
      "Predicting 3338\n",
      "Predicting 3339\n",
      "Predicting 3340\n",
      "Predicting 3341\n",
      "Predicting 3342\n",
      "Predicting 3343\n",
      "Predicting 3344\n",
      "Predicting 3345\n",
      "Predicting 3346\n",
      "Predicting 3347\n",
      "Predicting 3348\n",
      "Predicting 3349\n",
      "Predicting 3350\n",
      "Predicting 3351\n",
      "Predicting 3352\n",
      "Predicting 3353\n",
      "Predicting 3354\n",
      "Predicting 3355\n",
      "Predicting 3356\n",
      "Predicting 3357\n",
      "Predicting 3358\n",
      "Predicting 3359\n",
      "Predicting 3360\n",
      "Predicting 3361\n",
      "Predicting 3362\n",
      "Predicting 3363\n",
      "Predicting 3364\n",
      "Predicting 3365\n",
      "Predicting 3366\n",
      "Predicting 3367\n",
      "Predicting 3368\n",
      "Predicting 3369\n",
      "Predicting 3370\n",
      "Predicting 3371\n",
      "Predicting 3372\n",
      "Predicting 3373\n",
      "Predicting 3374\n",
      "Predicting 3375\n",
      "Predicting 3376\n",
      "Predicting 3377\n",
      "Predicting 3378\n",
      "Predicting 3379\n",
      "Predicting 3380\n",
      "Predicting 3381\n",
      "Predicting 3382\n",
      "Predicting 3383\n",
      "Predicting 3384\n",
      "Predicting 3385\n",
      "Predicting 3386\n",
      "Predicting 3387\n",
      "Predicting 3388\n",
      "Predicting 3389\n",
      "Predicting 3390\n",
      "Predicting 3391\n",
      "Predicting 3392\n",
      "Predicting 3393\n",
      "Predicting 3394\n",
      "Predicting 3395\n",
      "Predicting 3396\n",
      "Predicting 3397\n",
      "Predicting 3398\n",
      "Predicting 3399\n",
      "Predicting 3400\n",
      "Predicting 3401\n",
      "Predicting 3402\n",
      "Predicting 3403\n",
      "Predicting 3404\n",
      "Predicting 3405\n",
      "Predicting 3406\n",
      "Predicting 3407\n",
      "Predicting 3408\n",
      "Predicting 3409\n",
      "Predicting 3410\n",
      "Predicting 3411\n",
      "Predicting 3412\n",
      "Predicting 3413\n",
      "Predicting 3414\n",
      "Predicting 3415\n",
      "Predicting 3416\n",
      "Predicting 3417\n",
      "Predicting 3418\n",
      "Predicting 3419\n",
      "Predicting 3420\n",
      "Predicting 3421\n",
      "Predicting 3422\n",
      "Predicting 3423\n",
      "Predicting 3424\n",
      "Predicting 3425\n",
      "Predicting 3426\n",
      "Predicting 3427\n",
      "Predicting 3428\n",
      "Predicting 3429\n",
      "Predicting 3430\n",
      "Predicting 3431\n",
      "Predicting 3432\n",
      "Predicting 3433\n",
      "Predicting 3434\n",
      "Predicting 3435\n",
      "Predicting 3436\n",
      "Predicting 3437\n",
      "Predicting 3438\n",
      "Predicting 3439\n",
      "Predicting 3440\n",
      "Predicting 3441\n",
      "Predicting 3442\n",
      "Predicting 3443\n",
      "Predicting 3444\n",
      "Predicting 3445\n",
      "Predicting 3446\n",
      "Predicting 3447\n",
      "Predicting 3448\n",
      "Predicting 3449\n",
      "Predicting 3450\n",
      "Predicting 3451\n",
      "Predicting 3452\n",
      "Predicting 3453\n",
      "Predicting 3454\n",
      "Predicting 3455\n",
      "Predicting 3456\n",
      "Predicting 3457\n",
      "Predicting 3458\n",
      "Predicting 3459\n",
      "Predicting 3460\n",
      "Predicting 3461\n",
      "Predicting 3462\n",
      "Predicting 3463\n",
      "Predicting 3464\n",
      "Predicting 3465\n",
      "Predicting 3466\n",
      "Predicting 3467\n",
      "Predicting 3468\n",
      "Predicting 3469\n",
      "Predicting 3470\n",
      "Predicting 3471\n",
      "Predicting 3472\n",
      "Predicting 3473\n",
      "Predicting 3474\n",
      "Predicting 3475\n",
      "Predicting 3476\n",
      "Predicting 3477\n",
      "Predicting 3478\n",
      "Predicting 3479\n",
      "Predicting 3480\n",
      "Predicting 3481\n",
      "Predicting 3482\n",
      "Predicting 3483\n",
      "Predicting 3484\n",
      "Predicting 3485\n",
      "Predicting 3486\n",
      "Predicting 3487\n",
      "Predicting 3488\n",
      "Predicting 3489\n",
      "Predicting 3490\n",
      "Predicting 3491\n",
      "Predicting 3492\n",
      "Predicting 3493\n",
      "Predicting 3494\n",
      "Predicting 3495\n",
      "Predicting 3496\n",
      "Predicting 3497\n",
      "Predicting 3498\n",
      "Predicting 3499\n",
      "Predicting 3500\n",
      "Predicting 3501\n",
      "Predicting 3502\n",
      "Predicting 3503\n",
      "Predicting 3504\n",
      "Predicting 3505\n",
      "Predicting 3506\n",
      "Predicting 3507\n",
      "Predicting 3508\n",
      "Predicting 3509\n",
      "Predicting 3510\n",
      "Predicting 3511\n",
      "Predicting 3512\n",
      "Predicting 3513\n",
      "Predicting 3514\n",
      "Predicting 3515\n",
      "Predicting 3516\n",
      "Predicting 3517\n",
      "Predicting 3518\n",
      "Predicting 3519\n",
      "Predicting 3520\n",
      "Predicting 3521\n",
      "Predicting 3522\n",
      "Predicting 3523\n",
      "Predicting 3524\n",
      "Predicting 3525\n",
      "Predicting 3526\n",
      "Predicting 3527\n",
      "Predicting 3528\n",
      "Predicting 3529\n",
      "Predicting 3530\n",
      "Predicting 3531\n",
      "Predicting 3532\n",
      "Predicting 3533\n",
      "Predicting 3534\n",
      "Predicting 3535\n",
      "Predicting 3536\n",
      "Predicting 3537\n",
      "Predicting 3538\n",
      "Predicting 3539\n",
      "Predicting 3540\n",
      "Predicting 3541\n",
      "Predicting 3542\n",
      "Predicting 3543\n",
      "Predicting 3544\n",
      "Predicting 3545\n",
      "Predicting 3546\n",
      "Predicting 3547\n",
      "Predicting 3548\n",
      "Predicting 3549\n",
      "Predicting 3550\n",
      "Predicting 3551\n",
      "Predicting 3552\n",
      "Predicting 3553\n",
      "Predicting 3554\n",
      "Predicting 3555\n",
      "Predicting 3556\n",
      "Predicting 3557\n",
      "Predicting 3558\n",
      "Predicting 3559\n",
      "Predicting 3560\n",
      "Predicting 3561\n",
      "Predicting 3562\n",
      "Predicting 3563\n",
      "Predicting 3564\n",
      "Predicting 3565\n",
      "Predicting 3566\n",
      "Predicting 3567\n",
      "Predicting 3568\n",
      "Predicting 3569\n",
      "Predicting 3570\n",
      "Predicting 3571\n",
      "Predicting 3572\n",
      "Predicting 3573\n",
      "Predicting 3574\n",
      "Predicting 3575\n",
      "Predicting 3576\n",
      "Predicting 3577\n",
      "Predicting 3578\n",
      "Predicting 3579\n",
      "Predicting 3580\n",
      "Predicting 3581\n",
      "Predicting 3582\n",
      "Predicting 3583\n",
      "Predicting 3584\n",
      "Predicting 3585\n",
      "Predicting 3586\n",
      "Predicting 3587\n",
      "Predicting 3588\n",
      "Predicting 3589\n",
      "Predicting 3590\n",
      "Predicting 3591\n",
      "Predicting 3592\n",
      "Predicting 3593\n",
      "Predicting 3594\n",
      "Predicting 3595\n",
      "Predicting 3596\n",
      "Predicting 3597\n",
      "Predicting 3598\n",
      "Predicting 3599\n",
      "Predicting 3600\n",
      "Predicting 3601\n",
      "Predicting 3602\n",
      "Predicting 3603\n",
      "Predicting 3604\n",
      "Predicting 3605\n",
      "Predicting 3606\n",
      "Predicting 3607\n",
      "Predicting 3608\n",
      "Predicting 3609\n",
      "Predicting 3610\n",
      "Predicting 3611\n",
      "Predicting 3612\n",
      "Predicting 3613\n",
      "Predicting 3614\n",
      "Predicting 3615\n",
      "Predicting 3616\n",
      "Predicting 3617\n",
      "Predicting 3618\n",
      "Predicting 3619\n",
      "Predicting 3620\n",
      "Predicting 3621\n",
      "Predicting 3622\n",
      "Predicting 3623\n",
      "Predicting 3624\n",
      "Predicting 3625\n",
      "Predicting 3626\n",
      "Predicting 3627\n",
      "Predicting 3628\n",
      "Predicting 3629\n",
      "Predicting 3630\n",
      "Predicting 3631\n",
      "Predicting 3632\n",
      "Predicting 3633\n",
      "Predicting 3634\n",
      "Predicting 3635\n",
      "Predicting 3636\n",
      "Predicting 3637\n",
      "Predicting 3638\n",
      "Predicting 3639\n",
      "Predicting 3640\n",
      "Predicting 3641\n",
      "Predicting 3642\n",
      "Predicting 3643\n",
      "Predicting 3644\n",
      "Predicting 3645\n",
      "Predicting 3646\n",
      "Predicting 3647\n",
      "Predicting 3648\n",
      "Predicting 3649\n",
      "Predicting 3650\n",
      "Predicting 3651\n",
      "Predicting 3652\n",
      "Predicting 3653\n",
      "Predicting 3654\n",
      "Predicting 3655\n",
      "Predicting 3656\n",
      "Predicting 3657\n",
      "Predicting 3658\n",
      "Predicting 3659\n",
      "Predicting 3660\n",
      "Predicting 3661\n",
      "Predicting 3662\n",
      "Predicting 3663\n",
      "Predicting 3664\n",
      "Predicting 3665\n",
      "Predicting 3666\n",
      "Predicting 3667\n",
      "Predicting 3668\n",
      "Predicting 3669\n",
      "Predicting 3670\n",
      "Predicting 3671\n",
      "Predicting 3672\n",
      "Predicting 3673\n",
      "Predicting 3674\n",
      "Predicting 3675\n",
      "Predicting 3676\n",
      "Predicting 3677\n",
      "Predicting 3678\n",
      "Predicting 3679\n",
      "Predicting 3680\n",
      "Predicting 3681\n",
      "Predicting 3682\n",
      "Predicting 3683\n",
      "Predicting 3684\n",
      "Predicting 3685\n",
      "Predicting 3686\n",
      "Predicting 3687\n",
      "Predicting 3688\n",
      "Predicting 3689\n",
      "Predicting 3690\n",
      "Predicting 3691\n",
      "Predicting 3692\n",
      "Predicting 3693\n",
      "Predicting 3694\n",
      "Predicting 3695\n",
      "Predicting 3696\n",
      "Predicting 3697\n",
      "Predicting 3698\n",
      "Predicting 3699\n",
      "Predicting 3700\n",
      "Predicting 3701\n",
      "Predicting 3702\n",
      "Predicting 3703\n",
      "Predicting 3704\n",
      "Predicting 3705\n",
      "Predicting 3706\n",
      "Predicting 3707\n",
      "Predicting 3708\n",
      "Predicting 3709\n",
      "Predicting 3710\n",
      "Predicting 3711\n",
      "Predicting 3712\n",
      "Predicting 3713\n",
      "Predicting 3714\n",
      "Predicting 3715\n",
      "Predicting 3716\n",
      "Predicting 3717\n",
      "Predicting 3718\n",
      "Predicting 3719\n",
      "Predicting 3720\n",
      "Predicting 3721\n",
      "Predicting 3722\n",
      "Predicting 3723\n",
      "Predicting 3724\n",
      "Predicting 3725\n",
      "Predicting 3726\n",
      "Predicting 3727\n",
      "Predicting 3728\n",
      "Predicting 3729\n",
      "Predicting 3730\n",
      "Predicting 3731\n",
      "Predicting 3732\n",
      "Predicting 3733\n",
      "Predicting 3734\n",
      "Predicting 3735\n",
      "Predicting 3736\n",
      "Predicting 3737\n",
      "Predicting 3738\n",
      "Predicting 3739\n",
      "Predicting 3740\n",
      "Predicting 3741\n",
      "Predicting 3742\n",
      "Predicting 3743\n",
      "Predicting 3744\n",
      "Predicting 3745\n",
      "Predicting 3746\n",
      "Predicting 3747\n",
      "Predicting 3748\n",
      "Predicting 3749\n",
      "Predicting 3750\n",
      "Predicting 3751\n",
      "Predicting 3752\n",
      "Predicting 3753\n",
      "Predicting 3754\n",
      "Predicting 3755\n",
      "Predicting 3756\n",
      "Predicting 3757\n",
      "Predicting 3758\n",
      "Predicting 3759\n",
      "Predicting 3760\n",
      "Predicting 3761\n",
      "Predicting 3762\n",
      "Predicting 3763\n",
      "Predicting 3764\n",
      "Predicting 3765\n",
      "Predicting 3766\n",
      "Predicting 3767\n",
      "Predicting 3768\n",
      "Predicting 3769\n",
      "Predicting 3770\n",
      "Predicting 3771\n",
      "Predicting 3772\n",
      "Predicting 3773\n",
      "Predicting 3774\n",
      "Predicting 3775\n",
      "Predicting 3776\n",
      "Predicting 3777\n",
      "Predicting 3778\n",
      "Predicting 3779\n",
      "Predicting 3780\n",
      "Predicting 3781\n",
      "Predicting 3782\n",
      "Predicting 3783\n",
      "Predicting 3784\n",
      "Predicting 3785\n",
      "Predicting 3786\n",
      "Predicting 3787\n",
      "Predicting 3788\n",
      "Predicting 3789\n",
      "Predicting 3790\n",
      "Predicting 3791\n",
      "Predicting 3792\n",
      "Predicting 3793\n",
      "Predicting 3794\n",
      "Predicting 3795\n",
      "Predicting 3796\n",
      "Predicting 3797\n",
      "Predicting 3798\n",
      "Predicting 3799\n",
      "Predicting 3800\n",
      "Predicting 3801\n",
      "Predicting 3802\n",
      "Predicting 3803\n",
      "Predicting 3804\n",
      "Predicting 3805\n",
      "Predicting 3806\n",
      "Predicting 3807\n",
      "Predicting 3808\n",
      "Predicting 3809\n",
      "Predicting 3810\n",
      "Predicting 3811\n",
      "Predicting 3812\n",
      "Predicting 3813\n",
      "Predicting 3814\n",
      "Predicting 3815\n",
      "Predicting 3816\n",
      "Predicting 3817\n",
      "Predicting 3818\n",
      "Predicting 3819\n",
      "Predicting 3820\n",
      "Predicting 3821\n",
      "Predicting 3822\n",
      "Predicting 3823\n",
      "Predicting 3824\n",
      "Predicting 3825\n",
      "Predicting 3826\n",
      "Predicting 3827\n",
      "Predicting 3828\n",
      "Predicting 3829\n",
      "Predicting 3830\n",
      "Predicting 3831\n",
      "Predicting 3832\n",
      "Predicting 3833\n",
      "Predicting 3834\n",
      "Predicting 3835\n",
      "Predicting 3836\n",
      "Predicting 3837\n",
      "Predicting 3838\n",
      "Predicting 3839\n",
      "Predicting 3840\n",
      "Predicting 3841\n",
      "Predicting 3842\n",
      "Predicting 3843\n",
      "Predicting 3844\n",
      "Predicting 3845\n",
      "Predicting 3846\n",
      "Predicting 3847\n",
      "Predicting 3848\n",
      "Predicting 3849\n",
      "Predicting 3850\n",
      "Predicting 3851\n",
      "Predicting 3852\n",
      "Predicting 3853\n",
      "Predicting 3854\n",
      "Predicting 3855\n",
      "Predicting 3856\n",
      "Predicting 3857\n",
      "Predicting 3858\n",
      "Predicting 3859\n",
      "Predicting 3860\n",
      "Predicting 3861\n",
      "Predicting 3862\n",
      "Predicting 3863\n",
      "Predicting 3864\n",
      "Predicting 3865\n",
      "Predicting 3866\n",
      "Predicting 3867\n",
      "Predicting 3868\n",
      "Predicting 3869\n",
      "Predicting 3870\n",
      "Predicting 3871\n",
      "Predicting 3872\n",
      "Predicting 3873\n",
      "Predicting 3874\n",
      "Predicting 3875\n",
      "Predicting 3876\n",
      "Predicting 3877\n",
      "Predicting 3878\n",
      "Predicting 3879\n",
      "Predicting 3880\n",
      "Predicting 3881\n",
      "Predicting 3882\n",
      "Predicting 3883\n",
      "Predicting 3884\n",
      "Predicting 3885\n",
      "Predicting 3886\n",
      "Predicting 3887\n",
      "Predicting 3888\n",
      "Predicting 3889\n",
      "Predicting 3890\n",
      "Predicting 3891\n",
      "Predicting 3892\n",
      "Predicting 3893\n",
      "Predicting 3894\n",
      "Predicting 3895\n",
      "Predicting 3896\n",
      "Predicting 3897\n",
      "Predicting 3898\n",
      "Predicting 3899\n",
      "Predicting 3900\n",
      "Predicting 3901\n",
      "Predicting 3902\n",
      "Predicting 3903\n",
      "Predicting 3904\n",
      "Predicting 3905\n",
      "Predicting 3906\n",
      "Predicting 3907\n",
      "Predicting 3908\n",
      "Predicting 3909\n",
      "Predicting 3910\n",
      "Predicting 3911\n",
      "Predicting 3912\n",
      "Predicting 3913\n",
      "Predicting 3914\n",
      "Predicting 3915\n",
      "Predicting 3916\n",
      "Predicting 3917\n",
      "Predicting 3918\n",
      "Predicting 3919\n",
      "Predicting 3920\n",
      "Predicting 3921\n",
      "Predicting 3922\n",
      "Predicting 3923\n",
      "Predicting 3924\n",
      "Predicting 3925\n",
      "Predicting 3926\n",
      "Predicting 3927\n",
      "Predicting 3928\n",
      "Predicting 3929\n",
      "Predicting 3930\n",
      "Predicting 3931\n",
      "Predicting 3932\n",
      "Predicting 3933\n",
      "Predicting 3934\n",
      "Predicting 3935\n",
      "Predicting 3936\n",
      "Predicting 3937\n",
      "Predicting 3938\n",
      "Predicting 3939\n",
      "Predicting 3940\n",
      "Predicting 3941\n",
      "Predicting 3942\n",
      "Predicting 3943\n",
      "Predicting 3944\n",
      "Predicting 3945\n",
      "Predicting 3946\n",
      "Predicting 3947\n",
      "Predicting 3948\n",
      "Predicting 3949\n",
      "Predicting 3950\n",
      "Predicting 3951\n",
      "Predicting 3952\n",
      "Predicting 3953\n",
      "Predicting 3954\n",
      "Predicting 3955\n",
      "Predicting 3956\n",
      "Predicting 3957\n",
      "Predicting 3958\n",
      "Predicting 3959\n",
      "Predicting 3960\n",
      "Predicting 3961\n",
      "Predicting 3962\n",
      "Predicting 3963\n",
      "Predicting 3964\n",
      "Predicting 3965\n",
      "Predicting 3966\n",
      "Predicting 3967\n",
      "Predicting 3968\n",
      "Predicting 3969\n",
      "Predicting 3970\n",
      "Predicting 3971\n",
      "Predicting 3972\n",
      "Predicting 3973\n",
      "Predicting 3974\n",
      "Predicting 3975\n",
      "Predicting 3976\n",
      "Predicting 3977\n",
      "Predicting 3978\n",
      "Predicting 3979\n",
      "Predicting 3980\n",
      "Predicting 3981\n",
      "Predicting 3982\n",
      "Predicting 3983\n",
      "Predicting 3984\n",
      "Predicting 3985\n",
      "Predicting 3986\n",
      "Predicting 3987\n",
      "Predicting 3988\n",
      "Predicting 3989\n",
      "Predicting 3990\n",
      "Predicting 3991\n",
      "Predicting 3992\n",
      "Predicting 3993\n",
      "Predicting 3994\n",
      "Predicting 3995\n",
      "Predicting 3996\n",
      "Predicting 3997\n",
      "Predicting 3998\n",
      "Predicting 3999\n",
      "Predicting 4000\n",
      "Predicting 4001\n",
      "Predicting 4002\n",
      "Predicting 4003\n",
      "Predicting 4004\n",
      "Predicting 4005\n",
      "Predicting 4006\n",
      "Predicting 4007\n",
      "Predicting 4008\n",
      "Predicting 4009\n",
      "Predicting 4010\n",
      "Predicting 4011\n",
      "Predicting 4012\n",
      "Predicting 4013\n",
      "Predicting 4014\n",
      "Predicting 4015\n",
      "Predicting 4016\n",
      "Predicting 4017\n",
      "Predicting 4018\n",
      "Predicting 4019\n",
      "Predicting 4020\n",
      "Predicting 4021\n",
      "Predicting 4022\n",
      "Predicting 4023\n",
      "Predicting 4024\n",
      "Predicting 4025\n",
      "Predicting 4026\n",
      "Predicting 4027\n",
      "Predicting 4028\n",
      "Predicting 4029\n",
      "Predicting 4030\n",
      "Predicting 4031\n",
      "Predicting 4032\n",
      "Predicting 4033\n",
      "Predicting 4034\n",
      "Predicting 4035\n",
      "Predicting 4036\n",
      "Predicting 4037\n",
      "Predicting 4038\n",
      "Predicting 4039\n",
      "Predicting 4040\n",
      "Predicting 4041\n",
      "Predicting 4042\n",
      "Predicting 4043\n",
      "Predicting 4044\n",
      "Predicting 4045\n",
      "Predicting 4046\n",
      "Predicting 4047\n",
      "Predicting 4048\n",
      "Predicting 4049\n",
      "Predicting 4050\n",
      "Predicting 4051\n",
      "Predicting 4052\n",
      "Predicting 4053\n",
      "Predicting 4054\n",
      "Predicting 4055\n",
      "Predicting 4056\n",
      "Predicting 4057\n",
      "Predicting 4058\n",
      "Predicting 4059\n",
      "Predicting 4060\n",
      "Predicting 4061\n",
      "Predicting 4062\n",
      "Predicting 4063\n",
      "Predicting 4064\n",
      "Predicting 4065\n",
      "Predicting 4066\n",
      "Predicting 4067\n",
      "Predicting 4068\n",
      "Predicting 4069\n",
      "Predicting 4070\n",
      "Predicting 4071\n",
      "Predicting 4072\n",
      "Predicting 4073\n",
      "Predicting 4074\n",
      "Predicting 4075\n",
      "Predicting 4076\n",
      "Predicting 4077\n",
      "Predicting 4078\n",
      "Predicting 4079\n",
      "Predicting 4080\n",
      "Predicting 4081\n",
      "Predicting 4082\n",
      "Predicting 4083\n",
      "Predicting 4084\n",
      "Predicting 4085\n",
      "Predicting 4086\n",
      "Predicting 4087\n",
      "Predicting 4088\n",
      "Predicting 4089\n",
      "Predicting 4090\n",
      "Predicting 4091\n",
      "Predicting 4092\n",
      "Predicting 4093\n",
      "Predicting 4094\n",
      "Predicting 4095\n",
      "Predicting 4096\n",
      "Predicting 4097\n",
      "Predicting 4098\n",
      "Predicting 4099\n",
      "Predicting 4100\n",
      "Predicting 4101\n",
      "Predicting 4102\n",
      "Predicting 4103\n",
      "Predicting 4104\n",
      "Predicting 4105\n",
      "Predicting 4106\n",
      "Predicting 4107\n",
      "Predicting 4108\n",
      "Predicting 4109\n",
      "Predicting 4110\n",
      "Predicting 4111\n",
      "Predicting 4112\n",
      "Predicting 4113\n",
      "Predicting 4114\n",
      "Predicting 4115\n",
      "Predicting 4116\n",
      "Predicting 4117\n",
      "Predicting 4118\n",
      "Predicting 4119\n",
      "Predicting 4120\n",
      "Predicting 4121\n",
      "Predicting 4122\n",
      "Predicting 4123\n",
      "Predicting 4124\n",
      "Predicting 4125\n",
      "Predicting 4126\n",
      "Predicting 4127\n",
      "Predicting 4128\n",
      "Predicting 4129\n",
      "Predicting 4130\n",
      "Predicting 4131\n",
      "Predicting 4132\n",
      "Predicting 4133\n",
      "Predicting 4134\n",
      "Predicting 4135\n",
      "Predicting 4136\n",
      "Predicting 4137\n",
      "Predicting 4138\n",
      "Predicting 4139\n",
      "Predicting 4140\n",
      "Predicting 4141\n",
      "Predicting 4142\n",
      "Predicting 4143\n",
      "Predicting 4144\n",
      "Predicting 4145\n",
      "Predicting 4146\n",
      "Predicting 4147\n",
      "Predicting 4148\n",
      "Predicting 4149\n",
      "Predicting 4150\n",
      "Predicting 4151\n",
      "Predicting 4152\n",
      "Predicting 4153\n",
      "Predicting 4154\n",
      "Predicting 4155\n",
      "Predicting 4156\n",
      "Predicting 4157\n",
      "Predicting 4158\n",
      "Predicting 4159\n",
      "Predicting 4160\n",
      "Predicting 4161\n",
      "Predicting 4162\n",
      "Predicting 4163\n",
      "Predicting 4164\n",
      "Predicting 4165\n",
      "Predicting 4166\n",
      "Predicting 4167\n",
      "Predicting 4168\n",
      "Predicting 4169\n",
      "Predicting 4170\n",
      "Predicting 4171\n",
      "Predicting 4172\n",
      "Predicting 4173\n",
      "Predicting 4174\n",
      "Predicting 4175\n",
      "Predicting 4176\n",
      "Predicting 4177\n",
      "Predicting 4178\n",
      "Predicting 4179\n",
      "Predicting 4180\n",
      "Predicting 4181\n",
      "Predicting 4182\n",
      "Predicting 4183\n",
      "Predicting 4184\n",
      "Predicting 4185\n",
      "Predicting 4186\n",
      "Predicting 4187\n",
      "Predicting 4188\n",
      "Predicting 4189\n",
      "Predicting 4190\n",
      "Predicting 4191\n",
      "Predicting 4192\n",
      "Predicting 4193\n",
      "Predicting 4194\n",
      "Predicting 4195\n",
      "Predicting 4196\n",
      "Predicting 4197\n",
      "Predicting 4198\n",
      "Predicting 4199\n",
      "Predicting 4200\n",
      "Predicting 4201\n",
      "Predicting 4202\n",
      "Predicting 4203\n",
      "Predicting 4204\n",
      "Predicting 4205\n",
      "Predicting 4206\n",
      "Predicting 4207\n",
      "Predicting 4208\n",
      "Predicting 4209\n",
      "Predicting 4210\n",
      "Predicting 4211\n",
      "Predicting 4212\n",
      "Predicting 4213\n",
      "Predicting 4214\n",
      "Predicting 4215\n",
      "Predicting 4216\n",
      "Predicting 4217\n",
      "Predicting 4218\n",
      "Predicting 4219\n",
      "Predicting 4220\n",
      "Predicting 4221\n",
      "Predicting 4222\n",
      "Predicting 4223\n",
      "Predicting 4224\n",
      "Predicting 4225\n",
      "Predicting 4226\n",
      "Predicting 4227\n",
      "Predicting 4228\n",
      "Predicting 4229\n",
      "Predicting 4230\n",
      "Predicting 4231\n",
      "Predicting 4232\n",
      "Predicting 4233\n",
      "Predicting 4234\n",
      "Predicting 4235\n",
      "Predicting 4236\n",
      "Predicting 4237\n",
      "Predicting 4238\n",
      "Predicting 4239\n",
      "Predicting 4240\n",
      "Predicting 4241\n",
      "Predicting 4242\n",
      "Predicting 4243\n",
      "Predicting 4244\n",
      "Predicting 4245\n",
      "Predicting 4246\n",
      "Predicting 4247\n",
      "Predicting 4248\n",
      "Predicting 4249\n",
      "Predicting 4250\n",
      "Predicting 4251\n",
      "Predicting 4252\n",
      "Predicting 4253\n",
      "Predicting 4254\n",
      "Predicting 4255\n",
      "Predicting 4256\n",
      "Predicting 4257\n",
      "Predicting 4258\n",
      "Predicting 4259\n",
      "Predicting 4260\n",
      "Predicting 4261\n",
      "Predicting 4262\n",
      "Predicting 4263\n",
      "Predicting 4264\n",
      "Predicting 4265\n",
      "Predicting 4266\n",
      "Predicting 4267\n",
      "Predicting 4268\n",
      "Predicting 4269\n",
      "Predicting 4270\n",
      "Predicting 4271\n",
      "Predicting 4272\n",
      "Predicting 4273\n",
      "Predicting 4274\n",
      "Predicting 4275\n",
      "Predicting 4276\n",
      "Predicting 4277\n",
      "Predicting 4278\n",
      "Predicting 4279\n",
      "Predicting 4280\n",
      "Predicting 4281\n",
      "Predicting 4282\n",
      "Predicting 4283\n",
      "Predicting 4284\n",
      "Predicting 4285\n",
      "Predicting 4286\n",
      "Predicting 4287\n",
      "Predicting 4288\n",
      "Predicting 4289\n",
      "Predicting 4290\n",
      "Predicting 4291\n",
      "Predicting 4292\n",
      "Predicting 4293\n",
      "Predicting 4294\n",
      "Predicting 4295\n",
      "Predicting 4296\n",
      "Predicting 4297\n",
      "Predicting 4298\n",
      "Predicting 4299\n",
      "Predicting 4300\n",
      "Predicting 4301\n",
      "Predicting 4302\n",
      "Predicting 4303\n",
      "Predicting 4304\n",
      "Predicting 4305\n",
      "Predicting 4306\n",
      "Predicting 4307\n",
      "Predicting 4308\n",
      "Predicting 4309\n",
      "Predicting 4310\n",
      "Predicting 4311\n",
      "Predicting 4312\n",
      "Predicting 4313\n",
      "Predicting 4314\n",
      "Predicting 4315\n",
      "Predicting 4316\n",
      "Predicting 4317\n",
      "Predicting 4318\n",
      "Predicting 4319\n",
      "Predicting 4320\n",
      "Predicting 4321\n",
      "Predicting 4322\n",
      "Predicting 4323\n",
      "Predicting 4324\n",
      "Predicting 4325\n",
      "Predicting 4326\n",
      "Predicting 4327\n",
      "Predicting 4328\n",
      "Predicting 4329\n",
      "Predicting 4330\n",
      "Predicting 4331\n",
      "Predicting 4332\n",
      "Predicting 4333\n",
      "Predicting 4334\n",
      "Predicting 4335\n",
      "Predicting 4336\n",
      "Predicting 4337\n",
      "Predicting 4338\n",
      "Predicting 4339\n",
      "Predicting 4340\n",
      "Predicting 4341\n",
      "Predicting 4342\n",
      "Predicting 4343\n",
      "Predicting 4344\n",
      "Predicting 4345\n",
      "Predicting 4346\n",
      "Predicting 4347\n",
      "Predicting 4348\n",
      "Predicting 4349\n",
      "Predicting 4350\n",
      "Predicting 4351\n",
      "Predicting 4352\n",
      "Predicting 4353\n",
      "Predicting 4354\n",
      "Predicting 4355\n",
      "Predicting 4356\n",
      "Predicting 4357\n",
      "Predicting 4358\n",
      "Predicting 4359\n",
      "Predicting 4360\n",
      "Predicting 4361\n",
      "Predicting 4362\n",
      "Predicting 4363\n",
      "Predicting 4364\n",
      "Predicting 4365\n",
      "Predicting 4366\n",
      "Predicting 4367\n",
      "Predicting 4368\n",
      "Predicting 4369\n",
      "Predicting 4370\n",
      "Predicting 4371\n",
      "Predicting 4372\n",
      "Predicting 4373\n",
      "Predicting 4374\n",
      "Predicting 4375\n",
      "Predicting 4376\n",
      "Predicting 4377\n",
      "Predicting 4378\n",
      "Predicting 4379\n",
      "Predicting 4380\n",
      "Predicting 4381\n",
      "Predicting 4382\n",
      "Predicting 4383\n",
      "Predicting 4384\n",
      "Predicting 4385\n",
      "Predicting 4386\n",
      "Predicting 4387\n",
      "Predicting 4388\n",
      "Predicting 4389\n",
      "Predicting 4390\n",
      "Predicting 4391\n",
      "Predicting 4392\n",
      "Predicting 4393\n",
      "Predicting 4394\n",
      "Predicting 4395\n",
      "Predicting 4396\n",
      "Predicting 4397\n",
      "Predicting 4398\n",
      "Predicting 4399\n",
      "Predicting 4400\n",
      "Predicting 4401\n",
      "Predicting 4402\n",
      "Predicting 4403\n",
      "Predicting 4404\n",
      "Predicting 4405\n",
      "Predicting 4406\n",
      "Predicting 4407\n",
      "Predicting 4408\n",
      "Predicting 4409\n",
      "Predicting 4410\n",
      "Predicting 4411\n",
      "Predicting 4412\n",
      "Predicting 4413\n",
      "Predicting 4414\n",
      "Predicting 4415\n",
      "Predicting 4416\n",
      "Predicting 4417\n",
      "Predicting 4418\n",
      "Predicting 4419\n",
      "Predicting 4420\n",
      "Predicting 4421\n",
      "Predicting 4422\n",
      "Predicting 4423\n",
      "Predicting 4424\n",
      "Predicting 4425\n",
      "Predicting 4426\n",
      "Predicting 4427\n",
      "Predicting 4428\n",
      "Predicting 4429\n",
      "Predicting 4430\n",
      "Predicting 4431\n",
      "Predicting 4432\n",
      "Predicting 4433\n",
      "Predicting 4434\n",
      "Predicting 4435\n",
      "Predicting 4436\n",
      "Predicting 4437\n",
      "Predicting 4438\n",
      "Predicting 4439\n",
      "Predicting 4440\n",
      "Predicting 4441\n",
      "Predicting 4442\n",
      "Predicting 4443\n",
      "Predicting 4444\n",
      "Predicting 4445\n",
      "Predicting 4446\n",
      "Predicting 4447\n",
      "Predicting 4448\n",
      "Predicting 4449\n",
      "Predicting 4450\n",
      "Predicting 4451\n",
      "Predicting 4452\n",
      "Predicting 4453\n",
      "Predicting 4454\n",
      "Predicting 4455\n",
      "Predicting 4456\n",
      "Predicting 4457\n",
      "Predicting 4458\n",
      "Predicting 4459\n",
      "Predicting 4460\n",
      "Predicting 4461\n",
      "Predicting 4462\n",
      "Predicting 4463\n",
      "Predicting 4464\n",
      "Predicting 4465\n",
      "Predicting 4466\n",
      "Predicting 4467\n",
      "Predicting 4468\n",
      "Predicting 4469\n",
      "Predicting 4470\n",
      "Predicting 4471\n",
      "Predicting 4472\n",
      "Predicting 4473\n",
      "Predicting 4474\n",
      "Predicting 4475\n",
      "Predicting 4476\n",
      "Predicting 4477\n",
      "Predicting 4478\n",
      "Predicting 4479\n",
      "Predicting 4480\n",
      "Predicting 4481\n",
      "Predicting 4482\n",
      "Predicting 4483\n",
      "Predicting 4484\n",
      "Predicting 4485\n",
      "Predicting 4486\n",
      "Predicting 4487\n",
      "Predicting 4488\n",
      "Predicting 4489\n",
      "Predicting 4490\n",
      "Predicting 4491\n",
      "Predicting 4492\n",
      "Predicting 4493\n",
      "Predicting 4494\n",
      "Predicting 4495\n",
      "Predicting 4496\n",
      "Predicting 4497\n",
      "Predicting 4498\n",
      "Predicting 4499\n",
      "Predicting 4500\n",
      "Predicting 4501\n",
      "Predicting 4502\n",
      "Predicting 4503\n",
      "Predicting 4504\n",
      "Predicting 4505\n",
      "Predicting 4506\n",
      "Predicting 4507\n",
      "Predicting 4508\n",
      "Predicting 4509\n",
      "Predicting 4510\n",
      "Predicting 4511\n",
      "Predicting 4512\n",
      "Predicting 4513\n",
      "Predicting 4514\n",
      "Predicting 4515\n",
      "Predicting 4516\n",
      "Predicting 4517\n",
      "Predicting 4518\n",
      "Predicting 4519\n",
      "Predicting 4520\n",
      "Predicting 4521\n",
      "Predicting 4522\n",
      "Predicting 4523\n",
      "Predicting 4524\n",
      "Predicting 4525\n",
      "Predicting 4526\n",
      "Predicting 4527\n",
      "Predicting 4528\n",
      "Predicting 4529\n",
      "Predicting 4530\n",
      "Predicting 4531\n",
      "Predicting 4532\n",
      "Predicting 4533\n",
      "Predicting 4534\n",
      "Predicting 4535\n",
      "Predicting 4536\n",
      "Predicting 4537\n",
      "Predicting 4538\n",
      "Predicting 4539\n",
      "Predicting 4540\n",
      "Predicting 4541\n",
      "Predicting 4542\n",
      "Predicting 4543\n",
      "Predicting 4544\n",
      "Predicting 4545\n",
      "Predicting 4546\n",
      "Predicting 4547\n",
      "Predicting 4548\n",
      "Predicting 4549\n",
      "Predicting 4550\n",
      "Predicting 4551\n",
      "Predicting 4552\n",
      "Predicting 4553\n",
      "Predicting 4554\n",
      "Predicting 4555\n",
      "Predicting 4556\n",
      "Predicting 4557\n",
      "Predicting 4558\n",
      "Predicting 4559\n",
      "Predicting 4560\n",
      "Predicting 4561\n",
      "Predicting 4562\n",
      "Predicting 4563\n",
      "Predicting 4564\n",
      "Predicting 4565\n",
      "Predicting 4566\n",
      "Predicting 4567\n",
      "Predicting 4568\n",
      "Predicting 4569\n",
      "Predicting 4570\n",
      "Predicting 4571\n",
      "Predicting 4572\n",
      "Predicting 4573\n",
      "Predicting 4574\n",
      "Predicting 4575\n",
      "Predicting 4576\n",
      "Predicting 4577\n",
      "Predicting 4578\n",
      "Predicting 4579\n",
      "Predicting 4580\n",
      "Predicting 4581\n",
      "Predicting 4582\n",
      "Predicting 4583\n",
      "Predicting 4584\n",
      "Predicting 4585\n",
      "Predicting 4586\n",
      "Predicting 4587\n",
      "Predicting 4588\n",
      "Predicting 4589\n",
      "Predicting 4590\n",
      "Predicting 4591\n",
      "Predicting 4592\n",
      "Predicting 4593\n",
      "Predicting 4594\n",
      "Predicting 4595\n",
      "Predicting 4596\n",
      "Predicting 4597\n",
      "Predicting 4598\n",
      "Predicting 4599\n",
      "Predicting 4600\n",
      "Predicting 4601\n",
      "Predicting 4602\n",
      "Predicting 4603\n",
      "Predicting 4604\n",
      "Predicting 4605\n",
      "Predicting 4606\n",
      "Predicting 4607\n",
      "Predicting 4608\n",
      "Predicting 4609\n",
      "Predicting 4610\n",
      "Predicting 4611\n",
      "Predicting 4612\n",
      "Predicting 4613\n",
      "Predicting 4614\n",
      "Predicting 4615\n",
      "Predicting 4616\n",
      "Predicting 4617\n",
      "Predicting 4618\n",
      "Predicting 4619\n",
      "Predicting 4620\n",
      "Predicting 4621\n",
      "Predicting 4622\n",
      "Predicting 4623\n",
      "Predicting 4624\n",
      "Predicting 4625\n",
      "Predicting 4626\n",
      "Predicting 4627\n",
      "Predicting 4628\n",
      "Predicting 4629\n",
      "Predicting 4630\n",
      "Predicting 4631\n",
      "Predicting 4632\n",
      "Predicting 4633\n",
      "Predicting 4634\n",
      "Predicting 4635\n",
      "Predicting 4636\n",
      "Predicting 4637\n",
      "Predicting 4638\n",
      "Predicting 4639\n",
      "Predicting 4640\n",
      "Predicting 4641\n",
      "Predicting 4642\n",
      "Predicting 4643\n",
      "Predicting 4644\n",
      "Predicting 4645\n",
      "Predicting 4646\n",
      "Predicting 4647\n",
      "Predicting 4648\n",
      "Predicting 4649\n",
      "Predicting 4650\n",
      "Predicting 4651\n",
      "Predicting 4652\n",
      "Predicting 4653\n",
      "Predicting 4654\n",
      "Predicting 4655\n",
      "Predicting 4656\n",
      "Predicting 4657\n",
      "Predicting 4658\n",
      "Predicting 4659\n",
      "Predicting 4660\n",
      "Predicting 4661\n",
      "Predicting 4662\n",
      "Predicting 4663\n",
      "Predicting 4664\n",
      "Predicting 4665\n",
      "Predicting 4666\n",
      "Predicting 4667\n",
      "Predicting 4668\n",
      "Predicting 4669\n",
      "Predicting 4670\n",
      "Predicting 4671\n",
      "Predicting 4672\n",
      "Predicting 4673\n",
      "Predicting 4674\n",
      "Predicting 4675\n",
      "Predicting 4676\n",
      "Predicting 4677\n",
      "Predicting 4678\n",
      "Predicting 4679\n",
      "Predicting 4680\n",
      "Predicting 4681\n",
      "Predicting 4682\n",
      "Predicting 4683\n",
      "Predicting 4684\n",
      "Predicting 4685\n",
      "Predicting 4686\n",
      "Predicting 4687\n",
      "Predicting 4688\n",
      "Predicting 4689\n",
      "Predicting 4690\n",
      "Predicting 4691\n",
      "Predicting 4692\n",
      "Predicting 4693\n",
      "Predicting 4694\n",
      "Predicting 4695\n",
      "Predicting 4696\n",
      "Predicting 4697\n",
      "Predicting 4698\n",
      "Predicting 4699\n",
      "Predicting 4700\n",
      "Predicting 4701\n",
      "Predicting 4702\n",
      "Predicting 4703\n",
      "Predicting 4704\n",
      "Predicting 4705\n",
      "Predicting 4706\n",
      "Predicting 4707\n",
      "Predicting 4708\n",
      "Predicting 4709\n",
      "Predicting 4710\n",
      "Predicting 4711\n",
      "Predicting 4712\n",
      "Predicting 4713\n",
      "Predicting 4714\n",
      "Predicting 4715\n",
      "Predicting 4716\n",
      "Predicting 4717\n",
      "Predicting 4718\n",
      "Predicting 4719\n",
      "Predicting 4720\n",
      "Predicting 4721\n",
      "Predicting 4722\n",
      "Predicting 4723\n",
      "Predicting 4724\n",
      "Predicting 4725\n",
      "Predicting 4726\n",
      "Predicting 4727\n",
      "Predicting 4728\n",
      "Predicting 4729\n",
      "Predicting 4730\n",
      "Predicting 4731\n",
      "Predicting 4732\n",
      "Predicting 4733\n",
      "Predicting 4734\n",
      "Predicting 4735\n",
      "Predicting 4736\n",
      "Predicting 4737\n",
      "Predicting 4738\n",
      "Predicting 4739\n",
      "Predicting 4740\n",
      "Predicting 4741\n",
      "Predicting 4742\n",
      "Predicting 4743\n",
      "Predicting 4744\n",
      "Predicting 4745\n",
      "Predicting 4746\n",
      "Predicting 4747\n",
      "Predicting 4748\n",
      "Predicting 4749\n",
      "Predicting 4750\n",
      "Predicting 4751\n",
      "Predicting 4752\n",
      "Predicting 4753\n",
      "Predicting 4754\n",
      "Predicting 4755\n",
      "Predicting 4756\n",
      "Predicting 4757\n",
      "Predicting 4758\n",
      "Predicting 4759\n",
      "Predicting 4760\n",
      "Predicting 4761\n",
      "Predicting 4762\n",
      "Predicting 4763\n",
      "Predicting 4764\n",
      "Predicting 4765\n",
      "Predicting 4766\n",
      "Predicting 4767\n",
      "Predicting 4768\n",
      "Predicting 4769\n",
      "Predicting 4770\n",
      "Predicting 4771\n",
      "Predicting 4772\n",
      "Predicting 4773\n",
      "Predicting 4774\n",
      "Predicting 4775\n",
      "Predicting 4776\n",
      "Predicting 4777\n",
      "Predicting 4778\n",
      "Predicting 4779\n",
      "Predicting 4780\n",
      "Predicting 4781\n",
      "Predicting 4782\n",
      "Predicting 4783\n",
      "Predicting 4784\n",
      "Predicting 4785\n",
      "Predicting 4786\n",
      "Predicting 4787\n",
      "Predicting 4788\n",
      "Predicting 4789\n",
      "Predicting 4790\n",
      "Predicting 4791\n",
      "Predicting 4792\n",
      "Predicting 4793\n",
      "Predicting 4794\n",
      "Predicting 4795\n",
      "Predicting 4796\n",
      "Predicting 4797\n",
      "Predicting 4798\n",
      "Predicting 4799\n",
      "Predicting 4800\n",
      "Predicting 4801\n",
      "Predicting 4802\n",
      "Predicting 4803\n",
      "Predicting 4804\n",
      "Predicting 4805\n",
      "Predicting 4806\n",
      "Predicting 4807\n",
      "Predicting 4808\n",
      "Predicting 4809\n",
      "Predicting 4810\n",
      "Predicting 4811\n",
      "Predicting 4812\n",
      "Predicting 4813\n",
      "Predicting 4814\n",
      "Predicting 4815\n",
      "Predicting 4816\n",
      "Predicting 4817\n",
      "Predicting 4818\n",
      "Predicting 4819\n",
      "Predicting 4820\n",
      "Predicting 4821\n",
      "Predicting 4822\n",
      "Predicting 4823\n",
      "Predicting 4824\n",
      "Predicting 4825\n",
      "Predicting 4826\n",
      "Predicting 4827\n",
      "Predicting 4828\n",
      "Predicting 4829\n",
      "Predicting 4830\n",
      "Predicting 4831\n",
      "Predicting 4832\n",
      "Predicting 4833\n",
      "Predicting 4834\n",
      "Predicting 4835\n",
      "Predicting 4836\n",
      "Predicting 4837\n",
      "Predicting 4838\n",
      "Predicting 4839\n",
      "Predicting 4840\n",
      "Predicting 4841\n",
      "Predicting 4842\n",
      "Predicting 4843\n",
      "Predicting 4844\n",
      "Predicting 4845\n",
      "Predicting 4846\n",
      "Predicting 4847\n",
      "Predicting 4848\n",
      "Predicting 4849\n",
      "Predicting 4850\n",
      "Predicting 4851\n",
      "Predicting 4852\n",
      "Predicting 4853\n",
      "Predicting 4854\n",
      "Predicting 4855\n",
      "Predicting 4856\n",
      "Predicting 4857\n",
      "Predicting 4858\n",
      "Predicting 4859\n",
      "Predicting 4860\n",
      "Predicting 4861\n",
      "Predicting 4862\n",
      "Predicting 4863\n",
      "Predicting 4864\n",
      "Predicting 4865\n",
      "Predicting 4866\n",
      "Predicting 4867\n",
      "Predicting 4868\n",
      "Predicting 4869\n",
      "Predicting 4870\n",
      "Predicting 4871\n",
      "Predicting 4872\n",
      "Predicting 4873\n",
      "Predicting 4874\n",
      "Predicting 4875\n",
      "Predicting 4876\n",
      "Predicting 4877\n",
      "Predicting 4878\n",
      "Predicting 4879\n",
      "Predicting 4880\n",
      "Predicting 4881\n",
      "Predicting 4882\n",
      "Predicting 4883\n",
      "Predicting 4884\n",
      "Predicting 4885\n",
      "Predicting 4886\n",
      "Predicting 4887\n",
      "Predicting 4888\n",
      "Predicting 4889\n",
      "Predicting 4890\n",
      "Predicting 4891\n",
      "Predicting 4892\n",
      "Predicting 4893\n",
      "Predicting 4894\n",
      "Predicting 4895\n",
      "Predicting 4896\n",
      "Predicting 4897\n",
      "Predicting 4898\n",
      "Predicting 4899\n",
      "Predicting 4900\n",
      "Predicting 4901\n",
      "Predicting 4902\n",
      "Predicting 4903\n",
      "Predicting 4904\n",
      "Predicting 4905\n",
      "Predicting 4906\n",
      "Predicting 4907\n",
      "Predicting 4908\n",
      "Predicting 4909\n",
      "Predicting 4910\n",
      "Predicting 4911\n",
      "Predicting 4912\n",
      "Predicting 4913\n",
      "Predicting 4914\n",
      "Predicting 4915\n",
      "Predicting 4916\n",
      "Predicting 4917\n",
      "Predicting 4918\n",
      "Predicting 4919\n",
      "Predicting 4920\n",
      "Predicting 4921\n",
      "Predicting 4922\n",
      "Predicting 4923\n",
      "Predicting 4924\n",
      "Predicting 4925\n",
      "Predicting 4926\n",
      "Predicting 4927\n",
      "Predicting 4928\n",
      "Predicting 4929\n",
      "Predicting 4930\n",
      "Predicting 4931\n",
      "Predicting 4932\n",
      "Predicting 4933\n",
      "Predicting 4934\n",
      "Predicting 4935\n",
      "Predicting 4936\n",
      "Predicting 4937\n",
      "Predicting 4938\n",
      "Predicting 4939\n",
      "Predicting 4940\n",
      "Predicting 4941\n",
      "Predicting 4942\n",
      "Predicting 4943\n",
      "Predicting 4944\n",
      "Predicting 4945\n",
      "Predicting 4946\n",
      "Predicting 4947\n",
      "Predicting 4948\n",
      "Predicting 4949\n",
      "Predicting 4950\n",
      "Predicting 4951\n",
      "Predicting 4952\n",
      "Predicting 4953\n",
      "Predicting 4954\n",
      "Predicting 4955\n",
      "Predicting 4956\n",
      "Predicting 4957\n",
      "Predicting 4958\n",
      "Predicting 4959\n",
      "Predicting 4960\n",
      "Predicting 4961\n",
      "Predicting 4962\n",
      "Predicting 4963\n",
      "Predicting 4964\n",
      "Predicting 4965\n",
      "Predicting 4966\n",
      "Predicting 4967\n",
      "Predicting 4968\n",
      "Predicting 4969\n",
      "Predicting 4970\n",
      "Predicting 4971\n",
      "Predicting 4972\n",
      "Predicting 4973\n",
      "Predicting 4974\n",
      "Predicting 4975\n",
      "Predicting 4976\n",
      "Predicting 4977\n",
      "Predicting 4978\n",
      "Predicting 4979\n",
      "Predicting 4980\n",
      "Predicting 4981\n",
      "Predicting 4982\n",
      "Predicting 4983\n",
      "Predicting 4984\n",
      "Predicting 4985\n",
      "Predicting 4986\n",
      "Predicting 4987\n",
      "Predicting 4988\n",
      "Predicting 4989\n",
      "Predicting 4990\n",
      "Predicting 4991\n",
      "Predicting 4992\n",
      "Predicting 4993\n",
      "Predicting 4994\n",
      "Predicting 4995\n",
      "Predicting 4996\n",
      "Predicting 4997\n",
      "Predicting 4998\n",
      "Predicting 4999\n",
      "Predicting 5000\n",
      "Predicting 5001\n",
      "Predicting 5002\n",
      "Predicting 5003\n",
      "Predicting 5004\n",
      "Predicting 5005\n",
      "Predicting 5006\n",
      "Predicting 5007\n",
      "Predicting 5008\n",
      "Predicting 5009\n",
      "Predicting 5010\n",
      "Predicting 5011\n",
      "Predicting 5012\n",
      "Predicting 5013\n",
      "Predicting 5014\n",
      "Predicting 5015\n",
      "Predicting 5016\n",
      "Predicting 5017\n",
      "Predicting 5018\n",
      "Predicting 5019\n",
      "Predicting 5020\n",
      "Predicting 5021\n",
      "Predicting 5022\n",
      "Predicting 5023\n",
      "Predicting 5024\n",
      "Predicting 5025\n",
      "Predicting 5026\n",
      "Predicting 5027\n",
      "Predicting 5028\n",
      "Predicting 5029\n",
      "Predicting 5030\n",
      "Predicting 5031\n",
      "Predicting 5032\n",
      "Predicting 5033\n",
      "Predicting 5034\n",
      "Predicting 5035\n",
      "Predicting 5036\n",
      "Predicting 5037\n",
      "Predicting 5038\n",
      "Predicting 5039\n",
      "Predicting 5040\n",
      "Predicting 5041\n",
      "Predicting 5042\n",
      "Predicting 5043\n",
      "Predicting 5044\n",
      "Predicting 5045\n",
      "Predicting 5046\n",
      "Predicting 5047\n",
      "Predicting 5048\n",
      "Predicting 5049\n",
      "Predicting 5050\n",
      "Predicting 5051\n",
      "Predicting 5052\n",
      "Predicting 5053\n",
      "Predicting 5054\n",
      "Predicting 5055\n",
      "Predicting 5056\n",
      "Predicting 5057\n",
      "Predicting 5058\n",
      "Predicting 5059\n",
      "Predicting 5060\n",
      "Predicting 5061\n",
      "Predicting 5062\n",
      "Predicting 5063\n",
      "Predicting 5064\n",
      "Predicting 5065\n",
      "Predicting 5066\n",
      "Predicting 5067\n",
      "Predicting 5068\n",
      "Predicting 5069\n",
      "Predicting 5070\n",
      "Predicting 5071\n",
      "Predicting 5072\n",
      "Predicting 5073\n",
      "Predicting 5074\n",
      "Predicting 5075\n",
      "Predicting 5076\n",
      "Predicting 5077\n",
      "Predicting 5078\n",
      "Predicting 5079\n",
      "Predicting 5080\n",
      "Predicting 5081\n",
      "Predicting 5082\n",
      "Predicting 5083\n",
      "Predicting 5084\n",
      "Predicting 5085\n",
      "Predicting 5086\n",
      "Predicting 5087\n",
      "Predicting 5088\n",
      "Predicting 5089\n",
      "Predicting 5090\n",
      "Predicting 5091\n",
      "Predicting 5092\n",
      "Predicting 5093\n",
      "Predicting 5094\n",
      "Predicting 5095\n",
      "Predicting 5096\n",
      "Predicting 5097\n",
      "Predicting 5098\n",
      "Predicting 5099\n",
      "Predicting 5100\n",
      "Predicting 5101\n",
      "Predicting 5102\n",
      "Predicting 5103\n",
      "Predicting 5104\n",
      "Predicting 5105\n",
      "Predicting 5106\n",
      "Predicting 5107\n",
      "Predicting 5108\n",
      "Predicting 5109\n",
      "Predicting 5110\n",
      "Predicting 5111\n",
      "Predicting 5112\n",
      "Predicting 5113\n",
      "Predicting 5114\n",
      "Predicting 5115\n",
      "Predicting 5116\n",
      "Predicting 5117\n",
      "Predicting 5118\n",
      "Predicting 5119\n",
      "Predicting 5120\n",
      "Predicting 5121\n",
      "Predicting 5122\n",
      "Predicting 5123\n",
      "Predicting 5124\n",
      "Predicting 5125\n",
      "Predicting 5126\n",
      "Predicting 5127\n",
      "Predicting 5128\n",
      "Predicting 5129\n",
      "Predicting 5130\n",
      "Predicting 5131\n",
      "Predicting 5132\n",
      "Predicting 5133\n",
      "Predicting 5134\n",
      "Predicting 5135\n",
      "Predicting 5136\n",
      "Predicting 5137\n",
      "Predicting 5138\n",
      "Predicting 5139\n",
      "Predicting 5140\n",
      "Predicting 5141\n",
      "Predicting 5142\n",
      "Predicting 5143\n",
      "Predicting 5144\n",
      "Predicting 5145\n",
      "Predicting 5146\n",
      "Predicting 5147\n",
      "Predicting 5148\n",
      "Predicting 5149\n",
      "Predicting 5150\n",
      "Predicting 5151\n",
      "Predicting 5152\n",
      "Predicting 5153\n",
      "Predicting 5154\n",
      "Predicting 5155\n",
      "Predicting 5156\n",
      "Predicting 5157\n",
      "Predicting 5158\n",
      "Predicting 5159\n",
      "Predicting 5160\n",
      "Predicting 5161\n",
      "Predicting 5162\n",
      "Predicting 5163\n",
      "Predicting 5164\n",
      "Predicting 5165\n",
      "Predicting 5166\n",
      "Predicting 5167\n",
      "Predicting 5168\n",
      "Predicting 5169\n",
      "Predicting 5170\n",
      "Predicting 5171\n",
      "Predicting 5172\n",
      "Predicting 5173\n",
      "Predicting 5174\n",
      "Predicting 5175\n",
      "Predicting 5176\n",
      "Predicting 5177\n",
      "Predicting 5178\n",
      "Predicting 5179\n",
      "Predicting 5180\n",
      "Predicting 5181\n",
      "Predicting 5182\n",
      "Predicting 5183\n",
      "Predicting 5184\n",
      "Predicting 5185\n",
      "Predicting 5186\n",
      "Predicting 5187\n",
      "Predicting 5188\n",
      "Predicting 5189\n",
      "Predicting 5190\n",
      "Predicting 5191\n",
      "Predicting 5192\n",
      "Predicting 5193\n",
      "Predicting 5194\n",
      "Predicting 5195\n",
      "Predicting 5196\n",
      "Predicting 5197\n",
      "Predicting 5198\n",
      "Predicting 5199\n",
      "Predicting 5200\n",
      "Predicting 5201\n",
      "Predicting 5202\n",
      "Predicting 5203\n",
      "Predicting 5204\n",
      "Predicting 5205\n",
      "Predicting 5206\n",
      "Predicting 5207\n",
      "Predicting 5208\n",
      "Predicting 5209\n",
      "Predicting 5210\n",
      "Predicting 5211\n",
      "Predicting 5212\n",
      "Predicting 5213\n",
      "Predicting 5214\n",
      "Predicting 5215\n",
      "Predicting 5216\n",
      "Predicting 5217\n",
      "Predicting 5218\n",
      "Predicting 5219\n",
      "Predicting 5220\n",
      "Predicting 5221\n",
      "Predicting 5222\n",
      "Predicting 5223\n",
      "Predicting 5224\n",
      "Predicting 5225\n",
      "Predicting 5226\n",
      "Predicting 5227\n",
      "Predicting 5228\n",
      "Predicting 5229\n",
      "Predicting 5230\n",
      "Predicting 5231\n",
      "Predicting 5232\n",
      "Predicting 5233\n",
      "Predicting 5234\n",
      "Predicting 5235\n",
      "Predicting 5236\n",
      "Predicting 5237\n",
      "Predicting 5238\n",
      "Predicting 5239\n",
      "Predicting 5240\n",
      "Predicting 5241\n",
      "Predicting 5242\n",
      "Predicting 5243\n",
      "Predicting 5244\n",
      "Predicting 5245\n",
      "Predicting 5246\n",
      "Predicting 5247\n",
      "Predicting 5248\n",
      "Predicting 5249\n",
      "Predicting 5250\n",
      "Predicting 5251\n",
      "Predicting 5252\n",
      "Predicting 5253\n",
      "Predicting 5254\n",
      "Predicting 5255\n",
      "Predicting 5256\n",
      "Predicting 5257\n",
      "Predicting 5258\n",
      "Predicting 5259\n",
      "Predicting 5260\n",
      "Predicting 5261\n",
      "Predicting 5262\n",
      "Predicting 5263\n",
      "Predicting 5264\n",
      "Predicting 5265\n",
      "Predicting 5266\n",
      "Predicting 5267\n",
      "Predicting 5268\n",
      "Predicting 5269\n",
      "Predicting 5270\n",
      "Predicting 5271\n",
      "Predicting 5272\n",
      "Predicting 5273\n",
      "Predicting 5274\n",
      "Predicting 5275\n",
      "Predicting 5276\n",
      "Predicting 5277\n",
      "Predicting 5278\n",
      "Predicting 5279\n",
      "Predicting 5280\n",
      "Predicting 5281\n",
      "Predicting 5282\n",
      "Predicting 5283\n",
      "Predicting 5284\n",
      "Predicting 5285\n",
      "Predicting 5286\n",
      "Predicting 5287\n",
      "Predicting 5288\n",
      "Predicting 5289\n",
      "Predicting 5290\n",
      "Predicting 5291\n",
      "Predicting 5292\n",
      "Predicting 5293\n",
      "Predicting 5294\n",
      "Predicting 5295\n",
      "Predicting 5296\n",
      "Predicting 5297\n",
      "Predicting 5298\n",
      "Predicting 5299\n",
      "Predicting 5300\n",
      "Predicting 5301\n",
      "Predicting 5302\n",
      "Predicting 5303\n",
      "Predicting 5304\n",
      "Predicting 5305\n",
      "Predicting 5306\n",
      "Predicting 5307\n",
      "Predicting 5308\n",
      "Predicting 5309\n",
      "Predicting 5310\n",
      "Predicting 5311\n",
      "Predicting 5312\n",
      "Predicting 5313\n",
      "Predicting 5314\n",
      "Predicting 5315\n",
      "Predicting 5316\n",
      "Predicting 5317\n",
      "Predicting 5318\n",
      "Predicting 5319\n",
      "Predicting 5320\n",
      "Predicting 5321\n",
      "Predicting 5322\n",
      "Predicting 5323\n",
      "Predicting 5324\n",
      "Predicting 5325\n",
      "Predicting 5326\n",
      "Predicting 5327\n",
      "Predicting 5328\n",
      "Predicting 5329\n",
      "Predicting 5330\n",
      "Predicting 5331\n",
      "Predicting 5332\n",
      "Predicting 5333\n",
      "Predicting 5334\n",
      "Predicting 5335\n",
      "Predicting 5336\n",
      "Predicting 5337\n",
      "Predicting 5338\n",
      "Predicting 5339\n",
      "Predicting 5340\n",
      "Predicting 5341\n",
      "Predicting 5342\n",
      "Predicting 5343\n",
      "Predicting 5344\n",
      "Predicting 5345\n",
      "Predicting 5346\n",
      "Predicting 5347\n",
      "Predicting 5348\n",
      "Predicting 5349\n",
      "Predicting 5350\n",
      "Predicting 5351\n",
      "Predicting 5352\n",
      "Predicting 5353\n",
      "Predicting 5354\n",
      "Predicting 5355\n",
      "Predicting 5356\n",
      "Predicting 5357\n",
      "Predicting 5358\n",
      "Predicting 5359\n",
      "Predicting 5360\n",
      "Predicting 5361\n",
      "Predicting 5362\n",
      "Predicting 5363\n",
      "Predicting 5364\n",
      "Predicting 5365\n",
      "Predicting 5366\n",
      "Predicting 5367\n",
      "Predicting 5368\n",
      "Predicting 5369\n",
      "Predicting 5370\n",
      "Predicting 5371\n",
      "Predicting 5372\n",
      "Predicting 5373\n",
      "Predicting 5374\n",
      "Predicting 5375\n",
      "Predicting 5376\n",
      "Predicting 5377\n",
      "Predicting 5378\n",
      "Predicting 5379\n",
      "Predicting 5380\n",
      "Predicting 5381\n",
      "Predicting 5382\n",
      "Predicting 5383\n",
      "Predicting 5384\n",
      "Predicting 5385\n",
      "Predicting 5386\n",
      "Predicting 5387\n",
      "Predicting 5388\n",
      "Predicting 5389\n",
      "Predicting 5390\n",
      "Predicting 5391\n",
      "Predicting 5392\n",
      "Predicting 5393\n",
      "Predicting 5394\n",
      "Predicting 5395\n",
      "Predicting 5396\n",
      "Predicting 5397\n",
      "Predicting 5398\n",
      "Predicting 5399\n",
      "Predicting 5400\n",
      "Predicting 5401\n",
      "Predicting 5402\n",
      "Predicting 5403\n",
      "Predicting 5404\n",
      "Predicting 5405\n",
      "Predicting 5406\n",
      "Predicting 5407\n",
      "Predicting 5408\n",
      "Predicting 5409\n",
      "Predicting 5410\n",
      "Predicting 5411\n",
      "Predicting 5412\n",
      "Predicting 5413\n",
      "Predicting 5414\n",
      "Predicting 5415\n",
      "Predicting 5416\n",
      "Predicting 5417\n",
      "Predicting 5418\n",
      "Predicting 5419\n",
      "Predicting 5420\n",
      "Predicting 5421\n",
      "Predicting 5422\n",
      "Predicting 5423\n",
      "Predicting 5424\n",
      "Predicting 5425\n",
      "Predicting 5426\n",
      "Predicting 5427\n",
      "Predicting 5428\n",
      "Predicting 5429\n",
      "Predicting 5430\n",
      "Predicting 5431\n",
      "Predicting 5432\n",
      "Predicting 5433\n",
      "Predicting 5434\n",
      "Predicting 5435\n",
      "Predicting 5436\n",
      "Predicting 5437\n",
      "Predicting 5438\n",
      "Predicting 5439\n",
      "Predicting 5440\n",
      "Predicting 5441\n",
      "Predicting 5442\n",
      "Predicting 5443\n",
      "Predicting 5444\n",
      "Predicting 5445\n",
      "Predicting 5446\n",
      "Predicting 5447\n",
      "Predicting 5448\n",
      "Predicting 5449\n",
      "Predicting 5450\n",
      "Predicting 5451\n",
      "Predicting 5452\n",
      "Predicting 5453\n",
      "Predicting 5454\n",
      "Predicting 5455\n",
      "Predicting 5456\n",
      "Predicting 5457\n",
      "Predicting 5458\n",
      "Predicting 5459\n",
      "Predicting 5460\n",
      "Predicting 5461\n",
      "Predicting 5462\n",
      "Predicting 5463\n",
      "Predicting 5464\n",
      "Predicting 5465\n",
      "Predicting 5466\n",
      "Predicting 5467\n",
      "Predicting 5468\n",
      "Predicting 5469\n",
      "Predicting 5470\n",
      "Predicting 5471\n",
      "Predicting 5472\n",
      "Predicting 5473\n",
      "Predicting 5474\n",
      "Predicting 5475\n",
      "Predicting 5476\n",
      "Predicting 5477\n",
      "Predicting 5478\n",
      "Predicting 5479\n",
      "Predicting 5480\n",
      "Predicting 5481\n",
      "Predicting 5482\n",
      "Predicting 5483\n",
      "Predicting 5484\n",
      "Predicting 5485\n",
      "Predicting 5486\n",
      "Predicting 5487\n",
      "Predicting 5488\n",
      "Predicting 5489\n",
      "Predicting 5490\n",
      "Predicting 5491\n",
      "Predicting 5492\n",
      "Predicting 5493\n",
      "Predicting 5494\n",
      "Predicting 5495\n",
      "Predicting 5496\n",
      "Predicting 5497\n",
      "Predicting 5498\n",
      "Predicting 5499\n",
      "Predicting 5500\n",
      "Predicting 5501\n",
      "Predicting 5502\n",
      "Predicting 5503\n",
      "Predicting 5504\n",
      "Predicting 5505\n",
      "Predicting 5506\n",
      "Predicting 5507\n",
      "Predicting 5508\n",
      "Predicting 5509\n",
      "Predicting 5510\n",
      "Predicting 5511\n",
      "Predicting 5512\n",
      "Predicting 5513\n",
      "Predicting 5514\n",
      "Predicting 5515\n",
      "Predicting 5516\n",
      "Predicting 5517\n",
      "Predicting 5518\n",
      "Predicting 5519\n",
      "Predicting 5520\n",
      "Predicting 5521\n",
      "Predicting 5522\n",
      "Predicting 5523\n",
      "Predicting 5524\n",
      "Predicting 5525\n",
      "Predicting 5526\n",
      "Predicting 5527\n",
      "Predicting 5528\n",
      "Predicting 5529\n",
      "Predicting 5530\n",
      "Predicting 5531\n",
      "Predicting 5532\n",
      "Predicting 5533\n",
      "Threshold: 0.01\n",
      "Precision: 0.6976\n",
      "Recall: 0.9674\n",
      "TP: 1126\n",
      "TN: 3882\n",
      "FP: 488\n",
      "FN: 38\n",
      "\n",
      "Threshold: 0.02\n",
      "Precision: 0.7578\n",
      "Recall: 0.9596\n",
      "TP: 1117\n",
      "TN: 4013\n",
      "FP: 357\n",
      "FN: 47\n",
      "\n",
      "Threshold: 0.03\n",
      "Precision: 0.7923\n",
      "Recall: 0.9536\n",
      "TP: 1110\n",
      "TN: 4079\n",
      "FP: 291\n",
      "FN: 54\n",
      "\n",
      "Threshold: 0.04\n",
      "Precision: 0.8131\n",
      "Recall: 0.9493\n",
      "TP: 1105\n",
      "TN: 4116\n",
      "FP: 254\n",
      "FN: 59\n",
      "\n",
      "Threshold: 0.05\n",
      "Precision: 0.8314\n",
      "Recall: 0.9450\n",
      "TP: 1100\n",
      "TN: 4147\n",
      "FP: 223\n",
      "FN: 64\n",
      "\n",
      "Threshold: 0.06\n",
      "Precision: 0.8413\n",
      "Recall: 0.9424\n",
      "TP: 1097\n",
      "TN: 4163\n",
      "FP: 207\n",
      "FN: 67\n",
      "\n",
      "Threshold: 0.07\n",
      "Precision: 0.8502\n",
      "Recall: 0.9364\n",
      "TP: 1090\n",
      "TN: 4178\n",
      "FP: 192\n",
      "FN: 74\n",
      "\n",
      "Threshold: 0.08\n",
      "Precision: 0.8600\n",
      "Recall: 0.9338\n",
      "TP: 1087\n",
      "TN: 4193\n",
      "FP: 177\n",
      "FN: 77\n",
      "\n",
      "Threshold: 0.09\n",
      "Precision: 0.8650\n",
      "Recall: 0.9304\n",
      "TP: 1083\n",
      "TN: 4201\n",
      "FP: 169\n",
      "FN: 81\n",
      "\n",
      "Threshold: 0.10\n",
      "Precision: 0.8745\n",
      "Recall: 0.9278\n",
      "TP: 1080\n",
      "TN: 4215\n",
      "FP: 155\n",
      "FN: 84\n",
      "\n",
      "Threshold: 0.11\n",
      "Precision: 0.8815\n",
      "Recall: 0.9270\n",
      "TP: 1079\n",
      "TN: 4225\n",
      "FP: 145\n",
      "FN: 85\n",
      "\n",
      "Threshold: 0.12\n",
      "Precision: 0.8858\n",
      "Recall: 0.9261\n",
      "TP: 1078\n",
      "TN: 4231\n",
      "FP: 139\n",
      "FN: 86\n",
      "\n",
      "Threshold: 0.13\n",
      "Precision: 0.8908\n",
      "Recall: 0.9253\n",
      "TP: 1077\n",
      "TN: 4238\n",
      "FP: 132\n",
      "FN: 87\n",
      "\n",
      "Threshold: 0.14\n",
      "Precision: 0.8944\n",
      "Recall: 0.9244\n",
      "TP: 1076\n",
      "TN: 4243\n",
      "FP: 127\n",
      "FN: 88\n",
      "\n",
      "Threshold: 0.15\n",
      "Precision: 0.8968\n",
      "Recall: 0.9184\n",
      "TP: 1069\n",
      "TN: 4247\n",
      "FP: 123\n",
      "FN: 95\n",
      "\n",
      "Threshold: 0.16\n",
      "Precision: 0.9004\n",
      "Recall: 0.9167\n",
      "TP: 1067\n",
      "TN: 4252\n",
      "FP: 118\n",
      "FN: 97\n",
      "\n",
      "Threshold: 0.17\n",
      "Precision: 0.9026\n",
      "Recall: 0.9158\n",
      "TP: 1066\n",
      "TN: 4255\n",
      "FP: 115\n",
      "FN: 98\n",
      "\n",
      "Threshold: 0.18\n",
      "Precision: 0.9062\n",
      "Recall: 0.9132\n",
      "TP: 1063\n",
      "TN: 4260\n",
      "FP: 110\n",
      "FN: 101\n",
      "\n",
      "Threshold: 0.19\n",
      "Precision: 0.9099\n",
      "Recall: 0.9115\n",
      "TP: 1061\n",
      "TN: 4265\n",
      "FP: 105\n",
      "FN: 103\n",
      "\n",
      "Threshold: 0.20\n",
      "Precision: 0.9147\n",
      "Recall: 0.9115\n",
      "TP: 1061\n",
      "TN: 4271\n",
      "FP: 99\n",
      "FN: 103\n",
      "\n",
      "Threshold: 0.21\n",
      "Precision: 0.9166\n",
      "Recall: 0.9064\n",
      "TP: 1055\n",
      "TN: 4274\n",
      "FP: 96\n",
      "FN: 109\n",
      "\n",
      "Threshold: 0.22\n",
      "Precision: 0.9194\n",
      "Recall: 0.9021\n",
      "TP: 1050\n",
      "TN: 4278\n",
      "FP: 92\n",
      "FN: 114\n",
      "\n",
      "Threshold: 0.23\n",
      "Precision: 0.9209\n",
      "Recall: 0.9003\n",
      "TP: 1048\n",
      "TN: 4280\n",
      "FP: 90\n",
      "FN: 116\n",
      "\n",
      "Threshold: 0.24\n",
      "Precision: 0.9232\n",
      "Recall: 0.8986\n",
      "TP: 1046\n",
      "TN: 4283\n",
      "FP: 87\n",
      "FN: 118\n",
      "\n",
      "Threshold: 0.25\n",
      "Precision: 0.9231\n",
      "Recall: 0.8978\n",
      "TP: 1045\n",
      "TN: 4283\n",
      "FP: 87\n",
      "FN: 119\n",
      "\n",
      "Threshold: 0.26\n",
      "Precision: 0.9231\n",
      "Recall: 0.8969\n",
      "TP: 1044\n",
      "TN: 4283\n",
      "FP: 87\n",
      "FN: 120\n",
      "\n",
      "Threshold: 0.27\n",
      "Precision: 0.9263\n",
      "Recall: 0.8960\n",
      "TP: 1043\n",
      "TN: 4287\n",
      "FP: 83\n",
      "FN: 121\n",
      "\n",
      "Threshold: 0.28\n",
      "Precision: 0.9287\n",
      "Recall: 0.8952\n",
      "TP: 1042\n",
      "TN: 4290\n",
      "FP: 80\n",
      "FN: 122\n",
      "\n",
      "Threshold: 0.29\n",
      "Precision: 0.9326\n",
      "Recall: 0.8909\n",
      "TP: 1037\n",
      "TN: 4295\n",
      "FP: 75\n",
      "FN: 127\n",
      "\n",
      "Threshold: 0.30\n",
      "Precision: 0.9351\n",
      "Recall: 0.8909\n",
      "TP: 1037\n",
      "TN: 4298\n",
      "FP: 72\n",
      "FN: 127\n",
      "\n",
      "Threshold: 0.31\n",
      "Precision: 0.9350\n",
      "Recall: 0.8892\n",
      "TP: 1035\n",
      "TN: 4298\n",
      "FP: 72\n",
      "FN: 129\n",
      "\n",
      "Threshold: 0.32\n",
      "Precision: 0.9357\n",
      "Recall: 0.8883\n",
      "TP: 1034\n",
      "TN: 4299\n",
      "FP: 71\n",
      "FN: 130\n",
      "\n",
      "Threshold: 0.33\n",
      "Precision: 0.9366\n",
      "Recall: 0.8883\n",
      "TP: 1034\n",
      "TN: 4300\n",
      "FP: 70\n",
      "FN: 130\n",
      "\n",
      "Threshold: 0.34\n",
      "Precision: 0.9383\n",
      "Recall: 0.8883\n",
      "TP: 1034\n",
      "TN: 4302\n",
      "FP: 68\n",
      "FN: 130\n",
      "\n",
      "Threshold: 0.35\n",
      "Precision: 0.9398\n",
      "Recall: 0.8857\n",
      "TP: 1031\n",
      "TN: 4304\n",
      "FP: 66\n",
      "FN: 133\n",
      "\n",
      "Threshold: 0.36\n",
      "Precision: 0.9441\n",
      "Recall: 0.8849\n",
      "TP: 1030\n",
      "TN: 4309\n",
      "FP: 61\n",
      "FN: 134\n",
      "\n",
      "Threshold: 0.37\n",
      "Precision: 0.9458\n",
      "Recall: 0.8849\n",
      "TP: 1030\n",
      "TN: 4311\n",
      "FP: 59\n",
      "FN: 134\n",
      "\n",
      "Threshold: 0.38\n",
      "Precision: 0.9474\n",
      "Recall: 0.8823\n",
      "TP: 1027\n",
      "TN: 4313\n",
      "FP: 57\n",
      "FN: 137\n",
      "\n",
      "Threshold: 0.39\n",
      "Precision: 0.9481\n",
      "Recall: 0.8789\n",
      "TP: 1023\n",
      "TN: 4314\n",
      "FP: 56\n",
      "FN: 141\n",
      "\n",
      "Threshold: 0.40\n",
      "Precision: 0.9497\n",
      "Recall: 0.8763\n",
      "TP: 1020\n",
      "TN: 4316\n",
      "FP: 54\n",
      "FN: 144\n",
      "\n",
      "Threshold: 0.41\n",
      "Precision: 0.9506\n",
      "Recall: 0.8763\n",
      "TP: 1020\n",
      "TN: 4317\n",
      "FP: 53\n",
      "FN: 144\n",
      "\n",
      "Threshold: 0.42\n",
      "Precision: 0.9522\n",
      "Recall: 0.8729\n",
      "TP: 1016\n",
      "TN: 4319\n",
      "FP: 51\n",
      "FN: 148\n",
      "\n",
      "Threshold: 0.43\n",
      "Precision: 0.9530\n",
      "Recall: 0.8711\n",
      "TP: 1014\n",
      "TN: 4320\n",
      "FP: 50\n",
      "FN: 150\n",
      "\n",
      "Threshold: 0.44\n",
      "Precision: 0.9557\n",
      "Recall: 0.8711\n",
      "TP: 1014\n",
      "TN: 4323\n",
      "FP: 47\n",
      "FN: 150\n",
      "\n",
      "Threshold: 0.45\n",
      "Precision: 0.9564\n",
      "Recall: 0.8677\n",
      "TP: 1010\n",
      "TN: 4324\n",
      "FP: 46\n",
      "FN: 154\n",
      "\n",
      "Threshold: 0.46\n",
      "Precision: 0.9582\n",
      "Recall: 0.8660\n",
      "TP: 1008\n",
      "TN: 4326\n",
      "FP: 44\n",
      "FN: 156\n",
      "\n",
      "Threshold: 0.47\n",
      "Precision: 0.9590\n",
      "Recall: 0.8643\n",
      "TP: 1006\n",
      "TN: 4327\n",
      "FP: 43\n",
      "FN: 158\n",
      "\n",
      "Threshold: 0.48\n",
      "Precision: 0.9589\n",
      "Recall: 0.8617\n",
      "TP: 1003\n",
      "TN: 4327\n",
      "FP: 43\n",
      "FN: 161\n",
      "\n",
      "Threshold: 0.49\n",
      "Precision: 0.9588\n",
      "Recall: 0.8600\n",
      "TP: 1001\n",
      "TN: 4327\n",
      "FP: 43\n",
      "FN: 163\n",
      "\n",
      "Threshold: 0.50\n",
      "Precision: 0.9625\n",
      "Recall: 0.8600\n",
      "TP: 1001\n",
      "TN: 4331\n",
      "FP: 39\n",
      "FN: 163\n",
      "\n",
      "Threshold: 0.51\n",
      "Precision: 0.9625\n",
      "Recall: 0.8591\n",
      "TP: 1000\n",
      "TN: 4331\n",
      "FP: 39\n",
      "FN: 164\n",
      "\n",
      "Threshold: 0.52\n",
      "Precision: 0.9643\n",
      "Recall: 0.8591\n",
      "TP: 1000\n",
      "TN: 4333\n",
      "FP: 37\n",
      "FN: 164\n",
      "\n",
      "Threshold: 0.53\n",
      "Precision: 0.9643\n",
      "Recall: 0.8582\n",
      "TP: 999\n",
      "TN: 4333\n",
      "FP: 37\n",
      "FN: 165\n",
      "\n",
      "Threshold: 0.54\n",
      "Precision: 0.9643\n",
      "Recall: 0.8582\n",
      "TP: 999\n",
      "TN: 4333\n",
      "FP: 37\n",
      "FN: 165\n",
      "\n",
      "Threshold: 0.55\n",
      "Precision: 0.9669\n",
      "Recall: 0.8540\n",
      "TP: 994\n",
      "TN: 4336\n",
      "FP: 34\n",
      "FN: 170\n",
      "\n",
      "Threshold: 0.56\n",
      "Precision: 0.9668\n",
      "Recall: 0.8505\n",
      "TP: 990\n",
      "TN: 4336\n",
      "FP: 34\n",
      "FN: 174\n",
      "\n",
      "Threshold: 0.57\n",
      "Precision: 0.9687\n",
      "Recall: 0.8505\n",
      "TP: 990\n",
      "TN: 4338\n",
      "FP: 32\n",
      "FN: 174\n",
      "\n",
      "Threshold: 0.58\n",
      "Precision: 0.9705\n",
      "Recall: 0.8479\n",
      "TP: 987\n",
      "TN: 4340\n",
      "FP: 30\n",
      "FN: 177\n",
      "\n",
      "Threshold: 0.59\n",
      "Precision: 0.9714\n",
      "Recall: 0.8454\n",
      "TP: 984\n",
      "TN: 4341\n",
      "FP: 29\n",
      "FN: 180\n",
      "\n",
      "Threshold: 0.60\n",
      "Precision: 0.9732\n",
      "Recall: 0.8436\n",
      "TP: 982\n",
      "TN: 4343\n",
      "FP: 27\n",
      "FN: 182\n",
      "\n",
      "Threshold: 0.61\n",
      "Precision: 0.9732\n",
      "Recall: 0.8411\n",
      "TP: 979\n",
      "TN: 4343\n",
      "FP: 27\n",
      "FN: 185\n",
      "\n",
      "Threshold: 0.62\n",
      "Precision: 0.9731\n",
      "Recall: 0.8385\n",
      "TP: 976\n",
      "TN: 4343\n",
      "FP: 27\n",
      "FN: 188\n",
      "\n",
      "Threshold: 0.63\n",
      "Precision: 0.9730\n",
      "Recall: 0.8351\n",
      "TP: 972\n",
      "TN: 4343\n",
      "FP: 27\n",
      "FN: 192\n",
      "\n",
      "Threshold: 0.64\n",
      "Precision: 0.9749\n",
      "Recall: 0.8333\n",
      "TP: 970\n",
      "TN: 4345\n",
      "FP: 25\n",
      "FN: 194\n",
      "\n",
      "Threshold: 0.65\n",
      "Precision: 0.9768\n",
      "Recall: 0.8325\n",
      "TP: 969\n",
      "TN: 4347\n",
      "FP: 23\n",
      "FN: 195\n",
      "\n",
      "Threshold: 0.66\n",
      "Precision: 0.9778\n",
      "Recall: 0.8325\n",
      "TP: 969\n",
      "TN: 4348\n",
      "FP: 22\n",
      "FN: 195\n",
      "\n",
      "Threshold: 0.67\n",
      "Precision: 0.9788\n",
      "Recall: 0.8316\n",
      "TP: 968\n",
      "TN: 4349\n",
      "FP: 21\n",
      "FN: 196\n",
      "\n",
      "Threshold: 0.68\n",
      "Precision: 0.9787\n",
      "Recall: 0.8299\n",
      "TP: 966\n",
      "TN: 4349\n",
      "FP: 21\n",
      "FN: 198\n",
      "\n",
      "Threshold: 0.69\n",
      "Precision: 0.9787\n",
      "Recall: 0.8290\n",
      "TP: 965\n",
      "TN: 4349\n",
      "FP: 21\n",
      "FN: 199\n",
      "\n",
      "Threshold: 0.70\n",
      "Precision: 0.9787\n",
      "Recall: 0.8282\n",
      "TP: 964\n",
      "TN: 4349\n",
      "FP: 21\n",
      "FN: 200\n",
      "\n",
      "Threshold: 0.71\n",
      "Precision: 0.9786\n",
      "Recall: 0.8247\n",
      "TP: 960\n",
      "TN: 4349\n",
      "FP: 21\n",
      "FN: 204\n",
      "\n",
      "Threshold: 0.72\n",
      "Precision: 0.9795\n",
      "Recall: 0.8222\n",
      "TP: 957\n",
      "TN: 4350\n",
      "FP: 20\n",
      "FN: 207\n",
      "\n",
      "Threshold: 0.73\n",
      "Precision: 0.9805\n",
      "Recall: 0.8213\n",
      "TP: 956\n",
      "TN: 4351\n",
      "FP: 19\n",
      "FN: 208\n",
      "\n",
      "Threshold: 0.74\n",
      "Precision: 0.9825\n",
      "Recall: 0.8196\n",
      "TP: 954\n",
      "TN: 4353\n",
      "FP: 17\n",
      "FN: 210\n",
      "\n",
      "Threshold: 0.75\n",
      "Precision: 0.9825\n",
      "Recall: 0.8187\n",
      "TP: 953\n",
      "TN: 4353\n",
      "FP: 17\n",
      "FN: 211\n",
      "\n",
      "Threshold: 0.76\n",
      "Precision: 0.9824\n",
      "Recall: 0.8170\n",
      "TP: 951\n",
      "TN: 4353\n",
      "FP: 17\n",
      "FN: 213\n",
      "\n",
      "Threshold: 0.77\n",
      "Precision: 0.9824\n",
      "Recall: 0.8162\n",
      "TP: 950\n",
      "TN: 4353\n",
      "FP: 17\n",
      "FN: 214\n",
      "\n",
      "Threshold: 0.78\n",
      "Precision: 0.9834\n",
      "Recall: 0.8127\n",
      "TP: 946\n",
      "TN: 4354\n",
      "FP: 16\n",
      "FN: 218\n",
      "\n",
      "Threshold: 0.79\n",
      "Precision: 0.9874\n",
      "Recall: 0.8101\n",
      "TP: 943\n",
      "TN: 4358\n",
      "FP: 12\n",
      "FN: 221\n",
      "\n",
      "Threshold: 0.80\n",
      "Precision: 0.9885\n",
      "Recall: 0.8093\n",
      "TP: 942\n",
      "TN: 4359\n",
      "FP: 11\n",
      "FN: 222\n",
      "\n",
      "Threshold: 0.81\n",
      "Precision: 0.9895\n",
      "Recall: 0.8076\n",
      "TP: 940\n",
      "TN: 4360\n",
      "FP: 10\n",
      "FN: 224\n",
      "\n",
      "Threshold: 0.82\n",
      "Precision: 0.9905\n",
      "Recall: 0.8033\n",
      "TP: 935\n",
      "TN: 4361\n",
      "FP: 9\n",
      "FN: 229\n",
      "\n",
      "Threshold: 0.83\n",
      "Precision: 0.9915\n",
      "Recall: 0.7990\n",
      "TP: 930\n",
      "TN: 4362\n",
      "FP: 8\n",
      "FN: 234\n",
      "\n",
      "Threshold: 0.84\n",
      "Precision: 0.9914\n",
      "Recall: 0.7955\n",
      "TP: 926\n",
      "TN: 4362\n",
      "FP: 8\n",
      "FN: 238\n",
      "\n",
      "Threshold: 0.85\n",
      "Precision: 0.9914\n",
      "Recall: 0.7930\n",
      "TP: 923\n",
      "TN: 4362\n",
      "FP: 8\n",
      "FN: 241\n",
      "\n",
      "Threshold: 0.86\n",
      "Precision: 0.9914\n",
      "Recall: 0.7887\n",
      "TP: 918\n",
      "TN: 4362\n",
      "FP: 8\n",
      "FN: 246\n",
      "\n",
      "Threshold: 0.87\n",
      "Precision: 0.9913\n",
      "Recall: 0.7844\n",
      "TP: 913\n",
      "TN: 4362\n",
      "FP: 8\n",
      "FN: 251\n",
      "\n",
      "Threshold: 0.88\n",
      "Precision: 0.9923\n",
      "Recall: 0.7758\n",
      "TP: 903\n",
      "TN: 4363\n",
      "FP: 7\n",
      "FN: 261\n",
      "\n",
      "Threshold: 0.89\n",
      "Precision: 0.9945\n",
      "Recall: 0.7758\n",
      "TP: 903\n",
      "TN: 4365\n",
      "FP: 5\n",
      "FN: 261\n",
      "\n",
      "Threshold: 0.90\n",
      "Precision: 0.9945\n",
      "Recall: 0.7698\n",
      "TP: 896\n",
      "TN: 4365\n",
      "FP: 5\n",
      "FN: 268\n",
      "\n",
      "Threshold: 0.91\n",
      "Precision: 0.9955\n",
      "Recall: 0.7646\n",
      "TP: 890\n",
      "TN: 4366\n",
      "FP: 4\n",
      "FN: 274\n",
      "\n",
      "Threshold: 0.92\n",
      "Precision: 0.9955\n",
      "Recall: 0.7577\n",
      "TP: 882\n",
      "TN: 4366\n",
      "FP: 4\n",
      "FN: 282\n",
      "\n",
      "Threshold: 0.93\n",
      "Precision: 0.9954\n",
      "Recall: 0.7483\n",
      "TP: 871\n",
      "TN: 4366\n",
      "FP: 4\n",
      "FN: 293\n",
      "\n",
      "Threshold: 0.94\n",
      "Precision: 0.9965\n",
      "Recall: 0.7371\n",
      "TP: 858\n",
      "TN: 4367\n",
      "FP: 3\n",
      "FN: 306\n",
      "\n",
      "Threshold: 0.95\n",
      "Precision: 0.9964\n",
      "Recall: 0.7225\n",
      "TP: 841\n",
      "TN: 4367\n",
      "FP: 3\n",
      "FN: 323\n",
      "\n",
      "Threshold: 0.96\n",
      "Precision: 0.9964\n",
      "Recall: 0.7148\n",
      "TP: 832\n",
      "TN: 4367\n",
      "FP: 3\n",
      "FN: 332\n",
      "\n",
      "Threshold: 0.97\n",
      "Precision: 0.9963\n",
      "Recall: 0.6942\n",
      "TP: 808\n",
      "TN: 4367\n",
      "FP: 3\n",
      "FN: 356\n",
      "\n",
      "Threshold: 0.98\n",
      "Precision: 0.9987\n",
      "Recall: 0.6727\n",
      "TP: 783\n",
      "TN: 4369\n",
      "FP: 1\n",
      "FN: 381\n",
      "\n",
      "Threshold: 0.99\n",
      "Precision: 0.9986\n",
      "Recall: 0.6340\n",
      "TP: 738\n",
      "TN: 4369\n",
      "FP: 1\n",
      "FN: 426\n",
      "\n",
      "Threshold: 1.00\n",
      "Precision: 1.0000\n",
      "Recall: 0.1778\n",
      "TP: 207\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix\n",
    "\n",
    "def compute_metrics(y_true, y_pred, thresholds):\n",
    "    metrics = {\n",
    "        'threshold': [],\n",
    "        'precision': [],\n",
    "        'recall': [],\n",
    "        'tp': [],\n",
    "        'tn': [],\n",
    "        'fp': [],\n",
    "        'fn': []\n",
    "    }\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        y_pred_thresholded = (y_pred >= threshold).astype(int)\n",
    "        precision = precision_score(y_true, y_pred_thresholded, zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred_thresholded, zero_division=0)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred_thresholded).ravel()\n",
    "\n",
    "        metrics['threshold'].append(threshold)\n",
    "        metrics['precision'].append(precision)\n",
    "        metrics['recall'].append(recall)\n",
    "        metrics['tp'].append(tp)\n",
    "        metrics['tn'].append(tn)\n",
    "        metrics['fp'].append(fp)\n",
    "        metrics['fn'].append(fn)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Extract ground truth and predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "cnt = 0\n",
    "for audio, label in ds:\n",
    "    print(f'Predicting {cnt}')\n",
    "    cnt += 1\n",
    "    predictions = clasificador.predict_on_batch(audio)\n",
    "    y_true.append(label.numpy())\n",
    "    y_pred.append(predictions[0][0])\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred).squeeze()\n",
    "\n",
    "# Define thresholds\n",
    "thresholds = np.linspace(0.01, 1, 100, dtype=np.float64).round(2)\n",
    "\n",
    "# Compute metrics\n",
    "metrics = compute_metrics(y_true, y_pred, thresholds)\n",
    "\n",
    "# Display the metrics\n",
    "for i, threshold in enumerate(metrics['threshold']):\n",
    "    print(f\"Threshold: {threshold:.2f}\")\n",
    "    print(f\"Precision: {metrics['precision'][i]:.4f}\")\n",
    "    print(f\"Recall: {metrics['recall'][i]:.4f}\")\n",
    "    print(f\"TP: {metrics['tp'][i]}\")\n",
    "    print(f\"TN: {metrics['tn'][i]}\")\n",
    "    print(f\"FP: {metrics['fp'][i]}\")\n",
    "    print(f\"FN: {metrics['fn'][i]}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 0\n",
      "Predicting 1\n",
      "Predicting 2\n",
      "Predicting 3\n",
      "Predicting 4\n",
      "Predicting 5\n",
      "Predicting 6\n",
      "Predicting 7\n",
      "Predicting 8\n",
      "Predicting 9\n",
      "Predicting 10\n",
      "Predicting 11\n",
      "Predicting 12\n",
      "Predicting 13\n",
      "Predicting 14\n",
      "Predicting 15\n",
      "Predicting 16\n",
      "Predicting 17\n",
      "Predicting 18\n",
      "Predicting 19\n",
      "Predicting 20\n",
      "Predicting 21\n",
      "Predicting 22\n",
      "Predicting 23\n",
      "Predicting 24\n",
      "Predicting 25\n",
      "Predicting 26\n",
      "Predicting 27\n",
      "Predicting 28\n",
      "Predicting 29\n",
      "Predicting 30\n",
      "Predicting 31\n",
      "Predicting 32\n",
      "Predicting 33\n",
      "Predicting 34\n",
      "Predicting 35\n",
      "Predicting 36\n",
      "Predicting 37\n",
      "Predicting 38\n",
      "Predicting 39\n",
      "Predicting 40\n",
      "Predicting 41\n",
      "Predicting 42\n",
      "Predicting 43\n",
      "Predicting 44\n",
      "Predicting 45\n",
      "Predicting 46\n",
      "Predicting 47\n",
      "Predicting 48\n",
      "Predicting 49\n",
      "Predicting 50\n",
      "Predicting 51\n",
      "Predicting 52\n",
      "Predicting 53\n",
      "Predicting 54\n",
      "Predicting 55\n",
      "Predicting 56\n",
      "Predicting 57\n",
      "Predicting 58\n",
      "Predicting 59\n",
      "Predicting 60\n",
      "Predicting 61\n",
      "Predicting 62\n",
      "Predicting 63\n",
      "Predicting 64\n",
      "Predicting 65\n",
      "Predicting 66\n",
      "Predicting 67\n",
      "Predicting 68\n",
      "Predicting 69\n",
      "Predicting 70\n",
      "Predicting 71\n",
      "Predicting 72\n",
      "Predicting 73\n",
      "Predicting 74\n",
      "Predicting 75\n",
      "Predicting 76\n",
      "Predicting 77\n",
      "Predicting 78\n",
      "Predicting 79\n",
      "Predicting 80\n",
      "Predicting 81\n",
      "Predicting 82\n",
      "Predicting 83\n",
      "Predicting 84\n",
      "Predicting 85\n",
      "Predicting 86\n",
      "Predicting 87\n",
      "Predicting 88\n",
      "Predicting 89\n",
      "Predicting 90\n",
      "Predicting 91\n",
      "Predicting 92\n",
      "Predicting 93\n",
      "Predicting 94\n",
      "Predicting 95\n",
      "Predicting 96\n",
      "Predicting 97\n",
      "Predicting 98\n",
      "Predicting 99\n",
      "Predicting 100\n",
      "Predicting 101\n",
      "Predicting 102\n",
      "Predicting 103\n",
      "Predicting 104\n",
      "Predicting 105\n",
      "Predicting 106\n",
      "Predicting 107\n",
      "Predicting 108\n",
      "Predicting 109\n",
      "Predicting 110\n",
      "Predicting 111\n",
      "Predicting 112\n",
      "Predicting 113\n",
      "Predicting 114\n",
      "Predicting 115\n",
      "Predicting 116\n",
      "Predicting 117\n",
      "Predicting 118\n",
      "Predicting 119\n",
      "Predicting 120\n",
      "Predicting 121\n",
      "Predicting 122\n",
      "Predicting 123\n",
      "Predicting 124\n",
      "Predicting 125\n",
      "Predicting 126\n",
      "Predicting 127\n",
      "Predicting 128\n",
      "Predicting 129\n",
      "Predicting 130\n",
      "Predicting 131\n",
      "Predicting 132\n",
      "Predicting 133\n",
      "Predicting 134\n",
      "Predicting 135\n",
      "Predicting 136\n",
      "Predicting 137\n",
      "Predicting 138\n",
      "Predicting 139\n",
      "Predicting 140\n",
      "Predicting 141\n",
      "Predicting 142\n",
      "Predicting 143\n",
      "Predicting 144\n",
      "Predicting 145\n",
      "Predicting 146\n",
      "Predicting 147\n",
      "Predicting 148\n",
      "Predicting 149\n",
      "Predicting 150\n",
      "Predicting 151\n",
      "Predicting 152\n",
      "Predicting 153\n",
      "Predicting 154\n",
      "Predicting 155\n",
      "Predicting 156\n",
      "Predicting 157\n",
      "Predicting 158\n",
      "Predicting 159\n",
      "Predicting 160\n",
      "Predicting 161\n",
      "Predicting 162\n",
      "Predicting 163\n",
      "Predicting 164\n",
      "Predicting 165\n",
      "Predicting 166\n",
      "Predicting 167\n",
      "Predicting 168\n",
      "Predicting 169\n",
      "Predicting 170\n",
      "Predicting 171\n",
      "Predicting 172\n",
      "Predicting 173\n",
      "Predicting 174\n",
      "Predicting 175\n",
      "Predicting 176\n",
      "Predicting 177\n",
      "Predicting 178\n",
      "Predicting 179\n",
      "Predicting 180\n",
      "Predicting 181\n",
      "Predicting 182\n",
      "Predicting 183\n",
      "Predicting 184\n",
      "Predicting 185\n",
      "Predicting 186\n",
      "Predicting 187\n",
      "Predicting 188\n",
      "Predicting 189\n",
      "Predicting 190\n",
      "Predicting 191\n",
      "Predicting 192\n",
      "Predicting 193\n",
      "Predicting 194\n",
      "Predicting 195\n",
      "Predicting 196\n",
      "Predicting 197\n",
      "Predicting 198\n",
      "Predicting 199\n",
      "Predicting 200\n",
      "Predicting 201\n",
      "Predicting 202\n",
      "Predicting 203\n",
      "Predicting 204\n",
      "Predicting 205\n",
      "Predicting 206\n",
      "Predicting 207\n",
      "Predicting 208\n",
      "Predicting 209\n",
      "Predicting 210\n",
      "Predicting 211\n",
      "Predicting 212\n",
      "Predicting 213\n",
      "Predicting 214\n",
      "Predicting 215\n",
      "Predicting 216\n",
      "Predicting 217\n",
      "Predicting 218\n",
      "Predicting 219\n",
      "Predicting 220\n",
      "Predicting 221\n",
      "Predicting 222\n",
      "Predicting 223\n",
      "Predicting 224\n",
      "Predicting 225\n",
      "Predicting 226\n",
      "Predicting 227\n",
      "Predicting 228\n",
      "Predicting 229\n",
      "Predicting 230\n",
      "Predicting 231\n",
      "Predicting 232\n",
      "Predicting 233\n",
      "Predicting 234\n",
      "Predicting 235\n",
      "Predicting 236\n",
      "Predicting 237\n",
      "Predicting 238\n",
      "Predicting 239\n",
      "Predicting 240\n",
      "Predicting 241\n",
      "Predicting 242\n",
      "Predicting 243\n",
      "Predicting 244\n",
      "Predicting 245\n",
      "Predicting 246\n",
      "Predicting 247\n",
      "Predicting 248\n",
      "Predicting 249\n",
      "Predicting 250\n",
      "Predicting 251\n",
      "Predicting 252\n",
      "Predicting 253\n",
      "Predicting 254\n",
      "Predicting 255\n",
      "Predicting 256\n",
      "Predicting 257\n",
      "Predicting 258\n",
      "Predicting 259\n",
      "Predicting 260\n",
      "Predicting 261\n",
      "Predicting 262\n",
      "Predicting 263\n",
      "Predicting 264\n",
      "Predicting 265\n",
      "Predicting 266\n",
      "Predicting 267\n",
      "Predicting 268\n",
      "Predicting 269\n",
      "Predicting 270\n",
      "Predicting 271\n",
      "Predicting 272\n",
      "Predicting 273\n",
      "Predicting 274\n",
      "Predicting 275\n",
      "Predicting 276\n",
      "Predicting 277\n",
      "Predicting 278\n",
      "Predicting 279\n",
      "Predicting 280\n",
      "Predicting 281\n",
      "Predicting 282\n",
      "Predicting 283\n",
      "Predicting 284\n",
      "Predicting 285\n",
      "Predicting 286\n",
      "Predicting 287\n",
      "Predicting 288\n",
      "Predicting 289\n",
      "Predicting 290\n",
      "Predicting 291\n",
      "Predicting 292\n",
      "Predicting 293\n",
      "Predicting 294\n",
      "Predicting 295\n",
      "Predicting 296\n",
      "Predicting 297\n",
      "Predicting 298\n",
      "Predicting 299\n",
      "Predicting 300\n",
      "Predicting 301\n",
      "Predicting 302\n",
      "Predicting 303\n",
      "Predicting 304\n",
      "Predicting 305\n",
      "Predicting 306\n",
      "Predicting 307\n",
      "Predicting 308\n",
      "Predicting 309\n",
      "Predicting 310\n",
      "Predicting 311\n",
      "Predicting 312\n",
      "Predicting 313\n",
      "Predicting 314\n",
      "Predicting 315\n",
      "Predicting 316\n",
      "Predicting 317\n",
      "Predicting 318\n",
      "Predicting 319\n",
      "Predicting 320\n",
      "Predicting 321\n",
      "Predicting 322\n",
      "Predicting 323\n",
      "Predicting 324\n",
      "Predicting 325\n",
      "Predicting 326\n",
      "Predicting 327\n",
      "Predicting 328\n",
      "Predicting 329\n",
      "Predicting 330\n",
      "Predicting 331\n",
      "Predicting 332\n",
      "Predicting 333\n",
      "Predicting 334\n",
      "Predicting 335\n",
      "Predicting 336\n",
      "Predicting 337\n",
      "Predicting 338\n",
      "Predicting 339\n",
      "Predicting 340\n",
      "Predicting 341\n",
      "Predicting 342\n",
      "Predicting 343\n",
      "Predicting 344\n",
      "Predicting 345\n",
      "Predicting 346\n",
      "Predicting 347\n",
      "Predicting 348\n",
      "Predicting 349\n",
      "Predicting 350\n",
      "Predicting 351\n",
      "Predicting 352\n",
      "Predicting 353\n",
      "Predicting 354\n",
      "Predicting 355\n",
      "Predicting 356\n",
      "Predicting 357\n",
      "Predicting 358\n",
      "Predicting 359\n",
      "Predicting 360\n",
      "Predicting 361\n",
      "Predicting 362\n",
      "Predicting 363\n",
      "Predicting 364\n",
      "Predicting 365\n",
      "Predicting 366\n",
      "Predicting 367\n",
      "Predicting 368\n",
      "Predicting 369\n",
      "Predicting 370\n",
      "Predicting 371\n",
      "Predicting 372\n",
      "Predicting 373\n",
      "Predicting 374\n",
      "Predicting 375\n",
      "Predicting 376\n",
      "Predicting 377\n",
      "Predicting 378\n",
      "Predicting 379\n",
      "Predicting 380\n",
      "Predicting 381\n",
      "Predicting 382\n",
      "Predicting 383\n",
      "Predicting 384\n",
      "Predicting 385\n",
      "Predicting 386\n",
      "Predicting 387\n",
      "Predicting 388\n",
      "Predicting 389\n",
      "Predicting 390\n",
      "Predicting 391\n",
      "Predicting 392\n",
      "Predicting 393\n",
      "Predicting 394\n",
      "Predicting 395\n",
      "Predicting 396\n",
      "Predicting 397\n",
      "Predicting 398\n",
      "Predicting 399\n",
      "Predicting 400\n",
      "Predicting 401\n",
      "Predicting 402\n",
      "Predicting 403\n",
      "Predicting 404\n",
      "Predicting 405\n",
      "Predicting 406\n",
      "Predicting 407\n",
      "Predicting 408\n",
      "Predicting 409\n",
      "Predicting 410\n",
      "Predicting 411\n",
      "Predicting 412\n",
      "Predicting 413\n",
      "Predicting 414\n",
      "Predicting 415\n",
      "Predicting 416\n",
      "Predicting 417\n",
      "Predicting 418\n",
      "Predicting 419\n",
      "Predicting 420\n",
      "Predicting 421\n",
      "Predicting 422\n",
      "Predicting 423\n",
      "Predicting 424\n",
      "Predicting 425\n",
      "Predicting 426\n",
      "Predicting 427\n",
      "Predicting 428\n",
      "Predicting 429\n",
      "Predicting 430\n",
      "Predicting 431\n",
      "Predicting 432\n",
      "Predicting 433\n",
      "Predicting 434\n",
      "Predicting 435\n",
      "Predicting 436\n",
      "Predicting 437\n",
      "Predicting 438\n",
      "Predicting 439\n",
      "Predicting 440\n",
      "Predicting 441\n",
      "Predicting 442\n",
      "Predicting 443\n",
      "Predicting 444\n",
      "Predicting 445\n",
      "Predicting 446\n",
      "Predicting 447\n",
      "Predicting 448\n",
      "Predicting 449\n",
      "Predicting 450\n",
      "Predicting 451\n",
      "Predicting 452\n",
      "Predicting 453\n",
      "Predicting 454\n",
      "Predicting 455\n",
      "Predicting 456\n",
      "Predicting 457\n",
      "Predicting 458\n",
      "Predicting 459\n",
      "Predicting 460\n",
      "Predicting 461\n",
      "Predicting 462\n",
      "Predicting 463\n",
      "Predicting 464\n",
      "Predicting 465\n",
      "Predicting 466\n",
      "Predicting 467\n",
      "Predicting 468\n",
      "Predicting 469\n",
      "Predicting 470\n",
      "Predicting 471\n",
      "Predicting 472\n",
      "Predicting 473\n",
      "Predicting 474\n",
      "Predicting 475\n",
      "Predicting 476\n",
      "Predicting 477\n",
      "Predicting 478\n",
      "Predicting 479\n",
      "Predicting 480\n",
      "Predicting 481\n",
      "Predicting 482\n",
      "Predicting 483\n",
      "Predicting 484\n",
      "Predicting 485\n",
      "Predicting 486\n",
      "Predicting 487\n",
      "Predicting 488\n",
      "Predicting 489\n",
      "Predicting 490\n",
      "Predicting 491\n",
      "Predicting 492\n",
      "Predicting 493\n",
      "Predicting 494\n",
      "Predicting 495\n",
      "Predicting 496\n",
      "Predicting 497\n",
      "Predicting 498\n",
      "Predicting 499\n",
      "Predicting 500\n",
      "Predicting 501\n",
      "Predicting 502\n",
      "Predicting 503\n",
      "Predicting 504\n",
      "Predicting 505\n",
      "Predicting 506\n",
      "Predicting 507\n",
      "Predicting 508\n",
      "Predicting 509\n",
      "Predicting 510\n",
      "Predicting 511\n",
      "Predicting 512\n",
      "Predicting 513\n",
      "Predicting 514\n",
      "Predicting 515\n",
      "Predicting 516\n",
      "Predicting 517\n",
      "Predicting 518\n",
      "Predicting 519\n",
      "Predicting 520\n",
      "Predicting 521\n",
      "Predicting 522\n",
      "Predicting 523\n",
      "Predicting 524\n",
      "Predicting 525\n",
      "Predicting 526\n",
      "Predicting 527\n",
      "Predicting 528\n",
      "Predicting 529\n",
      "Predicting 530\n",
      "Predicting 531\n",
      "Predicting 532\n",
      "Predicting 533\n",
      "Predicting 534\n",
      "Predicting 535\n",
      "Predicting 536\n",
      "Predicting 537\n",
      "Predicting 538\n",
      "Predicting 539\n",
      "Predicting 540\n",
      "Predicting 541\n",
      "Predicting 542\n",
      "Predicting 543\n",
      "Predicting 544\n",
      "Predicting 545\n",
      "Predicting 546\n",
      "Predicting 547\n",
      "Predicting 548\n",
      "Predicting 549\n",
      "Predicting 550\n",
      "Predicting 551\n",
      "Predicting 552\n",
      "Predicting 553\n",
      "Predicting 554\n",
      "Predicting 555\n",
      "Predicting 556\n",
      "Predicting 557\n",
      "Predicting 558\n",
      "Predicting 559\n",
      "Predicting 560\n",
      "Predicting 561\n",
      "Predicting 562\n",
      "Predicting 563\n",
      "Predicting 564\n",
      "Predicting 565\n",
      "Predicting 566\n",
      "Predicting 567\n",
      "Predicting 568\n",
      "Predicting 569\n",
      "Predicting 570\n",
      "Predicting 571\n",
      "Predicting 572\n",
      "Predicting 573\n",
      "Predicting 574\n",
      "Predicting 575\n",
      "Predicting 576\n",
      "Predicting 577\n",
      "Predicting 578\n",
      "Predicting 579\n",
      "Predicting 580\n",
      "Predicting 581\n",
      "Predicting 582\n",
      "Predicting 583\n",
      "Predicting 584\n",
      "Predicting 585\n",
      "Predicting 586\n",
      "Predicting 587\n",
      "Predicting 588\n",
      "Predicting 589\n",
      "Predicting 590\n",
      "Predicting 591\n",
      "Predicting 592\n",
      "Predicting 593\n",
      "Predicting 594\n",
      "Predicting 595\n",
      "Predicting 596\n",
      "Predicting 597\n",
      "Predicting 598\n",
      "Predicting 599\n",
      "Predicting 600\n",
      "Predicting 601\n",
      "Predicting 602\n",
      "Predicting 603\n",
      "Predicting 604\n",
      "Predicting 605\n",
      "Predicting 606\n",
      "Predicting 607\n",
      "Predicting 608\n",
      "Predicting 609\n",
      "Predicting 610\n",
      "Predicting 611\n",
      "Predicting 612\n",
      "Predicting 613\n",
      "Predicting 614\n",
      "Predicting 615\n",
      "Predicting 616\n",
      "Predicting 617\n",
      "Predicting 618\n",
      "Predicting 619\n",
      "Predicting 620\n",
      "Predicting 621\n",
      "Predicting 622\n",
      "Predicting 623\n",
      "Predicting 624\n",
      "Predicting 625\n",
      "Predicting 626\n",
      "Predicting 627\n",
      "Predicting 628\n",
      "Predicting 629\n",
      "Predicting 630\n",
      "Predicting 631\n",
      "Predicting 632\n",
      "Predicting 633\n",
      "Predicting 634\n",
      "Predicting 635\n",
      "Predicting 636\n",
      "Predicting 637\n",
      "Predicting 638\n",
      "Predicting 639\n",
      "Predicting 640\n",
      "Predicting 641\n",
      "Predicting 642\n",
      "Predicting 643\n",
      "Predicting 644\n",
      "Predicting 645\n",
      "Predicting 646\n",
      "Predicting 647\n",
      "Predicting 648\n",
      "Predicting 649\n",
      "Predicting 650\n",
      "Predicting 651\n",
      "Predicting 652\n",
      "Predicting 653\n",
      "Predicting 654\n",
      "Predicting 655\n",
      "Predicting 656\n",
      "Predicting 657\n",
      "Predicting 658\n",
      "Predicting 659\n",
      "Predicting 660\n",
      "Predicting 661\n",
      "Predicting 662\n",
      "Predicting 663\n",
      "Predicting 664\n",
      "Predicting 665\n",
      "Predicting 666\n",
      "Predicting 667\n",
      "Predicting 668\n",
      "Predicting 669\n",
      "Predicting 670\n",
      "Predicting 671\n",
      "Predicting 672\n",
      "Predicting 673\n",
      "Predicting 674\n",
      "Predicting 675\n",
      "Predicting 676\n",
      "Predicting 677\n",
      "Predicting 678\n",
      "Predicting 679\n",
      "Predicting 680\n",
      "Predicting 681\n",
      "Predicting 682\n",
      "Predicting 683\n",
      "Predicting 684\n",
      "Predicting 685\n",
      "Predicting 686\n",
      "Predicting 687\n",
      "Predicting 688\n",
      "Predicting 689\n",
      "Predicting 690\n",
      "Predicting 691\n",
      "Predicting 692\n",
      "Predicting 693\n",
      "Predicting 694\n",
      "Predicting 695\n",
      "Predicting 696\n",
      "Predicting 697\n",
      "Predicting 698\n",
      "Predicting 699\n",
      "Predicting 700\n",
      "Predicting 701\n",
      "Predicting 702\n",
      "Predicting 703\n",
      "Predicting 704\n",
      "Predicting 705\n",
      "Predicting 706\n",
      "Predicting 707\n",
      "Predicting 708\n",
      "Predicting 709\n",
      "Predicting 710\n",
      "Predicting 711\n",
      "Predicting 712\n",
      "Predicting 713\n",
      "Predicting 714\n",
      "Predicting 715\n",
      "Predicting 716\n",
      "Predicting 717\n",
      "Predicting 718\n",
      "Predicting 719\n",
      "Predicting 720\n",
      "Predicting 721\n",
      "Predicting 722\n",
      "Predicting 723\n",
      "Predicting 724\n",
      "Predicting 725\n",
      "Predicting 726\n",
      "Predicting 727\n",
      "Predicting 728\n",
      "Predicting 729\n",
      "Predicting 730\n",
      "Predicting 731\n",
      "Predicting 732\n",
      "Predicting 733\n",
      "Predicting 734\n",
      "Predicting 735\n",
      "Predicting 736\n",
      "Predicting 737\n",
      "Predicting 738\n",
      "Predicting 739\n",
      "Predicting 740\n",
      "Predicting 741\n",
      "Predicting 742\n",
      "Predicting 743\n",
      "Predicting 744\n",
      "Predicting 745\n",
      "Predicting 746\n",
      "Predicting 747\n",
      "Predicting 748\n",
      "Predicting 749\n",
      "Predicting 750\n",
      "Predicting 751\n",
      "Predicting 752\n",
      "Predicting 753\n",
      "Predicting 754\n",
      "Predicting 755\n",
      "Predicting 756\n",
      "Predicting 757\n",
      "Predicting 758\n",
      "Predicting 759\n",
      "Predicting 760\n",
      "Predicting 761\n",
      "Predicting 762\n",
      "Predicting 763\n",
      "Predicting 764\n",
      "Predicting 765\n",
      "Predicting 766\n",
      "Predicting 767\n",
      "Predicting 768\n",
      "Predicting 769\n",
      "Predicting 770\n",
      "Predicting 771\n",
      "Predicting 772\n",
      "Predicting 773\n",
      "Predicting 774\n",
      "Predicting 775\n",
      "Predicting 776\n",
      "Predicting 777\n",
      "Predicting 778\n",
      "Predicting 779\n",
      "Predicting 780\n",
      "Predicting 781\n",
      "Predicting 782\n",
      "Predicting 783\n",
      "Predicting 784\n",
      "Predicting 785\n",
      "Predicting 786\n",
      "Predicting 787\n",
      "Predicting 788\n",
      "Predicting 789\n",
      "Predicting 790\n",
      "Predicting 791\n",
      "Predicting 792\n",
      "Predicting 793\n",
      "Predicting 794\n",
      "Predicting 795\n",
      "Predicting 796\n",
      "Predicting 797\n",
      "Predicting 798\n",
      "Predicting 799\n",
      "Predicting 800\n",
      "Predicting 801\n",
      "Predicting 802\n",
      "Predicting 803\n",
      "Predicting 804\n",
      "Predicting 805\n",
      "Predicting 806\n",
      "Predicting 807\n",
      "Predicting 808\n",
      "Predicting 809\n",
      "Predicting 810\n",
      "Predicting 811\n",
      "Predicting 812\n",
      "Predicting 813\n",
      "Predicting 814\n",
      "Predicting 815\n",
      "Predicting 816\n",
      "Predicting 817\n",
      "Predicting 818\n",
      "Predicting 819\n",
      "Predicting 820\n",
      "Predicting 821\n",
      "Predicting 822\n",
      "Predicting 823\n",
      "Predicting 824\n",
      "Predicting 825\n",
      "Predicting 826\n",
      "Predicting 827\n",
      "Predicting 828\n",
      "Predicting 829\n",
      "Predicting 830\n",
      "Predicting 831\n",
      "Predicting 832\n",
      "Predicting 833\n",
      "Predicting 834\n",
      "Predicting 835\n",
      "Predicting 836\n",
      "Predicting 837\n",
      "Predicting 838\n",
      "Predicting 839\n",
      "Predicting 840\n",
      "Predicting 841\n",
      "Predicting 842\n",
      "Predicting 843\n",
      "Predicting 844\n",
      "Predicting 845\n",
      "Predicting 846\n",
      "Predicting 847\n",
      "Predicting 848\n",
      "Predicting 849\n",
      "Predicting 850\n",
      "Predicting 851\n",
      "Predicting 852\n",
      "Predicting 853\n",
      "Predicting 854\n",
      "Predicting 855\n",
      "Predicting 856\n",
      "Predicting 857\n",
      "Predicting 858\n",
      "Predicting 859\n",
      "Predicting 860\n",
      "Predicting 861\n",
      "Predicting 862\n",
      "Predicting 863\n",
      "Predicting 864\n",
      "Predicting 865\n",
      "Predicting 866\n",
      "Predicting 867\n",
      "Predicting 868\n",
      "Predicting 869\n",
      "Predicting 870\n",
      "Predicting 871\n",
      "Predicting 872\n",
      "Predicting 873\n",
      "Predicting 874\n",
      "Predicting 875\n",
      "Predicting 876\n",
      "Predicting 877\n",
      "Predicting 878\n",
      "Predicting 879\n",
      "Predicting 880\n",
      "Predicting 881\n",
      "Predicting 882\n",
      "Predicting 883\n",
      "Predicting 884\n",
      "Predicting 885\n",
      "Predicting 886\n",
      "Predicting 887\n",
      "Predicting 888\n",
      "Predicting 889\n",
      "Predicting 890\n",
      "Predicting 891\n",
      "Predicting 892\n",
      "Predicting 893\n",
      "Predicting 894\n",
      "Predicting 895\n",
      "Predicting 896\n",
      "Predicting 897\n",
      "Predicting 898\n",
      "Predicting 899\n",
      "Predicting 900\n",
      "Predicting 901\n",
      "Predicting 902\n",
      "Predicting 903\n",
      "Predicting 904\n",
      "Predicting 905\n",
      "Predicting 906\n",
      "Predicting 907\n",
      "Predicting 908\n",
      "Predicting 909\n",
      "Predicting 910\n",
      "Predicting 911\n",
      "Predicting 912\n",
      "Predicting 913\n",
      "Predicting 914\n",
      "Predicting 915\n",
      "Predicting 916\n",
      "Predicting 917\n",
      "Predicting 918\n",
      "Predicting 919\n",
      "Predicting 920\n",
      "Predicting 921\n",
      "Predicting 922\n",
      "Predicting 923\n",
      "Predicting 924\n",
      "Predicting 925\n",
      "Predicting 926\n",
      "Predicting 927\n",
      "Predicting 928\n",
      "Predicting 929\n",
      "Predicting 930\n",
      "Predicting 931\n",
      "Predicting 932\n",
      "Predicting 933\n",
      "Predicting 934\n",
      "Predicting 935\n",
      "Predicting 936\n",
      "Predicting 937\n",
      "Predicting 938\n",
      "Predicting 939\n",
      "Predicting 940\n",
      "Predicting 941\n",
      "Predicting 942\n",
      "Predicting 943\n",
      "Predicting 944\n",
      "Predicting 945\n",
      "Predicting 946\n",
      "Predicting 947\n",
      "Predicting 948\n",
      "Predicting 949\n",
      "Predicting 950\n",
      "Predicting 951\n",
      "Predicting 952\n",
      "Predicting 953\n",
      "Predicting 954\n",
      "Predicting 955\n",
      "Predicting 956\n",
      "Predicting 957\n",
      "Predicting 958\n",
      "Predicting 959\n",
      "Predicting 960\n",
      "Predicting 961\n",
      "Predicting 962\n",
      "Predicting 963\n",
      "Predicting 964\n",
      "Predicting 965\n",
      "Predicting 966\n",
      "Predicting 967\n",
      "Predicting 968\n",
      "Predicting 969\n",
      "Predicting 970\n",
      "Predicting 971\n",
      "Predicting 972\n",
      "Predicting 973\n",
      "Predicting 974\n",
      "Predicting 975\n",
      "Predicting 976\n",
      "Predicting 977\n",
      "Predicting 978\n",
      "Predicting 979\n",
      "Predicting 980\n",
      "Predicting 981\n",
      "Predicting 982\n",
      "Predicting 983\n",
      "Predicting 984\n",
      "Predicting 985\n",
      "Predicting 986\n",
      "Predicting 987\n",
      "Predicting 988\n",
      "Predicting 989\n",
      "Predicting 990\n",
      "Predicting 991\n",
      "Predicting 992\n",
      "Predicting 993\n",
      "Predicting 994\n",
      "Predicting 995\n",
      "Predicting 996\n",
      "Predicting 997\n",
      "Predicting 998\n",
      "Predicting 999\n",
      "Predicting 1000\n",
      "Predicting 1001\n",
      "Predicting 1002\n",
      "Predicting 1003\n",
      "Predicting 1004\n",
      "Predicting 1005\n",
      "Predicting 1006\n",
      "Predicting 1007\n",
      "Predicting 1008\n",
      "Predicting 1009\n",
      "Predicting 1010\n",
      "Predicting 1011\n",
      "Predicting 1012\n",
      "Predicting 1013\n",
      "Predicting 1014\n",
      "Predicting 1015\n",
      "Predicting 1016\n",
      "Predicting 1017\n",
      "Predicting 1018\n",
      "Predicting 1019\n",
      "Predicting 1020\n",
      "Predicting 1021\n",
      "Predicting 1022\n",
      "Predicting 1023\n",
      "Predicting 1024\n",
      "Predicting 1025\n",
      "Predicting 1026\n",
      "Predicting 1027\n",
      "Predicting 1028\n",
      "Predicting 1029\n",
      "Predicting 1030\n",
      "Predicting 1031\n",
      "Predicting 1032\n",
      "Predicting 1033\n",
      "Predicting 1034\n",
      "Predicting 1035\n",
      "Predicting 1036\n",
      "Predicting 1037\n",
      "Predicting 1038\n",
      "Predicting 1039\n",
      "Predicting 1040\n",
      "Predicting 1041\n",
      "Predicting 1042\n",
      "Predicting 1043\n",
      "Predicting 1044\n",
      "Predicting 1045\n",
      "Predicting 1046\n",
      "Predicting 1047\n",
      "Predicting 1048\n",
      "Predicting 1049\n",
      "Predicting 1050\n",
      "Predicting 1051\n",
      "Predicting 1052\n",
      "Predicting 1053\n",
      "Predicting 1054\n",
      "Predicting 1055\n",
      "Predicting 1056\n",
      "Predicting 1057\n",
      "Predicting 1058\n",
      "Predicting 1059\n",
      "Predicting 1060\n",
      "Predicting 1061\n",
      "Predicting 1062\n",
      "Predicting 1063\n",
      "Predicting 1064\n",
      "Predicting 1065\n",
      "Predicting 1066\n",
      "Predicting 1067\n",
      "Predicting 1068\n",
      "Predicting 1069\n",
      "Predicting 1070\n",
      "Predicting 1071\n",
      "Predicting 1072\n",
      "Predicting 1073\n",
      "Predicting 1074\n",
      "Predicting 1075\n",
      "Predicting 1076\n",
      "Predicting 1077\n",
      "Predicting 1078\n",
      "Predicting 1079\n",
      "Predicting 1080\n",
      "Predicting 1081\n",
      "Predicting 1082\n",
      "Predicting 1083\n",
      "Predicting 1084\n",
      "Predicting 1085\n",
      "Predicting 1086\n",
      "Predicting 1087\n",
      "Predicting 1088\n",
      "Predicting 1089\n",
      "Predicting 1090\n",
      "Predicting 1091\n",
      "Predicting 1092\n",
      "Predicting 1093\n",
      "Predicting 1094\n",
      "Predicting 1095\n",
      "Predicting 1096\n",
      "Predicting 1097\n",
      "Predicting 1098\n",
      "Predicting 1099\n",
      "Predicting 1100\n",
      "Predicting 1101\n",
      "Predicting 1102\n",
      "Predicting 1103\n",
      "Predicting 1104\n",
      "Predicting 1105\n",
      "Predicting 1106\n",
      "Predicting 1107\n",
      "Predicting 1108\n",
      "Predicting 1109\n",
      "Predicting 1110\n",
      "Predicting 1111\n",
      "Predicting 1112\n",
      "Predicting 1113\n",
      "Predicting 1114\n",
      "Predicting 1115\n",
      "Predicting 1116\n",
      "Predicting 1117\n",
      "Predicting 1118\n",
      "Predicting 1119\n",
      "Predicting 1120\n",
      "Predicting 1121\n",
      "Predicting 1122\n",
      "Predicting 1123\n",
      "Predicting 1124\n",
      "Predicting 1125\n",
      "Predicting 1126\n",
      "Predicting 1127\n",
      "Predicting 1128\n",
      "Predicting 1129\n",
      "Predicting 1130\n",
      "Predicting 1131\n",
      "Predicting 1132\n",
      "Predicting 1133\n",
      "Predicting 1134\n",
      "Predicting 1135\n",
      "Predicting 1136\n",
      "Predicting 1137\n",
      "Predicting 1138\n",
      "Predicting 1139\n",
      "Predicting 1140\n",
      "Predicting 1141\n",
      "Predicting 1142\n",
      "Predicting 1143\n",
      "Predicting 1144\n",
      "Predicting 1145\n",
      "Predicting 1146\n",
      "Predicting 1147\n",
      "Predicting 1148\n",
      "Predicting 1149\n",
      "Predicting 1150\n",
      "Predicting 1151\n",
      "Predicting 1152\n",
      "Predicting 1153\n",
      "Predicting 1154\n",
      "Predicting 1155\n",
      "Predicting 1156\n",
      "Predicting 1157\n",
      "Predicting 1158\n",
      "Predicting 1159\n",
      "Predicting 1160\n",
      "Predicting 1161\n",
      "Predicting 1162\n",
      "Predicting 1163\n",
      "Predicting 1164\n",
      "Predicting 1165\n",
      "Predicting 1166\n",
      "Predicting 1167\n",
      "Predicting 1168\n",
      "Predicting 1169\n",
      "Predicting 1170\n",
      "Predicting 1171\n",
      "Predicting 1172\n",
      "Predicting 1173\n",
      "Predicting 1174\n",
      "Predicting 1175\n",
      "Predicting 1176\n",
      "Predicting 1177\n",
      "Predicting 1178\n",
      "Predicting 1179\n",
      "Predicting 1180\n",
      "Predicting 1181\n",
      "Predicting 1182\n",
      "Predicting 1183\n",
      "Predicting 1184\n",
      "Predicting 1185\n",
      "Predicting 1186\n",
      "Predicting 1187\n",
      "Predicting 1188\n",
      "Predicting 1189\n",
      "Predicting 1190\n",
      "Predicting 1191\n",
      "Predicting 1192\n",
      "Predicting 1193\n",
      "Predicting 1194\n",
      "Predicting 1195\n",
      "Predicting 1196\n",
      "Predicting 1197\n",
      "Predicting 1198\n",
      "Predicting 1199\n",
      "Predicting 1200\n",
      "Predicting 1201\n",
      "Predicting 1202\n",
      "Predicting 1203\n",
      "Predicting 1204\n",
      "Predicting 1205\n",
      "Predicting 1206\n",
      "Predicting 1207\n",
      "Predicting 1208\n",
      "Predicting 1209\n",
      "Predicting 1210\n",
      "Predicting 1211\n",
      "Predicting 1212\n",
      "Predicting 1213\n",
      "Predicting 1214\n",
      "Predicting 1215\n",
      "Predicting 1216\n",
      "Predicting 1217\n",
      "Predicting 1218\n",
      "Predicting 1219\n",
      "Predicting 1220\n",
      "Predicting 1221\n",
      "Predicting 1222\n",
      "Predicting 1223\n",
      "Predicting 1224\n",
      "Predicting 1225\n",
      "Predicting 1226\n",
      "Predicting 1227\n",
      "Predicting 1228\n",
      "Predicting 1229\n",
      "Predicting 1230\n",
      "Predicting 1231\n",
      "Predicting 1232\n",
      "Predicting 1233\n",
      "Predicting 1234\n",
      "Predicting 1235\n",
      "Predicting 1236\n",
      "Predicting 1237\n",
      "Predicting 1238\n",
      "Predicting 1239\n",
      "Predicting 1240\n",
      "Predicting 1241\n",
      "Predicting 1242\n",
      "Predicting 1243\n",
      "Predicting 1244\n",
      "Predicting 1245\n",
      "Predicting 1246\n",
      "Predicting 1247\n",
      "Predicting 1248\n",
      "Predicting 1249\n",
      "Predicting 1250\n",
      "Predicting 1251\n",
      "Predicting 1252\n",
      "Predicting 1253\n",
      "Predicting 1254\n",
      "Predicting 1255\n",
      "Predicting 1256\n",
      "Predicting 1257\n",
      "Predicting 1258\n",
      "Predicting 1259\n",
      "Predicting 1260\n",
      "Predicting 1261\n",
      "Predicting 1262\n",
      "Predicting 1263\n",
      "Predicting 1264\n",
      "Predicting 1265\n",
      "Predicting 1266\n",
      "Predicting 1267\n",
      "Predicting 1268\n",
      "Predicting 1269\n",
      "Predicting 1270\n",
      "Predicting 1271\n",
      "Predicting 1272\n",
      "Predicting 1273\n",
      "Predicting 1274\n",
      "Predicting 1275\n",
      "Predicting 1276\n",
      "Predicting 1277\n",
      "Predicting 1278\n",
      "Predicting 1279\n",
      "Predicting 1280\n",
      "Predicting 1281\n",
      "Predicting 1282\n",
      "Predicting 1283\n",
      "Predicting 1284\n",
      "Predicting 1285\n",
      "Predicting 1286\n",
      "Predicting 1287\n",
      "Predicting 1288\n",
      "Predicting 1289\n",
      "Predicting 1290\n",
      "Predicting 1291\n",
      "Predicting 1292\n",
      "Predicting 1293\n",
      "Predicting 1294\n",
      "Predicting 1295\n",
      "Predicting 1296\n",
      "Predicting 1297\n",
      "Predicting 1298\n",
      "Predicting 1299\n",
      "Predicting 1300\n",
      "Predicting 1301\n",
      "Predicting 1302\n",
      "Predicting 1303\n",
      "Predicting 1304\n",
      "Predicting 1305\n",
      "Predicting 1306\n",
      "Predicting 1307\n",
      "Predicting 1308\n",
      "Predicting 1309\n",
      "Predicting 1310\n",
      "Predicting 1311\n",
      "Predicting 1312\n",
      "Predicting 1313\n",
      "Predicting 1314\n",
      "Predicting 1315\n",
      "Predicting 1316\n",
      "Predicting 1317\n",
      "Predicting 1318\n",
      "Predicting 1319\n",
      "Predicting 1320\n",
      "Predicting 1321\n",
      "Predicting 1322\n",
      "Predicting 1323\n",
      "Predicting 1324\n",
      "Predicting 1325\n",
      "Predicting 1326\n",
      "Predicting 1327\n",
      "Predicting 1328\n",
      "Predicting 1329\n",
      "Predicting 1330\n",
      "Predicting 1331\n",
      "Predicting 1332\n",
      "Predicting 1333\n",
      "Predicting 1334\n",
      "Predicting 1335\n",
      "Predicting 1336\n",
      "Predicting 1337\n",
      "Predicting 1338\n",
      "Predicting 1339\n",
      "Predicting 1340\n",
      "Predicting 1341\n",
      "Predicting 1342\n",
      "Predicting 1343\n",
      "Predicting 1344\n",
      "Predicting 1345\n",
      "Predicting 1346\n",
      "Predicting 1347\n",
      "Predicting 1348\n",
      "Predicting 1349\n",
      "Predicting 1350\n",
      "Predicting 1351\n",
      "Predicting 1352\n",
      "Predicting 1353\n",
      "Predicting 1354\n",
      "Predicting 1355\n",
      "Predicting 1356\n",
      "Predicting 1357\n",
      "Predicting 1358\n",
      "Predicting 1359\n",
      "Predicting 1360\n",
      "Predicting 1361\n",
      "Predicting 1362\n",
      "Predicting 1363\n",
      "Predicting 1364\n",
      "Predicting 1365\n",
      "Predicting 1366\n",
      "Predicting 1367\n",
      "Predicting 1368\n",
      "Predicting 1369\n",
      "Predicting 1370\n",
      "Predicting 1371\n",
      "Predicting 1372\n",
      "Predicting 1373\n",
      "Predicting 1374\n",
      "Predicting 1375\n",
      "Predicting 1376\n",
      "Predicting 1377\n",
      "Predicting 1378\n",
      "Predicting 1379\n",
      "Predicting 1380\n",
      "Predicting 1381\n",
      "Predicting 1382\n",
      "Predicting 1383\n",
      "Predicting 1384\n",
      "Predicting 1385\n",
      "Predicting 1386\n",
      "Predicting 1387\n",
      "Predicting 1388\n",
      "Predicting 1389\n",
      "Predicting 1390\n",
      "Predicting 1391\n",
      "Predicting 1392\n",
      "Predicting 1393\n",
      "Predicting 1394\n",
      "Predicting 1395\n",
      "Predicting 1396\n",
      "Predicting 1397\n",
      "Predicting 1398\n",
      "Predicting 1399\n",
      "Predicting 1400\n",
      "Predicting 1401\n",
      "Predicting 1402\n",
      "Predicting 1403\n",
      "Predicting 1404\n",
      "Predicting 1405\n",
      "Predicting 1406\n",
      "Predicting 1407\n",
      "Predicting 1408\n",
      "Predicting 1409\n",
      "Predicting 1410\n",
      "Predicting 1411\n",
      "Predicting 1412\n",
      "Predicting 1413\n",
      "Predicting 1414\n",
      "Predicting 1415\n",
      "Predicting 1416\n",
      "Predicting 1417\n",
      "Predicting 1418\n",
      "Predicting 1419\n",
      "Predicting 1420\n",
      "Predicting 1421\n",
      "Predicting 1422\n",
      "Predicting 1423\n",
      "Predicting 1424\n",
      "Predicting 1425\n",
      "Predicting 1426\n",
      "Predicting 1427\n",
      "Predicting 1428\n",
      "Predicting 1429\n",
      "Predicting 1430\n",
      "Predicting 1431\n",
      "Predicting 1432\n",
      "Predicting 1433\n",
      "Predicting 1434\n",
      "Predicting 1435\n",
      "Predicting 1436\n",
      "Predicting 1437\n",
      "Predicting 1438\n",
      "Predicting 1439\n",
      "Predicting 1440\n",
      "Predicting 1441\n",
      "Predicting 1442\n",
      "Predicting 1443\n",
      "Predicting 1444\n",
      "Predicting 1445\n",
      "Predicting 1446\n",
      "Predicting 1447\n",
      "Predicting 1448\n",
      "Predicting 1449\n",
      "Predicting 1450\n",
      "Predicting 1451\n",
      "Predicting 1452\n",
      "Predicting 1453\n",
      "Predicting 1454\n",
      "Predicting 1455\n",
      "Predicting 1456\n",
      "Predicting 1457\n",
      "Predicting 1458\n",
      "Predicting 1459\n",
      "Predicting 1460\n",
      "Predicting 1461\n",
      "Predicting 1462\n",
      "Predicting 1463\n",
      "Predicting 1464\n",
      "Predicting 1465\n",
      "Predicting 1466\n",
      "Predicting 1467\n",
      "Predicting 1468\n",
      "Predicting 1469\n",
      "Predicting 1470\n",
      "Predicting 1471\n",
      "Predicting 1472\n",
      "Predicting 1473\n",
      "Predicting 1474\n",
      "Predicting 1475\n",
      "Predicting 1476\n",
      "Predicting 1477\n",
      "Predicting 1478\n",
      "Predicting 1479\n",
      "Predicting 1480\n",
      "Predicting 1481\n",
      "Predicting 1482\n",
      "Predicting 1483\n",
      "Predicting 1484\n",
      "Predicting 1485\n",
      "Predicting 1486\n",
      "Predicting 1487\n",
      "Predicting 1488\n",
      "Predicting 1489\n",
      "Predicting 1490\n",
      "Predicting 1491\n",
      "Predicting 1492\n",
      "Predicting 1493\n",
      "Predicting 1494\n",
      "Predicting 1495\n",
      "Predicting 1496\n",
      "Predicting 1497\n",
      "Predicting 1498\n",
      "Predicting 1499\n",
      "Predicting 1500\n",
      "Predicting 1501\n",
      "Predicting 1502\n",
      "Predicting 1503\n",
      "Predicting 1504\n",
      "Predicting 1505\n",
      "Predicting 1506\n",
      "Predicting 1507\n",
      "Predicting 1508\n",
      "Predicting 1509\n",
      "Predicting 1510\n",
      "Predicting 1511\n",
      "Predicting 1512\n",
      "Predicting 1513\n",
      "Predicting 1514\n",
      "Predicting 1515\n",
      "Predicting 1516\n",
      "Predicting 1517\n",
      "Predicting 1518\n",
      "Predicting 1519\n",
      "Predicting 1520\n",
      "Predicting 1521\n",
      "Predicting 1522\n",
      "Predicting 1523\n",
      "Predicting 1524\n",
      "Predicting 1525\n",
      "Predicting 1526\n",
      "Predicting 1527\n",
      "Predicting 1528\n",
      "Predicting 1529\n",
      "Predicting 1530\n",
      "Predicting 1531\n",
      "Predicting 1532\n",
      "Predicting 1533\n",
      "Predicting 1534\n",
      "Predicting 1535\n",
      "Predicting 1536\n",
      "Predicting 1537\n",
      "Predicting 1538\n",
      "Predicting 1539\n",
      "Predicting 1540\n",
      "Predicting 1541\n",
      "Predicting 1542\n",
      "Predicting 1543\n",
      "Predicting 1544\n",
      "Predicting 1545\n",
      "Predicting 1546\n",
      "Predicting 1547\n",
      "Predicting 1548\n",
      "Predicting 1549\n",
      "Predicting 1550\n",
      "Predicting 1551\n",
      "Predicting 1552\n",
      "Predicting 1553\n",
      "Predicting 1554\n",
      "Predicting 1555\n",
      "Predicting 1556\n",
      "Predicting 1557\n",
      "Predicting 1558\n",
      "Predicting 1559\n",
      "Predicting 1560\n",
      "Predicting 1561\n",
      "Predicting 1562\n",
      "Predicting 1563\n",
      "Predicting 1564\n",
      "Predicting 1565\n",
      "Predicting 1566\n",
      "Predicting 1567\n",
      "Predicting 1568\n",
      "Predicting 1569\n",
      "Predicting 1570\n",
      "Predicting 1571\n",
      "Predicting 1572\n",
      "Predicting 1573\n",
      "Predicting 1574\n",
      "Predicting 1575\n",
      "Predicting 1576\n",
      "Predicting 1577\n",
      "Predicting 1578\n",
      "Predicting 1579\n",
      "Predicting 1580\n",
      "Predicting 1581\n",
      "Predicting 1582\n",
      "Predicting 1583\n",
      "Predicting 1584\n",
      "Predicting 1585\n",
      "Predicting 1586\n",
      "Predicting 1587\n",
      "Predicting 1588\n",
      "Predicting 1589\n",
      "Predicting 1590\n",
      "Predicting 1591\n",
      "Predicting 1592\n",
      "Predicting 1593\n",
      "Predicting 1594\n",
      "Predicting 1595\n",
      "Predicting 1596\n",
      "Predicting 1597\n",
      "Predicting 1598\n",
      "Predicting 1599\n",
      "Predicting 1600\n",
      "Predicting 1601\n",
      "Predicting 1602\n",
      "Predicting 1603\n",
      "Predicting 1604\n",
      "Predicting 1605\n",
      "Predicting 1606\n",
      "Predicting 1607\n",
      "Predicting 1608\n",
      "Predicting 1609\n",
      "Predicting 1610\n",
      "Predicting 1611\n",
      "Predicting 1612\n",
      "Predicting 1613\n",
      "Predicting 1614\n",
      "Predicting 1615\n",
      "Predicting 1616\n",
      "Predicting 1617\n",
      "Predicting 1618\n",
      "Predicting 1619\n",
      "Predicting 1620\n",
      "Predicting 1621\n",
      "Predicting 1622\n",
      "Predicting 1623\n",
      "Predicting 1624\n",
      "Predicting 1625\n",
      "Predicting 1626\n",
      "Predicting 1627\n",
      "Predicting 1628\n",
      "Predicting 1629\n",
      "Predicting 1630\n",
      "Predicting 1631\n",
      "Predicting 1632\n",
      "Predicting 1633\n",
      "Predicting 1634\n",
      "Predicting 1635\n",
      "Predicting 1636\n",
      "Predicting 1637\n",
      "Predicting 1638\n",
      "Predicting 1639\n",
      "Predicting 1640\n",
      "Predicting 1641\n",
      "Predicting 1642\n",
      "Predicting 1643\n",
      "Predicting 1644\n",
      "Predicting 1645\n",
      "Predicting 1646\n",
      "Predicting 1647\n",
      "Predicting 1648\n",
      "Predicting 1649\n",
      "Predicting 1650\n",
      "Predicting 1651\n",
      "Predicting 1652\n",
      "Predicting 1653\n",
      "Predicting 1654\n",
      "Predicting 1655\n",
      "Predicting 1656\n",
      "Predicting 1657\n",
      "Predicting 1658\n",
      "Predicting 1659\n",
      "Predicting 1660\n",
      "Predicting 1661\n",
      "Predicting 1662\n",
      "Predicting 1663\n",
      "Predicting 1664\n",
      "Predicting 1665\n",
      "Predicting 1666\n",
      "Predicting 1667\n",
      "Predicting 1668\n",
      "Predicting 1669\n",
      "Predicting 1670\n",
      "Predicting 1671\n",
      "Predicting 1672\n",
      "Predicting 1673\n",
      "Predicting 1674\n",
      "Predicting 1675\n",
      "Predicting 1676\n",
      "Predicting 1677\n",
      "Predicting 1678\n",
      "Predicting 1679\n",
      "Predicting 1680\n",
      "Predicting 1681\n",
      "Predicting 1682\n",
      "Predicting 1683\n",
      "Predicting 1684\n",
      "Predicting 1685\n",
      "Predicting 1686\n",
      "Predicting 1687\n",
      "Predicting 1688\n",
      "Predicting 1689\n",
      "Predicting 1690\n",
      "Predicting 1691\n",
      "Predicting 1692\n",
      "Predicting 1693\n",
      "Predicting 1694\n",
      "Predicting 1695\n",
      "Predicting 1696\n",
      "Predicting 1697\n",
      "Predicting 1698\n",
      "Predicting 1699\n",
      "Predicting 1700\n",
      "Predicting 1701\n",
      "Predicting 1702\n",
      "Predicting 1703\n",
      "Predicting 1704\n",
      "Predicting 1705\n",
      "Predicting 1706\n",
      "Predicting 1707\n",
      "Predicting 1708\n",
      "Predicting 1709\n",
      "Predicting 1710\n",
      "Predicting 1711\n",
      "Predicting 1712\n",
      "Predicting 1713\n",
      "Predicting 1714\n",
      "Predicting 1715\n",
      "Predicting 1716\n",
      "Predicting 1717\n",
      "Predicting 1718\n",
      "Predicting 1719\n",
      "Predicting 1720\n",
      "Predicting 1721\n",
      "Predicting 1722\n",
      "Predicting 1723\n",
      "Predicting 1724\n",
      "Predicting 1725\n",
      "Predicting 1726\n",
      "Predicting 1727\n",
      "Predicting 1728\n",
      "Predicting 1729\n",
      "Predicting 1730\n",
      "Predicting 1731\n",
      "Predicting 1732\n",
      "Predicting 1733\n",
      "Predicting 1734\n",
      "Predicting 1735\n",
      "Predicting 1736\n",
      "Predicting 1737\n",
      "Predicting 1738\n",
      "Predicting 1739\n",
      "Predicting 1740\n",
      "Predicting 1741\n",
      "Predicting 1742\n",
      "Predicting 1743\n",
      "Predicting 1744\n",
      "Predicting 1745\n",
      "Predicting 1746\n",
      "Predicting 1747\n",
      "Predicting 1748\n",
      "Predicting 1749\n",
      "Predicting 1750\n",
      "Predicting 1751\n",
      "Predicting 1752\n",
      "Predicting 1753\n",
      "Predicting 1754\n",
      "Predicting 1755\n",
      "Predicting 1756\n",
      "Predicting 1757\n",
      "Predicting 1758\n",
      "Predicting 1759\n",
      "Predicting 1760\n",
      "Predicting 1761\n",
      "Predicting 1762\n",
      "Predicting 1763\n",
      "Predicting 1764\n",
      "Predicting 1765\n",
      "Predicting 1766\n",
      "Predicting 1767\n",
      "Predicting 1768\n",
      "Predicting 1769\n",
      "Predicting 1770\n",
      "Predicting 1771\n",
      "Predicting 1772\n",
      "Predicting 1773\n",
      "Predicting 1774\n",
      "Predicting 1775\n",
      "Predicting 1776\n",
      "Predicting 1777\n",
      "Predicting 1778\n",
      "Predicting 1779\n",
      "Predicting 1780\n",
      "Predicting 1781\n",
      "Predicting 1782\n",
      "Predicting 1783\n",
      "Predicting 1784\n",
      "Predicting 1785\n",
      "Predicting 1786\n",
      "Predicting 1787\n",
      "Predicting 1788\n",
      "Predicting 1789\n",
      "Predicting 1790\n",
      "Predicting 1791\n",
      "Predicting 1792\n",
      "Predicting 1793\n",
      "Predicting 1794\n",
      "Predicting 1795\n",
      "Predicting 1796\n",
      "Predicting 1797\n",
      "Predicting 1798\n",
      "Predicting 1799\n",
      "Predicting 1800\n",
      "Predicting 1801\n",
      "Predicting 1802\n",
      "Predicting 1803\n",
      "Predicting 1804\n",
      "Predicting 1805\n",
      "Predicting 1806\n",
      "Predicting 1807\n",
      "Predicting 1808\n",
      "Predicting 1809\n",
      "Predicting 1810\n",
      "Predicting 1811\n",
      "Predicting 1812\n",
      "Predicting 1813\n",
      "Predicting 1814\n",
      "Predicting 1815\n",
      "Predicting 1816\n",
      "Predicting 1817\n",
      "Predicting 1818\n",
      "Predicting 1819\n",
      "Predicting 1820\n",
      "Predicting 1821\n",
      "Predicting 1822\n",
      "Predicting 1823\n",
      "Predicting 1824\n",
      "Predicting 1825\n",
      "Predicting 1826\n",
      "Predicting 1827\n",
      "Predicting 1828\n",
      "Predicting 1829\n",
      "Predicting 1830\n",
      "Predicting 1831\n",
      "Predicting 1832\n",
      "Predicting 1833\n",
      "Predicting 1834\n",
      "Predicting 1835\n",
      "Predicting 1836\n",
      "Predicting 1837\n",
      "Predicting 1838\n",
      "Predicting 1839\n",
      "Predicting 1840\n",
      "Predicting 1841\n",
      "Predicting 1842\n",
      "Predicting 1843\n",
      "Predicting 1844\n",
      "Predicting 1845\n",
      "Predicting 1846\n",
      "Predicting 1847\n",
      "Predicting 1848\n",
      "Predicting 1849\n",
      "Predicting 1850\n",
      "Predicting 1851\n",
      "Predicting 1852\n",
      "Predicting 1853\n",
      "Predicting 1854\n",
      "Predicting 1855\n",
      "Predicting 1856\n",
      "Predicting 1857\n",
      "Predicting 1858\n",
      "Predicting 1859\n",
      "Predicting 1860\n",
      "Predicting 1861\n",
      "Predicting 1862\n",
      "Predicting 1863\n",
      "Predicting 1864\n",
      "Predicting 1865\n",
      "Predicting 1866\n",
      "Predicting 1867\n",
      "Predicting 1868\n",
      "Predicting 1869\n",
      "Predicting 1870\n",
      "Predicting 1871\n",
      "Predicting 1872\n",
      "Predicting 1873\n",
      "Predicting 1874\n",
      "Predicting 1875\n",
      "Predicting 1876\n",
      "Predicting 1877\n",
      "Predicting 1878\n",
      "Predicting 1879\n",
      "Predicting 1880\n",
      "Predicting 1881\n",
      "Predicting 1882\n",
      "Predicting 1883\n",
      "Predicting 1884\n",
      "Predicting 1885\n",
      "Predicting 1886\n",
      "Predicting 1887\n",
      "Predicting 1888\n",
      "Predicting 1889\n",
      "Predicting 1890\n",
      "Predicting 1891\n",
      "Predicting 1892\n",
      "Predicting 1893\n",
      "Predicting 1894\n",
      "Predicting 1895\n",
      "Predicting 1896\n",
      "Predicting 1897\n",
      "Predicting 1898\n",
      "Predicting 1899\n",
      "Predicting 1900\n",
      "Predicting 1901\n",
      "Predicting 1902\n",
      "Predicting 1903\n",
      "Predicting 1904\n",
      "Predicting 1905\n",
      "Predicting 1906\n",
      "Predicting 1907\n",
      "Predicting 1908\n",
      "Predicting 1909\n",
      "Predicting 1910\n",
      "Predicting 1911\n",
      "Predicting 1912\n",
      "Predicting 1913\n",
      "Predicting 1914\n",
      "Predicting 1915\n",
      "Predicting 1916\n",
      "Predicting 1917\n",
      "Predicting 1918\n",
      "Predicting 1919\n",
      "Predicting 1920\n",
      "Predicting 1921\n",
      "Predicting 1922\n",
      "Predicting 1923\n",
      "Predicting 1924\n",
      "Predicting 1925\n",
      "Predicting 1926\n",
      "Predicting 1927\n",
      "Predicting 1928\n",
      "Predicting 1929\n",
      "Predicting 1930\n",
      "Predicting 1931\n",
      "Predicting 1932\n",
      "Predicting 1933\n",
      "Predicting 1934\n",
      "Predicting 1935\n",
      "Predicting 1936\n",
      "Predicting 1937\n",
      "Predicting 1938\n",
      "Predicting 1939\n",
      "Predicting 1940\n",
      "Predicting 1941\n",
      "Predicting 1942\n",
      "Predicting 1943\n",
      "Predicting 1944\n",
      "Predicting 1945\n",
      "Predicting 1946\n",
      "Predicting 1947\n",
      "Predicting 1948\n",
      "Predicting 1949\n",
      "Predicting 1950\n",
      "Predicting 1951\n",
      "Predicting 1952\n",
      "Predicting 1953\n",
      "Predicting 1954\n",
      "Predicting 1955\n",
      "Predicting 1956\n",
      "Predicting 1957\n",
      "Predicting 1958\n",
      "Predicting 1959\n",
      "Predicting 1960\n",
      "Predicting 1961\n",
      "Predicting 1962\n",
      "Predicting 1963\n",
      "Predicting 1964\n",
      "Predicting 1965\n",
      "Predicting 1966\n",
      "Predicting 1967\n",
      "Predicting 1968\n",
      "Predicting 1969\n",
      "Predicting 1970\n",
      "Predicting 1971\n",
      "Predicting 1972\n",
      "Predicting 1973\n",
      "Predicting 1974\n",
      "Predicting 1975\n",
      "Predicting 1976\n",
      "Predicting 1977\n",
      "Predicting 1978\n",
      "Predicting 1979\n",
      "Predicting 1980\n",
      "Predicting 1981\n",
      "Predicting 1982\n",
      "Predicting 1983\n",
      "Predicting 1984\n",
      "Predicting 1985\n",
      "Predicting 1986\n",
      "Predicting 1987\n",
      "Predicting 1988\n",
      "Predicting 1989\n",
      "Predicting 1990\n",
      "Predicting 1991\n",
      "Predicting 1992\n",
      "Predicting 1993\n",
      "Predicting 1994\n",
      "Predicting 1995\n",
      "Predicting 1996\n",
      "Predicting 1997\n",
      "Predicting 1998\n",
      "Predicting 1999\n",
      "Predicting 2000\n",
      "Predicting 2001\n",
      "Predicting 2002\n",
      "Predicting 2003\n",
      "Predicting 2004\n",
      "Predicting 2005\n",
      "Predicting 2006\n",
      "Predicting 2007\n",
      "Predicting 2008\n",
      "Predicting 2009\n",
      "Predicting 2010\n",
      "Predicting 2011\n",
      "Predicting 2012\n",
      "Predicting 2013\n",
      "Predicting 2014\n",
      "Predicting 2015\n",
      "Predicting 2016\n",
      "Predicting 2017\n",
      "Predicting 2018\n",
      "Predicting 2019\n",
      "Predicting 2020\n",
      "Predicting 2021\n",
      "Predicting 2022\n",
      "Predicting 2023\n",
      "Predicting 2024\n",
      "Predicting 2025\n",
      "Predicting 2026\n",
      "Predicting 2027\n",
      "Predicting 2028\n",
      "Predicting 2029\n",
      "Predicting 2030\n",
      "Predicting 2031\n",
      "Predicting 2032\n",
      "Predicting 2033\n",
      "Predicting 2034\n",
      "Predicting 2035\n",
      "Predicting 2036\n",
      "Predicting 2037\n",
      "Predicting 2038\n",
      "Predicting 2039\n",
      "Predicting 2040\n",
      "Predicting 2041\n",
      "Predicting 2042\n",
      "Predicting 2043\n",
      "Predicting 2044\n",
      "Predicting 2045\n",
      "Predicting 2046\n",
      "Predicting 2047\n",
      "Predicting 2048\n",
      "Predicting 2049\n",
      "Predicting 2050\n",
      "Predicting 2051\n",
      "Predicting 2052\n",
      "Predicting 2053\n",
      "Predicting 2054\n",
      "Predicting 2055\n",
      "Predicting 2056\n",
      "Predicting 2057\n",
      "Predicting 2058\n",
      "Predicting 2059\n",
      "Predicting 2060\n",
      "Predicting 2061\n",
      "Predicting 2062\n",
      "Predicting 2063\n",
      "Predicting 2064\n",
      "Predicting 2065\n",
      "Predicting 2066\n",
      "Predicting 2067\n",
      "Predicting 2068\n",
      "Predicting 2069\n",
      "Predicting 2070\n",
      "Predicting 2071\n",
      "Predicting 2072\n",
      "Predicting 2073\n",
      "Predicting 2074\n",
      "Predicting 2075\n",
      "Predicting 2076\n",
      "Predicting 2077\n",
      "Predicting 2078\n",
      "Predicting 2079\n",
      "Predicting 2080\n",
      "Predicting 2081\n",
      "Predicting 2082\n",
      "Predicting 2083\n",
      "Predicting 2084\n",
      "Predicting 2085\n",
      "Predicting 2086\n",
      "Predicting 2087\n",
      "Predicting 2088\n",
      "Predicting 2089\n",
      "Predicting 2090\n",
      "Predicting 2091\n",
      "Predicting 2092\n",
      "Predicting 2093\n",
      "Predicting 2094\n",
      "Predicting 2095\n",
      "Predicting 2096\n",
      "Predicting 2097\n",
      "Predicting 2098\n",
      "Predicting 2099\n",
      "Predicting 2100\n",
      "Predicting 2101\n",
      "Predicting 2102\n",
      "Predicting 2103\n",
      "Predicting 2104\n",
      "Predicting 2105\n",
      "Predicting 2106\n",
      "Predicting 2107\n",
      "Predicting 2108\n",
      "Predicting 2109\n",
      "Predicting 2110\n",
      "Predicting 2111\n",
      "Predicting 2112\n",
      "Predicting 2113\n",
      "Predicting 2114\n",
      "Predicting 2115\n",
      "Predicting 2116\n",
      "Predicting 2117\n",
      "Predicting 2118\n",
      "Predicting 2119\n",
      "Predicting 2120\n",
      "Predicting 2121\n",
      "Predicting 2122\n",
      "Predicting 2123\n",
      "Predicting 2124\n",
      "Predicting 2125\n",
      "Predicting 2126\n",
      "Predicting 2127\n",
      "Predicting 2128\n",
      "Predicting 2129\n",
      "Predicting 2130\n",
      "Predicting 2131\n",
      "Predicting 2132\n",
      "Predicting 2133\n",
      "Predicting 2134\n",
      "Predicting 2135\n",
      "Predicting 2136\n",
      "Predicting 2137\n",
      "Predicting 2138\n",
      "Predicting 2139\n",
      "Predicting 2140\n",
      "Predicting 2141\n",
      "Predicting 2142\n",
      "Predicting 2143\n",
      "Predicting 2144\n",
      "Predicting 2145\n",
      "Predicting 2146\n",
      "Predicting 2147\n",
      "Predicting 2148\n",
      "Predicting 2149\n",
      "Predicting 2150\n",
      "Predicting 2151\n",
      "Predicting 2152\n",
      "Predicting 2153\n",
      "Predicting 2154\n",
      "Predicting 2155\n",
      "Predicting 2156\n",
      "Predicting 2157\n",
      "Predicting 2158\n",
      "Predicting 2159\n",
      "Predicting 2160\n",
      "Predicting 2161\n",
      "Predicting 2162\n",
      "Predicting 2163\n",
      "Predicting 2164\n",
      "Predicting 2165\n",
      "Predicting 2166\n",
      "Predicting 2167\n",
      "Predicting 2168\n",
      "Predicting 2169\n",
      "Predicting 2170\n",
      "Predicting 2171\n",
      "Predicting 2172\n",
      "Predicting 2173\n",
      "Predicting 2174\n",
      "Predicting 2175\n",
      "Predicting 2176\n",
      "Predicting 2177\n",
      "Predicting 2178\n",
      "Predicting 2179\n",
      "Predicting 2180\n",
      "Predicting 2181\n",
      "Predicting 2182\n",
      "Predicting 2183\n",
      "Predicting 2184\n",
      "Predicting 2185\n",
      "Predicting 2186\n",
      "Predicting 2187\n",
      "Predicting 2188\n",
      "Predicting 2189\n",
      "Predicting 2190\n",
      "Predicting 2191\n",
      "Predicting 2192\n",
      "Predicting 2193\n",
      "Predicting 2194\n",
      "Predicting 2195\n",
      "Predicting 2196\n",
      "Predicting 2197\n",
      "Predicting 2198\n",
      "Predicting 2199\n",
      "Predicting 2200\n",
      "Predicting 2201\n",
      "Predicting 2202\n",
      "Predicting 2203\n",
      "Predicting 2204\n",
      "Predicting 2205\n",
      "Predicting 2206\n",
      "Predicting 2207\n",
      "Predicting 2208\n",
      "Predicting 2209\n",
      "Predicting 2210\n",
      "Predicting 2211\n",
      "Predicting 2212\n",
      "Predicting 2213\n",
      "Predicting 2214\n",
      "Predicting 2215\n",
      "Predicting 2216\n",
      "Predicting 2217\n",
      "Predicting 2218\n",
      "Predicting 2219\n",
      "Predicting 2220\n",
      "Predicting 2221\n",
      "Predicting 2222\n",
      "Predicting 2223\n",
      "Predicting 2224\n",
      "Predicting 2225\n",
      "Predicting 2226\n",
      "Predicting 2227\n",
      "Predicting 2228\n",
      "Predicting 2229\n",
      "Predicting 2230\n",
      "Predicting 2231\n",
      "Predicting 2232\n",
      "Predicting 2233\n",
      "Predicting 2234\n",
      "Predicting 2235\n",
      "Predicting 2236\n",
      "Predicting 2237\n",
      "Predicting 2238\n",
      "Predicting 2239\n",
      "Predicting 2240\n",
      "Predicting 2241\n",
      "Predicting 2242\n",
      "Predicting 2243\n",
      "Predicting 2244\n",
      "Predicting 2245\n",
      "Predicting 2246\n",
      "Predicting 2247\n",
      "Predicting 2248\n",
      "Predicting 2249\n",
      "Predicting 2250\n",
      "Predicting 2251\n",
      "Predicting 2252\n",
      "Predicting 2253\n",
      "Predicting 2254\n",
      "Predicting 2255\n",
      "Predicting 2256\n",
      "Predicting 2257\n",
      "Predicting 2258\n",
      "Predicting 2259\n",
      "Predicting 2260\n",
      "Predicting 2261\n",
      "Predicting 2262\n",
      "Predicting 2263\n",
      "Predicting 2264\n",
      "Predicting 2265\n",
      "Predicting 2266\n",
      "Predicting 2267\n",
      "Predicting 2268\n",
      "Predicting 2269\n",
      "Predicting 2270\n",
      "Predicting 2271\n",
      "Predicting 2272\n",
      "Predicting 2273\n",
      "Predicting 2274\n",
      "Predicting 2275\n",
      "Predicting 2276\n",
      "Predicting 2277\n",
      "Predicting 2278\n",
      "Predicting 2279\n",
      "Predicting 2280\n",
      "Predicting 2281\n",
      "Predicting 2282\n",
      "Predicting 2283\n",
      "Predicting 2284\n",
      "Predicting 2285\n",
      "Predicting 2286\n",
      "Predicting 2287\n",
      "Predicting 2288\n",
      "Predicting 2289\n",
      "Predicting 2290\n",
      "Predicting 2291\n",
      "Predicting 2292\n",
      "Predicting 2293\n",
      "Predicting 2294\n",
      "Predicting 2295\n",
      "Predicting 2296\n",
      "Predicting 2297\n",
      "Predicting 2298\n",
      "Predicting 2299\n",
      "Predicting 2300\n",
      "Predicting 2301\n",
      "Predicting 2302\n",
      "Predicting 2303\n",
      "Predicting 2304\n",
      "Predicting 2305\n",
      "Predicting 2306\n",
      "Predicting 2307\n",
      "Predicting 2308\n",
      "Predicting 2309\n",
      "Predicting 2310\n",
      "Predicting 2311\n",
      "Predicting 2312\n",
      "Predicting 2313\n",
      "Predicting 2314\n",
      "Predicting 2315\n",
      "Predicting 2316\n",
      "Predicting 2317\n",
      "Predicting 2318\n",
      "Predicting 2319\n",
      "Predicting 2320\n",
      "Predicting 2321\n",
      "Predicting 2322\n",
      "Predicting 2323\n",
      "Predicting 2324\n",
      "Predicting 2325\n",
      "Predicting 2326\n",
      "Predicting 2327\n",
      "Predicting 2328\n",
      "Predicting 2329\n",
      "Predicting 2330\n",
      "Predicting 2331\n",
      "Predicting 2332\n",
      "Predicting 2333\n",
      "Predicting 2334\n",
      "Predicting 2335\n",
      "Predicting 2336\n",
      "Predicting 2337\n",
      "Predicting 2338\n",
      "Predicting 2339\n",
      "Predicting 2340\n",
      "Predicting 2341\n",
      "Predicting 2342\n",
      "Predicting 2343\n",
      "Predicting 2344\n",
      "Predicting 2345\n",
      "Predicting 2346\n",
      "Predicting 2347\n",
      "Predicting 2348\n",
      "Predicting 2349\n",
      "Predicting 2350\n",
      "Predicting 2351\n",
      "Predicting 2352\n",
      "Predicting 2353\n",
      "Predicting 2354\n",
      "Predicting 2355\n",
      "Predicting 2356\n",
      "Predicting 2357\n",
      "Predicting 2358\n",
      "Predicting 2359\n",
      "Predicting 2360\n",
      "Predicting 2361\n",
      "Predicting 2362\n",
      "Predicting 2363\n",
      "Predicting 2364\n",
      "Predicting 2365\n",
      "Predicting 2366\n",
      "Predicting 2367\n",
      "Predicting 2368\n",
      "Predicting 2369\n",
      "Predicting 2370\n",
      "Predicting 2371\n",
      "Predicting 2372\n",
      "Predicting 2373\n",
      "Predicting 2374\n",
      "Predicting 2375\n",
      "Predicting 2376\n",
      "Predicting 2377\n",
      "Predicting 2378\n",
      "Predicting 2379\n",
      "Predicting 2380\n",
      "Predicting 2381\n",
      "Predicting 2382\n",
      "Predicting 2383\n",
      "Predicting 2384\n",
      "Predicting 2385\n",
      "Predicting 2386\n",
      "Predicting 2387\n",
      "Predicting 2388\n",
      "Predicting 2389\n",
      "Predicting 2390\n",
      "Predicting 2391\n",
      "Predicting 2392\n",
      "Predicting 2393\n",
      "Predicting 2394\n",
      "Predicting 2395\n",
      "Predicting 2396\n",
      "Predicting 2397\n",
      "Predicting 2398\n",
      "Predicting 2399\n",
      "Predicting 2400\n",
      "Predicting 2401\n",
      "Predicting 2402\n",
      "Predicting 2403\n",
      "Predicting 2404\n",
      "Predicting 2405\n",
      "Predicting 2406\n",
      "Predicting 2407\n",
      "Predicting 2408\n",
      "Predicting 2409\n",
      "Predicting 2410\n",
      "Predicting 2411\n",
      "Predicting 2412\n",
      "Predicting 2413\n",
      "Predicting 2414\n",
      "Predicting 2415\n",
      "Predicting 2416\n",
      "Predicting 2417\n",
      "Predicting 2418\n",
      "Predicting 2419\n",
      "Predicting 2420\n",
      "Predicting 2421\n",
      "Predicting 2422\n",
      "Predicting 2423\n",
      "Predicting 2424\n",
      "Predicting 2425\n",
      "Predicting 2426\n",
      "Predicting 2427\n",
      "Predicting 2428\n",
      "Predicting 2429\n",
      "Predicting 2430\n",
      "Predicting 2431\n",
      "Predicting 2432\n",
      "Predicting 2433\n",
      "Predicting 2434\n",
      "Predicting 2435\n",
      "Predicting 2436\n",
      "Predicting 2437\n",
      "Predicting 2438\n",
      "Predicting 2439\n",
      "Predicting 2440\n",
      "Predicting 2441\n",
      "Predicting 2442\n",
      "Predicting 2443\n",
      "Predicting 2444\n",
      "Predicting 2445\n",
      "Predicting 2446\n",
      "Predicting 2447\n",
      "Predicting 2448\n",
      "Predicting 2449\n",
      "Predicting 2450\n",
      "Predicting 2451\n",
      "Predicting 2452\n",
      "Predicting 2453\n",
      "Predicting 2454\n",
      "Predicting 2455\n",
      "Predicting 2456\n",
      "Predicting 2457\n",
      "Predicting 2458\n",
      "Predicting 2459\n",
      "Predicting 2460\n",
      "Predicting 2461\n",
      "Predicting 2462\n",
      "Predicting 2463\n",
      "Predicting 2464\n",
      "Predicting 2465\n",
      "Predicting 2466\n",
      "Predicting 2467\n",
      "Predicting 2468\n",
      "Predicting 2469\n",
      "Predicting 2470\n",
      "Predicting 2471\n",
      "Predicting 2472\n",
      "Predicting 2473\n",
      "Predicting 2474\n",
      "Predicting 2475\n",
      "Predicting 2476\n",
      "Predicting 2477\n",
      "Predicting 2478\n",
      "Predicting 2479\n",
      "Predicting 2480\n",
      "Predicting 2481\n",
      "Predicting 2482\n",
      "Predicting 2483\n",
      "Predicting 2484\n",
      "Predicting 2485\n",
      "Predicting 2486\n",
      "Predicting 2487\n",
      "Predicting 2488\n",
      "Predicting 2489\n",
      "Predicting 2490\n",
      "Predicting 2491\n",
      "Predicting 2492\n",
      "Predicting 2493\n",
      "Predicting 2494\n",
      "Predicting 2495\n",
      "Predicting 2496\n",
      "Predicting 2497\n",
      "Predicting 2498\n",
      "Predicting 2499\n",
      "Predicting 2500\n",
      "Predicting 2501\n",
      "Predicting 2502\n",
      "Predicting 2503\n",
      "Predicting 2504\n",
      "Predicting 2505\n",
      "Predicting 2506\n",
      "Predicting 2507\n",
      "Predicting 2508\n",
      "Predicting 2509\n",
      "Predicting 2510\n",
      "Predicting 2511\n",
      "Predicting 2512\n",
      "Predicting 2513\n",
      "Predicting 2514\n",
      "Predicting 2515\n",
      "Predicting 2516\n",
      "Predicting 2517\n",
      "Predicting 2518\n",
      "Predicting 2519\n",
      "Predicting 2520\n",
      "Predicting 2521\n",
      "Predicting 2522\n",
      "Predicting 2523\n",
      "Predicting 2524\n",
      "Predicting 2525\n",
      "Predicting 2526\n",
      "Predicting 2527\n",
      "Predicting 2528\n",
      "Predicting 2529\n",
      "Predicting 2530\n",
      "Predicting 2531\n",
      "Predicting 2532\n",
      "Predicting 2533\n",
      "Predicting 2534\n",
      "Predicting 2535\n",
      "Predicting 2536\n",
      "Predicting 2537\n",
      "Predicting 2538\n",
      "Predicting 2539\n",
      "Predicting 2540\n",
      "Predicting 2541\n",
      "Predicting 2542\n",
      "Predicting 2543\n",
      "Predicting 2544\n",
      "Predicting 2545\n",
      "Predicting 2546\n",
      "Predicting 2547\n",
      "Predicting 2548\n",
      "Predicting 2549\n",
      "Predicting 2550\n",
      "Predicting 2551\n",
      "Predicting 2552\n",
      "Predicting 2553\n",
      "Predicting 2554\n",
      "Predicting 2555\n",
      "Predicting 2556\n",
      "Predicting 2557\n",
      "Predicting 2558\n",
      "Predicting 2559\n",
      "Predicting 2560\n",
      "Predicting 2561\n",
      "Predicting 2562\n",
      "Predicting 2563\n",
      "Predicting 2564\n",
      "Predicting 2565\n",
      "Predicting 2566\n",
      "Predicting 2567\n",
      "Predicting 2568\n",
      "Predicting 2569\n",
      "Predicting 2570\n",
      "Predicting 2571\n",
      "Predicting 2572\n",
      "Predicting 2573\n",
      "Predicting 2574\n",
      "Predicting 2575\n",
      "Predicting 2576\n",
      "Predicting 2577\n",
      "Predicting 2578\n",
      "Predicting 2579\n",
      "Predicting 2580\n",
      "Predicting 2581\n",
      "Predicting 2582\n",
      "Predicting 2583\n",
      "Predicting 2584\n",
      "Predicting 2585\n",
      "Predicting 2586\n",
      "Predicting 2587\n",
      "Predicting 2588\n",
      "Predicting 2589\n",
      "Predicting 2590\n",
      "Predicting 2591\n",
      "Predicting 2592\n",
      "Predicting 2593\n",
      "Predicting 2594\n",
      "Predicting 2595\n",
      "Predicting 2596\n",
      "Predicting 2597\n",
      "Predicting 2598\n",
      "Predicting 2599\n",
      "Predicting 2600\n",
      "Predicting 2601\n",
      "Predicting 2602\n",
      "Predicting 2603\n",
      "Predicting 2604\n",
      "Predicting 2605\n",
      "Predicting 2606\n",
      "Predicting 2607\n",
      "Predicting 2608\n",
      "Predicting 2609\n",
      "Predicting 2610\n",
      "Predicting 2611\n",
      "Predicting 2612\n",
      "Predicting 2613\n",
      "Predicting 2614\n",
      "Predicting 2615\n",
      "Predicting 2616\n",
      "Predicting 2617\n",
      "Predicting 2618\n",
      "Predicting 2619\n",
      "Predicting 2620\n",
      "Predicting 2621\n",
      "Predicting 2622\n",
      "Predicting 2623\n",
      "Predicting 2624\n",
      "Predicting 2625\n",
      "Predicting 2626\n",
      "Predicting 2627\n",
      "Predicting 2628\n",
      "Predicting 2629\n",
      "Predicting 2630\n",
      "Predicting 2631\n",
      "Predicting 2632\n",
      "Predicting 2633\n",
      "Predicting 2634\n",
      "Predicting 2635\n",
      "Predicting 2636\n",
      "Predicting 2637\n",
      "Predicting 2638\n",
      "Predicting 2639\n",
      "Predicting 2640\n",
      "Predicting 2641\n",
      "Predicting 2642\n",
      "Predicting 2643\n",
      "Predicting 2644\n",
      "Predicting 2645\n",
      "Predicting 2646\n",
      "Predicting 2647\n",
      "Predicting 2648\n",
      "Predicting 2649\n",
      "Predicting 2650\n",
      "Predicting 2651\n",
      "Predicting 2652\n",
      "Predicting 2653\n",
      "Predicting 2654\n",
      "Predicting 2655\n",
      "Predicting 2656\n",
      "Predicting 2657\n",
      "Predicting 2658\n",
      "Predicting 2659\n",
      "Predicting 2660\n",
      "Predicting 2661\n",
      "Predicting 2662\n",
      "Predicting 2663\n",
      "Predicting 2664\n",
      "Predicting 2665\n",
      "Predicting 2666\n",
      "Predicting 2667\n",
      "Predicting 2668\n",
      "Predicting 2669\n",
      "Predicting 2670\n",
      "Predicting 2671\n",
      "Predicting 2672\n",
      "Predicting 2673\n",
      "Predicting 2674\n",
      "Predicting 2675\n",
      "Predicting 2676\n",
      "Predicting 2677\n",
      "Predicting 2678\n",
      "Predicting 2679\n",
      "Predicting 2680\n",
      "Predicting 2681\n",
      "Predicting 2682\n",
      "Predicting 2683\n",
      "Predicting 2684\n",
      "Predicting 2685\n",
      "Predicting 2686\n",
      "Predicting 2687\n",
      "Predicting 2688\n",
      "Predicting 2689\n",
      "Predicting 2690\n",
      "Predicting 2691\n",
      "Predicting 2692\n",
      "Predicting 2693\n",
      "Predicting 2694\n",
      "Predicting 2695\n",
      "Predicting 2696\n",
      "Predicting 2697\n",
      "Predicting 2698\n",
      "Predicting 2699\n",
      "Predicting 2700\n",
      "Predicting 2701\n",
      "Predicting 2702\n",
      "Predicting 2703\n",
      "Predicting 2704\n",
      "Predicting 2705\n",
      "Predicting 2706\n",
      "Predicting 2707\n",
      "Predicting 2708\n",
      "Predicting 2709\n",
      "Predicting 2710\n",
      "Predicting 2711\n",
      "Predicting 2712\n",
      "Predicting 2713\n",
      "Predicting 2714\n",
      "Predicting 2715\n",
      "Predicting 2716\n",
      "Predicting 2717\n",
      "Predicting 2718\n",
      "Predicting 2719\n",
      "Predicting 2720\n",
      "Predicting 2721\n",
      "Predicting 2722\n",
      "Predicting 2723\n",
      "Predicting 2724\n",
      "Predicting 2725\n",
      "Predicting 2726\n",
      "Predicting 2727\n",
      "Predicting 2728\n",
      "Predicting 2729\n",
      "Predicting 2730\n",
      "Predicting 2731\n",
      "Predicting 2732\n",
      "Predicting 2733\n",
      "Predicting 2734\n",
      "Predicting 2735\n",
      "Predicting 2736\n",
      "Predicting 2737\n",
      "Predicting 2738\n",
      "Predicting 2739\n",
      "Predicting 2740\n",
      "Predicting 2741\n",
      "Predicting 2742\n",
      "Predicting 2743\n",
      "Predicting 2744\n",
      "Predicting 2745\n",
      "Predicting 2746\n",
      "Predicting 2747\n",
      "Predicting 2748\n",
      "Predicting 2749\n",
      "Predicting 2750\n",
      "Predicting 2751\n",
      "Predicting 2752\n",
      "Predicting 2753\n",
      "Predicting 2754\n",
      "Predicting 2755\n",
      "Predicting 2756\n",
      "Predicting 2757\n",
      "Predicting 2758\n",
      "Predicting 2759\n",
      "Predicting 2760\n",
      "Predicting 2761\n",
      "Predicting 2762\n",
      "Predicting 2763\n",
      "Predicting 2764\n",
      "Predicting 2765\n",
      "Predicting 2766\n",
      "Predicting 2767\n",
      "Predicting 2768\n",
      "Predicting 2769\n",
      "Predicting 2770\n",
      "Predicting 2771\n",
      "Predicting 2772\n",
      "Predicting 2773\n",
      "Predicting 2774\n",
      "Predicting 2775\n",
      "Predicting 2776\n",
      "Predicting 2777\n",
      "Predicting 2778\n",
      "Predicting 2779\n",
      "Predicting 2780\n",
      "Predicting 2781\n",
      "Predicting 2782\n",
      "Predicting 2783\n",
      "Predicting 2784\n",
      "Predicting 2785\n",
      "Predicting 2786\n",
      "Predicting 2787\n",
      "Predicting 2788\n",
      "Predicting 2789\n",
      "Predicting 2790\n",
      "Predicting 2791\n",
      "Predicting 2792\n",
      "Predicting 2793\n",
      "Predicting 2794\n",
      "Predicting 2795\n",
      "Predicting 2796\n",
      "Predicting 2797\n",
      "Predicting 2798\n",
      "Predicting 2799\n",
      "Predicting 2800\n",
      "Predicting 2801\n",
      "Predicting 2802\n",
      "Predicting 2803\n",
      "Predicting 2804\n",
      "Predicting 2805\n",
      "Predicting 2806\n",
      "Predicting 2807\n",
      "Predicting 2808\n",
      "Predicting 2809\n",
      "Predicting 2810\n",
      "Predicting 2811\n",
      "Predicting 2812\n",
      "Predicting 2813\n",
      "Predicting 2814\n",
      "Predicting 2815\n",
      "Predicting 2816\n",
      "Predicting 2817\n",
      "Predicting 2818\n",
      "Predicting 2819\n",
      "Predicting 2820\n",
      "Predicting 2821\n",
      "Predicting 2822\n",
      "Predicting 2823\n",
      "Predicting 2824\n",
      "Predicting 2825\n",
      "Predicting 2826\n",
      "Predicting 2827\n",
      "Predicting 2828\n",
      "Predicting 2829\n",
      "Predicting 2830\n",
      "Predicting 2831\n",
      "Predicting 2832\n",
      "Predicting 2833\n",
      "Predicting 2834\n",
      "Predicting 2835\n",
      "Predicting 2836\n",
      "Predicting 2837\n",
      "Predicting 2838\n",
      "Predicting 2839\n",
      "Predicting 2840\n",
      "Predicting 2841\n",
      "Predicting 2842\n",
      "Predicting 2843\n",
      "Predicting 2844\n",
      "Predicting 2845\n",
      "Predicting 2846\n",
      "Predicting 2847\n",
      "Predicting 2848\n",
      "Predicting 2849\n",
      "Predicting 2850\n",
      "Predicting 2851\n",
      "Predicting 2852\n",
      "Predicting 2853\n",
      "Predicting 2854\n",
      "Predicting 2855\n",
      "Predicting 2856\n",
      "Predicting 2857\n",
      "Predicting 2858\n",
      "Predicting 2859\n",
      "Predicting 2860\n",
      "Predicting 2861\n",
      "Predicting 2862\n",
      "Predicting 2863\n",
      "Predicting 2864\n",
      "Predicting 2865\n",
      "Predicting 2866\n",
      "Predicting 2867\n",
      "Predicting 2868\n",
      "Predicting 2869\n",
      "Predicting 2870\n",
      "Predicting 2871\n",
      "Predicting 2872\n",
      "Predicting 2873\n",
      "Predicting 2874\n",
      "Predicting 2875\n",
      "Predicting 2876\n",
      "Predicting 2877\n",
      "Predicting 2878\n",
      "Predicting 2879\n",
      "Predicting 2880\n",
      "Predicting 2881\n",
      "Predicting 2882\n",
      "Predicting 2883\n",
      "Predicting 2884\n",
      "Predicting 2885\n",
      "Predicting 2886\n",
      "Predicting 2887\n",
      "Predicting 2888\n",
      "Predicting 2889\n",
      "Predicting 2890\n",
      "Predicting 2891\n",
      "Predicting 2892\n",
      "Predicting 2893\n",
      "Predicting 2894\n",
      "Predicting 2895\n",
      "Predicting 2896\n",
      "Predicting 2897\n",
      "Predicting 2898\n",
      "Predicting 2899\n",
      "Predicting 2900\n",
      "Predicting 2901\n",
      "Predicting 2902\n",
      "Predicting 2903\n",
      "Predicting 2904\n",
      "Predicting 2905\n",
      "Predicting 2906\n",
      "Predicting 2907\n",
      "Predicting 2908\n",
      "Predicting 2909\n",
      "Predicting 2910\n",
      "Predicting 2911\n",
      "Predicting 2912\n",
      "Predicting 2913\n",
      "Predicting 2914\n",
      "Predicting 2915\n",
      "Predicting 2916\n",
      "Predicting 2917\n",
      "Predicting 2918\n",
      "Predicting 2919\n",
      "Predicting 2920\n",
      "Predicting 2921\n",
      "Predicting 2922\n",
      "Predicting 2923\n",
      "Predicting 2924\n",
      "Predicting 2925\n",
      "Predicting 2926\n",
      "Predicting 2927\n",
      "Predicting 2928\n",
      "Predicting 2929\n",
      "Predicting 2930\n",
      "Predicting 2931\n",
      "Predicting 2932\n",
      "Predicting 2933\n",
      "Predicting 2934\n",
      "Predicting 2935\n",
      "Predicting 2936\n",
      "Predicting 2937\n",
      "Predicting 2938\n",
      "Predicting 2939\n",
      "Predicting 2940\n",
      "Predicting 2941\n",
      "Predicting 2942\n",
      "Predicting 2943\n",
      "Predicting 2944\n",
      "Predicting 2945\n",
      "Predicting 2946\n",
      "Predicting 2947\n",
      "Predicting 2948\n",
      "Predicting 2949\n",
      "Predicting 2950\n",
      "Predicting 2951\n",
      "Predicting 2952\n",
      "Predicting 2953\n",
      "Predicting 2954\n",
      "Predicting 2955\n",
      "Predicting 2956\n",
      "Predicting 2957\n",
      "Predicting 2958\n",
      "Predicting 2959\n",
      "Predicting 2960\n",
      "Predicting 2961\n",
      "Predicting 2962\n",
      "Predicting 2963\n",
      "Predicting 2964\n",
      "Predicting 2965\n",
      "Predicting 2966\n",
      "Predicting 2967\n",
      "Predicting 2968\n",
      "Predicting 2969\n",
      "Predicting 2970\n",
      "Predicting 2971\n",
      "Predicting 2972\n",
      "Predicting 2973\n",
      "Predicting 2974\n",
      "Predicting 2975\n",
      "Predicting 2976\n",
      "Predicting 2977\n",
      "Predicting 2978\n",
      "Predicting 2979\n",
      "Predicting 2980\n",
      "Predicting 2981\n",
      "Predicting 2982\n",
      "Predicting 2983\n",
      "Predicting 2984\n",
      "Predicting 2985\n",
      "Predicting 2986\n",
      "Predicting 2987\n",
      "Predicting 2988\n",
      "Predicting 2989\n",
      "Predicting 2990\n",
      "Predicting 2991\n",
      "Predicting 2992\n",
      "Predicting 2993\n",
      "Predicting 2994\n",
      "Predicting 2995\n",
      "Predicting 2996\n",
      "Predicting 2997\n",
      "Predicting 2998\n",
      "Predicting 2999\n",
      "Predicting 3000\n",
      "Predicting 3001\n",
      "Predicting 3002\n",
      "Predicting 3003\n",
      "Predicting 3004\n",
      "Predicting 3005\n",
      "Predicting 3006\n",
      "Predicting 3007\n",
      "Predicting 3008\n",
      "Predicting 3009\n",
      "Predicting 3010\n",
      "Predicting 3011\n",
      "Predicting 3012\n",
      "Predicting 3013\n",
      "Predicting 3014\n",
      "Predicting 3015\n",
      "Predicting 3016\n",
      "Predicting 3017\n",
      "Predicting 3018\n",
      "Predicting 3019\n",
      "Predicting 3020\n",
      "Predicting 3021\n",
      "Predicting 3022\n",
      "Predicting 3023\n",
      "Predicting 3024\n",
      "Predicting 3025\n",
      "Predicting 3026\n",
      "Predicting 3027\n",
      "Predicting 3028\n",
      "Predicting 3029\n",
      "Predicting 3030\n",
      "Predicting 3031\n",
      "Predicting 3032\n",
      "Predicting 3033\n",
      "Predicting 3034\n",
      "Predicting 3035\n",
      "Predicting 3036\n",
      "Predicting 3037\n",
      "Predicting 3038\n",
      "Predicting 3039\n",
      "Predicting 3040\n",
      "Predicting 3041\n",
      "Predicting 3042\n",
      "Predicting 3043\n",
      "Predicting 3044\n",
      "Predicting 3045\n",
      "Predicting 3046\n",
      "Predicting 3047\n",
      "Predicting 3048\n",
      "Predicting 3049\n",
      "Predicting 3050\n",
      "Predicting 3051\n",
      "Predicting 3052\n",
      "Predicting 3053\n",
      "Predicting 3054\n",
      "Predicting 3055\n",
      "Predicting 3056\n",
      "Predicting 3057\n",
      "Predicting 3058\n",
      "Predicting 3059\n",
      "Predicting 3060\n",
      "Predicting 3061\n",
      "Predicting 3062\n",
      "Predicting 3063\n",
      "Predicting 3064\n",
      "Predicting 3065\n",
      "Predicting 3066\n",
      "Predicting 3067\n",
      "Predicting 3068\n",
      "Predicting 3069\n",
      "Predicting 3070\n",
      "Predicting 3071\n",
      "Predicting 3072\n",
      "Predicting 3073\n",
      "Predicting 3074\n",
      "Predicting 3075\n",
      "Predicting 3076\n",
      "Predicting 3077\n",
      "Predicting 3078\n",
      "Predicting 3079\n",
      "Predicting 3080\n",
      "Predicting 3081\n",
      "Predicting 3082\n",
      "Predicting 3083\n",
      "Predicting 3084\n",
      "Predicting 3085\n",
      "Predicting 3086\n",
      "Predicting 3087\n",
      "Predicting 3088\n",
      "Predicting 3089\n",
      "Predicting 3090\n",
      "Predicting 3091\n",
      "Predicting 3092\n",
      "Predicting 3093\n",
      "Predicting 3094\n",
      "Predicting 3095\n",
      "Predicting 3096\n",
      "Predicting 3097\n",
      "Predicting 3098\n",
      "Predicting 3099\n",
      "Predicting 3100\n",
      "Predicting 3101\n",
      "Predicting 3102\n",
      "Predicting 3103\n",
      "Predicting 3104\n",
      "Predicting 3105\n",
      "Predicting 3106\n",
      "Predicting 3107\n",
      "Predicting 3108\n",
      "Predicting 3109\n",
      "Predicting 3110\n",
      "Predicting 3111\n",
      "Predicting 3112\n",
      "Predicting 3113\n",
      "Predicting 3114\n",
      "Predicting 3115\n",
      "Predicting 3116\n",
      "Predicting 3117\n",
      "Predicting 3118\n",
      "Predicting 3119\n",
      "Predicting 3120\n",
      "Predicting 3121\n",
      "Predicting 3122\n",
      "Predicting 3123\n",
      "Predicting 3124\n",
      "Predicting 3125\n",
      "Predicting 3126\n",
      "Predicting 3127\n",
      "Predicting 3128\n",
      "Predicting 3129\n",
      "Predicting 3130\n",
      "Predicting 3131\n",
      "Predicting 3132\n",
      "Predicting 3133\n",
      "Predicting 3134\n",
      "Predicting 3135\n",
      "Predicting 3136\n",
      "Predicting 3137\n",
      "Predicting 3138\n",
      "Predicting 3139\n",
      "Predicting 3140\n",
      "Predicting 3141\n",
      "Predicting 3142\n",
      "Predicting 3143\n",
      "Predicting 3144\n",
      "Predicting 3145\n",
      "Predicting 3146\n",
      "Predicting 3147\n",
      "Predicting 3148\n",
      "Predicting 3149\n",
      "Predicting 3150\n",
      "Predicting 3151\n",
      "Predicting 3152\n",
      "Predicting 3153\n",
      "Predicting 3154\n",
      "Predicting 3155\n",
      "Predicting 3156\n",
      "Predicting 3157\n",
      "Predicting 3158\n",
      "Predicting 3159\n",
      "Predicting 3160\n",
      "Predicting 3161\n",
      "Predicting 3162\n",
      "Predicting 3163\n",
      "Predicting 3164\n",
      "Predicting 3165\n",
      "Predicting 3166\n",
      "Predicting 3167\n",
      "Predicting 3168\n",
      "Predicting 3169\n",
      "Predicting 3170\n",
      "Predicting 3171\n",
      "Predicting 3172\n",
      "Predicting 3173\n",
      "Predicting 3174\n",
      "Predicting 3175\n",
      "Predicting 3176\n",
      "Predicting 3177\n",
      "Predicting 3178\n",
      "Predicting 3179\n",
      "Predicting 3180\n",
      "Predicting 3181\n",
      "Predicting 3182\n",
      "Predicting 3183\n",
      "Predicting 3184\n",
      "Predicting 3185\n",
      "Predicting 3186\n",
      "Predicting 3187\n",
      "Predicting 3188\n",
      "Predicting 3189\n",
      "Predicting 3190\n",
      "Predicting 3191\n",
      "Predicting 3192\n",
      "Predicting 3193\n",
      "Predicting 3194\n",
      "Predicting 3195\n",
      "Predicting 3196\n",
      "Predicting 3197\n",
      "Predicting 3198\n",
      "Predicting 3199\n",
      "Predicting 3200\n",
      "Predicting 3201\n",
      "Predicting 3202\n",
      "Predicting 3203\n",
      "Predicting 3204\n",
      "Predicting 3205\n",
      "Predicting 3206\n",
      "Predicting 3207\n",
      "Predicting 3208\n",
      "Predicting 3209\n",
      "Predicting 3210\n",
      "Predicting 3211\n",
      "Predicting 3212\n",
      "Predicting 3213\n",
      "Predicting 3214\n",
      "Predicting 3215\n",
      "Predicting 3216\n",
      "Predicting 3217\n",
      "Predicting 3218\n",
      "Predicting 3219\n",
      "Predicting 3220\n",
      "Predicting 3221\n",
      "Predicting 3222\n",
      "Predicting 3223\n",
      "Predicting 3224\n",
      "Predicting 3225\n",
      "Predicting 3226\n",
      "Predicting 3227\n",
      "Predicting 3228\n",
      "Predicting 3229\n",
      "Predicting 3230\n",
      "Predicting 3231\n",
      "Predicting 3232\n",
      "Predicting 3233\n",
      "Predicting 3234\n",
      "Predicting 3235\n",
      "Predicting 3236\n",
      "Predicting 3237\n",
      "Predicting 3238\n",
      "Predicting 3239\n",
      "Predicting 3240\n",
      "Predicting 3241\n",
      "Predicting 3242\n",
      "Predicting 3243\n",
      "Predicting 3244\n",
      "Predicting 3245\n",
      "Predicting 3246\n",
      "Predicting 3247\n",
      "Predicting 3248\n",
      "Predicting 3249\n",
      "Predicting 3250\n",
      "Predicting 3251\n",
      "Predicting 3252\n",
      "Predicting 3253\n",
      "Predicting 3254\n",
      "Predicting 3255\n",
      "Predicting 3256\n",
      "Predicting 3257\n",
      "Predicting 3258\n",
      "Predicting 3259\n",
      "Predicting 3260\n",
      "Predicting 3261\n",
      "Predicting 3262\n",
      "Predicting 3263\n",
      "Predicting 3264\n",
      "Predicting 3265\n",
      "Predicting 3266\n",
      "Predicting 3267\n",
      "Predicting 3268\n",
      "Predicting 3269\n",
      "Predicting 3270\n",
      "Predicting 3271\n",
      "Predicting 3272\n",
      "Predicting 3273\n",
      "Predicting 3274\n",
      "Predicting 3275\n",
      "Predicting 3276\n",
      "Predicting 3277\n",
      "Predicting 3278\n",
      "Predicting 3279\n",
      "Predicting 3280\n",
      "Predicting 3281\n",
      "Predicting 3282\n",
      "Predicting 3283\n",
      "Predicting 3284\n",
      "Predicting 3285\n",
      "Predicting 3286\n",
      "Predicting 3287\n",
      "Predicting 3288\n",
      "Predicting 3289\n",
      "Predicting 3290\n",
      "Predicting 3291\n",
      "Predicting 3292\n",
      "Predicting 3293\n",
      "Predicting 3294\n",
      "Predicting 3295\n",
      "Predicting 3296\n",
      "Predicting 3297\n",
      "Predicting 3298\n",
      "Predicting 3299\n",
      "Predicting 3300\n",
      "Predicting 3301\n",
      "Predicting 3302\n",
      "Predicting 3303\n",
      "Predicting 3304\n",
      "Predicting 3305\n",
      "Predicting 3306\n",
      "Predicting 3307\n",
      "Predicting 3308\n",
      "Predicting 3309\n",
      "Predicting 3310\n",
      "Predicting 3311\n",
      "Predicting 3312\n",
      "Predicting 3313\n",
      "Predicting 3314\n",
      "Predicting 3315\n",
      "Predicting 3316\n",
      "Predicting 3317\n",
      "Predicting 3318\n",
      "Predicting 3319\n",
      "Predicting 3320\n",
      "Predicting 3321\n",
      "Predicting 3322\n",
      "Predicting 3323\n",
      "Predicting 3324\n",
      "Predicting 3325\n",
      "Predicting 3326\n",
      "Predicting 3327\n",
      "Predicting 3328\n",
      "Predicting 3329\n",
      "Predicting 3330\n",
      "Predicting 3331\n",
      "Predicting 3332\n",
      "Predicting 3333\n",
      "Predicting 3334\n",
      "Predicting 3335\n",
      "Predicting 3336\n",
      "Predicting 3337\n",
      "Predicting 3338\n",
      "Predicting 3339\n",
      "Predicting 3340\n",
      "Predicting 3341\n",
      "Predicting 3342\n",
      "Predicting 3343\n",
      "Predicting 3344\n",
      "Predicting 3345\n",
      "Predicting 3346\n",
      "Predicting 3347\n",
      "Predicting 3348\n",
      "Predicting 3349\n",
      "Predicting 3350\n",
      "Predicting 3351\n",
      "Predicting 3352\n",
      "Predicting 3353\n",
      "Predicting 3354\n",
      "Predicting 3355\n",
      "Predicting 3356\n",
      "Predicting 3357\n",
      "Predicting 3358\n",
      "Predicting 3359\n",
      "Predicting 3360\n",
      "Predicting 3361\n",
      "Predicting 3362\n",
      "Predicting 3363\n",
      "Predicting 3364\n",
      "Predicting 3365\n",
      "Predicting 3366\n",
      "Predicting 3367\n",
      "Predicting 3368\n",
      "Predicting 3369\n",
      "Predicting 3370\n",
      "Predicting 3371\n",
      "Predicting 3372\n",
      "Predicting 3373\n",
      "Predicting 3374\n",
      "Predicting 3375\n",
      "Predicting 3376\n",
      "Predicting 3377\n",
      "Predicting 3378\n",
      "Predicting 3379\n",
      "Predicting 3380\n",
      "Predicting 3381\n",
      "Predicting 3382\n",
      "Predicting 3383\n",
      "Predicting 3384\n",
      "Predicting 3385\n",
      "Predicting 3386\n",
      "Predicting 3387\n",
      "Predicting 3388\n",
      "Predicting 3389\n",
      "Predicting 3390\n",
      "Predicting 3391\n",
      "Predicting 3392\n",
      "Predicting 3393\n",
      "Predicting 3394\n",
      "Predicting 3395\n",
      "Predicting 3396\n",
      "Predicting 3397\n",
      "Predicting 3398\n",
      "Predicting 3399\n",
      "Predicting 3400\n",
      "Predicting 3401\n",
      "Predicting 3402\n",
      "Predicting 3403\n",
      "Predicting 3404\n",
      "Predicting 3405\n",
      "Predicting 3406\n",
      "Predicting 3407\n",
      "Predicting 3408\n",
      "Predicting 3409\n",
      "Predicting 3410\n",
      "Predicting 3411\n",
      "Predicting 3412\n",
      "Predicting 3413\n",
      "Predicting 3414\n",
      "Predicting 3415\n",
      "Predicting 3416\n",
      "Predicting 3417\n",
      "Predicting 3418\n",
      "Predicting 3419\n",
      "Predicting 3420\n",
      "Predicting 3421\n",
      "Predicting 3422\n",
      "Predicting 3423\n",
      "Predicting 3424\n",
      "Predicting 3425\n",
      "Predicting 3426\n",
      "Predicting 3427\n",
      "Predicting 3428\n",
      "Predicting 3429\n",
      "Predicting 3430\n",
      "Predicting 3431\n",
      "Predicting 3432\n",
      "Predicting 3433\n",
      "Predicting 3434\n",
      "Predicting 3435\n",
      "Predicting 3436\n",
      "Predicting 3437\n",
      "Predicting 3438\n",
      "Predicting 3439\n",
      "Predicting 3440\n",
      "Predicting 3441\n",
      "Predicting 3442\n",
      "Predicting 3443\n",
      "Predicting 3444\n",
      "Predicting 3445\n",
      "Predicting 3446\n",
      "Predicting 3447\n",
      "Predicting 3448\n",
      "Predicting 3449\n",
      "Predicting 3450\n",
      "Predicting 3451\n",
      "Predicting 3452\n",
      "Predicting 3453\n",
      "Predicting 3454\n",
      "Predicting 3455\n",
      "Predicting 3456\n",
      "Predicting 3457\n",
      "Predicting 3458\n",
      "Predicting 3459\n",
      "Predicting 3460\n",
      "Predicting 3461\n",
      "Predicting 3462\n",
      "Predicting 3463\n",
      "Predicting 3464\n",
      "Predicting 3465\n",
      "Predicting 3466\n",
      "Predicting 3467\n",
      "Predicting 3468\n",
      "Predicting 3469\n",
      "Predicting 3470\n",
      "Predicting 3471\n",
      "Predicting 3472\n",
      "Predicting 3473\n",
      "Predicting 3474\n",
      "Predicting 3475\n",
      "Predicting 3476\n",
      "Predicting 3477\n",
      "Predicting 3478\n",
      "Predicting 3479\n",
      "Predicting 3480\n",
      "Predicting 3481\n",
      "Predicting 3482\n",
      "Predicting 3483\n",
      "Predicting 3484\n",
      "Predicting 3485\n",
      "Predicting 3486\n",
      "Predicting 3487\n",
      "Predicting 3488\n",
      "Predicting 3489\n",
      "Predicting 3490\n",
      "Predicting 3491\n",
      "Predicting 3492\n",
      "Predicting 3493\n",
      "Predicting 3494\n",
      "Predicting 3495\n",
      "Predicting 3496\n",
      "Predicting 3497\n",
      "Predicting 3498\n",
      "Predicting 3499\n",
      "Predicting 3500\n",
      "Predicting 3501\n",
      "Predicting 3502\n",
      "Predicting 3503\n",
      "Predicting 3504\n",
      "Predicting 3505\n",
      "Predicting 3506\n",
      "Predicting 3507\n",
      "Predicting 3508\n",
      "Predicting 3509\n",
      "Predicting 3510\n",
      "Predicting 3511\n",
      "Predicting 3512\n",
      "Predicting 3513\n",
      "Predicting 3514\n",
      "Predicting 3515\n",
      "Predicting 3516\n",
      "Predicting 3517\n",
      "Predicting 3518\n",
      "Predicting 3519\n",
      "Predicting 3520\n",
      "Predicting 3521\n",
      "Predicting 3522\n",
      "Predicting 3523\n",
      "Predicting 3524\n",
      "Predicting 3525\n",
      "Predicting 3526\n",
      "Predicting 3527\n",
      "Predicting 3528\n",
      "Predicting 3529\n",
      "Predicting 3530\n",
      "Predicting 3531\n",
      "Predicting 3532\n",
      "Predicting 3533\n",
      "Predicting 3534\n",
      "Predicting 3535\n",
      "Predicting 3536\n",
      "Predicting 3537\n",
      "Predicting 3538\n",
      "Predicting 3539\n",
      "Predicting 3540\n",
      "Predicting 3541\n",
      "Predicting 3542\n",
      "Predicting 3543\n",
      "Predicting 3544\n",
      "Predicting 3545\n",
      "Predicting 3546\n",
      "Predicting 3547\n",
      "Predicting 3548\n",
      "Predicting 3549\n",
      "Predicting 3550\n",
      "Predicting 3551\n",
      "Predicting 3552\n",
      "Predicting 3553\n",
      "Predicting 3554\n",
      "Predicting 3555\n",
      "Predicting 3556\n",
      "Predicting 3557\n",
      "Predicting 3558\n",
      "Predicting 3559\n",
      "Predicting 3560\n",
      "Predicting 3561\n",
      "Predicting 3562\n",
      "Predicting 3563\n",
      "Predicting 3564\n",
      "Predicting 3565\n",
      "Predicting 3566\n",
      "Predicting 3567\n",
      "Predicting 3568\n",
      "Predicting 3569\n",
      "Predicting 3570\n",
      "Predicting 3571\n",
      "Predicting 3572\n",
      "Predicting 3573\n",
      "Predicting 3574\n",
      "Predicting 3575\n",
      "Predicting 3576\n",
      "Predicting 3577\n",
      "Predicting 3578\n",
      "Predicting 3579\n",
      "Predicting 3580\n",
      "Predicting 3581\n",
      "Predicting 3582\n",
      "Predicting 3583\n",
      "Predicting 3584\n",
      "Predicting 3585\n",
      "Predicting 3586\n",
      "Predicting 3587\n",
      "Predicting 3588\n",
      "Predicting 3589\n",
      "Predicting 3590\n",
      "Predicting 3591\n",
      "Predicting 3592\n",
      "Predicting 3593\n",
      "Predicting 3594\n",
      "Predicting 3595\n",
      "Predicting 3596\n",
      "Predicting 3597\n",
      "Predicting 3598\n",
      "Predicting 3599\n",
      "Predicting 3600\n",
      "Predicting 3601\n",
      "Predicting 3602\n",
      "Predicting 3603\n",
      "Predicting 3604\n",
      "Predicting 3605\n",
      "Predicting 3606\n",
      "Predicting 3607\n",
      "Predicting 3608\n",
      "Predicting 3609\n",
      "Predicting 3610\n",
      "Predicting 3611\n",
      "Predicting 3612\n",
      "Predicting 3613\n",
      "Predicting 3614\n",
      "Predicting 3615\n",
      "Predicting 3616\n",
      "Predicting 3617\n",
      "Predicting 3618\n",
      "Predicting 3619\n",
      "Predicting 3620\n",
      "Predicting 3621\n",
      "Predicting 3622\n",
      "Predicting 3623\n",
      "Predicting 3624\n",
      "Predicting 3625\n",
      "Predicting 3626\n",
      "Predicting 3627\n",
      "Predicting 3628\n",
      "Predicting 3629\n",
      "Predicting 3630\n",
      "Predicting 3631\n",
      "Predicting 3632\n",
      "Predicting 3633\n",
      "Predicting 3634\n",
      "Predicting 3635\n",
      "Predicting 3636\n",
      "Predicting 3637\n",
      "Predicting 3638\n",
      "Predicting 3639\n",
      "Predicting 3640\n",
      "Predicting 3641\n",
      "Predicting 3642\n",
      "Predicting 3643\n",
      "Predicting 3644\n",
      "Predicting 3645\n",
      "Predicting 3646\n",
      "Predicting 3647\n",
      "Predicting 3648\n",
      "Predicting 3649\n",
      "Predicting 3650\n",
      "Predicting 3651\n",
      "Predicting 3652\n",
      "Predicting 3653\n",
      "Predicting 3654\n",
      "Predicting 3655\n",
      "Predicting 3656\n",
      "Predicting 3657\n",
      "Predicting 3658\n",
      "Predicting 3659\n",
      "Predicting 3660\n",
      "Predicting 3661\n",
      "Predicting 3662\n",
      "Predicting 3663\n",
      "Predicting 3664\n",
      "Predicting 3665\n",
      "Predicting 3666\n",
      "Predicting 3667\n",
      "Predicting 3668\n",
      "Predicting 3669\n",
      "Predicting 3670\n",
      "Predicting 3671\n",
      "Predicting 3672\n",
      "Predicting 3673\n",
      "Predicting 3674\n",
      "Predicting 3675\n",
      "Predicting 3676\n",
      "Predicting 3677\n",
      "Predicting 3678\n",
      "Predicting 3679\n",
      "Predicting 3680\n",
      "Predicting 3681\n",
      "Predicting 3682\n",
      "Predicting 3683\n",
      "Predicting 3684\n",
      "Predicting 3685\n",
      "Predicting 3686\n",
      "Predicting 3687\n",
      "Predicting 3688\n",
      "Predicting 3689\n",
      "Predicting 3690\n",
      "Predicting 3691\n",
      "Predicting 3692\n",
      "Predicting 3693\n",
      "Predicting 3694\n",
      "Predicting 3695\n",
      "Predicting 3696\n",
      "Predicting 3697\n",
      "Predicting 3698\n",
      "Predicting 3699\n",
      "Predicting 3700\n",
      "Predicting 3701\n",
      "Predicting 3702\n",
      "Predicting 3703\n",
      "Predicting 3704\n",
      "Predicting 3705\n",
      "Predicting 3706\n",
      "Predicting 3707\n",
      "Predicting 3708\n",
      "Predicting 3709\n",
      "Predicting 3710\n",
      "Predicting 3711\n",
      "Predicting 3712\n",
      "Predicting 3713\n",
      "Predicting 3714\n",
      "Predicting 3715\n",
      "Predicting 3716\n",
      "Predicting 3717\n",
      "Predicting 3718\n",
      "Predicting 3719\n",
      "Predicting 3720\n",
      "Predicting 3721\n",
      "Predicting 3722\n",
      "Predicting 3723\n",
      "Predicting 3724\n",
      "Predicting 3725\n",
      "Predicting 3726\n",
      "Predicting 3727\n",
      "Predicting 3728\n",
      "Predicting 3729\n",
      "Predicting 3730\n",
      "Predicting 3731\n",
      "Predicting 3732\n",
      "Predicting 3733\n",
      "Predicting 3734\n",
      "Predicting 3735\n",
      "Predicting 3736\n",
      "Predicting 3737\n",
      "Predicting 3738\n",
      "Predicting 3739\n",
      "Predicting 3740\n",
      "Predicting 3741\n",
      "Predicting 3742\n",
      "Predicting 3743\n",
      "Predicting 3744\n",
      "Predicting 3745\n",
      "Predicting 3746\n",
      "Predicting 3747\n",
      "Predicting 3748\n",
      "Predicting 3749\n",
      "Predicting 3750\n",
      "Predicting 3751\n",
      "Predicting 3752\n",
      "Predicting 3753\n",
      "Predicting 3754\n",
      "Predicting 3755\n",
      "Predicting 3756\n",
      "Predicting 3757\n",
      "Predicting 3758\n",
      "Predicting 3759\n",
      "Predicting 3760\n",
      "Predicting 3761\n",
      "Predicting 3762\n",
      "Predicting 3763\n",
      "Predicting 3764\n",
      "Predicting 3765\n",
      "Predicting 3766\n",
      "Predicting 3767\n",
      "Predicting 3768\n",
      "Predicting 3769\n",
      "Predicting 3770\n",
      "Predicting 3771\n",
      "Predicting 3772\n",
      "Predicting 3773\n",
      "Predicting 3774\n",
      "Predicting 3775\n",
      "Predicting 3776\n",
      "Predicting 3777\n",
      "Predicting 3778\n",
      "Predicting 3779\n",
      "Predicting 3780\n",
      "Predicting 3781\n",
      "Predicting 3782\n",
      "Predicting 3783\n",
      "Predicting 3784\n",
      "Predicting 3785\n",
      "Predicting 3786\n",
      "Predicting 3787\n",
      "Predicting 3788\n",
      "Predicting 3789\n",
      "Predicting 3790\n",
      "Predicting 3791\n",
      "Predicting 3792\n",
      "Predicting 3793\n",
      "Predicting 3794\n",
      "Predicting 3795\n",
      "Predicting 3796\n",
      "Predicting 3797\n",
      "Predicting 3798\n",
      "Predicting 3799\n",
      "Predicting 3800\n",
      "Predicting 3801\n",
      "Predicting 3802\n",
      "Predicting 3803\n",
      "Predicting 3804\n",
      "Predicting 3805\n",
      "Predicting 3806\n",
      "Predicting 3807\n",
      "Predicting 3808\n",
      "Predicting 3809\n",
      "Predicting 3810\n",
      "Predicting 3811\n",
      "Predicting 3812\n",
      "Predicting 3813\n",
      "Predicting 3814\n",
      "Predicting 3815\n",
      "Predicting 3816\n",
      "Predicting 3817\n",
      "Predicting 3818\n",
      "Predicting 3819\n",
      "Predicting 3820\n",
      "Predicting 3821\n",
      "Predicting 3822\n",
      "Predicting 3823\n",
      "Predicting 3824\n",
      "Predicting 3825\n",
      "Predicting 3826\n",
      "Predicting 3827\n",
      "Predicting 3828\n",
      "Predicting 3829\n",
      "Predicting 3830\n",
      "Predicting 3831\n",
      "Predicting 3832\n",
      "Predicting 3833\n",
      "Predicting 3834\n",
      "Predicting 3835\n",
      "Predicting 3836\n",
      "Predicting 3837\n",
      "Predicting 3838\n",
      "Predicting 3839\n",
      "Predicting 3840\n",
      "Predicting 3841\n",
      "Predicting 3842\n",
      "Predicting 3843\n",
      "Predicting 3844\n",
      "Predicting 3845\n",
      "Predicting 3846\n",
      "Predicting 3847\n",
      "Predicting 3848\n",
      "Predicting 3849\n",
      "Predicting 3850\n",
      "Predicting 3851\n",
      "Predicting 3852\n",
      "Predicting 3853\n",
      "Predicting 3854\n",
      "Predicting 3855\n",
      "Predicting 3856\n",
      "Predicting 3857\n",
      "Predicting 3858\n",
      "Predicting 3859\n",
      "Predicting 3860\n",
      "Predicting 3861\n",
      "Predicting 3862\n",
      "Predicting 3863\n",
      "Predicting 3864\n",
      "Predicting 3865\n",
      "Predicting 3866\n",
      "Predicting 3867\n",
      "Predicting 3868\n",
      "Predicting 3869\n",
      "Predicting 3870\n",
      "Predicting 3871\n",
      "Predicting 3872\n",
      "Predicting 3873\n",
      "Predicting 3874\n",
      "Predicting 3875\n",
      "Predicting 3876\n",
      "Predicting 3877\n",
      "Predicting 3878\n",
      "Predicting 3879\n",
      "Predicting 3880\n",
      "Predicting 3881\n",
      "Predicting 3882\n",
      "Predicting 3883\n",
      "Predicting 3884\n",
      "Predicting 3885\n",
      "Predicting 3886\n",
      "Predicting 3887\n",
      "Predicting 3888\n",
      "Predicting 3889\n",
      "Predicting 3890\n",
      "Predicting 3891\n",
      "Predicting 3892\n",
      "Predicting 3893\n",
      "Predicting 3894\n",
      "Predicting 3895\n",
      "Predicting 3896\n",
      "Predicting 3897\n",
      "Predicting 3898\n",
      "Predicting 3899\n",
      "Predicting 3900\n",
      "Predicting 3901\n",
      "Predicting 3902\n",
      "Predicting 3903\n",
      "Predicting 3904\n",
      "Predicting 3905\n",
      "Predicting 3906\n",
      "Predicting 3907\n",
      "Predicting 3908\n",
      "Predicting 3909\n",
      "Predicting 3910\n",
      "Predicting 3911\n",
      "Predicting 3912\n",
      "Predicting 3913\n",
      "Predicting 3914\n",
      "Predicting 3915\n",
      "Predicting 3916\n",
      "Predicting 3917\n",
      "Predicting 3918\n",
      "Predicting 3919\n",
      "Predicting 3920\n",
      "Predicting 3921\n",
      "Predicting 3922\n",
      "Predicting 3923\n",
      "Predicting 3924\n",
      "Predicting 3925\n",
      "Predicting 3926\n",
      "Predicting 3927\n",
      "Predicting 3928\n",
      "Predicting 3929\n",
      "Predicting 3930\n",
      "Predicting 3931\n",
      "Predicting 3932\n",
      "Predicting 3933\n",
      "Predicting 3934\n",
      "Predicting 3935\n",
      "Predicting 3936\n",
      "Predicting 3937\n",
      "Predicting 3938\n",
      "Predicting 3939\n",
      "Predicting 3940\n",
      "Predicting 3941\n",
      "Predicting 3942\n",
      "Predicting 3943\n",
      "Predicting 3944\n",
      "Predicting 3945\n",
      "Predicting 3946\n",
      "Predicting 3947\n",
      "Predicting 3948\n",
      "Predicting 3949\n",
      "Predicting 3950\n",
      "Predicting 3951\n",
      "Predicting 3952\n",
      "Predicting 3953\n",
      "Predicting 3954\n",
      "Predicting 3955\n",
      "Predicting 3956\n",
      "Predicting 3957\n",
      "Predicting 3958\n",
      "Predicting 3959\n",
      "Predicting 3960\n",
      "Predicting 3961\n",
      "Predicting 3962\n",
      "Predicting 3963\n",
      "Predicting 3964\n",
      "Predicting 3965\n",
      "Predicting 3966\n",
      "Predicting 3967\n",
      "Predicting 3968\n",
      "Predicting 3969\n",
      "Predicting 3970\n",
      "Predicting 3971\n",
      "Predicting 3972\n",
      "Predicting 3973\n",
      "Predicting 3974\n",
      "Predicting 3975\n",
      "Predicting 3976\n",
      "Predicting 3977\n",
      "Predicting 3978\n",
      "Predicting 3979\n",
      "Predicting 3980\n",
      "Predicting 3981\n",
      "Predicting 3982\n",
      "Predicting 3983\n",
      "Predicting 3984\n",
      "Predicting 3985\n",
      "Predicting 3986\n",
      "Predicting 3987\n",
      "Predicting 3988\n",
      "Predicting 3989\n",
      "Predicting 3990\n",
      "Predicting 3991\n",
      "Predicting 3992\n",
      "Predicting 3993\n",
      "Predicting 3994\n",
      "Predicting 3995\n",
      "Predicting 3996\n",
      "Predicting 3997\n",
      "Predicting 3998\n",
      "Predicting 3999\n",
      "Predicting 4000\n",
      "Predicting 4001\n",
      "Predicting 4002\n",
      "Predicting 4003\n",
      "Predicting 4004\n",
      "Predicting 4005\n",
      "Predicting 4006\n",
      "Predicting 4007\n",
      "Predicting 4008\n",
      "Predicting 4009\n",
      "Predicting 4010\n",
      "Predicting 4011\n",
      "Predicting 4012\n",
      "Predicting 4013\n",
      "Predicting 4014\n",
      "Predicting 4015\n",
      "Predicting 4016\n",
      "Predicting 4017\n",
      "Predicting 4018\n",
      "Predicting 4019\n",
      "Predicting 4020\n",
      "Predicting 4021\n",
      "Predicting 4022\n",
      "Predicting 4023\n",
      "Predicting 4024\n",
      "Predicting 4025\n",
      "Predicting 4026\n",
      "Predicting 4027\n",
      "Predicting 4028\n",
      "Predicting 4029\n",
      "Predicting 4030\n",
      "Predicting 4031\n",
      "Predicting 4032\n",
      "Predicting 4033\n",
      "Predicting 4034\n",
      "Predicting 4035\n",
      "Predicting 4036\n",
      "Predicting 4037\n",
      "Predicting 4038\n",
      "Predicting 4039\n",
      "Predicting 4040\n",
      "Predicting 4041\n",
      "Predicting 4042\n",
      "Predicting 4043\n",
      "Predicting 4044\n",
      "Predicting 4045\n",
      "Predicting 4046\n",
      "Predicting 4047\n",
      "Predicting 4048\n",
      "Predicting 4049\n",
      "Predicting 4050\n",
      "Predicting 4051\n",
      "Predicting 4052\n",
      "Predicting 4053\n",
      "Predicting 4054\n",
      "Predicting 4055\n",
      "Predicting 4056\n",
      "Predicting 4057\n",
      "Predicting 4058\n",
      "Predicting 4059\n",
      "Predicting 4060\n",
      "Predicting 4061\n",
      "Predicting 4062\n",
      "Predicting 4063\n",
      "Predicting 4064\n",
      "Predicting 4065\n",
      "Predicting 4066\n",
      "Predicting 4067\n",
      "Predicting 4068\n",
      "Predicting 4069\n",
      "Predicting 4070\n",
      "Predicting 4071\n",
      "Predicting 4072\n",
      "Predicting 4073\n",
      "Predicting 4074\n",
      "Predicting 4075\n",
      "Predicting 4076\n",
      "Predicting 4077\n",
      "Predicting 4078\n",
      "Predicting 4079\n",
      "Predicting 4080\n",
      "Predicting 4081\n",
      "Predicting 4082\n",
      "Predicting 4083\n",
      "Predicting 4084\n",
      "Predicting 4085\n",
      "Predicting 4086\n",
      "Predicting 4087\n",
      "Predicting 4088\n",
      "Predicting 4089\n",
      "Predicting 4090\n",
      "Predicting 4091\n",
      "Predicting 4092\n",
      "Predicting 4093\n",
      "Predicting 4094\n",
      "Predicting 4095\n",
      "Predicting 4096\n",
      "Predicting 4097\n",
      "Predicting 4098\n",
      "Predicting 4099\n",
      "Predicting 4100\n",
      "Predicting 4101\n",
      "Predicting 4102\n",
      "Predicting 4103\n",
      "Predicting 4104\n",
      "Predicting 4105\n",
      "Predicting 4106\n",
      "Predicting 4107\n",
      "Predicting 4108\n",
      "Predicting 4109\n",
      "Predicting 4110\n",
      "Predicting 4111\n",
      "Predicting 4112\n",
      "Predicting 4113\n",
      "Predicting 4114\n",
      "Predicting 4115\n",
      "Predicting 4116\n",
      "Predicting 4117\n",
      "Predicting 4118\n",
      "Predicting 4119\n",
      "Predicting 4120\n",
      "Predicting 4121\n",
      "Predicting 4122\n",
      "Predicting 4123\n",
      "Predicting 4124\n",
      "Predicting 4125\n",
      "Predicting 4126\n",
      "Predicting 4127\n",
      "Predicting 4128\n",
      "Predicting 4129\n",
      "Predicting 4130\n",
      "Predicting 4131\n",
      "Predicting 4132\n",
      "Predicting 4133\n",
      "Predicting 4134\n",
      "Predicting 4135\n",
      "Predicting 4136\n",
      "Predicting 4137\n",
      "Predicting 4138\n",
      "Predicting 4139\n",
      "Predicting 4140\n",
      "Predicting 4141\n",
      "Predicting 4142\n",
      "Predicting 4143\n",
      "Predicting 4144\n",
      "Predicting 4145\n",
      "Predicting 4146\n",
      "Predicting 4147\n",
      "Predicting 4148\n",
      "Predicting 4149\n",
      "Predicting 4150\n",
      "Predicting 4151\n",
      "Predicting 4152\n",
      "Predicting 4153\n",
      "Predicting 4154\n",
      "Predicting 4155\n",
      "Predicting 4156\n",
      "Predicting 4157\n",
      "Predicting 4158\n",
      "Predicting 4159\n",
      "Predicting 4160\n",
      "Predicting 4161\n",
      "Predicting 4162\n",
      "Predicting 4163\n",
      "Predicting 4164\n",
      "Predicting 4165\n",
      "Predicting 4166\n",
      "Predicting 4167\n",
      "Predicting 4168\n",
      "Predicting 4169\n",
      "Predicting 4170\n",
      "Predicting 4171\n",
      "Predicting 4172\n",
      "Predicting 4173\n",
      "Predicting 4174\n",
      "Predicting 4175\n",
      "Predicting 4176\n",
      "Predicting 4177\n",
      "Predicting 4178\n",
      "Predicting 4179\n",
      "Predicting 4180\n",
      "Predicting 4181\n",
      "Predicting 4182\n",
      "Predicting 4183\n",
      "Predicting 4184\n",
      "Predicting 4185\n",
      "Predicting 4186\n",
      "Predicting 4187\n",
      "Predicting 4188\n",
      "Predicting 4189\n",
      "Predicting 4190\n",
      "Predicting 4191\n",
      "Predicting 4192\n",
      "Predicting 4193\n",
      "Predicting 4194\n",
      "Predicting 4195\n",
      "Predicting 4196\n",
      "Predicting 4197\n",
      "Predicting 4198\n",
      "Predicting 4199\n",
      "Predicting 4200\n",
      "Predicting 4201\n",
      "Predicting 4202\n",
      "Predicting 4203\n",
      "Predicting 4204\n",
      "Predicting 4205\n",
      "Predicting 4206\n",
      "Predicting 4207\n",
      "Predicting 4208\n",
      "Predicting 4209\n",
      "Predicting 4210\n",
      "Predicting 4211\n",
      "Predicting 4212\n",
      "Predicting 4213\n",
      "Predicting 4214\n",
      "Predicting 4215\n",
      "Predicting 4216\n",
      "Predicting 4217\n",
      "Predicting 4218\n",
      "Predicting 4219\n",
      "Predicting 4220\n",
      "Predicting 4221\n",
      "Predicting 4222\n",
      "Predicting 4223\n",
      "Predicting 4224\n",
      "Predicting 4225\n",
      "Predicting 4226\n",
      "Predicting 4227\n",
      "Predicting 4228\n",
      "Predicting 4229\n",
      "Predicting 4230\n",
      "Predicting 4231\n",
      "Predicting 4232\n",
      "Predicting 4233\n",
      "Predicting 4234\n",
      "Predicting 4235\n",
      "Predicting 4236\n",
      "Predicting 4237\n",
      "Predicting 4238\n",
      "Predicting 4239\n",
      "Predicting 4240\n",
      "Predicting 4241\n",
      "Predicting 4242\n",
      "Predicting 4243\n",
      "Predicting 4244\n",
      "Predicting 4245\n",
      "Predicting 4246\n",
      "Predicting 4247\n",
      "Predicting 4248\n",
      "Predicting 4249\n",
      "Predicting 4250\n",
      "Predicting 4251\n",
      "Predicting 4252\n",
      "Predicting 4253\n",
      "Predicting 4254\n",
      "Predicting 4255\n",
      "Predicting 4256\n",
      "Predicting 4257\n",
      "Predicting 4258\n",
      "Predicting 4259\n",
      "Predicting 4260\n",
      "Predicting 4261\n",
      "Predicting 4262\n",
      "Predicting 4263\n",
      "Predicting 4264\n",
      "Predicting 4265\n",
      "Predicting 4266\n",
      "Predicting 4267\n",
      "Predicting 4268\n",
      "Predicting 4269\n",
      "Predicting 4270\n",
      "Predicting 4271\n",
      "Predicting 4272\n",
      "Predicting 4273\n",
      "Predicting 4274\n",
      "Predicting 4275\n",
      "Predicting 4276\n",
      "Predicting 4277\n",
      "Predicting 4278\n",
      "Predicting 4279\n",
      "Predicting 4280\n",
      "Predicting 4281\n",
      "Predicting 4282\n",
      "Predicting 4283\n",
      "Predicting 4284\n",
      "Predicting 4285\n",
      "Predicting 4286\n",
      "Predicting 4287\n",
      "Predicting 4288\n",
      "Predicting 4289\n",
      "Predicting 4290\n",
      "Predicting 4291\n",
      "Predicting 4292\n",
      "Predicting 4293\n",
      "Predicting 4294\n",
      "Predicting 4295\n",
      "Predicting 4296\n",
      "Predicting 4297\n",
      "Predicting 4298\n",
      "Predicting 4299\n",
      "Predicting 4300\n",
      "Predicting 4301\n",
      "Predicting 4302\n",
      "Predicting 4303\n",
      "Predicting 4304\n",
      "Predicting 4305\n",
      "Predicting 4306\n",
      "Predicting 4307\n",
      "Predicting 4308\n",
      "Predicting 4309\n",
      "Predicting 4310\n",
      "Predicting 4311\n",
      "Predicting 4312\n",
      "Predicting 4313\n",
      "Predicting 4314\n",
      "Predicting 4315\n",
      "Predicting 4316\n",
      "Predicting 4317\n",
      "Predicting 4318\n",
      "Predicting 4319\n",
      "Predicting 4320\n",
      "Predicting 4321\n",
      "Predicting 4322\n",
      "Predicting 4323\n",
      "Predicting 4324\n",
      "Predicting 4325\n",
      "Predicting 4326\n",
      "Predicting 4327\n",
      "Predicting 4328\n",
      "Predicting 4329\n",
      "Predicting 4330\n",
      "Predicting 4331\n",
      "Predicting 4332\n",
      "Predicting 4333\n",
      "Predicting 4334\n",
      "Predicting 4335\n",
      "Predicting 4336\n",
      "Predicting 4337\n",
      "Predicting 4338\n",
      "Predicting 4339\n",
      "Predicting 4340\n",
      "Predicting 4341\n",
      "Predicting 4342\n",
      "Predicting 4343\n",
      "Predicting 4344\n",
      "Predicting 4345\n",
      "Predicting 4346\n",
      "Predicting 4347\n",
      "Predicting 4348\n",
      "Predicting 4349\n",
      "Predicting 4350\n",
      "Predicting 4351\n",
      "Predicting 4352\n",
      "Predicting 4353\n",
      "Predicting 4354\n",
      "Predicting 4355\n",
      "Predicting 4356\n",
      "Predicting 4357\n",
      "Predicting 4358\n",
      "Predicting 4359\n",
      "Predicting 4360\n",
      "Predicting 4361\n",
      "Predicting 4362\n",
      "Predicting 4363\n",
      "Predicting 4364\n",
      "Predicting 4365\n",
      "Predicting 4366\n",
      "Predicting 4367\n",
      "Predicting 4368\n",
      "Predicting 4369\n",
      "Predicting 4370\n",
      "Predicting 4371\n",
      "Predicting 4372\n",
      "Predicting 4373\n",
      "Predicting 4374\n",
      "Predicting 4375\n",
      "Predicting 4376\n",
      "Predicting 4377\n",
      "Predicting 4378\n",
      "Predicting 4379\n",
      "Predicting 4380\n",
      "Predicting 4381\n",
      "Predicting 4382\n",
      "Predicting 4383\n",
      "Predicting 4384\n",
      "Predicting 4385\n",
      "Predicting 4386\n",
      "Predicting 4387\n",
      "Predicting 4388\n",
      "Predicting 4389\n",
      "Predicting 4390\n",
      "Predicting 4391\n",
      "Predicting 4392\n",
      "Predicting 4393\n",
      "Predicting 4394\n",
      "Predicting 4395\n",
      "Predicting 4396\n",
      "Predicting 4397\n",
      "Predicting 4398\n",
      "Predicting 4399\n",
      "Predicting 4400\n",
      "Predicting 4401\n",
      "Predicting 4402\n",
      "Predicting 4403\n",
      "Predicting 4404\n",
      "Predicting 4405\n",
      "Predicting 4406\n",
      "Predicting 4407\n",
      "Predicting 4408\n",
      "Predicting 4409\n",
      "Predicting 4410\n",
      "Predicting 4411\n",
      "Predicting 4412\n",
      "Predicting 4413\n",
      "Predicting 4414\n",
      "Predicting 4415\n",
      "Predicting 4416\n",
      "Predicting 4417\n",
      "Predicting 4418\n",
      "Predicting 4419\n",
      "Predicting 4420\n",
      "Predicting 4421\n",
      "Predicting 4422\n",
      "Predicting 4423\n",
      "Predicting 4424\n",
      "Predicting 4425\n",
      "Predicting 4426\n",
      "Predicting 4427\n",
      "Predicting 4428\n",
      "Predicting 4429\n",
      "Predicting 4430\n",
      "Predicting 4431\n",
      "Predicting 4432\n",
      "Predicting 4433\n",
      "Predicting 4434\n",
      "Predicting 4435\n",
      "Predicting 4436\n",
      "Predicting 4437\n",
      "Predicting 4438\n",
      "Predicting 4439\n",
      "Predicting 4440\n",
      "Predicting 4441\n",
      "Predicting 4442\n",
      "Predicting 4443\n",
      "Predicting 4444\n",
      "Predicting 4445\n",
      "Predicting 4446\n",
      "Predicting 4447\n",
      "Predicting 4448\n",
      "Predicting 4449\n",
      "Predicting 4450\n",
      "Predicting 4451\n",
      "Predicting 4452\n",
      "Predicting 4453\n",
      "Predicting 4454\n",
      "Predicting 4455\n",
      "Predicting 4456\n",
      "Predicting 4457\n",
      "Predicting 4458\n",
      "Predicting 4459\n",
      "Predicting 4460\n",
      "Predicting 4461\n",
      "Predicting 4462\n",
      "Predicting 4463\n",
      "Predicting 4464\n",
      "Predicting 4465\n",
      "Predicting 4466\n",
      "Predicting 4467\n",
      "Predicting 4468\n",
      "Predicting 4469\n",
      "Predicting 4470\n",
      "Predicting 4471\n",
      "Predicting 4472\n",
      "Predicting 4473\n",
      "Predicting 4474\n",
      "Predicting 4475\n",
      "Predicting 4476\n",
      "Predicting 4477\n",
      "Predicting 4478\n",
      "Predicting 4479\n",
      "Predicting 4480\n",
      "Predicting 4481\n",
      "Predicting 4482\n",
      "Predicting 4483\n",
      "Predicting 4484\n",
      "Predicting 4485\n",
      "Predicting 4486\n",
      "Predicting 4487\n",
      "Predicting 4488\n",
      "Predicting 4489\n",
      "Predicting 4490\n",
      "Predicting 4491\n",
      "Predicting 4492\n",
      "Predicting 4493\n",
      "Predicting 4494\n",
      "Predicting 4495\n",
      "Predicting 4496\n",
      "Predicting 4497\n",
      "Predicting 4498\n",
      "Predicting 4499\n",
      "Predicting 4500\n",
      "Predicting 4501\n",
      "Predicting 4502\n",
      "Predicting 4503\n",
      "Predicting 4504\n",
      "Predicting 4505\n",
      "Predicting 4506\n",
      "Predicting 4507\n",
      "Predicting 4508\n",
      "Predicting 4509\n",
      "Predicting 4510\n",
      "Predicting 4511\n",
      "Predicting 4512\n",
      "Predicting 4513\n",
      "Predicting 4514\n",
      "Predicting 4515\n",
      "Predicting 4516\n",
      "Predicting 4517\n",
      "Predicting 4518\n",
      "Predicting 4519\n",
      "Predicting 4520\n",
      "Predicting 4521\n",
      "Predicting 4522\n",
      "Predicting 4523\n",
      "Predicting 4524\n",
      "Predicting 4525\n",
      "Predicting 4526\n",
      "Predicting 4527\n",
      "Predicting 4528\n",
      "Predicting 4529\n",
      "Predicting 4530\n",
      "Predicting 4531\n",
      "Predicting 4532\n",
      "Predicting 4533\n",
      "Predicting 4534\n",
      "Predicting 4535\n",
      "Predicting 4536\n",
      "Predicting 4537\n",
      "Predicting 4538\n",
      "Predicting 4539\n",
      "Predicting 4540\n",
      "Predicting 4541\n",
      "Predicting 4542\n",
      "Predicting 4543\n",
      "Predicting 4544\n",
      "Predicting 4545\n",
      "Predicting 4546\n",
      "Predicting 4547\n",
      "Predicting 4548\n",
      "Predicting 4549\n",
      "Predicting 4550\n",
      "Predicting 4551\n",
      "Predicting 4552\n",
      "Predicting 4553\n",
      "Predicting 4554\n",
      "Predicting 4555\n",
      "Predicting 4556\n",
      "Predicting 4557\n",
      "Predicting 4558\n",
      "Predicting 4559\n",
      "Predicting 4560\n",
      "Predicting 4561\n",
      "Predicting 4562\n",
      "Predicting 4563\n",
      "Predicting 4564\n",
      "Predicting 4565\n",
      "Predicting 4566\n",
      "Predicting 4567\n",
      "Predicting 4568\n",
      "Predicting 4569\n",
      "Predicting 4570\n",
      "Predicting 4571\n",
      "Predicting 4572\n",
      "Predicting 4573\n",
      "Predicting 4574\n",
      "Predicting 4575\n",
      "Predicting 4576\n",
      "Predicting 4577\n",
      "Predicting 4578\n",
      "Predicting 4579\n",
      "Predicting 4580\n",
      "Predicting 4581\n",
      "Predicting 4582\n",
      "Predicting 4583\n",
      "Predicting 4584\n",
      "Predicting 4585\n",
      "Predicting 4586\n",
      "Predicting 4587\n",
      "Predicting 4588\n",
      "Predicting 4589\n",
      "Predicting 4590\n",
      "Predicting 4591\n",
      "Predicting 4592\n",
      "Predicting 4593\n",
      "Predicting 4594\n",
      "Predicting 4595\n",
      "Predicting 4596\n",
      "Predicting 4597\n",
      "Predicting 4598\n",
      "Predicting 4599\n",
      "Predicting 4600\n",
      "Predicting 4601\n",
      "Predicting 4602\n",
      "Predicting 4603\n",
      "Predicting 4604\n",
      "Predicting 4605\n",
      "Predicting 4606\n",
      "Predicting 4607\n",
      "Predicting 4608\n",
      "Predicting 4609\n",
      "Predicting 4610\n",
      "Predicting 4611\n",
      "Predicting 4612\n",
      "Predicting 4613\n",
      "Predicting 4614\n",
      "Predicting 4615\n",
      "Predicting 4616\n",
      "Predicting 4617\n",
      "Predicting 4618\n",
      "Predicting 4619\n",
      "Predicting 4620\n",
      "Predicting 4621\n",
      "Predicting 4622\n",
      "Predicting 4623\n",
      "Predicting 4624\n",
      "Predicting 4625\n",
      "Predicting 4626\n",
      "Predicting 4627\n",
      "Predicting 4628\n",
      "Predicting 4629\n",
      "Predicting 4630\n",
      "Predicting 4631\n",
      "Predicting 4632\n",
      "Predicting 4633\n",
      "Predicting 4634\n",
      "Predicting 4635\n",
      "Predicting 4636\n",
      "Predicting 4637\n",
      "Predicting 4638\n",
      "Predicting 4639\n",
      "Predicting 4640\n",
      "Predicting 4641\n",
      "Predicting 4642\n",
      "Predicting 4643\n",
      "Predicting 4644\n",
      "Predicting 4645\n",
      "Predicting 4646\n",
      "Predicting 4647\n",
      "Predicting 4648\n",
      "Predicting 4649\n",
      "Predicting 4650\n",
      "Predicting 4651\n",
      "Predicting 4652\n",
      "Predicting 4653\n",
      "Predicting 4654\n",
      "Predicting 4655\n",
      "Predicting 4656\n",
      "Predicting 4657\n",
      "Predicting 4658\n",
      "Predicting 4659\n",
      "Predicting 4660\n",
      "Predicting 4661\n",
      "Predicting 4662\n",
      "Predicting 4663\n",
      "Predicting 4664\n",
      "Predicting 4665\n",
      "Predicting 4666\n",
      "Predicting 4667\n",
      "Predicting 4668\n",
      "Predicting 4669\n",
      "Predicting 4670\n",
      "Predicting 4671\n",
      "Predicting 4672\n",
      "Predicting 4673\n",
      "Predicting 4674\n",
      "Predicting 4675\n",
      "Predicting 4676\n",
      "Predicting 4677\n",
      "Predicting 4678\n",
      "Predicting 4679\n",
      "Predicting 4680\n",
      "Predicting 4681\n",
      "Predicting 4682\n",
      "Predicting 4683\n",
      "Predicting 4684\n",
      "Predicting 4685\n",
      "Predicting 4686\n",
      "Predicting 4687\n",
      "Predicting 4688\n",
      "Predicting 4689\n",
      "Predicting 4690\n",
      "Predicting 4691\n",
      "Predicting 4692\n",
      "Predicting 4693\n",
      "Predicting 4694\n",
      "Predicting 4695\n",
      "Predicting 4696\n",
      "Predicting 4697\n",
      "Predicting 4698\n",
      "Predicting 4699\n",
      "Predicting 4700\n",
      "Predicting 4701\n",
      "Predicting 4702\n",
      "Predicting 4703\n",
      "Predicting 4704\n",
      "Predicting 4705\n",
      "Predicting 4706\n",
      "Predicting 4707\n",
      "Predicting 4708\n",
      "Predicting 4709\n",
      "Predicting 4710\n",
      "Predicting 4711\n",
      "Predicting 4712\n",
      "Predicting 4713\n",
      "Predicting 4714\n",
      "Predicting 4715\n",
      "Predicting 4716\n",
      "Predicting 4717\n",
      "Predicting 4718\n",
      "Predicting 4719\n",
      "Predicting 4720\n",
      "Predicting 4721\n",
      "Predicting 4722\n",
      "Predicting 4723\n",
      "Predicting 4724\n",
      "Predicting 4725\n",
      "Predicting 4726\n",
      "Predicting 4727\n",
      "Predicting 4728\n",
      "Predicting 4729\n",
      "Predicting 4730\n",
      "Predicting 4731\n",
      "Predicting 4732\n",
      "Predicting 4733\n",
      "Predicting 4734\n",
      "Predicting 4735\n",
      "Predicting 4736\n",
      "Predicting 4737\n",
      "Predicting 4738\n",
      "Predicting 4739\n",
      "Predicting 4740\n",
      "Predicting 4741\n",
      "Predicting 4742\n",
      "Predicting 4743\n",
      "Predicting 4744\n",
      "Predicting 4745\n",
      "Predicting 4746\n",
      "Predicting 4747\n",
      "Predicting 4748\n",
      "Predicting 4749\n",
      "Predicting 4750\n",
      "Predicting 4751\n",
      "Predicting 4752\n",
      "Predicting 4753\n",
      "Predicting 4754\n",
      "Predicting 4755\n",
      "Predicting 4756\n",
      "Predicting 4757\n",
      "Predicting 4758\n",
      "Predicting 4759\n",
      "Predicting 4760\n",
      "Predicting 4761\n",
      "Predicting 4762\n",
      "Predicting 4763\n",
      "Predicting 4764\n",
      "Predicting 4765\n",
      "Predicting 4766\n",
      "Predicting 4767\n",
      "Predicting 4768\n",
      "Predicting 4769\n",
      "Predicting 4770\n",
      "Predicting 4771\n",
      "Predicting 4772\n",
      "Predicting 4773\n",
      "Predicting 4774\n",
      "Predicting 4775\n",
      "Predicting 4776\n",
      "Predicting 4777\n",
      "Predicting 4778\n",
      "Predicting 4779\n",
      "Predicting 4780\n",
      "Predicting 4781\n",
      "Predicting 4782\n",
      "Predicting 4783\n",
      "Predicting 4784\n",
      "Predicting 4785\n",
      "Predicting 4786\n",
      "Predicting 4787\n",
      "Predicting 4788\n",
      "Predicting 4789\n",
      "Predicting 4790\n",
      "Predicting 4791\n",
      "Predicting 4792\n",
      "Predicting 4793\n",
      "Predicting 4794\n",
      "Predicting 4795\n",
      "Predicting 4796\n",
      "Predicting 4797\n",
      "Predicting 4798\n",
      "Predicting 4799\n",
      "Predicting 4800\n",
      "Predicting 4801\n",
      "Predicting 4802\n",
      "Predicting 4803\n",
      "Predicting 4804\n",
      "Predicting 4805\n",
      "Predicting 4806\n",
      "Predicting 4807\n",
      "Predicting 4808\n",
      "Predicting 4809\n",
      "Predicting 4810\n",
      "Predicting 4811\n",
      "Predicting 4812\n",
      "Predicting 4813\n",
      "Predicting 4814\n",
      "Predicting 4815\n",
      "Predicting 4816\n",
      "Predicting 4817\n",
      "Predicting 4818\n",
      "Predicting 4819\n",
      "Predicting 4820\n",
      "Predicting 4821\n",
      "Predicting 4822\n",
      "Predicting 4823\n",
      "Predicting 4824\n",
      "Predicting 4825\n",
      "Predicting 4826\n",
      "Predicting 4827\n",
      "Predicting 4828\n",
      "Predicting 4829\n",
      "Predicting 4830\n",
      "Predicting 4831\n",
      "Predicting 4832\n",
      "Predicting 4833\n",
      "Predicting 4834\n",
      "Predicting 4835\n",
      "Predicting 4836\n",
      "Predicting 4837\n",
      "Predicting 4838\n",
      "Predicting 4839\n",
      "Predicting 4840\n",
      "Predicting 4841\n",
      "Predicting 4842\n",
      "Predicting 4843\n",
      "Predicting 4844\n",
      "Predicting 4845\n",
      "Predicting 4846\n",
      "Predicting 4847\n",
      "Predicting 4848\n",
      "Predicting 4849\n",
      "Predicting 4850\n",
      "Predicting 4851\n",
      "Predicting 4852\n",
      "Predicting 4853\n",
      "Predicting 4854\n",
      "Predicting 4855\n",
      "Predicting 4856\n",
      "Predicting 4857\n",
      "Predicting 4858\n",
      "Predicting 4859\n",
      "Predicting 4860\n",
      "Predicting 4861\n",
      "Predicting 4862\n",
      "Predicting 4863\n",
      "Predicting 4864\n",
      "Predicting 4865\n",
      "Predicting 4866\n",
      "Predicting 4867\n",
      "Predicting 4868\n",
      "Predicting 4869\n",
      "Predicting 4870\n",
      "Predicting 4871\n",
      "Predicting 4872\n",
      "Predicting 4873\n",
      "Predicting 4874\n",
      "Predicting 4875\n",
      "Predicting 4876\n",
      "Predicting 4877\n",
      "Predicting 4878\n",
      "Predicting 4879\n",
      "Predicting 4880\n",
      "Predicting 4881\n",
      "Predicting 4882\n",
      "Predicting 4883\n",
      "Predicting 4884\n",
      "Predicting 4885\n",
      "Predicting 4886\n",
      "Predicting 4887\n",
      "Predicting 4888\n",
      "Predicting 4889\n",
      "Predicting 4890\n",
      "Predicting 4891\n",
      "Predicting 4892\n",
      "Predicting 4893\n",
      "Predicting 4894\n",
      "Predicting 4895\n",
      "Predicting 4896\n",
      "Predicting 4897\n",
      "Predicting 4898\n",
      "Predicting 4899\n",
      "Predicting 4900\n",
      "Predicting 4901\n",
      "Predicting 4902\n",
      "Predicting 4903\n",
      "Predicting 4904\n",
      "Predicting 4905\n",
      "Predicting 4906\n",
      "Predicting 4907\n",
      "Predicting 4908\n",
      "Predicting 4909\n",
      "Predicting 4910\n",
      "Predicting 4911\n",
      "Predicting 4912\n",
      "Predicting 4913\n",
      "Predicting 4914\n",
      "Predicting 4915\n",
      "Predicting 4916\n",
      "Predicting 4917\n",
      "Predicting 4918\n",
      "Predicting 4919\n",
      "Predicting 4920\n",
      "Predicting 4921\n",
      "Predicting 4922\n",
      "Predicting 4923\n",
      "Predicting 4924\n",
      "Predicting 4925\n",
      "Predicting 4926\n",
      "Predicting 4927\n",
      "Predicting 4928\n",
      "Predicting 4929\n",
      "Predicting 4930\n",
      "Predicting 4931\n",
      "Predicting 4932\n",
      "Predicting 4933\n",
      "Predicting 4934\n",
      "Predicting 4935\n",
      "Predicting 4936\n",
      "Predicting 4937\n",
      "Predicting 4938\n",
      "Predicting 4939\n",
      "Predicting 4940\n",
      "Predicting 4941\n",
      "Predicting 4942\n",
      "Predicting 4943\n",
      "Predicting 4944\n",
      "Predicting 4945\n",
      "Predicting 4946\n",
      "Predicting 4947\n",
      "Predicting 4948\n",
      "Predicting 4949\n",
      "Predicting 4950\n",
      "Predicting 4951\n",
      "Predicting 4952\n",
      "Predicting 4953\n",
      "Predicting 4954\n",
      "Predicting 4955\n",
      "Predicting 4956\n",
      "Predicting 4957\n",
      "Predicting 4958\n",
      "Predicting 4959\n",
      "Predicting 4960\n",
      "Predicting 4961\n",
      "Predicting 4962\n",
      "Predicting 4963\n",
      "Predicting 4964\n",
      "Predicting 4965\n",
      "Predicting 4966\n",
      "Predicting 4967\n",
      "Predicting 4968\n",
      "Predicting 4969\n",
      "Predicting 4970\n",
      "Predicting 4971\n",
      "Predicting 4972\n",
      "Predicting 4973\n",
      "Predicting 4974\n",
      "Predicting 4975\n",
      "Predicting 4976\n",
      "Predicting 4977\n",
      "Predicting 4978\n",
      "Predicting 4979\n",
      "Predicting 4980\n",
      "Predicting 4981\n",
      "Predicting 4982\n",
      "Predicting 4983\n",
      "Predicting 4984\n",
      "Predicting 4985\n",
      "Predicting 4986\n",
      "Predicting 4987\n",
      "Predicting 4988\n",
      "Predicting 4989\n",
      "Predicting 4990\n",
      "Predicting 4991\n",
      "Predicting 4992\n",
      "Predicting 4993\n",
      "Predicting 4994\n",
      "Predicting 4995\n",
      "Predicting 4996\n",
      "Predicting 4997\n",
      "Predicting 4998\n",
      "Predicting 4999\n",
      "Predicting 5000\n",
      "Predicting 5001\n",
      "Predicting 5002\n",
      "Predicting 5003\n",
      "Predicting 5004\n",
      "Predicting 5005\n",
      "Predicting 5006\n",
      "Predicting 5007\n",
      "Predicting 5008\n",
      "Predicting 5009\n",
      "Predicting 5010\n",
      "Predicting 5011\n",
      "Predicting 5012\n",
      "Predicting 5013\n",
      "Predicting 5014\n",
      "Predicting 5015\n",
      "Predicting 5016\n",
      "Predicting 5017\n",
      "Predicting 5018\n",
      "Predicting 5019\n",
      "Predicting 5020\n",
      "Predicting 5021\n",
      "Predicting 5022\n",
      "Predicting 5023\n",
      "Predicting 5024\n",
      "Predicting 5025\n",
      "Predicting 5026\n",
      "Predicting 5027\n",
      "Predicting 5028\n",
      "Predicting 5029\n",
      "Predicting 5030\n",
      "Predicting 5031\n",
      "Predicting 5032\n",
      "Predicting 5033\n",
      "Predicting 5034\n",
      "Predicting 5035\n",
      "Predicting 5036\n",
      "Predicting 5037\n",
      "Predicting 5038\n",
      "Predicting 5039\n",
      "Predicting 5040\n",
      "Predicting 5041\n",
      "Predicting 5042\n",
      "Predicting 5043\n",
      "Predicting 5044\n",
      "Predicting 5045\n",
      "Predicting 5046\n",
      "Predicting 5047\n",
      "Predicting 5048\n",
      "Predicting 5049\n",
      "Predicting 5050\n",
      "Predicting 5051\n",
      "Predicting 5052\n",
      "Predicting 5053\n",
      "Predicting 5054\n",
      "Predicting 5055\n",
      "Predicting 5056\n",
      "Predicting 5057\n",
      "Predicting 5058\n",
      "Predicting 5059\n",
      "Predicting 5060\n",
      "Predicting 5061\n",
      "Predicting 5062\n",
      "Predicting 5063\n",
      "Predicting 5064\n",
      "Predicting 5065\n",
      "Predicting 5066\n",
      "Predicting 5067\n",
      "Predicting 5068\n",
      "Predicting 5069\n",
      "Predicting 5070\n",
      "Predicting 5071\n",
      "Predicting 5072\n",
      "Predicting 5073\n",
      "Predicting 5074\n",
      "Predicting 5075\n",
      "Predicting 5076\n",
      "Predicting 5077\n",
      "Predicting 5078\n",
      "Predicting 5079\n",
      "Predicting 5080\n",
      "Predicting 5081\n",
      "Predicting 5082\n",
      "Predicting 5083\n",
      "Predicting 5084\n",
      "Predicting 5085\n",
      "Predicting 5086\n",
      "Predicting 5087\n",
      "Predicting 5088\n",
      "Predicting 5089\n",
      "Predicting 5090\n",
      "Predicting 5091\n",
      "Predicting 5092\n",
      "Predicting 5093\n",
      "Predicting 5094\n",
      "Predicting 5095\n",
      "Predicting 5096\n",
      "Predicting 5097\n",
      "Predicting 5098\n",
      "Predicting 5099\n",
      "Predicting 5100\n",
      "Predicting 5101\n",
      "Predicting 5102\n",
      "Predicting 5103\n",
      "Predicting 5104\n",
      "Predicting 5105\n",
      "Predicting 5106\n",
      "Predicting 5107\n",
      "Predicting 5108\n",
      "Predicting 5109\n",
      "Predicting 5110\n",
      "Predicting 5111\n",
      "Predicting 5112\n",
      "Predicting 5113\n",
      "Predicting 5114\n",
      "Predicting 5115\n",
      "Predicting 5116\n",
      "Predicting 5117\n",
      "Predicting 5118\n",
      "Predicting 5119\n",
      "Predicting 5120\n",
      "Predicting 5121\n",
      "Predicting 5122\n",
      "Predicting 5123\n",
      "Predicting 5124\n",
      "Predicting 5125\n",
      "Predicting 5126\n",
      "Predicting 5127\n",
      "Predicting 5128\n",
      "Predicting 5129\n",
      "Predicting 5130\n",
      "Predicting 5131\n",
      "Predicting 5132\n",
      "Predicting 5133\n",
      "Predicting 5134\n",
      "Predicting 5135\n",
      "Predicting 5136\n",
      "Predicting 5137\n",
      "Predicting 5138\n",
      "Predicting 5139\n",
      "Predicting 5140\n",
      "Predicting 5141\n",
      "Predicting 5142\n",
      "Predicting 5143\n",
      "Predicting 5144\n",
      "Predicting 5145\n",
      "Predicting 5146\n",
      "Predicting 5147\n",
      "Predicting 5148\n",
      "Predicting 5149\n",
      "Predicting 5150\n",
      "Predicting 5151\n",
      "Predicting 5152\n",
      "Predicting 5153\n",
      "Predicting 5154\n",
      "Predicting 5155\n",
      "Predicting 5156\n",
      "Predicting 5157\n",
      "Predicting 5158\n",
      "Predicting 5159\n",
      "Predicting 5160\n",
      "Predicting 5161\n",
      "Predicting 5162\n",
      "Predicting 5163\n",
      "Predicting 5164\n",
      "Predicting 5165\n",
      "Predicting 5166\n",
      "Predicting 5167\n",
      "Predicting 5168\n",
      "Predicting 5169\n",
      "Predicting 5170\n",
      "Predicting 5171\n",
      "Predicting 5172\n",
      "Predicting 5173\n",
      "Predicting 5174\n",
      "Predicting 5175\n",
      "Predicting 5176\n",
      "Predicting 5177\n",
      "Predicting 5178\n",
      "Predicting 5179\n",
      "Predicting 5180\n",
      "Predicting 5181\n",
      "Predicting 5182\n",
      "Predicting 5183\n",
      "Predicting 5184\n",
      "Predicting 5185\n",
      "Predicting 5186\n",
      "Predicting 5187\n",
      "Predicting 5188\n",
      "Predicting 5189\n",
      "Predicting 5190\n",
      "Predicting 5191\n",
      "Predicting 5192\n",
      "Predicting 5193\n",
      "Predicting 5194\n",
      "Predicting 5195\n",
      "Predicting 5196\n",
      "Predicting 5197\n",
      "Predicting 5198\n",
      "Predicting 5199\n",
      "Predicting 5200\n",
      "Predicting 5201\n",
      "Predicting 5202\n",
      "Predicting 5203\n",
      "Predicting 5204\n",
      "Predicting 5205\n",
      "Predicting 5206\n",
      "Predicting 5207\n",
      "Predicting 5208\n",
      "Predicting 5209\n",
      "Predicting 5210\n",
      "Predicting 5211\n",
      "Predicting 5212\n",
      "Predicting 5213\n",
      "Predicting 5214\n",
      "Predicting 5215\n",
      "Predicting 5216\n",
      "Predicting 5217\n",
      "Predicting 5218\n",
      "Predicting 5219\n",
      "Predicting 5220\n",
      "Predicting 5221\n",
      "Predicting 5222\n",
      "Predicting 5223\n",
      "Predicting 5224\n",
      "Predicting 5225\n",
      "Predicting 5226\n",
      "Predicting 5227\n",
      "Predicting 5228\n",
      "Predicting 5229\n",
      "Predicting 5230\n",
      "Predicting 5231\n",
      "Predicting 5232\n",
      "Predicting 5233\n",
      "Predicting 5234\n",
      "Predicting 5235\n",
      "Predicting 5236\n",
      "Predicting 5237\n",
      "Predicting 5238\n",
      "Predicting 5239\n",
      "Predicting 5240\n",
      "Predicting 5241\n",
      "Predicting 5242\n",
      "Predicting 5243\n",
      "Predicting 5244\n",
      "Predicting 5245\n",
      "Predicting 5246\n",
      "Predicting 5247\n",
      "Predicting 5248\n",
      "Predicting 5249\n",
      "Predicting 5250\n",
      "Predicting 5251\n",
      "Predicting 5252\n",
      "Predicting 5253\n",
      "Predicting 5254\n",
      "Predicting 5255\n",
      "Predicting 5256\n",
      "Predicting 5257\n",
      "Predicting 5258\n",
      "Predicting 5259\n",
      "Predicting 5260\n",
      "Predicting 5261\n",
      "Predicting 5262\n",
      "Predicting 5263\n",
      "Predicting 5264\n",
      "Predicting 5265\n",
      "Predicting 5266\n",
      "Predicting 5267\n",
      "Predicting 5268\n",
      "Predicting 5269\n",
      "Predicting 5270\n",
      "Predicting 5271\n",
      "Predicting 5272\n",
      "Predicting 5273\n",
      "Predicting 5274\n",
      "Predicting 5275\n",
      "Predicting 5276\n",
      "Predicting 5277\n",
      "Predicting 5278\n",
      "Predicting 5279\n",
      "Predicting 5280\n",
      "Predicting 5281\n",
      "Predicting 5282\n",
      "Predicting 5283\n",
      "Predicting 5284\n",
      "Predicting 5285\n",
      "Predicting 5286\n",
      "Predicting 5287\n",
      "Predicting 5288\n",
      "Predicting 5289\n",
      "Predicting 5290\n",
      "Predicting 5291\n",
      "Predicting 5292\n",
      "Predicting 5293\n",
      "Predicting 5294\n",
      "Predicting 5295\n",
      "Predicting 5296\n",
      "Predicting 5297\n",
      "Predicting 5298\n",
      "Predicting 5299\n",
      "Predicting 5300\n",
      "Predicting 5301\n",
      "Predicting 5302\n",
      "Predicting 5303\n",
      "Predicting 5304\n",
      "Predicting 5305\n",
      "Predicting 5306\n",
      "Predicting 5307\n",
      "Predicting 5308\n",
      "Predicting 5309\n",
      "Predicting 5310\n",
      "Predicting 5311\n",
      "Predicting 5312\n",
      "Predicting 5313\n",
      "Predicting 5314\n",
      "Predicting 5315\n",
      "Predicting 5316\n",
      "Predicting 5317\n",
      "Predicting 5318\n",
      "Predicting 5319\n",
      "Predicting 5320\n",
      "Predicting 5321\n",
      "Predicting 5322\n",
      "Predicting 5323\n",
      "Predicting 5324\n",
      "Predicting 5325\n",
      "Predicting 5326\n",
      "Predicting 5327\n",
      "Predicting 5328\n",
      "Predicting 5329\n",
      "Predicting 5330\n",
      "Predicting 5331\n",
      "Predicting 5332\n",
      "Predicting 5333\n",
      "Predicting 5334\n",
      "Predicting 5335\n",
      "Predicting 5336\n",
      "Predicting 5337\n",
      "Predicting 5338\n",
      "Predicting 5339\n",
      "Predicting 5340\n",
      "Predicting 5341\n",
      "Predicting 5342\n",
      "Predicting 5343\n",
      "Predicting 5344\n",
      "Predicting 5345\n",
      "Predicting 5346\n",
      "Predicting 5347\n",
      "Predicting 5348\n",
      "Predicting 5349\n",
      "Predicting 5350\n",
      "Predicting 5351\n",
      "Predicting 5352\n",
      "Predicting 5353\n",
      "Predicting 5354\n",
      "Predicting 5355\n",
      "Predicting 5356\n",
      "Predicting 5357\n",
      "Predicting 5358\n",
      "Predicting 5359\n",
      "Predicting 5360\n",
      "Predicting 5361\n",
      "Predicting 5362\n",
      "Predicting 5363\n",
      "Predicting 5364\n",
      "Predicting 5365\n",
      "Predicting 5366\n",
      "Predicting 5367\n",
      "Predicting 5368\n",
      "Predicting 5369\n",
      "Predicting 5370\n",
      "Predicting 5371\n",
      "Predicting 5372\n",
      "Predicting 5373\n",
      "Predicting 5374\n",
      "Predicting 5375\n",
      "Predicting 5376\n",
      "Predicting 5377\n",
      "Predicting 5378\n",
      "Predicting 5379\n",
      "Predicting 5380\n",
      "Predicting 5381\n",
      "Predicting 5382\n",
      "Predicting 5383\n",
      "Predicting 5384\n",
      "Predicting 5385\n",
      "Predicting 5386\n",
      "Predicting 5387\n",
      "Predicting 5388\n",
      "Predicting 5389\n",
      "Predicting 5390\n",
      "Predicting 5391\n",
      "Predicting 5392\n",
      "Predicting 5393\n",
      "Predicting 5394\n",
      "Predicting 5395\n",
      "Predicting 5396\n",
      "Predicting 5397\n",
      "Predicting 5398\n",
      "Predicting 5399\n",
      "Predicting 5400\n",
      "Predicting 5401\n",
      "Predicting 5402\n",
      "Predicting 5403\n",
      "Predicting 5404\n",
      "Predicting 5405\n",
      "Predicting 5406\n",
      "Predicting 5407\n",
      "Predicting 5408\n",
      "Predicting 5409\n",
      "Predicting 5410\n",
      "Predicting 5411\n",
      "Predicting 5412\n",
      "Predicting 5413\n",
      "Predicting 5414\n",
      "Predicting 5415\n",
      "Predicting 5416\n",
      "Predicting 5417\n",
      "Predicting 5418\n",
      "Predicting 5419\n",
      "Predicting 5420\n",
      "Predicting 5421\n",
      "Predicting 5422\n",
      "Predicting 5423\n",
      "Predicting 5424\n",
      "Predicting 5425\n",
      "Predicting 5426\n",
      "Predicting 5427\n",
      "Predicting 5428\n",
      "Predicting 5429\n",
      "Predicting 5430\n",
      "Predicting 5431\n",
      "Predicting 5432\n",
      "Predicting 5433\n",
      "Predicting 5434\n",
      "Predicting 5435\n",
      "Predicting 5436\n",
      "Predicting 5437\n",
      "Predicting 5438\n",
      "Predicting 5439\n",
      "Predicting 5440\n",
      "Predicting 5441\n",
      "Predicting 5442\n",
      "Predicting 5443\n",
      "Predicting 5444\n",
      "Predicting 5445\n",
      "Predicting 5446\n",
      "Predicting 5447\n",
      "Predicting 5448\n",
      "Predicting 5449\n",
      "Predicting 5450\n",
      "Predicting 5451\n",
      "Predicting 5452\n",
      "Predicting 5453\n",
      "Predicting 5454\n",
      "Predicting 5455\n",
      "Predicting 5456\n",
      "Predicting 5457\n",
      "Predicting 5458\n",
      "Predicting 5459\n",
      "Predicting 5460\n",
      "Predicting 5461\n",
      "Predicting 5462\n",
      "Predicting 5463\n",
      "Predicting 5464\n",
      "Predicting 5465\n",
      "Predicting 5466\n",
      "Predicting 5467\n",
      "Predicting 5468\n",
      "Predicting 5469\n",
      "Predicting 5470\n",
      "Predicting 5471\n",
      "Predicting 5472\n",
      "Predicting 5473\n",
      "Predicting 5474\n",
      "Predicting 5475\n",
      "Predicting 5476\n",
      "Predicting 5477\n",
      "Predicting 5478\n",
      "Predicting 5479\n",
      "Predicting 5480\n",
      "Predicting 5481\n",
      "Predicting 5482\n",
      "Predicting 5483\n",
      "Predicting 5484\n",
      "Predicting 5485\n",
      "Predicting 5486\n",
      "Predicting 5487\n",
      "Predicting 5488\n",
      "Predicting 5489\n",
      "Predicting 5490\n",
      "Predicting 5491\n",
      "Predicting 5492\n",
      "Predicting 5493\n",
      "Predicting 5494\n",
      "Predicting 5495\n",
      "Predicting 5496\n",
      "Predicting 5497\n",
      "Predicting 5498\n",
      "Predicting 5499\n",
      "Predicting 5500\n",
      "Predicting 5501\n",
      "Predicting 5502\n",
      "Predicting 5503\n",
      "Predicting 5504\n",
      "Predicting 5505\n",
      "Predicting 5506\n",
      "Predicting 5507\n",
      "Predicting 5508\n",
      "Predicting 5509\n",
      "Predicting 5510\n",
      "Predicting 5511\n",
      "Predicting 5512\n",
      "Predicting 5513\n",
      "Predicting 5514\n",
      "Predicting 5515\n",
      "Predicting 5516\n",
      "Predicting 5517\n",
      "Predicting 5518\n",
      "Predicting 5519\n",
      "Predicting 5520\n",
      "Predicting 5521\n",
      "Predicting 5522\n",
      "Predicting 5523\n",
      "Predicting 5524\n",
      "Predicting 5525\n",
      "Predicting 5526\n",
      "Predicting 5527\n",
      "Predicting 5528\n",
      "Predicting 5529\n",
      "Predicting 5530\n",
      "Predicting 5531\n",
      "Predicting 5532\n",
      "Predicting 5533\n",
      "Threshold: 0.01\n",
      "Precision: 1.0000\n",
      "Recall: 0.4407\n",
      "TP: 513\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 651\n",
      "\n",
      "Threshold: 0.02\n",
      "Precision: 1.0000\n",
      "Recall: 0.4021\n",
      "TP: 468\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 696\n",
      "\n",
      "Threshold: 0.03\n",
      "Precision: 1.0000\n",
      "Recall: 0.3849\n",
      "TP: 448\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 716\n",
      "\n",
      "Threshold: 0.04\n",
      "Precision: 1.0000\n",
      "Recall: 0.3711\n",
      "TP: 432\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 732\n",
      "\n",
      "Threshold: 0.05\n",
      "Precision: 1.0000\n",
      "Recall: 0.3574\n",
      "TP: 416\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 748\n",
      "\n",
      "Threshold: 0.06\n",
      "Precision: 1.0000\n",
      "Recall: 0.3479\n",
      "TP: 405\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 759\n",
      "\n",
      "Threshold: 0.07\n",
      "Precision: 1.0000\n",
      "Recall: 0.3436\n",
      "TP: 400\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 764\n",
      "\n",
      "Threshold: 0.08\n",
      "Precision: 1.0000\n",
      "Recall: 0.3376\n",
      "TP: 393\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 771\n",
      "\n",
      "Threshold: 0.09\n",
      "Precision: 1.0000\n",
      "Recall: 0.3290\n",
      "TP: 383\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 781\n",
      "\n",
      "Threshold: 0.10\n",
      "Precision: 1.0000\n",
      "Recall: 0.3222\n",
      "TP: 375\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 789\n",
      "\n",
      "Threshold: 0.11\n",
      "Precision: 1.0000\n",
      "Recall: 0.3179\n",
      "TP: 370\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 794\n",
      "\n",
      "Threshold: 0.12\n",
      "Precision: 1.0000\n",
      "Recall: 0.3119\n",
      "TP: 363\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 801\n",
      "\n",
      "Threshold: 0.13\n",
      "Precision: 1.0000\n",
      "Recall: 0.3093\n",
      "TP: 360\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 804\n",
      "\n",
      "Threshold: 0.14\n",
      "Precision: 1.0000\n",
      "Recall: 0.3076\n",
      "TP: 358\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 806\n",
      "\n",
      "Threshold: 0.15\n",
      "Precision: 1.0000\n",
      "Recall: 0.3058\n",
      "TP: 356\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 808\n",
      "\n",
      "Threshold: 0.16\n",
      "Precision: 1.0000\n",
      "Recall: 0.3015\n",
      "TP: 351\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 813\n",
      "\n",
      "Threshold: 0.17\n",
      "Precision: 1.0000\n",
      "Recall: 0.2973\n",
      "TP: 346\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 818\n",
      "\n",
      "Threshold: 0.18\n",
      "Precision: 1.0000\n",
      "Recall: 0.2955\n",
      "TP: 344\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 820\n",
      "\n",
      "Threshold: 0.19\n",
      "Precision: 1.0000\n",
      "Recall: 0.2921\n",
      "TP: 340\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 824\n",
      "\n",
      "Threshold: 0.20\n",
      "Precision: 1.0000\n",
      "Recall: 0.2887\n",
      "TP: 336\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 828\n",
      "\n",
      "Threshold: 0.21\n",
      "Precision: 1.0000\n",
      "Recall: 0.2878\n",
      "TP: 335\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 829\n",
      "\n",
      "Threshold: 0.22\n",
      "Precision: 1.0000\n",
      "Recall: 0.2869\n",
      "TP: 334\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 830\n",
      "\n",
      "Threshold: 0.23\n",
      "Precision: 1.0000\n",
      "Recall: 0.2844\n",
      "TP: 331\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 833\n",
      "\n",
      "Threshold: 0.24\n",
      "Precision: 1.0000\n",
      "Recall: 0.2801\n",
      "TP: 326\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 838\n",
      "\n",
      "Threshold: 0.25\n",
      "Precision: 1.0000\n",
      "Recall: 0.2775\n",
      "TP: 323\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 841\n",
      "\n",
      "Threshold: 0.26\n",
      "Precision: 1.0000\n",
      "Recall: 0.2749\n",
      "TP: 320\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 844\n",
      "\n",
      "Threshold: 0.27\n",
      "Precision: 1.0000\n",
      "Recall: 0.2715\n",
      "TP: 316\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 848\n",
      "\n",
      "Threshold: 0.28\n",
      "Precision: 1.0000\n",
      "Recall: 0.2680\n",
      "TP: 312\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 852\n",
      "\n",
      "Threshold: 0.29\n",
      "Precision: 1.0000\n",
      "Recall: 0.2663\n",
      "TP: 310\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 854\n",
      "\n",
      "Threshold: 0.30\n",
      "Precision: 1.0000\n",
      "Recall: 0.2663\n",
      "TP: 310\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 854\n",
      "\n",
      "Threshold: 0.31\n",
      "Precision: 1.0000\n",
      "Recall: 0.2637\n",
      "TP: 307\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 857\n",
      "\n",
      "Threshold: 0.32\n",
      "Precision: 1.0000\n",
      "Recall: 0.2620\n",
      "TP: 305\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 859\n",
      "\n",
      "Threshold: 0.33\n",
      "Precision: 1.0000\n",
      "Recall: 0.2612\n",
      "TP: 304\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 860\n",
      "\n",
      "Threshold: 0.34\n",
      "Precision: 1.0000\n",
      "Recall: 0.2577\n",
      "TP: 300\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 864\n",
      "\n",
      "Threshold: 0.35\n",
      "Precision: 1.0000\n",
      "Recall: 0.2577\n",
      "TP: 300\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 864\n",
      "\n",
      "Threshold: 0.36\n",
      "Precision: 1.0000\n",
      "Recall: 0.2569\n",
      "TP: 299\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 865\n",
      "\n",
      "Threshold: 0.37\n",
      "Precision: 1.0000\n",
      "Recall: 0.2552\n",
      "TP: 297\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 867\n",
      "\n",
      "Threshold: 0.38\n",
      "Precision: 1.0000\n",
      "Recall: 0.2543\n",
      "TP: 296\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 868\n",
      "\n",
      "Threshold: 0.39\n",
      "Precision: 1.0000\n",
      "Recall: 0.2500\n",
      "TP: 291\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 873\n",
      "\n",
      "Threshold: 0.40\n",
      "Precision: 1.0000\n",
      "Recall: 0.2500\n",
      "TP: 291\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 873\n",
      "\n",
      "Threshold: 0.41\n",
      "Precision: 1.0000\n",
      "Recall: 0.2474\n",
      "TP: 288\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 876\n",
      "\n",
      "Threshold: 0.42\n",
      "Precision: 1.0000\n",
      "Recall: 0.2474\n",
      "TP: 288\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 876\n",
      "\n",
      "Threshold: 0.43\n",
      "Precision: 1.0000\n",
      "Recall: 0.2448\n",
      "TP: 285\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 879\n",
      "\n",
      "Threshold: 0.44\n",
      "Precision: 1.0000\n",
      "Recall: 0.2431\n",
      "TP: 283\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 881\n",
      "\n",
      "Threshold: 0.45\n",
      "Precision: 1.0000\n",
      "Recall: 0.2423\n",
      "TP: 282\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 882\n",
      "\n",
      "Threshold: 0.46\n",
      "Precision: 1.0000\n",
      "Recall: 0.2380\n",
      "TP: 277\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 887\n",
      "\n",
      "Threshold: 0.47\n",
      "Precision: 1.0000\n",
      "Recall: 0.2371\n",
      "TP: 276\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 888\n",
      "\n",
      "Threshold: 0.48\n",
      "Precision: 1.0000\n",
      "Recall: 0.2345\n",
      "TP: 273\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 891\n",
      "\n",
      "Threshold: 0.49\n",
      "Precision: 1.0000\n",
      "Recall: 0.2337\n",
      "TP: 272\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 892\n",
      "\n",
      "Threshold: 0.50\n",
      "Precision: 1.0000\n",
      "Recall: 0.2320\n",
      "TP: 270\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 894\n",
      "\n",
      "Threshold: 0.51\n",
      "Precision: 1.0000\n",
      "Recall: 0.2294\n",
      "TP: 267\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 897\n",
      "\n",
      "Threshold: 0.52\n",
      "Precision: 1.0000\n",
      "Recall: 0.2277\n",
      "TP: 265\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 899\n",
      "\n",
      "Threshold: 0.53\n",
      "Precision: 1.0000\n",
      "Recall: 0.2259\n",
      "TP: 263\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 901\n",
      "\n",
      "Threshold: 0.54\n",
      "Precision: 1.0000\n",
      "Recall: 0.2251\n",
      "TP: 262\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 902\n",
      "\n",
      "Threshold: 0.55\n",
      "Precision: 1.0000\n",
      "Recall: 0.2225\n",
      "TP: 259\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 905\n",
      "\n",
      "Threshold: 0.56\n",
      "Precision: 1.0000\n",
      "Recall: 0.2216\n",
      "TP: 258\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 906\n",
      "\n",
      "Threshold: 0.57\n",
      "Precision: 1.0000\n",
      "Recall: 0.2199\n",
      "TP: 256\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 908\n",
      "\n",
      "Threshold: 0.58\n",
      "Precision: 1.0000\n",
      "Recall: 0.2191\n",
      "TP: 255\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 909\n",
      "\n",
      "Threshold: 0.59\n",
      "Precision: 1.0000\n",
      "Recall: 0.2165\n",
      "TP: 252\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 912\n",
      "\n",
      "Threshold: 0.60\n",
      "Precision: 1.0000\n",
      "Recall: 0.2148\n",
      "TP: 250\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 914\n",
      "\n",
      "Threshold: 0.61\n",
      "Precision: 1.0000\n",
      "Recall: 0.2105\n",
      "TP: 245\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 919\n",
      "\n",
      "Threshold: 0.62\n",
      "Precision: 1.0000\n",
      "Recall: 0.2096\n",
      "TP: 244\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 920\n",
      "\n",
      "Threshold: 0.63\n",
      "Precision: 1.0000\n",
      "Recall: 0.2096\n",
      "TP: 244\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 920\n",
      "\n",
      "Threshold: 0.64\n",
      "Precision: 1.0000\n",
      "Recall: 0.2079\n",
      "TP: 242\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 922\n",
      "\n",
      "Threshold: 0.65\n",
      "Precision: 1.0000\n",
      "Recall: 0.2062\n",
      "TP: 240\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 924\n",
      "\n",
      "Threshold: 0.66\n",
      "Precision: 1.0000\n",
      "Recall: 0.2036\n",
      "TP: 237\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 927\n",
      "\n",
      "Threshold: 0.67\n",
      "Precision: 1.0000\n",
      "Recall: 0.2027\n",
      "TP: 236\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 928\n",
      "\n",
      "Threshold: 0.68\n",
      "Precision: 1.0000\n",
      "Recall: 0.2010\n",
      "TP: 234\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 930\n",
      "\n",
      "Threshold: 0.69\n",
      "Precision: 1.0000\n",
      "Recall: 0.1993\n",
      "TP: 232\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 932\n",
      "\n",
      "Threshold: 0.70\n",
      "Precision: 1.0000\n",
      "Recall: 0.1967\n",
      "TP: 229\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 935\n",
      "\n",
      "Threshold: 0.71\n",
      "Precision: 1.0000\n",
      "Recall: 0.1959\n",
      "TP: 228\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 936\n",
      "\n",
      "Threshold: 0.72\n",
      "Precision: 1.0000\n",
      "Recall: 0.1942\n",
      "TP: 226\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 938\n",
      "\n",
      "Threshold: 0.73\n",
      "Precision: 1.0000\n",
      "Recall: 0.1899\n",
      "TP: 221\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 943\n",
      "\n",
      "Threshold: 0.74\n",
      "Precision: 1.0000\n",
      "Recall: 0.1864\n",
      "TP: 217\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 947\n",
      "\n",
      "Threshold: 0.75\n",
      "Precision: 1.0000\n",
      "Recall: 0.1856\n",
      "TP: 216\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 948\n",
      "\n",
      "Threshold: 0.76\n",
      "Precision: 1.0000\n",
      "Recall: 0.1838\n",
      "TP: 214\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 950\n",
      "\n",
      "Threshold: 0.77\n",
      "Precision: 1.0000\n",
      "Recall: 0.1804\n",
      "TP: 210\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 954\n",
      "\n",
      "Threshold: 0.78\n",
      "Precision: 1.0000\n",
      "Recall: 0.1770\n",
      "TP: 206\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 958\n",
      "\n",
      "Threshold: 0.79\n",
      "Precision: 1.0000\n",
      "Recall: 0.1761\n",
      "TP: 205\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 959\n",
      "\n",
      "Threshold: 0.80\n",
      "Precision: 1.0000\n",
      "Recall: 0.1735\n",
      "TP: 202\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 962\n",
      "\n",
      "Threshold: 0.81\n",
      "Precision: 1.0000\n",
      "Recall: 0.1710\n",
      "TP: 199\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 965\n",
      "\n",
      "Threshold: 0.82\n",
      "Precision: 1.0000\n",
      "Recall: 0.1675\n",
      "TP: 195\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 969\n",
      "\n",
      "Threshold: 0.83\n",
      "Precision: 1.0000\n",
      "Recall: 0.1649\n",
      "TP: 192\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 972\n",
      "\n",
      "Threshold: 0.84\n",
      "Precision: 1.0000\n",
      "Recall: 0.1598\n",
      "TP: 186\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 978\n",
      "\n",
      "Threshold: 0.85\n",
      "Precision: 1.0000\n",
      "Recall: 0.1521\n",
      "TP: 177\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 987\n",
      "\n",
      "Threshold: 0.86\n",
      "Precision: 1.0000\n",
      "Recall: 0.1469\n",
      "TP: 171\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 993\n",
      "\n",
      "Threshold: 0.87\n",
      "Precision: 1.0000\n",
      "Recall: 0.1452\n",
      "TP: 169\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 995\n",
      "\n",
      "Threshold: 0.88\n",
      "Precision: 1.0000\n",
      "Recall: 0.1400\n",
      "TP: 163\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 1001\n",
      "\n",
      "Threshold: 0.89\n",
      "Precision: 1.0000\n",
      "Recall: 0.1375\n",
      "TP: 160\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 1004\n",
      "\n",
      "Threshold: 0.90\n",
      "Precision: 1.0000\n",
      "Recall: 0.1280\n",
      "TP: 149\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 1015\n",
      "\n",
      "Threshold: 0.91\n",
      "Precision: 1.0000\n",
      "Recall: 0.1211\n",
      "TP: 141\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 1023\n",
      "\n",
      "Threshold: 0.92\n",
      "Precision: 1.0000\n",
      "Recall: 0.1134\n",
      "TP: 132\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 1032\n",
      "\n",
      "Threshold: 0.93\n",
      "Precision: 1.0000\n",
      "Recall: 0.1082\n",
      "TP: 126\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 1038\n",
      "\n",
      "Threshold: 0.94\n",
      "Precision: 1.0000\n",
      "Recall: 0.0979\n",
      "TP: 114\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 1050\n",
      "\n",
      "Threshold: 0.95\n",
      "Precision: 1.0000\n",
      "Recall: 0.0902\n",
      "TP: 105\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 1059\n",
      "\n",
      "Threshold: 0.96\n",
      "Precision: 1.0000\n",
      "Recall: 0.0679\n",
      "TP: 79\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 1085\n",
      "\n",
      "Threshold: 0.97\n",
      "Precision: 1.0000\n",
      "Recall: 0.0507\n",
      "TP: 59\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 1105\n",
      "\n",
      "Threshold: 0.98\n",
      "Precision: 1.0000\n",
      "Recall: 0.0318\n",
      "TP: 37\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 1127\n",
      "\n",
      "Threshold: 0.99\n",
      "Precision: 1.0000\n",
      "Recall: 0.0137\n",
      "TP: 16\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 1148\n",
      "\n",
      "Threshold: 1.00\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "TP: 0\n",
      "TN: 4370\n",
      "FP: 0\n",
      "FN: 1164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract ground truth and predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "cnt = 0\n",
    "for audio, label in ds:\n",
    "    print(f'Predicting {cnt}')\n",
    "    cnt += 1\n",
    "    predictions = yamnet.predict_on_batch(audio)[0][0][341]\n",
    "    y_true.append(label.numpy())\n",
    "    y_pred.append(predictions)\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred).squeeze()\n",
    "\n",
    "# Define thresholds\n",
    "thresholds = np.linspace(0.01, 1, 100, dtype=np.float64).round(2)\n",
    "\n",
    "# Compute metrics_\n",
    "metrics_yamnet = compute_metrics(y_true, y_pred, thresholds)\n",
    "\n",
    "# Display the metrics\n",
    "for i, threshold in enumerate(metrics_yamnet['threshold']):\n",
    "    print(f\"Threshold: {threshold:.2f}\")\n",
    "    print(f\"Precision: {metrics_yamnet['precision'][i]:.4f}\")\n",
    "    print(f\"Recall: {metrics_yamnet['recall'][i]:.4f}\")\n",
    "    print(f\"TP: {metrics_yamnet['tp'][i]}\")\n",
    "    print(f\"TN: {metrics_yamnet['tn'][i]}\")\n",
    "    print(f\"FP: {metrics_yamnet['fp'][i]}\")\n",
    "    print(f\"FN: {metrics_yamnet['fn'][i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, det_curve\n",
    "\n",
    "def plot_precision_recall_vs_threshold_comparison(metrics1, metrics2, model1_name='Model 1', model2_name='Model 2'):\n",
    "    thresholds1 = metrics1['threshold']\n",
    "    precision1 = metrics1['precision']\n",
    "    recall1 = metrics1['recall']\n",
    "\n",
    "    thresholds2 = metrics2['threshold']\n",
    "    precision2 = metrics2['precision']\n",
    "    recall2 = metrics2['recall']\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "    \n",
    "    # Precision vs. Threshold\n",
    "    #ax[0].plot(thresholds1, precision1, label=f'{model1_name}', color='b')\n",
    "    #ax[0].plot(thresholds2, precision2, label=f'{model2_name}', color='g')\n",
    "    #ax[0].set_xlabel('Umbral')\n",
    "    #ax[0].set_ylabel('Precisin')\n",
    "    #ax[0].set_title('Precisin vs. Umbral')\n",
    "    #ax[0].legend()\n",
    "    #ax[0].grid(True)\n",
    "    \n",
    "    # Recall vs. Threshold\n",
    "    ax.plot(thresholds1, recall1, label=f'{model1_name}', color='b')\n",
    "    ax.plot(thresholds2, recall2, label=f'{model2_name}', color='g')\n",
    "    ax.set_xlabel('Umbral', fontsize=16)\n",
    "    ax.set_ylabel('Exhaustividad', fontsize=16)\n",
    "    ax.set_title('Exhaustividad vs. Umbral', fontsize=16)\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_det_curve_comparison(metrics1, metrics2, model1_name='Model 1', model2_name='Model 2'):\n",
    "    time1 = metrics1['tp'][0] + metrics1['fp'][0] + metrics1['tn'][0] + metrics1['fn'][0]\n",
    "    time2 = metrics2['tp'][0] + metrics2['fp'][0] + metrics2['tn'][0] + metrics2['fn'][0]\n",
    "    \n",
    "    for key in metrics1.keys():\n",
    "        metrics1[key] = np.array(metrics1[key])\n",
    "    \n",
    "    for key in metrics2.keys():\n",
    "        metrics2[key] = np.array(metrics2[key])\n",
    "\n",
    "    tpr1 = metrics1['recall']\n",
    "    fpr1 =  metrics1['fp'] / (metrics1['fp'] + metrics1['tn'])\n",
    "    \n",
    "    tpr2 = metrics2['recall']\n",
    "    fpr2 =  metrics2['fp'] / (metrics2['fp'] + metrics2['tn'])\n",
    "\n",
    "    fph1 = metrics1['fp'] / time1\n",
    "    fnr1 = metrics1['fn'] / (metrics1['fn'] + metrics1['tp'])\n",
    "\n",
    "    fph2 = metrics2['fp'] / time2\n",
    "    fnr2 = metrics2['fn'] / (metrics2['fn'] + metrics2['tp'])\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # ROC Curve\n",
    "    ax[0].plot(fpr1, tpr1, label=f'{model1_name}', color='b')\n",
    "    ax[0].plot(fpr2, tpr2, label=f'{model2_name}', color='g')\n",
    "    ax[0].plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    ax[0].set_xlabel('Taza de falsos positivos')\n",
    "    ax[0].set_ylabel('Taza de verdaderos negativos')\n",
    "    ax[0].set_xlim([0, 0.2])\n",
    "    ax[0].set_title('Curva ROC')\n",
    "    ax[0].legend()\n",
    "    ax[0].grid(True)\n",
    "    \n",
    "    # DET Curve\n",
    "    ax[1].plot(fph1, fnr1, label=f'{model1_name}', color='b')\n",
    "    ax[1].plot(fph2, fnr2, label=f'{model2_name}', color='g')\n",
    "    ax[1].set_yscale('log')\n",
    "    ax[1].set_xscale('log')\n",
    "    ax[1].set_xlabel('Falsos positivos por hora')\n",
    "    ax[1].set_ylabel('Taza de falsos negativos')\n",
    "    ax[1].set_title('Curva DET')\n",
    "    ax[1].legend()\n",
    "    ax[1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Assuming 'metrics1' and 'metrics2' are dictionaries for model 1 and model 2 respectively\n",
    "# 'y_true1' and 'y_pred1' are the true labels and predicted probabilities for model 1\n",
    "# 'y_true2' and 'y_pred2' are the true labels and predicted probabilities for model 2\n",
    "\n",
    "plot_precision_recall_vs_threshold_comparison(metrics, metrics_yamnet, model1_name='Clasificador', model2_name='Yamnet')\n",
    "plot_roc_det_curve_comparison(metrics, metrics_yamnet, model1_name='Clasificador', model2_name='Yamnet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Valores de TP, FP, TN y FN para dos conjuntos\n",
    "tp1, fp1, tn1, fn1 = 50, 10, 30, 10\n",
    "tp2, fp2, tn2, fn2 = 60, 15, 25, 5\n",
    "\n",
    "# Crear las matrices de confusin\n",
    "cm1 = np.array([[tp1, fp1],\n",
    "                [fn1, tn1]])\n",
    "\n",
    "cm2 = np.array([[tp2, fp2],\n",
    "                [fn2, tn2]])\n",
    "\n",
    "# Funcin para convertir la matriz de confusin a porcentajes\n",
    "def to_percentage(cm):\n",
    "    cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    return cm_percentage * 100\n",
    "\n",
    "cm1_percentage = to_percentage(cm1)\n",
    "cm2_percentage = to_percentage(cm2)\n",
    "\n",
    "# Funcin para plotear la matriz de confusin\n",
    "def plot_confusion_matrix(cm, title):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\".2f\", cmap='Blues', cbar=False)\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Graficar las matrices de confusin\n",
    "plot_confusion_matrix(cm1_percentage, 'Confusion Matrix 1 (Percentage)')\n",
    "plot_confusion_matrix(cm2_percentage, 'Confusion Matrix 2 (Percentage)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Datos proporcionados\n",
    "VP = [702, 701, 694, 696]\n",
    "VN = [1211, 1209, 1211, 1210]\n",
    "FP = [15, 17, 15, 16]\n",
    "FN = [36, 37, 44, 42]\n",
    "\n",
    "POS  \n",
    "NEG\n",
    "# Funcin para crear una matriz de confusin\n",
    "def crear_matriz_confusion(VP, VN, FP, FN):\n",
    "    return np.array([[VP, FN],\n",
    "                     [FP, VN]])\n",
    "\n",
    "# Crear las cuatro matrices de confusin\n",
    "matrices_confusion = [crear_matriz_confusion(VP[i], VN[i], FP[i], FN[i]) for i in range(4)]\n",
    "\n",
    "# Plotear las matrices de confusin\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "for i, matriz in enumerate(matrices_confusion):\n",
    "    sns.heatmap(matriz, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, ax=axes[i])\n",
    "    axes[i].set_title(f\"Matriz de Confusin {i+1}\")\n",
    "    axes[i].set_xlabel(\"Prediccin\")\n",
    "    axes[i].set_ylabel(\"Real\")\n",
    "    axes[i].set_xticklabels(['Positivo', 'Negativo'])\n",
    "    axes[i].set_yticklabels(['Positivo', 'Negativo'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11532\\4178909294.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[0mclass_map_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_map_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclass_names_from_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_map_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Should print 'Silence'.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_io as tfio\n",
    "import numpy as np\n",
    "import csv\n",
    "import io\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Load the model.\n",
    "model = hub.load('https://www.kaggle.com/models/google/yamnet/TensorFlow2/yamnet/1')\n",
    "\n",
    "# Input: 3 seconds of silence as mono 16 kHz waveform samples.\n",
    "def load_wav_16k_mono(filename):\n",
    "    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    \n",
    "    return wav\n",
    "\n",
    "waveform = load_wav_16k_mono('res\\\\2024-07-05_11-31-36.wav')\n",
    "\n",
    "# Run the model, check the output.\n",
    "scores, embeddings, log_mel_spectrogram = model(waveform)\n",
    "scores.shape.assert_is_compatible_with([None, 521])\n",
    "embeddings.shape.assert_is_compatible_with([None, 1024])\n",
    "log_mel_spectrogram.shape.assert_is_compatible_with([None, 64])\n",
    "\n",
    "# Find the name of the class with the top score when mean-aggregated across frames.\n",
    "def class_names_from_csv(class_map_csv_text):\n",
    "  \"\"\"Returns list of class names corresponding to score vector.\"\"\"\n",
    "  class_map_csv = io.StringIO(class_map_csv_text)\n",
    "  class_names = [display_name for (class_index, mid, display_name) in csv.reader(class_map_csv)]\n",
    "  class_names = class_names[1:]  # Skip CSV header\n",
    "  return class_names\n",
    "class_map_path = model.class_map_path().numpy()\n",
    "class_names = class_names_from_csv(tf.io.read_file(class_map_path).numpy().decode('utf-8'))\n",
    "print(class_names[scores.numpy().argmax(axis=1)])  # Should print 'Silence'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " '1',\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " '1',\n",
       " '1',\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " '1',\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " '1',\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " '1',\n",
       " '1',\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " '1',\n",
       " '1',\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " '1',\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_yamnet = ['1' if class_names[i] == 'Chainsaw' else 0 for i in scores.numpy().argmax(axis=1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporto el yamnet + mis capas como un solo modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: modelo_final_bn\\assets\n"
     ]
    }
   ],
   "source": [
    "from yamnet import params as yamnet_params\n",
    "from yamnet import yamnet as yamnet_model\n",
    "\n",
    "def load_wav_16k_mono(filename):\n",
    "    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    wav, sample_rate = tf.audio.decode_wav(\n",
    "          file_contents,\n",
    "          desired_channels=1)\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav\n",
    "\n",
    "\n",
    "params = yamnet_params.Params(patch_hop_seconds=0.96)\n",
    "yamnet = yamnet_model.yamnet_frames_model(params)\n",
    "yamnet.load_weights('C:\\\\Users\\\\user\\\\Documents\\\\Tesis\\\\codigo\\\\yamnet\\\\yamnet.h5')\n",
    "yamnet.traineable = False\n",
    "\n",
    "yamnet_input  = yamnet.input\n",
    "yamnet_output = yamnet(yamnet_input)[1]\n",
    "output_final  = classifier.model(yamnet_output)\n",
    "modelo_final  = tf.keras.Model(inputs=yamnet_input, outputs=output_final)\n",
    "modelo_final.compile()\n",
    "modelo_final.save('modelo_final_bn')\n",
    "\n",
    "#classifier.model.save('modelo_propio')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convierto a tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('modelo_final_bn') # path to the SavedModel directory\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('modelo_final.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('modelo_final') # path to the SavedModel directory\n",
    "\n",
    "# Enable float16 quantization\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "\n",
    "# Convert the model to TensorFlow Lite format with float16 quantization\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('modelo_final_float16.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "tf.Tensor(\n",
      "[[0.9999857]\n",
      " [0.9999397]\n",
      " [1.       ]\n",
      " [0.9999953]\n",
      " [1.       ]\n",
      " [0.9952451]], shape=(6, 1), dtype=float32)\n",
      "--------------\n",
      "tf.Tensor(\n",
      "[[0.0016734 ]\n",
      " [0.00352934]\n",
      " [0.00254762]\n",
      " [0.00211295]\n",
      " [0.00035775]\n",
      " [0.09869838]], shape=(6, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "filepath1 = 'C:\\\\Users\\\\user\\\\Documents\\\\Tesis\\\\dataset\\\\audios\\\\1-19898-A-41.wav'\n",
    "filepath2 = 'C:\\\\Users\\\\user\\\\Documents\\\\Tesis\\\\dataset\\\\audios\\\\75263__garybran__heavyfootstompsinforest-1.wav'\n",
    "motosierra = load_wav_16k_mono(filepath1)\n",
    "bosque     = load_wav_16k_mono(filepath2)\n",
    "\n",
    "modelo = tf.keras.models.load_model(\"modelo_final\")\n",
    "\n",
    "print(modelo(motosierra))\n",
    "print('--------------')\n",
    "print(modelo(bosque))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yamnet import params as yamnet_params\n",
    "from yamnet import yamnet as yamnet_model\n",
    "\n",
    "def load_wav_16k_mono(filename):\n",
    "    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    wav, sample_rate = tf.audio.decode_wav(\n",
    "          file_contents,\n",
    "          desired_channels=1)\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav\n",
    "\n",
    "filepath1 = 'C:\\\\Users\\\\user\\\\Documents\\\\Tesis\\\\dataset\\\\audios\\\\1-19898-A-41.wav'\n",
    "filepath2 = 'C:\\\\Users\\\\user\\\\Documents\\\\Tesis\\\\dataset\\\\audios\\\\75263__garybran__heavyfootstompsinforest-1.wav'\n",
    "motosierra = load_wav_16k_mono(filepath1)\n",
    "\n",
    "params = yamnet_params.Params(patch_hop_seconds=0.96, TM=0.2, FM=0.2)\n",
    "yamnet = yamnet_model.yamnet_frames_model(params)\n",
    "yamnet.load_weights('C:\\\\Users\\\\user\\\\Documents\\\\Tesis\\\\codigo\\\\yamnet\\\\yamnet.h5')\n",
    "yamnet.traineable = False\n",
    "\n",
    "scores, embeddings, stft = yamnet(motosierra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "def add_white_noise(tensor, snr_dB):\n",
    "    # Calculate the power of the original signal\n",
    "    signal_power = tf.reduce_mean(tf.square(tensor))\n",
    "    \n",
    "    # Convert SNR from dB to linear scale\n",
    "    snr_linear = tf.pow(10.0, snr_dB / 10.0)\n",
    "    \n",
    "    # Calculate noise power\n",
    "    noise_power = signal_power / snr_linear\n",
    "    \n",
    "    # Generate white noise with the same shape as the input tensor\n",
    "    noise = tf.random.normal(tf.shape(tensor), stddev=tf.sqrt(noise_power))\n",
    "    \n",
    "    # Add noise to the input tensor\n",
    "    noisy_tensor = tensor + noise\n",
    "    \n",
    "    return noisy_tensor\n",
    "\n",
    "def pitch_shift(signal, steps):\n",
    "    # Convert TensorFlow tensor to NumPy array\n",
    "    input_array = signal.numpy()\n",
    "\n",
    "    # Perform pitch shift using librosa\n",
    "    pitch_shifted_array = librosa.effects.pitch_shift(input_array, sr=16000, n_steps=steps)  # Assuming sampling rate of 44100 Hz and pitch shift of 2 semitones\n",
    "\n",
    "    # Convert the pitch-shifted NumPy array back to TensorFlow tensor\n",
    "    pitch_shifted_tensor = tf.constant(pitch_shifted_array, dtype=tf.float32)\n",
    "    return pitch_shifted_tensor\n",
    "\n",
    "\n",
    "def plot_spectrogram(tensor, title='Spectrogram'):\n",
    "    # Convert tensor to NumPy array\n",
    "    tensor_np = tensor.numpy()\n",
    "    \n",
    "    # Calculate spectrogram    \n",
    "    # Plot spectrogram\n",
    "    plt.imshow(tensor_np, aspect='auto', origin='lower') #, extent=[times.min(), times.max(), frequencies.min(), frequencies.max()])\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(title)\n",
    "    plt.colorbar(label='Intensity (dB)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 96, 64), dtype=float32, numpy=\n",
       "array([[[-4.426276  , -3.8136888 , -3.909086  , ..., -4.2971425 ,\n",
       "         -4.5174313 , -4.6094394 ],\n",
       "        [-3.382997  , -3.5896857 , -4.5780907 , ..., -3.961965  ,\n",
       "         -4.5379214 , -4.7375965 ],\n",
       "        [-3.4838333 , -3.7317836 , -4.4966288 , ..., -4.151671  ,\n",
       "         -3.8152423 , -4.578981  ],\n",
       "        ...,\n",
       "        [ 0.813667  ,  0.55188423,  0.30065954, ...,  0.40556756,\n",
       "          0.26622447, -0.5711235 ],\n",
       "        [ 0.15503533, -0.08355621,  0.7519841 , ...,  0.9878304 ,\n",
       "          0.34129146,  0.3472483 ],\n",
       "        [ 0.72728455,  0.9616052 ,  0.7920667 , ...,  0.9668622 ,\n",
       "          0.8843853 ,  0.9467148 ]],\n",
       "\n",
       "       [[ 0.74652135,  0.14266506,  0.54959786, ...,  0.5659682 ,\n",
       "          0.4108854 ,  0.09977674],\n",
       "        [ 0.82860696,  0.63213134,  0.41412857, ...,  0.36817676,\n",
       "          0.4187264 , -0.48190033],\n",
       "        [ 0.1795836 , -0.01125681,  0.78713894, ...,  1.4111152 ,\n",
       "          1.5740588 ,  1.5168401 ],\n",
       "        ...,\n",
       "        [ 1.0180961 ,  0.4317118 ,  0.26890334, ...,  0.75160146,\n",
       "          0.61930317, -0.0999575 ],\n",
       "        [ 0.47542977, -1.7545512 ,  0.8303053 , ..., -0.07988109,\n",
       "          0.15456776, -0.32944068],\n",
       "        [-0.03918033,  0.24598125,  0.81794536, ...,  0.84539914,\n",
       "          0.2548939 ,  0.07003304]],\n",
       "\n",
       "       [[ 0.2914885 ,  0.5858373 ,  1.0200368 , ...,  0.4744963 ,\n",
       "          0.51924497,  0.2871509 ],\n",
       "        [ 0.9785416 ,  1.1526939 ,  0.9488118 , ...,  0.59205866,\n",
       "          0.8378349 ,  0.24569988],\n",
       "        [ 0.85235006, -0.02955906,  0.8143546 , ...,  0.37357235,\n",
       "          0.39791632,  0.04720327],\n",
       "        ...,\n",
       "        [-0.51220775,  0.8206747 ,  1.2890508 , ..., -1.2636231 ,\n",
       "         -1.1706797 , -1.4024397 ],\n",
       "        [ 0.01750625,  0.70427626, -0.11161197, ..., -1.1770672 ,\n",
       "         -1.2358143 , -1.3981723 ],\n",
       "        [ 0.01706969,  0.8970541 ,  1.1526517 , ..., -1.0949191 ,\n",
       "         -1.1775383 , -1.6333613 ]],\n",
       "\n",
       "       [[ 0.1558356 ,  0.26175755, -0.8479465 , ..., -1.1415728 ,\n",
       "         -1.3850533 , -1.6487247 ],\n",
       "        [ 0.28742814,  0.83767337,  1.0022796 , ..., -1.1257775 ,\n",
       "         -1.2686069 , -1.3723114 ],\n",
       "        [-0.33959323,  0.04959553, -0.24966843, ..., -1.3858038 ,\n",
       "         -1.4869968 , -1.3377753 ],\n",
       "        ...,\n",
       "        [-0.61356056, -0.3220122 ,  0.8433138 , ..., -0.44343176,\n",
       "         -0.54816675, -1.7293223 ],\n",
       "        [-0.74116176, -1.016432  ,  0.7899453 , ..., -0.507922  ,\n",
       "         -0.6709257 , -1.0165415 ],\n",
       "        [-1.0704436 , -0.24012493,  0.92912656, ..., -0.6292527 ,\n",
       "         -0.88552344, -0.8113874 ]],\n",
       "\n",
       "       [[-0.49361295,  0.01677936,  0.9316406 , ..., -0.27461475,\n",
       "         -0.36311036, -0.559719  ],\n",
       "        [-0.71409833,  0.15148696,  0.79418814, ..., -0.5988905 ,\n",
       "         -0.64777875, -0.73255855],\n",
       "        [-0.08400433, -0.12506154, -0.44366163, ..., -0.83706194,\n",
       "         -0.71765995, -1.0762292 ],\n",
       "        ...,\n",
       "        [ 0.12416022,  0.6994275 ,  0.77929723, ..., -1.1734108 ,\n",
       "         -1.3619221 , -1.7102749 ],\n",
       "        [-0.55664974,  0.0328402 ,  0.5173223 , ..., -0.3680543 ,\n",
       "         -0.6870161 , -0.6088412 ],\n",
       "        [ 0.14500187,  0.28558537, -0.15788735, ...,  0.34575686,\n",
       "         -0.08796531,  0.17112029]],\n",
       "\n",
       "       [[ 0.07424871,  0.42140037,  0.997941  , ..., -0.8803951 ,\n",
       "         -0.34946322, -0.84420246],\n",
       "        [-0.78413624,  0.6106639 ,  1.2383661 , ..., -1.1620789 ,\n",
       "         -0.77619034, -1.6956862 ],\n",
       "        [-0.199986  ,  0.686816  ,  1.0283304 , ..., -1.1542351 ,\n",
       "         -0.9765956 , -1.5885506 ],\n",
       "        ...,\n",
       "        [-6.9077554 , -6.9077554 , -6.9077554 , ..., -6.9077554 ,\n",
       "         -6.9077554 , -6.9077554 ],\n",
       "        [-6.9077554 , -6.9077554 , -6.9077554 , ..., -6.9077554 ,\n",
       "         -6.9077554 , -6.9077554 ],\n",
       "        [-6.9077554 , -6.9077554 , -6.9077554 , ..., -6.9077554 ,\n",
       "         -6.9077554 , -6.9077554 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrogram_hop_length_samples = int(round(params.sample_rate * params.stft_hop_seconds))\n",
    "spectrogram_sample_rate = params.sample_rate / spectrogram_hop_length_samples\n",
    "patch_window_length_samples = int(round(spectrogram_sample_rate * params.patch_window_seconds))\n",
    "patch_hop_length_samples = int(round(spectrogram_sample_rate * params.patch_hop_seconds))\n",
    "features = tf.signal.frame(\n",
    "        signal=stft,\n",
    "        frame_length=patch_window_length_samples,\n",
    "        frame_step=patch_hop_length_samples,\n",
    "        axis=0)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for i in range(tf.shape(features)[0]):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stft_time_masked = tfio.audio.time_mask(stft, param=50)\n",
    "stft_freq_masked = tfio.audio.freq_mask(stft, param=10)\n",
    "\n",
    "plot_spectrogram(stft_freq_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording... Press Ctrl+C to stop.\n",
      "Todo ok\n",
      "Todo ok\n",
      "Todo ok\n",
      "Todo ok\n",
      "Todo ok\n",
      "Todo ok\n",
      "Todo ok\n",
      "Todo ok\n",
      "Todo ok\n",
      "Todo ok\n",
      "Todo ok\n",
      "Todo ok\n",
      "Todo ok\n",
      "Finished recording.\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "\n",
    "# Define constants for audio recording\n",
    "SAMPLE_RATE = 16000  # Sample rate (Hz)\n",
    "CHANNELS = 1         # Number of audio channels\n",
    "BLOCK_LENGHT = int(0.96*SAMPLE_RATE)\n",
    "\n",
    "try:\n",
    "    model_path = 'C:\\\\Users\\\\user\\\\Documents\\\\Tesis\\\\codigo\\\\modelo_final.tflite'\n",
    "    interpreter = tf.lite.Interpreter(model_path)\n",
    "\n",
    "    input_details = interpreter.get_input_details()\n",
    "    waveform_input_index = input_details[0]['index']\n",
    "    output_details = interpreter.get_output_details()\n",
    "    scores_output_index = output_details[0]['index']\n",
    "\n",
    "    interpreter.resize_tensor_input(waveform_input_index, [int(0.96*16000)], strict=False)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "except:\n",
    "    print('Error cargando el modelo')\n",
    "\n",
    "# Function to process audio data\n",
    "def process_audio(indata, frames, time, status):\n",
    "    # Convert audio data to numpy array\n",
    "    audio_data = np.asarray(indata, np.float32)\n",
    "    audio_data = audio_data.reshape(-1)\n",
    "\n",
    "    interpreter.set_tensor(waveform_input_index, audio_data)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(scores_output_index)\n",
    "    \n",
    "    if output > 0.9:\n",
    "        print('Motosierra!')\n",
    "    else:\n",
    "        print('Todo ok')\n",
    "    \n",
    "\n",
    "    # Calculate amplitude (absolute maximum) of audio samples\n",
    "    \n",
    "# Open a stream for audio input\n",
    "stream = sd.InputStream(callback=process_audio, blocksize=int(0.96*16000), \n",
    "                        samplerate=SAMPLE_RATE, channels=CHANNELS, dtype=np.float32)\n",
    "\n",
    "print(\"Recording... Press Ctrl+C to stop.\")\n",
    "\n",
    "# Start audio stream\n",
    "with stream:\n",
    "    try:\n",
    "        # Keep the stream open until interrupted by Ctrl+C\n",
    "        while True:\n",
    "            pass\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "print(\"Finished recording.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9999857 ]\n",
      " [0.99993956]\n",
      " [1.        ]\n",
      " [0.9999953 ]\n",
      " [1.        ]\n",
      " [0.9952452 ]]\n"
     ]
    }
   ],
   "source": [
    "model_path = 'modelo_final.tflite'\n",
    "interpreter = tf.lite.Interpreter(model_path)\n",
    "\n",
    "def load_wav_16k_mono(filename):\n",
    "    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    wav, sample_rate = tf.audio.decode_wav(\n",
    "          file_contents,\n",
    "          desired_channels=1)\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "waveform_input_index = input_details[0]['index']\n",
    "output_details = interpreter.get_output_details()\n",
    "scores_output_index = output_details[0]['index']\n",
    "\n",
    "# Input: 0.975 seconds of silence as mono 16 kHz waveform samples.\n",
    "filepath1 = 'C:\\\\Users\\\\user\\\\Documents\\\\Tesis\\\\dataset\\\\audios\\\\1-19898-A-41.wav'\n",
    "waveform = load_wav_16k_mono(filepath1)\n",
    "\n",
    "interpreter.resize_tensor_input(waveform_input_index, [tf.shape(waveform)[0]], strict=True)\n",
    "interpreter.allocate_tensors()\n",
    "interpreter.set_tensor(waveform_input_index, waveform)\n",
    "interpreter.invoke()\n",
    "scores = interpreter.get_tensor(scores_output_index)\n",
    "print(scores)  # Should print (1, 521)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "\n",
    "tflite_fp16_model = converter.convert()\n",
    "tflite_model_fp16_file = tflite_models_dir/\"mnist_model_quant_f16.tflite\"\n",
    "tflite_model_fp16_file.write_bytes(tflite_fp16_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cortando negativos otra vez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import soundfile as sf\n",
    "\n",
    "enteros = '..\\\\dataset\\\\bosques\\\\Enteros'\n",
    "cortados = '..\\\\dataset\\\\bosques'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(enteros):\n",
    "    filepath = os.path.join(enteros, file)\n",
    "    \n",
    "    sr = sf.info(filepath).samplerate\n",
    "\n",
    "    \n",
    "    bloques = sf.blocks(filepath, blocksize=sr*5)\n",
    "    n = 1\n",
    "    \n",
    "    for block in bloques:\n",
    "        if sf.info(filepath).channels == 2:\n",
    "            block = (block[:,0] + block[:,1])        \n",
    "        fname = f'{file[:-4]}-{n}.wav'\n",
    "        sf.write(os.path.join(cortados, fname), block, samplerate = sr)\n",
    "        n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for i in os.listdir(cortados):\n",
    "    dic = {'filename':i,\n",
    "           'category':0}\n",
    "    lst.append(dic)\n",
    "lst\n",
    "df2 = pd.DataFrame(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"..\\\\metadata.csv\")\n",
    "df = df[df.category != 0]\n",
    "\n",
    "concatenated_df = pd.concat([df, df2])\n",
    "\n",
    "# Reset index if needed\n",
    "concatenated_df.reset_index(drop=True, inplace=True)\n",
    "concatenated_df.to_csv(\"..\\\\metadata.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
